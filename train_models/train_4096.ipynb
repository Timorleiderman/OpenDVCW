{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "import OpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import DataGen\n",
    "import Callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 500\n",
    "STEPS_PER_EPOCH = 100\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 4096\n",
    "lr_init = 1e-8\n",
    "early_stop = 40\n",
    "I_QP=27\n",
    "\n",
    "args = OpenDVCW.Arguments()\n",
    "last = 12\n",
    "checkponts_last_path = \"checkpoints_wavelets_L_{}_{}_{}x{}/\".format(lmbda, last, Width, Height)\n",
    "checkponts_new_path = \"checkpoints_wavelets_L_{}_{}_{}x{}/\".format(lmbda, last+1, Width, Height)\n",
    "save_name = \"model_save_wavelets_L_{}_{}_{}x{}\".format(lmbda, last+1, Width, Height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "* [Loading dataset]...\n",
      "Loading weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fccf68f3610>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OpenDVCW.OpenDVC(width=Width, height=Height, batch_size=BATCH_SIZE, num_filters=128, lmbda=lmbda)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init),)\n",
    "print(\"* [Model compiled]...\")\n",
    "\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = DataGen.DataVimeo90kGenerator(\"folder_cloud_test.npy\", \n",
    "                                    BATCH_SIZE,\n",
    "                                    (Height,Width,Channel),\n",
    "                                    Channel,\n",
    "                                    True, \n",
    "                                    I_QP,\n",
    "                                    True)\n",
    "\n",
    "print(\"Loading weights\")\n",
    "model.load_weights(checkponts_last_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].trainable = False\n",
    "# model.layers[1].trainable = False\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[3].trainable = True\n",
    "# model.layers[4].trainable = False\n",
    "# model.layers[5].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_analysis True\n",
      "mv_synthesis True\n",
      "res_analysis True\n",
      "res_synthesis True\n",
      "wavelets_optical_flow_4 True\n",
      "motion_compensation_4 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  6/100 [>.............................] - ETA: 19s - loss: 1.6893 - bpp: 0.7375 - mse: 2.3238e-04WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1969s vs `on_train_batch_end` time: 0.2260s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1969s vs `on_train_batch_end` time: 0.2260s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 1.4255 - bpp: 0.7079 - mse: 1.7519e-04[MemoryCallback]:  10094976\n",
      "\n",
      "Epoch 1: loss improved from inf to 1.42546, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 63s 184ms/step - loss: 1.4255 - bpp: 0.7079 - mse: 1.7519e-04\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3263 - bpp: 0.6681 - mse: 1.6069e-04[MemoryCallback]:  10170508\n",
      "\n",
      "Epoch 2: loss improved from 1.42546 to 1.32629, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 1.3263 - bpp: 0.6681 - mse: 1.6069e-04\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3150 - bpp: 0.6672 - mse: 1.5816e-04[MemoryCallback]:  10223164\n",
      "\n",
      "Epoch 3: loss improved from 1.32629 to 1.31501, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 1.3150 - bpp: 0.6672 - mse: 1.5816e-04\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4907 - bpp: 0.7053 - mse: 1.9176e-04[MemoryCallback]:  10223264\n",
      "\n",
      "Epoch 4: loss did not improve from 1.31501\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 1.4907 - bpp: 0.7053 - mse: 1.9176e-04\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3114 - bpp: 0.6765 - mse: 1.5500e-04[MemoryCallback]:  10223264\n",
      "\n",
      "Epoch 5: loss improved from 1.31501 to 1.31136, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 1.3114 - bpp: 0.6765 - mse: 1.5500e-04\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2700 - bpp: 0.6509 - mse: 1.5117e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 6: loss improved from 1.31136 to 1.27004, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 1.2700 - bpp: 0.6509 - mse: 1.5117e-04\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2884 - bpp: 0.6568 - mse: 1.5419e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 7: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 1.2884 - bpp: 0.6568 - mse: 1.5419e-04\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4637 - bpp: 0.7038 - mse: 1.8550e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 8: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 18s 174ms/step - loss: 1.4637 - bpp: 0.7038 - mse: 1.8550e-04\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3493 - bpp: 0.6765 - mse: 1.6425e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 9: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 1.3493 - bpp: 0.6765 - mse: 1.6425e-04\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3674 - bpp: 0.6728 - mse: 1.6957e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 10: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 1.3674 - bpp: 0.6728 - mse: 1.6957e-04\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3739 - bpp: 0.6504 - mse: 1.7663e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 11: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 1.3739 - bpp: 0.6504 - mse: 1.7663e-04\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5155 - bpp: 0.7298 - mse: 1.9181e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 12: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 21s 202ms/step - loss: 1.5155 - bpp: 0.7298 - mse: 1.9181e-04\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3536 - bpp: 0.6851 - mse: 1.6321e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 13: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 21s 200ms/step - loss: 1.3536 - bpp: 0.6851 - mse: 1.6321e-04\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4178 - bpp: 0.6873 - mse: 1.7836e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 14: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 1.4178 - bpp: 0.6873 - mse: 1.7836e-04\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4245 - bpp: 0.6805 - mse: 1.8164e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 15: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.4245 - bpp: 0.6805 - mse: 1.8164e-04\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2821 - bpp: 0.6493 - mse: 1.5449e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 16: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 1.2821 - bpp: 0.6493 - mse: 1.5449e-04\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3753 - bpp: 0.6923 - mse: 1.6674e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 17: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 1.3753 - bpp: 0.6923 - mse: 1.6674e-04\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5440 - bpp: 0.7233 - mse: 2.0037e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 18: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 20s 195ms/step - loss: 1.5440 - bpp: 0.7233 - mse: 2.0037e-04\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3147 - bpp: 0.6722 - mse: 1.5684e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 19: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 20s 194ms/step - loss: 1.3147 - bpp: 0.6722 - mse: 1.5684e-04\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2930 - bpp: 0.6416 - mse: 1.5905e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 20: loss did not improve from 1.27004\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.2930 - bpp: 0.6416 - mse: 1.5905e-04\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2279 - bpp: 0.6302 - mse: 1.4592e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 21: loss improved from 1.27004 to 1.22792, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 22s 212ms/step - loss: 1.2279 - bpp: 0.6302 - mse: 1.4592e-04\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2352 - bpp: 0.6572 - mse: 1.4112e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 22: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 1.2352 - bpp: 0.6572 - mse: 1.4112e-04\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5780 - bpp: 0.7345 - mse: 2.0595e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 23: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 1.5780 - bpp: 0.7345 - mse: 2.0595e-04\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5254 - bpp: 0.6945 - mse: 2.0287e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 24: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.5254 - bpp: 0.6945 - mse: 2.0287e-04\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4544 - bpp: 0.7172 - mse: 1.7998e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 25: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 1.4544 - bpp: 0.7172 - mse: 1.7998e-04\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2955 - bpp: 0.6692 - mse: 1.5291e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 26: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 22s 214ms/step - loss: 1.2955 - bpp: 0.6692 - mse: 1.5291e-04\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4020 - bpp: 0.6981 - mse: 1.7185e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 27: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 20s 195ms/step - loss: 1.4020 - bpp: 0.6981 - mse: 1.7185e-04\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4203 - bpp: 0.6863 - mse: 1.7921e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 28: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.4203 - bpp: 0.6863 - mse: 1.7921e-04\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5311 - bpp: 0.7039 - mse: 2.0195e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 29: loss did not improve from 1.22792\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.5311 - bpp: 0.7039 - mse: 2.0195e-04\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2188 - bpp: 0.6212 - mse: 1.4589e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 30: loss improved from 1.22792 to 1.21878, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.2188 - bpp: 0.6212 - mse: 1.4589e-04\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3013 - bpp: 0.6702 - mse: 1.5406e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 31: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.3013 - bpp: 0.6702 - mse: 1.5406e-04\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4067 - bpp: 0.6768 - mse: 1.7818e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 32: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 195ms/step - loss: 1.4067 - bpp: 0.6768 - mse: 1.7818e-04\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3230 - bpp: 0.6710 - mse: 1.5919e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 33: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.3230 - bpp: 0.6710 - mse: 1.5919e-04\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2547 - bpp: 0.6422 - mse: 1.4954e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 34: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 1.2547 - bpp: 0.6422 - mse: 1.4954e-04\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4739 - bpp: 0.7034 - mse: 1.8812e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 35: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.4739 - bpp: 0.7034 - mse: 1.8812e-04\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3919 - bpp: 0.6757 - mse: 1.7487e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 36: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 1.3919 - bpp: 0.6757 - mse: 1.7487e-04\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2545 - bpp: 0.6551 - mse: 1.4633e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 37: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 203ms/step - loss: 1.2545 - bpp: 0.6551 - mse: 1.4633e-04\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4408 - bpp: 0.6710 - mse: 1.8794e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 38: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.4408 - bpp: 0.6710 - mse: 1.8794e-04\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2552 - bpp: 0.6445 - mse: 1.4909e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 39: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.2552 - bpp: 0.6445 - mse: 1.4909e-04\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4338 - bpp: 0.6728 - mse: 1.8578e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 40: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.4338 - bpp: 0.6728 - mse: 1.8578e-04\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4279 - bpp: 0.7007 - mse: 1.7753e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 41: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.4279 - bpp: 0.7007 - mse: 1.7753e-04\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2961 - bpp: 0.6396 - mse: 1.6028e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 42: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.2961 - bpp: 0.6396 - mse: 1.6028e-04\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2791 - bpp: 0.6444 - mse: 1.5497e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 43: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 1.2791 - bpp: 0.6444 - mse: 1.5497e-04\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3453 - bpp: 0.6800 - mse: 1.6243e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 44: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 1.3453 - bpp: 0.6800 - mse: 1.6243e-04\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2691 - bpp: 0.6597 - mse: 1.4880e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 45: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 204ms/step - loss: 1.2691 - bpp: 0.6597 - mse: 1.4880e-04\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3206 - bpp: 0.6617 - mse: 1.6085e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 46: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.3206 - bpp: 0.6617 - mse: 1.6085e-04\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3495 - bpp: 0.6764 - mse: 1.6434e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 47: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.3495 - bpp: 0.6764 - mse: 1.6434e-04\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4214 - bpp: 0.6780 - mse: 1.8149e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 48: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 1.4214 - bpp: 0.6780 - mse: 1.8149e-04\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3904 - bpp: 0.6804 - mse: 1.7334e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 49: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.3904 - bpp: 0.6804 - mse: 1.7334e-04\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3614 - bpp: 0.6444 - mse: 1.7505e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 50: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 1.3614 - bpp: 0.6444 - mse: 1.7505e-04\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2918 - bpp: 0.6467 - mse: 1.5749e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 51: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.2918 - bpp: 0.6467 - mse: 1.5749e-04\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3454 - bpp: 0.6619 - mse: 1.6689e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 52: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.3454 - bpp: 0.6619 - mse: 1.6689e-04\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5182 - bpp: 0.7163 - mse: 1.9577e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 53: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 1.5182 - bpp: 0.7163 - mse: 1.9577e-04\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3931 - bpp: 0.6712 - mse: 1.7625e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 54: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.3931 - bpp: 0.6712 - mse: 1.7625e-04\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2650 - bpp: 0.6401 - mse: 1.5257e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 55: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 1.2650 - bpp: 0.6401 - mse: 1.5257e-04\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3320 - bpp: 0.6627 - mse: 1.6340e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 56: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.3320 - bpp: 0.6627 - mse: 1.6340e-04\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4791 - bpp: 0.7214 - mse: 1.8499e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 57: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.4791 - bpp: 0.7214 - mse: 1.8499e-04\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2983 - bpp: 0.6639 - mse: 1.5488e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 58: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.2983 - bpp: 0.6639 - mse: 1.5488e-04\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2303 - bpp: 0.6506 - mse: 1.4153e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 59: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.2303 - bpp: 0.6506 - mse: 1.4153e-04\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5381 - bpp: 0.6898 - mse: 2.0711e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 60: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 1.5381 - bpp: 0.6898 - mse: 2.0711e-04\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3109 - bpp: 0.6499 - mse: 1.6139e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 61: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 1.3109 - bpp: 0.6499 - mse: 1.6139e-04\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2623 - bpp: 0.6555 - mse: 1.4813e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 62: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 22s 214ms/step - loss: 1.2623 - bpp: 0.6555 - mse: 1.4813e-04\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4223 - bpp: 0.6967 - mse: 1.7715e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 63: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.4223 - bpp: 0.6967 - mse: 1.7715e-04\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2592 - bpp: 0.6377 - mse: 1.5173e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 64: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.2592 - bpp: 0.6377 - mse: 1.5173e-04\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3286 - bpp: 0.6718 - mse: 1.6036e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 65: loss did not improve from 1.21878\n",
      "100/100 [==============================] - 21s 202ms/step - loss: 1.3286 - bpp: 0.6718 - mse: 1.6036e-04\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1839 - bpp: 0.6187 - mse: 1.3799e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 66: loss improved from 1.21878 to 1.18391, saving model to checkpoints_wavelets_L_4096_13_240x240/\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 1.1839 - bpp: 0.6187 - mse: 1.3799e-04\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2703 - bpp: 0.6620 - mse: 1.4852e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 67: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 195ms/step - loss: 1.2703 - bpp: 0.6620 - mse: 1.4852e-04\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2998 - bpp: 0.6505 - mse: 1.5854e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 68: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 195ms/step - loss: 1.2998 - bpp: 0.6505 - mse: 1.5854e-04\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3141 - bpp: 0.6682 - mse: 1.5768e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 69: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.3141 - bpp: 0.6682 - mse: 1.5768e-04\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7502 - bpp: 0.7716 - mse: 2.3893e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 70: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.7502 - bpp: 0.7716 - mse: 2.3893e-04\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2322 - bpp: 0.6352 - mse: 1.4575e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 71: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.2322 - bpp: 0.6352 - mse: 1.4575e-04\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4296 - bpp: 0.6825 - mse: 1.8241e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 72: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.4296 - bpp: 0.6825 - mse: 1.8241e-04\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6111 - bpp: 0.7427 - mse: 2.1202e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 73: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 1.6111 - bpp: 0.7427 - mse: 2.1202e-04\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3170 - bpp: 0.6600 - mse: 1.6041e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 74: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.3170 - bpp: 0.6600 - mse: 1.6041e-04\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2513 - bpp: 0.6462 - mse: 1.4774e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 75: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.2513 - bpp: 0.6462 - mse: 1.4774e-04\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4628 - bpp: 0.7139 - mse: 1.8284e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 76: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 1.4628 - bpp: 0.7139 - mse: 1.8284e-04\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5022 - bpp: 0.7184 - mse: 1.9136e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 77: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 1.5022 - bpp: 0.7184 - mse: 1.9136e-04\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3743 - bpp: 0.6735 - mse: 1.7110e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 78: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.3743 - bpp: 0.6735 - mse: 1.7110e-04\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4331 - bpp: 0.6705 - mse: 1.8617e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 79: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 1.4331 - bpp: 0.6705 - mse: 1.8617e-04\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4338 - bpp: 0.6931 - mse: 1.8082e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 80: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 1.4338 - bpp: 0.6931 - mse: 1.8082e-04\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6782 - bpp: 0.7402 - mse: 2.2902e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 81: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.6782 - bpp: 0.7402 - mse: 2.2902e-04\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3449 - bpp: 0.6736 - mse: 1.6391e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 82: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 23s 221ms/step - loss: 1.3449 - bpp: 0.6736 - mse: 1.6391e-04\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2428 - bpp: 0.6273 - mse: 1.5027e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 83: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.2428 - bpp: 0.6273 - mse: 1.5027e-04\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3172 - bpp: 0.6673 - mse: 1.5866e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 84: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 1.3172 - bpp: 0.6673 - mse: 1.5866e-04\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3602 - bpp: 0.6700 - mse: 1.6849e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 85: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 1.3602 - bpp: 0.6700 - mse: 1.6849e-04\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2082 - bpp: 0.6404 - mse: 1.3862e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 86: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 1.2082 - bpp: 0.6404 - mse: 1.3862e-04\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4175 - bpp: 0.6813 - mse: 1.7972e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 87: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.4175 - bpp: 0.6813 - mse: 1.7972e-04\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2658 - bpp: 0.6569 - mse: 1.4863e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 88: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 1.2658 - bpp: 0.6569 - mse: 1.4863e-04\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4050 - bpp: 0.6748 - mse: 1.7826e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 89: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 1.4050 - bpp: 0.6748 - mse: 1.7826e-04\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4274 - bpp: 0.6831 - mse: 1.8171e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 90: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.4274 - bpp: 0.6831 - mse: 1.8171e-04\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2677 - bpp: 0.6439 - mse: 1.5229e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 91: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.2677 - bpp: 0.6439 - mse: 1.5229e-04\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3908 - bpp: 0.6881 - mse: 1.7157e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 92: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 22s 214ms/step - loss: 1.3908 - bpp: 0.6881 - mse: 1.7157e-04\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4504 - bpp: 0.6818 - mse: 1.8764e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 93: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.4504 - bpp: 0.6818 - mse: 1.8764e-04\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4758 - bpp: 0.6899 - mse: 1.9186e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 94: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 1.4758 - bpp: 0.6899 - mse: 1.9186e-04\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1904 - bpp: 0.6316 - mse: 1.3643e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 95: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.1904 - bpp: 0.6316 - mse: 1.3643e-04\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5000 - bpp: 0.7051 - mse: 1.9408e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 96: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.5000 - bpp: 0.7051 - mse: 1.9408e-04\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3727 - bpp: 0.6763 - mse: 1.7001e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 97: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 204ms/step - loss: 1.3727 - bpp: 0.6763 - mse: 1.7001e-04\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3972 - bpp: 0.6772 - mse: 1.7577e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 98: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.3972 - bpp: 0.6772 - mse: 1.7577e-04\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3311 - bpp: 0.6468 - mse: 1.6707e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 99: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.3311 - bpp: 0.6468 - mse: 1.6707e-04\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4295 - bpp: 0.7047 - mse: 1.7694e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 100: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 1.4295 - bpp: 0.7047 - mse: 1.7694e-04\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2671 - bpp: 0.6368 - mse: 1.5387e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch 101: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.2671 - bpp: 0.6368 - mse: 1.5387e-04\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2585 - bpp: 0.6450 - mse: 1.4977e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch: 101. Reducing Learning Rate from 2.8470813049352728e-05 to 2.818610482790973e-05\n",
      "\n",
      "Epoch 102: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 1.2585 - bpp: 0.6450 - mse: 1.4977e-04\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3042 - bpp: 0.6372 - mse: 1.6285e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch: 102. Reducing Learning Rate from 2.818610482790973e-05 to 2.7904243324883282e-05\n",
      "\n",
      "Epoch 103: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 22s 210ms/step - loss: 1.3042 - bpp: 0.6372 - mse: 1.6285e-04\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3793 - bpp: 0.6688 - mse: 1.7346e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch: 103. Reducing Learning Rate from 2.7904243324883282e-05 to 2.762520125543233e-05\n",
      "\n",
      "Epoch 104: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.3793 - bpp: 0.6688 - mse: 1.7346e-04\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5071 - bpp: 0.7038 - mse: 1.9611e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch: 104. Reducing Learning Rate from 2.762520125543233e-05 to 2.7348949515726417e-05\n",
      "\n",
      "Epoch 105: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5071 - bpp: 0.7038 - mse: 1.9611e-04\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3338 - bpp: 0.6672 - mse: 1.6275e-04[MemoryCallback]:  10223328\n",
      "\n",
      "Epoch: 105. Reducing Learning Rate from 2.7348949515726417e-05 to 2.707546082092449e-05\n",
      "\n",
      "Epoch 106: loss did not improve from 1.18391\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 1.3338 - bpp: 0.6672 - mse: 1.6275e-04\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "hist = model.fit(x=data, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, verbose=1, batch_size=BATCH_SIZE,\n",
    "                callbacks=[\n",
    "                    Callbacks.MemoryCallback(),\n",
    "                    Callbacks.LearningRateReducer(),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch', monitor=\"loss\", mode='min',  save_best_only=True, verbose=1), \n",
    "                    tf.keras.callbacks.TerminateOnNaN(),\n",
    "                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stop),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq=\"epoch\"),            \n",
    "                    ],\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00088/0172/im1.png\n",
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n"
     ]
    }
   ],
   "source": [
    "path = load.load_random_path(\"folder_cloud_test.npy\")\n",
    "i=0\n",
    "out_bin = \"Test_com/test{}.bin\".format(i)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(i)\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(i)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(i)\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, out_bin, out_decom, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_4_layer_call_fn, optical_flow_loss_4_layer_call_and_return_conditional_losses, dwt_4_layer_call_fn, dwt_4_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_wavelets_L_4096_13_240x240/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_wavelets_L_4096_13_240x240/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00049/0289/im1.png\n",
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00049/0289/im2.png\n",
      "compress\n",
      "decompress\n",
      "bin size:  2398 psnr:  41.02665227844598\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from math import log10, sqrt\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "\n",
    "path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "p_frame_out_bin = \"Test_com/dvcw/p_frame_dvcw.bin\"\n",
    "out_decom = \"Test_com/dvcw/frame1.png\"\n",
    "i_on_test = \"Test_com/frame0.png\"\n",
    "p_on_test = \"Test_com/frame1.png\"\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "print(p_frame)\n",
    "\n",
    "# write inputs to disk\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, p_frame_out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, p_frame_out_bin, out_decom, 240, 240)\n",
    "\n",
    "\n",
    "original = cv2.imread(p_on_test)\n",
    "compressed = cv2.imread(out_decom)\n",
    "bin_size = os.path.getsize(p_frame_out_bin)\n",
    "value = PSNR(original, compressed)\n",
    "print(\"bin size: \", bin_size , \"psnr: \", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
