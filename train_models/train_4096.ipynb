{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW/train_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "import OpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import DataGen\n",
    "import Callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 700\n",
    "STEPS_PER_EPOCH = 200\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 4096\n",
    "lr_init = 1e-4\n",
    "early_stop = 15\n",
    "I_QP=27\n",
    "\n",
    "args = OpenDVCW.Arguments()\n",
    "last = 0\n",
    "checkponts_last_path = \"checkpoints_wavelets_L_{}_{}_{}x{}/\".format(lmbda, last, Width, Height)\n",
    "checkponts_new_path = \"checkpoints_wavelets_L_{}_{}_{}x{}/\".format(lmbda, last+1, Width, Height)\n",
    "save_name = \"model_save_wavelets_L_{}_{}_{}x{}\".format(lmbda, last+1, Width, Height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 12:12:58.278104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:12:58.348177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:12:58.349496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:12:58.353395: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 12:12:58.359147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:12:58.360190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:12:58.361075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:13:00.232479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:13:00.233273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:13:00.234029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 12:13:00.234784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "* [Loading dataset]...\n"
     ]
    }
   ],
   "source": [
    "model = OpenDVCW.OpenDVC(width=Width, height=Height, batch_size=BATCH_SIZE, num_filters=128, lmbda=lmbda)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init),)\n",
    "print(\"* [Model compiled]...\")\n",
    "\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = DataGen.DataVimeo90kGenerator(\"folder_cloud_test.npy\", \n",
    "                                    BATCH_SIZE,\n",
    "                                    (Height,Width,Channel),\n",
    "                                    Channel,\n",
    "                                    True, \n",
    "                                    I_QP,\n",
    "                                    True)\n",
    "\n",
    "# print(\"Loading weights\")\n",
    "# model.load_weights(checkponts_last_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].trainable = False\n",
    "# model.layers[1].trainable = False\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[3].trainable = True\n",
    "# model.layers[4].trainable = False\n",
    "# model.layers[5].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_analysis True\n",
      "mv_synthesis True\n",
      "res_analysis True\n",
      "res_synthesis True\n",
      "wavelets_optical_flow True\n",
      "motion_compensation True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 12:13:18.718830: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-06 12:13:45.014248: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/200 [..............................] - ETA: 33s - loss: 498.1257 - bpp: 5.3797 - mse: 0.1203WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1600s vs `on_train_batch_end` time: 0.2153s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1600s vs `on_train_batch_end` time: 0.2153s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 59.9549 - bpp: 5.3119 - mse: 0.0133[MemoryCallback]:  4812168\n",
      "\n",
      "Epoch 1: loss improved from inf to 59.95486, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 76s 183ms/step - loss: 59.9549 - bpp: 5.3119 - mse: 0.0133\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.8178 - bpp: 5.1730 - mse: 0.0028[MemoryCallback]:  4927068\n",
      "\n",
      "Epoch 2: loss improved from 59.95486 to 16.81783, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 16.8178 - bpp: 5.1730 - mse: 0.0028\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.6631 - bpp: 5.0371 - mse: 0.0024[MemoryCallback]:  4987520\n",
      "\n",
      "Epoch 3: loss improved from 16.81783 to 14.66315, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 14.6631 - bpp: 5.0371 - mse: 0.0024\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.8906 - bpp: 4.9038 - mse: 0.0019[MemoryCallback]:  5082380\n",
      "\n",
      "Epoch 4: loss improved from 14.66315 to 12.89062, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 12.8906 - bpp: 4.9038 - mse: 0.0019\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5183 - bpp: 4.7727 - mse: 0.0012[MemoryCallback]:  5142832\n",
      "\n",
      "Epoch 5: loss improved from 12.89062 to 9.51830, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 9.5183 - bpp: 4.7727 - mse: 0.0012\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5859 - bpp: 4.6455 - mse: 9.6202e-04[MemoryCallback]:  5196460\n",
      "\n",
      "Epoch 6: loss improved from 9.51830 to 8.58589, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 8.5859 - bpp: 4.6455 - mse: 9.6202e-04\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1124 - bpp: 4.5202 - mse: 8.7700e-04[MemoryCallback]:  5248960\n",
      "\n",
      "Epoch 7: loss improved from 8.58589 to 8.11240, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 8.1124 - bpp: 4.5202 - mse: 8.7700e-04\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3553 - bpp: 4.3970 - mse: 7.2225e-04[MemoryCallback]:  5297888\n",
      "\n",
      "Epoch 8: loss improved from 8.11240 to 7.35534, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 7.3553 - bpp: 4.3970 - mse: 7.2225e-04\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3458 - bpp: 4.2776 - mse: 7.4906e-04[MemoryCallback]:  5301420\n",
      "\n",
      "Epoch 9: loss improved from 7.35534 to 7.34578, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 7.3458 - bpp: 4.2776 - mse: 7.4906e-04\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9645 - bpp: 4.1603 - mse: 6.8461e-04[MemoryCallback]:  5344384\n",
      "\n",
      "Epoch 10: loss improved from 7.34578 to 6.96448, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 6.9645 - bpp: 4.1603 - mse: 6.8461e-04\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7872 - bpp: 4.0461 - mse: 6.6920e-04[MemoryCallback]:  5399508\n",
      "\n",
      "Epoch 11: loss improved from 6.96448 to 6.78716, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 6.7872 - bpp: 4.0461 - mse: 6.6920e-04\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2735 - bpp: 3.9328 - mse: 5.7145e-04[MemoryCallback]:  5457424\n",
      "\n",
      "Epoch 12: loss improved from 6.78716 to 6.27348, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 6.2735 - bpp: 3.9328 - mse: 5.7145e-04\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4940 - bpp: 3.8249 - mse: 6.5164e-04[MemoryCallback]:  5517612\n",
      "\n",
      "Epoch 13: loss did not improve from 6.27348\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 6.4940 - bpp: 3.8249 - mse: 6.5164e-04\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1766 - bpp: 3.7160 - mse: 6.0074e-04[MemoryCallback]:  5517612\n",
      "\n",
      "Epoch 14: loss improved from 6.27348 to 6.17657, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 6.1766 - bpp: 3.7160 - mse: 6.0074e-04\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0849 - bpp: 3.6110 - mse: 6.0397e-04[MemoryCallback]:  5568340\n",
      "\n",
      "Epoch 15: loss improved from 6.17657 to 6.08488, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 6.0849 - bpp: 3.6110 - mse: 6.0397e-04\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2880 - bpp: 3.5049 - mse: 4.3534e-04[MemoryCallback]:  5616380\n",
      "\n",
      "Epoch 16: loss improved from 6.08488 to 5.28804, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 5.2880 - bpp: 3.5049 - mse: 4.3534e-04\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0870 - bpp: 3.4056 - mse: 4.1050e-04[MemoryCallback]:  5666916\n",
      "\n",
      "Epoch 17: loss improved from 5.28804 to 5.08701, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 5.0870 - bpp: 3.4056 - mse: 4.1050e-04\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1527 - bpp: 3.3088 - mse: 4.5015e-04[MemoryCallback]:  5667544\n",
      "\n",
      "Epoch 18: loss did not improve from 5.08701\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 5.1527 - bpp: 3.3088 - mse: 4.5015e-04\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2867 - bpp: 3.2167 - mse: 5.0536e-04[MemoryCallback]:  5667544\n",
      "\n",
      "Epoch 19: loss did not improve from 5.08701\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.2867 - bpp: 3.2167 - mse: 5.0536e-04\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8034 - bpp: 3.1164 - mse: 4.1186e-04[MemoryCallback]:  5667544\n",
      "\n",
      "Epoch 20: loss improved from 5.08701 to 4.80335, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 4.8034 - bpp: 3.1164 - mse: 4.1186e-04\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3775 - bpp: 3.0179 - mse: 3.3192e-04[MemoryCallback]:  5667708\n",
      "\n",
      "Epoch 21: loss improved from 4.80335 to 4.37749, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 4.3775 - bpp: 3.0179 - mse: 3.3192e-04\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6066 - bpp: 2.9412 - mse: 4.0659e-04[MemoryCallback]:  5667716\n",
      "\n",
      "Epoch 22: loss did not improve from 4.37749\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 4.6066 - bpp: 2.9412 - mse: 4.0659e-04\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0864 - bpp: 2.8417 - mse: 3.0387e-04[MemoryCallback]:  5667716\n",
      "\n",
      "Epoch 23: loss improved from 4.37749 to 4.08637, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 4.0864 - bpp: 2.8417 - mse: 3.0387e-04\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0606 - bpp: 2.7628 - mse: 3.1685e-04[MemoryCallback]:  5719716\n",
      "\n",
      "Epoch 24: loss improved from 4.08637 to 4.06061, saving model to checkpoints_wavelets_L_4096_1_240x240/\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 4.0606 - bpp: 2.7628 - mse: 3.1685e-04\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.1164 - bpp: 2.7351 - mse: 0.0057[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 25: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 26.1164 - bpp: 2.7351 - mse: 0.0057\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2520 - bpp: 2.6023 - mse: 0.0011[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 26: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 7.2520 - bpp: 2.6023 - mse: 0.0011\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9441 - bpp: 2.5209 - mse: 8.3576e-04[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 27: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.9441 - bpp: 2.5209 - mse: 8.3576e-04\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9099 - bpp: 2.4374 - mse: 8.4778e-04[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 28: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 5.9099 - bpp: 2.4374 - mse: 8.4778e-04\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5809 - bpp: 2.3714 - mse: 7.8357e-04[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 29: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 5.5809 - bpp: 2.3714 - mse: 7.8357e-04\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7297 - bpp: 2.2919 - mse: 8.3930e-04[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 30: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 5.7297 - bpp: 2.2919 - mse: 8.3930e-04\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6947 - bpp: 2.2328 - mse: 8.4521e-04[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 31: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.6947 - bpp: 2.2328 - mse: 8.4521e-04\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8247 - bpp: 2.1627 - mse: 6.4991e-04[MemoryCallback]:  5719908\n",
      "\n",
      "Epoch 32: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.8247 - bpp: 2.1627 - mse: 6.4991e-04\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7707 - bpp: 2.1020 - mse: 6.5154e-04[MemoryCallback]:  5808280\n",
      "\n",
      "Epoch 33: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.7707 - bpp: 2.1020 - mse: 6.5154e-04\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2257 - bpp: 2.0504 - mse: 7.7522e-04[MemoryCallback]:  5860308\n",
      "\n",
      "Epoch 34: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.2257 - bpp: 2.0504 - mse: 7.7522e-04\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6821 - bpp: 1.9637 - mse: 6.6367e-04[MemoryCallback]:  5911648\n",
      "\n",
      "Epoch 35: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.6821 - bpp: 1.9637 - mse: 6.6367e-04\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8320 - bpp: 1.9414 - mse: 7.0570e-04[MemoryCallback]:  6008024\n",
      "\n",
      "Epoch 36: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.8320 - bpp: 1.9414 - mse: 7.0570e-04\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6861 - bpp: 1.8792 - mse: 6.8527e-04[MemoryCallback]:  6008552\n",
      "\n",
      "Epoch 37: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.6861 - bpp: 1.8792 - mse: 6.8527e-04\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3777 - bpp: 1.8173 - mse: 6.2510e-04[MemoryCallback]:  6008672\n",
      "\n",
      "Epoch 38: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.3777 - bpp: 1.8173 - mse: 6.2510e-04\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5687 - bpp: 1.7716 - mse: 6.8287e-04[MemoryCallback]:  6008680\n",
      "\n",
      "Epoch 39: loss did not improve from 4.06061\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.5687 - bpp: 1.7716 - mse: 6.8287e-04\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "hist = model.fit(x=data, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, verbose=1, batch_size=BATCH_SIZE,\n",
    "                callbacks=[\n",
    "                    Callbacks.MemoryCallback(),\n",
    "                    Callbacks.LearningRateReducer(),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch', monitor=\"loss\", mode='min',  save_best_only=True, verbose=1), \n",
    "                    tf.keras.callbacks.TerminateOnNaN(),\n",
    "                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stop),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq=\"epoch\"),            \n",
    "                    ],\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00080/0747/im1.png\n",
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n"
     ]
    }
   ],
   "source": [
    "path = load.load_random_path(\"folder_cloud_test.npy\")\n",
    "i=0\n",
    "out_bin = \"Test_com/test{}.bin\".format(i)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(i)\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(i)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(i)\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, out_bin, out_decom, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_wavelets_L_4096_1_240x240/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_wavelets_L_4096_1_240x240/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
