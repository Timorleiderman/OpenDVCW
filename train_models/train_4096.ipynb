{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "import OpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import DataGen\n",
    "import Callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 800\n",
    "STEPS_PER_EPOCH = 100\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 4096\n",
    "lr_init = 1e-4\n",
    "early_stop = 400\n",
    "I_QP=27\n",
    "wavelet_name = \"haar\"\n",
    "args = OpenDVCW.Arguments()\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkponts_last_path = \"\"\n",
    "checkponts_new_path = \"checkpoints_wavelets_{}_Lmbd_{}_epcs_{}_es_{}_I_QP_{}_{}x{}_CosineDecay_{}/\".format(wavelet_name, lmbda, EPOCHS,  early_stop, I_QP, Width, Height, timestamp)\n",
    "save_name = \"model_save_\" + checkponts_new_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "* [Loading dataset]...\n",
      "Loading weights\n"
     ]
    }
   ],
   "source": [
    "model = OpenDVCW.OpenDVC(width=Width, height=Height, batch_size=BATCH_SIZE, num_filters=128, lmbda=lmbda)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=lr_init, decay_steps=EPOCHS*(STEPS_PER_EPOCH), alpha=1e-8, name=\"lr_CosineDecay\")\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),)\n",
    "print(\"* [Model compiled]...\")\n",
    "\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = DataGen.DataVimeo90kGenerator(\"folder_cloud_test.npy\", \n",
    "                                    BATCH_SIZE,\n",
    "                                    (Height,Width,Channel),\n",
    "                                    Channel,\n",
    "                                    True, \n",
    "                                    I_QP,\n",
    "                                    True)\n",
    "\n",
    "print(\"Loading weights\")\n",
    "if not checkponts_last_path == \"\":\n",
    "    model.load_weights(checkponts_last_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"open_dvc_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mv_analysis (AnalysisTransf  (1, 15, 15, 128)         659456    \n",
      " orm)                                                            \n",
      "                                                                 \n",
      " mv_synthesis (SynthesisTran  (1, 240, 240, 2)         642824    \n",
      " sform)                                                          \n",
      "                                                                 \n",
      " res_analysis (AnalysisTrans  (None, 15, 15, 128)      1552640   \n",
      " form)                                                           \n",
      "                                                                 \n",
      " res_synthesis (SynthesisTra  (None, 240, 240, 3)      1536015   \n",
      " nsform)                                                         \n",
      "                                                                 \n",
      " wavelets_optical_flow_1 (Wa  multiple                 240050    \n",
      " veletsOpticalFlow)                                              \n",
      "                                                                 \n",
      " motion_compensation_1 (Moti  multiple                 486467    \n",
      " onCompensation)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,124,626\n",
      "Trainable params: 5,124,620\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].trainable = False\n",
    "# model.layers[1].trainable = False\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[3].trainable = True\n",
    "# model.layers[4].trainable = False\n",
    "# model.layers[5].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_analysis True\n",
      "mv_synthesis True\n",
      "res_analysis True\n",
      "res_synthesis True\n",
      "wavelets_optical_flow_1 True\n",
      "motion_compensation_1 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 61.4022 - bpp: 5.3399 - mse: 0.0137\n",
      "Epoch 1: loss improved from inf to 61.40216, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 63s 235ms/step - loss: 61.4022 - bpp: 5.3399 - mse: 0.0137\n",
      "Epoch 2/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 21.1088 - bpp: 5.2694 - mse: 0.0039\n",
      "Epoch 2: loss improved from 61.40216 to 21.10878, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 24s 232ms/step - loss: 21.1088 - bpp: 5.2694 - mse: 0.0039\n",
      "Epoch 3/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 14.4823 - bpp: 5.2006 - mse: 0.0023\n",
      "Epoch 3: loss improved from 21.10878 to 14.48230, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 14.4823 - bpp: 5.2006 - mse: 0.0023\n",
      "Epoch 4/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 13.8608 - bpp: 5.1325 - mse: 0.0021\n",
      "Epoch 4: loss improved from 14.48230 to 13.86082, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 13.8608 - bpp: 5.1325 - mse: 0.0021\n",
      "Epoch 5/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.2225 - bpp: 5.0651 - mse: 0.0015\n",
      "Epoch 5: loss improved from 13.86082 to 11.22246, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 25s 242ms/step - loss: 11.2225 - bpp: 5.0651 - mse: 0.0015\n",
      "Epoch 6/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.4116 - bpp: 4.9985 - mse: 0.0013\n",
      "Epoch 6: loss improved from 11.22246 to 10.41159, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 10.4116 - bpp: 4.9985 - mse: 0.0013\n",
      "Epoch 7/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.3928 - bpp: 4.9322 - mse: 0.0013\n",
      "Epoch 7: loss improved from 10.41159 to 10.39281, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 10.3928 - bpp: 4.9322 - mse: 0.0013\n",
      "Epoch 8/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.6048 - bpp: 4.8670 - mse: 0.0016\n",
      "Epoch 8: loss did not improve from 10.39281\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 11.6048 - bpp: 4.8670 - mse: 0.0016\n",
      "Epoch 9/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.3451 - bpp: 4.8019 - mse: 0.0016\n",
      "Epoch 9: loss did not improve from 10.39281\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 11.3451 - bpp: 4.8019 - mse: 0.0016\n",
      "Epoch 10/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.0140 - bpp: 4.7374 - mse: 0.0013\n",
      "Epoch 10: loss improved from 10.39281 to 10.01396, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 10.0140 - bpp: 4.7374 - mse: 0.0013\n",
      "Epoch 11/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.7078 - bpp: 4.6735 - mse: 0.0012\n",
      "Epoch 11: loss improved from 10.01396 to 9.70778, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 9.7078 - bpp: 4.6735 - mse: 0.0012\n",
      "Epoch 12/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.7057 - bpp: 4.6107 - mse: 0.0017\n",
      "Epoch 12: loss did not improve from 9.70778\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 11.7057 - bpp: 4.6107 - mse: 0.0017\n",
      "Epoch 13/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.4285 - bpp: 4.5481 - mse: 0.0012\n",
      "Epoch 13: loss improved from 9.70778 to 9.42853, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 9.4285 - bpp: 4.5481 - mse: 0.0012\n",
      "Epoch 14/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.3203 - bpp: 4.4860 - mse: 0.0012\n",
      "Epoch 14: loss improved from 9.42853 to 9.32025, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 9.3203 - bpp: 4.4860 - mse: 0.0012\n",
      "Epoch 15/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.3905 - bpp: 4.4245 - mse: 0.0012\n",
      "Epoch 15: loss did not improve from 9.32025\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 9.3905 - bpp: 4.4245 - mse: 0.0012\n",
      "Epoch 16/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.9234 - bpp: 4.3639 - mse: 0.0018\n",
      "Epoch 16: loss did not improve from 9.32025\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 11.9234 - bpp: 4.3639 - mse: 0.0018\n",
      "Epoch 17/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.1019 - bpp: 4.3032 - mse: 0.0012\n",
      "Epoch 17: loss improved from 9.32025 to 9.10186, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 9.1019 - bpp: 4.3032 - mse: 0.0012\n",
      "Epoch 18/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.3005 - bpp: 4.2427 - mse: 9.9068e-04\n",
      "Epoch 18: loss improved from 9.10186 to 8.30050, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 8.3005 - bpp: 4.2427 - mse: 9.9068e-04\n",
      "Epoch 19/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.6402 - bpp: 4.1853 - mse: 0.0011\n",
      "Epoch 19: loss did not improve from 8.30050\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 8.6402 - bpp: 4.1853 - mse: 0.0011\n",
      "Epoch 20/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5608 - bpp: 4.1236 - mse: 8.3916e-04\n",
      "Epoch 20: loss improved from 8.30050 to 7.56084, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 25s 242ms/step - loss: 7.5608 - bpp: 4.1236 - mse: 8.3916e-04\n",
      "Epoch 21/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.2745 - bpp: 4.0685 - mse: 0.0013\n",
      "Epoch 21: loss did not improve from 7.56084\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 9.2745 - bpp: 4.0685 - mse: 0.0013\n",
      "Epoch 22/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.3012 - bpp: 4.0076 - mse: 8.0410e-04\n",
      "Epoch 22: loss improved from 7.56084 to 7.30123, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 7.3012 - bpp: 4.0076 - mse: 8.0410e-04\n",
      "Epoch 23/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.2127 - bpp: 3.9557 - mse: 0.0018\n",
      "Epoch 23: loss did not improve from 7.30123\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 11.2127 - bpp: 3.9557 - mse: 0.0018\n",
      "Epoch 24/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.6353 - bpp: 3.8994 - mse: 0.0019\n",
      "Epoch 24: loss did not improve from 7.30123\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 11.6353 - bpp: 3.8994 - mse: 0.0019\n",
      "Epoch 25/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.6667 - bpp: 3.8407 - mse: 9.3408e-04\n",
      "Epoch 25: loss did not improve from 7.30123\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 7.6667 - bpp: 3.8407 - mse: 9.3408e-04\n",
      "Epoch 26/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5509 - bpp: 3.7858 - mse: 9.1920e-04\n",
      "Epoch 26: loss did not improve from 7.30123\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 7.5509 - bpp: 3.7858 - mse: 9.1920e-04\n",
      "Epoch 27/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.4808 - bpp: 3.7326 - mse: 9.1509e-04\n",
      "Epoch 27: loss did not improve from 7.30123\n",
      "100/100 [==============================] - 25s 242ms/step - loss: 7.4808 - bpp: 3.7326 - mse: 9.1509e-04\n",
      "Epoch 28/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.0301 - bpp: 3.6768 - mse: 8.1868e-04\n",
      "Epoch 28: loss improved from 7.30123 to 7.03011, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 7.0301 - bpp: 3.6768 - mse: 8.1868e-04\n",
      "Epoch 29/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.7713 - bpp: 3.6270 - mse: 0.0010\n",
      "Epoch 29: loss did not improve from 7.03011\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 7.7713 - bpp: 3.6270 - mse: 0.0010\n",
      "Epoch 30/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.7285 - bpp: 3.5697 - mse: 7.7120e-04\n",
      "Epoch 30: loss improved from 7.03011 to 6.72855, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 6.7285 - bpp: 3.5697 - mse: 7.7120e-04\n",
      "Epoch 31/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.8089 - bpp: 3.5179 - mse: 8.0345e-04\n",
      "Epoch 31: loss did not improve from 6.72855\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 6.8089 - bpp: 3.5179 - mse: 8.0345e-04\n",
      "Epoch 32/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.1074 - bpp: 3.4697 - mse: 8.8811e-04\n",
      "Epoch 32: loss did not improve from 6.72855\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 7.1074 - bpp: 3.4697 - mse: 8.8811e-04\n",
      "Epoch 33/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.1756 - bpp: 3.4127 - mse: 6.7453e-04\n",
      "Epoch 33: loss improved from 6.72855 to 6.17561, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 6.1756 - bpp: 3.4127 - mse: 6.7453e-04\n",
      "Epoch 34/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.7444 - bpp: 3.3711 - mse: 8.2356e-04\n",
      "Epoch 34: loss did not improve from 6.17561\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 6.7444 - bpp: 3.3711 - mse: 8.2356e-04\n",
      "Epoch 35/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.2395 - bpp: 3.3157 - mse: 7.1381e-04\n",
      "Epoch 35: loss did not improve from 6.17561\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 6.2395 - bpp: 3.3157 - mse: 7.1381e-04\n",
      "Epoch 36/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.7708 - bpp: 3.2635 - mse: 6.1211e-04\n",
      "Epoch 36: loss improved from 6.17561 to 5.77075, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 5.7708 - bpp: 3.2635 - mse: 6.1211e-04\n",
      "Epoch 37/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.4662 - bpp: 3.2233 - mse: 7.9174e-04\n",
      "Epoch 37: loss did not improve from 5.77075\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 6.4662 - bpp: 3.2233 - mse: 7.9174e-04\n",
      "Epoch 38/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.5260 - bpp: 3.1734 - mse: 8.1849e-04\n",
      "Epoch 38: loss did not improve from 5.77075\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 6.5260 - bpp: 3.1734 - mse: 8.1849e-04\n",
      "Epoch 39/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.5568 - bpp: 3.1319 - mse: 8.3615e-04\n",
      "Epoch 39: loss did not improve from 5.77075\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 6.5568 - bpp: 3.1319 - mse: 8.3615e-04\n",
      "Epoch 40/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.5659 - bpp: 3.0705 - mse: 6.0923e-04\n",
      "Epoch 40: loss improved from 5.77075 to 5.56588, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 5.5659 - bpp: 3.0705 - mse: 6.0923e-04\n",
      "Epoch 41/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6562 - bpp: 3.0298 - mse: 6.4121e-04\n",
      "Epoch 41: loss did not improve from 5.56588\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 5.6562 - bpp: 3.0298 - mse: 6.4121e-04\n",
      "Epoch 42/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.2953 - bpp: 2.9956 - mse: 0.0013\n",
      "Epoch 42: loss did not improve from 5.56588\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 8.2953 - bpp: 2.9956 - mse: 0.0013\n",
      "Epoch 43/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.0587 - bpp: 2.9452 - mse: 0.0010\n",
      "Epoch 43: loss did not improve from 5.56588\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 7.0587 - bpp: 2.9452 - mse: 0.0010\n",
      "Epoch 44/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.5259 - bpp: 2.8925 - mse: 6.4292e-04\n",
      "Epoch 44: loss improved from 5.56588 to 5.52587, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 5.5259 - bpp: 2.8925 - mse: 6.4292e-04\n",
      "Epoch 45/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.5586 - bpp: 2.8628 - mse: 9.0230e-04\n",
      "Epoch 45: loss did not improve from 5.52587\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 6.5586 - bpp: 2.8628 - mse: 9.0230e-04\n",
      "Epoch 46/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.7186 - bpp: 2.8185 - mse: 7.0804e-04\n",
      "Epoch 46: loss did not improve from 5.52587\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 5.7186 - bpp: 2.8185 - mse: 7.0804e-04\n",
      "Epoch 47/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.7304 - bpp: 2.7691 - mse: 7.2297e-04\n",
      "Epoch 47: loss did not improve from 5.52587\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 5.7304 - bpp: 2.7691 - mse: 7.2297e-04\n",
      "Epoch 48/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.5999 - bpp: 2.7310 - mse: 7.0042e-04\n",
      "Epoch 48: loss did not improve from 5.52587\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 5.5999 - bpp: 2.7310 - mse: 7.0042e-04\n",
      "Epoch 49/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.3167 - bpp: 2.6887 - mse: 6.4161e-04\n",
      "Epoch 49: loss improved from 5.52587 to 5.31671, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 5.3167 - bpp: 2.6887 - mse: 6.4161e-04\n",
      "Epoch 50/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.3396 - bpp: 2.6503 - mse: 6.5656e-04\n",
      "Epoch 50: loss did not improve from 5.31671\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 5.3396 - bpp: 2.6503 - mse: 6.5656e-04\n",
      "Epoch 51/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2585 - bpp: 2.6040 - mse: 6.4807e-04\n",
      "Epoch 51: loss improved from 5.31671 to 5.25855, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 5.2585 - bpp: 2.6040 - mse: 6.4807e-04\n",
      "Epoch 52/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.4953 - bpp: 2.5751 - mse: 7.1294e-04\n",
      "Epoch 52: loss did not improve from 5.25855\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 5.4953 - bpp: 2.5751 - mse: 7.1294e-04\n",
      "Epoch 53/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.0408 - bpp: 2.5339 - mse: 6.1203e-04\n",
      "Epoch 53: loss improved from 5.25855 to 5.04081, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 5.0408 - bpp: 2.5339 - mse: 6.1203e-04\n",
      "Epoch 54/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7813 - bpp: 2.4968 - mse: 5.5774e-04\n",
      "Epoch 54: loss improved from 5.04081 to 4.78134, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 4.7813 - bpp: 2.4968 - mse: 5.5774e-04\n",
      "Epoch 55/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.9080 - bpp: 2.4566 - mse: 5.9849e-04\n",
      "Epoch 55: loss did not improve from 4.78134\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 4.9080 - bpp: 2.4566 - mse: 5.9849e-04\n",
      "Epoch 56/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6677 - bpp: 2.4199 - mse: 5.4879e-04\n",
      "Epoch 56: loss improved from 4.78134 to 4.66769, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 4.6677 - bpp: 2.4199 - mse: 5.4879e-04\n",
      "Epoch 57/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6446 - bpp: 2.3868 - mse: 5.5123e-04\n",
      "Epoch 57: loss improved from 4.66769 to 4.64461, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 4.6446 - bpp: 2.3868 - mse: 5.5123e-04\n",
      "Epoch 58/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8939 - bpp: 2.3600 - mse: 6.1863e-04\n",
      "Epoch 58: loss did not improve from 4.64461\n",
      "100/100 [==============================] - 29s 280ms/step - loss: 4.8939 - bpp: 2.3600 - mse: 6.1863e-04\n",
      "Epoch 59/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.9877 - bpp: 2.3324 - mse: 8.9240e-04\n",
      "Epoch 59: loss did not improve from 4.64461\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 5.9877 - bpp: 2.3324 - mse: 8.9240e-04\n",
      "Epoch 60/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8338 - bpp: 2.2763 - mse: 6.2438e-04\n",
      "Epoch 60: loss did not improve from 4.64461\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 4.8338 - bpp: 2.2763 - mse: 6.2438e-04\n",
      "Epoch 61/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.4432 - bpp: 2.2665 - mse: 7.7556e-04\n",
      "Epoch 61: loss did not improve from 4.64461\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 5.4432 - bpp: 2.2665 - mse: 7.7556e-04\n",
      "Epoch 62/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.2692 - bpp: 2.2597 - mse: 9.7888e-04\n",
      "Epoch 62: loss did not improve from 4.64461\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 6.2692 - bpp: 2.2597 - mse: 9.7888e-04\n",
      "Epoch 63/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6703 - bpp: 2.1779 - mse: 6.0851e-04\n",
      "Epoch 63: loss did not improve from 4.64461\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 4.6703 - bpp: 2.1779 - mse: 6.0851e-04\n",
      "Epoch 64/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9853 - bpp: 2.1386 - mse: 4.5086e-04\n",
      "Epoch 64: loss improved from 4.64461 to 3.98527, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.9853 - bpp: 2.1386 - mse: 4.5086e-04\n",
      "Epoch 65/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8341 - bpp: 2.1491 - mse: 6.5553e-04\n",
      "Epoch 65: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 4.8341 - bpp: 2.1491 - mse: 6.5553e-04\n",
      "Epoch 66/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6360 - bpp: 2.1384 - mse: 6.0976e-04\n",
      "Epoch 66: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 4.6360 - bpp: 2.1384 - mse: 6.0976e-04\n",
      "Epoch 67/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.3729 - bpp: 2.1141 - mse: 0.0013\n",
      "Epoch 67: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 7.3729 - bpp: 2.1141 - mse: 0.0013\n",
      "Epoch 68/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7116 - bpp: 2.0494 - mse: 6.4994e-04\n",
      "Epoch 68: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.7116 - bpp: 2.0494 - mse: 6.4994e-04\n",
      "Epoch 69/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.8512 - bpp: 2.0412 - mse: 0.0022\n",
      "Epoch 69: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 10.8512 - bpp: 2.0412 - mse: 0.0022\n",
      "Epoch 70/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.9541 - bpp: 1.9978 - mse: 7.2177e-04\n",
      "Epoch 70: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.9541 - bpp: 1.9978 - mse: 7.2177e-04\n",
      "Epoch 71/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7826 - bpp: 1.9650 - mse: 6.8787e-04\n",
      "Epoch 71: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 4.7826 - bpp: 1.9650 - mse: 6.8787e-04\n",
      "Epoch 72/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0940 - bpp: 1.9184 - mse: 5.3114e-04\n",
      "Epoch 72: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 4.0940 - bpp: 1.9184 - mse: 5.3114e-04\n",
      "Epoch 73/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2758 - bpp: 1.9338 - mse: 5.7176e-04\n",
      "Epoch 73: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 4.2758 - bpp: 1.9338 - mse: 5.7176e-04\n",
      "Epoch 74/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4344 - bpp: 1.8913 - mse: 6.2089e-04\n",
      "Epoch 74: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 4.4344 - bpp: 1.8913 - mse: 6.2089e-04\n",
      "Epoch 75/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.9745 - bpp: 1.8701 - mse: 7.5791e-04\n",
      "Epoch 75: loss did not improve from 3.98527\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 4.9745 - bpp: 1.8701 - mse: 7.5791e-04\n",
      "Epoch 76/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8775 - bpp: 1.8382 - mse: 4.9787e-04\n",
      "Epoch 76: loss improved from 3.98527 to 3.87746, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.8775 - bpp: 1.8382 - mse: 4.9787e-04\n",
      "Epoch 77/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0831 - bpp: 1.8171 - mse: 5.5324e-04\n",
      "Epoch 77: loss did not improve from 3.87746\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 4.0831 - bpp: 1.8171 - mse: 5.5324e-04\n",
      "Epoch 78/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2560 - bpp: 1.8193 - mse: 5.9489e-04\n",
      "Epoch 78: loss did not improve from 3.87746\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 4.2560 - bpp: 1.8193 - mse: 5.9489e-04\n",
      "Epoch 79/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6058 - bpp: 1.7412 - mse: 4.5523e-04\n",
      "Epoch 79: loss improved from 3.87746 to 3.60579, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.6058 - bpp: 1.7412 - mse: 4.5523e-04\n",
      "Epoch 80/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0669 - bpp: 1.7356 - mse: 5.6917e-04\n",
      "Epoch 80: loss did not improve from 3.60579\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 4.0669 - bpp: 1.7356 - mse: 5.6917e-04\n",
      "Epoch 81/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1185 - bpp: 1.7180 - mse: 5.8607e-04\n",
      "Epoch 81: loss did not improve from 3.60579\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 4.1185 - bpp: 1.7180 - mse: 5.8607e-04\n",
      "Epoch 82/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7054 - bpp: 1.7000 - mse: 4.8961e-04\n",
      "Epoch 82: loss did not improve from 3.60579\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.7054 - bpp: 1.7000 - mse: 4.8961e-04\n",
      "Epoch 83/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3589 - bpp: 1.7167 - mse: 6.4509e-04\n",
      "Epoch 83: loss did not improve from 3.60579\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 4.3589 - bpp: 1.7167 - mse: 6.4509e-04\n",
      "Epoch 84/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.5883 - bpp: 1.7315 - mse: 6.9748e-04\n",
      "Epoch 84: loss did not improve from 3.60579\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 4.5883 - bpp: 1.7315 - mse: 6.9748e-04\n",
      "Epoch 85/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7590 - bpp: 1.6520 - mse: 5.1439e-04\n",
      "Epoch 85: loss did not improve from 3.60579\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 3.7590 - bpp: 1.6520 - mse: 5.1439e-04\n",
      "Epoch 86/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5533 - bpp: 1.6153 - mse: 4.7314e-04\n",
      "Epoch 86: loss improved from 3.60579 to 3.55328, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 3.5533 - bpp: 1.6153 - mse: 4.7314e-04\n",
      "Epoch 87/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3569 - bpp: 1.6435 - mse: 6.6246e-04\n",
      "Epoch 87: loss did not improve from 3.55328\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 4.3569 - bpp: 1.6435 - mse: 6.6246e-04\n",
      "Epoch 88/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7938 - bpp: 1.6012 - mse: 5.3532e-04\n",
      "Epoch 88: loss did not improve from 3.55328\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 3.7938 - bpp: 1.6012 - mse: 5.3532e-04\n",
      "Epoch 89/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9196 - bpp: 1.5914 - mse: 5.6841e-04\n",
      "Epoch 89: loss did not improve from 3.55328\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 3.9196 - bpp: 1.5914 - mse: 5.6841e-04\n",
      "Epoch 90/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8026 - bpp: 1.5622 - mse: 7.9112e-04\n",
      "Epoch 90: loss did not improve from 3.55328\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 4.8026 - bpp: 1.5622 - mse: 7.9112e-04\n",
      "Epoch 91/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7024 - bpp: 1.5614 - mse: 7.6684e-04\n",
      "Epoch 91: loss did not improve from 3.55328\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 4.7024 - bpp: 1.5614 - mse: 7.6684e-04\n",
      "Epoch 92/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0757 - bpp: 1.5285 - mse: 6.2189e-04\n",
      "Epoch 92: loss did not improve from 3.55328\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 4.0757 - bpp: 1.5285 - mse: 6.2189e-04\n",
      "Epoch 93/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4857 - bpp: 1.5024 - mse: 4.8420e-04\n",
      "Epoch 93: loss improved from 3.55328 to 3.48568, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 3.4857 - bpp: 1.5024 - mse: 4.8420e-04\n",
      "Epoch 94/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6354 - bpp: 1.5031 - mse: 5.2057e-04\n",
      "Epoch 94: loss did not improve from 3.48568\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 3.6354 - bpp: 1.5031 - mse: 5.2057e-04\n",
      "Epoch 95/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5277 - bpp: 1.4799 - mse: 4.9996e-04\n",
      "Epoch 95: loss did not improve from 3.48568\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 3.5277 - bpp: 1.4799 - mse: 4.9996e-04\n",
      "Epoch 96/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7230 - bpp: 1.4728 - mse: 5.4936e-04\n",
      "Epoch 96: loss did not improve from 3.48568\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 3.7230 - bpp: 1.4728 - mse: 5.4936e-04\n",
      "Epoch 97/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4238 - bpp: 1.4429 - mse: 4.8361e-04\n",
      "Epoch 97: loss improved from 3.48568 to 3.42378, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 3.4238 - bpp: 1.4429 - mse: 4.8361e-04\n",
      "Epoch 98/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5455 - bpp: 1.4304 - mse: 5.1638e-04\n",
      "Epoch 98: loss did not improve from 3.42378\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 3.5455 - bpp: 1.4304 - mse: 5.1638e-04\n",
      "Epoch 99/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2424 - bpp: 1.4058 - mse: 4.4839e-04\n",
      "Epoch 99: loss improved from 3.42378 to 3.24239, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 3.2424 - bpp: 1.4058 - mse: 4.4839e-04\n",
      "Epoch 100/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5148 - bpp: 1.3943 - mse: 5.1771e-04\n",
      "Epoch 100: loss did not improve from 3.24239\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 3.5148 - bpp: 1.3943 - mse: 5.1771e-04\n",
      "Epoch 101/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9185 - bpp: 1.4502 - mse: 6.0261e-04\n",
      "Epoch 101: loss did not improve from 3.24239\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 3.9185 - bpp: 1.4502 - mse: 6.0261e-04\n",
      "Epoch 102/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2508 - bpp: 1.3804 - mse: 4.5663e-04\n",
      "Epoch 102: loss did not improve from 3.24239\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.2508 - bpp: 1.3804 - mse: 4.5663e-04\n",
      "Epoch 103/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0249 - bpp: 1.4306 - mse: 6.3338e-04\n",
      "Epoch 103: loss did not improve from 3.24239\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.0249 - bpp: 1.4306 - mse: 6.3338e-04\n",
      "Epoch 104/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1760 - bpp: 1.3419 - mse: 4.4777e-04\n",
      "Epoch 104: loss improved from 3.24239 to 3.17598, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.1760 - bpp: 1.3419 - mse: 4.4777e-04\n",
      "Epoch 105/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3102 - bpp: 1.3749 - mse: 4.7248e-04\n",
      "Epoch 105: loss did not improve from 3.17598\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.3102 - bpp: 1.3749 - mse: 4.7248e-04\n",
      "Epoch 106/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8847 - bpp: 1.3894 - mse: 8.5333e-04\n",
      "Epoch 106: loss did not improve from 3.17598\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 4.8847 - bpp: 1.3894 - mse: 8.5333e-04\n",
      "Epoch 107/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3280 - bpp: 1.3833 - mse: 7.1891e-04\n",
      "Epoch 107: loss did not improve from 3.17598\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 4.3280 - bpp: 1.3833 - mse: 7.1891e-04\n",
      "Epoch 108/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0860 - bpp: 1.3001 - mse: 4.3601e-04\n",
      "Epoch 108: loss improved from 3.17598 to 3.08596, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.0860 - bpp: 1.3001 - mse: 4.3601e-04\n",
      "Epoch 109/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3013 - bpp: 1.3332 - mse: 4.8049e-04\n",
      "Epoch 109: loss did not improve from 3.08596\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 3.3013 - bpp: 1.3332 - mse: 4.8049e-04\n",
      "Epoch 110/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5848 - bpp: 1.3096 - mse: 5.5547e-04\n",
      "Epoch 110: loss did not improve from 3.08596\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 3.5848 - bpp: 1.3096 - mse: 5.5547e-04\n",
      "Epoch 111/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6546 - bpp: 1.3554 - mse: 5.6133e-04\n",
      "Epoch 111: loss did not improve from 3.08596\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 3.6546 - bpp: 1.3554 - mse: 5.6133e-04\n",
      "Epoch 112/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1068 - bpp: 1.3334 - mse: 6.7710e-04\n",
      "Epoch 112: loss did not improve from 3.08596\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 4.1068 - bpp: 1.3334 - mse: 6.7710e-04\n",
      "Epoch 113/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0158 - bpp: 1.2887 - mse: 4.2166e-04\n",
      "Epoch 113: loss improved from 3.08596 to 3.01581, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.0158 - bpp: 1.2887 - mse: 4.2166e-04\n",
      "Epoch 114/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3008 - bpp: 1.2964 - mse: 4.8935e-04\n",
      "Epoch 114: loss did not improve from 3.01581\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 3.3008 - bpp: 1.2964 - mse: 4.8935e-04\n",
      "Epoch 115/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0671 - bpp: 1.2402 - mse: 4.4601e-04\n",
      "Epoch 115: loss did not improve from 3.01581\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.0671 - bpp: 1.2402 - mse: 4.4601e-04\n",
      "Epoch 116/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0611 - bpp: 1.2410 - mse: 4.4434e-04\n",
      "Epoch 116: loss did not improve from 3.01581\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 3.0611 - bpp: 1.2410 - mse: 4.4434e-04\n",
      "Epoch 117/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3228 - bpp: 1.2605 - mse: 5.0347e-04\n",
      "Epoch 117: loss did not improve from 3.01581\n",
      "100/100 [==============================] - 25s 239ms/step - loss: 3.3228 - bpp: 1.2605 - mse: 5.0347e-04\n",
      "Epoch 118/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3190 - bpp: 1.2808 - mse: 4.9760e-04\n",
      "Epoch 118: loss did not improve from 3.01581\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 3.3190 - bpp: 1.2808 - mse: 4.9760e-04\n",
      "Epoch 119/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0001 - bpp: 1.2315 - mse: 4.3178e-04\n",
      "Epoch 119: loss improved from 3.01581 to 3.00006, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 3.0001 - bpp: 1.2315 - mse: 4.3178e-04\n",
      "Epoch 120/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3640 - bpp: 1.2177 - mse: 5.2399e-04\n",
      "Epoch 120: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 3.3640 - bpp: 1.2177 - mse: 5.2399e-04\n",
      "Epoch 121/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2708 - bpp: 1.2417 - mse: 4.9541e-04\n",
      "Epoch 121: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 3.2708 - bpp: 1.2417 - mse: 4.9541e-04\n",
      "Epoch 122/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2451 - bpp: 1.2328 - mse: 4.9130e-04\n",
      "Epoch 122: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 3.2451 - bpp: 1.2328 - mse: 4.9130e-04\n",
      "Epoch 123/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1471 - bpp: 1.2208 - mse: 4.7029e-04\n",
      "Epoch 123: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.1471 - bpp: 1.2208 - mse: 4.7029e-04\n",
      "Epoch 124/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2571 - bpp: 1.2349 - mse: 4.9369e-04\n",
      "Epoch 124: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 3.2571 - bpp: 1.2349 - mse: 4.9369e-04\n",
      "Epoch 125/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3667 - bpp: 1.2358 - mse: 5.2026e-04\n",
      "Epoch 125: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.3667 - bpp: 1.2358 - mse: 5.2026e-04\n",
      "Epoch 126/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0915 - bpp: 1.2230 - mse: 4.5616e-04\n",
      "Epoch 126: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 3.0915 - bpp: 1.2230 - mse: 4.5616e-04\n",
      "Epoch 127/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1142 - bpp: 1.1937 - mse: 4.6888e-04\n",
      "Epoch 127: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.1142 - bpp: 1.1937 - mse: 4.6888e-04\n",
      "Epoch 128/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4675 - bpp: 1.2416 - mse: 5.4344e-04\n",
      "Epoch 128: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 3.4675 - bpp: 1.2416 - mse: 5.4344e-04\n",
      "Epoch 129/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3179 - bpp: 1.1834 - mse: 5.2111e-04\n",
      "Epoch 129: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 3.3179 - bpp: 1.1834 - mse: 5.2111e-04\n",
      "Epoch 130/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4598 - bpp: 1.2149 - mse: 5.4808e-04\n",
      "Epoch 130: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 3.4598 - bpp: 1.2149 - mse: 5.4808e-04\n",
      "Epoch 131/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0858 - bpp: 1.1933 - mse: 4.6204e-04\n",
      "Epoch 131: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 3.0858 - bpp: 1.1933 - mse: 4.6204e-04\n",
      "Epoch 132/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1827 - bpp: 1.1948 - mse: 4.8533e-04\n",
      "Epoch 132: loss did not improve from 3.00006\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.1827 - bpp: 1.1948 - mse: 4.8533e-04\n",
      "Epoch 133/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8552 - bpp: 1.1617 - mse: 4.1345e-04\n",
      "Epoch 133: loss improved from 3.00006 to 2.85516, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.8552 - bpp: 1.1617 - mse: 4.1345e-04\n",
      "Epoch 134/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2157 - bpp: 1.2113 - mse: 4.8936e-04\n",
      "Epoch 134: loss did not improve from 2.85516\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.2157 - bpp: 1.2113 - mse: 4.8936e-04\n",
      "Epoch 135/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5660 - bpp: 1.1556 - mse: 5.8847e-04\n",
      "Epoch 135: loss did not improve from 2.85516\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.5660 - bpp: 1.1556 - mse: 5.8847e-04\n",
      "Epoch 136/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4817 - bpp: 1.1677 - mse: 5.6494e-04\n",
      "Epoch 136: loss did not improve from 2.85516\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 3.4817 - bpp: 1.1677 - mse: 5.6494e-04\n",
      "Epoch 137/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3932 - bpp: 1.1685 - mse: 5.4313e-04\n",
      "Epoch 137: loss did not improve from 2.85516\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 3.3932 - bpp: 1.1685 - mse: 5.4313e-04\n",
      "Epoch 138/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1244 - bpp: 1.1514 - mse: 4.8170e-04\n",
      "Epoch 138: loss did not improve from 2.85516\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 3.1244 - bpp: 1.1514 - mse: 4.8170e-04\n",
      "Epoch 139/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8496 - bpp: 1.1451 - mse: 4.1614e-04\n",
      "Epoch 139: loss improved from 2.85516 to 2.84964, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.8496 - bpp: 1.1451 - mse: 4.1614e-04\n",
      "Epoch 140/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1513 - bpp: 1.1608 - mse: 4.8597e-04\n",
      "Epoch 140: loss did not improve from 2.84964\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 3.1513 - bpp: 1.1608 - mse: 4.8597e-04\n",
      "Epoch 141/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8852 - bpp: 1.1377 - mse: 4.2665e-04\n",
      "Epoch 141: loss did not improve from 2.84964\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 2.8852 - bpp: 1.1377 - mse: 4.2665e-04\n",
      "Epoch 142/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9993 - bpp: 1.1322 - mse: 4.5583e-04\n",
      "Epoch 142: loss did not improve from 2.84964\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.9993 - bpp: 1.1322 - mse: 4.5583e-04\n",
      "Epoch 143/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3431 - bpp: 1.1678 - mse: 5.3108e-04\n",
      "Epoch 143: loss did not improve from 2.84964\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.3431 - bpp: 1.1678 - mse: 5.3108e-04\n",
      "Epoch 144/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2102 - bpp: 1.1413 - mse: 5.0509e-04\n",
      "Epoch 144: loss did not improve from 2.84964\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 3.2102 - bpp: 1.1413 - mse: 5.0509e-04\n",
      "Epoch 145/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0291 - bpp: 1.1302 - mse: 4.6359e-04\n",
      "Epoch 145: loss did not improve from 2.84964\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 3.0291 - bpp: 1.1302 - mse: 4.6359e-04\n",
      "Epoch 146/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8043 - bpp: 1.1075 - mse: 4.1425e-04\n",
      "Epoch 146: loss improved from 2.84964 to 2.80425, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 2.8043 - bpp: 1.1075 - mse: 4.1425e-04\n",
      "Epoch 147/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4292 - bpp: 1.1204 - mse: 5.6366e-04\n",
      "Epoch 147: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 3.4292 - bpp: 1.1204 - mse: 5.6366e-04\n",
      "Epoch 148/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0060 - bpp: 1.1353 - mse: 4.5671e-04\n",
      "Epoch 148: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.0060 - bpp: 1.1353 - mse: 4.5671e-04\n",
      "Epoch 149/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4998 - bpp: 1.1811 - mse: 8.1022e-04\n",
      "Epoch 149: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 4.4998 - bpp: 1.1811 - mse: 8.1022e-04\n",
      "Epoch 150/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4676 - bpp: 1.1610 - mse: 5.6314e-04\n",
      "Epoch 150: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.4676 - bpp: 1.1610 - mse: 5.6314e-04\n",
      "Epoch 151/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3643 - bpp: 1.1514 - mse: 5.4024e-04\n",
      "Epoch 151: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.3643 - bpp: 1.1514 - mse: 5.4024e-04\n",
      "Epoch 152/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5812 - bpp: 1.1402 - mse: 5.9596e-04\n",
      "Epoch 152: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.5812 - bpp: 1.1402 - mse: 5.9596e-04\n",
      "Epoch 153/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9465 - bpp: 1.1073 - mse: 4.4901e-04\n",
      "Epoch 153: loss did not improve from 2.80425\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.9465 - bpp: 1.1073 - mse: 4.4901e-04\n",
      "Epoch 154/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6212 - bpp: 1.0995 - mse: 3.7150e-04\n",
      "Epoch 154: loss improved from 2.80425 to 2.62119, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.6212 - bpp: 1.0995 - mse: 3.7150e-04\n",
      "Epoch 155/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1589 - bpp: 1.1019 - mse: 5.0218e-04\n",
      "Epoch 155: loss did not improve from 2.62119\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.1589 - bpp: 1.1019 - mse: 5.0218e-04\n",
      "Epoch 156/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0945 - bpp: 1.0437 - mse: 5.0068e-04\n",
      "Epoch 156: loss did not improve from 2.62119\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 3.0945 - bpp: 1.0437 - mse: 5.0068e-04\n",
      "Epoch 157/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0728 - bpp: 1.1280 - mse: 4.7481e-04\n",
      "Epoch 157: loss did not improve from 2.62119\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 3.0728 - bpp: 1.1280 - mse: 4.7481e-04\n",
      "Epoch 158/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6760 - bpp: 1.0716 - mse: 3.9169e-04\n",
      "Epoch 158: loss did not improve from 2.62119\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.6760 - bpp: 1.0716 - mse: 3.9169e-04\n",
      "Epoch 159/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4247 - bpp: 1.0343 - mse: 3.3944e-04\n",
      "Epoch 159: loss improved from 2.62119 to 2.42470, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4247 - bpp: 1.0343 - mse: 3.3944e-04\n",
      "Epoch 160/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6835 - bpp: 1.0451 - mse: 3.9999e-04\n",
      "Epoch 160: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.6835 - bpp: 1.0451 - mse: 3.9999e-04\n",
      "Epoch 161/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7691 - bpp: 1.0676 - mse: 4.1541e-04\n",
      "Epoch 161: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.7691 - bpp: 1.0676 - mse: 4.1541e-04\n",
      "Epoch 162/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2709 - bpp: 1.0945 - mse: 5.3136e-04\n",
      "Epoch 162: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 3.2709 - bpp: 1.0945 - mse: 5.3136e-04\n",
      "Epoch 163/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3603 - bpp: 1.1186 - mse: 5.4729e-04\n",
      "Epoch 163: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 3.3603 - bpp: 1.1186 - mse: 5.4729e-04\n",
      "Epoch 164/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9240 - bpp: 1.0871 - mse: 4.4846e-04\n",
      "Epoch 164: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.9240 - bpp: 1.0871 - mse: 4.4846e-04\n",
      "Epoch 165/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7176 - bpp: 1.0695 - mse: 4.0236e-04\n",
      "Epoch 165: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.7176 - bpp: 1.0695 - mse: 4.0236e-04\n",
      "Epoch 166/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7647 - bpp: 1.0443 - mse: 4.2002e-04\n",
      "Epoch 166: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 2.7647 - bpp: 1.0443 - mse: 4.2002e-04\n",
      "Epoch 167/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9458 - bpp: 1.0662 - mse: 4.5890e-04\n",
      "Epoch 167: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.9458 - bpp: 1.0662 - mse: 4.5890e-04\n",
      "Epoch 168/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7793 - bpp: 1.0580 - mse: 4.2024e-04\n",
      "Epoch 168: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.7793 - bpp: 1.0580 - mse: 4.2024e-04\n",
      "Epoch 169/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0579 - bpp: 1.1236 - mse: 4.7224e-04\n",
      "Epoch 169: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 3.0579 - bpp: 1.1236 - mse: 4.7224e-04\n",
      "Epoch 170/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8398 - bpp: 1.0798 - mse: 4.2971e-04\n",
      "Epoch 170: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.8398 - bpp: 1.0798 - mse: 4.2971e-04\n",
      "Epoch 171/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6163 - bpp: 1.1302 - mse: 6.0697e-04\n",
      "Epoch 171: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 3.6163 - bpp: 1.1302 - mse: 6.0697e-04\n",
      "Epoch 172/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7822 - bpp: 1.0523 - mse: 4.2234e-04\n",
      "Epoch 172: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.7822 - bpp: 1.0523 - mse: 4.2234e-04\n",
      "Epoch 173/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6123 - bpp: 1.0202 - mse: 3.8870e-04\n",
      "Epoch 173: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.6123 - bpp: 1.0202 - mse: 3.8870e-04\n",
      "Epoch 174/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8835 - bpp: 1.0577 - mse: 4.4575e-04\n",
      "Epoch 174: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.8835 - bpp: 1.0577 - mse: 4.4575e-04\n",
      "Epoch 175/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5760 - bpp: 1.0132 - mse: 3.8153e-04\n",
      "Epoch 175: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.5760 - bpp: 1.0132 - mse: 3.8153e-04\n",
      "Epoch 176/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5929 - bpp: 1.0270 - mse: 3.8232e-04\n",
      "Epoch 176: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.5929 - bpp: 1.0270 - mse: 3.8232e-04\n",
      "Epoch 177/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9256 - bpp: 1.0444 - mse: 4.5926e-04\n",
      "Epoch 177: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.9256 - bpp: 1.0444 - mse: 4.5926e-04\n",
      "Epoch 178/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9609 - bpp: 1.0648 - mse: 4.6292e-04\n",
      "Epoch 178: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.9609 - bpp: 1.0648 - mse: 4.6292e-04\n",
      "Epoch 179/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7060 - bpp: 1.0509 - mse: 4.0406e-04\n",
      "Epoch 179: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.7060 - bpp: 1.0509 - mse: 4.0406e-04\n",
      "Epoch 180/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7709 - bpp: 1.0674 - mse: 4.1590e-04\n",
      "Epoch 180: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.7709 - bpp: 1.0674 - mse: 4.1590e-04\n",
      "Epoch 181/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1949 - bpp: 1.0510 - mse: 5.2341e-04\n",
      "Epoch 181: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 3.1949 - bpp: 1.0510 - mse: 5.2341e-04\n",
      "Epoch 182/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8609 - bpp: 1.0556 - mse: 4.4073e-04\n",
      "Epoch 182: loss did not improve from 2.42470\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 2.8609 - bpp: 1.0556 - mse: 4.4073e-04\n",
      "Epoch 183/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2999 - bpp: 0.9909 - mse: 3.1958e-04\n",
      "Epoch 183: loss improved from 2.42470 to 2.29993, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 2.2999 - bpp: 0.9909 - mse: 3.1958e-04\n",
      "Epoch 184/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7881 - bpp: 1.0563 - mse: 4.2279e-04\n",
      "Epoch 184: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 2.7881 - bpp: 1.0563 - mse: 4.2279e-04\n",
      "Epoch 185/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5149 - bpp: 1.0270 - mse: 3.6324e-04\n",
      "Epoch 185: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.5149 - bpp: 1.0270 - mse: 3.6324e-04\n",
      "Epoch 186/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6474 - bpp: 1.0350 - mse: 3.9366e-04\n",
      "Epoch 186: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 2.6474 - bpp: 1.0350 - mse: 3.9366e-04\n",
      "Epoch 187/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6293 - bpp: 1.0350 - mse: 3.8922e-04\n",
      "Epoch 187: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.6293 - bpp: 1.0350 - mse: 3.8922e-04\n",
      "Epoch 188/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3884 - bpp: 0.9909 - mse: 3.4118e-04\n",
      "Epoch 188: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.3884 - bpp: 0.9909 - mse: 3.4118e-04\n",
      "Epoch 189/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0333 - bpp: 1.0730 - mse: 4.7860e-04\n",
      "Epoch 189: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 3.0333 - bpp: 1.0730 - mse: 4.7860e-04\n",
      "Epoch 190/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4751 - bpp: 1.1073 - mse: 5.7807e-04\n",
      "Epoch 190: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.4751 - bpp: 1.1073 - mse: 5.7807e-04\n",
      "Epoch 191/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1966 - bpp: 1.0149 - mse: 5.3265e-04\n",
      "Epoch 191: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 3.1966 - bpp: 1.0149 - mse: 5.3265e-04\n",
      "Epoch 192/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3775 - bpp: 0.9921 - mse: 3.3825e-04\n",
      "Epoch 192: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 2.3775 - bpp: 0.9921 - mse: 3.3825e-04\n",
      "Epoch 193/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3973 - bpp: 0.9914 - mse: 3.4323e-04\n",
      "Epoch 193: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 28s 261ms/step - loss: 2.3973 - bpp: 0.9914 - mse: 3.4323e-04\n",
      "Epoch 194/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3188 - bpp: 0.9955 - mse: 3.2308e-04\n",
      "Epoch 194: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.3188 - bpp: 0.9955 - mse: 3.2308e-04\n",
      "Epoch 195/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4025 - bpp: 0.9948 - mse: 3.4368e-04\n",
      "Epoch 195: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.4025 - bpp: 0.9948 - mse: 3.4368e-04\n",
      "Epoch 196/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8032 - bpp: 1.0441 - mse: 4.2948e-04\n",
      "Epoch 196: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.8032 - bpp: 1.0441 - mse: 4.2948e-04\n",
      "Epoch 197/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5569 - bpp: 1.0004 - mse: 3.8001e-04\n",
      "Epoch 197: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.5569 - bpp: 1.0004 - mse: 3.8001e-04\n",
      "Epoch 198/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6464 - bpp: 1.0317 - mse: 3.9422e-04\n",
      "Epoch 198: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.6464 - bpp: 1.0317 - mse: 3.9422e-04\n",
      "Epoch 199/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3642 - bpp: 1.0574 - mse: 5.6318e-04\n",
      "Epoch 199: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.3642 - bpp: 1.0574 - mse: 5.6318e-04\n",
      "Epoch 200/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8634 - bpp: 1.0405 - mse: 4.4505e-04\n",
      "Epoch 200: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.8634 - bpp: 1.0405 - mse: 4.4505e-04\n",
      "Epoch 201/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7314 - bpp: 1.0519 - mse: 4.1002e-04\n",
      "Epoch 201: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.7314 - bpp: 1.0519 - mse: 4.1002e-04\n",
      "Epoch 202/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4649 - bpp: 1.0329 - mse: 5.9375e-04\n",
      "Epoch 202: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 3.4649 - bpp: 1.0329 - mse: 5.9375e-04\n",
      "Epoch 203/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1104 - bpp: 1.0260 - mse: 5.0890e-04\n",
      "Epoch 203: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 3.1104 - bpp: 1.0260 - mse: 5.0890e-04\n",
      "Epoch 204/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4268 - bpp: 0.9976 - mse: 3.4893e-04\n",
      "Epoch 204: loss did not improve from 2.29993\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4268 - bpp: 0.9976 - mse: 3.4893e-04\n",
      "Epoch 205/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2843 - bpp: 0.9607 - mse: 3.2316e-04\n",
      "Epoch 205: loss improved from 2.29993 to 2.28434, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 2.2843 - bpp: 0.9607 - mse: 3.2316e-04\n",
      "Epoch 206/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4968 - bpp: 1.0055 - mse: 3.6407e-04\n",
      "Epoch 206: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 2.4968 - bpp: 1.0055 - mse: 3.6407e-04\n",
      "Epoch 207/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5261 - bpp: 0.9922 - mse: 3.7447e-04\n",
      "Epoch 207: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.5261 - bpp: 0.9922 - mse: 3.7447e-04\n",
      "Epoch 208/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3723 - bpp: 0.9597 - mse: 3.4486e-04\n",
      "Epoch 208: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3723 - bpp: 0.9597 - mse: 3.4486e-04\n",
      "Epoch 209/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5658 - bpp: 1.0093 - mse: 3.8000e-04\n",
      "Epoch 209: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 2.5658 - bpp: 1.0093 - mse: 3.8000e-04\n",
      "Epoch 210/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4422 - bpp: 0.9928 - mse: 3.5386e-04\n",
      "Epoch 210: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4422 - bpp: 0.9928 - mse: 3.5386e-04\n",
      "Epoch 211/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4847 - bpp: 0.9870 - mse: 3.6564e-04\n",
      "Epoch 211: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.4847 - bpp: 0.9870 - mse: 3.6564e-04\n",
      "Epoch 212/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5948 - bpp: 0.9818 - mse: 3.9380e-04\n",
      "Epoch 212: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.5948 - bpp: 0.9818 - mse: 3.9380e-04\n",
      "Epoch 213/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7495 - bpp: 0.9899 - mse: 4.2960e-04\n",
      "Epoch 213: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.7495 - bpp: 0.9899 - mse: 4.2960e-04\n",
      "Epoch 214/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7869 - bpp: 0.9871 - mse: 4.3942e-04\n",
      "Epoch 214: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.7869 - bpp: 0.9871 - mse: 4.3942e-04\n",
      "Epoch 215/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3807 - bpp: 1.0287 - mse: 5.7420e-04\n",
      "Epoch 215: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 3.3807 - bpp: 1.0287 - mse: 5.7420e-04\n",
      "Epoch 216/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3984 - bpp: 0.9589 - mse: 3.5143e-04\n",
      "Epoch 216: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.3984 - bpp: 0.9589 - mse: 3.5143e-04\n",
      "Epoch 217/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5863 - bpp: 1.0003 - mse: 3.8722e-04\n",
      "Epoch 217: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.5863 - bpp: 1.0003 - mse: 3.8722e-04\n",
      "Epoch 218/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6350 - bpp: 0.9969 - mse: 3.9992e-04\n",
      "Epoch 218: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.6350 - bpp: 0.9969 - mse: 3.9992e-04\n",
      "Epoch 219/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4299 - bpp: 0.9507 - mse: 3.6114e-04\n",
      "Epoch 219: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 2.4299 - bpp: 0.9507 - mse: 3.6114e-04\n",
      "Epoch 220/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3753 - bpp: 0.9578 - mse: 3.4607e-04\n",
      "Epoch 220: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3753 - bpp: 0.9578 - mse: 3.4607e-04\n",
      "Epoch 221/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4396 - bpp: 0.9628 - mse: 3.6057e-04\n",
      "Epoch 221: loss did not improve from 2.28434\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.4396 - bpp: 0.9628 - mse: 3.6057e-04\n",
      "Epoch 222/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1547 - bpp: 0.9125 - mse: 3.0327e-04\n",
      "Epoch 222: loss improved from 2.28434 to 2.15473, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 2.1547 - bpp: 0.9125 - mse: 3.0327e-04\n",
      "Epoch 223/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8991 - bpp: 1.0226 - mse: 4.5812e-04\n",
      "Epoch 223: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 2.8991 - bpp: 1.0226 - mse: 4.5812e-04\n",
      "Epoch 224/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4409 - bpp: 1.0006 - mse: 3.5164e-04\n",
      "Epoch 224: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.4409 - bpp: 1.0006 - mse: 3.5164e-04\n",
      "Epoch 225/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1568 - bpp: 0.9211 - mse: 3.0168e-04\n",
      "Epoch 225: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.1568 - bpp: 0.9211 - mse: 3.0168e-04\n",
      "Epoch 226/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5932 - bpp: 0.9900 - mse: 3.9138e-04\n",
      "Epoch 226: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.5932 - bpp: 0.9900 - mse: 3.9138e-04\n",
      "Epoch 227/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3771 - bpp: 0.9590 - mse: 3.4623e-04\n",
      "Epoch 227: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3771 - bpp: 0.9590 - mse: 3.4623e-04\n",
      "Epoch 228/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4097 - bpp: 0.9706 - mse: 3.5134e-04\n",
      "Epoch 228: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.4097 - bpp: 0.9706 - mse: 3.5134e-04\n",
      "Epoch 229/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5888 - bpp: 0.9717 - mse: 3.9479e-04\n",
      "Epoch 229: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.5888 - bpp: 0.9717 - mse: 3.9479e-04\n",
      "Epoch 230/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8675 - bpp: 0.9691 - mse: 4.6348e-04\n",
      "Epoch 230: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.8675 - bpp: 0.9691 - mse: 4.6348e-04\n",
      "Epoch 231/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5149 - bpp: 1.0581 - mse: 5.9981e-04\n",
      "Epoch 231: loss did not improve from 2.15473\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 3.5149 - bpp: 1.0581 - mse: 5.9981e-04\n",
      "Epoch 232/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1298 - bpp: 0.9301 - mse: 2.9289e-04\n",
      "Epoch 232: loss improved from 2.15473 to 2.12981, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.1298 - bpp: 0.9301 - mse: 2.9289e-04\n",
      "Epoch 233/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3374 - bpp: 0.9644 - mse: 3.3521e-04\n",
      "Epoch 233: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 29s 281ms/step - loss: 2.3374 - bpp: 0.9644 - mse: 3.3521e-04\n",
      "Epoch 234/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6296 - bpp: 0.9716 - mse: 4.0479e-04\n",
      "Epoch 234: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.6296 - bpp: 0.9716 - mse: 4.0479e-04\n",
      "Epoch 235/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9059 - bpp: 0.9956 - mse: 4.6639e-04\n",
      "Epoch 235: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.9059 - bpp: 0.9956 - mse: 4.6639e-04\n",
      "Epoch 236/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7952 - bpp: 0.9267 - mse: 4.5617e-04\n",
      "Epoch 236: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 2.7952 - bpp: 0.9267 - mse: 4.5617e-04\n",
      "Epoch 237/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3367 - bpp: 0.9477 - mse: 3.3912e-04\n",
      "Epoch 237: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 2.3367 - bpp: 0.9477 - mse: 3.3912e-04\n",
      "Epoch 238/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3300 - bpp: 0.9499 - mse: 3.3692e-04\n",
      "Epoch 238: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.3300 - bpp: 0.9499 - mse: 3.3692e-04\n",
      "Epoch 239/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5028 - bpp: 0.9656 - mse: 3.7529e-04\n",
      "Epoch 239: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.5028 - bpp: 0.9656 - mse: 3.7529e-04\n",
      "Epoch 240/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1826 - bpp: 0.9454 - mse: 3.0206e-04\n",
      "Epoch 240: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.1826 - bpp: 0.9454 - mse: 3.0206e-04\n",
      "Epoch 241/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6388 - bpp: 0.9780 - mse: 4.0547e-04\n",
      "Epoch 241: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.6388 - bpp: 0.9780 - mse: 4.0547e-04\n",
      "Epoch 242/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3460 - bpp: 0.9415 - mse: 3.4290e-04\n",
      "Epoch 242: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.3460 - bpp: 0.9415 - mse: 3.4290e-04\n",
      "Epoch 243/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2504 - bpp: 0.9536 - mse: 3.1660e-04\n",
      "Epoch 243: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.2504 - bpp: 0.9536 - mse: 3.1660e-04\n",
      "Epoch 244/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2500 - bpp: 0.9194 - mse: 3.2485e-04\n",
      "Epoch 244: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.2500 - bpp: 0.9194 - mse: 3.2485e-04\n",
      "Epoch 245/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3917 - bpp: 0.9476 - mse: 3.5255e-04\n",
      "Epoch 245: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3917 - bpp: 0.9476 - mse: 3.5255e-04\n",
      "Epoch 246/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4310 - bpp: 0.9533 - mse: 3.6077e-04\n",
      "Epoch 246: loss did not improve from 2.12981\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.4310 - bpp: 0.9533 - mse: 3.6077e-04\n",
      "Epoch 247/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0862 - bpp: 0.8741 - mse: 2.9591e-04\n",
      "Epoch 247: loss improved from 2.12981 to 2.08615, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 2.0862 - bpp: 0.8741 - mse: 2.9591e-04\n",
      "Epoch 248/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3383 - bpp: 0.9367 - mse: 3.4220e-04\n",
      "Epoch 248: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 30s 292ms/step - loss: 2.3383 - bpp: 0.9367 - mse: 3.4220e-04\n",
      "Epoch 249/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3526 - bpp: 0.9531 - mse: 3.4168e-04\n",
      "Epoch 249: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.3526 - bpp: 0.9531 - mse: 3.4168e-04\n",
      "Epoch 250/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4728 - bpp: 0.9730 - mse: 3.6617e-04\n",
      "Epoch 250: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4728 - bpp: 0.9730 - mse: 3.6617e-04\n",
      "Epoch 251/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3215 - bpp: 0.9291 - mse: 3.3996e-04\n",
      "Epoch 251: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.3215 - bpp: 0.9291 - mse: 3.3996e-04\n",
      "Epoch 252/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3971 - bpp: 0.9657 - mse: 3.4946e-04\n",
      "Epoch 252: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.3971 - bpp: 0.9657 - mse: 3.4946e-04\n",
      "Epoch 253/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8223 - bpp: 0.9694 - mse: 4.5236e-04\n",
      "Epoch 253: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 2.8223 - bpp: 0.9694 - mse: 4.5236e-04\n",
      "Epoch 254/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4302 - bpp: 0.9482 - mse: 3.6182e-04\n",
      "Epoch 254: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.4302 - bpp: 0.9482 - mse: 3.6182e-04\n",
      "Epoch 255/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0847 - bpp: 1.0345 - mse: 7.4466e-04\n",
      "Epoch 255: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 4.0847 - bpp: 1.0345 - mse: 7.4466e-04\n",
      "Epoch 256/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5279 - bpp: 0.9683 - mse: 3.8075e-04\n",
      "Epoch 256: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 2.5279 - bpp: 0.9683 - mse: 3.8075e-04\n",
      "Epoch 257/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4877 - bpp: 0.9718 - mse: 3.7010e-04\n",
      "Epoch 257: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.4877 - bpp: 0.9718 - mse: 3.7010e-04\n",
      "Epoch 258/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1426 - bpp: 0.9296 - mse: 2.9615e-04\n",
      "Epoch 258: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.1426 - bpp: 0.9296 - mse: 2.9615e-04\n",
      "Epoch 259/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1115 - bpp: 0.9199 - mse: 2.9093e-04\n",
      "Epoch 259: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.1115 - bpp: 0.9199 - mse: 2.9093e-04\n",
      "Epoch 260/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4953 - bpp: 0.9620 - mse: 3.7435e-04\n",
      "Epoch 260: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 2.4953 - bpp: 0.9620 - mse: 3.7435e-04\n",
      "Epoch 261/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3084 - bpp: 0.9365 - mse: 3.3495e-04\n",
      "Epoch 261: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.3084 - bpp: 0.9365 - mse: 3.3495e-04\n",
      "Epoch 262/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1042 - bpp: 0.9217 - mse: 2.8871e-04\n",
      "Epoch 262: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.1042 - bpp: 0.9217 - mse: 2.8871e-04\n",
      "Epoch 263/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1438 - bpp: 0.9221 - mse: 2.9828e-04\n",
      "Epoch 263: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.1438 - bpp: 0.9221 - mse: 2.9828e-04\n",
      "Epoch 264/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6519 - bpp: 0.9293 - mse: 4.2055e-04\n",
      "Epoch 264: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 2.6519 - bpp: 0.9293 - mse: 4.2055e-04\n",
      "Epoch 265/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8936 - bpp: 0.9595 - mse: 4.7218e-04\n",
      "Epoch 265: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.8936 - bpp: 0.9595 - mse: 4.7218e-04\n",
      "Epoch 266/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3825 - bpp: 0.9359 - mse: 3.5317e-04\n",
      "Epoch 266: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.3825 - bpp: 0.9359 - mse: 3.5317e-04\n",
      "Epoch 267/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1869 - bpp: 0.9146 - mse: 3.1061e-04\n",
      "Epoch 267: loss did not improve from 2.08615\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.1869 - bpp: 0.9146 - mse: 3.1061e-04\n",
      "Epoch 268/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9795 - bpp: 0.8946 - mse: 2.6486e-04\n",
      "Epoch 268: loss improved from 2.08615 to 1.97951, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 281ms/step - loss: 1.9795 - bpp: 0.8946 - mse: 2.6486e-04\n",
      "Epoch 269/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3896 - bpp: 0.9518 - mse: 3.5101e-04\n",
      "Epoch 269: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.3896 - bpp: 0.9518 - mse: 3.5101e-04\n",
      "Epoch 270/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2975 - bpp: 0.9343 - mse: 3.3280e-04\n",
      "Epoch 270: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.2975 - bpp: 0.9343 - mse: 3.3280e-04\n",
      "Epoch 271/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2193 - bpp: 0.9285 - mse: 3.1515e-04\n",
      "Epoch 271: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.2193 - bpp: 0.9285 - mse: 3.1515e-04\n",
      "Epoch 272/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2082 - bpp: 0.9286 - mse: 3.1242e-04\n",
      "Epoch 272: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 2.2082 - bpp: 0.9286 - mse: 3.1242e-04\n",
      "Epoch 273/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4252 - bpp: 0.9541 - mse: 3.5915e-04\n",
      "Epoch 273: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 2.4252 - bpp: 0.9541 - mse: 3.5915e-04\n",
      "Epoch 274/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1581 - bpp: 0.9376 - mse: 2.9797e-04\n",
      "Epoch 274: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 2.1581 - bpp: 0.9376 - mse: 2.9797e-04\n",
      "Epoch 275/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3620 - bpp: 0.9500 - mse: 3.4473e-04\n",
      "Epoch 275: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.3620 - bpp: 0.9500 - mse: 3.4473e-04\n",
      "Epoch 276/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2959 - bpp: 0.9285 - mse: 3.3384e-04\n",
      "Epoch 276: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 2.2959 - bpp: 0.9285 - mse: 3.3384e-04\n",
      "Epoch 277/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5253 - bpp: 0.9470 - mse: 3.8531e-04\n",
      "Epoch 277: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.5253 - bpp: 0.9470 - mse: 3.8531e-04\n",
      "Epoch 278/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2812 - bpp: 0.9249 - mse: 3.3115e-04\n",
      "Epoch 278: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.2812 - bpp: 0.9249 - mse: 3.3115e-04\n",
      "Epoch 279/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3265 - bpp: 0.9077 - mse: 3.4640e-04\n",
      "Epoch 279: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.3265 - bpp: 0.9077 - mse: 3.4640e-04\n",
      "Epoch 280/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3754 - bpp: 0.9284 - mse: 3.5327e-04\n",
      "Epoch 280: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.3754 - bpp: 0.9284 - mse: 3.5327e-04\n",
      "Epoch 281/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4354 - bpp: 0.9191 - mse: 3.7020e-04\n",
      "Epoch 281: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.4354 - bpp: 0.9191 - mse: 3.7020e-04\n",
      "Epoch 282/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5349 - bpp: 0.9659 - mse: 3.8307e-04\n",
      "Epoch 282: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.5349 - bpp: 0.9659 - mse: 3.8307e-04\n",
      "Epoch 283/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1953 - bpp: 0.9125 - mse: 3.1318e-04\n",
      "Epoch 283: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 2.1953 - bpp: 0.9125 - mse: 3.1318e-04\n",
      "Epoch 284/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2941 - bpp: 0.9119 - mse: 3.3746e-04\n",
      "Epoch 284: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.2941 - bpp: 0.9119 - mse: 3.3746e-04\n",
      "Epoch 285/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9904 - bpp: 0.9064 - mse: 2.6466e-04\n",
      "Epoch 285: loss did not improve from 1.97951\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.9904 - bpp: 0.9064 - mse: 2.6466e-04\n",
      "Epoch 286/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9645 - bpp: 0.8947 - mse: 2.6118e-04\n",
      "Epoch 286: loss improved from 1.97951 to 1.96450, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.9645 - bpp: 0.8947 - mse: 2.6118e-04\n",
      "Epoch 287/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2764 - bpp: 0.9180 - mse: 3.3164e-04\n",
      "Epoch 287: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 2.2764 - bpp: 0.9180 - mse: 3.3164e-04\n",
      "Epoch 288/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1899 - bpp: 0.8980 - mse: 3.1540e-04\n",
      "Epoch 288: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 2.1899 - bpp: 0.8980 - mse: 3.1540e-04\n",
      "Epoch 289/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9714 - bpp: 0.8825 - mse: 2.6584e-04\n",
      "Epoch 289: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.9714 - bpp: 0.8825 - mse: 2.6584e-04\n",
      "Epoch 290/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9760 - bpp: 0.9480 - mse: 4.9510e-04\n",
      "Epoch 290: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.9760 - bpp: 0.9480 - mse: 4.9510e-04\n",
      "Epoch 291/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6957 - bpp: 0.9674 - mse: 6.6610e-04\n",
      "Epoch 291: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 3.6957 - bpp: 0.9674 - mse: 6.6610e-04\n",
      "Epoch 292/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3685 - bpp: 0.9216 - mse: 3.5326e-04\n",
      "Epoch 292: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 2.3685 - bpp: 0.9216 - mse: 3.5326e-04\n",
      "Epoch 293/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0558 - bpp: 0.8956 - mse: 2.8327e-04\n",
      "Epoch 293: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.0558 - bpp: 0.8956 - mse: 2.8327e-04\n",
      "Epoch 294/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3109 - bpp: 0.9224 - mse: 3.3900e-04\n",
      "Epoch 294: loss did not improve from 1.96450\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.3109 - bpp: 0.9224 - mse: 3.3900e-04\n",
      "Epoch 295/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9460 - bpp: 0.9007 - mse: 2.5520e-04\n",
      "Epoch 295: loss improved from 1.96450 to 1.94602, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.9460 - bpp: 0.9007 - mse: 2.5520e-04\n",
      "Epoch 296/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2670 - bpp: 0.9182 - mse: 3.2931e-04\n",
      "Epoch 296: loss did not improve from 1.94602\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.2670 - bpp: 0.9182 - mse: 3.2931e-04\n",
      "Epoch 297/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9228 - bpp: 0.8572 - mse: 2.6014e-04\n",
      "Epoch 297: loss improved from 1.94602 to 1.92275, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.9228 - bpp: 0.8572 - mse: 2.6014e-04\n",
      "Epoch 298/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3108 - bpp: 0.9335 - mse: 3.3627e-04\n",
      "Epoch 298: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 2.3108 - bpp: 0.9335 - mse: 3.3627e-04\n",
      "Epoch 299/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1714 - bpp: 0.8967 - mse: 3.1121e-04\n",
      "Epoch 299: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.1714 - bpp: 0.8967 - mse: 3.1121e-04\n",
      "Epoch 300/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9954 - bpp: 0.8857 - mse: 2.7091e-04\n",
      "Epoch 300: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9954 - bpp: 0.8857 - mse: 2.7091e-04\n",
      "Epoch 301/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1804 - bpp: 0.8965 - mse: 3.1345e-04\n",
      "Epoch 301: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.1804 - bpp: 0.8965 - mse: 3.1345e-04\n",
      "Epoch 302/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4722 - bpp: 0.8779 - mse: 3.8923e-04\n",
      "Epoch 302: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 2.4722 - bpp: 0.8779 - mse: 3.8923e-04\n",
      "Epoch 303/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1284 - bpp: 0.8941 - mse: 3.0136e-04\n",
      "Epoch 303: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1284 - bpp: 0.8941 - mse: 3.0136e-04\n",
      "Epoch 304/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1667 - bpp: 0.8958 - mse: 3.1029e-04\n",
      "Epoch 304: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.1667 - bpp: 0.8958 - mse: 3.1029e-04\n",
      "Epoch 305/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2547 - bpp: 0.9076 - mse: 3.2888e-04\n",
      "Epoch 305: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.2547 - bpp: 0.9076 - mse: 3.2888e-04\n",
      "Epoch 306/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3293 - bpp: 0.9097 - mse: 3.4658e-04\n",
      "Epoch 306: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3293 - bpp: 0.9097 - mse: 3.4658e-04\n",
      "Epoch 307/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9628 - bpp: 0.8613 - mse: 2.6892e-04\n",
      "Epoch 307: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.9628 - bpp: 0.8613 - mse: 2.6892e-04\n",
      "Epoch 308/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0615 - bpp: 0.8931 - mse: 2.8526e-04\n",
      "Epoch 308: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.0615 - bpp: 0.8931 - mse: 2.8526e-04\n",
      "Epoch 309/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2784 - bpp: 0.9365 - mse: 3.2762e-04\n",
      "Epoch 309: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.2784 - bpp: 0.9365 - mse: 3.2762e-04\n",
      "Epoch 310/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2580 - bpp: 0.9105 - mse: 3.2897e-04\n",
      "Epoch 310: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.2580 - bpp: 0.9105 - mse: 3.2897e-04\n",
      "Epoch 311/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1267 - bpp: 0.9064 - mse: 2.9793e-04\n",
      "Epoch 311: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.1267 - bpp: 0.9064 - mse: 2.9793e-04\n",
      "Epoch 312/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0739 - bpp: 0.8749 - mse: 2.9271e-04\n",
      "Epoch 312: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.0739 - bpp: 0.8749 - mse: 2.9271e-04\n",
      "Epoch 313/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2435 - bpp: 0.9221 - mse: 3.2260e-04\n",
      "Epoch 313: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.2435 - bpp: 0.9221 - mse: 3.2260e-04\n",
      "Epoch 314/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0989 - bpp: 0.8902 - mse: 2.9509e-04\n",
      "Epoch 314: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0989 - bpp: 0.8902 - mse: 2.9509e-04\n",
      "Epoch 315/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5058 - bpp: 0.9374 - mse: 3.8293e-04\n",
      "Epoch 315: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.5058 - bpp: 0.9374 - mse: 3.8293e-04\n",
      "Epoch 316/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3425 - bpp: 0.9061 - mse: 3.5069e-04\n",
      "Epoch 316: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.3425 - bpp: 0.9061 - mse: 3.5069e-04\n",
      "Epoch 317/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0775 - bpp: 0.8967 - mse: 2.8827e-04\n",
      "Epoch 317: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.0775 - bpp: 0.8967 - mse: 2.8827e-04\n",
      "Epoch 318/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1961 - bpp: 0.8763 - mse: 3.2223e-04\n",
      "Epoch 318: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.1961 - bpp: 0.8763 - mse: 3.2223e-04\n",
      "Epoch 319/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4184 - bpp: 0.9312 - mse: 3.6308e-04\n",
      "Epoch 319: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.4184 - bpp: 0.9312 - mse: 3.6308e-04\n",
      "Epoch 320/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6498 - bpp: 0.9117 - mse: 4.2434e-04\n",
      "Epoch 320: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 2.6498 - bpp: 0.9117 - mse: 4.2434e-04\n",
      "Epoch 321/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1723 - bpp: 0.8787 - mse: 3.1582e-04\n",
      "Epoch 321: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.1723 - bpp: 0.8787 - mse: 3.1582e-04\n",
      "Epoch 322/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0054 - bpp: 0.8809 - mse: 2.7455e-04\n",
      "Epoch 322: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.0054 - bpp: 0.8809 - mse: 2.7455e-04\n",
      "Epoch 323/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1980 - bpp: 0.8873 - mse: 3.1999e-04\n",
      "Epoch 323: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1980 - bpp: 0.8873 - mse: 3.1999e-04\n",
      "Epoch 324/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1091 - bpp: 0.8893 - mse: 2.9781e-04\n",
      "Epoch 324: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.1091 - bpp: 0.8893 - mse: 2.9781e-04\n",
      "Epoch 325/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1045 - bpp: 0.8589 - mse: 3.0411e-04\n",
      "Epoch 325: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1045 - bpp: 0.8589 - mse: 3.0411e-04\n",
      "Epoch 326/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0470 - bpp: 0.8864 - mse: 2.8335e-04\n",
      "Epoch 326: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0470 - bpp: 0.8864 - mse: 2.8335e-04\n",
      "Epoch 327/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0051 - bpp: 0.8626 - mse: 2.7893e-04\n",
      "Epoch 327: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.0051 - bpp: 0.8626 - mse: 2.7893e-04\n",
      "Epoch 328/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3430 - bpp: 0.9262 - mse: 3.4591e-04\n",
      "Epoch 328: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.3430 - bpp: 0.9262 - mse: 3.4591e-04\n",
      "Epoch 329/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6519 - bpp: 0.9457 - mse: 4.1656e-04\n",
      "Epoch 329: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 2.6519 - bpp: 0.9457 - mse: 4.1656e-04\n",
      "Epoch 330/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3509 - bpp: 0.9351 - mse: 3.4566e-04\n",
      "Epoch 330: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.3509 - bpp: 0.9351 - mse: 3.4566e-04\n",
      "Epoch 331/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9887 - bpp: 0.8620 - mse: 2.7507e-04\n",
      "Epoch 331: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9887 - bpp: 0.8620 - mse: 2.7507e-04\n",
      "Epoch 332/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8672 - bpp: 0.9669 - mse: 4.6395e-04\n",
      "Epoch 332: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.8672 - bpp: 0.9669 - mse: 4.6395e-04\n",
      "Epoch 333/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2385 - bpp: 0.9121 - mse: 3.2382e-04\n",
      "Epoch 333: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.2385 - bpp: 0.9121 - mse: 3.2382e-04\n",
      "Epoch 334/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2269 - bpp: 0.8915 - mse: 3.2602e-04\n",
      "Epoch 334: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.2269 - bpp: 0.8915 - mse: 3.2602e-04\n",
      "Epoch 335/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0742 - bpp: 0.8860 - mse: 2.9009e-04\n",
      "Epoch 335: loss did not improve from 1.92275\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.0742 - bpp: 0.8860 - mse: 2.9009e-04\n",
      "Epoch 336/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8549 - bpp: 0.8437 - mse: 2.4686e-04\n",
      "Epoch 336: loss improved from 1.92275 to 1.85486, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8549 - bpp: 0.8437 - mse: 2.4686e-04\n",
      "Epoch 337/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0960 - bpp: 0.8778 - mse: 2.9740e-04\n",
      "Epoch 337: loss did not improve from 1.85486\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.0960 - bpp: 0.8778 - mse: 2.9740e-04\n",
      "Epoch 338/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1140 - bpp: 0.8840 - mse: 3.0029e-04\n",
      "Epoch 338: loss did not improve from 1.85486\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 2.1140 - bpp: 0.8840 - mse: 3.0029e-04\n",
      "Epoch 339/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2841 - bpp: 0.8670 - mse: 3.4596e-04\n",
      "Epoch 339: loss did not improve from 1.85486\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.2841 - bpp: 0.8670 - mse: 3.4596e-04\n",
      "Epoch 340/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0218 - bpp: 0.8776 - mse: 2.7935e-04\n",
      "Epoch 340: loss did not improve from 1.85486\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.0218 - bpp: 0.8776 - mse: 2.7935e-04\n",
      "Epoch 341/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7589 - bpp: 0.8434 - mse: 2.2350e-04\n",
      "Epoch 341: loss improved from 1.85486 to 1.75887, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.7589 - bpp: 0.8434 - mse: 2.2350e-04\n",
      "Epoch 342/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2500 - bpp: 0.8749 - mse: 3.3571e-04\n",
      "Epoch 342: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.2500 - bpp: 0.8749 - mse: 3.3571e-04\n",
      "Epoch 343/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4927 - bpp: 0.9160 - mse: 3.8492e-04\n",
      "Epoch 343: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4927 - bpp: 0.9160 - mse: 3.8492e-04\n",
      "Epoch 344/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2620 - bpp: 0.9071 - mse: 3.3079e-04\n",
      "Epoch 344: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.2620 - bpp: 0.9071 - mse: 3.3079e-04\n",
      "Epoch 345/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1504 - bpp: 0.8777 - mse: 3.1073e-04\n",
      "Epoch 345: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.1504 - bpp: 0.8777 - mse: 3.1073e-04\n",
      "Epoch 346/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0699 - bpp: 0.8846 - mse: 2.8938e-04\n",
      "Epoch 346: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.0699 - bpp: 0.8846 - mse: 2.8938e-04\n",
      "Epoch 347/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0947 - bpp: 0.8830 - mse: 2.9583e-04\n",
      "Epoch 347: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0947 - bpp: 0.8830 - mse: 2.9583e-04\n",
      "Epoch 348/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0761 - bpp: 0.8878 - mse: 2.9012e-04\n",
      "Epoch 348: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 250ms/step - loss: 2.0761 - bpp: 0.8878 - mse: 2.9012e-04\n",
      "Epoch 349/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1252 - bpp: 0.8977 - mse: 2.9969e-04\n",
      "Epoch 349: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.1252 - bpp: 0.8977 - mse: 2.9969e-04\n",
      "Epoch 350/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2855 - bpp: 0.8847 - mse: 3.4199e-04\n",
      "Epoch 350: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.2855 - bpp: 0.8847 - mse: 3.4199e-04\n",
      "Epoch 351/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9113 - bpp: 0.8531 - mse: 2.5836e-04\n",
      "Epoch 351: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.9113 - bpp: 0.8531 - mse: 2.5836e-04\n",
      "Epoch 352/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9603 - bpp: 0.8349 - mse: 2.7477e-04\n",
      "Epoch 352: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 1.9603 - bpp: 0.8349 - mse: 2.7477e-04\n",
      "Epoch 353/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2627 - bpp: 0.8759 - mse: 3.3858e-04\n",
      "Epoch 353: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.2627 - bpp: 0.8759 - mse: 3.3858e-04\n",
      "Epoch 354/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9015 - bpp: 0.9407 - mse: 4.7872e-04\n",
      "Epoch 354: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.9015 - bpp: 0.9407 - mse: 4.7872e-04\n",
      "Epoch 355/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5030 - bpp: 0.9393 - mse: 3.8177e-04\n",
      "Epoch 355: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 2.5030 - bpp: 0.9393 - mse: 3.8177e-04\n",
      "Epoch 356/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0640 - bpp: 0.8955 - mse: 2.8529e-04\n",
      "Epoch 356: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.0640 - bpp: 0.8955 - mse: 2.8529e-04\n",
      "Epoch 357/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1360 - bpp: 0.8814 - mse: 3.0631e-04\n",
      "Epoch 357: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.1360 - bpp: 0.8814 - mse: 3.0631e-04\n",
      "Epoch 358/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0321 - bpp: 0.8697 - mse: 2.8379e-04\n",
      "Epoch 358: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 250ms/step - loss: 2.0321 - bpp: 0.8697 - mse: 2.8379e-04\n",
      "Epoch 359/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1188 - bpp: 0.8737 - mse: 3.0396e-04\n",
      "Epoch 359: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.1188 - bpp: 0.8737 - mse: 3.0396e-04\n",
      "Epoch 360/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9671 - bpp: 0.8532 - mse: 2.7196e-04\n",
      "Epoch 360: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9671 - bpp: 0.8532 - mse: 2.7196e-04\n",
      "Epoch 361/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9974 - bpp: 0.8437 - mse: 2.8167e-04\n",
      "Epoch 361: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9974 - bpp: 0.8437 - mse: 2.8167e-04\n",
      "Epoch 362/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8203 - bpp: 0.8449 - mse: 2.3813e-04\n",
      "Epoch 362: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.8203 - bpp: 0.8449 - mse: 2.3813e-04\n",
      "Epoch 363/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0819 - bpp: 0.8781 - mse: 2.9389e-04\n",
      "Epoch 363: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 2.0819 - bpp: 0.8781 - mse: 2.9389e-04\n",
      "Epoch 364/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1158 - bpp: 0.8865 - mse: 3.0013e-04\n",
      "Epoch 364: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 2.1158 - bpp: 0.8865 - mse: 3.0013e-04\n",
      "Epoch 365/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9819 - bpp: 0.8525 - mse: 2.7574e-04\n",
      "Epoch 365: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 30s 292ms/step - loss: 1.9819 - bpp: 0.8525 - mse: 2.7574e-04\n",
      "Epoch 366/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7701 - bpp: 0.8301 - mse: 2.2949e-04\n",
      "Epoch 366: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 30s 293ms/step - loss: 1.7701 - bpp: 0.8301 - mse: 2.2949e-04\n",
      "Epoch 367/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1292 - bpp: 0.8580 - mse: 3.1035e-04\n",
      "Epoch 367: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.1292 - bpp: 0.8580 - mse: 3.1035e-04\n",
      "Epoch 368/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3601 - bpp: 0.9240 - mse: 3.5062e-04\n",
      "Epoch 368: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3601 - bpp: 0.9240 - mse: 3.5062e-04\n",
      "Epoch 369/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0301 - bpp: 0.8614 - mse: 2.8533e-04\n",
      "Epoch 369: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.0301 - bpp: 0.8614 - mse: 2.8533e-04\n",
      "Epoch 370/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3071 - bpp: 0.8998 - mse: 3.4356e-04\n",
      "Epoch 370: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.3071 - bpp: 0.8998 - mse: 3.4356e-04\n",
      "Epoch 371/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0623 - bpp: 0.8792 - mse: 2.8885e-04\n",
      "Epoch 371: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.0623 - bpp: 0.8792 - mse: 2.8885e-04\n",
      "Epoch 372/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9172 - bpp: 0.8605 - mse: 2.5798e-04\n",
      "Epoch 372: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9172 - bpp: 0.8605 - mse: 2.5798e-04\n",
      "Epoch 373/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8795 - bpp: 0.8675 - mse: 2.4706e-04\n",
      "Epoch 373: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.8795 - bpp: 0.8675 - mse: 2.4706e-04\n",
      "Epoch 374/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7919 - bpp: 0.8242 - mse: 2.3626e-04\n",
      "Epoch 374: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.7919 - bpp: 0.8242 - mse: 2.3626e-04\n",
      "Epoch 375/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0079 - bpp: 0.8643 - mse: 2.7921e-04\n",
      "Epoch 375: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.0079 - bpp: 0.8643 - mse: 2.7921e-04\n",
      "Epoch 376/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0525 - bpp: 0.8878 - mse: 2.8434e-04\n",
      "Epoch 376: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0525 - bpp: 0.8878 - mse: 2.8434e-04\n",
      "Epoch 377/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8285 - bpp: 0.8389 - mse: 2.4160e-04\n",
      "Epoch 377: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.8285 - bpp: 0.8389 - mse: 2.4160e-04\n",
      "Epoch 378/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0687 - bpp: 0.8782 - mse: 2.9065e-04\n",
      "Epoch 378: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0687 - bpp: 0.8782 - mse: 2.9065e-04\n",
      "Epoch 379/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8190 - bpp: 0.8413 - mse: 2.3870e-04\n",
      "Epoch 379: loss did not improve from 1.75887\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.8190 - bpp: 0.8413 - mse: 2.3870e-04\n",
      "Epoch 380/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7177 - bpp: 0.8239 - mse: 2.1823e-04\n",
      "Epoch 380: loss improved from 1.75887 to 1.71773, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.7177 - bpp: 0.8239 - mse: 2.1823e-04\n",
      "Epoch 381/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6707 - bpp: 0.8104 - mse: 2.1004e-04\n",
      "Epoch 381: loss improved from 1.71773 to 1.67068, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.6707 - bpp: 0.8104 - mse: 2.1004e-04\n",
      "Epoch 382/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1432 - bpp: 0.8972 - mse: 3.0420e-04\n",
      "Epoch 382: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1432 - bpp: 0.8972 - mse: 3.0420e-04\n",
      "Epoch 383/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0170 - bpp: 0.8744 - mse: 2.7896e-04\n",
      "Epoch 383: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0170 - bpp: 0.8744 - mse: 2.7896e-04\n",
      "Epoch 384/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1024 - bpp: 0.8806 - mse: 2.9830e-04\n",
      "Epoch 384: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.1024 - bpp: 0.8806 - mse: 2.9830e-04\n",
      "Epoch 385/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1115 - bpp: 0.8588 - mse: 3.0585e-04\n",
      "Epoch 385: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1115 - bpp: 0.8588 - mse: 3.0585e-04\n",
      "Epoch 386/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1207 - bpp: 0.8604 - mse: 3.0768e-04\n",
      "Epoch 386: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1207 - bpp: 0.8604 - mse: 3.0768e-04\n",
      "Epoch 387/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1007 - bpp: 0.8758 - mse: 2.9905e-04\n",
      "Epoch 387: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.1007 - bpp: 0.8758 - mse: 2.9905e-04\n",
      "Epoch 388/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0328 - bpp: 0.8575 - mse: 2.8695e-04\n",
      "Epoch 388: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0328 - bpp: 0.8575 - mse: 2.8695e-04\n",
      "Epoch 389/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9368 - bpp: 0.8558 - mse: 2.6394e-04\n",
      "Epoch 389: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.9368 - bpp: 0.8558 - mse: 2.6394e-04\n",
      "Epoch 390/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8543 - bpp: 0.8281 - mse: 2.5052e-04\n",
      "Epoch 390: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.8543 - bpp: 0.8281 - mse: 2.5052e-04\n",
      "Epoch 391/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0807 - bpp: 0.8592 - mse: 2.9822e-04\n",
      "Epoch 391: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.0807 - bpp: 0.8592 - mse: 2.9822e-04\n",
      "Epoch 392/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0249 - bpp: 0.8691 - mse: 2.8217e-04\n",
      "Epoch 392: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0249 - bpp: 0.8691 - mse: 2.8217e-04\n",
      "Epoch 393/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1012 - bpp: 0.8791 - mse: 2.9835e-04\n",
      "Epoch 393: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.1012 - bpp: 0.8791 - mse: 2.9835e-04\n",
      "Epoch 394/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9118 - bpp: 0.8727 - mse: 2.5368e-04\n",
      "Epoch 394: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.9118 - bpp: 0.8727 - mse: 2.5368e-04\n",
      "Epoch 395/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0788 - bpp: 0.8658 - mse: 2.9616e-04\n",
      "Epoch 395: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0788 - bpp: 0.8658 - mse: 2.9616e-04\n",
      "Epoch 396/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0719 - bpp: 0.8680 - mse: 2.9392e-04\n",
      "Epoch 396: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.0719 - bpp: 0.8680 - mse: 2.9392e-04\n",
      "Epoch 397/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9304 - bpp: 0.8554 - mse: 2.6245e-04\n",
      "Epoch 397: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9304 - bpp: 0.8554 - mse: 2.6245e-04\n",
      "Epoch 398/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9401 - bpp: 0.8446 - mse: 2.6744e-04\n",
      "Epoch 398: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.9401 - bpp: 0.8446 - mse: 2.6744e-04\n",
      "Epoch 399/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8601 - bpp: 0.8373 - mse: 2.4970e-04\n",
      "Epoch 399: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.8601 - bpp: 0.8373 - mse: 2.4970e-04\n",
      "Epoch 400/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0363 - bpp: 0.8817 - mse: 2.8188e-04\n",
      "Epoch 400: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0363 - bpp: 0.8817 - mse: 2.8188e-04\n",
      "Epoch 401/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9195 - bpp: 0.8407 - mse: 2.6336e-04\n",
      "Epoch 401: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.9195 - bpp: 0.8407 - mse: 2.6336e-04\n",
      "Epoch 402/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8426 - bpp: 0.8143 - mse: 2.5105e-04\n",
      "Epoch 402: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.8426 - bpp: 0.8143 - mse: 2.5105e-04\n",
      "Epoch 403/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0969 - bpp: 0.8581 - mse: 3.0245e-04\n",
      "Epoch 403: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.0969 - bpp: 0.8581 - mse: 3.0245e-04\n",
      "Epoch 404/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0449 - bpp: 0.8499 - mse: 2.9175e-04\n",
      "Epoch 404: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.0449 - bpp: 0.8499 - mse: 2.9175e-04\n",
      "Epoch 405/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8053 - bpp: 0.8301 - mse: 2.3808e-04\n",
      "Epoch 405: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.8053 - bpp: 0.8301 - mse: 2.3808e-04\n",
      "Epoch 406/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9124 - bpp: 0.8403 - mse: 2.6176e-04\n",
      "Epoch 406: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9124 - bpp: 0.8403 - mse: 2.6176e-04\n",
      "Epoch 407/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8944 - bpp: 0.8622 - mse: 2.5201e-04\n",
      "Epoch 407: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.8944 - bpp: 0.8622 - mse: 2.5201e-04\n",
      "Epoch 408/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3941 - bpp: 0.9172 - mse: 3.6057e-04\n",
      "Epoch 408: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.3941 - bpp: 0.9172 - mse: 3.6057e-04\n",
      "Epoch 409/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0898 - bpp: 0.8423 - mse: 3.0456e-04\n",
      "Epoch 409: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.0898 - bpp: 0.8423 - mse: 3.0456e-04\n",
      "Epoch 410/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0660 - bpp: 0.8822 - mse: 2.8901e-04\n",
      "Epoch 410: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.0660 - bpp: 0.8822 - mse: 2.8901e-04\n",
      "Epoch 411/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9408 - bpp: 0.8360 - mse: 2.6972e-04\n",
      "Epoch 411: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.9408 - bpp: 0.8360 - mse: 2.6972e-04\n",
      "Epoch 412/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9939 - bpp: 0.8743 - mse: 2.7334e-04\n",
      "Epoch 412: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.9939 - bpp: 0.8743 - mse: 2.7334e-04\n",
      "Epoch 413/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9521 - bpp: 0.8530 - mse: 2.6834e-04\n",
      "Epoch 413: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.9521 - bpp: 0.8530 - mse: 2.6834e-04\n",
      "Epoch 414/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9186 - bpp: 0.8409 - mse: 2.6311e-04\n",
      "Epoch 414: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.9186 - bpp: 0.8409 - mse: 2.6311e-04\n",
      "Epoch 415/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9237 - bpp: 0.8643 - mse: 2.5864e-04\n",
      "Epoch 415: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.9237 - bpp: 0.8643 - mse: 2.5864e-04\n",
      "Epoch 416/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7518 - bpp: 0.8234 - mse: 2.2666e-04\n",
      "Epoch 416: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 1.7518 - bpp: 0.8234 - mse: 2.2666e-04\n",
      "Epoch 417/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8062 - bpp: 0.8325 - mse: 2.3773e-04\n",
      "Epoch 417: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8062 - bpp: 0.8325 - mse: 2.3773e-04\n",
      "Epoch 418/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3083 - bpp: 0.8551 - mse: 3.5479e-04\n",
      "Epoch 418: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.3083 - bpp: 0.8551 - mse: 3.5479e-04\n",
      "Epoch 419/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1350 - bpp: 0.8671 - mse: 3.0955e-04\n",
      "Epoch 419: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.1350 - bpp: 0.8671 - mse: 3.0955e-04\n",
      "Epoch 420/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0466 - bpp: 0.8692 - mse: 2.8744e-04\n",
      "Epoch 420: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.0466 - bpp: 0.8692 - mse: 2.8744e-04\n",
      "Epoch 421/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0551 - bpp: 0.8751 - mse: 2.8809e-04\n",
      "Epoch 421: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.0551 - bpp: 0.8751 - mse: 2.8809e-04\n",
      "Epoch 422/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7219 - bpp: 0.8128 - mse: 2.2195e-04\n",
      "Epoch 422: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.7219 - bpp: 0.8128 - mse: 2.2195e-04\n",
      "Epoch 423/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9079 - bpp: 0.8656 - mse: 2.5445e-04\n",
      "Epoch 423: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.9079 - bpp: 0.8656 - mse: 2.5445e-04\n",
      "Epoch 424/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0261 - bpp: 0.8652 - mse: 2.8342e-04\n",
      "Epoch 424: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.0261 - bpp: 0.8652 - mse: 2.8342e-04\n",
      "Epoch 425/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8792 - bpp: 0.8450 - mse: 2.5248e-04\n",
      "Epoch 425: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.8792 - bpp: 0.8450 - mse: 2.5248e-04\n",
      "Epoch 426/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8780 - bpp: 0.8523 - mse: 2.5043e-04\n",
      "Epoch 426: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.8780 - bpp: 0.8523 - mse: 2.5043e-04\n",
      "Epoch 427/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9473 - bpp: 0.8650 - mse: 2.6424e-04\n",
      "Epoch 427: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9473 - bpp: 0.8650 - mse: 2.6424e-04\n",
      "Epoch 428/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7622 - bpp: 0.8035 - mse: 2.3406e-04\n",
      "Epoch 428: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.7622 - bpp: 0.8035 - mse: 2.3406e-04\n",
      "Epoch 429/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9365 - bpp: 0.8596 - mse: 2.6292e-04\n",
      "Epoch 429: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 1.9365 - bpp: 0.8596 - mse: 2.6292e-04\n",
      "Epoch 430/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0075 - bpp: 0.8545 - mse: 2.8149e-04\n",
      "Epoch 430: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.0075 - bpp: 0.8545 - mse: 2.8149e-04\n",
      "Epoch 431/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8355 - bpp: 0.8409 - mse: 2.4283e-04\n",
      "Epoch 431: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 1.8355 - bpp: 0.8409 - mse: 2.4283e-04\n",
      "Epoch 432/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0847 - bpp: 0.8558 - mse: 3.0003e-04\n",
      "Epoch 432: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.0847 - bpp: 0.8558 - mse: 3.0003e-04\n",
      "Epoch 433/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0830 - bpp: 0.8624 - mse: 2.9798e-04\n",
      "Epoch 433: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.0830 - bpp: 0.8624 - mse: 2.9798e-04\n",
      "Epoch 434/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9757 - bpp: 0.8625 - mse: 2.7177e-04\n",
      "Epoch 434: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.9757 - bpp: 0.8625 - mse: 2.7177e-04\n",
      "Epoch 435/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8297 - bpp: 0.8367 - mse: 2.4243e-04\n",
      "Epoch 435: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8297 - bpp: 0.8367 - mse: 2.4243e-04\n",
      "Epoch 436/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9646 - bpp: 0.8661 - mse: 2.6817e-04\n",
      "Epoch 436: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.9646 - bpp: 0.8661 - mse: 2.6817e-04\n",
      "Epoch 437/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0975 - bpp: 0.8729 - mse: 2.9900e-04\n",
      "Epoch 437: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.0975 - bpp: 0.8729 - mse: 2.9900e-04\n",
      "Epoch 438/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9991 - bpp: 0.8429 - mse: 2.8226e-04\n",
      "Epoch 438: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.9991 - bpp: 0.8429 - mse: 2.8226e-04\n",
      "Epoch 439/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6984 - bpp: 0.8059 - mse: 2.1789e-04\n",
      "Epoch 439: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 1.6984 - bpp: 0.8059 - mse: 2.1789e-04\n",
      "Epoch 440/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9804 - bpp: 0.8701 - mse: 2.7106e-04\n",
      "Epoch 440: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.9804 - bpp: 0.8701 - mse: 2.7106e-04\n",
      "Epoch 441/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9675 - bpp: 0.8525 - mse: 2.7222e-04\n",
      "Epoch 441: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.9675 - bpp: 0.8525 - mse: 2.7222e-04\n",
      "Epoch 442/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8054 - bpp: 0.8309 - mse: 2.3790e-04\n",
      "Epoch 442: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.8054 - bpp: 0.8309 - mse: 2.3790e-04\n",
      "Epoch 443/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0723 - bpp: 0.8697 - mse: 2.9362e-04\n",
      "Epoch 443: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.0723 - bpp: 0.8697 - mse: 2.9362e-04\n",
      "Epoch 444/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1205 - bpp: 0.8779 - mse: 3.0336e-04\n",
      "Epoch 444: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1205 - bpp: 0.8779 - mse: 3.0336e-04\n",
      "Epoch 445/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9381 - bpp: 0.8517 - mse: 2.6526e-04\n",
      "Epoch 445: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9381 - bpp: 0.8517 - mse: 2.6526e-04\n",
      "Epoch 446/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7539 - bpp: 0.8353 - mse: 2.2427e-04\n",
      "Epoch 446: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.7539 - bpp: 0.8353 - mse: 2.2427e-04\n",
      "Epoch 447/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9585 - bpp: 0.8539 - mse: 2.6967e-04\n",
      "Epoch 447: loss did not improve from 1.67068\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.9585 - bpp: 0.8539 - mse: 2.6967e-04\n",
      "Epoch 448/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6212 - bpp: 0.7977 - mse: 2.0103e-04\n",
      "Epoch 448: loss improved from 1.67068 to 1.62117, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.6212 - bpp: 0.7977 - mse: 2.0103e-04\n",
      "Epoch 449/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8567 - bpp: 0.8425 - mse: 2.4761e-04\n",
      "Epoch 449: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 1.8567 - bpp: 0.8425 - mse: 2.4761e-04\n",
      "Epoch 450/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7969 - bpp: 0.8134 - mse: 2.4011e-04\n",
      "Epoch 450: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7969 - bpp: 0.8134 - mse: 2.4011e-04\n",
      "Epoch 451/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9651 - bpp: 0.8312 - mse: 2.7682e-04\n",
      "Epoch 451: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 1.9651 - bpp: 0.8312 - mse: 2.7682e-04\n",
      "Epoch 452/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7429 - bpp: 0.8000 - mse: 2.3021e-04\n",
      "Epoch 452: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.7429 - bpp: 0.8000 - mse: 2.3021e-04\n",
      "Epoch 453/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7838 - bpp: 0.8355 - mse: 2.3154e-04\n",
      "Epoch 453: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.7838 - bpp: 0.8355 - mse: 2.3154e-04\n",
      "Epoch 454/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7967 - bpp: 0.8167 - mse: 2.3925e-04\n",
      "Epoch 454: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.7967 - bpp: 0.8167 - mse: 2.3925e-04\n",
      "Epoch 455/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9389 - bpp: 0.8409 - mse: 2.6806e-04\n",
      "Epoch 455: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 26s 249ms/step - loss: 1.9389 - bpp: 0.8409 - mse: 2.6806e-04\n",
      "Epoch 456/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8194 - bpp: 0.8420 - mse: 2.3861e-04\n",
      "Epoch 456: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8194 - bpp: 0.8420 - mse: 2.3861e-04\n",
      "Epoch 457/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8116 - bpp: 0.8108 - mse: 2.4434e-04\n",
      "Epoch 457: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 1.8116 - bpp: 0.8108 - mse: 2.4434e-04\n",
      "Epoch 458/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9113 - bpp: 0.8387 - mse: 2.6187e-04\n",
      "Epoch 458: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.9113 - bpp: 0.8387 - mse: 2.6187e-04\n",
      "Epoch 459/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8084 - bpp: 0.8117 - mse: 2.4334e-04\n",
      "Epoch 459: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.8084 - bpp: 0.8117 - mse: 2.4334e-04\n",
      "Epoch 460/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9454 - bpp: 0.8605 - mse: 2.6488e-04\n",
      "Epoch 460: loss did not improve from 1.62117\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.9454 - bpp: 0.8605 - mse: 2.6488e-04\n",
      "Epoch 461/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6038 - bpp: 0.7802 - mse: 2.0108e-04\n",
      "Epoch 461: loss improved from 1.62117 to 1.60379, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.6038 - bpp: 0.7802 - mse: 2.0108e-04\n",
      "Epoch 462/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0127 - bpp: 0.8582 - mse: 2.8185e-04\n",
      "Epoch 462: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 2.0127 - bpp: 0.8582 - mse: 2.8185e-04\n",
      "Epoch 463/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0178 - bpp: 0.8775 - mse: 2.7841e-04\n",
      "Epoch 463: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.0178 - bpp: 0.8775 - mse: 2.7841e-04\n",
      "Epoch 464/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7972 - bpp: 0.8145 - mse: 2.3993e-04\n",
      "Epoch 464: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.7972 - bpp: 0.8145 - mse: 2.3993e-04\n",
      "Epoch 465/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8478 - bpp: 0.8418 - mse: 2.4563e-04\n",
      "Epoch 465: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.8478 - bpp: 0.8418 - mse: 2.4563e-04\n",
      "Epoch 466/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8255 - bpp: 0.8360 - mse: 2.4157e-04\n",
      "Epoch 466: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.8255 - bpp: 0.8360 - mse: 2.4157e-04\n",
      "Epoch 467/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0007 - bpp: 0.8331 - mse: 2.8508e-04\n",
      "Epoch 467: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0007 - bpp: 0.8331 - mse: 2.8508e-04\n",
      "Epoch 468/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9109 - bpp: 0.8482 - mse: 2.5946e-04\n",
      "Epoch 468: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.9109 - bpp: 0.8482 - mse: 2.5946e-04\n",
      "Epoch 469/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9709 - bpp: 0.8393 - mse: 2.7626e-04\n",
      "Epoch 469: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.9709 - bpp: 0.8393 - mse: 2.7626e-04\n",
      "Epoch 470/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7711 - bpp: 0.8136 - mse: 2.3376e-04\n",
      "Epoch 470: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.7711 - bpp: 0.8136 - mse: 2.3376e-04\n",
      "Epoch 471/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8253 - bpp: 0.8347 - mse: 2.4186e-04\n",
      "Epoch 471: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.8253 - bpp: 0.8347 - mse: 2.4186e-04\n",
      "Epoch 472/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8684 - bpp: 0.8428 - mse: 2.5039e-04\n",
      "Epoch 472: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.8684 - bpp: 0.8428 - mse: 2.5039e-04\n",
      "Epoch 473/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9642 - bpp: 0.8331 - mse: 2.7614e-04\n",
      "Epoch 473: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9642 - bpp: 0.8331 - mse: 2.7614e-04\n",
      "Epoch 474/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7479 - bpp: 0.8136 - mse: 2.2809e-04\n",
      "Epoch 474: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.7479 - bpp: 0.8136 - mse: 2.2809e-04\n",
      "Epoch 475/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0578 - bpp: 0.8501 - mse: 2.9486e-04\n",
      "Epoch 475: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.0578 - bpp: 0.8501 - mse: 2.9486e-04\n",
      "Epoch 476/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8092 - bpp: 0.8283 - mse: 2.3948e-04\n",
      "Epoch 476: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.8092 - bpp: 0.8283 - mse: 2.3948e-04\n",
      "Epoch 477/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2029 - bpp: 0.8668 - mse: 3.2619e-04\n",
      "Epoch 477: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.2029 - bpp: 0.8668 - mse: 3.2619e-04\n",
      "Epoch 478/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2480 - bpp: 0.8774 - mse: 3.3461e-04\n",
      "Epoch 478: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 250ms/step - loss: 2.2480 - bpp: 0.8774 - mse: 3.3461e-04\n",
      "Epoch 479/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6591 - bpp: 0.7992 - mse: 2.0995e-04\n",
      "Epoch 479: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.6591 - bpp: 0.7992 - mse: 2.0995e-04\n",
      "Epoch 480/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2376 - bpp: 0.8528 - mse: 3.3809e-04\n",
      "Epoch 480: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.2376 - bpp: 0.8528 - mse: 3.3809e-04\n",
      "Epoch 481/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8786 - bpp: 0.8239 - mse: 2.5748e-04\n",
      "Epoch 481: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8786 - bpp: 0.8239 - mse: 2.5748e-04\n",
      "Epoch 482/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9250 - bpp: 0.8140 - mse: 2.7125e-04\n",
      "Epoch 482: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 1.9250 - bpp: 0.8140 - mse: 2.7125e-04\n",
      "Epoch 483/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7677 - bpp: 0.8094 - mse: 2.3398e-04\n",
      "Epoch 483: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 250ms/step - loss: 1.7677 - bpp: 0.8094 - mse: 2.3398e-04\n",
      "Epoch 484/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0779 - bpp: 0.8648 - mse: 2.9618e-04\n",
      "Epoch 484: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.0779 - bpp: 0.8648 - mse: 2.9618e-04\n",
      "Epoch 485/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8848 - bpp: 0.8174 - mse: 2.6058e-04\n",
      "Epoch 485: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.8848 - bpp: 0.8174 - mse: 2.6058e-04\n",
      "Epoch 486/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0484 - bpp: 0.8664 - mse: 2.8858e-04\n",
      "Epoch 486: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.0484 - bpp: 0.8664 - mse: 2.8858e-04\n",
      "Epoch 487/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0382 - bpp: 0.8522 - mse: 2.8954e-04\n",
      "Epoch 487: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.0382 - bpp: 0.8522 - mse: 2.8954e-04\n",
      "Epoch 488/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8495 - bpp: 0.8163 - mse: 2.5224e-04\n",
      "Epoch 488: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.8495 - bpp: 0.8163 - mse: 2.5224e-04\n",
      "Epoch 489/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8201 - bpp: 0.8335 - mse: 2.4085e-04\n",
      "Epoch 489: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.8201 - bpp: 0.8335 - mse: 2.4085e-04\n",
      "Epoch 490/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7693 - bpp: 0.8238 - mse: 2.3083e-04\n",
      "Epoch 490: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.7693 - bpp: 0.8238 - mse: 2.3083e-04\n",
      "Epoch 491/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6272 - bpp: 0.8001 - mse: 2.0194e-04\n",
      "Epoch 491: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.6272 - bpp: 0.8001 - mse: 2.0194e-04\n",
      "Epoch 492/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7538 - bpp: 0.8242 - mse: 2.2695e-04\n",
      "Epoch 492: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 1.7538 - bpp: 0.8242 - mse: 2.2695e-04\n",
      "Epoch 493/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0540 - bpp: 0.8532 - mse: 2.9316e-04\n",
      "Epoch 493: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.0540 - bpp: 0.8532 - mse: 2.9316e-04\n",
      "Epoch 494/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6887 - bpp: 0.7955 - mse: 2.1806e-04\n",
      "Epoch 494: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.6887 - bpp: 0.7955 - mse: 2.1806e-04\n",
      "Epoch 495/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7268 - bpp: 0.8037 - mse: 2.2538e-04\n",
      "Epoch 495: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.7268 - bpp: 0.8037 - mse: 2.2538e-04\n",
      "Epoch 496/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9155 - bpp: 0.8290 - mse: 2.6525e-04\n",
      "Epoch 496: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.9155 - bpp: 0.8290 - mse: 2.6525e-04\n",
      "Epoch 497/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7855 - bpp: 0.8255 - mse: 2.3440e-04\n",
      "Epoch 497: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.7855 - bpp: 0.8255 - mse: 2.3440e-04\n",
      "Epoch 498/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7514 - bpp: 0.8284 - mse: 2.2535e-04\n",
      "Epoch 498: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.7514 - bpp: 0.8284 - mse: 2.2535e-04\n",
      "Epoch 499/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7549 - bpp: 0.8251 - mse: 2.2701e-04\n",
      "Epoch 499: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.7549 - bpp: 0.8251 - mse: 2.2701e-04\n",
      "Epoch 500/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7352 - bpp: 0.8179 - mse: 2.2394e-04\n",
      "Epoch 500: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.7352 - bpp: 0.8179 - mse: 2.2394e-04\n",
      "Epoch 501/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8571 - bpp: 0.8405 - mse: 2.4821e-04\n",
      "Epoch 501: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8571 - bpp: 0.8405 - mse: 2.4821e-04\n",
      "Epoch 502/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6511 - bpp: 0.8052 - mse: 2.0652e-04\n",
      "Epoch 502: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.6511 - bpp: 0.8052 - mse: 2.0652e-04\n",
      "Epoch 503/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7929 - bpp: 0.8262 - mse: 2.3600e-04\n",
      "Epoch 503: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.7929 - bpp: 0.8262 - mse: 2.3600e-04\n",
      "Epoch 504/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7781 - bpp: 0.8187 - mse: 2.3423e-04\n",
      "Epoch 504: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.7781 - bpp: 0.8187 - mse: 2.3423e-04\n",
      "Epoch 505/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0326 - bpp: 0.8453 - mse: 2.8988e-04\n",
      "Epoch 505: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.0326 - bpp: 0.8453 - mse: 2.8988e-04\n",
      "Epoch 506/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8714 - bpp: 0.8303 - mse: 2.5417e-04\n",
      "Epoch 506: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.8714 - bpp: 0.8303 - mse: 2.5417e-04\n",
      "Epoch 507/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3324 - bpp: 0.8391 - mse: 3.6457e-04\n",
      "Epoch 507: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3324 - bpp: 0.8391 - mse: 3.6457e-04\n",
      "Epoch 508/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9429 - bpp: 0.8423 - mse: 2.6872e-04\n",
      "Epoch 508: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9429 - bpp: 0.8423 - mse: 2.6872e-04\n",
      "Epoch 509/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6225 - bpp: 0.7826 - mse: 2.0503e-04\n",
      "Epoch 509: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.6225 - bpp: 0.7826 - mse: 2.0503e-04\n",
      "Epoch 510/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6623 - bpp: 0.8020 - mse: 2.1002e-04\n",
      "Epoch 510: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.6623 - bpp: 0.8020 - mse: 2.1002e-04\n",
      "Epoch 511/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7566 - bpp: 0.8195 - mse: 2.2880e-04\n",
      "Epoch 511: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7566 - bpp: 0.8195 - mse: 2.2880e-04\n",
      "Epoch 512/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8417 - bpp: 0.8206 - mse: 2.4930e-04\n",
      "Epoch 512: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.8417 - bpp: 0.8206 - mse: 2.4930e-04\n",
      "Epoch 513/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8166 - bpp: 0.8146 - mse: 2.4465e-04\n",
      "Epoch 513: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.8166 - bpp: 0.8146 - mse: 2.4465e-04\n",
      "Epoch 514/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7092 - bpp: 0.8026 - mse: 2.2135e-04\n",
      "Epoch 514: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.7092 - bpp: 0.8026 - mse: 2.2135e-04\n",
      "Epoch 515/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0317 - bpp: 0.8460 - mse: 2.8948e-04\n",
      "Epoch 515: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.0317 - bpp: 0.8460 - mse: 2.8948e-04\n",
      "Epoch 516/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7957 - bpp: 0.8140 - mse: 2.3968e-04\n",
      "Epoch 516: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.7957 - bpp: 0.8140 - mse: 2.3968e-04\n",
      "Epoch 517/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8867 - bpp: 0.8413 - mse: 2.5523e-04\n",
      "Epoch 517: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.8867 - bpp: 0.8413 - mse: 2.5523e-04\n",
      "Epoch 518/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6228 - bpp: 0.7962 - mse: 2.0182e-04\n",
      "Epoch 518: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.6228 - bpp: 0.7962 - mse: 2.0182e-04\n",
      "Epoch 519/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6338 - bpp: 0.7977 - mse: 2.0413e-04\n",
      "Epoch 519: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.6338 - bpp: 0.7977 - mse: 2.0413e-04\n",
      "Epoch 520/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8598 - bpp: 0.8180 - mse: 2.5436e-04\n",
      "Epoch 520: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.8598 - bpp: 0.8180 - mse: 2.5436e-04\n",
      "Epoch 521/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0955 - bpp: 0.8368 - mse: 3.0731e-04\n",
      "Epoch 521: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0955 - bpp: 0.8368 - mse: 3.0731e-04\n",
      "Epoch 522/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0217 - bpp: 0.8501 - mse: 2.8603e-04\n",
      "Epoch 522: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 2.0217 - bpp: 0.8501 - mse: 2.8603e-04\n",
      "Epoch 523/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8887 - bpp: 0.8298 - mse: 2.5853e-04\n",
      "Epoch 523: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8887 - bpp: 0.8298 - mse: 2.5853e-04\n",
      "Epoch 524/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7370 - bpp: 0.8122 - mse: 2.2578e-04\n",
      "Epoch 524: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.7370 - bpp: 0.8122 - mse: 2.2578e-04\n",
      "Epoch 525/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9558 - bpp: 0.8455 - mse: 2.7108e-04\n",
      "Epoch 525: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.9558 - bpp: 0.8455 - mse: 2.7108e-04\n",
      "Epoch 526/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6962 - bpp: 0.7910 - mse: 2.2100e-04\n",
      "Epoch 526: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.6962 - bpp: 0.7910 - mse: 2.2100e-04\n",
      "Epoch 527/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7611 - bpp: 0.8182 - mse: 2.3019e-04\n",
      "Epoch 527: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.7611 - bpp: 0.8182 - mse: 2.3019e-04\n",
      "Epoch 528/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8025 - bpp: 0.8150 - mse: 2.4108e-04\n",
      "Epoch 528: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8025 - bpp: 0.8150 - mse: 2.4108e-04\n",
      "Epoch 529/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7080 - bpp: 0.8191 - mse: 2.1701e-04\n",
      "Epoch 529: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.7080 - bpp: 0.8191 - mse: 2.1701e-04\n",
      "Epoch 530/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9809 - bpp: 0.8479 - mse: 2.7659e-04\n",
      "Epoch 530: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.9809 - bpp: 0.8479 - mse: 2.7659e-04\n",
      "Epoch 531/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0982 - bpp: 0.8675 - mse: 3.0046e-04\n",
      "Epoch 531: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.0982 - bpp: 0.8675 - mse: 3.0046e-04\n",
      "Epoch 532/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7966 - bpp: 0.7970 - mse: 2.4406e-04\n",
      "Epoch 532: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.7966 - bpp: 0.7970 - mse: 2.4406e-04\n",
      "Epoch 533/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6756 - bpp: 0.7922 - mse: 2.1568e-04\n",
      "Epoch 533: loss did not improve from 1.60379\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.6756 - bpp: 0.7922 - mse: 2.1568e-04\n",
      "Epoch 534/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5150 - bpp: 0.7620 - mse: 1.8383e-04\n",
      "Epoch 534: loss improved from 1.60379 to 1.51498, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5150 - bpp: 0.7620 - mse: 1.8383e-04\n",
      "Epoch 535/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7041 - bpp: 0.8140 - mse: 2.1731e-04\n",
      "Epoch 535: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 1.7041 - bpp: 0.8140 - mse: 2.1731e-04\n",
      "Epoch 536/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8581 - bpp: 0.8442 - mse: 2.4754e-04\n",
      "Epoch 536: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.8581 - bpp: 0.8442 - mse: 2.4754e-04\n",
      "Epoch 537/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6800 - bpp: 0.8104 - mse: 2.1229e-04\n",
      "Epoch 537: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.6800 - bpp: 0.8104 - mse: 2.1229e-04\n",
      "Epoch 538/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9730 - bpp: 0.8516 - mse: 2.7379e-04\n",
      "Epoch 538: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 1.9730 - bpp: 0.8516 - mse: 2.7379e-04\n",
      "Epoch 539/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8249 - bpp: 0.8337 - mse: 2.4199e-04\n",
      "Epoch 539: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8249 - bpp: 0.8337 - mse: 2.4199e-04\n",
      "Epoch 540/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7804 - bpp: 0.8224 - mse: 2.3390e-04\n",
      "Epoch 540: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.7804 - bpp: 0.8224 - mse: 2.3390e-04\n",
      "Epoch 541/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8095 - bpp: 0.8140 - mse: 2.4306e-04\n",
      "Epoch 541: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.8095 - bpp: 0.8140 - mse: 2.4306e-04\n",
      "Epoch 542/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8871 - bpp: 0.8534 - mse: 2.5236e-04\n",
      "Epoch 542: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8871 - bpp: 0.8534 - mse: 2.5236e-04\n",
      "Epoch 543/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0008 - bpp: 0.8470 - mse: 2.8171e-04\n",
      "Epoch 543: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.0008 - bpp: 0.8470 - mse: 2.8171e-04\n",
      "Epoch 544/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5312 - bpp: 0.7617 - mse: 1.8785e-04\n",
      "Epoch 544: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.5312 - bpp: 0.7617 - mse: 1.8785e-04\n",
      "Epoch 545/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8008 - bpp: 0.7965 - mse: 2.4519e-04\n",
      "Epoch 545: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8008 - bpp: 0.7965 - mse: 2.4519e-04\n",
      "Epoch 546/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7487 - bpp: 0.8076 - mse: 2.2976e-04\n",
      "Epoch 546: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.7487 - bpp: 0.8076 - mse: 2.2976e-04\n",
      "Epoch 547/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6742 - bpp: 0.7999 - mse: 2.1346e-04\n",
      "Epoch 547: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.6742 - bpp: 0.7999 - mse: 2.1346e-04\n",
      "Epoch 548/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0699 - bpp: 0.8631 - mse: 2.9461e-04\n",
      "Epoch 548: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0699 - bpp: 0.8631 - mse: 2.9461e-04\n",
      "Epoch 549/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9091 - bpp: 0.8233 - mse: 2.6510e-04\n",
      "Epoch 549: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.9091 - bpp: 0.8233 - mse: 2.6510e-04\n",
      "Epoch 550/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8647 - bpp: 0.8371 - mse: 2.5089e-04\n",
      "Epoch 550: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.8647 - bpp: 0.8371 - mse: 2.5089e-04\n",
      "Epoch 551/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6765 - bpp: 0.7955 - mse: 2.1510e-04\n",
      "Epoch 551: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.6765 - bpp: 0.7955 - mse: 2.1510e-04\n",
      "Epoch 552/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9957 - bpp: 0.8481 - mse: 2.8020e-04\n",
      "Epoch 552: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.9957 - bpp: 0.8481 - mse: 2.8020e-04\n",
      "Epoch 553/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7996 - bpp: 0.8154 - mse: 2.4029e-04\n",
      "Epoch 553: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.7996 - bpp: 0.8154 - mse: 2.4029e-04\n",
      "Epoch 554/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8724 - bpp: 0.8220 - mse: 2.5644e-04\n",
      "Epoch 554: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.8724 - bpp: 0.8220 - mse: 2.5644e-04\n",
      "Epoch 555/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7516 - bpp: 0.8157 - mse: 2.2849e-04\n",
      "Epoch 555: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.7516 - bpp: 0.8157 - mse: 2.2849e-04\n",
      "Epoch 556/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8361 - bpp: 0.8353 - mse: 2.4434e-04\n",
      "Epoch 556: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8361 - bpp: 0.8353 - mse: 2.4434e-04\n",
      "Epoch 557/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6986 - bpp: 0.8043 - mse: 2.1832e-04\n",
      "Epoch 557: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.6986 - bpp: 0.8043 - mse: 2.1832e-04\n",
      "Epoch 558/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7897 - bpp: 0.8240 - mse: 2.3576e-04\n",
      "Epoch 558: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.7897 - bpp: 0.8240 - mse: 2.3576e-04\n",
      "Epoch 559/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5966 - bpp: 0.7898 - mse: 1.9698e-04\n",
      "Epoch 559: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5966 - bpp: 0.7898 - mse: 1.9698e-04\n",
      "Epoch 560/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7268 - bpp: 0.8071 - mse: 2.2454e-04\n",
      "Epoch 560: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.7268 - bpp: 0.8071 - mse: 2.2454e-04\n",
      "Epoch 561/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8565 - bpp: 0.8487 - mse: 2.4605e-04\n",
      "Epoch 561: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.8565 - bpp: 0.8487 - mse: 2.4605e-04\n",
      "Epoch 562/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7003 - bpp: 0.8068 - mse: 2.1813e-04\n",
      "Epoch 562: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.7003 - bpp: 0.8068 - mse: 2.1813e-04\n",
      "Epoch 563/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6121 - bpp: 0.7792 - mse: 2.0334e-04\n",
      "Epoch 563: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.6121 - bpp: 0.7792 - mse: 2.0334e-04\n",
      "Epoch 564/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7361 - bpp: 0.8147 - mse: 2.2495e-04\n",
      "Epoch 564: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.7361 - bpp: 0.8147 - mse: 2.2495e-04\n",
      "Epoch 565/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8755 - bpp: 0.8360 - mse: 2.5381e-04\n",
      "Epoch 565: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.8755 - bpp: 0.8360 - mse: 2.5381e-04\n",
      "Epoch 566/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8679 - bpp: 0.8406 - mse: 2.5081e-04\n",
      "Epoch 566: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.8679 - bpp: 0.8406 - mse: 2.5081e-04\n",
      "Epoch 567/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7065 - bpp: 0.8041 - mse: 2.2034e-04\n",
      "Epoch 567: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.7065 - bpp: 0.8041 - mse: 2.2034e-04\n",
      "Epoch 568/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8428 - bpp: 0.8471 - mse: 2.4311e-04\n",
      "Epoch 568: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8428 - bpp: 0.8471 - mse: 2.4311e-04\n",
      "Epoch 569/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7111 - bpp: 0.7938 - mse: 2.2395e-04\n",
      "Epoch 569: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.7111 - bpp: 0.7938 - mse: 2.2395e-04\n",
      "Epoch 570/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9425 - bpp: 0.8343 - mse: 2.7056e-04\n",
      "Epoch 570: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.9425 - bpp: 0.8343 - mse: 2.7056e-04\n",
      "Epoch 571/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7183 - bpp: 0.8038 - mse: 2.2327e-04\n",
      "Epoch 571: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.7183 - bpp: 0.8038 - mse: 2.2327e-04\n",
      "Epoch 572/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9900 - bpp: 0.8594 - mse: 2.7601e-04\n",
      "Epoch 572: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.9900 - bpp: 0.8594 - mse: 2.7601e-04\n",
      "Epoch 573/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9374 - bpp: 0.8414 - mse: 2.6758e-04\n",
      "Epoch 573: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.9374 - bpp: 0.8414 - mse: 2.6758e-04\n",
      "Epoch 574/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5413 - bpp: 0.7732 - mse: 1.8750e-04\n",
      "Epoch 574: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.5413 - bpp: 0.7732 - mse: 1.8750e-04\n",
      "Epoch 575/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7835 - bpp: 0.8203 - mse: 2.3517e-04\n",
      "Epoch 575: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7835 - bpp: 0.8203 - mse: 2.3517e-04\n",
      "Epoch 576/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7932 - bpp: 0.8221 - mse: 2.3709e-04\n",
      "Epoch 576: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.7932 - bpp: 0.8221 - mse: 2.3709e-04\n",
      "Epoch 577/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6409 - bpp: 0.7786 - mse: 2.1053e-04\n",
      "Epoch 577: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6409 - bpp: 0.7786 - mse: 2.1053e-04\n",
      "Epoch 578/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8791 - bpp: 0.8340 - mse: 2.5516e-04\n",
      "Epoch 578: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8791 - bpp: 0.8340 - mse: 2.5516e-04\n",
      "Epoch 579/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8436 - bpp: 0.8340 - mse: 2.4649e-04\n",
      "Epoch 579: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8436 - bpp: 0.8340 - mse: 2.4649e-04\n",
      "Epoch 580/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6499 - bpp: 0.8108 - mse: 2.0485e-04\n",
      "Epoch 580: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.6499 - bpp: 0.8108 - mse: 2.0485e-04\n",
      "Epoch 581/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8036 - bpp: 0.8180 - mse: 2.4061e-04\n",
      "Epoch 581: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8036 - bpp: 0.8180 - mse: 2.4061e-04\n",
      "Epoch 582/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7344 - bpp: 0.8063 - mse: 2.2659e-04\n",
      "Epoch 582: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.7344 - bpp: 0.8063 - mse: 2.2659e-04\n",
      "Epoch 583/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6931 - bpp: 0.8024 - mse: 2.1746e-04\n",
      "Epoch 583: loss did not improve from 1.51498\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.6931 - bpp: 0.8024 - mse: 2.1746e-04\n",
      "Epoch 584/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5019 - bpp: 0.7834 - mse: 1.7540e-04\n",
      "Epoch 584: loss improved from 1.51498 to 1.50187, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 1.5019 - bpp: 0.7834 - mse: 1.7540e-04\n",
      "Epoch 585/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7842 - bpp: 0.8332 - mse: 2.3217e-04\n",
      "Epoch 585: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 30s 293ms/step - loss: 1.7842 - bpp: 0.8332 - mse: 2.3217e-04\n",
      "Epoch 586/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6852 - bpp: 0.8102 - mse: 2.1362e-04\n",
      "Epoch 586: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.6852 - bpp: 0.8102 - mse: 2.1362e-04\n",
      "Epoch 587/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7868 - bpp: 0.8219 - mse: 2.3556e-04\n",
      "Epoch 587: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.7868 - bpp: 0.8219 - mse: 2.3556e-04\n",
      "Epoch 588/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7958 - bpp: 0.8228 - mse: 2.3757e-04\n",
      "Epoch 588: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.7958 - bpp: 0.8228 - mse: 2.3757e-04\n",
      "Epoch 589/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6794 - bpp: 0.7923 - mse: 2.1660e-04\n",
      "Epoch 589: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.6794 - bpp: 0.7923 - mse: 2.1660e-04\n",
      "Epoch 590/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7799 - bpp: 0.8022 - mse: 2.3870e-04\n",
      "Epoch 590: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.7799 - bpp: 0.8022 - mse: 2.3870e-04\n",
      "Epoch 591/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6503 - bpp: 0.7926 - mse: 2.0941e-04\n",
      "Epoch 591: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.6503 - bpp: 0.7926 - mse: 2.0941e-04\n",
      "Epoch 592/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7005 - bpp: 0.8145 - mse: 2.1632e-04\n",
      "Epoch 592: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7005 - bpp: 0.8145 - mse: 2.1632e-04\n",
      "Epoch 593/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6180 - bpp: 0.7785 - mse: 2.0496e-04\n",
      "Epoch 593: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.6180 - bpp: 0.7785 - mse: 2.0496e-04\n",
      "Epoch 594/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9341 - bpp: 0.8365 - mse: 2.6797e-04\n",
      "Epoch 594: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.9341 - bpp: 0.8365 - mse: 2.6797e-04\n",
      "Epoch 595/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8900 - bpp: 0.8279 - mse: 2.5932e-04\n",
      "Epoch 595: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8900 - bpp: 0.8279 - mse: 2.5932e-04\n",
      "Epoch 596/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6404 - bpp: 0.7924 - mse: 2.0705e-04\n",
      "Epoch 596: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.6404 - bpp: 0.7924 - mse: 2.0705e-04\n",
      "Epoch 597/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8317 - bpp: 0.8219 - mse: 2.4655e-04\n",
      "Epoch 597: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8317 - bpp: 0.8219 - mse: 2.4655e-04\n",
      "Epoch 598/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8465 - bpp: 0.8239 - mse: 2.4966e-04\n",
      "Epoch 598: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8465 - bpp: 0.8239 - mse: 2.4966e-04\n",
      "Epoch 599/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7946 - bpp: 0.8175 - mse: 2.3853e-04\n",
      "Epoch 599: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 1.7946 - bpp: 0.8175 - mse: 2.3853e-04\n",
      "Epoch 600/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6339 - bpp: 0.7978 - mse: 2.0413e-04\n",
      "Epoch 600: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.6339 - bpp: 0.7978 - mse: 2.0413e-04\n",
      "Epoch 601/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7207 - bpp: 0.8169 - mse: 2.2066e-04\n",
      "Epoch 601: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.7207 - bpp: 0.8169 - mse: 2.2066e-04\n",
      "Epoch 602/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9296 - bpp: 0.8380 - mse: 2.6650e-04\n",
      "Epoch 602: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.9296 - bpp: 0.8380 - mse: 2.6650e-04\n",
      "Epoch 603/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9156 - bpp: 0.8337 - mse: 2.6413e-04\n",
      "Epoch 603: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.9156 - bpp: 0.8337 - mse: 2.6413e-04\n",
      "Epoch 604/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5977 - bpp: 0.7902 - mse: 1.9714e-04\n",
      "Epoch 604: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5977 - bpp: 0.7902 - mse: 1.9714e-04\n",
      "Epoch 605/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8018 - bpp: 0.8131 - mse: 2.4138e-04\n",
      "Epoch 605: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8018 - bpp: 0.8131 - mse: 2.4138e-04\n",
      "Epoch 606/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7734 - bpp: 0.7987 - mse: 2.3798e-04\n",
      "Epoch 606: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.7734 - bpp: 0.7987 - mse: 2.3798e-04\n",
      "Epoch 607/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7814 - bpp: 0.8148 - mse: 2.3600e-04\n",
      "Epoch 607: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.7814 - bpp: 0.8148 - mse: 2.3600e-04\n",
      "Epoch 608/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7032 - bpp: 0.7993 - mse: 2.2066e-04\n",
      "Epoch 608: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 1.7032 - bpp: 0.7993 - mse: 2.2066e-04\n",
      "Epoch 609/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7483 - bpp: 0.8135 - mse: 2.2821e-04\n",
      "Epoch 609: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.7483 - bpp: 0.8135 - mse: 2.2821e-04\n",
      "Epoch 610/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9685 - bpp: 0.8546 - mse: 2.7194e-04\n",
      "Epoch 610: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.9685 - bpp: 0.8546 - mse: 2.7194e-04\n",
      "Epoch 611/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8667 - bpp: 0.8249 - mse: 2.5435e-04\n",
      "Epoch 611: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.8667 - bpp: 0.8249 - mse: 2.5435e-04\n",
      "Epoch 612/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5983 - bpp: 0.7659 - mse: 2.0323e-04\n",
      "Epoch 612: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.5983 - bpp: 0.7659 - mse: 2.0323e-04\n",
      "Epoch 613/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5789 - bpp: 0.7602 - mse: 1.9988e-04\n",
      "Epoch 613: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 1.5789 - bpp: 0.7602 - mse: 1.9988e-04\n",
      "Epoch 614/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8266 - bpp: 0.8061 - mse: 2.4916e-04\n",
      "Epoch 614: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.8266 - bpp: 0.8061 - mse: 2.4916e-04\n",
      "Epoch 615/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7209 - bpp: 0.7954 - mse: 2.2596e-04\n",
      "Epoch 615: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.7209 - bpp: 0.7954 - mse: 2.2596e-04\n",
      "Epoch 616/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5135 - bpp: 0.7709 - mse: 1.8131e-04\n",
      "Epoch 616: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.5135 - bpp: 0.7709 - mse: 1.8131e-04\n",
      "Epoch 617/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9064 - bpp: 0.8128 - mse: 2.6700e-04\n",
      "Epoch 617: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.9064 - bpp: 0.8128 - mse: 2.6700e-04\n",
      "Epoch 618/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7547 - bpp: 0.8262 - mse: 2.2668e-04\n",
      "Epoch 618: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.7547 - bpp: 0.8262 - mse: 2.2668e-04\n",
      "Epoch 619/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5932 - bpp: 0.7900 - mse: 1.9610e-04\n",
      "Epoch 619: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.5932 - bpp: 0.7900 - mse: 1.9610e-04\n",
      "Epoch 620/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7164 - bpp: 0.7911 - mse: 2.2590e-04\n",
      "Epoch 620: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.7164 - bpp: 0.7911 - mse: 2.2590e-04\n",
      "Epoch 621/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7846 - bpp: 0.8078 - mse: 2.3848e-04\n",
      "Epoch 621: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.7846 - bpp: 0.8078 - mse: 2.3848e-04\n",
      "Epoch 622/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5927 - bpp: 0.7808 - mse: 1.9823e-04\n",
      "Epoch 622: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.5927 - bpp: 0.7808 - mse: 1.9823e-04\n",
      "Epoch 623/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6635 - bpp: 0.7952 - mse: 2.1199e-04\n",
      "Epoch 623: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.6635 - bpp: 0.7952 - mse: 2.1199e-04\n",
      "Epoch 624/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8378 - bpp: 0.8079 - mse: 2.5144e-04\n",
      "Epoch 624: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.8378 - bpp: 0.8079 - mse: 2.5144e-04\n",
      "Epoch 625/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8803 - bpp: 0.8326 - mse: 2.5579e-04\n",
      "Epoch 625: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8803 - bpp: 0.8326 - mse: 2.5579e-04\n",
      "Epoch 626/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9977 - bpp: 0.8583 - mse: 2.7818e-04\n",
      "Epoch 626: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.9977 - bpp: 0.8583 - mse: 2.7818e-04\n",
      "Epoch 627/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5963 - bpp: 0.7806 - mse: 1.9915e-04\n",
      "Epoch 627: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.5963 - bpp: 0.7806 - mse: 1.9915e-04\n",
      "Epoch 628/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6352 - bpp: 0.8083 - mse: 2.0187e-04\n",
      "Epoch 628: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.6352 - bpp: 0.8083 - mse: 2.0187e-04\n",
      "Epoch 629/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8473 - bpp: 0.8190 - mse: 2.5105e-04\n",
      "Epoch 629: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8473 - bpp: 0.8190 - mse: 2.5105e-04\n",
      "Epoch 630/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8576 - bpp: 0.8099 - mse: 2.5577e-04\n",
      "Epoch 630: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.8576 - bpp: 0.8099 - mse: 2.5577e-04\n",
      "Epoch 631/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8446 - bpp: 0.8154 - mse: 2.5128e-04\n",
      "Epoch 631: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 1.8446 - bpp: 0.8154 - mse: 2.5128e-04\n",
      "Epoch 632/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7879 - bpp: 0.7910 - mse: 2.4339e-04\n",
      "Epoch 632: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.7879 - bpp: 0.7910 - mse: 2.4339e-04\n",
      "Epoch 633/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7904 - bpp: 0.8219 - mse: 2.3644e-04\n",
      "Epoch 633: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7904 - bpp: 0.8219 - mse: 2.3644e-04\n",
      "Epoch 634/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7457 - bpp: 0.8151 - mse: 2.2718e-04\n",
      "Epoch 634: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.7457 - bpp: 0.8151 - mse: 2.2718e-04\n",
      "Epoch 635/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8271 - bpp: 0.8164 - mse: 2.4675e-04\n",
      "Epoch 635: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.8271 - bpp: 0.8164 - mse: 2.4675e-04\n",
      "Epoch 636/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8046 - bpp: 0.8198 - mse: 2.4042e-04\n",
      "Epoch 636: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8046 - bpp: 0.8198 - mse: 2.4042e-04\n",
      "Epoch 637/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5738 - bpp: 0.7858 - mse: 1.9237e-04\n",
      "Epoch 637: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.5738 - bpp: 0.7858 - mse: 1.9237e-04\n",
      "Epoch 638/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6712 - bpp: 0.7851 - mse: 2.1633e-04\n",
      "Epoch 638: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 1.6712 - bpp: 0.7851 - mse: 2.1633e-04\n",
      "Epoch 639/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7358 - bpp: 0.8092 - mse: 2.2622e-04\n",
      "Epoch 639: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7358 - bpp: 0.8092 - mse: 2.2622e-04\n",
      "Epoch 640/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7692 - bpp: 0.8314 - mse: 2.2895e-04\n",
      "Epoch 640: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.7692 - bpp: 0.8314 - mse: 2.2895e-04\n",
      "Epoch 641/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6025 - bpp: 0.7738 - mse: 2.0232e-04\n",
      "Epoch 641: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.6025 - bpp: 0.7738 - mse: 2.0232e-04\n",
      "Epoch 642/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8903 - bpp: 0.8433 - mse: 2.5562e-04\n",
      "Epoch 642: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8903 - bpp: 0.8433 - mse: 2.5562e-04\n",
      "Epoch 643/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7240 - bpp: 0.8015 - mse: 2.2524e-04\n",
      "Epoch 643: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.7240 - bpp: 0.8015 - mse: 2.2524e-04\n",
      "Epoch 644/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6811 - bpp: 0.8146 - mse: 2.1155e-04\n",
      "Epoch 644: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.6811 - bpp: 0.8146 - mse: 2.1155e-04\n",
      "Epoch 645/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7198 - bpp: 0.8004 - mse: 2.2446e-04\n",
      "Epoch 645: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.7198 - bpp: 0.8004 - mse: 2.2446e-04\n",
      "Epoch 646/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6351 - bpp: 0.7992 - mse: 2.0408e-04\n",
      "Epoch 646: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.6351 - bpp: 0.7992 - mse: 2.0408e-04\n",
      "Epoch 647/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7805 - bpp: 0.8218 - mse: 2.3406e-04\n",
      "Epoch 647: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.7805 - bpp: 0.8218 - mse: 2.3406e-04\n",
      "Epoch 648/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5925 - bpp: 0.7908 - mse: 1.9573e-04\n",
      "Epoch 648: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.5925 - bpp: 0.7908 - mse: 1.9573e-04\n",
      "Epoch 649/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5850 - bpp: 0.7738 - mse: 1.9805e-04\n",
      "Epoch 649: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.5850 - bpp: 0.7738 - mse: 1.9805e-04\n",
      "Epoch 650/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6604 - bpp: 0.8098 - mse: 2.0766e-04\n",
      "Epoch 650: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.6604 - bpp: 0.8098 - mse: 2.0766e-04\n",
      "Epoch 651/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8377 - bpp: 0.8230 - mse: 2.4772e-04\n",
      "Epoch 651: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.8377 - bpp: 0.8230 - mse: 2.4772e-04\n",
      "Epoch 652/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8464 - bpp: 0.8087 - mse: 2.5334e-04\n",
      "Epoch 652: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.8464 - bpp: 0.8087 - mse: 2.5334e-04\n",
      "Epoch 653/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7322 - bpp: 0.8074 - mse: 2.2578e-04\n",
      "Epoch 653: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.7322 - bpp: 0.8074 - mse: 2.2578e-04\n",
      "Epoch 654/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6925 - bpp: 0.8077 - mse: 2.1602e-04\n",
      "Epoch 654: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 1.6925 - bpp: 0.8077 - mse: 2.1602e-04\n",
      "Epoch 655/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6411 - bpp: 0.7846 - mse: 2.0911e-04\n",
      "Epoch 655: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.6411 - bpp: 0.7846 - mse: 2.0911e-04\n",
      "Epoch 656/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6808 - bpp: 0.8119 - mse: 2.1214e-04\n",
      "Epoch 656: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6808 - bpp: 0.8119 - mse: 2.1214e-04\n",
      "Epoch 657/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6813 - bpp: 0.8054 - mse: 2.1385e-04\n",
      "Epoch 657: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.6813 - bpp: 0.8054 - mse: 2.1385e-04\n",
      "Epoch 658/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6370 - bpp: 0.7848 - mse: 2.0805e-04\n",
      "Epoch 658: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6370 - bpp: 0.7848 - mse: 2.0805e-04\n",
      "Epoch 659/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5365 - bpp: 0.7703 - mse: 1.8705e-04\n",
      "Epoch 659: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.5365 - bpp: 0.7703 - mse: 1.8705e-04\n",
      "Epoch 660/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6575 - bpp: 0.7923 - mse: 2.1124e-04\n",
      "Epoch 660: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.6575 - bpp: 0.7923 - mse: 2.1124e-04\n",
      "Epoch 661/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6862 - bpp: 0.7979 - mse: 2.1688e-04\n",
      "Epoch 661: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.6862 - bpp: 0.7979 - mse: 2.1688e-04\n",
      "Epoch 662/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6280 - bpp: 0.7893 - mse: 2.0477e-04\n",
      "Epoch 662: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.6280 - bpp: 0.7893 - mse: 2.0477e-04\n",
      "Epoch 663/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8106 - bpp: 0.8150 - mse: 2.4307e-04\n",
      "Epoch 663: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.8106 - bpp: 0.8150 - mse: 2.4307e-04\n",
      "Epoch 664/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6796 - bpp: 0.8133 - mse: 2.1150e-04\n",
      "Epoch 664: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.6796 - bpp: 0.8133 - mse: 2.1150e-04\n",
      "Epoch 665/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7605 - bpp: 0.8026 - mse: 2.3387e-04\n",
      "Epoch 665: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.7605 - bpp: 0.8026 - mse: 2.3387e-04\n",
      "Epoch 666/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6599 - bpp: 0.7971 - mse: 2.1064e-04\n",
      "Epoch 666: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.6599 - bpp: 0.7971 - mse: 2.1064e-04\n",
      "Epoch 667/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7832 - bpp: 0.8090 - mse: 2.3786e-04\n",
      "Epoch 667: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.7832 - bpp: 0.8090 - mse: 2.3786e-04\n",
      "Epoch 668/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6719 - bpp: 0.7907 - mse: 2.1513e-04\n",
      "Epoch 668: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.6719 - bpp: 0.7907 - mse: 2.1513e-04\n",
      "Epoch 669/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5842 - bpp: 0.7767 - mse: 1.9715e-04\n",
      "Epoch 669: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5842 - bpp: 0.7767 - mse: 1.9715e-04\n",
      "Epoch 670/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8017 - bpp: 0.8101 - mse: 2.4208e-04\n",
      "Epoch 670: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.8017 - bpp: 0.8101 - mse: 2.4208e-04\n",
      "Epoch 671/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6986 - bpp: 0.7976 - mse: 2.1997e-04\n",
      "Epoch 671: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6986 - bpp: 0.7976 - mse: 2.1997e-04\n",
      "Epoch 672/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8623 - bpp: 0.8336 - mse: 2.5115e-04\n",
      "Epoch 672: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.8623 - bpp: 0.8336 - mse: 2.5115e-04\n",
      "Epoch 673/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6750 - bpp: 0.7817 - mse: 2.1810e-04\n",
      "Epoch 673: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 1.6750 - bpp: 0.7817 - mse: 2.1810e-04\n",
      "Epoch 674/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8449 - bpp: 0.8364 - mse: 2.4621e-04\n",
      "Epoch 674: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.8449 - bpp: 0.8364 - mse: 2.4621e-04\n",
      "Epoch 675/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6578 - bpp: 0.7958 - mse: 2.1044e-04\n",
      "Epoch 675: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.6578 - bpp: 0.7958 - mse: 2.1044e-04\n",
      "Epoch 676/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7835 - bpp: 0.8264 - mse: 2.3365e-04\n",
      "Epoch 676: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.7835 - bpp: 0.8264 - mse: 2.3365e-04\n",
      "Epoch 677/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8771 - bpp: 0.8040 - mse: 2.6197e-04\n",
      "Epoch 677: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8771 - bpp: 0.8040 - mse: 2.6197e-04\n",
      "Epoch 678/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8403 - bpp: 0.8340 - mse: 2.4566e-04\n",
      "Epoch 678: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.8403 - bpp: 0.8340 - mse: 2.4566e-04\n",
      "Epoch 679/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8675 - bpp: 0.8422 - mse: 2.5031e-04\n",
      "Epoch 679: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.8675 - bpp: 0.8422 - mse: 2.5031e-04\n",
      "Epoch 680/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7559 - bpp: 0.8199 - mse: 2.2850e-04\n",
      "Epoch 680: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.7559 - bpp: 0.8199 - mse: 2.2850e-04\n",
      "Epoch 681/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0045 - bpp: 0.8079 - mse: 2.9213e-04\n",
      "Epoch 681: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 2.0045 - bpp: 0.8079 - mse: 2.9213e-04\n",
      "Epoch 682/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8972 - bpp: 0.8187 - mse: 2.6331e-04\n",
      "Epoch 682: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.8972 - bpp: 0.8187 - mse: 2.6331e-04\n",
      "Epoch 683/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6775 - bpp: 0.8083 - mse: 2.1221e-04\n",
      "Epoch 683: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6775 - bpp: 0.8083 - mse: 2.1221e-04\n",
      "Epoch 684/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7850 - bpp: 0.8219 - mse: 2.3515e-04\n",
      "Epoch 684: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.7850 - bpp: 0.8219 - mse: 2.3515e-04\n",
      "Epoch 685/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9650 - bpp: 0.8566 - mse: 2.7060e-04\n",
      "Epoch 685: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.9650 - bpp: 0.8566 - mse: 2.7060e-04\n",
      "Epoch 686/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6510 - bpp: 0.7859 - mse: 2.1119e-04\n",
      "Epoch 686: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.6510 - bpp: 0.7859 - mse: 2.1119e-04\n",
      "Epoch 687/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6107 - bpp: 0.7885 - mse: 2.0074e-04\n",
      "Epoch 687: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.6107 - bpp: 0.7885 - mse: 2.0074e-04\n",
      "Epoch 688/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5484 - bpp: 0.7748 - mse: 1.8887e-04\n",
      "Epoch 688: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5484 - bpp: 0.7748 - mse: 1.8887e-04\n",
      "Epoch 689/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6365 - bpp: 0.8013 - mse: 2.0391e-04\n",
      "Epoch 689: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.6365 - bpp: 0.8013 - mse: 2.0391e-04\n",
      "Epoch 690/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5815 - bpp: 0.7751 - mse: 1.9690e-04\n",
      "Epoch 690: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5815 - bpp: 0.7751 - mse: 1.9690e-04\n",
      "Epoch 691/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7997 - bpp: 0.8164 - mse: 2.4005e-04\n",
      "Epoch 691: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.7997 - bpp: 0.8164 - mse: 2.4005e-04\n",
      "Epoch 692/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7247 - bpp: 0.8074 - mse: 2.2395e-04\n",
      "Epoch 692: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.7247 - bpp: 0.8074 - mse: 2.2395e-04\n",
      "Epoch 693/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6798 - bpp: 0.8056 - mse: 2.1342e-04\n",
      "Epoch 693: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.6798 - bpp: 0.8056 - mse: 2.1342e-04\n",
      "Epoch 694/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6526 - bpp: 0.7939 - mse: 2.0965e-04\n",
      "Epoch 694: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.6526 - bpp: 0.7939 - mse: 2.0965e-04\n",
      "Epoch 695/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6976 - bpp: 0.7973 - mse: 2.1981e-04\n",
      "Epoch 695: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.6976 - bpp: 0.7973 - mse: 2.1981e-04\n",
      "Epoch 696/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6939 - bpp: 0.7877 - mse: 2.2122e-04\n",
      "Epoch 696: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.6939 - bpp: 0.7877 - mse: 2.2122e-04\n",
      "Epoch 697/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7002 - bpp: 0.8033 - mse: 2.1896e-04\n",
      "Epoch 697: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.7002 - bpp: 0.8033 - mse: 2.1896e-04\n",
      "Epoch 698/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5711 - bpp: 0.7700 - mse: 1.9560e-04\n",
      "Epoch 698: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.5711 - bpp: 0.7700 - mse: 1.9560e-04\n",
      "Epoch 699/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8276 - bpp: 0.8383 - mse: 2.4152e-04\n",
      "Epoch 699: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8276 - bpp: 0.8383 - mse: 2.4152e-04\n",
      "Epoch 700/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7163 - bpp: 0.7766 - mse: 2.2941e-04\n",
      "Epoch 700: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 1.7163 - bpp: 0.7766 - mse: 2.2941e-04\n",
      "Epoch 701/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6036 - bpp: 0.7881 - mse: 1.9910e-04\n",
      "Epoch 701: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6036 - bpp: 0.7881 - mse: 1.9910e-04\n",
      "Epoch 702/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9101 - bpp: 0.8263 - mse: 2.6461e-04\n",
      "Epoch 702: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.9101 - bpp: 0.8263 - mse: 2.6461e-04\n",
      "Epoch 703/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7544 - bpp: 0.8127 - mse: 2.2992e-04\n",
      "Epoch 703: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.7544 - bpp: 0.8127 - mse: 2.2992e-04\n",
      "Epoch 704/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7328 - bpp: 0.8042 - mse: 2.2670e-04\n",
      "Epoch 704: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.7328 - bpp: 0.8042 - mse: 2.2670e-04\n",
      "Epoch 705/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6646 - bpp: 0.7903 - mse: 2.1346e-04\n",
      "Epoch 705: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.6646 - bpp: 0.7903 - mse: 2.1346e-04\n",
      "Epoch 706/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6231 - bpp: 0.8015 - mse: 2.0057e-04\n",
      "Epoch 706: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.6231 - bpp: 0.8015 - mse: 2.0057e-04\n",
      "Epoch 707/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8104 - bpp: 0.8069 - mse: 2.4500e-04\n",
      "Epoch 707: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.8104 - bpp: 0.8069 - mse: 2.4500e-04\n",
      "Epoch 708/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6306 - bpp: 0.8034 - mse: 2.0195e-04\n",
      "Epoch 708: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.6306 - bpp: 0.8034 - mse: 2.0195e-04\n",
      "Epoch 709/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6289 - bpp: 0.7837 - mse: 2.0636e-04\n",
      "Epoch 709: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 1.6289 - bpp: 0.7837 - mse: 2.0636e-04\n",
      "Epoch 710/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7537 - bpp: 0.8148 - mse: 2.2923e-04\n",
      "Epoch 710: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7537 - bpp: 0.8148 - mse: 2.2923e-04\n",
      "Epoch 711/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7631 - bpp: 0.7903 - mse: 2.3751e-04\n",
      "Epoch 711: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7631 - bpp: 0.7903 - mse: 2.3751e-04\n",
      "Epoch 712/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6076 - bpp: 0.7903 - mse: 1.9955e-04\n",
      "Epoch 712: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.6076 - bpp: 0.7903 - mse: 1.9955e-04\n",
      "Epoch 713/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8359 - bpp: 0.8281 - mse: 2.4605e-04\n",
      "Epoch 713: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.8359 - bpp: 0.8281 - mse: 2.4605e-04\n",
      "Epoch 714/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5824 - bpp: 0.7851 - mse: 1.9467e-04\n",
      "Epoch 714: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.5824 - bpp: 0.7851 - mse: 1.9467e-04\n",
      "Epoch 715/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7337 - bpp: 0.7997 - mse: 2.2802e-04\n",
      "Epoch 715: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.7337 - bpp: 0.7997 - mse: 2.2802e-04\n",
      "Epoch 716/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8684 - bpp: 0.8371 - mse: 2.5178e-04\n",
      "Epoch 716: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.8684 - bpp: 0.8371 - mse: 2.5178e-04\n",
      "Epoch 717/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5373 - bpp: 0.7822 - mse: 1.8437e-04\n",
      "Epoch 717: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.5373 - bpp: 0.7822 - mse: 1.8437e-04\n",
      "Epoch 718/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6855 - bpp: 0.8069 - mse: 2.1452e-04\n",
      "Epoch 718: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.6855 - bpp: 0.8069 - mse: 2.1452e-04\n",
      "Epoch 719/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6768 - bpp: 0.7906 - mse: 2.1634e-04\n",
      "Epoch 719: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.6768 - bpp: 0.7906 - mse: 2.1634e-04\n",
      "Epoch 720/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7194 - bpp: 0.7936 - mse: 2.2604e-04\n",
      "Epoch 720: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.7194 - bpp: 0.7936 - mse: 2.2604e-04\n",
      "Epoch 721/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8546 - bpp: 0.8110 - mse: 2.5477e-04\n",
      "Epoch 721: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.8546 - bpp: 0.8110 - mse: 2.5477e-04\n",
      "Epoch 722/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9116 - bpp: 0.8188 - mse: 2.6680e-04\n",
      "Epoch 722: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.9116 - bpp: 0.8188 - mse: 2.6680e-04\n",
      "Epoch 723/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6380 - bpp: 0.7921 - mse: 2.0653e-04\n",
      "Epoch 723: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 1.6380 - bpp: 0.7921 - mse: 2.0653e-04\n",
      "Epoch 724/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6870 - bpp: 0.7944 - mse: 2.1792e-04\n",
      "Epoch 724: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.6870 - bpp: 0.7944 - mse: 2.1792e-04\n",
      "Epoch 725/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6971 - bpp: 0.7900 - mse: 2.2145e-04\n",
      "Epoch 725: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.6971 - bpp: 0.7900 - mse: 2.2145e-04\n",
      "Epoch 726/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6259 - bpp: 0.7866 - mse: 2.0492e-04\n",
      "Epoch 726: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.6259 - bpp: 0.7866 - mse: 2.0492e-04\n",
      "Epoch 727/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9407 - bpp: 0.8397 - mse: 2.6878e-04\n",
      "Epoch 727: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.9407 - bpp: 0.8397 - mse: 2.6878e-04\n",
      "Epoch 728/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6013 - bpp: 0.7909 - mse: 1.9786e-04\n",
      "Epoch 728: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 1.6013 - bpp: 0.7909 - mse: 1.9786e-04\n",
      "Epoch 729/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6414 - bpp: 0.7935 - mse: 2.0701e-04\n",
      "Epoch 729: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.6414 - bpp: 0.7935 - mse: 2.0701e-04\n",
      "Epoch 730/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8056 - bpp: 0.8325 - mse: 2.3756e-04\n",
      "Epoch 730: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.8056 - bpp: 0.8325 - mse: 2.3756e-04\n",
      "Epoch 731/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8825 - bpp: 0.8463 - mse: 2.5298e-04\n",
      "Epoch 731: loss did not improve from 1.50187\n",
      "100/100 [==============================] - 29s 283ms/step - loss: 1.8825 - bpp: 0.8463 - mse: 2.5298e-04\n",
      "Epoch 732/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4553 - bpp: 0.7609 - mse: 1.6954e-04\n",
      "Epoch 732: loss improved from 1.50187 to 1.45534, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.4553 - bpp: 0.7609 - mse: 1.6954e-04\n",
      "Epoch 733/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6279 - bpp: 0.8049 - mse: 2.0093e-04\n",
      "Epoch 733: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.6279 - bpp: 0.8049 - mse: 2.0093e-04\n",
      "Epoch 734/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6129 - bpp: 0.7875 - mse: 2.0149e-04\n",
      "Epoch 734: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.6129 - bpp: 0.7875 - mse: 2.0149e-04\n",
      "Epoch 735/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5571 - bpp: 0.7799 - mse: 1.8974e-04\n",
      "Epoch 735: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.5571 - bpp: 0.7799 - mse: 1.8974e-04\n",
      "Epoch 736/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7570 - bpp: 0.8205 - mse: 2.2863e-04\n",
      "Epoch 736: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7570 - bpp: 0.8205 - mse: 2.2863e-04\n",
      "Epoch 737/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8326 - bpp: 0.8174 - mse: 2.4785e-04\n",
      "Epoch 737: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8326 - bpp: 0.8174 - mse: 2.4785e-04\n",
      "Epoch 738/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7730 - bpp: 0.8349 - mse: 2.2902e-04\n",
      "Epoch 738: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7730 - bpp: 0.8349 - mse: 2.2902e-04\n",
      "Epoch 739/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6342 - bpp: 0.7943 - mse: 2.0506e-04\n",
      "Epoch 739: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.6342 - bpp: 0.7943 - mse: 2.0506e-04\n",
      "Epoch 740/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8106 - bpp: 0.8233 - mse: 2.4103e-04\n",
      "Epoch 740: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.8106 - bpp: 0.8233 - mse: 2.4103e-04\n",
      "Epoch 741/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9102 - bpp: 0.8466 - mse: 2.5967e-04\n",
      "Epoch 741: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.9102 - bpp: 0.8466 - mse: 2.5967e-04\n",
      "Epoch 742/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6807 - bpp: 0.7739 - mse: 2.2139e-04\n",
      "Epoch 742: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.6807 - bpp: 0.7739 - mse: 2.2139e-04\n",
      "Epoch 743/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7538 - bpp: 0.7962 - mse: 2.3378e-04\n",
      "Epoch 743: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.7538 - bpp: 0.7962 - mse: 2.3378e-04\n",
      "Epoch 744/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7137 - bpp: 0.8158 - mse: 2.1920e-04\n",
      "Epoch 744: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.7137 - bpp: 0.8158 - mse: 2.1920e-04\n",
      "Epoch 745/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7305 - bpp: 0.8092 - mse: 2.2491e-04\n",
      "Epoch 745: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.7305 - bpp: 0.8092 - mse: 2.2491e-04\n",
      "Epoch 746/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9418 - bpp: 0.8261 - mse: 2.7239e-04\n",
      "Epoch 746: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.9418 - bpp: 0.8261 - mse: 2.7239e-04\n",
      "Epoch 747/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7179 - bpp: 0.7899 - mse: 2.2657e-04\n",
      "Epoch 747: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.7179 - bpp: 0.7899 - mse: 2.2657e-04\n",
      "Epoch 748/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7877 - bpp: 0.8123 - mse: 2.3812e-04\n",
      "Epoch 748: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.7877 - bpp: 0.8123 - mse: 2.3812e-04\n",
      "Epoch 749/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7601 - bpp: 0.8015 - mse: 2.3402e-04\n",
      "Epoch 749: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 35s 345ms/step - loss: 1.7601 - bpp: 0.8015 - mse: 2.3402e-04\n",
      "Epoch 750/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6588 - bpp: 0.7935 - mse: 2.1125e-04\n",
      "Epoch 750: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 31s 304ms/step - loss: 1.6588 - bpp: 0.7935 - mse: 2.1125e-04\n",
      "Epoch 751/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9265 - bpp: 0.8344 - mse: 2.6663e-04\n",
      "Epoch 751: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 33s 330ms/step - loss: 1.9265 - bpp: 0.8344 - mse: 2.6663e-04\n",
      "Epoch 752/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6794 - bpp: 0.8041 - mse: 2.1370e-04\n",
      "Epoch 752: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.6794 - bpp: 0.8041 - mse: 2.1370e-04\n",
      "Epoch 753/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7813 - bpp: 0.8142 - mse: 2.3611e-04\n",
      "Epoch 753: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.7813 - bpp: 0.8142 - mse: 2.3611e-04\n",
      "Epoch 754/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6955 - bpp: 0.8077 - mse: 2.1674e-04\n",
      "Epoch 754: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.6955 - bpp: 0.8077 - mse: 2.1674e-04\n",
      "Epoch 755/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6306 - bpp: 0.8077 - mse: 2.0091e-04\n",
      "Epoch 755: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.6306 - bpp: 0.8077 - mse: 2.0091e-04\n",
      "Epoch 756/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5864 - bpp: 0.7911 - mse: 1.9415e-04\n",
      "Epoch 756: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5864 - bpp: 0.7911 - mse: 1.9415e-04\n",
      "Epoch 757/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6209 - bpp: 0.7985 - mse: 2.0080e-04\n",
      "Epoch 757: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.6209 - bpp: 0.7985 - mse: 2.0080e-04\n",
      "Epoch 758/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6948 - bpp: 0.8152 - mse: 2.1476e-04\n",
      "Epoch 758: loss did not improve from 1.45534\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6948 - bpp: 0.8152 - mse: 2.1476e-04\n",
      "Epoch 759/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4177 - bpp: 0.7401 - mse: 1.6543e-04\n",
      "Epoch 759: loss improved from 1.45534 to 1.41768, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.4177 - bpp: 0.7401 - mse: 1.6543e-04\n",
      "Epoch 760/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8216 - bpp: 0.8168 - mse: 2.4531e-04\n",
      "Epoch 760: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.8216 - bpp: 0.8168 - mse: 2.4531e-04\n",
      "Epoch 761/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7006 - bpp: 0.8032 - mse: 2.1909e-04\n",
      "Epoch 761: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.7006 - bpp: 0.8032 - mse: 2.1909e-04\n",
      "Epoch 762/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7699 - bpp: 0.8203 - mse: 2.3184e-04\n",
      "Epoch 762: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.7699 - bpp: 0.8203 - mse: 2.3184e-04\n",
      "Epoch 763/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5358 - bpp: 0.7625 - mse: 1.8877e-04\n",
      "Epoch 763: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.5358 - bpp: 0.7625 - mse: 1.8877e-04\n",
      "Epoch 764/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5899 - bpp: 0.7773 - mse: 1.9839e-04\n",
      "Epoch 764: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5899 - bpp: 0.7773 - mse: 1.9839e-04\n",
      "Epoch 765/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7120 - bpp: 0.8080 - mse: 2.2070e-04\n",
      "Epoch 765: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.7120 - bpp: 0.8080 - mse: 2.2070e-04\n",
      "Epoch 766/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1155 - bpp: 0.8694 - mse: 3.0423e-04\n",
      "Epoch 766: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 2.1155 - bpp: 0.8694 - mse: 3.0423e-04\n",
      "Epoch 767/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7512 - bpp: 0.8177 - mse: 2.2792e-04\n",
      "Epoch 767: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.7512 - bpp: 0.8177 - mse: 2.2792e-04\n",
      "Epoch 768/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6433 - bpp: 0.8072 - mse: 2.0413e-04\n",
      "Epoch 768: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.6433 - bpp: 0.8072 - mse: 2.0413e-04\n",
      "Epoch 769/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8149 - bpp: 0.8236 - mse: 2.4201e-04\n",
      "Epoch 769: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.8149 - bpp: 0.8236 - mse: 2.4201e-04\n",
      "Epoch 770/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0378 - bpp: 0.8389 - mse: 2.9270e-04\n",
      "Epoch 770: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 2.0378 - bpp: 0.8389 - mse: 2.9270e-04\n",
      "Epoch 771/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6254 - bpp: 0.7970 - mse: 2.0225e-04\n",
      "Epoch 771: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.6254 - bpp: 0.7970 - mse: 2.0225e-04\n",
      "Epoch 772/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7496 - bpp: 0.8160 - mse: 2.2794e-04\n",
      "Epoch 772: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.7496 - bpp: 0.8160 - mse: 2.2794e-04\n",
      "Epoch 773/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6554 - bpp: 0.7985 - mse: 2.0922e-04\n",
      "Epoch 773: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.6554 - bpp: 0.7985 - mse: 2.0922e-04\n",
      "Epoch 774/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5852 - bpp: 0.7636 - mse: 2.0058e-04\n",
      "Epoch 774: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.5852 - bpp: 0.7636 - mse: 2.0058e-04\n",
      "Epoch 775/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8254 - bpp: 0.8136 - mse: 2.4703e-04\n",
      "Epoch 775: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.8254 - bpp: 0.8136 - mse: 2.4703e-04\n",
      "Epoch 776/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7926 - bpp: 0.8210 - mse: 2.3721e-04\n",
      "Epoch 776: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.7926 - bpp: 0.8210 - mse: 2.3721e-04\n",
      "Epoch 777/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2949 - bpp: 0.8926 - mse: 3.4236e-04\n",
      "Epoch 777: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 2.2949 - bpp: 0.8926 - mse: 3.4236e-04\n",
      "Epoch 778/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6167 - bpp: 0.7746 - mse: 2.0559e-04\n",
      "Epoch 778: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 30s 292ms/step - loss: 1.6167 - bpp: 0.7746 - mse: 2.0559e-04\n",
      "Epoch 779/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8211 - bpp: 0.8119 - mse: 2.4641e-04\n",
      "Epoch 779: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.8211 - bpp: 0.8119 - mse: 2.4641e-04\n",
      "Epoch 780/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7671 - bpp: 0.8084 - mse: 2.3407e-04\n",
      "Epoch 780: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.7671 - bpp: 0.8084 - mse: 2.3407e-04\n",
      "Epoch 781/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7930 - bpp: 0.8045 - mse: 2.4135e-04\n",
      "Epoch 781: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.7930 - bpp: 0.8045 - mse: 2.4135e-04\n",
      "Epoch 782/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7924 - bpp: 0.8179 - mse: 2.3793e-04\n",
      "Epoch 782: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.7924 - bpp: 0.8179 - mse: 2.3793e-04\n",
      "Epoch 783/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7047 - bpp: 0.7916 - mse: 2.2293e-04\n",
      "Epoch 783: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7047 - bpp: 0.7916 - mse: 2.2293e-04\n",
      "Epoch 784/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8519 - bpp: 0.8072 - mse: 2.5505e-04\n",
      "Epoch 784: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.8519 - bpp: 0.8072 - mse: 2.5505e-04\n",
      "Epoch 785/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8171 - bpp: 0.8064 - mse: 2.4673e-04\n",
      "Epoch 785: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.8171 - bpp: 0.8064 - mse: 2.4673e-04\n",
      "Epoch 786/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6401 - bpp: 0.7979 - mse: 2.0561e-04\n",
      "Epoch 786: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.6401 - bpp: 0.7979 - mse: 2.0561e-04\n",
      "Epoch 787/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6807 - bpp: 0.7970 - mse: 2.1574e-04\n",
      "Epoch 787: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 31s 294ms/step - loss: 1.6807 - bpp: 0.7970 - mse: 2.1574e-04\n",
      "Epoch 788/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8484 - bpp: 0.8354 - mse: 2.4732e-04\n",
      "Epoch 788: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.8484 - bpp: 0.8354 - mse: 2.4732e-04\n",
      "Epoch 789/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7218 - bpp: 0.8008 - mse: 2.2486e-04\n",
      "Epoch 789: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.7218 - bpp: 0.8008 - mse: 2.2486e-04\n",
      "Epoch 790/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5635 - bpp: 0.7933 - mse: 1.8802e-04\n",
      "Epoch 790: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5635 - bpp: 0.7933 - mse: 1.8802e-04\n",
      "Epoch 791/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6377 - bpp: 0.7905 - mse: 2.0683e-04\n",
      "Epoch 791: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.6377 - bpp: 0.7905 - mse: 2.0683e-04\n",
      "Epoch 792/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6741 - bpp: 0.7923 - mse: 2.1529e-04\n",
      "Epoch 792: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.6741 - bpp: 0.7923 - mse: 2.1529e-04\n",
      "Epoch 793/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7271 - bpp: 0.8325 - mse: 2.1840e-04\n",
      "Epoch 793: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7271 - bpp: 0.8325 - mse: 2.1840e-04\n",
      "Epoch 794/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8335 - bpp: 0.8315 - mse: 2.4464e-04\n",
      "Epoch 794: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8335 - bpp: 0.8315 - mse: 2.4464e-04\n",
      "Epoch 795/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6237 - bpp: 0.7954 - mse: 2.0224e-04\n",
      "Epoch 795: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.6237 - bpp: 0.7954 - mse: 2.0224e-04\n",
      "Epoch 796/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6882 - bpp: 0.8000 - mse: 2.1685e-04\n",
      "Epoch 796: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.6882 - bpp: 0.8000 - mse: 2.1685e-04\n",
      "Epoch 797/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6443 - bpp: 0.7974 - mse: 2.0677e-04\n",
      "Epoch 797: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.6443 - bpp: 0.7974 - mse: 2.0677e-04\n",
      "Epoch 798/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6347 - bpp: 0.8035 - mse: 2.0294e-04\n",
      "Epoch 798: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.6347 - bpp: 0.8035 - mse: 2.0294e-04\n",
      "Epoch 799/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7466 - bpp: 0.8094 - mse: 2.2881e-04\n",
      "Epoch 799: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.7466 - bpp: 0.8094 - mse: 2.2881e-04\n",
      "Epoch 800/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6302 - bpp: 0.8020 - mse: 2.0221e-04\n",
      "Epoch 800: loss did not improve from 1.41768\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.6302 - bpp: 0.8020 - mse: 2.0221e-04\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "hist = model.fit(x=data, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, verbose=1, batch_size=BATCH_SIZE,\n",
    "                callbacks=[\n",
    "                    # Callbacks.MemoryCallback(),\n",
    "                    # Callbacks.LearningRateReducer(),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch', monitor=\"loss\", mode='min',  save_best_only=True, verbose=1), \n",
    "                    tf.keras.callbacks.TerminateOnNaN(),\n",
    "                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stop),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq=\"epoch\"),            \n",
    "                    ],\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00089/0736/im1.png\n",
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n"
     ]
    }
   ],
   "source": [
    "path = load.load_random_path(\"folder_cloud_test.npy\")\n",
    "i=0\n",
    "out_bin = \"Test_com/test{}.bin\".format(i)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(i)\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(i)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(i)\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, out_bin, out_decom, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_1_layer_call_fn, optical_flow_loss_1_layer_call_and_return_conditional_losses, dwt_1_layer_call_fn, dwt_1_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220428-202700/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00049/0289/im1.png\n",
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00049/0289/im2.png\n",
      "compress\n",
      "decompress\n",
      "bin size:  4247 psnr:  40.709933345318625\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from math import log10, sqrt\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "\n",
    "path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "p_frame_out_bin = \"Test_com/dvcw/p_frame_dvcw.bin\"\n",
    "out_decom = \"Test_com/dvcw/frame1.png\"\n",
    "i_on_test = \"Test_com/frame0.png\"\n",
    "p_on_test = \"Test_com/frame1.png\"\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "print(p_frame)\n",
    "\n",
    "# write inputs to disk\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, p_frame_out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, p_frame_out_bin, out_decom, 240, 240)\n",
    "\n",
    "\n",
    "original = cv2.imread(p_on_test)\n",
    "compressed = cv2.imread(out_decom)\n",
    "bin_size = os.path.getsize(p_frame_out_bin)\n",
    "value = PSNR(original, compressed)\n",
    "print(\"bin size: \", bin_size , \"psnr: \", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
