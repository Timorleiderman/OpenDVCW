{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW/train_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "import OpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import DataGen\n",
    "import Callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 800\n",
    "STEPS_PER_EPOCH = 100\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 8192\n",
    "lr_init = 1e-4\n",
    "early_stop = 400\n",
    "I_QP=27\n",
    "wavelet_name = \"haar\"\n",
    "args = OpenDVCW.Arguments()\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkponts_last_path = \"\"\n",
    "checkponts_new_path = \"checkpoints_wavelets_{}_Lmbd_{}_epcs_{}_es_{}_I_QP_{}_{}x{}_CosineDecay_{}/\".format(wavelet_name, lmbda, EPOCHS,  early_stop, I_QP, Width, Height, timestamp)\n",
    "save_name = \"model_save_\" + checkponts_new_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 15:58:41.375766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:41.425914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:41.426826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:41.431415: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-27 15:58:41.436877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:41.437617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:41.438483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:44.757509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:44.758548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:44.759374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:58:44.760286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "* [Loading dataset]...\n",
      "Loading weights\n"
     ]
    }
   ],
   "source": [
    "model = OpenDVCW.OpenDVC(width=Width, height=Height, batch_size=BATCH_SIZE, num_filters=128, lmbda=lmbda)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=lr_init, decay_steps=EPOCHS*(STEPS_PER_EPOCH), alpha=1e-8, name=\"lr_CosineDecay\")\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),)\n",
    "print(\"* [Model compiled]...\")\n",
    "\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = DataGen.DataVimeo90kGenerator(\"folder_cloud_test.npy\", \n",
    "                                    BATCH_SIZE,\n",
    "                                    (Height,Width,Channel),\n",
    "                                    Channel,\n",
    "                                    True, \n",
    "                                    I_QP,\n",
    "                                    True)\n",
    "\n",
    "print(\"Loading weights\")\n",
    "if not checkponts_last_path == \"\":\n",
    "    model.load_weights(checkponts_last_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"open_dvc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mv_analysis (AnalysisTransf  (1, 15, 15, 128)         659456    \n",
      " orm)                                                            \n",
      "                                                                 \n",
      " mv_synthesis (SynthesisTran  (1, 240, 240, 2)         642824    \n",
      " sform)                                                          \n",
      "                                                                 \n",
      " res_analysis (AnalysisTrans  (None, 15, 15, 128)      1552640   \n",
      " form)                                                           \n",
      "                                                                 \n",
      " res_synthesis (SynthesisTra  (None, 240, 240, 3)      1536015   \n",
      " nsform)                                                         \n",
      "                                                                 \n",
      " wavelets_optical_flow (Wave  multiple                 240050    \n",
      " letsOpticalFlow)                                                \n",
      "                                                                 \n",
      " motion_compensation (Motion  multiple                 486467    \n",
      " Compensation)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,124,626\n",
      "Trainable params: 5,124,620\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 15:58:59.189531: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].trainable = False\n",
    "# model.layers[1].trainable = False\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[3].trainable = True\n",
    "# model.layers[4].trainable = False\n",
    "# model.layers[5].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_analysis True\n",
      "mv_synthesis True\n",
      "res_analysis True\n",
      "res_synthesis True\n",
      "wavelets_optical_flow True\n",
      "motion_compensation True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 15:59:53.395754: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 286.1653 - bpp: 5.3365 - mse: 0.0343\n",
      "Epoch 1: loss improved from inf to 286.16528, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 91s 291ms/step - loss: 286.1653 - bpp: 5.3365 - mse: 0.0343\n",
      "Epoch 2/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 82.0973 - bpp: 5.2655 - mse: 0.0094\n",
      "Epoch 2: loss improved from 286.16528 to 82.09732, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 82.0973 - bpp: 5.2655 - mse: 0.0094\n",
      "Epoch 3/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 39.4099 - bpp: 5.1960 - mse: 0.0042\n",
      "Epoch 3: loss improved from 82.09732 to 39.40990, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 39.4099 - bpp: 5.1960 - mse: 0.0042\n",
      "Epoch 4/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 34.3604 - bpp: 5.1278 - mse: 0.0036\n",
      "Epoch 4: loss improved from 39.40990 to 34.36041, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 34.3604 - bpp: 5.1278 - mse: 0.0036\n",
      "Epoch 5/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 26.1168 - bpp: 5.0604 - mse: 0.0026\n",
      "Epoch 5: loss improved from 34.36041 to 26.11680, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 239ms/step - loss: 26.1168 - bpp: 5.0604 - mse: 0.0026\n",
      "Epoch 6/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 25.0529 - bpp: 4.9938 - mse: 0.0024\n",
      "Epoch 6: loss improved from 26.11680 to 25.05292, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 25.0529 - bpp: 4.9938 - mse: 0.0024\n",
      "Epoch 7/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 25.7982 - bpp: 4.9276 - mse: 0.0025\n",
      "Epoch 7: loss did not improve from 25.05292\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 25.7982 - bpp: 4.9276 - mse: 0.0025\n",
      "Epoch 8/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 27.5637 - bpp: 4.8627 - mse: 0.0028\n",
      "Epoch 8: loss did not improve from 25.05292\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 27.5637 - bpp: 4.8627 - mse: 0.0028\n",
      "Epoch 9/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 19.3596 - bpp: 4.7975 - mse: 0.0018\n",
      "Epoch 9: loss improved from 25.05292 to 19.35960, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 19.3596 - bpp: 4.7975 - mse: 0.0018\n",
      "Epoch 10/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 18.5530 - bpp: 4.7334 - mse: 0.0017\n",
      "Epoch 10: loss improved from 19.35960 to 18.55305, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 18.5530 - bpp: 4.7334 - mse: 0.0017\n",
      "Epoch 11/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 16.6021 - bpp: 4.6696 - mse: 0.0015\n",
      "Epoch 11: loss improved from 18.55305 to 16.60207, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 16.6021 - bpp: 4.6696 - mse: 0.0015\n",
      "Epoch 12/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 17.6752 - bpp: 4.6067 - mse: 0.0016\n",
      "Epoch 12: loss did not improve from 16.60207\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 17.6752 - bpp: 4.6067 - mse: 0.0016\n",
      "Epoch 13/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 17.1334 - bpp: 4.5441 - mse: 0.0015\n",
      "Epoch 13: loss did not improve from 16.60207\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 17.1334 - bpp: 4.5441 - mse: 0.0015\n",
      "Epoch 14/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 18.6866 - bpp: 4.4828 - mse: 0.0017\n",
      "Epoch 14: loss did not improve from 16.60207\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 18.6866 - bpp: 4.4828 - mse: 0.0017\n",
      "Epoch 15/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 15.6483 - bpp: 4.4205 - mse: 0.0014\n",
      "Epoch 15: loss improved from 16.60207 to 15.64831, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 15.6483 - bpp: 4.4205 - mse: 0.0014\n",
      "Epoch 16/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 16.8244 - bpp: 4.3593 - mse: 0.0015\n",
      "Epoch 16: loss did not improve from 15.64831\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 16.8244 - bpp: 4.3593 - mse: 0.0015\n",
      "Epoch 17/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 18.3928 - bpp: 4.3000 - mse: 0.0017\n",
      "Epoch 17: loss did not improve from 15.64831\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 18.3928 - bpp: 4.3000 - mse: 0.0017\n",
      "Epoch 18/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 15.9411 - bpp: 4.2398 - mse: 0.0014\n",
      "Epoch 18: loss did not improve from 15.64831\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 15.9411 - bpp: 4.2398 - mse: 0.0014\n",
      "Epoch 19/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 16.0648 - bpp: 4.1803 - mse: 0.0015\n",
      "Epoch 19: loss did not improve from 15.64831\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 16.0648 - bpp: 4.1803 - mse: 0.0015\n",
      "Epoch 20/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 15.1585 - bpp: 4.1216 - mse: 0.0013\n",
      "Epoch 20: loss improved from 15.64831 to 15.15854, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 15.1585 - bpp: 4.1216 - mse: 0.0013\n",
      "Epoch 21/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 15.2116 - bpp: 4.0635 - mse: 0.0014\n",
      "Epoch 21: loss did not improve from 15.15854\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 15.2116 - bpp: 4.0635 - mse: 0.0014\n",
      "Epoch 22/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 18.7760 - bpp: 4.0082 - mse: 0.0018\n",
      "Epoch 22: loss did not improve from 15.15854\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 18.7760 - bpp: 4.0082 - mse: 0.0018\n",
      "Epoch 23/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 15.4033 - bpp: 3.9501 - mse: 0.0014\n",
      "Epoch 23: loss did not improve from 15.15854\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 15.4033 - bpp: 3.9501 - mse: 0.0014\n",
      "Epoch 24/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 13.2060 - bpp: 3.8918 - mse: 0.0011\n",
      "Epoch 24: loss improved from 15.15854 to 13.20596, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 13.2060 - bpp: 3.8918 - mse: 0.0011\n",
      "Epoch 25/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.0194 - bpp: 3.8339 - mse: 8.7713e-04\n",
      "Epoch 25: loss improved from 13.20596 to 11.01941, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 11.0194 - bpp: 3.8339 - mse: 8.7713e-04\n",
      "Epoch 26/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 12.8083 - bpp: 3.7817 - mse: 0.0011\n",
      "Epoch 26: loss did not improve from 11.01941\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 12.8083 - bpp: 3.7817 - mse: 0.0011\n",
      "Epoch 27/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.0724 - bpp: 3.7302 - mse: 8.9627e-04\n",
      "Epoch 27: loss did not improve from 11.01941\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 11.0724 - bpp: 3.7302 - mse: 8.9627e-04\n",
      "Epoch 28/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.4066 - bpp: 3.6765 - mse: 9.4361e-04\n",
      "Epoch 28: loss did not improve from 11.01941\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 11.4066 - bpp: 3.6765 - mse: 9.4361e-04\n",
      "Epoch 29/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.6795 - bpp: 3.6208 - mse: 7.3958e-04\n",
      "Epoch 29: loss improved from 11.01941 to 9.67945, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 9.6795 - bpp: 3.6208 - mse: 7.3958e-04\n",
      "Epoch 30/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.1411 - bpp: 3.5669 - mse: 8.0251e-04\n",
      "Epoch 30: loss did not improve from 9.67945\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 10.1411 - bpp: 3.5669 - mse: 8.0251e-04\n",
      "Epoch 31/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.3258 - bpp: 3.5149 - mse: 7.0934e-04\n",
      "Epoch 31: loss improved from 9.67945 to 9.32580, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 9.3258 - bpp: 3.5149 - mse: 7.0934e-04\n",
      "Epoch 32/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.6470 - bpp: 3.4661 - mse: 7.5450e-04\n",
      "Epoch 32: loss did not improve from 9.32580\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 9.6470 - bpp: 3.4661 - mse: 7.5450e-04\n",
      "Epoch 33/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.4786 - bpp: 3.4151 - mse: 7.4017e-04\n",
      "Epoch 33: loss did not improve from 9.32580\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 9.4786 - bpp: 3.4151 - mse: 7.4017e-04\n",
      "Epoch 34/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.0628 - bpp: 3.3628 - mse: 6.9580e-04\n",
      "Epoch 34: loss improved from 9.32580 to 9.06281, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 240ms/step - loss: 9.0628 - bpp: 3.3628 - mse: 6.9580e-04\n",
      "Epoch 35/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.6227 - bpp: 3.3131 - mse: 6.4814e-04\n",
      "Epoch 35: loss improved from 9.06281 to 8.62267, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 8.6227 - bpp: 3.3131 - mse: 6.4814e-04\n",
      "Epoch 36/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.6335 - bpp: 3.2630 - mse: 6.5559e-04\n",
      "Epoch 36: loss did not improve from 8.62267\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 8.6335 - bpp: 3.2630 - mse: 6.5559e-04\n",
      "Epoch 37/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.7290 - bpp: 3.2151 - mse: 5.5101e-04\n",
      "Epoch 37: loss improved from 8.62267 to 7.72898, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 7.7290 - bpp: 3.2151 - mse: 5.5101e-04\n",
      "Epoch 38/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.3558 - bpp: 3.1679 - mse: 6.3329e-04\n",
      "Epoch 38: loss did not improve from 7.72898\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 8.3558 - bpp: 3.1679 - mse: 6.3329e-04\n",
      "Epoch 39/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5544 - bpp: 3.1225 - mse: 5.4100e-04\n",
      "Epoch 39: loss improved from 7.72898 to 7.55436, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 242ms/step - loss: 7.5544 - bpp: 3.1225 - mse: 5.4100e-04\n",
      "Epoch 40/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.8349 - bpp: 3.0786 - mse: 5.8060e-04\n",
      "Epoch 40: loss did not improve from 7.55436\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 7.8349 - bpp: 3.0786 - mse: 5.8060e-04\n",
      "Epoch 41/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.2310 - bpp: 3.0365 - mse: 6.3410e-04\n",
      "Epoch 41: loss did not improve from 7.55436\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 8.2310 - bpp: 3.0365 - mse: 6.3410e-04\n",
      "Epoch 42/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5159 - bpp: 2.9862 - mse: 5.5293e-04\n",
      "Epoch 42: loss improved from 7.55436 to 7.51587, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 7.5159 - bpp: 2.9862 - mse: 5.5293e-04\n",
      "Epoch 43/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.5236 - bpp: 2.9339 - mse: 4.3820e-04\n",
      "Epoch 43: loss improved from 7.51587 to 6.52358, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 6.5236 - bpp: 2.9339 - mse: 4.3820e-04\n",
      "Epoch 44/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.6093 - bpp: 2.9049 - mse: 6.9635e-04\n",
      "Epoch 44: loss did not improve from 6.52358\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 8.6093 - bpp: 2.9049 - mse: 6.9635e-04\n",
      "Epoch 45/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.9718 - bpp: 2.8611 - mse: 5.0180e-04\n",
      "Epoch 45: loss did not improve from 6.52358\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 6.9718 - bpp: 2.8611 - mse: 5.0180e-04\n",
      "Epoch 46/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.2002 - bpp: 2.8093 - mse: 4.1392e-04\n",
      "Epoch 46: loss improved from 6.52358 to 6.20017, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 6.2002 - bpp: 2.8093 - mse: 4.1392e-04\n",
      "Epoch 47/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.2522 - bpp: 2.7849 - mse: 5.4532e-04\n",
      "Epoch 47: loss did not improve from 6.20017\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 7.2522 - bpp: 2.7849 - mse: 5.4532e-04\n",
      "Epoch 48/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5173 - bpp: 2.7597 - mse: 5.8076e-04\n",
      "Epoch 48: loss did not improve from 6.20017\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 7.5173 - bpp: 2.7597 - mse: 5.8076e-04\n",
      "Epoch 49/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.0029 - bpp: 2.7058 - mse: 5.2456e-04\n",
      "Epoch 49: loss did not improve from 6.20017\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 7.0029 - bpp: 2.7058 - mse: 5.2456e-04\n",
      "Epoch 50/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.3196 - bpp: 2.6603 - mse: 4.4669e-04\n",
      "Epoch 50: loss did not improve from 6.20017\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 6.3196 - bpp: 2.6603 - mse: 4.4669e-04\n",
      "Epoch 51/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.2786 - bpp: 2.6259 - mse: 4.4588e-04\n",
      "Epoch 51: loss did not improve from 6.20017\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 6.2786 - bpp: 2.6259 - mse: 4.4588e-04\n",
      "Epoch 52/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.7406 - bpp: 2.5865 - mse: 3.8502e-04\n",
      "Epoch 52: loss improved from 6.20017 to 5.74058, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 5.7406 - bpp: 2.5865 - mse: 3.8502e-04\n",
      "Epoch 53/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.9025 - bpp: 2.5613 - mse: 5.2993e-04\n",
      "Epoch 53: loss did not improve from 5.74058\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 6.9025 - bpp: 2.5613 - mse: 5.2993e-04\n",
      "Epoch 54/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.7401 - bpp: 2.5128 - mse: 3.9397e-04\n",
      "Epoch 54: loss improved from 5.74058 to 5.74015, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 5.7401 - bpp: 2.5128 - mse: 3.9397e-04\n",
      "Epoch 55/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.3692 - bpp: 2.4795 - mse: 3.5275e-04\n",
      "Epoch 55: loss improved from 5.74015 to 5.36920, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 5.3692 - bpp: 2.4795 - mse: 3.5275e-04\n",
      "Epoch 56/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2254 - bpp: 2.4379 - mse: 3.4027e-04\n",
      "Epoch 56: loss improved from 5.36920 to 5.22538, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 5.2254 - bpp: 2.4379 - mse: 3.4027e-04\n",
      "Epoch 57/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6745 - bpp: 2.4187 - mse: 3.9744e-04\n",
      "Epoch 57: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 5.6745 - bpp: 2.4187 - mse: 3.9744e-04\n",
      "Epoch 58/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 18.1660 - bpp: 2.4425 - mse: 0.0019\n",
      "Epoch 58: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 18.1660 - bpp: 2.4425 - mse: 0.0019\n",
      "Epoch 59/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.0862 - bpp: 2.3818 - mse: 8.1840e-04\n",
      "Epoch 59: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 9.0862 - bpp: 2.3818 - mse: 8.1840e-04\n",
      "Epoch 60/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.2808 - bpp: 2.3187 - mse: 4.8366e-04\n",
      "Epoch 60: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 6.2808 - bpp: 2.3187 - mse: 4.8366e-04\n",
      "Epoch 61/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.9727 - bpp: 2.2797 - mse: 4.5080e-04\n",
      "Epoch 61: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 5.9727 - bpp: 2.2797 - mse: 4.5080e-04\n",
      "Epoch 62/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2280 - bpp: 2.2240 - mse: 3.6670e-04\n",
      "Epoch 62: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 232ms/step - loss: 5.2280 - bpp: 2.2240 - mse: 3.6670e-04\n",
      "Epoch 63/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.5946 - bpp: 2.2136 - mse: 4.1272e-04\n",
      "Epoch 63: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 5.5946 - bpp: 2.2136 - mse: 4.1272e-04\n",
      "Epoch 64/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.4038 - bpp: 2.1755 - mse: 3.9407e-04\n",
      "Epoch 64: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 5.4038 - bpp: 2.1755 - mse: 3.9407e-04\n",
      "Epoch 65/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 50.6440 - bpp: 2.2604 - mse: 0.0059\n",
      "Epoch 65: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 50.6440 - bpp: 2.2604 - mse: 0.0059\n",
      "Epoch 66/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 14.5082 - bpp: 2.1675 - mse: 0.0015\n",
      "Epoch 66: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 14.5082 - bpp: 2.1675 - mse: 0.0015\n",
      "Epoch 67/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 13.2670 - bpp: 2.2030 - mse: 0.0014\n",
      "Epoch 67: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 13.2670 - bpp: 2.2030 - mse: 0.0014\n",
      "Epoch 68/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.0311 - bpp: 2.1789 - mse: 8.3645e-04\n",
      "Epoch 68: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 9.0311 - bpp: 2.1789 - mse: 8.3645e-04\n",
      "Epoch 69/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5536 - bpp: 2.1338 - mse: 6.6160e-04\n",
      "Epoch 69: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 7.5536 - bpp: 2.1338 - mse: 6.6160e-04\n",
      "Epoch 70/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.6195 - bpp: 2.0364 - mse: 5.5947e-04\n",
      "Epoch 70: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 6.6195 - bpp: 2.0364 - mse: 5.5947e-04\n",
      "Epoch 71/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.3198 - bpp: 2.0492 - mse: 5.2132e-04\n",
      "Epoch 71: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 6.3198 - bpp: 2.0492 - mse: 5.2132e-04\n",
      "Epoch 72/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.4514 - bpp: 2.0185 - mse: 5.4113e-04\n",
      "Epoch 72: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 6.4514 - bpp: 2.0185 - mse: 5.4113e-04\n",
      "Epoch 73/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.2247 - bpp: 1.9846 - mse: 5.1759e-04\n",
      "Epoch 73: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 6.2247 - bpp: 1.9846 - mse: 5.1759e-04\n",
      "Epoch 74/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6625 - bpp: 1.9575 - mse: 4.5226e-04\n",
      "Epoch 74: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 5.6625 - bpp: 1.9575 - mse: 4.5226e-04\n",
      "Epoch 75/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.1733 - bpp: 2.0007 - mse: 7.5349e-04\n",
      "Epoch 75: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 24s 230ms/step - loss: 8.1733 - bpp: 2.0007 - mse: 7.5349e-04\n",
      "Epoch 76/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.9816 - bpp: 1.9547 - mse: 4.9157e-04\n",
      "Epoch 76: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 5.9816 - bpp: 1.9547 - mse: 4.9157e-04\n",
      "Epoch 77/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.9751 - bpp: 1.9095 - mse: 4.9630e-04\n",
      "Epoch 77: loss did not improve from 5.22538\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 5.9751 - bpp: 1.9095 - mse: 4.9630e-04\n",
      "Epoch 78/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2041 - bpp: 1.8784 - mse: 4.0598e-04\n",
      "Epoch 78: loss improved from 5.22538 to 5.20413, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 5.2041 - bpp: 1.8784 - mse: 4.0598e-04\n",
      "Epoch 79/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.5184 - bpp: 1.8591 - mse: 4.4669e-04\n",
      "Epoch 79: loss did not improve from 5.20413\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 5.5184 - bpp: 1.8591 - mse: 4.4669e-04\n",
      "Epoch 80/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6791 - bpp: 1.8684 - mse: 4.6518e-04\n",
      "Epoch 80: loss did not improve from 5.20413\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 5.6791 - bpp: 1.8684 - mse: 4.6518e-04\n",
      "Epoch 81/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2403 - bpp: 1.7943 - mse: 4.2065e-04\n",
      "Epoch 81: loss did not improve from 5.20413\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 5.2403 - bpp: 1.7943 - mse: 4.2065e-04\n",
      "Epoch 82/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2218 - bpp: 1.7653 - mse: 4.2194e-04\n",
      "Epoch 82: loss did not improve from 5.20413\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 5.2218 - bpp: 1.7653 - mse: 4.2194e-04\n",
      "Epoch 83/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.0086 - bpp: 1.7695 - mse: 3.9540e-04\n",
      "Epoch 83: loss improved from 5.20413 to 5.00856, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 5.0086 - bpp: 1.7695 - mse: 3.9540e-04\n",
      "Epoch 84/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4550 - bpp: 1.7598 - mse: 3.2901e-04\n",
      "Epoch 84: loss improved from 5.00856 to 4.45503, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 4.4550 - bpp: 1.7598 - mse: 3.2901e-04\n",
      "Epoch 85/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.5378 - bpp: 1.7263 - mse: 3.4321e-04\n",
      "Epoch 85: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.5378 - bpp: 1.7263 - mse: 3.4321e-04\n",
      "Epoch 86/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6873 - bpp: 1.7005 - mse: 3.6460e-04\n",
      "Epoch 86: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 4.6873 - bpp: 1.7005 - mse: 3.6460e-04\n",
      "Epoch 87/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.1933 - bpp: 1.7466 - mse: 4.2075e-04\n",
      "Epoch 87: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 5.1933 - bpp: 1.7466 - mse: 4.2075e-04\n",
      "Epoch 88/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7772 - bpp: 1.7019 - mse: 3.7541e-04\n",
      "Epoch 88: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 4.7772 - bpp: 1.7019 - mse: 3.7541e-04\n",
      "Epoch 89/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6870 - bpp: 1.6442 - mse: 3.7144e-04\n",
      "Epoch 89: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.6870 - bpp: 1.6442 - mse: 3.7144e-04\n",
      "Epoch 90/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7358 - bpp: 1.6195 - mse: 3.8041e-04\n",
      "Epoch 90: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 24s 232ms/step - loss: 4.7358 - bpp: 1.6195 - mse: 3.8041e-04\n",
      "Epoch 91/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6889 - bpp: 1.6001 - mse: 3.7705e-04\n",
      "Epoch 91: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 24s 234ms/step - loss: 4.6889 - bpp: 1.6001 - mse: 3.7705e-04\n",
      "Epoch 92/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8438 - bpp: 1.6439 - mse: 3.9062e-04\n",
      "Epoch 92: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.8438 - bpp: 1.6439 - mse: 3.9062e-04\n",
      "Epoch 93/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4607 - bpp: 1.5989 - mse: 3.4935e-04\n",
      "Epoch 93: loss did not improve from 4.45503\n",
      "100/100 [==============================] - 24s 231ms/step - loss: 4.4607 - bpp: 1.5989 - mse: 3.4935e-04\n",
      "Epoch 94/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9947 - bpp: 1.5288 - mse: 3.0102e-04\n",
      "Epoch 94: loss improved from 4.45503 to 3.99474, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.9947 - bpp: 1.5288 - mse: 3.0102e-04\n",
      "Epoch 95/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9594 - bpp: 1.5367 - mse: 2.9574e-04\n",
      "Epoch 95: loss improved from 3.99474 to 3.95939, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 3.9594 - bpp: 1.5367 - mse: 2.9574e-04\n",
      "Epoch 96/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7733 - bpp: 1.5885 - mse: 3.8877e-04\n",
      "Epoch 96: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 4.7733 - bpp: 1.5885 - mse: 3.8877e-04\n",
      "Epoch 97/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7557 - bpp: 1.5941 - mse: 3.8594e-04\n",
      "Epoch 97: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 4.7557 - bpp: 1.5941 - mse: 3.8594e-04\n",
      "Epoch 98/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2886 - bpp: 1.5642 - mse: 3.3257e-04\n",
      "Epoch 98: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 4.2886 - bpp: 1.5642 - mse: 3.3257e-04\n",
      "Epoch 99/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4116 - bpp: 1.5130 - mse: 3.5383e-04\n",
      "Epoch 99: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 241ms/step - loss: 4.4116 - bpp: 1.5130 - mse: 3.5383e-04\n",
      "Epoch 100/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2509 - bpp: 1.5374 - mse: 3.3125e-04\n",
      "Epoch 100: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.2509 - bpp: 1.5374 - mse: 3.3125e-04\n",
      "Epoch 101/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7101 - bpp: 1.5451 - mse: 3.8636e-04\n",
      "Epoch 101: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.7101 - bpp: 1.5451 - mse: 3.8636e-04\n",
      "Epoch 102/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1936 - bpp: 1.5189 - mse: 3.2650e-04\n",
      "Epoch 102: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 232ms/step - loss: 4.1936 - bpp: 1.5189 - mse: 3.2650e-04\n",
      "Epoch 103/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 26.4944 - bpp: 1.6730 - mse: 0.0030\n",
      "Epoch 103: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 26.4944 - bpp: 1.6730 - mse: 0.0030\n",
      "Epoch 104/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 14.9640 - bpp: 1.6538 - mse: 0.0016\n",
      "Epoch 104: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 14.9640 - bpp: 1.6538 - mse: 0.0016\n",
      "Epoch 105/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.8029 - bpp: 1.5596 - mse: 6.4005e-04\n",
      "Epoch 105: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 240ms/step - loss: 6.8029 - bpp: 1.5596 - mse: 6.4005e-04\n",
      "Epoch 106/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.5486 - bpp: 1.4943 - mse: 4.9490e-04\n",
      "Epoch 106: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 5.5486 - bpp: 1.4943 - mse: 4.9490e-04\n",
      "Epoch 107/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6915 - bpp: 1.5261 - mse: 5.0848e-04\n",
      "Epoch 107: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 5.6915 - bpp: 1.5261 - mse: 5.0848e-04\n",
      "Epoch 108/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3911 - bpp: 1.4347 - mse: 3.6088e-04\n",
      "Epoch 108: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 237ms/step - loss: 4.3911 - bpp: 1.4347 - mse: 3.6088e-04\n",
      "Epoch 109/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1762 - bpp: 1.4369 - mse: 3.3440e-04\n",
      "Epoch 109: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 236ms/step - loss: 4.1762 - bpp: 1.4369 - mse: 3.3440e-04\n",
      "Epoch 110/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3121 - bpp: 1.4122 - mse: 3.5399e-04\n",
      "Epoch 110: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 4.3121 - bpp: 1.4122 - mse: 3.5399e-04\n",
      "Epoch 111/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4355 - bpp: 1.4221 - mse: 3.6785e-04\n",
      "Epoch 111: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 4.4355 - bpp: 1.4221 - mse: 3.6785e-04\n",
      "Epoch 112/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3378 - bpp: 1.4057 - mse: 3.5792e-04\n",
      "Epoch 112: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 24s 234ms/step - loss: 4.3378 - bpp: 1.4057 - mse: 3.5792e-04\n",
      "Epoch 113/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4408 - bpp: 1.4107 - mse: 3.6989e-04\n",
      "Epoch 113: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 4.4408 - bpp: 1.4107 - mse: 3.6989e-04\n",
      "Epoch 114/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1300 - bpp: 1.3740 - mse: 3.3642e-04\n",
      "Epoch 114: loss did not improve from 3.95939\n",
      "100/100 [==============================] - 25s 237ms/step - loss: 4.1300 - bpp: 1.3740 - mse: 3.3642e-04\n",
      "Epoch 115/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8321 - bpp: 1.3748 - mse: 2.9997e-04\n",
      "Epoch 115: loss improved from 3.95939 to 3.83212, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.8321 - bpp: 1.3748 - mse: 2.9997e-04\n",
      "Epoch 116/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9666 - bpp: 1.4043 - mse: 3.1278e-04\n",
      "Epoch 116: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 3.9666 - bpp: 1.4043 - mse: 3.1278e-04\n",
      "Epoch 117/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1317 - bpp: 1.3179 - mse: 3.4347e-04\n",
      "Epoch 117: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.1317 - bpp: 1.3179 - mse: 3.4347e-04\n",
      "Epoch 118/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3235 - bpp: 1.4182 - mse: 3.5465e-04\n",
      "Epoch 118: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 4.3235 - bpp: 1.4182 - mse: 3.5465e-04\n",
      "Epoch 119/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.7479 - bpp: 1.4418 - mse: 4.0357e-04\n",
      "Epoch 119: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.7479 - bpp: 1.4418 - mse: 4.0357e-04\n",
      "Epoch 120/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8468 - bpp: 1.3619 - mse: 3.0332e-04\n",
      "Epoch 120: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8468 - bpp: 1.3619 - mse: 3.0332e-04\n",
      "Epoch 121/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2484 - bpp: 1.4198 - mse: 3.4529e-04\n",
      "Epoch 121: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 4.2484 - bpp: 1.4198 - mse: 3.4529e-04\n",
      "Epoch 122/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1586 - bpp: 1.4102 - mse: 3.3550e-04\n",
      "Epoch 122: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 4.1586 - bpp: 1.4102 - mse: 3.3550e-04\n",
      "Epoch 123/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1355 - bpp: 1.3892 - mse: 3.3524e-04\n",
      "Epoch 123: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 4.1355 - bpp: 1.3892 - mse: 3.3524e-04\n",
      "Epoch 124/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8878 - bpp: 1.3332 - mse: 3.1184e-04\n",
      "Epoch 124: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8878 - bpp: 1.3332 - mse: 3.1184e-04\n",
      "Epoch 125/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1332 - bpp: 1.3812 - mse: 3.3594e-04\n",
      "Epoch 125: loss did not improve from 3.83212\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.1332 - bpp: 1.3812 - mse: 3.3594e-04\n",
      "Epoch 126/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8139 - bpp: 1.3055 - mse: 3.0621e-04\n",
      "Epoch 126: loss improved from 3.83212 to 3.81394, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 3.8139 - bpp: 1.3055 - mse: 3.0621e-04\n",
      "Epoch 127/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7710 - bpp: 1.3389 - mse: 2.9689e-04\n",
      "Epoch 127: loss improved from 3.81394 to 3.77097, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.7710 - bpp: 1.3389 - mse: 2.9689e-04\n",
      "Epoch 128/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8704 - bpp: 1.3689 - mse: 3.0536e-04\n",
      "Epoch 128: loss did not improve from 3.77097\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 3.8704 - bpp: 1.3689 - mse: 3.0536e-04\n",
      "Epoch 129/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3598 - bpp: 1.3596 - mse: 3.6623e-04\n",
      "Epoch 129: loss did not improve from 3.77097\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.3598 - bpp: 1.3596 - mse: 3.6623e-04\n",
      "Epoch 130/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6855 - bpp: 1.3067 - mse: 2.9038e-04\n",
      "Epoch 130: loss improved from 3.77097 to 3.68551, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 3.6855 - bpp: 1.3067 - mse: 2.9038e-04\n",
      "Epoch 131/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7533 - bpp: 1.3148 - mse: 2.9768e-04\n",
      "Epoch 131: loss did not improve from 3.68551\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 3.7533 - bpp: 1.3148 - mse: 2.9768e-04\n",
      "Epoch 132/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4738 - bpp: 1.2891 - mse: 2.6669e-04\n",
      "Epoch 132: loss improved from 3.68551 to 3.47382, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 3.4738 - bpp: 1.2891 - mse: 2.6669e-04\n",
      "Epoch 133/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6550 - bpp: 1.2896 - mse: 2.8875e-04\n",
      "Epoch 133: loss did not improve from 3.47382\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 3.6550 - bpp: 1.2896 - mse: 2.8875e-04\n",
      "Epoch 134/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4332 - bpp: 1.3104 - mse: 2.5913e-04\n",
      "Epoch 134: loss improved from 3.47382 to 3.43315, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 250ms/step - loss: 3.4332 - bpp: 1.3104 - mse: 2.5913e-04\n",
      "Epoch 135/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2599 - bpp: 1.3565 - mse: 3.5442e-04\n",
      "Epoch 135: loss did not improve from 3.43315\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 4.2599 - bpp: 1.3565 - mse: 3.5442e-04\n",
      "Epoch 136/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2557 - bpp: 1.2248 - mse: 2.4792e-04\n",
      "Epoch 136: loss improved from 3.43315 to 3.25573, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 3.2557 - bpp: 1.2248 - mse: 2.4792e-04\n",
      "Epoch 137/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5689 - bpp: 1.3048 - mse: 2.7638e-04\n",
      "Epoch 137: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 233ms/step - loss: 3.5689 - bpp: 1.3048 - mse: 2.7638e-04\n",
      "Epoch 138/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5748 - bpp: 1.3045 - mse: 2.7713e-04\n",
      "Epoch 138: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 3.5748 - bpp: 1.3045 - mse: 2.7713e-04\n",
      "Epoch 139/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3657 - bpp: 1.2215 - mse: 2.6174e-04\n",
      "Epoch 139: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 3.3657 - bpp: 1.2215 - mse: 2.6174e-04\n",
      "Epoch 140/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4913 - bpp: 1.2708 - mse: 2.7106e-04\n",
      "Epoch 140: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 3.4913 - bpp: 1.2708 - mse: 2.7106e-04\n",
      "Epoch 141/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1178 - bpp: 1.3376 - mse: 3.3939e-04\n",
      "Epoch 141: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 4.1178 - bpp: 1.3376 - mse: 3.3939e-04\n",
      "Epoch 142/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4045 - bpp: 1.2477 - mse: 2.6329e-04\n",
      "Epoch 142: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 3.4045 - bpp: 1.2477 - mse: 2.6329e-04\n",
      "Epoch 143/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5578 - bpp: 1.3101 - mse: 2.7438e-04\n",
      "Epoch 143: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 3.5578 - bpp: 1.3101 - mse: 2.7438e-04\n",
      "Epoch 144/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8983 - bpp: 1.3033 - mse: 3.1676e-04\n",
      "Epoch 144: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 3.8983 - bpp: 1.3033 - mse: 3.1676e-04\n",
      "Epoch 145/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8471 - bpp: 1.2781 - mse: 3.1360e-04\n",
      "Epoch 145: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 3.8471 - bpp: 1.2781 - mse: 3.1360e-04\n",
      "Epoch 146/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3340 - bpp: 1.2310 - mse: 2.5672e-04\n",
      "Epoch 146: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 232ms/step - loss: 3.3340 - bpp: 1.2310 - mse: 2.5672e-04\n",
      "Epoch 147/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3411 - bpp: 1.2784 - mse: 2.5179e-04\n",
      "Epoch 147: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 234ms/step - loss: 3.3411 - bpp: 1.2784 - mse: 2.5179e-04\n",
      "Epoch 148/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4418 - bpp: 1.2392 - mse: 2.6887e-04\n",
      "Epoch 148: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 3.4418 - bpp: 1.2392 - mse: 2.6887e-04\n",
      "Epoch 149/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4604 - bpp: 1.2655 - mse: 2.6793e-04\n",
      "Epoch 149: loss did not improve from 3.25573\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 3.4604 - bpp: 1.2655 - mse: 2.6793e-04\n",
      "Epoch 150/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2139 - bpp: 1.2040 - mse: 2.4535e-04\n",
      "Epoch 150: loss improved from 3.25573 to 3.21387, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 3.2139 - bpp: 1.2040 - mse: 2.4535e-04\n",
      "Epoch 151/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5037 - bpp: 1.2532 - mse: 2.7472e-04\n",
      "Epoch 151: loss did not improve from 3.21387\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.5037 - bpp: 1.2532 - mse: 2.7472e-04\n",
      "Epoch 152/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3258 - bpp: 1.2343 - mse: 2.5531e-04\n",
      "Epoch 152: loss did not improve from 3.21387\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 3.3258 - bpp: 1.2343 - mse: 2.5531e-04\n",
      "Epoch 153/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2633 - bpp: 1.2233 - mse: 2.4902e-04\n",
      "Epoch 153: loss did not improve from 3.21387\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 3.2633 - bpp: 1.2233 - mse: 2.4902e-04\n",
      "Epoch 154/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0230 - bpp: 1.2561 - mse: 2.1568e-04\n",
      "Epoch 154: loss improved from 3.21387 to 3.02295, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.0230 - bpp: 1.2561 - mse: 2.1568e-04\n",
      "Epoch 155/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0182 - bpp: 1.3135 - mse: 3.3017e-04\n",
      "Epoch 155: loss did not improve from 3.02295\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 4.0182 - bpp: 1.3135 - mse: 3.3017e-04\n",
      "Epoch 156/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0414 - bpp: 1.3148 - mse: 3.3284e-04\n",
      "Epoch 156: loss did not improve from 3.02295\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 4.0414 - bpp: 1.3148 - mse: 3.3284e-04\n",
      "Epoch 157/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6079 - bpp: 1.2502 - mse: 2.8780e-04\n",
      "Epoch 157: loss did not improve from 3.02295\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 3.6079 - bpp: 1.2502 - mse: 2.8780e-04\n",
      "Epoch 158/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9954 - bpp: 1.1954 - mse: 2.1972e-04\n",
      "Epoch 158: loss improved from 3.02295 to 2.99542, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 2.9954 - bpp: 1.1954 - mse: 2.1972e-04\n",
      "Epoch 159/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2879 - bpp: 1.2056 - mse: 2.5418e-04\n",
      "Epoch 159: loss did not improve from 2.99542\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 3.2879 - bpp: 1.2056 - mse: 2.5418e-04\n",
      "Epoch 160/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7399 - bpp: 1.2813 - mse: 3.0012e-04\n",
      "Epoch 160: loss did not improve from 2.99542\n",
      "100/100 [==============================] - 27s 258ms/step - loss: 3.7399 - bpp: 1.2813 - mse: 3.0012e-04\n",
      "Epoch 161/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8468 - bpp: 1.2954 - mse: 3.1145e-04\n",
      "Epoch 161: loss did not improve from 2.99542\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.8468 - bpp: 1.2954 - mse: 3.1145e-04\n",
      "Epoch 162/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7000 - bpp: 1.2791 - mse: 2.9552e-04\n",
      "Epoch 162: loss did not improve from 2.99542\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.7000 - bpp: 1.2791 - mse: 2.9552e-04\n",
      "Epoch 163/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3847 - bpp: 1.2460 - mse: 2.6107e-04\n",
      "Epoch 163: loss did not improve from 2.99542\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.3847 - bpp: 1.2460 - mse: 2.6107e-04\n",
      "Epoch 164/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7897 - bpp: 1.2007 - mse: 1.9396e-04\n",
      "Epoch 164: loss improved from 2.99542 to 2.78965, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.7897 - bpp: 1.2007 - mse: 1.9396e-04\n",
      "Epoch 165/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9592 - bpp: 1.1623 - mse: 2.1935e-04\n",
      "Epoch 165: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.9592 - bpp: 1.1623 - mse: 2.1935e-04\n",
      "Epoch 166/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4303 - bpp: 1.2335 - mse: 2.6816e-04\n",
      "Epoch 166: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 3.4303 - bpp: 1.2335 - mse: 2.6816e-04\n",
      "Epoch 167/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3006 - bpp: 1.2316 - mse: 2.5257e-04\n",
      "Epoch 167: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.3006 - bpp: 1.2316 - mse: 2.5257e-04\n",
      "Epoch 168/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3333 - bpp: 1.2376 - mse: 2.5582e-04\n",
      "Epoch 168: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.3333 - bpp: 1.2376 - mse: 2.5582e-04\n",
      "Epoch 169/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9278 - bpp: 1.1902 - mse: 2.1211e-04\n",
      "Epoch 169: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.9278 - bpp: 1.1902 - mse: 2.1211e-04\n",
      "Epoch 170/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3522 - bpp: 1.2698 - mse: 2.5419e-04\n",
      "Epoch 170: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 3.3522 - bpp: 1.2698 - mse: 2.5419e-04\n",
      "Epoch 171/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0633 - bpp: 1.1966 - mse: 2.2787e-04\n",
      "Epoch 171: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 3.0633 - bpp: 1.1966 - mse: 2.2787e-04\n",
      "Epoch 172/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6852 - bpp: 1.2614 - mse: 2.9587e-04\n",
      "Epoch 172: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 3.6852 - bpp: 1.2614 - mse: 2.9587e-04\n",
      "Epoch 173/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3680 - bpp: 1.2493 - mse: 2.5864e-04\n",
      "Epoch 173: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 242ms/step - loss: 3.3680 - bpp: 1.2493 - mse: 2.5864e-04\n",
      "Epoch 174/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6249 - bpp: 1.2521 - mse: 2.8965e-04\n",
      "Epoch 174: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 3.6249 - bpp: 1.2521 - mse: 2.8965e-04\n",
      "Epoch 175/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2388 - bpp: 1.2219 - mse: 2.4621e-04\n",
      "Epoch 175: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.2388 - bpp: 1.2219 - mse: 2.4621e-04\n",
      "Epoch 176/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9304 - bpp: 1.2095 - mse: 2.1007e-04\n",
      "Epoch 176: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.9304 - bpp: 1.2095 - mse: 2.1007e-04\n",
      "Epoch 177/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1530 - bpp: 1.1884 - mse: 2.3982e-04\n",
      "Epoch 177: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 3.1530 - bpp: 1.1884 - mse: 2.3982e-04\n",
      "Epoch 178/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8391 - bpp: 1.1832 - mse: 2.0214e-04\n",
      "Epoch 178: loss did not improve from 2.78965\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.8391 - bpp: 1.1832 - mse: 2.0214e-04\n",
      "Epoch 179/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7800 - bpp: 1.1503 - mse: 1.9894e-04\n",
      "Epoch 179: loss improved from 2.78965 to 2.77999, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.7800 - bpp: 1.1503 - mse: 1.9894e-04\n",
      "Epoch 180/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4074 - bpp: 1.2719 - mse: 2.6069e-04\n",
      "Epoch 180: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 3.4074 - bpp: 1.2719 - mse: 2.6069e-04\n",
      "Epoch 181/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8829 - bpp: 1.1942 - mse: 2.0615e-04\n",
      "Epoch 181: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.8829 - bpp: 1.1942 - mse: 2.0615e-04\n",
      "Epoch 182/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.9479 - bpp: 1.3722 - mse: 8.0269e-04\n",
      "Epoch 182: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 7.9479 - bpp: 1.3722 - mse: 8.0269e-04\n",
      "Epoch 183/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 17.7938 - bpp: 1.6190 - mse: 0.0020\n",
      "Epoch 183: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 17.7938 - bpp: 1.6190 - mse: 0.0020\n",
      "Epoch 184/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.9579 - bpp: 1.4449 - mse: 4.2884e-04\n",
      "Epoch 184: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 4.9579 - bpp: 1.4449 - mse: 4.2884e-04\n",
      "Epoch 185/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8437 - bpp: 1.3039 - mse: 3.1004e-04\n",
      "Epoch 185: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 3.8437 - bpp: 1.3039 - mse: 3.1004e-04\n",
      "Epoch 186/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1948 - bpp: 1.1917 - mse: 2.4451e-04\n",
      "Epoch 186: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 3.1948 - bpp: 1.1917 - mse: 2.4451e-04\n",
      "Epoch 187/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9022 - bpp: 1.2096 - mse: 2.0661e-04\n",
      "Epoch 187: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.9022 - bpp: 1.2096 - mse: 2.0661e-04\n",
      "Epoch 188/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7219 - bpp: 1.2830 - mse: 2.9771e-04\n",
      "Epoch 188: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 3.7219 - bpp: 1.2830 - mse: 2.9771e-04\n",
      "Epoch 189/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3344 - bpp: 1.2478 - mse: 2.5471e-04\n",
      "Epoch 189: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 3.3344 - bpp: 1.2478 - mse: 2.5471e-04\n",
      "Epoch 190/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8945 - bpp: 1.2253 - mse: 2.0376e-04\n",
      "Epoch 190: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 27s 258ms/step - loss: 2.8945 - bpp: 1.2253 - mse: 2.0376e-04\n",
      "Epoch 191/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0666 - bpp: 1.2042 - mse: 2.2734e-04\n",
      "Epoch 191: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 3.0666 - bpp: 1.2042 - mse: 2.2734e-04\n",
      "Epoch 192/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2174 - bpp: 1.2586 - mse: 2.3912e-04\n",
      "Epoch 192: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 3.2174 - bpp: 1.2586 - mse: 2.3912e-04\n",
      "Epoch 193/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2630 - bpp: 1.2723 - mse: 2.4301e-04\n",
      "Epoch 193: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.2630 - bpp: 1.2723 - mse: 2.4301e-04\n",
      "Epoch 194/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1054 - bpp: 1.2184 - mse: 2.3034e-04\n",
      "Epoch 194: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 3.1054 - bpp: 1.2184 - mse: 2.3034e-04\n",
      "Epoch 195/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7875 - bpp: 1.1741 - mse: 1.9694e-04\n",
      "Epoch 195: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.7875 - bpp: 1.1741 - mse: 1.9694e-04\n",
      "Epoch 196/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2296 - bpp: 1.2663 - mse: 2.3966e-04\n",
      "Epoch 196: loss did not improve from 2.77999\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 3.2296 - bpp: 1.2663 - mse: 2.3966e-04\n",
      "Epoch 197/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7056 - bpp: 1.1350 - mse: 1.9172e-04\n",
      "Epoch 197: loss improved from 2.77999 to 2.70556, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 2.7056 - bpp: 1.1350 - mse: 1.9172e-04\n",
      "Epoch 198/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 16.6715 - bpp: 1.3873 - mse: 0.0019\n",
      "Epoch 198: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 16.6715 - bpp: 1.3873 - mse: 0.0019\n",
      "Epoch 199/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.0398 - bpp: 1.6350 - mse: 0.0010\n",
      "Epoch 199: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 10.0398 - bpp: 1.6350 - mse: 0.0010\n",
      "Epoch 200/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0419 - bpp: 1.4054 - mse: 3.2184e-04\n",
      "Epoch 200: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 4.0419 - bpp: 1.4054 - mse: 3.2184e-04\n",
      "Epoch 201/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.5573 - bpp: 1.4486 - mse: 3.7949e-04\n",
      "Epoch 201: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 4.5573 - bpp: 1.4486 - mse: 3.7949e-04\n",
      "Epoch 202/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5275 - bpp: 1.3214 - mse: 2.6930e-04\n",
      "Epoch 202: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.5275 - bpp: 1.3214 - mse: 2.6930e-04\n",
      "Epoch 203/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6203 - bpp: 1.3358 - mse: 2.7887e-04\n",
      "Epoch 203: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.6203 - bpp: 1.3358 - mse: 2.7887e-04\n",
      "Epoch 204/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4552 - bpp: 1.2921 - mse: 2.6405e-04\n",
      "Epoch 204: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 25s 243ms/step - loss: 3.4552 - bpp: 1.2921 - mse: 2.6405e-04\n",
      "Epoch 205/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8908 - bpp: 1.3639 - mse: 3.0846e-04\n",
      "Epoch 205: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 3.8908 - bpp: 1.3639 - mse: 3.0846e-04\n",
      "Epoch 206/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7489 - bpp: 1.3421 - mse: 2.9380e-04\n",
      "Epoch 206: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.7489 - bpp: 1.3421 - mse: 2.9380e-04\n",
      "Epoch 207/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0327 - bpp: 1.2185 - mse: 2.2146e-04\n",
      "Epoch 207: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 3.0327 - bpp: 1.2185 - mse: 2.2146e-04\n",
      "Epoch 208/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4315 - bpp: 1.3090 - mse: 2.5910e-04\n",
      "Epoch 208: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 3.4315 - bpp: 1.3090 - mse: 2.5910e-04\n",
      "Epoch 209/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3877 - bpp: 1.2496 - mse: 2.6100e-04\n",
      "Epoch 209: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 3.3877 - bpp: 1.2496 - mse: 2.6100e-04\n",
      "Epoch 210/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2099 - bpp: 1.2960 - mse: 2.3363e-04\n",
      "Epoch 210: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.2099 - bpp: 1.2960 - mse: 2.3363e-04\n",
      "Epoch 211/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9734 - bpp: 1.2399 - mse: 2.1160e-04\n",
      "Epoch 211: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.9734 - bpp: 1.2399 - mse: 2.1160e-04\n",
      "Epoch 212/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1463 - bpp: 1.2622 - mse: 2.2999e-04\n",
      "Epoch 212: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 3.1463 - bpp: 1.2622 - mse: 2.2999e-04\n",
      "Epoch 213/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2657 - bpp: 1.3141 - mse: 2.3823e-04\n",
      "Epoch 213: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.2657 - bpp: 1.3141 - mse: 2.3823e-04\n",
      "Epoch 214/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2681 - bpp: 1.2892 - mse: 2.4156e-04\n",
      "Epoch 214: loss did not improve from 2.70556\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.2681 - bpp: 1.2892 - mse: 2.4156e-04\n",
      "Epoch 215/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6358 - bpp: 1.1534 - mse: 1.8095e-04\n",
      "Epoch 215: loss improved from 2.70556 to 2.63576, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.6358 - bpp: 1.1534 - mse: 1.8095e-04\n",
      "Epoch 216/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0166 - bpp: 1.2123 - mse: 2.2024e-04\n",
      "Epoch 216: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 3.0166 - bpp: 1.2123 - mse: 2.2024e-04\n",
      "Epoch 217/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2213 - bpp: 1.2717 - mse: 2.3799e-04\n",
      "Epoch 217: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 3.2213 - bpp: 1.2717 - mse: 2.3799e-04\n",
      "Epoch 218/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2516 - bpp: 1.2845 - mse: 2.4013e-04\n",
      "Epoch 218: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.2516 - bpp: 1.2845 - mse: 2.4013e-04\n",
      "Epoch 219/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0136 - bpp: 1.2412 - mse: 2.1636e-04\n",
      "Epoch 219: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.0136 - bpp: 1.2412 - mse: 2.1636e-04\n",
      "Epoch 220/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7167 - bpp: 1.1690 - mse: 1.8892e-04\n",
      "Epoch 220: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.7167 - bpp: 1.1690 - mse: 1.8892e-04\n",
      "Epoch 221/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7500 - bpp: 1.1960 - mse: 1.8970e-04\n",
      "Epoch 221: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.7500 - bpp: 1.1960 - mse: 1.8970e-04\n",
      "Epoch 222/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8687 - bpp: 1.2235 - mse: 2.0083e-04\n",
      "Epoch 222: loss did not improve from 2.63576\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.8687 - bpp: 1.2235 - mse: 2.0083e-04\n",
      "Epoch 223/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4720 - bpp: 1.1512 - mse: 1.6124e-04\n",
      "Epoch 223: loss improved from 2.63576 to 2.47202, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 2.4720 - bpp: 1.1512 - mse: 1.6124e-04\n",
      "Epoch 224/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2044 - bpp: 1.2670 - mse: 2.3650e-04\n",
      "Epoch 224: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 3.2044 - bpp: 1.2670 - mse: 2.3650e-04\n",
      "Epoch 225/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9919 - bpp: 1.1858 - mse: 2.2047e-04\n",
      "Epoch 225: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 2.9919 - bpp: 1.1858 - mse: 2.2047e-04\n",
      "Epoch 226/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8478 - bpp: 1.2188 - mse: 1.9885e-04\n",
      "Epoch 226: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.8478 - bpp: 1.2188 - mse: 1.9885e-04\n",
      "Epoch 227/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9919 - bpp: 1.2019 - mse: 2.1850e-04\n",
      "Epoch 227: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.9919 - bpp: 1.2019 - mse: 2.1850e-04\n",
      "Epoch 228/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9593 - bpp: 1.1809 - mse: 2.1710e-04\n",
      "Epoch 228: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.9593 - bpp: 1.1809 - mse: 2.1710e-04\n",
      "Epoch 229/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3039 - bpp: 1.2774 - mse: 2.4737e-04\n",
      "Epoch 229: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 3.3039 - bpp: 1.2774 - mse: 2.4737e-04\n",
      "Epoch 230/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9635 - bpp: 1.2135 - mse: 2.1363e-04\n",
      "Epoch 230: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.9635 - bpp: 1.2135 - mse: 2.1363e-04\n",
      "Epoch 231/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9054 - bpp: 1.2060 - mse: 2.0744e-04\n",
      "Epoch 231: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.9054 - bpp: 1.2060 - mse: 2.0744e-04\n",
      "Epoch 232/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8140 - bpp: 1.1905 - mse: 1.9818e-04\n",
      "Epoch 232: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.8140 - bpp: 1.1905 - mse: 1.9818e-04\n",
      "Epoch 233/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7243 - bpp: 1.1682 - mse: 1.8996e-04\n",
      "Epoch 233: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.7243 - bpp: 1.1682 - mse: 1.8996e-04\n",
      "Epoch 234/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0564 - bpp: 1.2420 - mse: 2.2149e-04\n",
      "Epoch 234: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 3.0564 - bpp: 1.2420 - mse: 2.2149e-04\n",
      "Epoch 235/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2834 - bpp: 1.2706 - mse: 2.4570e-04\n",
      "Epoch 235: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 3.2834 - bpp: 1.2706 - mse: 2.4570e-04\n",
      "Epoch 236/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8845 - bpp: 1.2240 - mse: 2.0271e-04\n",
      "Epoch 236: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.8845 - bpp: 1.2240 - mse: 2.0271e-04\n",
      "Epoch 237/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0504 - bpp: 1.2465 - mse: 2.2020e-04\n",
      "Epoch 237: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 3.0504 - bpp: 1.2465 - mse: 2.2020e-04\n",
      "Epoch 238/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7499 - bpp: 1.1686 - mse: 1.9304e-04\n",
      "Epoch 238: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.7499 - bpp: 1.1686 - mse: 1.9304e-04\n",
      "Epoch 239/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8356 - bpp: 1.2009 - mse: 1.9955e-04\n",
      "Epoch 239: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.8356 - bpp: 1.2009 - mse: 1.9955e-04\n",
      "Epoch 240/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8865 - bpp: 1.1757 - mse: 2.0884e-04\n",
      "Epoch 240: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.8865 - bpp: 1.1757 - mse: 2.0884e-04\n",
      "Epoch 241/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0636 - bpp: 1.2063 - mse: 2.2672e-04\n",
      "Epoch 241: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.0636 - bpp: 1.2063 - mse: 2.2672e-04\n",
      "Epoch 242/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7157 - bpp: 1.1539 - mse: 1.9065e-04\n",
      "Epoch 242: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.7157 - bpp: 1.1539 - mse: 1.9065e-04\n",
      "Epoch 243/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7316 - bpp: 1.1783 - mse: 1.8961e-04\n",
      "Epoch 243: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 2.7316 - bpp: 1.1783 - mse: 1.8961e-04\n",
      "Epoch 244/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1141 - bpp: 1.2204 - mse: 2.3116e-04\n",
      "Epoch 244: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 3.1141 - bpp: 1.2204 - mse: 2.3116e-04\n",
      "Epoch 245/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8109 - bpp: 1.1604 - mse: 2.0148e-04\n",
      "Epoch 245: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.8109 - bpp: 1.1604 - mse: 2.0148e-04\n",
      "Epoch 246/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6774 - bpp: 1.1670 - mse: 1.8437e-04\n",
      "Epoch 246: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.6774 - bpp: 1.1670 - mse: 1.8437e-04\n",
      "Epoch 247/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8995 - bpp: 1.2286 - mse: 2.0396e-04\n",
      "Epoch 247: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.8995 - bpp: 1.2286 - mse: 2.0396e-04\n",
      "Epoch 248/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5775 - bpp: 1.1531 - mse: 1.7388e-04\n",
      "Epoch 248: loss did not improve from 2.47202\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.5775 - bpp: 1.1531 - mse: 1.7388e-04\n",
      "Epoch 249/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4326 - bpp: 1.1032 - mse: 1.6228e-04\n",
      "Epoch 249: loss improved from 2.47202 to 2.43259, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 2.4326 - bpp: 1.1032 - mse: 1.6228e-04\n",
      "Epoch 250/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0004 - bpp: 1.2022 - mse: 2.1950e-04\n",
      "Epoch 250: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 3.0004 - bpp: 1.2022 - mse: 2.1950e-04\n",
      "Epoch 251/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5531 - bpp: 1.1479 - mse: 1.7153e-04\n",
      "Epoch 251: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.5531 - bpp: 1.1479 - mse: 1.7153e-04\n",
      "Epoch 252/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.4402 - bpp: 1.4080 - mse: 9.8049e-04\n",
      "Epoch 252: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 9.4402 - bpp: 1.4080 - mse: 9.8049e-04\n",
      "Epoch 253/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.1953 - bpp: 1.3628 - mse: 7.1197e-04\n",
      "Epoch 253: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 7.1953 - bpp: 1.3628 - mse: 7.1197e-04\n",
      "Epoch 254/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8775 - bpp: 1.3318 - mse: 3.1076e-04\n",
      "Epoch 254: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.8775 - bpp: 1.3318 - mse: 3.1076e-04\n",
      "Epoch 255/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3463 - bpp: 1.2280 - mse: 2.5858e-04\n",
      "Epoch 255: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 3.3463 - bpp: 1.2280 - mse: 2.5858e-04\n",
      "Epoch 256/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7473 - bpp: 1.3360 - mse: 2.9435e-04\n",
      "Epoch 256: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 3.7473 - bpp: 1.3360 - mse: 2.9435e-04\n",
      "Epoch 257/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0774 - bpp: 1.2709 - mse: 2.2053e-04\n",
      "Epoch 257: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.0774 - bpp: 1.2709 - mse: 2.2053e-04\n",
      "Epoch 258/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7186 - bpp: 1.1528 - mse: 1.9113e-04\n",
      "Epoch 258: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.7186 - bpp: 1.1528 - mse: 1.9113e-04\n",
      "Epoch 259/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3743 - bpp: 1.2978 - mse: 2.5347e-04\n",
      "Epoch 259: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 3.3743 - bpp: 1.2978 - mse: 2.5347e-04\n",
      "Epoch 260/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9248 - bpp: 1.1932 - mse: 2.1137e-04\n",
      "Epoch 260: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.9248 - bpp: 1.1932 - mse: 2.1137e-04\n",
      "Epoch 261/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7042 - bpp: 1.1662 - mse: 1.8774e-04\n",
      "Epoch 261: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.7042 - bpp: 1.1662 - mse: 1.8774e-04\n",
      "Epoch 262/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5623 - bpp: 1.1441 - mse: 1.7312e-04\n",
      "Epoch 262: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.5623 - bpp: 1.1441 - mse: 1.7312e-04\n",
      "Epoch 263/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7466 - bpp: 1.1683 - mse: 1.9267e-04\n",
      "Epoch 263: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.7466 - bpp: 1.1683 - mse: 1.9267e-04\n",
      "Epoch 264/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8187 - bpp: 1.1907 - mse: 1.9873e-04\n",
      "Epoch 264: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.8187 - bpp: 1.1907 - mse: 1.9873e-04\n",
      "Epoch 265/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9785 - bpp: 1.2117 - mse: 2.1567e-04\n",
      "Epoch 265: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.9785 - bpp: 1.2117 - mse: 2.1567e-04\n",
      "Epoch 266/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8944 - bpp: 1.2289 - mse: 2.0331e-04\n",
      "Epoch 266: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.8944 - bpp: 1.2289 - mse: 2.0331e-04\n",
      "Epoch 267/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7089 - bpp: 1.1264 - mse: 1.9318e-04\n",
      "Epoch 267: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 2.7089 - bpp: 1.1264 - mse: 1.9318e-04\n",
      "Epoch 268/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0705 - bpp: 1.2506 - mse: 2.2216e-04\n",
      "Epoch 268: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 3.0705 - bpp: 1.2506 - mse: 2.2216e-04\n",
      "Epoch 269/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8117 - bpp: 1.1635 - mse: 2.0119e-04\n",
      "Epoch 269: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.8117 - bpp: 1.1635 - mse: 2.0119e-04\n",
      "Epoch 270/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9391 - bpp: 1.1984 - mse: 2.1249e-04\n",
      "Epoch 270: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.9391 - bpp: 1.1984 - mse: 2.1249e-04\n",
      "Epoch 271/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6773 - bpp: 1.1605 - mse: 1.8515e-04\n",
      "Epoch 271: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.6773 - bpp: 1.1605 - mse: 1.8515e-04\n",
      "Epoch 272/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7853 - bpp: 1.1981 - mse: 1.9375e-04\n",
      "Epoch 272: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.7853 - bpp: 1.1981 - mse: 1.9375e-04\n",
      "Epoch 273/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5563 - bpp: 1.1489 - mse: 1.7180e-04\n",
      "Epoch 273: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.5563 - bpp: 1.1489 - mse: 1.7180e-04\n",
      "Epoch 274/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5087 - bpp: 1.0809 - mse: 1.7429e-04\n",
      "Epoch 274: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.5087 - bpp: 1.0809 - mse: 1.7429e-04\n",
      "Epoch 275/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5860 - bpp: 1.1570 - mse: 1.7444e-04\n",
      "Epoch 275: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.5860 - bpp: 1.1570 - mse: 1.7444e-04\n",
      "Epoch 276/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5775 - bpp: 1.1167 - mse: 1.7832e-04\n",
      "Epoch 276: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.5775 - bpp: 1.1167 - mse: 1.7832e-04\n",
      "Epoch 277/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8275 - bpp: 1.1572 - mse: 2.0390e-04\n",
      "Epoch 277: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.8275 - bpp: 1.1572 - mse: 2.0390e-04\n",
      "Epoch 278/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3168 - bpp: 1.2583 - mse: 2.5129e-04\n",
      "Epoch 278: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 3.3168 - bpp: 1.2583 - mse: 2.5129e-04\n",
      "Epoch 279/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7941 - bpp: 1.1600 - mse: 1.9948e-04\n",
      "Epoch 279: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.7941 - bpp: 1.1600 - mse: 1.9948e-04\n",
      "Epoch 280/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8199 - bpp: 1.1679 - mse: 2.0165e-04\n",
      "Epoch 280: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.8199 - bpp: 1.1679 - mse: 2.0165e-04\n",
      "Epoch 281/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7112 - bpp: 1.1641 - mse: 1.8885e-04\n",
      "Epoch 281: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.7112 - bpp: 1.1641 - mse: 1.8885e-04\n",
      "Epoch 282/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6480 - bpp: 1.1556 - mse: 1.8218e-04\n",
      "Epoch 282: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.6480 - bpp: 1.1556 - mse: 1.8218e-04\n",
      "Epoch 283/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6150 - bpp: 1.1596 - mse: 1.7767e-04\n",
      "Epoch 283: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.6150 - bpp: 1.1596 - mse: 1.7767e-04\n",
      "Epoch 284/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5506 - bpp: 1.1454 - mse: 1.7154e-04\n",
      "Epoch 284: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.5506 - bpp: 1.1454 - mse: 1.7154e-04\n",
      "Epoch 285/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6760 - bpp: 1.1565 - mse: 1.8549e-04\n",
      "Epoch 285: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.6760 - bpp: 1.1565 - mse: 1.8549e-04\n",
      "Epoch 286/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6043 - bpp: 1.1360 - mse: 1.7924e-04\n",
      "Epoch 286: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.6043 - bpp: 1.1360 - mse: 1.7924e-04\n",
      "Epoch 287/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5036 - bpp: 1.1226 - mse: 1.6858e-04\n",
      "Epoch 287: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.5036 - bpp: 1.1226 - mse: 1.6858e-04\n",
      "Epoch 288/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8346 - bpp: 1.1740 - mse: 2.0271e-04\n",
      "Epoch 288: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.8346 - bpp: 1.1740 - mse: 2.0271e-04\n",
      "Epoch 289/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9854 - bpp: 1.2950 - mse: 3.2841e-04\n",
      "Epoch 289: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.9854 - bpp: 1.2950 - mse: 3.2841e-04\n",
      "Epoch 290/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3827 - bpp: 1.2734 - mse: 2.5749e-04\n",
      "Epoch 290: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 3.3827 - bpp: 1.2734 - mse: 2.5749e-04\n",
      "Epoch 291/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6174 - bpp: 1.1087 - mse: 1.8417e-04\n",
      "Epoch 291: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.6174 - bpp: 1.1087 - mse: 1.8417e-04\n",
      "Epoch 292/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9521 - bpp: 1.2528 - mse: 2.0744e-04\n",
      "Epoch 292: loss did not improve from 2.43259\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.9521 - bpp: 1.2528 - mse: 2.0744e-04\n",
      "Epoch 293/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4061 - bpp: 1.1153 - mse: 1.5757e-04\n",
      "Epoch 293: loss improved from 2.43259 to 2.40608, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.4061 - bpp: 1.1153 - mse: 1.5757e-04\n",
      "Epoch 294/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7714 - bpp: 1.1619 - mse: 1.9646e-04\n",
      "Epoch 294: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.7714 - bpp: 1.1619 - mse: 1.9646e-04\n",
      "Epoch 295/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5414 - bpp: 1.1153 - mse: 1.7408e-04\n",
      "Epoch 295: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 29s 280ms/step - loss: 2.5414 - bpp: 1.1153 - mse: 1.7408e-04\n",
      "Epoch 296/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7010 - bpp: 1.1558 - mse: 1.8863e-04\n",
      "Epoch 296: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 27s 259ms/step - loss: 2.7010 - bpp: 1.1558 - mse: 1.8863e-04\n",
      "Epoch 297/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6404 - bpp: 1.1384 - mse: 1.8335e-04\n",
      "Epoch 297: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.6404 - bpp: 1.1384 - mse: 1.8335e-04\n",
      "Epoch 298/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5767 - bpp: 1.1495 - mse: 1.7422e-04\n",
      "Epoch 298: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.5767 - bpp: 1.1495 - mse: 1.7422e-04\n",
      "Epoch 299/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8169 - bpp: 1.1948 - mse: 1.9801e-04\n",
      "Epoch 299: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.8169 - bpp: 1.1948 - mse: 1.9801e-04\n",
      "Epoch 300/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4742 - bpp: 1.1216 - mse: 1.6511e-04\n",
      "Epoch 300: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4742 - bpp: 1.1216 - mse: 1.6511e-04\n",
      "Epoch 301/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7450 - bpp: 1.1253 - mse: 1.9772e-04\n",
      "Epoch 301: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.7450 - bpp: 1.1253 - mse: 1.9772e-04\n",
      "Epoch 302/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5142 - bpp: 1.1436 - mse: 1.6731e-04\n",
      "Epoch 302: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.5142 - bpp: 1.1436 - mse: 1.6731e-04\n",
      "Epoch 303/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6985 - bpp: 1.1429 - mse: 1.8989e-04\n",
      "Epoch 303: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 2.6985 - bpp: 1.1429 - mse: 1.8989e-04\n",
      "Epoch 304/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5666 - bpp: 1.1231 - mse: 1.7621e-04\n",
      "Epoch 304: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.5666 - bpp: 1.1231 - mse: 1.7621e-04\n",
      "Epoch 305/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0396 - bpp: 1.1596 - mse: 2.2948e-04\n",
      "Epoch 305: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 3.0396 - bpp: 1.1596 - mse: 2.2948e-04\n",
      "Epoch 306/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0472 - bpp: 1.2058 - mse: 2.2478e-04\n",
      "Epoch 306: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 3.0472 - bpp: 1.2058 - mse: 2.2478e-04\n",
      "Epoch 307/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4181 - bpp: 1.0648 - mse: 1.6519e-04\n",
      "Epoch 307: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.4181 - bpp: 1.0648 - mse: 1.6519e-04\n",
      "Epoch 308/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4143 - bpp: 1.0965 - mse: 1.6086e-04\n",
      "Epoch 308: loss did not improve from 2.40608\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.4143 - bpp: 1.0965 - mse: 1.6086e-04\n",
      "Epoch 309/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3883 - bpp: 1.1065 - mse: 1.5647e-04\n",
      "Epoch 309: loss improved from 2.40608 to 2.38830, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.3883 - bpp: 1.1065 - mse: 1.5647e-04\n",
      "Epoch 310/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4983 - bpp: 1.1227 - mse: 1.6792e-04\n",
      "Epoch 310: loss did not improve from 2.38830\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4983 - bpp: 1.1227 - mse: 1.6792e-04\n",
      "Epoch 311/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1571 - bpp: 1.0260 - mse: 1.3806e-04\n",
      "Epoch 311: loss improved from 2.38830 to 2.15706, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 2.1571 - bpp: 1.0260 - mse: 1.3806e-04\n",
      "Epoch 312/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6064 - bpp: 1.3618 - mse: 5.1814e-04\n",
      "Epoch 312: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 5.6064 - bpp: 1.3618 - mse: 5.1814e-04\n",
      "Epoch 313/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0184 - bpp: 1.2803 - mse: 2.1217e-04\n",
      "Epoch 313: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 3.0184 - bpp: 1.2803 - mse: 2.1217e-04\n",
      "Epoch 314/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2127 - bpp: 1.2594 - mse: 2.3845e-04\n",
      "Epoch 314: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 3.2127 - bpp: 1.2594 - mse: 2.3845e-04\n",
      "Epoch 315/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5591 - bpp: 1.1604 - mse: 1.7073e-04\n",
      "Epoch 315: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.5591 - bpp: 1.1604 - mse: 1.7073e-04\n",
      "Epoch 316/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7901 - bpp: 1.1747 - mse: 1.9720e-04\n",
      "Epoch 316: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.7901 - bpp: 1.1747 - mse: 1.9720e-04\n",
      "Epoch 317/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6099 - bpp: 1.1638 - mse: 1.7653e-04\n",
      "Epoch 317: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.6099 - bpp: 1.1638 - mse: 1.7653e-04\n",
      "Epoch 318/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6618 - bpp: 1.1732 - mse: 1.8171e-04\n",
      "Epoch 318: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 2.6618 - bpp: 1.1732 - mse: 1.8171e-04\n",
      "Epoch 319/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3439 - bpp: 1.0897 - mse: 1.5310e-04\n",
      "Epoch 319: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.3439 - bpp: 1.0897 - mse: 1.5310e-04\n",
      "Epoch 320/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4252 - bpp: 1.1231 - mse: 1.5894e-04\n",
      "Epoch 320: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 259ms/step - loss: 2.4252 - bpp: 1.1231 - mse: 1.5894e-04\n",
      "Epoch 321/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3480 - bpp: 1.0858 - mse: 1.5408e-04\n",
      "Epoch 321: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.3480 - bpp: 1.0858 - mse: 1.5408e-04\n",
      "Epoch 322/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6547 - bpp: 1.1662 - mse: 1.8170e-04\n",
      "Epoch 322: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.6547 - bpp: 1.1662 - mse: 1.8170e-04\n",
      "Epoch 323/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5661 - bpp: 1.1716 - mse: 1.7022e-04\n",
      "Epoch 323: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.5661 - bpp: 1.1716 - mse: 1.7022e-04\n",
      "Epoch 324/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4415 - bpp: 1.0892 - mse: 1.6507e-04\n",
      "Epoch 324: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4415 - bpp: 1.0892 - mse: 1.6507e-04\n",
      "Epoch 325/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6486 - bpp: 1.1654 - mse: 1.8105e-04\n",
      "Epoch 325: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.6486 - bpp: 1.1654 - mse: 1.8105e-04\n",
      "Epoch 326/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4774 - bpp: 1.1025 - mse: 1.6783e-04\n",
      "Epoch 326: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.4774 - bpp: 1.1025 - mse: 1.6783e-04\n",
      "Epoch 327/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4741 - bpp: 1.1004 - mse: 1.6769e-04\n",
      "Epoch 327: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4741 - bpp: 1.1004 - mse: 1.6769e-04\n",
      "Epoch 328/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2619 - bpp: 1.0544 - mse: 1.4739e-04\n",
      "Epoch 328: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.2619 - bpp: 1.0544 - mse: 1.4739e-04\n",
      "Epoch 329/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5696 - bpp: 1.1454 - mse: 1.7386e-04\n",
      "Epoch 329: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.5696 - bpp: 1.1454 - mse: 1.7386e-04\n",
      "Epoch 330/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7981 - bpp: 1.1822 - mse: 1.9725e-04\n",
      "Epoch 330: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.7981 - bpp: 1.1822 - mse: 1.9725e-04\n",
      "Epoch 331/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4218 - bpp: 1.0847 - mse: 1.6323e-04\n",
      "Epoch 331: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.4218 - bpp: 1.0847 - mse: 1.6323e-04\n",
      "Epoch 332/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4809 - bpp: 1.1003 - mse: 1.6852e-04\n",
      "Epoch 332: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.4809 - bpp: 1.1003 - mse: 1.6852e-04\n",
      "Epoch 333/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2597 - bpp: 1.0524 - mse: 1.4738e-04\n",
      "Epoch 333: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.2597 - bpp: 1.0524 - mse: 1.4738e-04\n",
      "Epoch 334/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2352 - bpp: 1.0690 - mse: 1.4236e-04\n",
      "Epoch 334: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.2352 - bpp: 1.0690 - mse: 1.4236e-04\n",
      "Epoch 335/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4213 - bpp: 1.1145 - mse: 1.5953e-04\n",
      "Epoch 335: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 2.4213 - bpp: 1.1145 - mse: 1.5953e-04\n",
      "Epoch 336/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5467 - bpp: 1.1222 - mse: 1.7389e-04\n",
      "Epoch 336: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.5467 - bpp: 1.1222 - mse: 1.7389e-04\n",
      "Epoch 337/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5567 - bpp: 1.1189 - mse: 1.7552e-04\n",
      "Epoch 337: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.5567 - bpp: 1.1189 - mse: 1.7552e-04\n",
      "Epoch 338/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5534 - bpp: 1.1333 - mse: 1.7334e-04\n",
      "Epoch 338: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.5534 - bpp: 1.1333 - mse: 1.7334e-04\n",
      "Epoch 339/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4061 - bpp: 1.0901 - mse: 1.6065e-04\n",
      "Epoch 339: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.4061 - bpp: 1.0901 - mse: 1.6065e-04\n",
      "Epoch 340/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4430 - bpp: 1.1147 - mse: 1.6215e-04\n",
      "Epoch 340: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.4430 - bpp: 1.1147 - mse: 1.6215e-04\n",
      "Epoch 341/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2556 - bpp: 1.0570 - mse: 1.4631e-04\n",
      "Epoch 341: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.2556 - bpp: 1.0570 - mse: 1.4631e-04\n",
      "Epoch 342/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3227 - bpp: 1.0621 - mse: 1.5388e-04\n",
      "Epoch 342: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.3227 - bpp: 1.0621 - mse: 1.5388e-04\n",
      "Epoch 343/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2166 - bpp: 1.0599 - mse: 1.4120e-04\n",
      "Epoch 343: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.2166 - bpp: 1.0599 - mse: 1.4120e-04\n",
      "Epoch 344/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4261 - bpp: 1.1181 - mse: 1.5967e-04\n",
      "Epoch 344: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.4261 - bpp: 1.1181 - mse: 1.5967e-04\n",
      "Epoch 345/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4345 - bpp: 1.0858 - mse: 1.6463e-04\n",
      "Epoch 345: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.4345 - bpp: 1.0858 - mse: 1.6463e-04\n",
      "Epoch 346/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6109 - bpp: 1.1253 - mse: 1.8135e-04\n",
      "Epoch 346: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.6109 - bpp: 1.1253 - mse: 1.8135e-04\n",
      "Epoch 347/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4044 - bpp: 1.0604 - mse: 1.6406e-04\n",
      "Epoch 347: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.4044 - bpp: 1.0604 - mse: 1.6406e-04\n",
      "Epoch 348/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3524 - bpp: 1.0847 - mse: 1.5476e-04\n",
      "Epoch 348: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.3524 - bpp: 1.0847 - mse: 1.5476e-04\n",
      "Epoch 349/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7461 - bpp: 1.1682 - mse: 1.9261e-04\n",
      "Epoch 349: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.7461 - bpp: 1.1682 - mse: 1.9261e-04\n",
      "Epoch 350/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2567 - bpp: 1.0530 - mse: 1.4693e-04\n",
      "Epoch 350: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.2567 - bpp: 1.0530 - mse: 1.4693e-04\n",
      "Epoch 351/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5566 - bpp: 1.1125 - mse: 1.7628e-04\n",
      "Epoch 351: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.5566 - bpp: 1.1125 - mse: 1.7628e-04\n",
      "Epoch 352/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4186 - bpp: 1.1042 - mse: 1.6046e-04\n",
      "Epoch 352: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4186 - bpp: 1.1042 - mse: 1.6046e-04\n",
      "Epoch 353/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2936 - bpp: 1.0562 - mse: 1.5105e-04\n",
      "Epoch 353: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.2936 - bpp: 1.0562 - mse: 1.5105e-04\n",
      "Epoch 354/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3217 - bpp: 1.0260 - mse: 1.5817e-04\n",
      "Epoch 354: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.3217 - bpp: 1.0260 - mse: 1.5817e-04\n",
      "Epoch 355/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3790 - bpp: 1.0572 - mse: 1.6136e-04\n",
      "Epoch 355: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.3790 - bpp: 1.0572 - mse: 1.6136e-04\n",
      "Epoch 356/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5568 - bpp: 1.1176 - mse: 1.7569e-04\n",
      "Epoch 356: loss did not improve from 2.15706\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.5568 - bpp: 1.1176 - mse: 1.7569e-04\n",
      "Epoch 357/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0551 - bpp: 0.9993 - mse: 1.2888e-04\n",
      "Epoch 357: loss improved from 2.15706 to 2.05507, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 2.0551 - bpp: 0.9993 - mse: 1.2888e-04\n",
      "Epoch 358/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3411 - bpp: 1.0716 - mse: 1.5497e-04\n",
      "Epoch 358: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.3411 - bpp: 1.0716 - mse: 1.5497e-04\n",
      "Epoch 359/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5237 - bpp: 1.1045 - mse: 1.7325e-04\n",
      "Epoch 359: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 2.5237 - bpp: 1.1045 - mse: 1.7325e-04\n",
      "Epoch 360/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2471 - bpp: 1.0526 - mse: 1.4581e-04\n",
      "Epoch 360: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.2471 - bpp: 1.0526 - mse: 1.4581e-04\n",
      "Epoch 361/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4886 - bpp: 1.0873 - mse: 1.7106e-04\n",
      "Epoch 361: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.4886 - bpp: 1.0873 - mse: 1.7106e-04\n",
      "Epoch 362/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3693 - bpp: 1.0692 - mse: 1.5871e-04\n",
      "Epoch 362: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3693 - bpp: 1.0692 - mse: 1.5871e-04\n",
      "Epoch 363/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3825 - bpp: 1.0481 - mse: 1.6289e-04\n",
      "Epoch 363: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.3825 - bpp: 1.0481 - mse: 1.6289e-04\n",
      "Epoch 364/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7207 - bpp: 1.1168 - mse: 1.9579e-04\n",
      "Epoch 364: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 28s 269ms/step - loss: 2.7207 - bpp: 1.1168 - mse: 1.9579e-04\n",
      "Epoch 365/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4168 - bpp: 1.0881 - mse: 1.6220e-04\n",
      "Epoch 365: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.4168 - bpp: 1.0881 - mse: 1.6220e-04\n",
      "Epoch 366/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2472 - bpp: 1.0341 - mse: 1.4807e-04\n",
      "Epoch 366: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.2472 - bpp: 1.0341 - mse: 1.4807e-04\n",
      "Epoch 367/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4395 - bpp: 1.0794 - mse: 1.6603e-04\n",
      "Epoch 367: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.4395 - bpp: 1.0794 - mse: 1.6603e-04\n",
      "Epoch 368/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3610 - bpp: 1.0944 - mse: 1.5462e-04\n",
      "Epoch 368: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.3610 - bpp: 1.0944 - mse: 1.5462e-04\n",
      "Epoch 369/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3466 - bpp: 1.0621 - mse: 1.5680e-04\n",
      "Epoch 369: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.3466 - bpp: 1.0621 - mse: 1.5680e-04\n",
      "Epoch 370/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5613 - bpp: 1.1040 - mse: 1.7788e-04\n",
      "Epoch 370: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.5613 - bpp: 1.1040 - mse: 1.7788e-04\n",
      "Epoch 371/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5947 - bpp: 1.1056 - mse: 1.8178e-04\n",
      "Epoch 371: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.5947 - bpp: 1.1056 - mse: 1.8178e-04\n",
      "Epoch 372/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5527 - bpp: 1.1096 - mse: 1.7616e-04\n",
      "Epoch 372: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.5527 - bpp: 1.1096 - mse: 1.7616e-04\n",
      "Epoch 373/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3493 - bpp: 1.2147 - mse: 3.8264e-04\n",
      "Epoch 373: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 4.3493 - bpp: 1.2147 - mse: 3.8264e-04\n",
      "Epoch 374/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7312 - bpp: 1.1659 - mse: 1.9108e-04\n",
      "Epoch 374: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.7312 - bpp: 1.1659 - mse: 1.9108e-04\n",
      "Epoch 375/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2499 - bpp: 1.0825 - mse: 1.4251e-04\n",
      "Epoch 375: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.2499 - bpp: 1.0825 - mse: 1.4251e-04\n",
      "Epoch 376/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5232 - bpp: 1.1188 - mse: 1.7144e-04\n",
      "Epoch 376: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.5232 - bpp: 1.1188 - mse: 1.7144e-04\n",
      "Epoch 377/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5108 - bpp: 1.0734 - mse: 1.7547e-04\n",
      "Epoch 377: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.5108 - bpp: 1.0734 - mse: 1.7547e-04\n",
      "Epoch 378/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4411 - bpp: 1.0926 - mse: 1.6462e-04\n",
      "Epoch 378: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 23s 218ms/step - loss: 2.4411 - bpp: 1.0926 - mse: 1.6462e-04\n",
      "Epoch 379/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3410 - bpp: 1.0579 - mse: 1.5662e-04\n",
      "Epoch 379: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 2.3410 - bpp: 1.0579 - mse: 1.5662e-04\n",
      "Epoch 380/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2470 - bpp: 1.0361 - mse: 1.4782e-04\n",
      "Epoch 380: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.2470 - bpp: 1.0361 - mse: 1.4782e-04\n",
      "Epoch 381/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2804 - bpp: 1.0446 - mse: 1.5084e-04\n",
      "Epoch 381: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 17s 161ms/step - loss: 2.2804 - bpp: 1.0446 - mse: 1.5084e-04\n",
      "Epoch 382/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4717 - bpp: 1.0869 - mse: 1.6904e-04\n",
      "Epoch 382: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.4717 - bpp: 1.0869 - mse: 1.6904e-04\n",
      "Epoch 383/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5087 - bpp: 1.0979 - mse: 1.7222e-04\n",
      "Epoch 383: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 17s 162ms/step - loss: 2.5087 - bpp: 1.0979 - mse: 1.7222e-04\n",
      "Epoch 384/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3360 - bpp: 1.0434 - mse: 1.5779e-04\n",
      "Epoch 384: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 17s 161ms/step - loss: 2.3360 - bpp: 1.0434 - mse: 1.5779e-04\n",
      "Epoch 385/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0645 - bpp: 0.9980 - mse: 1.3019e-04\n",
      "Epoch 385: loss did not improve from 2.05507\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.0645 - bpp: 0.9980 - mse: 1.3019e-04\n",
      "Epoch 386/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0308 - bpp: 0.9886 - mse: 1.2722e-04\n",
      "Epoch 386: loss improved from 2.05507 to 2.03080, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 18s 173ms/step - loss: 2.0308 - bpp: 0.9886 - mse: 1.2722e-04\n",
      "Epoch 387/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0727 - bpp: 1.0000 - mse: 1.3095e-04\n",
      "Epoch 387: loss did not improve from 2.03080\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.0727 - bpp: 1.0000 - mse: 1.3095e-04\n",
      "Epoch 388/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5656 - bpp: 1.1146 - mse: 1.7713e-04\n",
      "Epoch 388: loss did not improve from 2.03080\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 2.5656 - bpp: 1.1146 - mse: 1.7713e-04\n",
      "Epoch 389/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2612 - bpp: 1.0543 - mse: 1.4732e-04\n",
      "Epoch 389: loss did not improve from 2.03080\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.2612 - bpp: 1.0543 - mse: 1.4732e-04\n",
      "Epoch 390/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2877 - bpp: 1.0577 - mse: 1.5014e-04\n",
      "Epoch 390: loss did not improve from 2.03080\n",
      "100/100 [==============================] - 17s 160ms/step - loss: 2.2877 - bpp: 1.0577 - mse: 1.5014e-04\n",
      "Epoch 391/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3420 - bpp: 1.0417 - mse: 1.5873e-04\n",
      "Epoch 391: loss did not improve from 2.03080\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 2.3420 - bpp: 1.0417 - mse: 1.5873e-04\n",
      "Epoch 392/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9896 - bpp: 0.9697 - mse: 1.2450e-04\n",
      "Epoch 392: loss improved from 2.03080 to 1.98964, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.9896 - bpp: 0.9697 - mse: 1.2450e-04\n",
      "Epoch 393/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4937 - bpp: 1.1067 - mse: 1.6931e-04\n",
      "Epoch 393: loss did not improve from 1.98964\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.4937 - bpp: 1.1067 - mse: 1.6931e-04\n",
      "Epoch 394/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2302 - bpp: 1.0229 - mse: 1.4738e-04\n",
      "Epoch 394: loss did not improve from 1.98964\n",
      "100/100 [==============================] - 18s 173ms/step - loss: 2.2302 - bpp: 1.0229 - mse: 1.4738e-04\n",
      "Epoch 395/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2461 - bpp: 1.0327 - mse: 1.4812e-04\n",
      "Epoch 395: loss did not improve from 1.98964\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 2.2461 - bpp: 1.0327 - mse: 1.4812e-04\n",
      "Epoch 396/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4693 - bpp: 1.0997 - mse: 1.6719e-04\n",
      "Epoch 396: loss did not improve from 1.98964\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.4693 - bpp: 1.0997 - mse: 1.6719e-04\n",
      "Epoch 397/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1771 - bpp: 1.0106 - mse: 1.4239e-04\n",
      "Epoch 397: loss did not improve from 1.98964\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 2.1771 - bpp: 1.0106 - mse: 1.4239e-04\n",
      "Epoch 398/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9299 - bpp: 0.9802 - mse: 1.1593e-04\n",
      "Epoch 398: loss improved from 1.98964 to 1.92994, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 1.9299 - bpp: 0.9802 - mse: 1.1593e-04\n",
      "Epoch 399/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3115 - bpp: 1.0447 - mse: 1.5464e-04\n",
      "Epoch 399: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.3115 - bpp: 1.0447 - mse: 1.5464e-04\n",
      "Epoch 400/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1387 - bpp: 1.0060 - mse: 1.3827e-04\n",
      "Epoch 400: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.1387 - bpp: 1.0060 - mse: 1.3827e-04\n",
      "Epoch 401/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3690 - bpp: 1.0872 - mse: 1.5647e-04\n",
      "Epoch 401: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 2.3690 - bpp: 1.0872 - mse: 1.5647e-04\n",
      "Epoch 402/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5571 - bpp: 1.1096 - mse: 1.7670e-04\n",
      "Epoch 402: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 2.5571 - bpp: 1.1096 - mse: 1.7670e-04\n",
      "Epoch 403/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2699 - bpp: 1.0169 - mse: 1.5295e-04\n",
      "Epoch 403: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.2699 - bpp: 1.0169 - mse: 1.5295e-04\n",
      "Epoch 404/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2743 - bpp: 1.0260 - mse: 1.5239e-04\n",
      "Epoch 404: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.2743 - bpp: 1.0260 - mse: 1.5239e-04\n",
      "Epoch 405/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2760 - bpp: 1.0294 - mse: 1.5217e-04\n",
      "Epoch 405: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 17s 163ms/step - loss: 2.2760 - bpp: 1.0294 - mse: 1.5217e-04\n",
      "Epoch 406/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4047 - bpp: 1.0474 - mse: 1.6569e-04\n",
      "Epoch 406: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.4047 - bpp: 1.0474 - mse: 1.6569e-04\n",
      "Epoch 407/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2087 - bpp: 1.0128 - mse: 1.4599e-04\n",
      "Epoch 407: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 2.2087 - bpp: 1.0128 - mse: 1.4599e-04\n",
      "Epoch 408/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1594 - bpp: 0.9985 - mse: 1.4171e-04\n",
      "Epoch 408: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 17s 162ms/step - loss: 2.1594 - bpp: 0.9985 - mse: 1.4171e-04\n",
      "Epoch 409/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5281 - bpp: 1.0740 - mse: 1.7750e-04\n",
      "Epoch 409: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 2.5281 - bpp: 1.0740 - mse: 1.7750e-04\n",
      "Epoch 410/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3227 - bpp: 1.0200 - mse: 1.5902e-04\n",
      "Epoch 410: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 17s 161ms/step - loss: 2.3227 - bpp: 1.0200 - mse: 1.5902e-04\n",
      "Epoch 411/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5272 - bpp: 1.0701 - mse: 1.7786e-04\n",
      "Epoch 411: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 17s 163ms/step - loss: 2.5272 - bpp: 1.0701 - mse: 1.7786e-04\n",
      "Epoch 412/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3697 - bpp: 1.0660 - mse: 1.5915e-04\n",
      "Epoch 412: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 2.3697 - bpp: 1.0660 - mse: 1.5915e-04\n",
      "Epoch 413/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.4572 - bpp: 1.2126 - mse: 3.9606e-04\n",
      "Epoch 413: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 16s 154ms/step - loss: 4.4572 - bpp: 1.2126 - mse: 3.9606e-04\n",
      "Epoch 414/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7775 - bpp: 1.1538 - mse: 1.9820e-04\n",
      "Epoch 414: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 2.7775 - bpp: 1.1538 - mse: 1.9820e-04\n",
      "Epoch 415/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3058 - bpp: 1.0780 - mse: 1.4988e-04\n",
      "Epoch 415: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3058 - bpp: 1.0780 - mse: 1.4988e-04\n",
      "Epoch 416/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3381 - bpp: 1.0756 - mse: 1.5411e-04\n",
      "Epoch 416: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3381 - bpp: 1.0756 - mse: 1.5411e-04\n",
      "Epoch 417/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2586 - bpp: 1.0604 - mse: 1.4626e-04\n",
      "Epoch 417: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 2.2586 - bpp: 1.0604 - mse: 1.4626e-04\n",
      "Epoch 418/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0629 - bpp: 1.0286 - mse: 1.2626e-04\n",
      "Epoch 418: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.0629 - bpp: 1.0286 - mse: 1.2626e-04\n",
      "Epoch 419/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6200 - bpp: 1.1211 - mse: 1.8297e-04\n",
      "Epoch 419: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.6200 - bpp: 1.1211 - mse: 1.8297e-04\n",
      "Epoch 420/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1315 - bpp: 0.9963 - mse: 1.3857e-04\n",
      "Epoch 420: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 2.1315 - bpp: 0.9963 - mse: 1.3857e-04\n",
      "Epoch 421/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1875 - bpp: 1.0074 - mse: 1.4405e-04\n",
      "Epoch 421: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1875 - bpp: 1.0074 - mse: 1.4405e-04\n",
      "Epoch 422/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4707 - bpp: 1.0607 - mse: 1.7212e-04\n",
      "Epoch 422: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4707 - bpp: 1.0607 - mse: 1.7212e-04\n",
      "Epoch 423/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2238 - bpp: 1.0136 - mse: 1.4773e-04\n",
      "Epoch 423: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.2238 - bpp: 1.0136 - mse: 1.4773e-04\n",
      "Epoch 424/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4064 - bpp: 1.0735 - mse: 1.6270e-04\n",
      "Epoch 424: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.4064 - bpp: 1.0735 - mse: 1.6270e-04\n",
      "Epoch 425/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2108 - bpp: 1.0465 - mse: 1.4213e-04\n",
      "Epoch 425: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.2108 - bpp: 1.0465 - mse: 1.4213e-04\n",
      "Epoch 426/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4165 - bpp: 1.0862 - mse: 1.6240e-04\n",
      "Epoch 426: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.4165 - bpp: 1.0862 - mse: 1.6240e-04\n",
      "Epoch 427/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5399 - bpp: 1.1176 - mse: 1.7362e-04\n",
      "Epoch 427: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.5399 - bpp: 1.1176 - mse: 1.7362e-04\n",
      "Epoch 428/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1842 - bpp: 0.9901 - mse: 1.4576e-04\n",
      "Epoch 428: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.1842 - bpp: 0.9901 - mse: 1.4576e-04\n",
      "Epoch 429/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4166 - bpp: 1.0379 - mse: 1.6830e-04\n",
      "Epoch 429: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 2.4166 - bpp: 1.0379 - mse: 1.6830e-04\n",
      "Epoch 430/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3303 - bpp: 1.0386 - mse: 1.5768e-04\n",
      "Epoch 430: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3303 - bpp: 1.0386 - mse: 1.5768e-04\n",
      "Epoch 431/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9895 - bpp: 0.9991 - mse: 1.2090e-04\n",
      "Epoch 431: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 1.9895 - bpp: 0.9991 - mse: 1.2090e-04\n",
      "Epoch 432/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4262 - bpp: 1.0364 - mse: 1.6966e-04\n",
      "Epoch 432: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.4262 - bpp: 1.0364 - mse: 1.6966e-04\n",
      "Epoch 433/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3333 - bpp: 1.0563 - mse: 1.5589e-04\n",
      "Epoch 433: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3333 - bpp: 1.0563 - mse: 1.5589e-04\n",
      "Epoch 434/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4212 - bpp: 1.0285 - mse: 1.7002e-04\n",
      "Epoch 434: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.4212 - bpp: 1.0285 - mse: 1.7002e-04\n",
      "Epoch 435/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3366 - bpp: 1.0150 - mse: 1.6134e-04\n",
      "Epoch 435: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.3366 - bpp: 1.0150 - mse: 1.6134e-04\n",
      "Epoch 436/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3813 - bpp: 1.0583 - mse: 1.6150e-04\n",
      "Epoch 436: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 2.3813 - bpp: 1.0583 - mse: 1.6150e-04\n",
      "Epoch 437/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1110 - bpp: 0.9852 - mse: 1.3743e-04\n",
      "Epoch 437: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.1110 - bpp: 0.9852 - mse: 1.3743e-04\n",
      "Epoch 438/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2645 - bpp: 1.0045 - mse: 1.5381e-04\n",
      "Epoch 438: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 2.2645 - bpp: 1.0045 - mse: 1.5381e-04\n",
      "Epoch 439/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1731 - bpp: 1.0292 - mse: 1.3963e-04\n",
      "Epoch 439: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.1731 - bpp: 1.0292 - mse: 1.3963e-04\n",
      "Epoch 440/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2049 - bpp: 1.0126 - mse: 1.4555e-04\n",
      "Epoch 440: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.2049 - bpp: 1.0126 - mse: 1.4555e-04\n",
      "Epoch 441/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2741 - bpp: 0.9992 - mse: 1.5563e-04\n",
      "Epoch 441: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.2741 - bpp: 0.9992 - mse: 1.5563e-04\n",
      "Epoch 442/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1409 - bpp: 1.0154 - mse: 1.3739e-04\n",
      "Epoch 442: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.1409 - bpp: 1.0154 - mse: 1.3739e-04\n",
      "Epoch 443/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2102 - bpp: 1.0154 - mse: 1.4584e-04\n",
      "Epoch 443: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.2102 - bpp: 1.0154 - mse: 1.4584e-04\n",
      "Epoch 444/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2097 - bpp: 1.0083 - mse: 1.4666e-04\n",
      "Epoch 444: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.2097 - bpp: 1.0083 - mse: 1.4666e-04\n",
      "Epoch 445/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3739 - bpp: 1.0215 - mse: 1.6508e-04\n",
      "Epoch 445: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3739 - bpp: 1.0215 - mse: 1.6508e-04\n",
      "Epoch 446/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0473 - bpp: 0.9956 - mse: 1.2838e-04\n",
      "Epoch 446: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.0473 - bpp: 0.9956 - mse: 1.2838e-04\n",
      "Epoch 447/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3081 - bpp: 1.0478 - mse: 1.5384e-04\n",
      "Epoch 447: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.3081 - bpp: 1.0478 - mse: 1.5384e-04\n",
      "Epoch 448/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9705 - bpp: 0.9726 - mse: 1.2182e-04\n",
      "Epoch 448: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.9705 - bpp: 0.9726 - mse: 1.2182e-04\n",
      "Epoch 449/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1451 - bpp: 0.9822 - mse: 1.4195e-04\n",
      "Epoch 449: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.1451 - bpp: 0.9822 - mse: 1.4195e-04\n",
      "Epoch 450/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3061 - bpp: 1.0517 - mse: 1.5312e-04\n",
      "Epoch 450: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3061 - bpp: 1.0517 - mse: 1.5312e-04\n",
      "Epoch 451/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1790 - bpp: 1.0277 - mse: 1.4053e-04\n",
      "Epoch 451: loss did not improve from 1.92994\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.1790 - bpp: 1.0277 - mse: 1.4053e-04\n",
      "Epoch 452/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8533 - bpp: 0.9300 - mse: 1.1271e-04\n",
      "Epoch 452: loss improved from 1.92994 to 1.85332, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8533 - bpp: 0.9300 - mse: 1.1271e-04\n",
      "Epoch 453/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1716 - bpp: 1.0263 - mse: 1.3980e-04\n",
      "Epoch 453: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 2.1716 - bpp: 1.0263 - mse: 1.3980e-04\n",
      "Epoch 454/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2887 - bpp: 1.0204 - mse: 1.5483e-04\n",
      "Epoch 454: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 29s 280ms/step - loss: 2.2887 - bpp: 1.0204 - mse: 1.5483e-04\n",
      "Epoch 455/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1901 - bpp: 1.0253 - mse: 1.4218e-04\n",
      "Epoch 455: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1901 - bpp: 1.0253 - mse: 1.4218e-04\n",
      "Epoch 456/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1567 - bpp: 1.0020 - mse: 1.4096e-04\n",
      "Epoch 456: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.1567 - bpp: 1.0020 - mse: 1.4096e-04\n",
      "Epoch 457/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1398 - bpp: 0.9858 - mse: 1.4087e-04\n",
      "Epoch 457: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.1398 - bpp: 0.9858 - mse: 1.4087e-04\n",
      "Epoch 458/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2013 - bpp: 1.0258 - mse: 1.4350e-04\n",
      "Epoch 458: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.2013 - bpp: 1.0258 - mse: 1.4350e-04\n",
      "Epoch 459/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1561 - bpp: 0.9947 - mse: 1.4177e-04\n",
      "Epoch 459: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.1561 - bpp: 0.9947 - mse: 1.4177e-04\n",
      "Epoch 460/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4235 - bpp: 1.0426 - mse: 1.6856e-04\n",
      "Epoch 460: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.4235 - bpp: 1.0426 - mse: 1.6856e-04\n",
      "Epoch 461/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3212 - bpp: 1.0450 - mse: 1.5578e-04\n",
      "Epoch 461: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.3212 - bpp: 1.0450 - mse: 1.5578e-04\n",
      "Epoch 462/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2806 - bpp: 1.0205 - mse: 1.5382e-04\n",
      "Epoch 462: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.2806 - bpp: 1.0205 - mse: 1.5382e-04\n",
      "Epoch 463/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2106 - bpp: 0.9835 - mse: 1.4980e-04\n",
      "Epoch 463: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 2.2106 - bpp: 0.9835 - mse: 1.4980e-04\n",
      "Epoch 464/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9412 - bpp: 0.9588 - mse: 1.1991e-04\n",
      "Epoch 464: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.9412 - bpp: 0.9588 - mse: 1.1991e-04\n",
      "Epoch 465/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9775 - bpp: 0.9655 - mse: 1.2354e-04\n",
      "Epoch 465: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9775 - bpp: 0.9655 - mse: 1.2354e-04\n",
      "Epoch 466/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3673 - bpp: 1.0303 - mse: 1.6320e-04\n",
      "Epoch 466: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.3673 - bpp: 1.0303 - mse: 1.6320e-04\n",
      "Epoch 467/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0839 - bpp: 0.9703 - mse: 1.3594e-04\n",
      "Epoch 467: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.0839 - bpp: 0.9703 - mse: 1.3594e-04\n",
      "Epoch 468/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0339 - bpp: 0.9735 - mse: 1.2944e-04\n",
      "Epoch 468: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.0339 - bpp: 0.9735 - mse: 1.2944e-04\n",
      "Epoch 469/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5350 - bpp: 1.0628 - mse: 1.7971e-04\n",
      "Epoch 469: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.5350 - bpp: 1.0628 - mse: 1.7971e-04\n",
      "Epoch 470/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0887 - bpp: 0.9778 - mse: 1.3561e-04\n",
      "Epoch 470: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0887 - bpp: 0.9778 - mse: 1.3561e-04\n",
      "Epoch 471/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3355 - bpp: 1.0410 - mse: 1.5801e-04\n",
      "Epoch 471: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.3355 - bpp: 1.0410 - mse: 1.5801e-04\n",
      "Epoch 472/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1600 - bpp: 0.9976 - mse: 1.4191e-04\n",
      "Epoch 472: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.1600 - bpp: 0.9976 - mse: 1.4191e-04\n",
      "Epoch 473/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2061 - bpp: 1.0236 - mse: 1.4434e-04\n",
      "Epoch 473: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.2061 - bpp: 1.0236 - mse: 1.4434e-04\n",
      "Epoch 474/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1192 - bpp: 0.9801 - mse: 1.3905e-04\n",
      "Epoch 474: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.1192 - bpp: 0.9801 - mse: 1.3905e-04\n",
      "Epoch 475/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1542 - bpp: 0.9761 - mse: 1.4381e-04\n",
      "Epoch 475: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.1542 - bpp: 0.9761 - mse: 1.4381e-04\n",
      "Epoch 476/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1643 - bpp: 0.9959 - mse: 1.4262e-04\n",
      "Epoch 476: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.1643 - bpp: 0.9959 - mse: 1.4262e-04\n",
      "Epoch 477/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5150 - bpp: 1.0464 - mse: 1.7928e-04\n",
      "Epoch 477: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.5150 - bpp: 1.0464 - mse: 1.7928e-04\n",
      "Epoch 478/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2532 - bpp: 1.0045 - mse: 1.5243e-04\n",
      "Epoch 478: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.2532 - bpp: 1.0045 - mse: 1.5243e-04\n",
      "Epoch 479/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2813 - bpp: 1.0218 - mse: 1.5375e-04\n",
      "Epoch 479: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.2813 - bpp: 1.0218 - mse: 1.5375e-04\n",
      "Epoch 480/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1397 - bpp: 0.9917 - mse: 1.4014e-04\n",
      "Epoch 480: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.1397 - bpp: 0.9917 - mse: 1.4014e-04\n",
      "Epoch 481/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0925 - bpp: 0.9701 - mse: 1.3702e-04\n",
      "Epoch 481: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.0925 - bpp: 0.9701 - mse: 1.3702e-04\n",
      "Epoch 482/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4297 - bpp: 1.0457 - mse: 1.6895e-04\n",
      "Epoch 482: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.4297 - bpp: 1.0457 - mse: 1.6895e-04\n",
      "Epoch 483/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0669 - bpp: 0.9975 - mse: 1.3054e-04\n",
      "Epoch 483: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.0669 - bpp: 0.9975 - mse: 1.3054e-04\n",
      "Epoch 484/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0809 - bpp: 0.9861 - mse: 1.3364e-04\n",
      "Epoch 484: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.0809 - bpp: 0.9861 - mse: 1.3364e-04\n",
      "Epoch 485/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1904 - bpp: 1.0059 - mse: 1.4459e-04\n",
      "Epoch 485: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.1904 - bpp: 1.0059 - mse: 1.4459e-04\n",
      "Epoch 486/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0191 - bpp: 0.9692 - mse: 1.2816e-04\n",
      "Epoch 486: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.0191 - bpp: 0.9692 - mse: 1.2816e-04\n",
      "Epoch 487/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1423 - bpp: 0.9974 - mse: 1.3975e-04\n",
      "Epoch 487: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1423 - bpp: 0.9974 - mse: 1.3975e-04\n",
      "Epoch 488/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0626 - bpp: 0.9721 - mse: 1.3311e-04\n",
      "Epoch 488: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.0626 - bpp: 0.9721 - mse: 1.3311e-04\n",
      "Epoch 489/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8708 - bpp: 0.9355 - mse: 1.1418e-04\n",
      "Epoch 489: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.8708 - bpp: 0.9355 - mse: 1.1418e-04\n",
      "Epoch 490/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1842 - bpp: 1.0033 - mse: 1.4415e-04\n",
      "Epoch 490: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.1842 - bpp: 1.0033 - mse: 1.4415e-04\n",
      "Epoch 491/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3213 - bpp: 1.0306 - mse: 1.5756e-04\n",
      "Epoch 491: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.3213 - bpp: 1.0306 - mse: 1.5756e-04\n",
      "Epoch 492/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3265 - bpp: 1.0204 - mse: 1.5944e-04\n",
      "Epoch 492: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 2.3265 - bpp: 1.0204 - mse: 1.5944e-04\n",
      "Epoch 493/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4008 - bpp: 1.0621 - mse: 1.6341e-04\n",
      "Epoch 493: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.4008 - bpp: 1.0621 - mse: 1.6341e-04\n",
      "Epoch 494/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9070 - bpp: 0.9349 - mse: 1.1867e-04\n",
      "Epoch 494: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9070 - bpp: 0.9349 - mse: 1.1867e-04\n",
      "Epoch 495/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9355 - bpp: 0.9628 - mse: 1.1873e-04\n",
      "Epoch 495: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.9355 - bpp: 0.9628 - mse: 1.1873e-04\n",
      "Epoch 496/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0924 - bpp: 0.9828 - mse: 1.3545e-04\n",
      "Epoch 496: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.0924 - bpp: 0.9828 - mse: 1.3545e-04\n",
      "Epoch 497/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8837 - bpp: 0.9463 - mse: 1.1443e-04\n",
      "Epoch 497: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.8837 - bpp: 0.9463 - mse: 1.1443e-04\n",
      "Epoch 498/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1169 - bpp: 0.9716 - mse: 1.3981e-04\n",
      "Epoch 498: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.1169 - bpp: 0.9716 - mse: 1.3981e-04\n",
      "Epoch 499/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1794 - bpp: 0.9853 - mse: 1.4577e-04\n",
      "Epoch 499: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.1794 - bpp: 0.9853 - mse: 1.4577e-04\n",
      "Epoch 500/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9636 - bpp: 0.9466 - mse: 1.2414e-04\n",
      "Epoch 500: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.9636 - bpp: 0.9466 - mse: 1.2414e-04\n",
      "Epoch 501/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1826 - bpp: 0.9905 - mse: 1.4551e-04\n",
      "Epoch 501: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 249ms/step - loss: 2.1826 - bpp: 0.9905 - mse: 1.4551e-04\n",
      "Epoch 502/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0177 - bpp: 0.9634 - mse: 1.2869e-04\n",
      "Epoch 502: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.0177 - bpp: 0.9634 - mse: 1.2869e-04\n",
      "Epoch 503/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1696 - bpp: 1.0022 - mse: 1.4251e-04\n",
      "Epoch 503: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.1696 - bpp: 1.0022 - mse: 1.4251e-04\n",
      "Epoch 504/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1418 - bpp: 0.9951 - mse: 1.3998e-04\n",
      "Epoch 504: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 2.1418 - bpp: 0.9951 - mse: 1.3998e-04\n",
      "Epoch 505/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9464 - bpp: 0.9513 - mse: 1.2148e-04\n",
      "Epoch 505: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.9464 - bpp: 0.9513 - mse: 1.2148e-04\n",
      "Epoch 506/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0736 - bpp: 0.9908 - mse: 1.3217e-04\n",
      "Epoch 506: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 256ms/step - loss: 2.0736 - bpp: 0.9908 - mse: 1.3217e-04\n",
      "Epoch 507/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9347 - bpp: 0.9446 - mse: 1.2086e-04\n",
      "Epoch 507: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.9347 - bpp: 0.9446 - mse: 1.2086e-04\n",
      "Epoch 508/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2822 - bpp: 1.0037 - mse: 1.5606e-04\n",
      "Epoch 508: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.2822 - bpp: 1.0037 - mse: 1.5606e-04\n",
      "Epoch 509/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3198 - bpp: 1.0245 - mse: 1.5811e-04\n",
      "Epoch 509: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.3198 - bpp: 1.0245 - mse: 1.5811e-04\n",
      "Epoch 510/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6595 - bpp: 1.0525 - mse: 1.9617e-04\n",
      "Epoch 510: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.6595 - bpp: 1.0525 - mse: 1.9617e-04\n",
      "Epoch 511/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9011 - bpp: 0.9416 - mse: 1.1713e-04\n",
      "Epoch 511: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 1.9011 - bpp: 0.9416 - mse: 1.1713e-04\n",
      "Epoch 512/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0486 - bpp: 0.9888 - mse: 1.2936e-04\n",
      "Epoch 512: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.0486 - bpp: 0.9888 - mse: 1.2936e-04\n",
      "Epoch 513/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0424 - bpp: 0.9704 - mse: 1.3086e-04\n",
      "Epoch 513: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0424 - bpp: 0.9704 - mse: 1.3086e-04\n",
      "Epoch 514/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9325 - bpp: 0.9450 - mse: 1.2054e-04\n",
      "Epoch 514: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.9325 - bpp: 0.9450 - mse: 1.2054e-04\n",
      "Epoch 515/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0957 - bpp: 0.9741 - mse: 1.3692e-04\n",
      "Epoch 515: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.0957 - bpp: 0.9741 - mse: 1.3692e-04\n",
      "Epoch 516/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1181 - bpp: 0.9983 - mse: 1.3670e-04\n",
      "Epoch 516: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 2.1181 - bpp: 0.9983 - mse: 1.3670e-04\n",
      "Epoch 517/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0774 - bpp: 0.9871 - mse: 1.3310e-04\n",
      "Epoch 517: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.0774 - bpp: 0.9871 - mse: 1.3310e-04\n",
      "Epoch 518/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0607 - bpp: 0.9530 - mse: 1.3522e-04\n",
      "Epoch 518: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 26s 250ms/step - loss: 2.0607 - bpp: 0.9530 - mse: 1.3522e-04\n",
      "Epoch 519/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8994 - bpp: 0.9350 - mse: 1.1772e-04\n",
      "Epoch 519: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 1.8994 - bpp: 0.9350 - mse: 1.1772e-04\n",
      "Epoch 520/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8818 - bpp: 0.9467 - mse: 1.1415e-04\n",
      "Epoch 520: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8818 - bpp: 0.9467 - mse: 1.1415e-04\n",
      "Epoch 521/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0938 - bpp: 0.9874 - mse: 1.3505e-04\n",
      "Epoch 521: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 2.0938 - bpp: 0.9874 - mse: 1.3505e-04\n",
      "Epoch 522/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0374 - bpp: 0.9847 - mse: 1.2850e-04\n",
      "Epoch 522: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 2.0374 - bpp: 0.9847 - mse: 1.2850e-04\n",
      "Epoch 523/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2676 - bpp: 1.0247 - mse: 1.5172e-04\n",
      "Epoch 523: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.2676 - bpp: 1.0247 - mse: 1.5172e-04\n",
      "Epoch 524/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1599 - bpp: 1.0145 - mse: 1.3982e-04\n",
      "Epoch 524: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.1599 - bpp: 1.0145 - mse: 1.3982e-04\n",
      "Epoch 525/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0744 - bpp: 1.0009 - mse: 1.3104e-04\n",
      "Epoch 525: loss did not improve from 1.85332\n",
      "100/100 [==============================] - 25s 244ms/step - loss: 2.0744 - bpp: 1.0009 - mse: 1.3104e-04\n",
      "Epoch 526/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7376 - bpp: 0.9084 - mse: 1.0122e-04\n",
      "Epoch 526: loss improved from 1.85332 to 1.73761, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.7376 - bpp: 0.9084 - mse: 1.0122e-04\n",
      "Epoch 527/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0277 - bpp: 0.9855 - mse: 1.2723e-04\n",
      "Epoch 527: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.0277 - bpp: 0.9855 - mse: 1.2723e-04\n",
      "Epoch 528/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0548 - bpp: 0.9982 - mse: 1.2898e-04\n",
      "Epoch 528: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.0548 - bpp: 0.9982 - mse: 1.2898e-04\n",
      "Epoch 529/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0906 - bpp: 0.9917 - mse: 1.3413e-04\n",
      "Epoch 529: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.0906 - bpp: 0.9917 - mse: 1.3413e-04\n",
      "Epoch 530/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0302 - bpp: 0.9567 - mse: 1.3104e-04\n",
      "Epoch 530: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0302 - bpp: 0.9567 - mse: 1.3104e-04\n",
      "Epoch 531/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1376 - bpp: 0.9927 - mse: 1.3976e-04\n",
      "Epoch 531: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.1376 - bpp: 0.9927 - mse: 1.3976e-04\n",
      "Epoch 532/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9643 - bpp: 0.9550 - mse: 1.2321e-04\n",
      "Epoch 532: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.9643 - bpp: 0.9550 - mse: 1.2321e-04\n",
      "Epoch 533/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2861 - bpp: 1.0250 - mse: 1.5395e-04\n",
      "Epoch 533: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.2861 - bpp: 1.0250 - mse: 1.5395e-04\n",
      "Epoch 534/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9628 - bpp: 0.9653 - mse: 1.2176e-04\n",
      "Epoch 534: loss did not improve from 1.73761\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.9628 - bpp: 0.9653 - mse: 1.2176e-04\n",
      "Epoch 535/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7332 - bpp: 0.9129 - mse: 1.0013e-04\n",
      "Epoch 535: loss improved from 1.73761 to 1.73323, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.7332 - bpp: 0.9129 - mse: 1.0013e-04\n",
      "Epoch 536/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1317 - bpp: 0.9551 - mse: 1.4363e-04\n",
      "Epoch 536: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.1317 - bpp: 0.9551 - mse: 1.4363e-04\n",
      "Epoch 537/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0491 - bpp: 0.9496 - mse: 1.3421e-04\n",
      "Epoch 537: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.0491 - bpp: 0.9496 - mse: 1.3421e-04\n",
      "Epoch 538/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1088 - bpp: 0.9608 - mse: 1.4014e-04\n",
      "Epoch 538: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.1088 - bpp: 0.9608 - mse: 1.4014e-04\n",
      "Epoch 539/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1262 - bpp: 1.0026 - mse: 1.3716e-04\n",
      "Epoch 539: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.1262 - bpp: 1.0026 - mse: 1.3716e-04\n",
      "Epoch 540/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9901 - bpp: 0.9622 - mse: 1.2546e-04\n",
      "Epoch 540: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.9901 - bpp: 0.9622 - mse: 1.2546e-04\n",
      "Epoch 541/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1867 - bpp: 0.9804 - mse: 1.4726e-04\n",
      "Epoch 541: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 2.1867 - bpp: 0.9804 - mse: 1.4726e-04\n",
      "Epoch 542/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1633 - bpp: 0.9761 - mse: 1.4492e-04\n",
      "Epoch 542: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.1633 - bpp: 0.9761 - mse: 1.4492e-04\n",
      "Epoch 543/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9355 - bpp: 0.9247 - mse: 1.2339e-04\n",
      "Epoch 543: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.9355 - bpp: 0.9247 - mse: 1.2339e-04\n",
      "Epoch 544/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8655 - bpp: 0.9304 - mse: 1.1415e-04\n",
      "Epoch 544: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.8655 - bpp: 0.9304 - mse: 1.1415e-04\n",
      "Epoch 545/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9673 - bpp: 0.9390 - mse: 1.2552e-04\n",
      "Epoch 545: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9673 - bpp: 0.9390 - mse: 1.2552e-04\n",
      "Epoch 546/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3046 - bpp: 1.0150 - mse: 1.5743e-04\n",
      "Epoch 546: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.3046 - bpp: 1.0150 - mse: 1.5743e-04\n",
      "Epoch 547/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0976 - bpp: 0.9758 - mse: 1.3694e-04\n",
      "Epoch 547: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.0976 - bpp: 0.9758 - mse: 1.3694e-04\n",
      "Epoch 548/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9635 - bpp: 0.9552 - mse: 1.2309e-04\n",
      "Epoch 548: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.9635 - bpp: 0.9552 - mse: 1.2309e-04\n",
      "Epoch 549/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2139 - bpp: 1.0088 - mse: 1.4711e-04\n",
      "Epoch 549: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.2139 - bpp: 1.0088 - mse: 1.4711e-04\n",
      "Epoch 550/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1758 - bpp: 0.9889 - mse: 1.4488e-04\n",
      "Epoch 550: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.1758 - bpp: 0.9889 - mse: 1.4488e-04\n",
      "Epoch 551/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0575 - bpp: 0.9709 - mse: 1.3263e-04\n",
      "Epoch 551: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.0575 - bpp: 0.9709 - mse: 1.3263e-04\n",
      "Epoch 552/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0239 - bpp: 0.9505 - mse: 1.3103e-04\n",
      "Epoch 552: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0239 - bpp: 0.9505 - mse: 1.3103e-04\n",
      "Epoch 553/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0041 - bpp: 0.9417 - mse: 1.2968e-04\n",
      "Epoch 553: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.0041 - bpp: 0.9417 - mse: 1.2968e-04\n",
      "Epoch 554/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2585 - bpp: 1.0034 - mse: 1.5321e-04\n",
      "Epoch 554: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.2585 - bpp: 1.0034 - mse: 1.5321e-04\n",
      "Epoch 555/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9805 - bpp: 0.9473 - mse: 1.2612e-04\n",
      "Epoch 555: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 1.9805 - bpp: 0.9473 - mse: 1.2612e-04\n",
      "Epoch 556/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2641 - bpp: 1.0115 - mse: 1.5290e-04\n",
      "Epoch 556: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.2641 - bpp: 1.0115 - mse: 1.5290e-04\n",
      "Epoch 557/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9872 - bpp: 0.9425 - mse: 1.2752e-04\n",
      "Epoch 557: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.9872 - bpp: 0.9425 - mse: 1.2752e-04\n",
      "Epoch 558/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0916 - bpp: 0.9754 - mse: 1.3625e-04\n",
      "Epoch 558: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.0916 - bpp: 0.9754 - mse: 1.3625e-04\n",
      "Epoch 559/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1312 - bpp: 0.9847 - mse: 1.3996e-04\n",
      "Epoch 559: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.1312 - bpp: 0.9847 - mse: 1.3996e-04\n",
      "Epoch 560/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5141 - bpp: 1.0902 - mse: 1.7381e-04\n",
      "Epoch 560: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.5141 - bpp: 1.0902 - mse: 1.7381e-04\n",
      "Epoch 561/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8786 - bpp: 0.9483 - mse: 1.1357e-04\n",
      "Epoch 561: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 1.8786 - bpp: 0.9483 - mse: 1.1357e-04\n",
      "Epoch 562/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1713 - bpp: 1.0207 - mse: 1.4045e-04\n",
      "Epoch 562: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.1713 - bpp: 1.0207 - mse: 1.4045e-04\n",
      "Epoch 563/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1037 - bpp: 0.9796 - mse: 1.3723e-04\n",
      "Epoch 563: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 2.1037 - bpp: 0.9796 - mse: 1.3723e-04\n",
      "Epoch 564/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9816 - bpp: 0.9591 - mse: 1.2482e-04\n",
      "Epoch 564: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.9816 - bpp: 0.9591 - mse: 1.2482e-04\n",
      "Epoch 565/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0015 - bpp: 0.9414 - mse: 1.2940e-04\n",
      "Epoch 565: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.0015 - bpp: 0.9414 - mse: 1.2940e-04\n",
      "Epoch 566/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0599 - bpp: 0.9702 - mse: 1.3303e-04\n",
      "Epoch 566: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.0599 - bpp: 0.9702 - mse: 1.3303e-04\n",
      "Epoch 567/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9113 - bpp: 0.9216 - mse: 1.2081e-04\n",
      "Epoch 567: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.9113 - bpp: 0.9216 - mse: 1.2081e-04\n",
      "Epoch 568/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9467 - bpp: 0.9598 - mse: 1.2047e-04\n",
      "Epoch 568: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.9467 - bpp: 0.9598 - mse: 1.2047e-04\n",
      "Epoch 569/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9173 - bpp: 0.9247 - mse: 1.2117e-04\n",
      "Epoch 569: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.9173 - bpp: 0.9247 - mse: 1.2117e-04\n",
      "Epoch 570/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1671 - bpp: 0.9754 - mse: 1.4547e-04\n",
      "Epoch 570: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.1671 - bpp: 0.9754 - mse: 1.4547e-04\n",
      "Epoch 571/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0895 - bpp: 0.9851 - mse: 1.3481e-04\n",
      "Epoch 571: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.0895 - bpp: 0.9851 - mse: 1.3481e-04\n",
      "Epoch 572/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9126 - bpp: 0.9427 - mse: 1.1840e-04\n",
      "Epoch 572: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.9126 - bpp: 0.9427 - mse: 1.1840e-04\n",
      "Epoch 573/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9509 - bpp: 0.9496 - mse: 1.2223e-04\n",
      "Epoch 573: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.9509 - bpp: 0.9496 - mse: 1.2223e-04\n",
      "Epoch 574/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0883 - bpp: 0.9797 - mse: 1.3533e-04\n",
      "Epoch 574: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.0883 - bpp: 0.9797 - mse: 1.3533e-04\n",
      "Epoch 575/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1908 - bpp: 0.9804 - mse: 1.4776e-04\n",
      "Epoch 575: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.1908 - bpp: 0.9804 - mse: 1.4776e-04\n",
      "Epoch 576/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2129 - bpp: 0.9994 - mse: 1.4813e-04\n",
      "Epoch 576: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 2.2129 - bpp: 0.9994 - mse: 1.4813e-04\n",
      "Epoch 577/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0392 - bpp: 0.9732 - mse: 1.3012e-04\n",
      "Epoch 577: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0392 - bpp: 0.9732 - mse: 1.3012e-04\n",
      "Epoch 578/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7468 - bpp: 0.8887 - mse: 1.0475e-04\n",
      "Epoch 578: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 1.7468 - bpp: 0.8887 - mse: 1.0475e-04\n",
      "Epoch 579/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9295 - bpp: 0.9385 - mse: 1.2097e-04\n",
      "Epoch 579: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.9295 - bpp: 0.9385 - mse: 1.2097e-04\n",
      "Epoch 580/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9847 - bpp: 0.9811 - mse: 1.2251e-04\n",
      "Epoch 580: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.9847 - bpp: 0.9811 - mse: 1.2251e-04\n",
      "Epoch 581/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1075 - bpp: 0.9905 - mse: 1.3636e-04\n",
      "Epoch 581: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.1075 - bpp: 0.9905 - mse: 1.3636e-04\n",
      "Epoch 582/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0890 - bpp: 0.9817 - mse: 1.3517e-04\n",
      "Epoch 582: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.0890 - bpp: 0.9817 - mse: 1.3517e-04\n",
      "Epoch 583/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8868 - bpp: 0.9407 - mse: 1.1549e-04\n",
      "Epoch 583: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.8868 - bpp: 0.9407 - mse: 1.1549e-04\n",
      "Epoch 584/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8921 - bpp: 0.9194 - mse: 1.1874e-04\n",
      "Epoch 584: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8921 - bpp: 0.9194 - mse: 1.1874e-04\n",
      "Epoch 585/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0713 - bpp: 0.9710 - mse: 1.3431e-04\n",
      "Epoch 585: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 2.0713 - bpp: 0.9710 - mse: 1.3431e-04\n",
      "Epoch 586/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0008 - bpp: 0.9652 - mse: 1.2641e-04\n",
      "Epoch 586: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.0008 - bpp: 0.9652 - mse: 1.2641e-04\n",
      "Epoch 587/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0666 - bpp: 0.9198 - mse: 1.3999e-04\n",
      "Epoch 587: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.0666 - bpp: 0.9198 - mse: 1.3999e-04\n",
      "Epoch 588/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0302 - bpp: 0.9563 - mse: 1.3109e-04\n",
      "Epoch 588: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.0302 - bpp: 0.9563 - mse: 1.3109e-04\n",
      "Epoch 589/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9662 - bpp: 0.9609 - mse: 1.2271e-04\n",
      "Epoch 589: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 1.9662 - bpp: 0.9609 - mse: 1.2271e-04\n",
      "Epoch 590/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9933 - bpp: 0.9472 - mse: 1.2770e-04\n",
      "Epoch 590: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.9933 - bpp: 0.9472 - mse: 1.2770e-04\n",
      "Epoch 591/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7841 - bpp: 0.9279 - mse: 1.0452e-04\n",
      "Epoch 591: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.7841 - bpp: 0.9279 - mse: 1.0452e-04\n",
      "Epoch 592/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0843 - bpp: 0.9588 - mse: 1.3738e-04\n",
      "Epoch 592: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.0843 - bpp: 0.9588 - mse: 1.3738e-04\n",
      "Epoch 593/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8280 - bpp: 0.9356 - mse: 1.0894e-04\n",
      "Epoch 593: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.8280 - bpp: 0.9356 - mse: 1.0894e-04\n",
      "Epoch 594/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0138 - bpp: 0.9548 - mse: 1.2927e-04\n",
      "Epoch 594: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 29s 281ms/step - loss: 2.0138 - bpp: 0.9548 - mse: 1.2927e-04\n",
      "Epoch 595/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9750 - bpp: 0.9415 - mse: 1.2617e-04\n",
      "Epoch 595: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 1.9750 - bpp: 0.9415 - mse: 1.2617e-04\n",
      "Epoch 596/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8799 - bpp: 0.9334 - mse: 1.1554e-04\n",
      "Epoch 596: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.8799 - bpp: 0.9334 - mse: 1.1554e-04\n",
      "Epoch 597/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8806 - bpp: 0.9328 - mse: 1.1569e-04\n",
      "Epoch 597: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.8806 - bpp: 0.9328 - mse: 1.1569e-04\n",
      "Epoch 598/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9181 - bpp: 0.9550 - mse: 1.1757e-04\n",
      "Epoch 598: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 1.9181 - bpp: 0.9550 - mse: 1.1757e-04\n",
      "Epoch 599/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9512 - bpp: 0.9568 - mse: 1.2138e-04\n",
      "Epoch 599: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.9512 - bpp: 0.9568 - mse: 1.2138e-04\n",
      "Epoch 600/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9862 - bpp: 0.9417 - mse: 1.2750e-04\n",
      "Epoch 600: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.9862 - bpp: 0.9417 - mse: 1.2750e-04\n",
      "Epoch 601/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1048 - bpp: 0.9732 - mse: 1.3814e-04\n",
      "Epoch 601: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.1048 - bpp: 0.9732 - mse: 1.3814e-04\n",
      "Epoch 602/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8583 - bpp: 0.9235 - mse: 1.1411e-04\n",
      "Epoch 602: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8583 - bpp: 0.9235 - mse: 1.1411e-04\n",
      "Epoch 603/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0109 - bpp: 0.9522 - mse: 1.2923e-04\n",
      "Epoch 603: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.0109 - bpp: 0.9522 - mse: 1.2923e-04\n",
      "Epoch 604/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0933 - bpp: 0.9668 - mse: 1.3752e-04\n",
      "Epoch 604: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.0933 - bpp: 0.9668 - mse: 1.3752e-04\n",
      "Epoch 605/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9129 - bpp: 0.9323 - mse: 1.1970e-04\n",
      "Epoch 605: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 1.9129 - bpp: 0.9323 - mse: 1.1970e-04\n",
      "Epoch 606/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1576 - bpp: 0.9824 - mse: 1.4346e-04\n",
      "Epoch 606: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 258ms/step - loss: 2.1576 - bpp: 0.9824 - mse: 1.4346e-04\n",
      "Epoch 607/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8402 - bpp: 0.9045 - mse: 1.1423e-04\n",
      "Epoch 607: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8402 - bpp: 0.9045 - mse: 1.1423e-04\n",
      "Epoch 608/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2073 - bpp: 1.0120 - mse: 1.4591e-04\n",
      "Epoch 608: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.2073 - bpp: 1.0120 - mse: 1.4591e-04\n",
      "Epoch 609/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0360 - bpp: 0.9696 - mse: 1.3018e-04\n",
      "Epoch 609: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 251ms/step - loss: 2.0360 - bpp: 0.9696 - mse: 1.3018e-04\n",
      "Epoch 610/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9443 - bpp: 0.9566 - mse: 1.2057e-04\n",
      "Epoch 610: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.9443 - bpp: 0.9566 - mse: 1.2057e-04\n",
      "Epoch 611/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9794 - bpp: 0.9450 - mse: 1.2626e-04\n",
      "Epoch 611: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.9794 - bpp: 0.9450 - mse: 1.2626e-04\n",
      "Epoch 612/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9049 - bpp: 0.9463 - mse: 1.1701e-04\n",
      "Epoch 612: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9049 - bpp: 0.9463 - mse: 1.1701e-04\n",
      "Epoch 613/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9249 - bpp: 0.9395 - mse: 1.2028e-04\n",
      "Epoch 613: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 1.9249 - bpp: 0.9395 - mse: 1.2028e-04\n",
      "Epoch 614/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2335 - bpp: 1.0130 - mse: 1.4898e-04\n",
      "Epoch 614: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.2335 - bpp: 1.0130 - mse: 1.4898e-04\n",
      "Epoch 615/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9449 - bpp: 0.9379 - mse: 1.2292e-04\n",
      "Epoch 615: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.9449 - bpp: 0.9379 - mse: 1.2292e-04\n",
      "Epoch 616/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9651 - bpp: 0.9598 - mse: 1.2273e-04\n",
      "Epoch 616: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.9651 - bpp: 0.9598 - mse: 1.2273e-04\n",
      "Epoch 617/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1721 - bpp: 1.0030 - mse: 1.4271e-04\n",
      "Epoch 617: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.1721 - bpp: 1.0030 - mse: 1.4271e-04\n",
      "Epoch 618/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1210 - bpp: 0.9769 - mse: 1.3967e-04\n",
      "Epoch 618: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.1210 - bpp: 0.9769 - mse: 1.3967e-04\n",
      "Epoch 619/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9437 - bpp: 0.9609 - mse: 1.1998e-04\n",
      "Epoch 619: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9437 - bpp: 0.9609 - mse: 1.1998e-04\n",
      "Epoch 620/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9758 - bpp: 0.9319 - mse: 1.2742e-04\n",
      "Epoch 620: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.9758 - bpp: 0.9319 - mse: 1.2742e-04\n",
      "Epoch 621/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0715 - bpp: 0.9529 - mse: 1.3655e-04\n",
      "Epoch 621: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.0715 - bpp: 0.9529 - mse: 1.3655e-04\n",
      "Epoch 622/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0393 - bpp: 0.9657 - mse: 1.3106e-04\n",
      "Epoch 622: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 2.0393 - bpp: 0.9657 - mse: 1.3106e-04\n",
      "Epoch 623/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0696 - bpp: 0.9465 - mse: 1.3709e-04\n",
      "Epoch 623: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.0696 - bpp: 0.9465 - mse: 1.3709e-04\n",
      "Epoch 624/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8687 - bpp: 0.9138 - mse: 1.1657e-04\n",
      "Epoch 624: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.8687 - bpp: 0.9138 - mse: 1.1657e-04\n",
      "Epoch 625/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0380 - bpp: 0.9687 - mse: 1.3053e-04\n",
      "Epoch 625: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0380 - bpp: 0.9687 - mse: 1.3053e-04\n",
      "Epoch 626/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9976 - bpp: 0.9479 - mse: 1.2813e-04\n",
      "Epoch 626: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.9976 - bpp: 0.9479 - mse: 1.2813e-04\n",
      "Epoch 627/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9347 - bpp: 0.9519 - mse: 1.1998e-04\n",
      "Epoch 627: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9347 - bpp: 0.9519 - mse: 1.1998e-04\n",
      "Epoch 628/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1564 - bpp: 1.0074 - mse: 1.4026e-04\n",
      "Epoch 628: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.1564 - bpp: 1.0074 - mse: 1.4026e-04\n",
      "Epoch 629/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0483 - bpp: 0.9651 - mse: 1.3223e-04\n",
      "Epoch 629: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.0483 - bpp: 0.9651 - mse: 1.3223e-04\n",
      "Epoch 630/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1119 - bpp: 0.9777 - mse: 1.3845e-04\n",
      "Epoch 630: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.1119 - bpp: 0.9777 - mse: 1.3845e-04\n",
      "Epoch 631/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9795 - bpp: 0.9611 - mse: 1.2432e-04\n",
      "Epoch 631: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 252ms/step - loss: 1.9795 - bpp: 0.9611 - mse: 1.2432e-04\n",
      "Epoch 632/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8939 - bpp: 0.9261 - mse: 1.1814e-04\n",
      "Epoch 632: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.8939 - bpp: 0.9261 - mse: 1.1814e-04\n",
      "Epoch 633/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1192 - bpp: 0.9874 - mse: 1.3816e-04\n",
      "Epoch 633: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 2.1192 - bpp: 0.9874 - mse: 1.3816e-04\n",
      "Epoch 634/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1800 - bpp: 0.9848 - mse: 1.4590e-04\n",
      "Epoch 634: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.1800 - bpp: 0.9848 - mse: 1.4590e-04\n",
      "Epoch 635/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1605 - bpp: 0.9979 - mse: 1.4191e-04\n",
      "Epoch 635: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.1605 - bpp: 0.9979 - mse: 1.4191e-04\n",
      "Epoch 636/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8332 - bpp: 0.9152 - mse: 1.1206e-04\n",
      "Epoch 636: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.8332 - bpp: 0.9152 - mse: 1.1206e-04\n",
      "Epoch 637/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9462 - bpp: 0.9484 - mse: 1.2180e-04\n",
      "Epoch 637: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 1.9462 - bpp: 0.9484 - mse: 1.2180e-04\n",
      "Epoch 638/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0245 - bpp: 0.9669 - mse: 1.2911e-04\n",
      "Epoch 638: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.0245 - bpp: 0.9669 - mse: 1.2911e-04\n",
      "Epoch 639/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8803 - bpp: 0.9463 - mse: 1.1401e-04\n",
      "Epoch 639: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.8803 - bpp: 0.9463 - mse: 1.1401e-04\n",
      "Epoch 640/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1101 - bpp: 0.9720 - mse: 1.3892e-04\n",
      "Epoch 640: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.1101 - bpp: 0.9720 - mse: 1.3892e-04\n",
      "Epoch 641/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9545 - bpp: 0.9621 - mse: 1.2114e-04\n",
      "Epoch 641: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.9545 - bpp: 0.9621 - mse: 1.2114e-04\n",
      "Epoch 642/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8871 - bpp: 0.9284 - mse: 1.1702e-04\n",
      "Epoch 642: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 1.8871 - bpp: 0.9284 - mse: 1.1702e-04\n",
      "Epoch 643/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3633 - bpp: 1.0150 - mse: 1.6459e-04\n",
      "Epoch 643: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.3633 - bpp: 1.0150 - mse: 1.6459e-04\n",
      "Epoch 644/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9259 - bpp: 0.9521 - mse: 1.1886e-04\n",
      "Epoch 644: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.9259 - bpp: 0.9521 - mse: 1.1886e-04\n",
      "Epoch 645/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9875 - bpp: 0.9541 - mse: 1.2616e-04\n",
      "Epoch 645: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.9875 - bpp: 0.9541 - mse: 1.2616e-04\n",
      "Epoch 646/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8760 - bpp: 0.9445 - mse: 1.1372e-04\n",
      "Epoch 646: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.8760 - bpp: 0.9445 - mse: 1.1372e-04\n",
      "Epoch 647/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1672 - bpp: 1.0045 - mse: 1.4193e-04\n",
      "Epoch 647: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.1672 - bpp: 1.0045 - mse: 1.4193e-04\n",
      "Epoch 648/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8121 - bpp: 0.9222 - mse: 1.0864e-04\n",
      "Epoch 648: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.8121 - bpp: 0.9222 - mse: 1.0864e-04\n",
      "Epoch 649/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0568 - bpp: 0.9627 - mse: 1.3356e-04\n",
      "Epoch 649: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 26s 253ms/step - loss: 2.0568 - bpp: 0.9627 - mse: 1.3356e-04\n",
      "Epoch 650/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9192 - bpp: 0.9459 - mse: 1.1880e-04\n",
      "Epoch 650: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 28s 267ms/step - loss: 1.9192 - bpp: 0.9459 - mse: 1.1880e-04\n",
      "Epoch 651/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0750 - bpp: 0.9658 - mse: 1.3540e-04\n",
      "Epoch 651: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 2.0750 - bpp: 0.9658 - mse: 1.3540e-04\n",
      "Epoch 652/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1743 - bpp: 0.9910 - mse: 1.4445e-04\n",
      "Epoch 652: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.1743 - bpp: 0.9910 - mse: 1.4445e-04\n",
      "Epoch 653/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1951 - bpp: 0.9927 - mse: 1.4677e-04\n",
      "Epoch 653: loss did not improve from 1.73323\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.1951 - bpp: 0.9927 - mse: 1.4677e-04\n",
      "Epoch 654/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7190 - bpp: 0.8977 - mse: 1.0025e-04\n",
      "Epoch 654: loss improved from 1.73323 to 1.71900, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 29s 282ms/step - loss: 1.7190 - bpp: 0.8977 - mse: 1.0025e-04\n",
      "Epoch 655/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8704 - bpp: 0.9408 - mse: 1.1348e-04\n",
      "Epoch 655: loss did not improve from 1.71900\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8704 - bpp: 0.9408 - mse: 1.1348e-04\n",
      "Epoch 656/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0047 - bpp: 0.9478 - mse: 1.2901e-04\n",
      "Epoch 656: loss did not improve from 1.71900\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0047 - bpp: 0.9478 - mse: 1.2901e-04\n",
      "Epoch 657/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2989 - bpp: 1.0025 - mse: 1.5826e-04\n",
      "Epoch 657: loss did not improve from 1.71900\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 2.2989 - bpp: 1.0025 - mse: 1.5826e-04\n",
      "Epoch 658/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8983 - bpp: 0.9269 - mse: 1.1858e-04\n",
      "Epoch 658: loss did not improve from 1.71900\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8983 - bpp: 0.9269 - mse: 1.1858e-04\n",
      "Epoch 659/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9379 - bpp: 0.9226 - mse: 1.2394e-04\n",
      "Epoch 659: loss did not improve from 1.71900\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.9379 - bpp: 0.9226 - mse: 1.2394e-04\n",
      "Epoch 660/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1993 - bpp: 1.0097 - mse: 1.4522e-04\n",
      "Epoch 660: loss did not improve from 1.71900\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.1993 - bpp: 1.0097 - mse: 1.4522e-04\n",
      "Epoch 661/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6772 - bpp: 0.8530 - mse: 1.0061e-04\n",
      "Epoch 661: loss improved from 1.71900 to 1.67721, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.6772 - bpp: 0.8530 - mse: 1.0061e-04\n",
      "Epoch 662/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7500 - bpp: 0.9002 - mse: 1.0375e-04\n",
      "Epoch 662: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.7500 - bpp: 0.9002 - mse: 1.0375e-04\n",
      "Epoch 663/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7923 - bpp: 0.9151 - mse: 1.0708e-04\n",
      "Epoch 663: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.7923 - bpp: 0.9151 - mse: 1.0708e-04\n",
      "Epoch 664/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3150 - bpp: 1.0079 - mse: 1.5955e-04\n",
      "Epoch 664: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.3150 - bpp: 1.0079 - mse: 1.5955e-04\n",
      "Epoch 665/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1248 - bpp: 0.9936 - mse: 1.3809e-04\n",
      "Epoch 665: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 2.1248 - bpp: 0.9936 - mse: 1.3809e-04\n",
      "Epoch 666/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8463 - bpp: 0.8974 - mse: 1.1584e-04\n",
      "Epoch 666: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.8463 - bpp: 0.8974 - mse: 1.1584e-04\n",
      "Epoch 667/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0672 - bpp: 0.9625 - mse: 1.3485e-04\n",
      "Epoch 667: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.0672 - bpp: 0.9625 - mse: 1.3485e-04\n",
      "Epoch 668/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4244 - bpp: 1.0448 - mse: 1.6841e-04\n",
      "Epoch 668: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.4244 - bpp: 1.0448 - mse: 1.6841e-04\n",
      "Epoch 669/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9858 - bpp: 0.9392 - mse: 1.2777e-04\n",
      "Epoch 669: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.9858 - bpp: 0.9392 - mse: 1.2777e-04\n",
      "Epoch 670/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9836 - bpp: 0.9505 - mse: 1.2611e-04\n",
      "Epoch 670: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.9836 - bpp: 0.9505 - mse: 1.2611e-04\n",
      "Epoch 671/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8154 - bpp: 0.9006 - mse: 1.1167e-04\n",
      "Epoch 671: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.8154 - bpp: 0.9006 - mse: 1.1167e-04\n",
      "Epoch 672/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7532 - bpp: 0.9119 - mse: 1.0270e-04\n",
      "Epoch 672: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 1.7532 - bpp: 0.9119 - mse: 1.0270e-04\n",
      "Epoch 673/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9477 - bpp: 0.9573 - mse: 1.2089e-04\n",
      "Epoch 673: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.9477 - bpp: 0.9573 - mse: 1.2089e-04\n",
      "Epoch 674/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0696 - bpp: 0.9874 - mse: 1.3210e-04\n",
      "Epoch 674: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.0696 - bpp: 0.9874 - mse: 1.3210e-04\n",
      "Epoch 675/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0649 - bpp: 0.9632 - mse: 1.3449e-04\n",
      "Epoch 675: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 260ms/step - loss: 2.0649 - bpp: 0.9632 - mse: 1.3449e-04\n",
      "Epoch 676/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9702 - bpp: 0.9683 - mse: 1.2230e-04\n",
      "Epoch 676: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9702 - bpp: 0.9683 - mse: 1.2230e-04\n",
      "Epoch 677/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7091 - bpp: 0.8912 - mse: 9.9842e-05\n",
      "Epoch 677: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.7091 - bpp: 0.8912 - mse: 9.9842e-05\n",
      "Epoch 678/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0634 - bpp: 0.9695 - mse: 1.3353e-04\n",
      "Epoch 678: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.0634 - bpp: 0.9695 - mse: 1.3353e-04\n",
      "Epoch 679/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1062 - bpp: 0.9797 - mse: 1.3752e-04\n",
      "Epoch 679: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.1062 - bpp: 0.9797 - mse: 1.3752e-04\n",
      "Epoch 680/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9830 - bpp: 0.9472 - mse: 1.2645e-04\n",
      "Epoch 680: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.9830 - bpp: 0.9472 - mse: 1.2645e-04\n",
      "Epoch 681/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8186 - bpp: 0.9185 - mse: 1.0987e-04\n",
      "Epoch 681: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.8186 - bpp: 0.9185 - mse: 1.0987e-04\n",
      "Epoch 682/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9442 - bpp: 0.9432 - mse: 1.2219e-04\n",
      "Epoch 682: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.9442 - bpp: 0.9432 - mse: 1.2219e-04\n",
      "Epoch 683/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1915 - bpp: 1.0001 - mse: 1.4543e-04\n",
      "Epoch 683: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.1915 - bpp: 1.0001 - mse: 1.4543e-04\n",
      "Epoch 684/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7524 - bpp: 0.9102 - mse: 1.0281e-04\n",
      "Epoch 684: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.7524 - bpp: 0.9102 - mse: 1.0281e-04\n",
      "Epoch 685/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1586 - bpp: 1.0116 - mse: 1.4001e-04\n",
      "Epoch 685: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.1586 - bpp: 1.0116 - mse: 1.4001e-04\n",
      "Epoch 686/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7842 - bpp: 0.8757 - mse: 1.1090e-04\n",
      "Epoch 686: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 1.7842 - bpp: 0.8757 - mse: 1.1090e-04\n",
      "Epoch 687/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9856 - bpp: 0.9268 - mse: 1.2924e-04\n",
      "Epoch 687: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.9856 - bpp: 0.9268 - mse: 1.2924e-04\n",
      "Epoch 688/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8591 - bpp: 0.9278 - mse: 1.1369e-04\n",
      "Epoch 688: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8591 - bpp: 0.9278 - mse: 1.1369e-04\n",
      "Epoch 689/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9008 - bpp: 0.9219 - mse: 1.1950e-04\n",
      "Epoch 689: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.9008 - bpp: 0.9219 - mse: 1.1950e-04\n",
      "Epoch 690/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8697 - bpp: 0.9326 - mse: 1.1440e-04\n",
      "Epoch 690: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.8697 - bpp: 0.9326 - mse: 1.1440e-04\n",
      "Epoch 691/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1989 - bpp: 0.9797 - mse: 1.4884e-04\n",
      "Epoch 691: loss did not improve from 1.67721\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.1989 - bpp: 0.9797 - mse: 1.4884e-04\n",
      "Epoch 692/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6424 - bpp: 0.8648 - mse: 9.4920e-05\n",
      "Epoch 692: loss improved from 1.67721 to 1.64241, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.6424 - bpp: 0.8648 - mse: 9.4920e-05\n",
      "Epoch 693/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2065 - bpp: 0.9986 - mse: 1.4745e-04\n",
      "Epoch 693: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.2065 - bpp: 0.9986 - mse: 1.4745e-04\n",
      "Epoch 694/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2628 - bpp: 1.0075 - mse: 1.5324e-04\n",
      "Epoch 694: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 2.2628 - bpp: 1.0075 - mse: 1.5324e-04\n",
      "Epoch 695/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7331 - bpp: 0.8930 - mse: 1.0255e-04\n",
      "Epoch 695: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.7331 - bpp: 0.8930 - mse: 1.0255e-04\n",
      "Epoch 696/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8022 - bpp: 0.8969 - mse: 1.1051e-04\n",
      "Epoch 696: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.8022 - bpp: 0.8969 - mse: 1.1051e-04\n",
      "Epoch 697/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9888 - bpp: 0.9798 - mse: 1.2316e-04\n",
      "Epoch 697: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.9888 - bpp: 0.9798 - mse: 1.2316e-04\n",
      "Epoch 698/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9723 - bpp: 0.9546 - mse: 1.2422e-04\n",
      "Epoch 698: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.9723 - bpp: 0.9546 - mse: 1.2422e-04\n",
      "Epoch 699/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0031 - bpp: 0.9522 - mse: 1.2828e-04\n",
      "Epoch 699: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.0031 - bpp: 0.9522 - mse: 1.2828e-04\n",
      "Epoch 700/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9879 - bpp: 0.9550 - mse: 1.2608e-04\n",
      "Epoch 700: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.9879 - bpp: 0.9550 - mse: 1.2608e-04\n",
      "Epoch 701/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0004 - bpp: 0.9472 - mse: 1.2857e-04\n",
      "Epoch 701: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.0004 - bpp: 0.9472 - mse: 1.2857e-04\n",
      "Epoch 702/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2132 - bpp: 0.9834 - mse: 1.5013e-04\n",
      "Epoch 702: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.2132 - bpp: 0.9834 - mse: 1.5013e-04\n",
      "Epoch 703/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0379 - bpp: 0.9730 - mse: 1.2999e-04\n",
      "Epoch 703: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.0379 - bpp: 0.9730 - mse: 1.2999e-04\n",
      "Epoch 704/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9556 - bpp: 0.9528 - mse: 1.2241e-04\n",
      "Epoch 704: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.9556 - bpp: 0.9528 - mse: 1.2241e-04\n",
      "Epoch 705/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8246 - bpp: 0.9235 - mse: 1.1000e-04\n",
      "Epoch 705: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.8246 - bpp: 0.9235 - mse: 1.1000e-04\n",
      "Epoch 706/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9615 - bpp: 0.9567 - mse: 1.2266e-04\n",
      "Epoch 706: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 1.9615 - bpp: 0.9567 - mse: 1.2266e-04\n",
      "Epoch 707/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9626 - bpp: 0.9559 - mse: 1.2288e-04\n",
      "Epoch 707: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.9626 - bpp: 0.9559 - mse: 1.2288e-04\n",
      "Epoch 708/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9641 - bpp: 0.9429 - mse: 1.2465e-04\n",
      "Epoch 708: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.9641 - bpp: 0.9429 - mse: 1.2465e-04\n",
      "Epoch 709/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9605 - bpp: 0.9358 - mse: 1.2509e-04\n",
      "Epoch 709: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.9605 - bpp: 0.9358 - mse: 1.2509e-04\n",
      "Epoch 710/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1841 - bpp: 0.9887 - mse: 1.4592e-04\n",
      "Epoch 710: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 2.1841 - bpp: 0.9887 - mse: 1.4592e-04\n",
      "Epoch 711/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8683 - bpp: 0.9393 - mse: 1.1340e-04\n",
      "Epoch 711: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8683 - bpp: 0.9393 - mse: 1.1340e-04\n",
      "Epoch 712/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8292 - bpp: 0.9248 - mse: 1.1041e-04\n",
      "Epoch 712: loss did not improve from 1.64241\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.8292 - bpp: 0.9248 - mse: 1.1041e-04\n",
      "Epoch 713/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6380 - bpp: 0.8710 - mse: 9.3626e-05\n",
      "Epoch 713: loss improved from 1.64241 to 1.63796, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.6380 - bpp: 0.8710 - mse: 9.3626e-05\n",
      "Epoch 714/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8343 - bpp: 0.9234 - mse: 1.1120e-04\n",
      "Epoch 714: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8343 - bpp: 0.9234 - mse: 1.1120e-04\n",
      "Epoch 715/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0541 - bpp: 0.9807 - mse: 1.3103e-04\n",
      "Epoch 715: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.0541 - bpp: 0.9807 - mse: 1.3103e-04\n",
      "Epoch 716/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0452 - bpp: 0.9632 - mse: 1.3207e-04\n",
      "Epoch 716: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.0452 - bpp: 0.9632 - mse: 1.3207e-04\n",
      "Epoch 717/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9813 - bpp: 0.9429 - mse: 1.2676e-04\n",
      "Epoch 717: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 1.9813 - bpp: 0.9429 - mse: 1.2676e-04\n",
      "Epoch 718/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8679 - bpp: 0.9284 - mse: 1.1469e-04\n",
      "Epoch 718: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.8679 - bpp: 0.9284 - mse: 1.1469e-04\n",
      "Epoch 719/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7335 - bpp: 0.8854 - mse: 1.0354e-04\n",
      "Epoch 719: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.7335 - bpp: 0.8854 - mse: 1.0354e-04\n",
      "Epoch 720/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2259 - bpp: 1.0186 - mse: 1.4737e-04\n",
      "Epoch 720: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.2259 - bpp: 1.0186 - mse: 1.4737e-04\n",
      "Epoch 721/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1576 - bpp: 0.9934 - mse: 1.4212e-04\n",
      "Epoch 721: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.1576 - bpp: 0.9934 - mse: 1.4212e-04\n",
      "Epoch 722/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0301 - bpp: 0.9752 - mse: 1.2877e-04\n",
      "Epoch 722: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 2.0301 - bpp: 0.9752 - mse: 1.2877e-04\n",
      "Epoch 723/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9440 - bpp: 0.9456 - mse: 1.2188e-04\n",
      "Epoch 723: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.9440 - bpp: 0.9456 - mse: 1.2188e-04\n",
      "Epoch 724/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.3551 - bpp: 1.0280 - mse: 1.6199e-04\n",
      "Epoch 724: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 2.3551 - bpp: 1.0280 - mse: 1.6199e-04\n",
      "Epoch 725/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8562 - bpp: 0.8997 - mse: 1.1676e-04\n",
      "Epoch 725: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.8562 - bpp: 0.8997 - mse: 1.1676e-04\n",
      "Epoch 726/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0012 - bpp: 0.9214 - mse: 1.3181e-04\n",
      "Epoch 726: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 270ms/step - loss: 2.0012 - bpp: 0.9214 - mse: 1.3181e-04\n",
      "Epoch 727/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9338 - bpp: 0.9527 - mse: 1.1976e-04\n",
      "Epoch 727: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 1.9338 - bpp: 0.9527 - mse: 1.1976e-04\n",
      "Epoch 728/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8881 - bpp: 0.9222 - mse: 1.1790e-04\n",
      "Epoch 728: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.8881 - bpp: 0.9222 - mse: 1.1790e-04\n",
      "Epoch 729/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7992 - bpp: 0.9084 - mse: 1.0874e-04\n",
      "Epoch 729: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.7992 - bpp: 0.9084 - mse: 1.0874e-04\n",
      "Epoch 730/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0234 - bpp: 0.9652 - mse: 1.2917e-04\n",
      "Epoch 730: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 2.0234 - bpp: 0.9652 - mse: 1.2917e-04\n",
      "Epoch 731/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9751 - bpp: 0.9616 - mse: 1.2373e-04\n",
      "Epoch 731: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.9751 - bpp: 0.9616 - mse: 1.2373e-04\n",
      "Epoch 732/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2581 - bpp: 1.0188 - mse: 1.5129e-04\n",
      "Epoch 732: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 31s 303ms/step - loss: 2.2581 - bpp: 1.0188 - mse: 1.5129e-04\n",
      "Epoch 733/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0842 - bpp: 0.9910 - mse: 1.3344e-04\n",
      "Epoch 733: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.0842 - bpp: 0.9910 - mse: 1.3344e-04\n",
      "Epoch 734/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9181 - bpp: 0.9114 - mse: 1.2288e-04\n",
      "Epoch 734: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.9181 - bpp: 0.9114 - mse: 1.2288e-04\n",
      "Epoch 735/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7968 - bpp: 0.9013 - mse: 1.0931e-04\n",
      "Epoch 735: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.7968 - bpp: 0.9013 - mse: 1.0931e-04\n",
      "Epoch 736/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1393 - bpp: 0.9793 - mse: 1.4160e-04\n",
      "Epoch 736: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.1393 - bpp: 0.9793 - mse: 1.4160e-04\n",
      "Epoch 737/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1245 - bpp: 0.9872 - mse: 1.3884e-04\n",
      "Epoch 737: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.1245 - bpp: 0.9872 - mse: 1.3884e-04\n",
      "Epoch 738/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9606 - bpp: 0.9633 - mse: 1.2174e-04\n",
      "Epoch 738: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.9606 - bpp: 0.9633 - mse: 1.2174e-04\n",
      "Epoch 739/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0088 - bpp: 0.9533 - mse: 1.2883e-04\n",
      "Epoch 739: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.0088 - bpp: 0.9533 - mse: 1.2883e-04\n",
      "Epoch 740/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8643 - bpp: 0.9375 - mse: 1.1313e-04\n",
      "Epoch 740: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8643 - bpp: 0.9375 - mse: 1.1313e-04\n",
      "Epoch 741/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2530 - bpp: 1.0220 - mse: 1.5027e-04\n",
      "Epoch 741: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 30s 292ms/step - loss: 2.2530 - bpp: 1.0220 - mse: 1.5027e-04\n",
      "Epoch 742/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0188 - bpp: 0.9430 - mse: 1.3131e-04\n",
      "Epoch 742: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.0188 - bpp: 0.9430 - mse: 1.3131e-04\n",
      "Epoch 743/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0259 - bpp: 0.9464 - mse: 1.3178e-04\n",
      "Epoch 743: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.0259 - bpp: 0.9464 - mse: 1.3178e-04\n",
      "Epoch 744/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6538 - bpp: 0.8804 - mse: 9.4417e-05\n",
      "Epoch 744: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.6538 - bpp: 0.8804 - mse: 9.4417e-05\n",
      "Epoch 745/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8872 - bpp: 0.9319 - mse: 1.1661e-04\n",
      "Epoch 745: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.8872 - bpp: 0.9319 - mse: 1.1661e-04\n",
      "Epoch 746/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9907 - bpp: 0.9541 - mse: 1.2653e-04\n",
      "Epoch 746: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.9907 - bpp: 0.9541 - mse: 1.2653e-04\n",
      "Epoch 747/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9890 - bpp: 0.9677 - mse: 1.2467e-04\n",
      "Epoch 747: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.9890 - bpp: 0.9677 - mse: 1.2467e-04\n",
      "Epoch 748/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8928 - bpp: 0.9370 - mse: 1.1668e-04\n",
      "Epoch 748: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.8928 - bpp: 0.9370 - mse: 1.1668e-04\n",
      "Epoch 749/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9536 - bpp: 0.9364 - mse: 1.2416e-04\n",
      "Epoch 749: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 1.9536 - bpp: 0.9364 - mse: 1.2416e-04\n",
      "Epoch 750/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9607 - bpp: 0.9448 - mse: 1.2401e-04\n",
      "Epoch 750: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.9607 - bpp: 0.9448 - mse: 1.2401e-04\n",
      "Epoch 751/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1958 - bpp: 1.0004 - mse: 1.4593e-04\n",
      "Epoch 751: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 29s 280ms/step - loss: 2.1958 - bpp: 1.0004 - mse: 1.4593e-04\n",
      "Epoch 752/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8418 - bpp: 0.9090 - mse: 1.1386e-04\n",
      "Epoch 752: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.8418 - bpp: 0.9090 - mse: 1.1386e-04\n",
      "Epoch 753/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0669 - bpp: 0.9672 - mse: 1.3425e-04\n",
      "Epoch 753: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.0669 - bpp: 0.9672 - mse: 1.3425e-04\n",
      "Epoch 754/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8894 - bpp: 0.9199 - mse: 1.1835e-04\n",
      "Epoch 754: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 274ms/step - loss: 1.8894 - bpp: 0.9199 - mse: 1.1835e-04\n",
      "Epoch 755/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7737 - bpp: 0.8993 - mse: 1.0674e-04\n",
      "Epoch 755: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 29s 281ms/step - loss: 1.7737 - bpp: 0.8993 - mse: 1.0674e-04\n",
      "Epoch 756/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8996 - bpp: 0.9425 - mse: 1.1682e-04\n",
      "Epoch 756: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.8996 - bpp: 0.9425 - mse: 1.1682e-04\n",
      "Epoch 757/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8233 - bpp: 0.9241 - mse: 1.0976e-04\n",
      "Epoch 757: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.8233 - bpp: 0.9241 - mse: 1.0976e-04\n",
      "Epoch 758/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7750 - bpp: 0.9174 - mse: 1.0470e-04\n",
      "Epoch 758: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.7750 - bpp: 0.9174 - mse: 1.0470e-04\n",
      "Epoch 759/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9274 - bpp: 0.9280 - mse: 1.2200e-04\n",
      "Epoch 759: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 30s 292ms/step - loss: 1.9274 - bpp: 0.9280 - mse: 1.2200e-04\n",
      "Epoch 760/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0186 - bpp: 0.9557 - mse: 1.2974e-04\n",
      "Epoch 760: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 261ms/step - loss: 2.0186 - bpp: 0.9557 - mse: 1.2974e-04\n",
      "Epoch 761/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8238 - bpp: 0.9024 - mse: 1.1246e-04\n",
      "Epoch 761: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.8238 - bpp: 0.9024 - mse: 1.1246e-04\n",
      "Epoch 762/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7577 - bpp: 0.9053 - mse: 1.0405e-04\n",
      "Epoch 762: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.7577 - bpp: 0.9053 - mse: 1.0405e-04\n",
      "Epoch 763/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0037 - bpp: 0.9545 - mse: 1.2808e-04\n",
      "Epoch 763: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.0037 - bpp: 0.9545 - mse: 1.2808e-04\n",
      "Epoch 764/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8818 - bpp: 0.9159 - mse: 1.1790e-04\n",
      "Epoch 764: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 273ms/step - loss: 1.8818 - bpp: 0.9159 - mse: 1.1790e-04\n",
      "Epoch 765/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9231 - bpp: 0.9380 - mse: 1.2025e-04\n",
      "Epoch 765: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.9231 - bpp: 0.9380 - mse: 1.2025e-04\n",
      "Epoch 766/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0561 - bpp: 0.9819 - mse: 1.3114e-04\n",
      "Epoch 766: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 2.0561 - bpp: 0.9819 - mse: 1.3114e-04\n",
      "Epoch 767/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1411 - bpp: 0.9742 - mse: 1.4244e-04\n",
      "Epoch 767: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 271ms/step - loss: 2.1411 - bpp: 0.9742 - mse: 1.4244e-04\n",
      "Epoch 768/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9371 - bpp: 0.9184 - mse: 1.2435e-04\n",
      "Epoch 768: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.9371 - bpp: 0.9184 - mse: 1.2435e-04\n",
      "Epoch 769/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8151 - bpp: 0.9217 - mse: 1.0905e-04\n",
      "Epoch 769: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 29s 284ms/step - loss: 1.8151 - bpp: 0.9217 - mse: 1.0905e-04\n",
      "Epoch 770/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0190 - bpp: 0.9635 - mse: 1.2884e-04\n",
      "Epoch 770: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 2.0190 - bpp: 0.9635 - mse: 1.2884e-04\n",
      "Epoch 771/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1562 - bpp: 0.9719 - mse: 1.4457e-04\n",
      "Epoch 771: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.1562 - bpp: 0.9719 - mse: 1.4457e-04\n",
      "Epoch 772/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8823 - bpp: 0.9473 - mse: 1.1414e-04\n",
      "Epoch 772: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.8823 - bpp: 0.9473 - mse: 1.1414e-04\n",
      "Epoch 773/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6636 - bpp: 0.8749 - mse: 9.6274e-05\n",
      "Epoch 773: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.6636 - bpp: 0.8749 - mse: 9.6274e-05\n",
      "Epoch 774/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7364 - bpp: 0.8981 - mse: 1.0233e-04\n",
      "Epoch 774: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.7364 - bpp: 0.8981 - mse: 1.0233e-04\n",
      "Epoch 775/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0798 - bpp: 0.9933 - mse: 1.3262e-04\n",
      "Epoch 775: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.0798 - bpp: 0.9933 - mse: 1.3262e-04\n",
      "Epoch 776/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8997 - bpp: 0.9384 - mse: 1.1735e-04\n",
      "Epoch 776: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 263ms/step - loss: 1.8997 - bpp: 0.9384 - mse: 1.1735e-04\n",
      "Epoch 777/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8433 - bpp: 0.9092 - mse: 1.1403e-04\n",
      "Epoch 777: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8433 - bpp: 0.9092 - mse: 1.1403e-04\n",
      "Epoch 778/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9573 - bpp: 0.9728 - mse: 1.2018e-04\n",
      "Epoch 778: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 272ms/step - loss: 1.9573 - bpp: 0.9728 - mse: 1.2018e-04\n",
      "Epoch 779/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9076 - bpp: 0.9407 - mse: 1.1803e-04\n",
      "Epoch 779: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.9076 - bpp: 0.9407 - mse: 1.1803e-04\n",
      "Epoch 780/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9403 - bpp: 0.9268 - mse: 1.2371e-04\n",
      "Epoch 780: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.9403 - bpp: 0.9268 - mse: 1.2371e-04\n",
      "Epoch 781/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0060 - bpp: 0.9569 - mse: 1.2807e-04\n",
      "Epoch 781: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 2.0060 - bpp: 0.9569 - mse: 1.2807e-04\n",
      "Epoch 782/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0366 - bpp: 0.9259 - mse: 1.3558e-04\n",
      "Epoch 782: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.0366 - bpp: 0.9259 - mse: 1.3558e-04\n",
      "Epoch 783/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0017 - bpp: 0.9697 - mse: 1.2598e-04\n",
      "Epoch 783: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.0017 - bpp: 0.9697 - mse: 1.2598e-04\n",
      "Epoch 784/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0329 - bpp: 0.9296 - mse: 1.3468e-04\n",
      "Epoch 784: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.0329 - bpp: 0.9296 - mse: 1.3468e-04\n",
      "Epoch 785/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9609 - bpp: 0.9497 - mse: 1.2345e-04\n",
      "Epoch 785: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.9609 - bpp: 0.9497 - mse: 1.2345e-04\n",
      "Epoch 786/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8846 - bpp: 0.9339 - mse: 1.1606e-04\n",
      "Epoch 786: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 1.8846 - bpp: 0.9339 - mse: 1.1606e-04\n",
      "Epoch 787/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7712 - bpp: 0.8997 - mse: 1.0639e-04\n",
      "Epoch 787: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.7712 - bpp: 0.8997 - mse: 1.0639e-04\n",
      "Epoch 788/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7828 - bpp: 0.9101 - mse: 1.0653e-04\n",
      "Epoch 788: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.7828 - bpp: 0.9101 - mse: 1.0653e-04\n",
      "Epoch 789/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7757 - bpp: 0.9032 - mse: 1.0650e-04\n",
      "Epoch 789: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.7757 - bpp: 0.9032 - mse: 1.0650e-04\n",
      "Epoch 790/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9611 - bpp: 0.9412 - mse: 1.2450e-04\n",
      "Epoch 790: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.9611 - bpp: 0.9412 - mse: 1.2450e-04\n",
      "Epoch 791/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0349 - bpp: 0.9584 - mse: 1.3140e-04\n",
      "Epoch 791: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.0349 - bpp: 0.9584 - mse: 1.3140e-04\n",
      "Epoch 792/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1145 - bpp: 0.9993 - mse: 1.3613e-04\n",
      "Epoch 792: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 2.1145 - bpp: 0.9993 - mse: 1.3613e-04\n",
      "Epoch 793/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8840 - bpp: 0.9179 - mse: 1.1793e-04\n",
      "Epoch 793: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.8840 - bpp: 0.9179 - mse: 1.1793e-04\n",
      "Epoch 794/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0147 - bpp: 0.9647 - mse: 1.2817e-04\n",
      "Epoch 794: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.0147 - bpp: 0.9647 - mse: 1.2817e-04\n",
      "Epoch 795/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8599 - bpp: 0.9281 - mse: 1.1374e-04\n",
      "Epoch 795: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.8599 - bpp: 0.9281 - mse: 1.1374e-04\n",
      "Epoch 796/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0996 - bpp: 0.9750 - mse: 1.3727e-04\n",
      "Epoch 796: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.0996 - bpp: 0.9750 - mse: 1.3727e-04\n",
      "Epoch 797/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0721 - bpp: 0.9408 - mse: 1.3811e-04\n",
      "Epoch 797: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.0721 - bpp: 0.9408 - mse: 1.3811e-04\n",
      "Epoch 798/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9873 - bpp: 0.9575 - mse: 1.2571e-04\n",
      "Epoch 798: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.9873 - bpp: 0.9575 - mse: 1.2571e-04\n",
      "Epoch 799/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8385 - bpp: 0.9319 - mse: 1.1068e-04\n",
      "Epoch 799: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.8385 - bpp: 0.9319 - mse: 1.1068e-04\n",
      "Epoch 800/800\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.0038 - bpp: 0.9612 - mse: 1.2728e-04\n",
      "Epoch 800: loss did not improve from 1.63796\n",
      "100/100 [==============================] - 27s 262ms/step - loss: 2.0038 - bpp: 0.9612 - mse: 1.2728e-04\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "hist = model.fit(x=data, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, verbose=1, batch_size=BATCH_SIZE,\n",
    "                callbacks=[\n",
    "                    # Callbacks.MemoryCallback(),\n",
    "                    # Callbacks.LearningRateReducer(),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch', monitor=\"loss\", mode='min',  save_best_only=True, verbose=1), \n",
    "                    tf.keras.callbacks.TerminateOnNaN(),\n",
    "                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stop),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq=\"epoch\"),            \n",
    "                    ],\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00081/0197/im1.png\n",
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n"
     ]
    }
   ],
   "source": [
    "path = load.load_random_path(\"folder_cloud_test.npy\")\n",
    "i=0\n",
    "out_bin = \"Test_com/test{}.bin\".format(i)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(i)\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(i)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(i)\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, out_bin, out_decom, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_800_es_400_I_QP_27_240x240_CosineDecay_20220427-155837/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00049/0289/im1.png\n",
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00049/0289/im2.png\n",
      "compress\n",
      "decompress\n",
      "bin size:  3919 psnr:  42.516131869471266\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from math import log10, sqrt\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "\n",
    "path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "p_frame_out_bin = \"Test_com/dvcw/p_frame_dvcw.bin\"\n",
    "out_decom = \"Test_com/dvcw/frame1.png\"\n",
    "i_on_test = \"Test_com/frame0.png\"\n",
    "p_on_test = \"Test_com/frame1.png\"\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "print(p_frame)\n",
    "\n",
    "# write inputs to disk\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, p_frame_out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, p_frame_out_bin, out_decom, 240, 240)\n",
    "\n",
    "\n",
    "original = cv2.imread(p_on_test)\n",
    "compressed = cv2.imread(out_decom)\n",
    "bin_size = os.path.getsize(p_frame_out_bin)\n",
    "value = PSNR(original, compressed)\n",
    "print(\"bin size: \", bin_size , \"psnr: \", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
