{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW/train_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "import OpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import DataGen\n",
    "import Callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 700\n",
    "STEPS_PER_EPOCH = 200\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 2048\n",
    "lr_init = 1e-4\n",
    "early_stop = 15\n",
    "I_QP=27\n",
    "\n",
    "args = OpenDVCW.Arguments()\n",
    "last = 4\n",
    "checkponts_last_path = \"checkpoints_wavelets_L_{}_{}_{}x{}/\".format(lmbda, last, Width, Height)\n",
    "checkponts_new_path = \"checkpoints_wavelets_L_{}_{}_{}x{}/\".format(lmbda, last+1, Width, Height)\n",
    "save_name = \"model_save_wavelets_L_{}_{}_{}x{}\".format(lmbda, last+1, Width, Height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 20:17:23.634131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:23.722779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:23.724019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:23.731483: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-05 20:17:23.738723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:23.739713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:23.740544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:25.817520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:25.818309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:25.819032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 20:17:25.819756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "* [Loading dataset]...\n"
     ]
    }
   ],
   "source": [
    "model = OpenDVCW.OpenDVC(width=Width, height=Height, batch_size=BATCH_SIZE, num_filters=128, lmbda=lmbda)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init),)\n",
    "print(\"* [Model compiled]...\")\n",
    "\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = DataGen.DataVimeo90kGenerator(\"folder_cloud_test.npy\", \n",
    "                                    BATCH_SIZE,\n",
    "                                    (Height,Width,Channel),\n",
    "                                    Channel,\n",
    "                                    True, \n",
    "                                    I_QP,\n",
    "                                    True)\n",
    "\n",
    "# print(\"Loading weights\")\n",
    "# model.load_weights(checkponts_last_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].trainable = False\n",
    "# model.layers[1].trainable = False\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[3].trainable = True\n",
    "# model.layers[4].trainable = False\n",
    "# model.layers[5].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_analysis True\n",
      "mv_synthesis True\n",
      "res_analysis True\n",
      "res_synthesis True\n",
      "wavelets_optical_flow True\n",
      "motion_compensation True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 20:17:52.334509: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-05 20:18:27.914443: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/200 [..............................] - ETA: 40s - loss: 375.2754 - bpp: 5.3825 - mse: 0.1806WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1969s vs `on_train_batch_end` time: 0.2458s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1969s vs `on_train_batch_end` time: 0.2458s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 40.2785 - bpp: 5.3148 - mse: 0.0171[MemoryCallback]:  4832728\n",
      "\n",
      "Epoch 1: loss improved from inf to 40.27846, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 95s 198ms/step - loss: 40.2785 - bpp: 5.3148 - mse: 0.0171\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.1304 - bpp: 5.1754 - mse: 0.0029[MemoryCallback]:  4989596\n",
      "\n",
      "Epoch 2: loss improved from 40.27846 to 11.13039, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 11.1304 - bpp: 5.1754 - mse: 0.0029\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0073 - bpp: 5.0393 - mse: 0.0019[MemoryCallback]:  5118564\n",
      "\n",
      "Epoch 3: loss improved from 11.13039 to 9.00733, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 9.0073 - bpp: 5.0393 - mse: 0.0019\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0291 - bpp: 4.9058 - mse: 0.0015[MemoryCallback]:  5221644\n",
      "\n",
      "Epoch 4: loss improved from 9.00733 to 8.02907, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 36s 173ms/step - loss: 8.0291 - bpp: 4.9058 - mse: 0.0015\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5069 - bpp: 4.7745 - mse: 0.0013[MemoryCallback]:  5270288\n",
      "\n",
      "Epoch 5: loss improved from 8.02907 to 7.50686, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 34s 163ms/step - loss: 7.5069 - bpp: 4.7745 - mse: 0.0013\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2733 - bpp: 4.6458 - mse: 0.0013[MemoryCallback]:  5367388\n",
      "\n",
      "Epoch 6: loss improved from 7.50686 to 7.27327, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 7.2733 - bpp: 4.6458 - mse: 0.0013\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.7462 - bpp: 4.5208 - mse: 0.0026[MemoryCallback]:  5469460\n",
      "\n",
      "Epoch 7: loss did not improve from 7.27327\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 9.7462 - bpp: 4.5208 - mse: 0.0026\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4574 - bpp: 4.3961 - mse: 0.0015[MemoryCallback]:  5470656\n",
      "\n",
      "Epoch 8: loss did not improve from 7.27327\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 7.4574 - bpp: 4.3961 - mse: 0.0015\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5827 - bpp: 4.2742 - mse: 0.0011[MemoryCallback]:  5471940\n",
      "\n",
      "Epoch 9: loss improved from 7.27327 to 6.58268, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 6.5827 - bpp: 4.2742 - mse: 0.0011\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1790 - bpp: 4.1542 - mse: 9.8868e-04[MemoryCallback]:  5476564\n",
      "\n",
      "Epoch 10: loss improved from 6.58268 to 6.17899, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 6.1790 - bpp: 4.1542 - mse: 9.8868e-04\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7780 - bpp: 4.0366 - mse: 8.5026e-04[MemoryCallback]:  5476564\n",
      "\n",
      "Epoch 11: loss improved from 6.17899 to 5.77796, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 5.7780 - bpp: 4.0366 - mse: 8.5026e-04\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9504 - bpp: 3.9234 - mse: 9.8973e-04[MemoryCallback]:  5571628\n",
      "\n",
      "Epoch 12: loss did not improve from 5.77796\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 5.9504 - bpp: 3.9234 - mse: 9.8973e-04\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8739 - bpp: 3.8114 - mse: 0.0010[MemoryCallback]:  5622344\n",
      "\n",
      "Epoch 13: loss did not improve from 5.77796\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 5.8739 - bpp: 3.8114 - mse: 0.0010\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5016 - bpp: 3.7018 - mse: 8.7879e-04[MemoryCallback]:  5622548\n",
      "\n",
      "Epoch 14: loss improved from 5.77796 to 5.50158, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 5.5016 - bpp: 3.7018 - mse: 8.7879e-04\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1923 - bpp: 3.5954 - mse: 7.7972e-04[MemoryCallback]:  5622548\n",
      "\n",
      "Epoch 15: loss improved from 5.50158 to 5.19228, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 5.1923 - bpp: 3.5954 - mse: 7.7972e-04\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9276 - bpp: 3.4917 - mse: 7.0116e-04[MemoryCallback]:  5622932\n",
      "\n",
      "Epoch 16: loss improved from 5.19228 to 4.92764, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 4.9276 - bpp: 3.4917 - mse: 7.0116e-04\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8684 - bpp: 3.3935 - mse: 7.2016e-04[MemoryCallback]:  5623248\n",
      "\n",
      "Epoch 17: loss improved from 4.92764 to 4.86836, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 4.8684 - bpp: 3.3935 - mse: 7.2016e-04\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9252 - bpp: 3.2964 - mse: 7.9534e-04[MemoryCallback]:  5623260\n",
      "\n",
      "Epoch 18: loss did not improve from 4.86836\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 4.9252 - bpp: 3.2964 - mse: 7.9534e-04\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8976 - bpp: 3.2043 - mse: 8.2681e-04[MemoryCallback]:  5624964\n",
      "\n",
      "Epoch 19: loss did not improve from 4.86836\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 4.8976 - bpp: 3.2043 - mse: 8.2681e-04\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0133 - bpp: 3.1067 - mse: 0.0014[MemoryCallback]:  5626536\n",
      "\n",
      "Epoch 20: loss did not improve from 4.86836\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 6.0133 - bpp: 3.1067 - mse: 0.0014\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2046 - bpp: 3.0129 - mse: 5.8189e-04[MemoryCallback]:  5626536\n",
      "\n",
      "Epoch 21: loss improved from 4.86836 to 4.20460, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 4.2046 - bpp: 3.0129 - mse: 5.8189e-04\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1647 - bpp: 2.9185 - mse: 6.0851e-04[MemoryCallback]:  5722836\n",
      "\n",
      "Epoch 22: loss improved from 4.20460 to 4.16472, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 4.1647 - bpp: 2.9185 - mse: 6.0851e-04\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9674 - bpp: 2.8312 - mse: 5.5476e-04[MemoryCallback]:  5723456\n",
      "\n",
      "Epoch 23: loss improved from 4.16472 to 3.96736, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 3.9674 - bpp: 2.8312 - mse: 5.5476e-04\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7309 - bpp: 2.7448 - mse: 4.8149e-04[MemoryCallback]:  5771916\n",
      "\n",
      "Epoch 24: loss improved from 3.96736 to 3.73090, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 3.7309 - bpp: 2.7448 - mse: 4.8149e-04\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2663 - bpp: 2.6821 - mse: 7.7353e-04[MemoryCallback]:  5773444\n",
      "\n",
      "Epoch 25: loss did not improve from 3.73090\n",
      "200/200 [==============================] - 33s 160ms/step - loss: 4.2663 - bpp: 2.6821 - mse: 7.7353e-04\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7282 - bpp: 2.5874 - mse: 5.5703e-04[MemoryCallback]:  5774796\n",
      "\n",
      "Epoch 26: loss improved from 3.73090 to 3.72817, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 3.7282 - bpp: 2.5874 - mse: 5.5703e-04\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5117 - bpp: 2.5039 - mse: 4.9207e-04[MemoryCallback]:  5826056\n",
      "\n",
      "Epoch 27: loss improved from 3.72817 to 3.51170, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 3.5117 - bpp: 2.5039 - mse: 4.9207e-04\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4191 - bpp: 2.4203 - mse: 4.8769e-04[MemoryCallback]:  5830828\n",
      "\n",
      "Epoch 28: loss improved from 3.51170 to 3.41906, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 3.4191 - bpp: 2.4203 - mse: 4.8769e-04\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1432 - bpp: 2.3301 - mse: 3.9705e-04[MemoryCallback]:  5881424\n",
      "\n",
      "Epoch 29: loss improved from 3.41906 to 3.14321, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 3.1432 - bpp: 2.3301 - mse: 3.9705e-04\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0676 - bpp: 2.2685 - mse: 3.9020e-04[MemoryCallback]:  5883104\n",
      "\n",
      "Epoch 30: loss improved from 3.14321 to 3.06763, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 3.0676 - bpp: 2.2685 - mse: 3.9020e-04\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9888 - bpp: 2.1942 - mse: 3.8797e-04[MemoryCallback]:  5933572\n",
      "\n",
      "Epoch 31: loss improved from 3.06763 to 2.98881, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 2.9888 - bpp: 2.1942 - mse: 3.8797e-04\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8849 - bpp: 2.1158 - mse: 3.7554e-04[MemoryCallback]:  5936308\n",
      "\n",
      "Epoch 32: loss improved from 2.98881 to 2.88489, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 2.8849 - bpp: 2.1158 - mse: 3.7554e-04\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9515 - bpp: 2.0545 - mse: 4.3799e-04[MemoryCallback]:  5936496\n",
      "\n",
      "Epoch 33: loss did not improve from 2.88489\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 2.9515 - bpp: 2.0545 - mse: 4.3799e-04\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7350 - bpp: 1.9906 - mse: 3.6345e-04[MemoryCallback]:  5940332\n",
      "\n",
      "Epoch 34: loss improved from 2.88489 to 2.73498, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 2.7350 - bpp: 1.9906 - mse: 3.6345e-04\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6512 - bpp: 1.9152 - mse: 3.5937e-04[MemoryCallback]:  5940696\n",
      "\n",
      "Epoch 35: loss improved from 2.73498 to 2.65119, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 2.6512 - bpp: 1.9152 - mse: 3.5937e-04\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5893 - bpp: 1.8614 - mse: 3.5541e-04[MemoryCallback]:  5940960\n",
      "\n",
      "Epoch 36: loss improved from 2.65119 to 2.58931, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 34s 165ms/step - loss: 2.5893 - bpp: 1.8614 - mse: 3.5541e-04\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5290 - bpp: 1.8073 - mse: 3.5236e-04[MemoryCallback]:  5942804\n",
      "\n",
      "Epoch 37: loss improved from 2.58931 to 2.52896, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.5290 - bpp: 1.8073 - mse: 3.5236e-04\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3732 - bpp: 1.7211 - mse: 3.1841e-04[MemoryCallback]:  5945140\n",
      "\n",
      "Epoch 38: loss improved from 2.52896 to 2.37318, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.3732 - bpp: 1.7211 - mse: 3.1841e-04\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2372 - bpp: 1.6629 - mse: 2.8045e-04[MemoryCallback]:  5945484\n",
      "\n",
      "Epoch 39: loss improved from 2.37318 to 2.23722, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 2.2372 - bpp: 1.6629 - mse: 2.8045e-04\n",
      "Epoch 40/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3741 - bpp: 1.6350 - mse: 3.6086e-04[MemoryCallback]:  5998164\n",
      "\n",
      "Epoch 40: loss did not improve from 2.23722\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 2.3741 - bpp: 1.6350 - mse: 3.6086e-04\n",
      "Epoch 41/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2250 - bpp: 1.5580 - mse: 3.2568e-04[MemoryCallback]:  6046528\n",
      "\n",
      "Epoch 41: loss improved from 2.23722 to 2.22503, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 2.2250 - bpp: 1.5580 - mse: 3.2568e-04\n",
      "Epoch 42/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1320 - bpp: 1.5206 - mse: 2.9854e-04[MemoryCallback]:  6093744\n",
      "\n",
      "Epoch 42: loss improved from 2.22503 to 2.13200, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 2.1320 - bpp: 1.5206 - mse: 2.9854e-04\n",
      "Epoch 43/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1404 - bpp: 1.4716 - mse: 3.2655e-04[MemoryCallback]:  6095860\n",
      "\n",
      "Epoch 43: loss did not improve from 2.13200\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 2.1404 - bpp: 1.4716 - mse: 3.2655e-04\n",
      "Epoch 44/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0567 - bpp: 1.4276 - mse: 3.0717e-04[MemoryCallback]:  6144348\n",
      "\n",
      "Epoch 44: loss improved from 2.13200 to 2.05670, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 2.0567 - bpp: 1.4276 - mse: 3.0717e-04\n",
      "Epoch 45/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9566 - bpp: 1.3661 - mse: 2.8829e-04[MemoryCallback]:  6144696\n",
      "\n",
      "Epoch 45: loss improved from 2.05670 to 1.95657, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.9566 - bpp: 1.3661 - mse: 2.8829e-04\n",
      "Epoch 46/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9763 - bpp: 1.3390 - mse: 3.1119e-04[MemoryCallback]:  6144696\n",
      "\n",
      "Epoch 46: loss did not improve from 1.95657\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.9763 - bpp: 1.3390 - mse: 3.1119e-04\n",
      "Epoch 47/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9672 - bpp: 1.3040 - mse: 3.2382e-04[MemoryCallback]:  6144844\n",
      "\n",
      "Epoch 47: loss did not improve from 1.95657\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.9672 - bpp: 1.3040 - mse: 3.2382e-04\n",
      "Epoch 48/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9337 - bpp: 1.2706 - mse: 3.2378e-04[MemoryCallback]:  6144964\n",
      "\n",
      "Epoch 48: loss improved from 1.95657 to 1.93365, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 160ms/step - loss: 1.9337 - bpp: 1.2706 - mse: 3.2378e-04\n",
      "Epoch 49/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5209 - bpp: 1.3782 - mse: 0.0020[MemoryCallback]:  6144964\n",
      "\n",
      "Epoch 49: loss did not improve from 1.93365\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 5.5209 - bpp: 1.3782 - mse: 0.0020\n",
      "Epoch 50/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3607 - bpp: 1.2878 - mse: 5.2388e-04[MemoryCallback]:  6193944\n",
      "\n",
      "Epoch 50: loss did not improve from 1.93365\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 2.3607 - bpp: 1.2878 - mse: 5.2388e-04\n",
      "Epoch 51/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9968 - bpp: 1.2183 - mse: 3.8012e-04[MemoryCallback]:  6197952\n",
      "\n",
      "Epoch 51: loss did not improve from 1.93365\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 1.9968 - bpp: 1.2183 - mse: 3.8012e-04\n",
      "Epoch 52/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8472 - bpp: 1.1668 - mse: 3.3221e-04[MemoryCallback]:  6198168\n",
      "\n",
      "Epoch 52: loss improved from 1.93365 to 1.84717, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.8472 - bpp: 1.1668 - mse: 3.3221e-04\n",
      "Epoch 53/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8995 - bpp: 1.1568 - mse: 3.6266e-04[MemoryCallback]:  6198168\n",
      "\n",
      "Epoch 53: loss did not improve from 1.84717\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.8995 - bpp: 1.1568 - mse: 3.6266e-04\n",
      "Epoch 54/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6932 - bpp: 1.0924 - mse: 2.9335e-04[MemoryCallback]:  6200700\n",
      "\n",
      "Epoch 54: loss improved from 1.84717 to 1.69322, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.6932 - bpp: 1.0924 - mse: 2.9335e-04\n",
      "Epoch 55/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9421 - bpp: 1.1288 - mse: 3.9708e-04[MemoryCallback]:  6200832\n",
      "\n",
      "Epoch 55: loss did not improve from 1.69322\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 1.9421 - bpp: 1.1288 - mse: 3.9708e-04\n",
      "Epoch 56/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8045 - bpp: 1.0753 - mse: 3.5605e-04[MemoryCallback]:  6200832\n",
      "\n",
      "Epoch 56: loss did not improve from 1.69322\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.8045 - bpp: 1.0753 - mse: 3.5605e-04\n",
      "Epoch 57/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7752 - bpp: 1.0494 - mse: 3.5438e-04[MemoryCallback]:  6200848\n",
      "\n",
      "Epoch 57: loss did not improve from 1.69322\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.7752 - bpp: 1.0494 - mse: 3.5438e-04\n",
      "Epoch 58/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6882 - bpp: 1.0170 - mse: 3.2776e-04[MemoryCallback]:  6201252\n",
      "\n",
      "Epoch 58: loss improved from 1.69322 to 1.68823, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.6882 - bpp: 1.0170 - mse: 3.2776e-04\n",
      "Epoch 59/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6408 - bpp: 0.9844 - mse: 3.2055e-04[MemoryCallback]:  6201520\n",
      "\n",
      "Epoch 59: loss improved from 1.68823 to 1.64083, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.6408 - bpp: 0.9844 - mse: 3.2055e-04\n",
      "Epoch 60/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5351 - bpp: 0.9474 - mse: 2.8696e-04[MemoryCallback]:  6250500\n",
      "\n",
      "Epoch 60: loss improved from 1.64083 to 1.53508, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5351 - bpp: 0.9474 - mse: 2.8696e-04\n",
      "Epoch 61/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5807 - bpp: 0.9538 - mse: 3.0609e-04[MemoryCallback]:  6287324\n",
      "\n",
      "Epoch 61: loss did not improve from 1.53508\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5807 - bpp: 0.9538 - mse: 3.0609e-04\n",
      "Epoch 62/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5244 - bpp: 0.9168 - mse: 2.9667e-04[MemoryCallback]:  6287520\n",
      "\n",
      "Epoch 62: loss improved from 1.53508 to 1.52440, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.5244 - bpp: 0.9168 - mse: 2.9667e-04\n",
      "Epoch 63/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5676 - bpp: 0.9261 - mse: 3.1319e-04[MemoryCallback]:  6336500\n",
      "\n",
      "Epoch 63: loss did not improve from 1.52440\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 1.5676 - bpp: 0.9261 - mse: 3.1319e-04\n",
      "Epoch 64/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5003 - bpp: 0.8861 - mse: 2.9990e-04[MemoryCallback]:  6336692\n",
      "\n",
      "Epoch 64: loss improved from 1.52440 to 1.50033, saving model to checkpoints_wavelets_L_2048_5_240x240/\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5003 - bpp: 0.8861 - mse: 2.9990e-04\n",
      "Epoch 65/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6170 - bpp: 0.9049 - mse: 3.4771e-04[MemoryCallback]:  6339208\n",
      "\n",
      "Epoch 65: loss did not improve from 1.50033\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.6170 - bpp: 0.9049 - mse: 3.4771e-04\n",
      "Epoch 66/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5792 - bpp: 0.8867 - mse: 3.3811e-04[MemoryCallback]:  6339532\n",
      "\n",
      "Epoch 66: loss did not improve from 1.50033\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.5792 - bpp: 0.8867 - mse: 3.3811e-04\n",
      "Epoch 67/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5431 - bpp: 0.8726 - mse: 3.2736e-04[MemoryCallback]:  6343488\n",
      "\n",
      "Epoch 67: loss did not improve from 1.50033\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.5431 - bpp: 0.8726 - mse: 3.2736e-04\n",
      "Epoch 68/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5945 - bpp: 0.8869 - mse: 3.4555e-04[MemoryCallback]:  6343660\n",
      "\n",
      "Epoch 68: loss did not improve from 1.50033\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.5945 - bpp: 0.8869 - mse: 3.4555e-04\n",
      "Epoch 69/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5328 - bpp: 0.8583 - mse: 3.2934e-04[MemoryCallback]:  6343660\n",
      "\n",
      "Epoch 69: loss did not improve from 1.50033\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5328 - bpp: 0.8583 - mse: 3.2934e-04\n",
      "Epoch 70/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5707 - bpp: 0.8521 - mse: 3.5087e-04[MemoryCallback]:  6343804\n",
      "\n",
      "Epoch 70: loss did not improve from 1.50033\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.5707 - bpp: 0.8521 - mse: 3.5087e-04\n",
      "Epoch 71/700\n",
      "173/200 [========================>.....] - ETA: 4s - loss: 1.7430 - bpp: 0.8780 - mse: 4.2238e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 21:01:45.768877: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated\"\n",
      "Please see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 896, in load_read\n",
      "    cid, pos, length = self.png.read()\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 162, in read\n",
      "    length = i32(s)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/_binary.py\", line 85, in i32be\n",
      "    return unpack_from(\">I\", c, o)[0]\n",
      "\n",
      "struct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 654, in pil_try_read\n",
      "    im.getdata()[0]\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 1294, in getdata\n",
      "    self.load()\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 241, in load\n",
      "    raise OSError(\"image file is truncated\") from e\n",
      "\n",
      "OSError: image file is truncated\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/workspaces/OpenDVCW/DataGen.py\", line 32, in __getitem__\n",
      "    return self.__data_generation()\n",
      "\n",
      "  File \"/workspaces/OpenDVCW/DataGen.py\", line 56, in __data_generation\n",
      "    img_ref = load.read_png_crop_np(path + 'im1_bpg444_QP' + str(I_QP) + '.png', Width, Height)\n",
      "\n",
      "  File \"/workspaces/OpenDVCW/load.py\", line 57, in read_png_crop_np\n",
      "    img = imageio.imread(filename)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/__init__.py\", line 86, in imread\n",
      "    return imread_v2(uri, format=format, **kwargs)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/v2.py\", line 160, in imread\n",
      "    return file.read(index=0, **kwargs)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 132, in read\n",
      "    reader = self.legacy_get_reader(**kwargs)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 104, in legacy_get_reader\n",
      "    return self._format.get_reader(self._request)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 190, in get_reader\n",
      "    return self.Reader(self, request)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 281, in __init__\n",
      "    self._open(**self.request.kwargs.copy())\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 394, in _open\n",
      "    return PillowFormat.Reader._open(self, pilmode=pilmode, as_gray=as_gray)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 300, in _open\n",
      "    pil_try_read(self._im)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 665, in pil_try_read\n",
      "    raise ValueError(error_message)\n",
      "\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated\"\n",
      "Please see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: Could not load \"\" \nReason: \"image file is truncated\"\nPlease see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n    s = read(self.decodermaxblock)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 896, in load_read\n    cid, pos, length = self.png.read()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 162, in read\n    length = i32(s)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 654, in pil_try_read\n    im.getdata()[0]\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 1294, in getdata\n    self.load()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 241, in load\n    raise OSError(\"image file is truncated\") from e\n\nOSError: image file is truncated\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 32, in __getitem__\n    return self.__data_generation()\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 56, in __data_generation\n    img_ref = load.read_png_crop_np(path + 'im1_bpg444_QP' + str(I_QP) + '.png', Width, Height)\n\n  File \"/workspaces/OpenDVCW/load.py\", line 57, in read_png_crop_np\n    img = imageio.imread(filename)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/__init__.py\", line 86, in imread\n    return imread_v2(uri, format=format, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/v2.py\", line 160, in imread\n    return file.read(index=0, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 132, in read\n    reader = self.legacy_get_reader(**kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 104, in legacy_get_reader\n    return self._format.get_reader(self._request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 190, in get_reader\n    return self.Reader(self, request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 281, in __init__\n    self._open(**self.request.kwargs.copy())\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 394, in _open\n    return PillowFormat.Reader._open(self, pilmode=pilmode, as_gray=as_gray)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 300, in _open\n    pil_try_read(self._im)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 665, in pil_try_read\n    raise ValueError(error_message)\n\nValueError: Could not load \"\" \nReason: \"image file is truncated\"\nPlease see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[open_dvc/wavelets_optical_flow/optical_flow_loss/lambda_7/StatefulPartitionedCall/dense_image_warp/StatefulPartitionedCall/assert_greater_equal/Assert/Assert/data_2/_658]]\n  (1) INVALID_ARGUMENT:  ValueError: Could not load \"\" \nReason: \"image file is truncated\"\nPlease see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n    s = read(self.decodermaxblock)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 896, in load_read\n    cid, pos, length = self.png.read()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 162, in read\n    length = i32(s)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 654, in pil_try_read\n    im.getdata()[0]\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 1294, in getdata\n    self.load()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 241, in load\n    raise OSError(\"image file is truncated\") from e\n\nOSError: image file is truncated\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 32, in __getitem__\n    return self.__data_generation()\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 56, in __data_generation\n    img_ref = load.read_png_crop_np(path + 'im1_bpg444_QP' + str(I_QP) + '.png', Width, Height)\n\n  File \"/workspaces/OpenDVCW/load.py\", line 57, in read_png_crop_np\n    img = imageio.imread(filename)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/__init__.py\", line 86, in imread\n    return imread_v2(uri, format=format, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/v2.py\", line 160, in imread\n    return file.read(index=0, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 132, in read\n    reader = self.legacy_get_reader(**kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 104, in legacy_get_reader\n    return self._format.get_reader(self._request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 190, in get_reader\n    return self.Reader(self, request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 281, in __init__\n    self._open(**self.request.kwargs.copy())\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 394, in _open\n    return PillowFormat.Reader._open(self, pilmode=pilmode, as_gray=as_gray)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 300, in _open\n    pil_try_read(self._im)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 6 [Op:__inference_train_function_38247]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OpenDVCW/train_models/train_2048.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# tf.config.run_functions_eagerly(True)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mdata, steps_per_epoch\u001b[39m=\u001b[39;49mSTEPS_PER_EPOCH, epochs\u001b[39m=\u001b[39;49mEPOCHS, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m                     Callbacks\u001b[39m.\u001b[39;49mMemoryCallback(),\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m                     Callbacks\u001b[39m.\u001b[39;49mLearningRateReducer(),\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m                     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(filepath\u001b[39m=\u001b[39;49mcheckponts_new_path, save_weights_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_freq\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, monitor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,  save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), \n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=6'>7</a>\u001b[0m                     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTerminateOnNaN(),\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=7'>8</a>\u001b[0m                     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m, patience\u001b[39m=\u001b[39;49mearly_stop),\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=8'>9</a>\u001b[0m                     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(log_dir\u001b[39m=\u001b[39;49mlog_dir, histogram_freq\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, update_freq\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m\"\u001b[39;49m),            \n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=9'>10</a>\u001b[0m                     ],\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f7562752d61646d696e2f446576656c6f7065722f4f70656e44564357/workspaces/OpenDVCW/train_models/train_2048.ipynb#ch0000009vscode-remote?line=10'>11</a>\u001b[0m \t\t\t\t)\n",
      "File \u001b[0;32m/workspaces/OpenDVCW/OpenDVCW.py:393\u001b[0m, in \u001b[0;36mOpenDVC.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/OpenDVCW/OpenDVCW.py?line=391'>392</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///workspaces/OpenDVCW/OpenDVCW.py?line=392'>393</a>\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///workspaces/OpenDVCW/OpenDVCW.py?line=393'>394</a>\u001b[0m     \u001b[39m# After training, fix range coding tables.\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/OpenDVCW/OpenDVCW.py?line=394'>395</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentropy_model_mv \u001b[39m=\u001b[39m tfc\u001b[39m.\u001b[39mContinuousBatchedEntropyModel(\n\u001b[1;32m    <a href='file:///workspaces/OpenDVCW/OpenDVCW.py?line=395'>396</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprior_mv, coding_rank\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, compression\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: Could not load \"\" \nReason: \"image file is truncated\"\nPlease see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n    s = read(self.decodermaxblock)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 896, in load_read\n    cid, pos, length = self.png.read()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 162, in read\n    length = i32(s)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 654, in pil_try_read\n    im.getdata()[0]\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 1294, in getdata\n    self.load()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 241, in load\n    raise OSError(\"image file is truncated\") from e\n\nOSError: image file is truncated\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 32, in __getitem__\n    return self.__data_generation()\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 56, in __data_generation\n    img_ref = load.read_png_crop_np(path + 'im1_bpg444_QP' + str(I_QP) + '.png', Width, Height)\n\n  File \"/workspaces/OpenDVCW/load.py\", line 57, in read_png_crop_np\n    img = imageio.imread(filename)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/__init__.py\", line 86, in imread\n    return imread_v2(uri, format=format, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/v2.py\", line 160, in imread\n    return file.read(index=0, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 132, in read\n    reader = self.legacy_get_reader(**kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 104, in legacy_get_reader\n    return self._format.get_reader(self._request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 190, in get_reader\n    return self.Reader(self, request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 281, in __init__\n    self._open(**self.request.kwargs.copy())\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 394, in _open\n    return PillowFormat.Reader._open(self, pilmode=pilmode, as_gray=as_gray)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 300, in _open\n    pil_try_read(self._im)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 665, in pil_try_read\n    raise ValueError(error_message)\n\nValueError: Could not load \"\" \nReason: \"image file is truncated\"\nPlease see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[open_dvc/wavelets_optical_flow/optical_flow_loss/lambda_7/StatefulPartitionedCall/dense_image_warp/StatefulPartitionedCall/assert_greater_equal/Assert/Assert/data_2/_658]]\n  (1) INVALID_ARGUMENT:  ValueError: Could not load \"\" \nReason: \"image file is truncated\"\nPlease see documentation at: http://pillow.readthedocs.io/en/latest/installation.html#external-libraries\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n    s = read(self.decodermaxblock)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 896, in load_read\n    cid, pos, length = self.png.read()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\", line 162, in read\n    length = i32(s)\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 654, in pil_try_read\n    im.getdata()[0]\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 1294, in getdata\n    self.load()\n\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 241, in load\n    raise OSError(\"image file is truncated\") from e\n\nOSError: image file is truncated\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 32, in __getitem__\n    return self.__data_generation()\n\n  File \"/workspaces/OpenDVCW/DataGen.py\", line 56, in __data_generation\n    img_ref = load.read_png_crop_np(path + 'im1_bpg444_QP' + str(I_QP) + '.png', Width, Height)\n\n  File \"/workspaces/OpenDVCW/load.py\", line 57, in read_png_crop_np\n    img = imageio.imread(filename)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/__init__.py\", line 86, in imread\n    return imread_v2(uri, format=format, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/v2.py\", line 160, in imread\n    return file.read(index=0, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 132, in read\n    reader = self.legacy_get_reader(**kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py\", line 104, in legacy_get_reader\n    return self._format.get_reader(self._request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 190, in get_reader\n    return self.Reader(self, request)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/core/format.py\", line 281, in __init__\n    self._open(**self.request.kwargs.copy())\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 394, in _open\n    return PillowFormat.Reader._open(self, pilmode=pilmode, as_gray=as_gray)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 300, in _open\n    pil_try_read(self._im)\n\n  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py\", line 6 [Op:__inference_train_function_38247]"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "hist = model.fit(x=data, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, verbose=1, batch_size=BATCH_SIZE,\n",
    "                callbacks=[\n",
    "                    Callbacks.MemoryCallback(),\n",
    "                    Callbacks.LearningRateReducer(),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch', monitor=\"loss\", mode='min',  save_best_only=True, verbose=1), \n",
    "                    tf.keras.callbacks.TerminateOnNaN(),\n",
    "                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stop),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq=\"epoch\"),            \n",
    "                    ],\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00059/0223/im1.png\n",
      "compress\n",
      "in the compress\n",
      "in decompress\n"
     ]
    }
   ],
   "source": [
    "path = load.load_random_path(\"folder_cloud_test.npy\")\n",
    "i=0\n",
    "out_bin = \"Test_com/test{}.bin\".format(i)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(i)\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(i)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(i)\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, out_bin, out_decom, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_wavelets_L__2048_5_240x240/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_wavelets_L__2048_5_240x240/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
