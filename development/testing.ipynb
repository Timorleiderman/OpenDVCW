{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd \n",
    "%cd /workspaces/tensorflow-wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenDVC\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1\n",
    "EPOCHS = 3\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 512\n",
    "lr_init = 1e-5\n",
    "samples = 300\n",
    "I_QP=27\n",
    "early_stop_patience = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenDVC.OpenDVC(width=Width, height=Height, batch_size=batch_size, num_filters=128, lmbda=lmbda)\n",
    "# model.summary()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init),\n",
    ")\n",
    "print(\"* [Model compiled]...\")\n",
    "args = OpenDVC.Arguments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, \"Trainable: \",layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = np.load(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\")\n",
    "# data = load.load_data_vimeo90k(samples, batch_size, Height, Width, Channel, folder, I_QP)\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = load.load_data_vimeo90k(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\",\n",
    "                                samples, Height, Width, Channel, I_QP)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "# data_out = tf.data.Dataset.from_tensor_slices(data_out)\n",
    "\n",
    "# for perm in dataset:\n",
    "#     print(perm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"* [Loading model/weights]...\")\n",
    "\n",
    "# model.load_weights(\"checkpoint_me.back/\")\n",
    "# model.load_weights(args.model_checkpoints_me)\n",
    "# model.load_weights(args.model_checkpoints_mc)\n",
    "# model = tf.keras.models.load_model(args.model_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Going to fit\")\n",
    "checkponts_last_path = \"checkpoints_test/\"\n",
    "checkponts_new_path = \"checkpoints_test1/\"\n",
    "model.load_weights(checkponts_last_path)\n",
    "\n",
    "hist = model.fit(\n",
    "        dataset,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1, \n",
    "        callbacks=\n",
    "            [\n",
    "            OpenDVC.MemoryCallback(),\n",
    "            # tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_me, save_weights_only=True, save_freq='epoch', monitor=\"train_loss_ME\", mode='min',  save_best_only=True, verbose=2), \n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch',monitor=\"loss\",mode='min',  save_best_only=True, verbose=1), \n",
    "            # tf.keras.callbacks.EarlyStopping(monitor='train_loss_MV', patience=early_stop_patience),\n",
    "            # tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_mc, save_weights_only=True, save_freq='epoch',monitor=\"train_loss_MC\",mode='min',  save_best_only=True, verbose=2), \n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=args.backup_restore, histogram_freq=0, update_freq=\"epoch\"),\n",
    "            # tf.keras.callbacks.experimental.BackupAndRestore(args.backup_restore),\n",
    "            \n",
    "            ],\n",
    "\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_save_test1\", save_format=\"tf\")\n",
    "# model.save_weights(\"model.h5\")\n",
    "\n",
    "# tf.keras.models.save_model(model, args.model_save)\n",
    "# tf.saved_model.save(model, args.model_save)\n",
    "print(\"saved\", args.model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = load.load_random_path(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\")\n",
    "out_bin = \"/workspaces/tensorflow-wavelets/Development/OpenDVC/Test_com/test.bin\"\n",
    "out_decom = \"/workspaces/tensorflow-wavelets/Development/OpenDVC/Test_com/testdcom.png\"\n",
    "p_on_test = \"/workspaces/tensorflow-wavelets/Development/OpenDVC/Test_com/test_p_frame.png\"\n",
    "i_on_test = \"/workspaces/tensorflow-wavelets/Development/OpenDVC/Test_com/test_i_frame.png\"\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVC.write_png(p_on_test, OpenDVC.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVC.write_png(i_on_test, OpenDVC.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVC.compress(model, i_frame, p_frame,out_bin, 240, 240)\n",
    "OpenDVC.decompress(model, i_frame, out_bin, out_decom, 240, 240)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* [Loading dataset]...\")\n",
    "data = load.load_data_vimeo90k(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\",\n",
    "                                samples, Height, Width, Channel, I_QP)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Going to fit\")\n",
    "hist = model.fit(\n",
    "        dataset,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1, \n",
    "        callbacks=\n",
    "            [\n",
    "            OpenDVC.MemoryCallback(),\n",
    "            # tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_me, save_weights_only=True, save_freq='epoch', monitor=\"train_loss_ME\", mode='min',  save_best_only=True, verbose=2), \n",
    "            # tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_mv, save_weights_only=True, save_freq='epoch',monitor=\"train_loss_MV\",mode='min',  save_best_only=True, verbose=2), \n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_mc, save_weights_only=True, save_freq='epoch',monitor=\"train_loss_MC\",mode='min',  save_best_only=True, verbose=2), \n",
    "            tf.keras.callbacks.EarlyStopping(monitor='train_loss_MC', patience=early_stop_patience),\n",
    "            # tf.keras.callbacks.TerminateOnNaN(),\n",
    "            # tf.keras.callbacks.TensorBoard(log_dir=args.backup_restore, histogram_freq=0, update_freq=\"epoch\"),\n",
    "            tf.keras.callbacks.experimental.BackupAndRestore(args.backup_restore),\n",
    "            ],\n",
    "\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_save_mc\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "# print_tensors_in_checkpoint_file(file_name=args.model_checkpoints_me, tensor_name='', all_tensors=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* [Loading dataset]...\")\n",
    "data = load.load_data_vimeo90k(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\",\n",
    "                                samples, Height, Width, Channel, I_QP)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Going to fit\")\n",
    "hist = model.fit(\n",
    "        dataset,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1, \n",
    "        callbacks=\n",
    "            [\n",
    "            OpenDVC.MemoryCallback(),\n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_me, save_weights_only=True, save_freq='epoch', monitor=\"train_loss_ME\", mode='min',  save_best_only=True, verbose=2), \n",
    "            tf.keras.callbacks.EarlyStopping(monitor='train_loss_ME', patience=early_stop_patience),\n",
    "            # tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_mv, save_weights_only=True, save_freq='epoch',monitor=\"train_loss_MV\",mode='min',  save_best_only=True, verbose=2), \n",
    "            # tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_mc, save_weights_only=True, save_freq='epoch',monitor=\"train_loss_MC\",mode='min',  save_best_only=True, verbose=2), \n",
    "\n",
    "            # tf.keras.callbacks.TerminateOnNaN(),\n",
    "            # tf.keras.callbacks.TensorBoard(log_dir=args.backup_restore, histogram_freq=0, update_freq=\"epoch\"),\n",
    "            tf.keras.callbacks.experimental.BackupAndRestore(args.backup_restore),\n",
    "            ],\n",
    "\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_save_me\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* [Loading dataset]...\")\n",
    "data = load.load_data_vimeo90k(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\",\n",
    "                                samples, Height, Width, Channel, I_QP)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init/10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "        dataset,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1, \n",
    "        callbacks=\n",
    "            [\n",
    "            OpenDVC.MemoryCallback(),\n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath=args.model_checkpoints_mv, save_weights_only=True, save_freq='epoch',monitor=\"psnr\",mode='max',  save_best_only=True, verbose=2), \n",
    "            tf.keras.callbacks.EarlyStopping(monitor='psnr', patience=early_stop_patience),\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=args.backup_restore, histogram_freq=0, update_freq=\"epoch\"),\n",
    "            tf.keras.callbacks.experimental.BackupAndRestore(args.backup_restore),\n",
    "            \n",
    "            ],\n",
    "\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_save_psnr\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "  with tf.GradientTape() as tape:\n",
    "    train_loss_ME, train_loss_MV, train_loss_MC, ME_mse, warp_mse, MC_mse, train_bpp_MV, train_bpp_Res, psnr = model(inputs, training=True)\n",
    "    loss = compute_loss(labels, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_accuracy.update_state(labels, predictions)\n",
    "  return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pwd \n",
    "%cd /workspaces/tensorflow-wavelets\n",
    "import OpenDVC\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 1\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lr_init = 1e-4\n",
    "samples = 1\n",
    "I_QP=27\n",
    "early_stop_patience = 3\n",
    "\n",
    "vimeo_npy_path = \"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\"\n",
    "\n",
    "# model, optimizer, and checkpoint must be created under `strategy.scope`.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = OpenDVC.OpenDVC(width=Width, height=Height, batch_size=batch_size, num_filters=128)\n",
    "    model.compile(freeze = [], optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init),)\n",
    "    checkpoint = tf.train.Checkpoint(optimizer= model.optimizer, model=model)\n",
    "\n",
    "args = OpenDVC.Arguments()\n",
    "\n",
    "\n",
    "for iter in range(1000000):\n",
    "    if iter % 100 == 0:\n",
    "        print(\"iter %d\" % (iter,))\n",
    "    \n",
    "    x = load.load_data_vimeo90k(vimeo_npy_path,samples, Height, Width, Channel, I_QP)\n",
    "    with tf.GradientTape() as tape:\n",
    "        train_loss_ME, train_loss_MV, train_loss_MC, ME_mse, warp_mse, MC_mse, train_bpp_MV, train_bpp_Res, psnr = model(x[0], training=True)\n",
    "    # print(train_loss_ME, train_loss_MV, train_loss_MC, ME_mse, warp_mse, MC_mse, train_bpp_MV, train_bpp_Res, psnr)\n",
    "    \n",
    "    if iter < 20000:\n",
    "        loss = train_loss_MV\n",
    "    elif iter < 40000:\n",
    "        loss = train_loss_MC\n",
    "    else:\n",
    "        loss = train_loss_ME\n",
    "\n",
    "    variables = model.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    model.optimizer.apply_gradients((grad, var) for (grad, var) in zip(gradients, variables) if grad is not None)\n",
    "\n",
    "    \n",
    "    if iter % 500 == 0:\n",
    "        print(\"Training loss at step %d: %.4f\" % (iter, float(loss)))\n",
    "    iter += 1\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
