{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "from train import TrainOpenDVCW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 800\n",
    "STEPS_PER_EPOCH = 200\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "NUM_FILTERS = 256\n",
    "MV_KERNEL_SIZE=3\n",
    "RES_KERNEL_SIZE=5\n",
    "M=256\n",
    "lmbda = 2048\n",
    "lr_init = 1e-4\n",
    "lr_alpha = 1e-8\n",
    "early_stop = 800\n",
    "I_QP=22\n",
    "wavelet_name = \"bior1.3\"\n",
    "np_folder = \"folder_cloud_test.npy\"\n",
    "checkponts_prev_path = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 17:48:29.725943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:29.775611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:29.776536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:29.778986: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-01 17:48:29.781334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:29.782073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:29.782882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:31.221510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:31.222255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:31.222984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-01 17:48:31.224369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 17:48:46.394195: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "I_QP=22\n",
    "lmbda = 2048\n",
    "\n",
    "trainer_11 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_11.compile()\n",
    "trainer_11.fit()\n",
    "trainer_11.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 84.9664 - bpp: 5.3060 - mse: 0.0194\n",
      "Epoch 1: loss improved from inf to 84.96638, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 51s 118ms/step - loss: 84.9664 - bpp: 5.3060 - mse: 0.0194\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.3652 - bpp: 5.1665 - mse: 0.0037\n",
      "Epoch 2: loss improved from 84.96638 to 20.36518, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 20.3652 - bpp: 5.1665 - mse: 0.0037\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.8216 - bpp: 5.0310 - mse: 0.0024\n",
      "Epoch 3: loss improved from 20.36518 to 14.82162, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 14.8216 - bpp: 5.0310 - mse: 0.0024\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.6203 - bpp: 4.8984 - mse: 0.0019\n",
      "Epoch 4: loss improved from 14.82162 to 12.62034, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 12.6203 - bpp: 4.8984 - mse: 0.0019\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.9052 - bpp: 4.7686 - mse: 0.0017\n",
      "Epoch 5: loss improved from 12.62034 to 11.90519, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 11.9052 - bpp: 4.7686 - mse: 0.0017\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8125 - bpp: 4.6408 - mse: 0.0015\n",
      "Epoch 6: loss improved from 11.90519 to 10.81253, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 10.8125 - bpp: 4.6408 - mse: 0.0015\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4496 - bpp: 4.5160 - mse: 0.0017\n",
      "Epoch 7: loss did not improve from 10.81253\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 11.4496 - bpp: 4.5160 - mse: 0.0017\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9578 - bpp: 4.3924 - mse: 0.0011\n",
      "Epoch 8: loss improved from 10.81253 to 8.95784, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 8.9578 - bpp: 4.3924 - mse: 0.0011\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0790 - bpp: 4.2716 - mse: 0.0012\n",
      "Epoch 9: loss did not improve from 8.95784\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 9.0790 - bpp: 4.2716 - mse: 0.0012\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0482 - bpp: 4.1530 - mse: 0.0014\n",
      "Epoch 10: loss did not improve from 8.95784\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.0482 - bpp: 4.1530 - mse: 0.0014\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6204 - bpp: 4.0365 - mse: 0.0011\n",
      "Epoch 11: loss improved from 8.95784 to 8.62042, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.6204 - bpp: 4.0365 - mse: 0.0011\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0272 - bpp: 3.9221 - mse: 0.0010\n",
      "Epoch 12: loss improved from 8.62042 to 8.02720, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 8.0272 - bpp: 3.9221 - mse: 0.0010\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1400 - bpp: 3.8126 - mse: 0.0015\n",
      "Epoch 13: loss did not improve from 8.02720\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.1400 - bpp: 3.8126 - mse: 0.0015\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9340 - bpp: 3.7000 - mse: 0.0010\n",
      "Epoch 14: loss improved from 8.02720 to 7.93398, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.9340 - bpp: 3.7000 - mse: 0.0010\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1926 - bpp: 3.5914 - mse: 8.7921e-04\n",
      "Epoch 15: loss improved from 7.93398 to 7.19262, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 7.1926 - bpp: 3.5914 - mse: 8.7921e-04\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4469 - bpp: 3.4877 - mse: 9.6661e-04\n",
      "Epoch 16: loss did not improve from 7.19262\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.4469 - bpp: 3.4877 - mse: 9.6661e-04\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3175 - bpp: 3.3878 - mse: 0.0022\n",
      "Epoch 17: loss did not improve from 7.19262\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 12.3175 - bpp: 3.3878 - mse: 0.0022\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5963 - bpp: 3.2825 - mse: 0.0011\n",
      "Epoch 18: loss did not improve from 7.19262\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.5963 - bpp: 3.2825 - mse: 0.0011\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2171 - bpp: 3.1808 - mse: 7.4128e-04\n",
      "Epoch 19: loss improved from 7.19262 to 6.21707, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.2171 - bpp: 3.1808 - mse: 7.4128e-04\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4260 - bpp: 3.0886 - mse: 8.1480e-04\n",
      "Epoch 20: loss did not improve from 6.21707\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.4260 - bpp: 3.0886 - mse: 8.1480e-04\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2215 - bpp: 2.9949 - mse: 7.8776e-04\n",
      "Epoch 21: loss did not improve from 6.21707\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.2215 - bpp: 2.9949 - mse: 7.8776e-04\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0218 - bpp: 2.9049 - mse: 7.6094e-04\n",
      "Epoch 22: loss improved from 6.21707 to 6.02177, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.0218 - bpp: 2.9049 - mse: 7.6094e-04\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6576 - bpp: 2.8148 - mse: 6.9403e-04\n",
      "Epoch 23: loss improved from 6.02177 to 5.65757, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 5.6576 - bpp: 2.8148 - mse: 6.9403e-04\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6563 - bpp: 2.7319 - mse: 7.1397e-04\n",
      "Epoch 24: loss improved from 5.65757 to 5.65631, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.6563 - bpp: 2.7319 - mse: 7.1397e-04\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3089 - bpp: 2.6503 - mse: 6.4906e-04\n",
      "Epoch 25: loss improved from 5.65631 to 5.30891, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.3089 - bpp: 2.6503 - mse: 6.4906e-04\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3834 - bpp: 2.5654 - mse: 6.8799e-04\n",
      "Epoch 26: loss did not improve from 5.30891\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.3834 - bpp: 2.5654 - mse: 6.8799e-04\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6098 - bpp: 2.5014 - mse: 7.5888e-04\n",
      "Epoch 27: loss did not improve from 5.30891\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 5.6098 - bpp: 2.5014 - mse: 7.5888e-04\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6762 - bpp: 2.4264 - mse: 0.0018\n",
      "Epoch 28: loss did not improve from 5.30891\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 9.6762 - bpp: 2.4264 - mse: 0.0018\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3888 - bpp: 2.3433 - mse: 7.4353e-04\n",
      "Epoch 29: loss did not improve from 5.30891\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.3888 - bpp: 2.3433 - mse: 7.4353e-04\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9969 - bpp: 2.2733 - mse: 6.6494e-04\n",
      "Epoch 30: loss improved from 5.30891 to 4.99689, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 4.9969 - bpp: 2.2733 - mse: 6.6494e-04\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0432 - bpp: 2.2111 - mse: 6.9143e-04\n",
      "Epoch 31: loss did not improve from 4.99689\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.0432 - bpp: 2.2111 - mse: 6.9143e-04\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4354 - bpp: 2.1554 - mse: 8.0078e-04\n",
      "Epoch 32: loss did not improve from 4.99689\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.4354 - bpp: 2.1554 - mse: 8.0078e-04\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3079 - bpp: 2.0773 - mse: 7.8873e-04\n",
      "Epoch 33: loss did not improve from 4.99689\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.3079 - bpp: 2.0773 - mse: 7.8873e-04\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7699 - bpp: 2.0230 - mse: 6.7063e-04\n",
      "Epoch 34: loss improved from 4.99689 to 4.76990, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.7699 - bpp: 2.0230 - mse: 6.7063e-04\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2591 - bpp: 1.9862 - mse: 7.9907e-04\n",
      "Epoch 35: loss did not improve from 4.76990\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.2591 - bpp: 1.9862 - mse: 7.9907e-04\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3244 - bpp: 1.9089 - mse: 5.8972e-04\n",
      "Epoch 36: loss improved from 4.76990 to 4.32436, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.3244 - bpp: 1.9089 - mse: 5.8972e-04\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4121 - bpp: 1.8712 - mse: 6.2035e-04\n",
      "Epoch 37: loss did not improve from 4.32436\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.4121 - bpp: 1.8712 - mse: 6.2035e-04\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1745 - bpp: 1.8059 - mse: 5.7828e-04\n",
      "Epoch 38: loss improved from 4.32436 to 4.17452, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 4.1745 - bpp: 1.8059 - mse: 5.7828e-04\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3602 - bpp: 1.7814 - mse: 6.2960e-04\n",
      "Epoch 39: loss did not improve from 4.17452\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 4.3602 - bpp: 1.7814 - mse: 6.2960e-04\n",
      "Epoch 40/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3005 - bpp: 1.7482 - mse: 6.2312e-04\n",
      "Epoch 40: loss did not improve from 4.17452\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 4.3005 - bpp: 1.7482 - mse: 6.2312e-04\n",
      "Epoch 41/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5057 - bpp: 1.7263 - mse: 9.2271e-04\n",
      "Epoch 41: loss did not improve from 4.17452\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.5057 - bpp: 1.7263 - mse: 9.2271e-04\n",
      "Epoch 42/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9904 - bpp: 1.6515 - mse: 5.7100e-04\n",
      "Epoch 42: loss improved from 4.17452 to 3.99035, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.9904 - bpp: 1.6515 - mse: 5.7100e-04\n",
      "Epoch 43/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0373 - bpp: 1.5879 - mse: 5.9799e-04\n",
      "Epoch 43: loss did not improve from 3.99035\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.0373 - bpp: 1.5879 - mse: 5.9799e-04\n",
      "Epoch 44/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3784 - bpp: 1.6359 - mse: 0.0012\n",
      "Epoch 44: loss did not improve from 3.99035\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.3784 - bpp: 1.6359 - mse: 0.0012\n",
      "Epoch 45/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9255 - bpp: 1.5646 - mse: 8.2052e-04\n",
      "Epoch 45: loss did not improve from 3.99035\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 4.9255 - bpp: 1.5646 - mse: 8.2052e-04\n",
      "Epoch 46/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8380 - bpp: 1.5110 - mse: 5.6812e-04\n",
      "Epoch 46: loss improved from 3.99035 to 3.83802, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 3.8380 - bpp: 1.5110 - mse: 5.6812e-04\n",
      "Epoch 47/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1469 - bpp: 1.4868 - mse: 6.4944e-04\n",
      "Epoch 47: loss did not improve from 3.83802\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.1469 - bpp: 1.4868 - mse: 6.4944e-04\n",
      "Epoch 48/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6872 - bpp: 1.4585 - mse: 5.4411e-04\n",
      "Epoch 48: loss improved from 3.83802 to 3.68715, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6872 - bpp: 1.4585 - mse: 5.4411e-04\n",
      "Epoch 49/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5917 - bpp: 1.4304 - mse: 5.2766e-04\n",
      "Epoch 49: loss improved from 3.68715 to 3.59173, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 42s 119ms/step - loss: 3.5917 - bpp: 1.4304 - mse: 5.2766e-04\n",
      "Epoch 50/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3564 - bpp: 1.4286 - mse: 9.5894e-04\n",
      "Epoch 50: loss did not improve from 3.59173\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 5.3564 - bpp: 1.4286 - mse: 9.5894e-04\n",
      "Epoch 51/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2289 - bpp: 1.4215 - mse: 9.2954e-04\n",
      "Epoch 51: loss did not improve from 3.59173\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.2289 - bpp: 1.4215 - mse: 9.2954e-04\n",
      "Epoch 52/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5436 - bpp: 1.3663 - mse: 5.3156e-04\n",
      "Epoch 52: loss improved from 3.59173 to 3.54359, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.5436 - bpp: 1.3663 - mse: 5.3156e-04\n",
      "Epoch 53/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3837 - bpp: 1.3297 - mse: 5.0147e-04\n",
      "Epoch 53: loss improved from 3.54359 to 3.38371, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3837 - bpp: 1.3297 - mse: 5.0147e-04\n",
      "Epoch 54/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1495 - bpp: 1.3452 - mse: 6.8464e-04\n",
      "Epoch 54: loss did not improve from 3.38371\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 4.1495 - bpp: 1.3452 - mse: 6.8464e-04\n",
      "Epoch 55/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7779 - bpp: 1.3071 - mse: 6.0322e-04\n",
      "Epoch 55: loss did not improve from 3.38371\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 3.7779 - bpp: 1.3071 - mse: 6.0322e-04\n",
      "Epoch 56/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5495 - bpp: 1.2882 - mse: 5.5208e-04\n",
      "Epoch 56: loss did not improve from 3.38371\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.5495 - bpp: 1.2882 - mse: 5.5208e-04\n",
      "Epoch 57/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6445 - bpp: 1.2876 - mse: 5.7541e-04\n",
      "Epoch 57: loss did not improve from 3.38371\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.6445 - bpp: 1.2876 - mse: 5.7541e-04\n",
      "Epoch 58/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4503 - bpp: 1.3168 - mse: 0.0013\n",
      "Epoch 58: loss did not improve from 3.38371\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.4503 - bpp: 1.3168 - mse: 0.0013\n",
      "Epoch 59/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0221 - bpp: 1.2706 - mse: 6.7173e-04\n",
      "Epoch 59: loss did not improve from 3.38371\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 4.0221 - bpp: 1.2706 - mse: 6.7173e-04\n",
      "Epoch 60/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2890 - bpp: 1.2280 - mse: 5.0316e-04\n",
      "Epoch 60: loss improved from 3.38371 to 3.28896, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.2890 - bpp: 1.2280 - mse: 5.0316e-04\n",
      "Epoch 61/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7329 - bpp: 1.2390 - mse: 6.0886e-04\n",
      "Epoch 61: loss did not improve from 3.28896\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.7329 - bpp: 1.2390 - mse: 6.0886e-04\n",
      "Epoch 62/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4566 - bpp: 1.2062 - mse: 5.4942e-04\n",
      "Epoch 62: loss did not improve from 3.28896\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.4566 - bpp: 1.2062 - mse: 5.4942e-04\n",
      "Epoch 63/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4300 - bpp: 1.2054 - mse: 5.4312e-04\n",
      "Epoch 63: loss did not improve from 3.28896\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.4300 - bpp: 1.2054 - mse: 5.4312e-04\n",
      "Epoch 64/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2916 - bpp: 1.1657 - mse: 5.1902e-04\n",
      "Epoch 64: loss did not improve from 3.28896\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.2916 - bpp: 1.1657 - mse: 5.1902e-04\n",
      "Epoch 65/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9024 - bpp: 1.1365 - mse: 4.3113e-04\n",
      "Epoch 65: loss improved from 3.28896 to 2.90239, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9024 - bpp: 1.1365 - mse: 4.3113e-04\n",
      "Epoch 66/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4400 - bpp: 1.1604 - mse: 5.5655e-04\n",
      "Epoch 66: loss did not improve from 2.90239\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.4400 - bpp: 1.1604 - mse: 5.5655e-04\n",
      "Epoch 67/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0507 - bpp: 1.1325 - mse: 4.6831e-04\n",
      "Epoch 67: loss did not improve from 2.90239\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.0507 - bpp: 1.1325 - mse: 4.6831e-04\n",
      "Epoch 68/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4312 - bpp: 1.1766 - mse: 5.5045e-04\n",
      "Epoch 68: loss did not improve from 2.90239\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.4312 - bpp: 1.1766 - mse: 5.5045e-04\n",
      "Epoch 69/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3055 - bpp: 1.1401 - mse: 5.2867e-04\n",
      "Epoch 69: loss did not improve from 2.90239\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.3055 - bpp: 1.1401 - mse: 5.2867e-04\n",
      "Epoch 70/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9646 - bpp: 1.1231 - mse: 4.4959e-04\n",
      "Epoch 70: loss did not improve from 2.90239\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9646 - bpp: 1.1231 - mse: 4.4959e-04\n",
      "Epoch 71/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8609 - bpp: 1.1170 - mse: 4.2575e-04\n",
      "Epoch 71: loss improved from 2.90239 to 2.86086, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8609 - bpp: 1.1170 - mse: 4.2575e-04\n",
      "Epoch 72/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8747 - bpp: 1.0892 - mse: 4.3590e-04\n",
      "Epoch 72: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.8747 - bpp: 1.0892 - mse: 4.3590e-04\n",
      "Epoch 73/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8967 - bpp: 1.0916 - mse: 4.4070e-04\n",
      "Epoch 73: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.8967 - bpp: 1.0916 - mse: 4.4070e-04\n",
      "Epoch 74/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1229 - bpp: 1.0906 - mse: 4.9616e-04\n",
      "Epoch 74: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.1229 - bpp: 1.0906 - mse: 4.9616e-04\n",
      "Epoch 75/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3656 - bpp: 1.0939 - mse: 5.5462e-04\n",
      "Epoch 75: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.3656 - bpp: 1.0939 - mse: 5.5462e-04\n",
      "Epoch 76/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0829 - bpp: 1.1361 - mse: 7.1945e-04\n",
      "Epoch 76: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 4.0829 - bpp: 1.1361 - mse: 7.1945e-04\n",
      "Epoch 77/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9573 - bpp: 1.0711 - mse: 4.6049e-04\n",
      "Epoch 77: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.9573 - bpp: 1.0711 - mse: 4.6049e-04\n",
      "Epoch 78/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0516 - bpp: 1.0941 - mse: 4.7790e-04\n",
      "Epoch 78: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.0516 - bpp: 1.0941 - mse: 4.7790e-04\n",
      "Epoch 79/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5139 - bpp: 1.0948 - mse: 5.9059e-04\n",
      "Epoch 79: loss did not improve from 2.86086\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.5139 - bpp: 1.0948 - mse: 5.9059e-04\n",
      "Epoch 80/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7992 - bpp: 1.0534 - mse: 4.2621e-04\n",
      "Epoch 80: loss improved from 2.86086 to 2.79916, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.7992 - bpp: 1.0534 - mse: 4.2621e-04\n",
      "Epoch 81/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3734 - bpp: 1.0656 - mse: 5.6343e-04\n",
      "Epoch 81: loss did not improve from 2.79916\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.3734 - bpp: 1.0656 - mse: 5.6343e-04\n",
      "Epoch 82/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9640 - bpp: 1.1363 - mse: 6.9035e-04\n",
      "Epoch 82: loss did not improve from 2.79916\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.9640 - bpp: 1.1363 - mse: 6.9035e-04\n",
      "Epoch 83/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8191 - bpp: 1.0706 - mse: 4.2689e-04\n",
      "Epoch 83: loss did not improve from 2.79916\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.8191 - bpp: 1.0706 - mse: 4.2689e-04\n",
      "Epoch 84/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0347 - bpp: 1.0696 - mse: 4.7975e-04\n",
      "Epoch 84: loss did not improve from 2.79916\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.0347 - bpp: 1.0696 - mse: 4.7975e-04\n",
      "Epoch 85/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8697 - bpp: 1.0543 - mse: 4.4322e-04\n",
      "Epoch 85: loss did not improve from 2.79916\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.8697 - bpp: 1.0543 - mse: 4.4322e-04\n",
      "Epoch 86/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7081 - bpp: 1.0316 - mse: 4.0931e-04\n",
      "Epoch 86: loss improved from 2.79916 to 2.70813, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.7081 - bpp: 1.0316 - mse: 4.0931e-04\n",
      "Epoch 87/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5784 - bpp: 1.0137 - mse: 3.8201e-04\n",
      "Epoch 87: loss improved from 2.70813 to 2.57843, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5784 - bpp: 1.0137 - mse: 3.8201e-04\n",
      "Epoch 88/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7160 - bpp: 1.1066 - mse: 8.8119e-04\n",
      "Epoch 88: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.7160 - bpp: 1.1066 - mse: 8.8119e-04\n",
      "Epoch 89/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9682 - bpp: 1.0314 - mse: 4.7285e-04\n",
      "Epoch 89: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.9682 - bpp: 1.0314 - mse: 4.7285e-04\n",
      "Epoch 90/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8058 - bpp: 1.0210 - mse: 4.3573e-04\n",
      "Epoch 90: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8058 - bpp: 1.0210 - mse: 4.3573e-04\n",
      "Epoch 91/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3777 - bpp: 1.0417 - mse: 5.7032e-04\n",
      "Epoch 91: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.3777 - bpp: 1.0417 - mse: 5.7032e-04\n",
      "Epoch 92/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8385 - bpp: 1.0144 - mse: 4.4533e-04\n",
      "Epoch 92: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8385 - bpp: 1.0144 - mse: 4.4533e-04\n",
      "Epoch 93/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5863 - bpp: 1.0269 - mse: 6.2485e-04\n",
      "Epoch 93: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.5863 - bpp: 1.0269 - mse: 6.2485e-04\n",
      "Epoch 94/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8290 - bpp: 1.0328 - mse: 4.3852e-04\n",
      "Epoch 94: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8290 - bpp: 1.0328 - mse: 4.3852e-04\n",
      "Epoch 95/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6239 - bpp: 1.0088 - mse: 3.9433e-04\n",
      "Epoch 95: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6239 - bpp: 1.0088 - mse: 3.9433e-04\n",
      "Epoch 96/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8275 - bpp: 1.0052 - mse: 4.4490e-04\n",
      "Epoch 96: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8275 - bpp: 1.0052 - mse: 4.4490e-04\n",
      "Epoch 97/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6159 - bpp: 0.9873 - mse: 3.9762e-04\n",
      "Epoch 97: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.6159 - bpp: 0.9873 - mse: 3.9762e-04\n",
      "Epoch 98/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7301 - bpp: 0.9989 - mse: 4.2265e-04\n",
      "Epoch 98: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 2.7301 - bpp: 0.9989 - mse: 4.2265e-04\n",
      "Epoch 99/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6356 - bpp: 0.9782 - mse: 4.0465e-04\n",
      "Epoch 99: loss did not improve from 2.57843\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6356 - bpp: 0.9782 - mse: 4.0465e-04\n",
      "Epoch 100/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4077 - bpp: 0.9599 - mse: 3.5347e-04\n",
      "Epoch 100: loss improved from 2.57843 to 2.40766, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4077 - bpp: 0.9599 - mse: 3.5347e-04\n",
      "Epoch 101/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5659 - bpp: 0.9596 - mse: 3.9218e-04\n",
      "Epoch 101: loss did not improve from 2.40766\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.5659 - bpp: 0.9596 - mse: 3.9218e-04\n",
      "Epoch 102/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6166 - bpp: 0.9906 - mse: 3.9698e-04\n",
      "Epoch 102: loss did not improve from 2.40766\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6166 - bpp: 0.9906 - mse: 3.9698e-04\n",
      "Epoch 103/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3937 - bpp: 0.9641 - mse: 3.4903e-04\n",
      "Epoch 103: loss improved from 2.40766 to 2.39369, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3937 - bpp: 0.9641 - mse: 3.4903e-04\n",
      "Epoch 104/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6370 - bpp: 0.9731 - mse: 4.0622e-04\n",
      "Epoch 104: loss did not improve from 2.39369\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6370 - bpp: 0.9731 - mse: 4.0622e-04\n",
      "Epoch 105/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3640 - bpp: 0.9656 - mse: 3.4142e-04\n",
      "Epoch 105: loss improved from 2.39369 to 2.36401, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3640 - bpp: 0.9656 - mse: 3.4142e-04\n",
      "Epoch 106/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4275 - bpp: 0.9599 - mse: 3.5830e-04\n",
      "Epoch 106: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4275 - bpp: 0.9599 - mse: 3.5830e-04\n",
      "Epoch 107/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5864 - bpp: 0.9675 - mse: 3.9525e-04\n",
      "Epoch 107: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.5864 - bpp: 0.9675 - mse: 3.9525e-04\n",
      "Epoch 108/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9606 - bpp: 1.0033 - mse: 7.2200e-04\n",
      "Epoch 108: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.9606 - bpp: 1.0033 - mse: 7.2200e-04\n",
      "Epoch 109/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6015 - bpp: 0.9435 - mse: 4.0480e-04\n",
      "Epoch 109: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6015 - bpp: 0.9435 - mse: 4.0480e-04\n",
      "Epoch 110/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5845 - bpp: 0.9564 - mse: 3.9749e-04\n",
      "Epoch 110: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.5845 - bpp: 0.9564 - mse: 3.9749e-04\n",
      "Epoch 111/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4085 - bpp: 0.9554 - mse: 3.5477e-04\n",
      "Epoch 111: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.4085 - bpp: 0.9554 - mse: 3.5477e-04\n",
      "Epoch 112/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3475 - bpp: 1.0057 - mse: 5.7172e-04\n",
      "Epoch 112: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.3475 - bpp: 1.0057 - mse: 5.7172e-04\n",
      "Epoch 113/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3942 - bpp: 0.9320 - mse: 3.5698e-04\n",
      "Epoch 113: loss did not improve from 2.36401\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3942 - bpp: 0.9320 - mse: 3.5698e-04\n",
      "Epoch 114/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3443 - bpp: 0.9194 - mse: 3.4788e-04\n",
      "Epoch 114: loss improved from 2.36401 to 2.34429, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3443 - bpp: 0.9194 - mse: 3.4788e-04\n",
      "Epoch 115/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5985 - bpp: 0.9556 - mse: 4.0110e-04\n",
      "Epoch 115: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.5985 - bpp: 0.9556 - mse: 4.0110e-04\n",
      "Epoch 116/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6283 - bpp: 0.9473 - mse: 4.1040e-04\n",
      "Epoch 116: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 26s 124ms/step - loss: 2.6283 - bpp: 0.9473 - mse: 4.1040e-04\n",
      "Epoch 117/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4141 - bpp: 0.9829 - mse: 0.0011\n",
      "Epoch 117: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.4141 - bpp: 0.9829 - mse: 0.0011\n",
      "Epoch 118/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6912 - bpp: 0.9321 - mse: 4.2946e-04\n",
      "Epoch 118: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.6912 - bpp: 0.9321 - mse: 4.2946e-04\n",
      "Epoch 119/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5275 - bpp: 0.9597 - mse: 3.8277e-04\n",
      "Epoch 119: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5275 - bpp: 0.9597 - mse: 3.8277e-04\n",
      "Epoch 120/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5002 - bpp: 0.9564 - mse: 3.7692e-04\n",
      "Epoch 120: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.5002 - bpp: 0.9564 - mse: 3.7692e-04\n",
      "Epoch 121/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6548 - bpp: 0.9623 - mse: 4.1321e-04\n",
      "Epoch 121: loss did not improve from 2.34429\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.6548 - bpp: 0.9623 - mse: 4.1321e-04\n",
      "Epoch 122/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2913 - bpp: 0.9129 - mse: 3.3651e-04\n",
      "Epoch 122: loss improved from 2.34429 to 2.29130, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2913 - bpp: 0.9129 - mse: 3.3651e-04\n",
      "Epoch 123/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2082 - bpp: 0.9049 - mse: 3.1820e-04\n",
      "Epoch 123: loss improved from 2.29130 to 2.20822, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2082 - bpp: 0.9049 - mse: 3.1820e-04\n",
      "Epoch 124/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3188 - bpp: 0.9076 - mse: 3.4453e-04\n",
      "Epoch 124: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.3188 - bpp: 0.9076 - mse: 3.4453e-04\n",
      "Epoch 125/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3276 - bpp: 0.9200 - mse: 3.4364e-04\n",
      "Epoch 125: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.3276 - bpp: 0.9200 - mse: 3.4364e-04\n",
      "Epoch 126/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3744 - bpp: 0.9282 - mse: 3.5308e-04\n",
      "Epoch 126: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3744 - bpp: 0.9282 - mse: 3.5308e-04\n",
      "Epoch 127/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4368 - bpp: 0.9165 - mse: 3.7117e-04\n",
      "Epoch 127: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.4368 - bpp: 0.9165 - mse: 3.7117e-04\n",
      "Epoch 128/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2454 - bpp: 0.8820 - mse: 3.3288e-04\n",
      "Epoch 128: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.2454 - bpp: 0.8820 - mse: 3.3288e-04\n",
      "Epoch 129/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3968 - bpp: 0.9097 - mse: 3.6306e-04\n",
      "Epoch 129: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.3968 - bpp: 0.9097 - mse: 3.6306e-04\n",
      "Epoch 130/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9689 - bpp: 0.9216 - mse: 4.9983e-04\n",
      "Epoch 130: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.9689 - bpp: 0.9216 - mse: 4.9983e-04\n",
      "Epoch 131/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5095 - bpp: 0.9160 - mse: 3.8903e-04\n",
      "Epoch 131: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.5095 - bpp: 0.9160 - mse: 3.8903e-04\n",
      "Epoch 132/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2584 - bpp: 0.8942 - mse: 3.3304e-04\n",
      "Epoch 132: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.2584 - bpp: 0.8942 - mse: 3.3304e-04\n",
      "Epoch 133/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4204 - bpp: 0.8887 - mse: 3.7396e-04\n",
      "Epoch 133: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4204 - bpp: 0.8887 - mse: 3.7396e-04\n",
      "Epoch 134/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5675 - bpp: 0.9010 - mse: 4.0685e-04\n",
      "Epoch 134: loss did not improve from 2.20822\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5675 - bpp: 0.9010 - mse: 4.0685e-04\n",
      "Epoch 135/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1851 - bpp: 0.8973 - mse: 3.1441e-04\n",
      "Epoch 135: loss improved from 2.20822 to 2.18512, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.1851 - bpp: 0.8973 - mse: 3.1441e-04\n",
      "Epoch 136/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4594 - bpp: 0.9061 - mse: 3.7921e-04\n",
      "Epoch 136: loss did not improve from 2.18512\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.4594 - bpp: 0.9061 - mse: 3.7921e-04\n",
      "Epoch 137/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2277 - bpp: 0.8729 - mse: 3.3075e-04\n",
      "Epoch 137: loss did not improve from 2.18512\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.2277 - bpp: 0.8729 - mse: 3.3075e-04\n",
      "Epoch 138/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2615 - bpp: 0.8889 - mse: 3.3510e-04\n",
      "Epoch 138: loss did not improve from 2.18512\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.2615 - bpp: 0.8889 - mse: 3.3510e-04\n",
      "Epoch 139/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3174 - bpp: 0.9111 - mse: 3.4333e-04\n",
      "Epoch 139: loss did not improve from 2.18512\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3174 - bpp: 0.9111 - mse: 3.4333e-04\n",
      "Epoch 140/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1106 - bpp: 0.8589 - mse: 3.0559e-04\n",
      "Epoch 140: loss improved from 2.18512 to 2.11063, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.1106 - bpp: 0.8589 - mse: 3.0559e-04\n",
      "Epoch 141/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4433 - bpp: 0.8919 - mse: 3.7876e-04\n",
      "Epoch 141: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.4433 - bpp: 0.8919 - mse: 3.7876e-04\n",
      "Epoch 142/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3733 - bpp: 0.8931 - mse: 3.6136e-04\n",
      "Epoch 142: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.3733 - bpp: 0.8931 - mse: 3.6136e-04\n",
      "Epoch 143/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5770 - bpp: 0.8943 - mse: 6.5496e-04\n",
      "Epoch 143: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.5770 - bpp: 0.8943 - mse: 6.5496e-04\n",
      "Epoch 144/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8920 - bpp: 0.9128 - mse: 4.8321e-04\n",
      "Epoch 144: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8920 - bpp: 0.9128 - mse: 4.8321e-04\n",
      "Epoch 145/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4929 - bpp: 0.8804 - mse: 3.9369e-04\n",
      "Epoch 145: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.4929 - bpp: 0.8804 - mse: 3.9369e-04\n",
      "Epoch 146/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1149 - bpp: 0.8575 - mse: 3.0699e-04\n",
      "Epoch 146: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.1149 - bpp: 0.8575 - mse: 3.0699e-04\n",
      "Epoch 147/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1769 - bpp: 0.8802 - mse: 3.1656e-04\n",
      "Epoch 147: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.1769 - bpp: 0.8802 - mse: 3.1656e-04\n",
      "Epoch 148/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1509 - bpp: 0.8699 - mse: 3.1272e-04\n",
      "Epoch 148: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1509 - bpp: 0.8699 - mse: 3.1272e-04\n",
      "Epoch 149/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1438 - bpp: 0.8609 - mse: 3.1322e-04\n",
      "Epoch 149: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.1438 - bpp: 0.8609 - mse: 3.1322e-04\n",
      "Epoch 150/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2106 - bpp: 0.8817 - mse: 3.2443e-04\n",
      "Epoch 150: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2106 - bpp: 0.8817 - mse: 3.2443e-04\n",
      "Epoch 151/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1810 - bpp: 0.8732 - mse: 3.1928e-04\n",
      "Epoch 151: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.1810 - bpp: 0.8732 - mse: 3.1928e-04\n",
      "Epoch 152/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2588 - bpp: 0.8785 - mse: 3.3698e-04\n",
      "Epoch 152: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.2588 - bpp: 0.8785 - mse: 3.3698e-04\n",
      "Epoch 153/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6442 - bpp: 0.8854 - mse: 4.2939e-04\n",
      "Epoch 153: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6442 - bpp: 0.8854 - mse: 4.2939e-04\n",
      "Epoch 154/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1251 - bpp: 0.8384 - mse: 3.1414e-04\n",
      "Epoch 154: loss did not improve from 2.11063\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1251 - bpp: 0.8384 - mse: 3.1414e-04\n",
      "Epoch 155/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0839 - bpp: 0.8363 - mse: 3.0461e-04\n",
      "Epoch 155: loss improved from 2.11063 to 2.08395, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.0839 - bpp: 0.8363 - mse: 3.0461e-04\n",
      "Epoch 156/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9787 - bpp: 0.8336 - mse: 2.7955e-04\n",
      "Epoch 156: loss improved from 2.08395 to 1.97865, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 1.9787 - bpp: 0.8336 - mse: 2.7955e-04\n",
      "Epoch 157/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9448 - bpp: 0.8360 - mse: 2.7070e-04\n",
      "Epoch 157: loss improved from 1.97865 to 1.94482, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.9448 - bpp: 0.8360 - mse: 2.7070e-04\n",
      "Epoch 158/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2443 - bpp: 0.8636 - mse: 3.3708e-04\n",
      "Epoch 158: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2443 - bpp: 0.8636 - mse: 3.3708e-04\n",
      "Epoch 159/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0467 - bpp: 0.8415 - mse: 2.9422e-04\n",
      "Epoch 159: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0467 - bpp: 0.8415 - mse: 2.9422e-04\n",
      "Epoch 160/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2859 - bpp: 0.8685 - mse: 3.4604e-04\n",
      "Epoch 160: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2859 - bpp: 0.8685 - mse: 3.4604e-04\n",
      "Epoch 161/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1606 - bpp: 0.8351 - mse: 3.2358e-04\n",
      "Epoch 161: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1606 - bpp: 0.8351 - mse: 3.2358e-04\n",
      "Epoch 162/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1686 - bpp: 0.8463 - mse: 3.2282e-04\n",
      "Epoch 162: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.1686 - bpp: 0.8463 - mse: 3.2282e-04\n",
      "Epoch 163/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1275 - bpp: 0.8331 - mse: 3.1602e-04\n",
      "Epoch 163: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1275 - bpp: 0.8331 - mse: 3.1602e-04\n",
      "Epoch 164/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1366 - bpp: 0.8574 - mse: 3.1229e-04\n",
      "Epoch 164: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1366 - bpp: 0.8574 - mse: 3.1229e-04\n",
      "Epoch 165/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1232 - bpp: 0.8825 - mse: 5.4704e-04\n",
      "Epoch 165: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.1232 - bpp: 0.8825 - mse: 5.4704e-04\n",
      "Epoch 166/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0855 - bpp: 0.8754 - mse: 5.3958e-04\n",
      "Epoch 166: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.0855 - bpp: 0.8754 - mse: 5.3958e-04\n",
      "Epoch 167/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1259 - bpp: 0.8394 - mse: 3.1407e-04\n",
      "Epoch 167: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1259 - bpp: 0.8394 - mse: 3.1407e-04\n",
      "Epoch 168/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9887 - bpp: 0.8278 - mse: 2.8341e-04\n",
      "Epoch 168: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.9887 - bpp: 0.8278 - mse: 2.8341e-04\n",
      "Epoch 169/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2061 - bpp: 0.8469 - mse: 3.3184e-04\n",
      "Epoch 169: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.2061 - bpp: 0.8469 - mse: 3.3184e-04\n",
      "Epoch 170/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2916 - bpp: 0.8184 - mse: 3.5968e-04\n",
      "Epoch 170: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.2916 - bpp: 0.8184 - mse: 3.5968e-04\n",
      "Epoch 171/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2008 - bpp: 0.8279 - mse: 3.3519e-04\n",
      "Epoch 171: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2008 - bpp: 0.8279 - mse: 3.3519e-04\n",
      "Epoch 172/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9589 - bpp: 0.8172 - mse: 2.7873e-04\n",
      "Epoch 172: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9589 - bpp: 0.8172 - mse: 2.7873e-04\n",
      "Epoch 173/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1108 - bpp: 0.8440 - mse: 3.0929e-04\n",
      "Epoch 173: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1108 - bpp: 0.8440 - mse: 3.0929e-04\n",
      "Epoch 174/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0443 - bpp: 0.8227 - mse: 2.9824e-04\n",
      "Epoch 174: loss did not improve from 1.94482\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.0443 - bpp: 0.8227 - mse: 2.9824e-04\n",
      "Epoch 175/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8510 - bpp: 0.7920 - mse: 2.5856e-04\n",
      "Epoch 175: loss improved from 1.94482 to 1.85103, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.8510 - bpp: 0.7920 - mse: 2.5856e-04\n",
      "Epoch 176/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0873 - bpp: 0.8411 - mse: 3.0424e-04\n",
      "Epoch 176: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.0873 - bpp: 0.8411 - mse: 3.0424e-04\n",
      "Epoch 177/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9622 - bpp: 0.8074 - mse: 2.8193e-04\n",
      "Epoch 177: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.9622 - bpp: 0.8074 - mse: 2.8193e-04\n",
      "Epoch 178/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0638 - bpp: 0.8257 - mse: 3.0228e-04\n",
      "Epoch 178: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0638 - bpp: 0.8257 - mse: 3.0228e-04\n",
      "Epoch 179/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0177 - bpp: 0.8142 - mse: 2.9383e-04\n",
      "Epoch 179: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.0177 - bpp: 0.8142 - mse: 2.9383e-04\n",
      "Epoch 180/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8952 - bpp: 0.8699 - mse: 4.9446e-04\n",
      "Epoch 180: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.8952 - bpp: 0.8699 - mse: 4.9446e-04\n",
      "Epoch 181/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2213 - bpp: 0.8281 - mse: 3.4014e-04\n",
      "Epoch 181: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 2.2213 - bpp: 0.8281 - mse: 3.4014e-04\n",
      "Epoch 182/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9867 - bpp: 0.8146 - mse: 2.8617e-04\n",
      "Epoch 182: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9867 - bpp: 0.8146 - mse: 2.8617e-04\n",
      "Epoch 183/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1267 - bpp: 0.8567 - mse: 3.1005e-04\n",
      "Epoch 183: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1267 - bpp: 0.8567 - mse: 3.1005e-04\n",
      "Epoch 184/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9014 - bpp: 0.8257 - mse: 2.6264e-04\n",
      "Epoch 184: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9014 - bpp: 0.8257 - mse: 2.6264e-04\n",
      "Epoch 185/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1163 - bpp: 0.8387 - mse: 3.1192e-04\n",
      "Epoch 185: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.1163 - bpp: 0.8387 - mse: 3.1192e-04\n",
      "Epoch 186/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0992 - bpp: 0.8383 - mse: 3.0785e-04\n",
      "Epoch 186: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0992 - bpp: 0.8383 - mse: 3.0785e-04\n",
      "Epoch 187/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0907 - bpp: 0.8288 - mse: 3.0809e-04\n",
      "Epoch 187: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0907 - bpp: 0.8288 - mse: 3.0809e-04\n",
      "Epoch 188/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9590 - bpp: 0.8134 - mse: 2.7968e-04\n",
      "Epoch 188: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.9590 - bpp: 0.8134 - mse: 2.7968e-04\n",
      "Epoch 189/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9849 - bpp: 0.8035 - mse: 2.8842e-04\n",
      "Epoch 189: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.9849 - bpp: 0.8035 - mse: 2.8842e-04\n",
      "Epoch 190/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1031 - bpp: 0.8410 - mse: 3.0811e-04\n",
      "Epoch 190: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1031 - bpp: 0.8410 - mse: 3.0811e-04\n",
      "Epoch 191/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8744 - bpp: 0.7968 - mse: 2.6309e-04\n",
      "Epoch 191: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.8744 - bpp: 0.7968 - mse: 2.6309e-04\n",
      "Epoch 192/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0334 - bpp: 0.8172 - mse: 2.9691e-04\n",
      "Epoch 192: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 115ms/step - loss: 2.0334 - bpp: 0.8172 - mse: 2.9691e-04\n",
      "Epoch 193/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2284 - bpp: 0.8522 - mse: 5.8014e-04\n",
      "Epoch 193: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2284 - bpp: 0.8522 - mse: 5.8014e-04\n",
      "Epoch 194/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2199 - bpp: 0.8420 - mse: 3.3639e-04\n",
      "Epoch 194: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.2199 - bpp: 0.8420 - mse: 3.3639e-04\n",
      "Epoch 195/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0339 - bpp: 0.8342 - mse: 2.9289e-04\n",
      "Epoch 195: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0339 - bpp: 0.8342 - mse: 2.9289e-04\n",
      "Epoch 196/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1175 - bpp: 0.8451 - mse: 3.1064e-04\n",
      "Epoch 196: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1175 - bpp: 0.8451 - mse: 3.1064e-04\n",
      "Epoch 197/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9366 - bpp: 0.8082 - mse: 2.7547e-04\n",
      "Epoch 197: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.9366 - bpp: 0.8082 - mse: 2.7547e-04\n",
      "Epoch 198/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9767 - bpp: 0.8232 - mse: 2.8160e-04\n",
      "Epoch 198: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9767 - bpp: 0.8232 - mse: 2.8160e-04\n",
      "Epoch 199/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0144 - bpp: 0.8318 - mse: 2.8872e-04\n",
      "Epoch 199: loss did not improve from 1.85103\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.0144 - bpp: 0.8318 - mse: 2.8872e-04\n",
      "Epoch 200/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7977 - bpp: 0.7793 - mse: 2.4865e-04\n",
      "Epoch 200: loss improved from 1.85103 to 1.79774, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.7977 - bpp: 0.7793 - mse: 2.4865e-04\n",
      "Epoch 201/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9957 - bpp: 0.8074 - mse: 2.9011e-04\n",
      "Epoch 201: loss did not improve from 1.79774\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.9957 - bpp: 0.8074 - mse: 2.9011e-04\n",
      "Epoch 202/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0127 - bpp: 0.8168 - mse: 2.9198e-04\n",
      "Epoch 202: loss did not improve from 1.79774\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.0127 - bpp: 0.8168 - mse: 2.9198e-04\n",
      "Epoch 203/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0622 - bpp: 0.8173 - mse: 3.0393e-04\n",
      "Epoch 203: loss did not improve from 1.79774\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0622 - bpp: 0.8173 - mse: 3.0393e-04\n",
      "Epoch 204/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0972 - bpp: 0.8168 - mse: 3.1261e-04\n",
      "Epoch 204: loss did not improve from 1.79774\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.0972 - bpp: 0.8168 - mse: 3.1261e-04\n",
      "Epoch 205/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8830 - bpp: 0.8050 - mse: 2.6319e-04\n",
      "Epoch 205: loss did not improve from 1.79774\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.8830 - bpp: 0.8050 - mse: 2.6319e-04\n",
      "Epoch 206/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0855 - bpp: 0.8301 - mse: 3.0647e-04\n",
      "Epoch 206: loss did not improve from 1.79774\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0855 - bpp: 0.8301 - mse: 3.0647e-04\n",
      "Epoch 207/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7812 - bpp: 0.7996 - mse: 2.3966e-04\n",
      "Epoch 207: loss improved from 1.79774 to 1.78123, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.7812 - bpp: 0.7996 - mse: 2.3966e-04\n",
      "Epoch 208/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9902 - bpp: 0.8088 - mse: 2.8845e-04\n",
      "Epoch 208: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9902 - bpp: 0.8088 - mse: 2.8845e-04\n",
      "Epoch 209/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9811 - bpp: 0.7982 - mse: 2.8881e-04\n",
      "Epoch 209: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.9811 - bpp: 0.7982 - mse: 2.8881e-04\n",
      "Epoch 210/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8834 - bpp: 0.7936 - mse: 2.6606e-04\n",
      "Epoch 210: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.8834 - bpp: 0.7936 - mse: 2.6606e-04\n",
      "Epoch 211/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9437 - bpp: 0.7987 - mse: 2.7956e-04\n",
      "Epoch 211: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9437 - bpp: 0.7987 - mse: 2.7956e-04\n",
      "Epoch 212/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9210 - bpp: 0.7939 - mse: 2.7517e-04\n",
      "Epoch 212: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.9210 - bpp: 0.7939 - mse: 2.7517e-04\n",
      "Epoch 213/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1308 - bpp: 0.8043 - mse: 3.2386e-04\n",
      "Epoch 213: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1308 - bpp: 0.8043 - mse: 3.2386e-04\n",
      "Epoch 214/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1377 - bpp: 0.8078 - mse: 3.2469e-04\n",
      "Epoch 214: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.1377 - bpp: 0.8078 - mse: 3.2469e-04\n",
      "Epoch 215/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9318 - bpp: 0.7958 - mse: 2.7735e-04\n",
      "Epoch 215: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.9318 - bpp: 0.7958 - mse: 2.7735e-04\n",
      "Epoch 216/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8928 - bpp: 0.7863 - mse: 2.7014e-04\n",
      "Epoch 216: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.8928 - bpp: 0.7863 - mse: 2.7014e-04\n",
      "Epoch 217/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0001 - bpp: 0.8073 - mse: 2.9121e-04\n",
      "Epoch 217: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0001 - bpp: 0.8073 - mse: 2.9121e-04\n",
      "Epoch 218/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2020 - bpp: 0.8227 - mse: 3.3675e-04\n",
      "Epoch 218: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.2020 - bpp: 0.8227 - mse: 3.3675e-04\n",
      "Epoch 219/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9097 - bpp: 0.7939 - mse: 2.7241e-04\n",
      "Epoch 219: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9097 - bpp: 0.7939 - mse: 2.7241e-04\n",
      "Epoch 220/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0273 - bpp: 0.8135 - mse: 2.9635e-04\n",
      "Epoch 220: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.0273 - bpp: 0.8135 - mse: 2.9635e-04\n",
      "Epoch 221/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0403 - bpp: 0.8016 - mse: 3.0242e-04\n",
      "Epoch 221: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.0403 - bpp: 0.8016 - mse: 3.0242e-04\n",
      "Epoch 222/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3943 - bpp: 0.8293 - mse: 3.8207e-04\n",
      "Epoch 222: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3943 - bpp: 0.8293 - mse: 3.8207e-04\n",
      "Epoch 223/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9460 - bpp: 0.7933 - mse: 2.8142e-04\n",
      "Epoch 223: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.9460 - bpp: 0.7933 - mse: 2.8142e-04\n",
      "Epoch 224/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1177 - bpp: 0.7972 - mse: 3.2240e-04\n",
      "Epoch 224: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1177 - bpp: 0.7972 - mse: 3.2240e-04\n",
      "Epoch 225/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0231 - bpp: 0.7933 - mse: 3.0025e-04\n",
      "Epoch 225: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0231 - bpp: 0.7933 - mse: 3.0025e-04\n",
      "Epoch 226/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5244 - bpp: 0.8106 - mse: 4.1842e-04\n",
      "Epoch 226: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.5244 - bpp: 0.8106 - mse: 4.1842e-04\n",
      "Epoch 227/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2457 - bpp: 0.8166 - mse: 3.4890e-04\n",
      "Epoch 227: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.2457 - bpp: 0.8166 - mse: 3.4890e-04\n",
      "Epoch 228/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0693 - bpp: 0.8148 - mse: 3.0628e-04\n",
      "Epoch 228: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0693 - bpp: 0.8148 - mse: 3.0628e-04\n",
      "Epoch 229/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8532 - bpp: 0.7873 - mse: 2.6024e-04\n",
      "Epoch 229: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.8532 - bpp: 0.7873 - mse: 2.6024e-04\n",
      "Epoch 230/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8798 - bpp: 0.7844 - mse: 2.6742e-04\n",
      "Epoch 230: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.8798 - bpp: 0.7844 - mse: 2.6742e-04\n",
      "Epoch 231/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8876 - bpp: 0.7807 - mse: 2.7024e-04\n",
      "Epoch 231: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.8876 - bpp: 0.7807 - mse: 2.7024e-04\n",
      "Epoch 232/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9563 - bpp: 0.7873 - mse: 2.8540e-04\n",
      "Epoch 232: loss did not improve from 1.78123\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9563 - bpp: 0.7873 - mse: 2.8540e-04\n",
      "Epoch 233/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7300 - bpp: 0.7645 - mse: 2.3572e-04\n",
      "Epoch 233: loss improved from 1.78123 to 1.73001, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.7300 - bpp: 0.7645 - mse: 2.3572e-04\n",
      "Epoch 234/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9952 - bpp: 0.7905 - mse: 2.9410e-04\n",
      "Epoch 234: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.9952 - bpp: 0.7905 - mse: 2.9410e-04\n",
      "Epoch 235/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8233 - bpp: 0.7628 - mse: 2.5891e-04\n",
      "Epoch 235: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8233 - bpp: 0.7628 - mse: 2.5891e-04\n",
      "Epoch 236/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0652 - bpp: 0.8076 - mse: 3.0702e-04\n",
      "Epoch 236: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.0652 - bpp: 0.8076 - mse: 3.0702e-04\n",
      "Epoch 237/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8218 - bpp: 0.7928 - mse: 2.5122e-04\n",
      "Epoch 237: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 26s 124ms/step - loss: 1.8218 - bpp: 0.7928 - mse: 2.5122e-04\n",
      "Epoch 238/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0108 - bpp: 0.7933 - mse: 2.9725e-04\n",
      "Epoch 238: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0108 - bpp: 0.7933 - mse: 2.9725e-04\n",
      "Epoch 239/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9564 - bpp: 0.8032 - mse: 2.8156e-04\n",
      "Epoch 239: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.9564 - bpp: 0.8032 - mse: 2.8156e-04\n",
      "Epoch 240/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8668 - bpp: 0.7953 - mse: 2.6159e-04\n",
      "Epoch 240: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8668 - bpp: 0.7953 - mse: 2.6159e-04\n",
      "Epoch 241/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8343 - bpp: 0.7693 - mse: 2.6001e-04\n",
      "Epoch 241: loss did not improve from 1.73001\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8343 - bpp: 0.7693 - mse: 2.6001e-04\n",
      "Epoch 242/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6390 - bpp: 0.7552 - mse: 2.1577e-04\n",
      "Epoch 242: loss improved from 1.73001 to 1.63898, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.6390 - bpp: 0.7552 - mse: 2.1577e-04\n",
      "Epoch 243/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0749 - bpp: 0.8210 - mse: 3.0612e-04\n",
      "Epoch 243: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.0749 - bpp: 0.8210 - mse: 3.0612e-04\n",
      "Epoch 244/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8717 - bpp: 0.7899 - mse: 2.6412e-04\n",
      "Epoch 244: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 1.8717 - bpp: 0.7899 - mse: 2.6412e-04\n",
      "Epoch 245/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9260 - bpp: 0.7840 - mse: 2.7879e-04\n",
      "Epoch 245: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.9260 - bpp: 0.7840 - mse: 2.7879e-04\n",
      "Epoch 246/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0310 - bpp: 0.8158 - mse: 2.9668e-04\n",
      "Epoch 246: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.0310 - bpp: 0.8158 - mse: 2.9668e-04\n",
      "Epoch 247/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5593 - bpp: 0.8049 - mse: 4.2832e-04\n",
      "Epoch 247: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.5593 - bpp: 0.8049 - mse: 4.2832e-04\n",
      "Epoch 248/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8748 - bpp: 0.7895 - mse: 2.6497e-04\n",
      "Epoch 248: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8748 - bpp: 0.7895 - mse: 2.6497e-04\n",
      "Epoch 249/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7302 - bpp: 0.7629 - mse: 2.3616e-04\n",
      "Epoch 249: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.7302 - bpp: 0.7629 - mse: 2.3616e-04\n",
      "Epoch 250/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7700 - bpp: 0.7738 - mse: 2.4321e-04\n",
      "Epoch 250: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.7700 - bpp: 0.7738 - mse: 2.4321e-04\n",
      "Epoch 251/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7417 - bpp: 0.7606 - mse: 2.3953e-04\n",
      "Epoch 251: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7417 - bpp: 0.7606 - mse: 2.3953e-04\n",
      "Epoch 252/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7598 - bpp: 0.7532 - mse: 2.4574e-04\n",
      "Epoch 252: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.7598 - bpp: 0.7532 - mse: 2.4574e-04\n",
      "Epoch 253/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8173 - bpp: 0.7706 - mse: 2.5555e-04\n",
      "Epoch 253: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.8173 - bpp: 0.7706 - mse: 2.5555e-04\n",
      "Epoch 254/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7016 - bpp: 0.7652 - mse: 2.2861e-04\n",
      "Epoch 254: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.7016 - bpp: 0.7652 - mse: 2.2861e-04\n",
      "Epoch 255/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8606 - bpp: 0.7862 - mse: 2.6232e-04\n",
      "Epoch 255: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.8606 - bpp: 0.7862 - mse: 2.6232e-04\n",
      "Epoch 256/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8743 - bpp: 0.7869 - mse: 2.6548e-04\n",
      "Epoch 256: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.8743 - bpp: 0.7869 - mse: 2.6548e-04\n",
      "Epoch 257/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7144 - bpp: 0.7619 - mse: 2.3253e-04\n",
      "Epoch 257: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.7144 - bpp: 0.7619 - mse: 2.3253e-04\n",
      "Epoch 258/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8235 - bpp: 0.7719 - mse: 2.5676e-04\n",
      "Epoch 258: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.8235 - bpp: 0.7719 - mse: 2.5676e-04\n",
      "Epoch 259/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7238 - bpp: 0.7554 - mse: 2.3643e-04\n",
      "Epoch 259: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.7238 - bpp: 0.7554 - mse: 2.3643e-04\n",
      "Epoch 260/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1385 - bpp: 0.7937 - mse: 3.2830e-04\n",
      "Epoch 260: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1385 - bpp: 0.7937 - mse: 3.2830e-04\n",
      "Epoch 261/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1856 - bpp: 0.8054 - mse: 3.3698e-04\n",
      "Epoch 261: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1856 - bpp: 0.8054 - mse: 3.3698e-04\n",
      "Epoch 262/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8626 - bpp: 0.7814 - mse: 2.6394e-04\n",
      "Epoch 262: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.8626 - bpp: 0.7814 - mse: 2.6394e-04\n",
      "Epoch 263/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9125 - bpp: 0.7717 - mse: 2.7850e-04\n",
      "Epoch 263: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.9125 - bpp: 0.7717 - mse: 2.7850e-04\n",
      "Epoch 264/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6810 - bpp: 0.7553 - mse: 2.2601e-04\n",
      "Epoch 264: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6810 - bpp: 0.7553 - mse: 2.2601e-04\n",
      "Epoch 265/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9591 - bpp: 0.7905 - mse: 2.8532e-04\n",
      "Epoch 265: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.9591 - bpp: 0.7905 - mse: 2.8532e-04\n",
      "Epoch 266/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7296 - bpp: 0.7575 - mse: 2.3733e-04\n",
      "Epoch 266: loss did not improve from 1.63898\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7296 - bpp: 0.7575 - mse: 2.3733e-04\n",
      "Epoch 267/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5972 - bpp: 0.7462 - mse: 2.0777e-04\n",
      "Epoch 267: loss improved from 1.63898 to 1.59722, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 1.5972 - bpp: 0.7462 - mse: 2.0777e-04\n",
      "Epoch 268/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7746 - bpp: 0.7774 - mse: 2.4344e-04\n",
      "Epoch 268: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.7746 - bpp: 0.7774 - mse: 2.4344e-04\n",
      "Epoch 269/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6626 - bpp: 0.7521 - mse: 2.2229e-04\n",
      "Epoch 269: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6626 - bpp: 0.7521 - mse: 2.2229e-04\n",
      "Epoch 270/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6280 - bpp: 0.7381 - mse: 2.1726e-04\n",
      "Epoch 270: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.6280 - bpp: 0.7381 - mse: 2.1726e-04\n",
      "Epoch 271/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0600 - bpp: 0.7902 - mse: 3.0999e-04\n",
      "Epoch 271: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.0600 - bpp: 0.7902 - mse: 3.0999e-04\n",
      "Epoch 272/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0863 - bpp: 0.7898 - mse: 3.1652e-04\n",
      "Epoch 272: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.0863 - bpp: 0.7898 - mse: 3.1652e-04\n",
      "Epoch 273/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7072 - bpp: 0.7673 - mse: 2.2948e-04\n",
      "Epoch 273: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.7072 - bpp: 0.7673 - mse: 2.2948e-04\n",
      "Epoch 274/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7998 - bpp: 0.7719 - mse: 2.5095e-04\n",
      "Epoch 274: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7998 - bpp: 0.7719 - mse: 2.5095e-04\n",
      "Epoch 275/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8462 - bpp: 0.7793 - mse: 2.6047e-04\n",
      "Epoch 275: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.8462 - bpp: 0.7793 - mse: 2.6047e-04\n",
      "Epoch 276/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8456 - bpp: 0.7802 - mse: 2.6013e-04\n",
      "Epoch 276: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8456 - bpp: 0.7802 - mse: 2.6013e-04\n",
      "Epoch 277/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1390 - bpp: 0.7783 - mse: 3.3220e-04\n",
      "Epoch 277: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1390 - bpp: 0.7783 - mse: 3.3220e-04\n",
      "Epoch 278/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7974 - bpp: 0.7566 - mse: 2.5410e-04\n",
      "Epoch 278: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7974 - bpp: 0.7566 - mse: 2.5410e-04\n",
      "Epoch 279/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8601 - bpp: 0.7734 - mse: 2.6531e-04\n",
      "Epoch 279: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.8601 - bpp: 0.7734 - mse: 2.6531e-04\n",
      "Epoch 280/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0820 - bpp: 0.7956 - mse: 3.1407e-04\n",
      "Epoch 280: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0820 - bpp: 0.7956 - mse: 3.1407e-04\n",
      "Epoch 281/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7305 - bpp: 0.7615 - mse: 2.3656e-04\n",
      "Epoch 281: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.7305 - bpp: 0.7615 - mse: 2.3656e-04\n",
      "Epoch 282/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6067 - bpp: 0.7453 - mse: 2.1032e-04\n",
      "Epoch 282: loss did not improve from 1.59722\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.6067 - bpp: 0.7453 - mse: 2.1032e-04\n",
      "Epoch 283/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5854 - bpp: 0.7486 - mse: 2.0429e-04\n",
      "Epoch 283: loss improved from 1.59722 to 1.58539, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.5854 - bpp: 0.7486 - mse: 2.0429e-04\n",
      "Epoch 284/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8345 - bpp: 0.7785 - mse: 2.5781e-04\n",
      "Epoch 284: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8345 - bpp: 0.7785 - mse: 2.5781e-04\n",
      "Epoch 285/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8237 - bpp: 0.7728 - mse: 2.5658e-04\n",
      "Epoch 285: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.8237 - bpp: 0.7728 - mse: 2.5658e-04\n",
      "Epoch 286/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8709 - bpp: 0.7919 - mse: 2.6342e-04\n",
      "Epoch 286: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8709 - bpp: 0.7919 - mse: 2.6342e-04\n",
      "Epoch 287/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8700 - bpp: 0.7739 - mse: 2.6760e-04\n",
      "Epoch 287: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.8700 - bpp: 0.7739 - mse: 2.6760e-04\n",
      "Epoch 288/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7749 - bpp: 0.7577 - mse: 2.4836e-04\n",
      "Epoch 288: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 25s 118ms/step - loss: 1.7749 - bpp: 0.7577 - mse: 2.4836e-04\n",
      "Epoch 289/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6467 - bpp: 0.7484 - mse: 2.1932e-04\n",
      "Epoch 289: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6467 - bpp: 0.7484 - mse: 2.1932e-04\n",
      "Epoch 290/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8477 - bpp: 0.7737 - mse: 2.6220e-04\n",
      "Epoch 290: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.8477 - bpp: 0.7737 - mse: 2.6220e-04\n",
      "Epoch 291/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7151 - bpp: 0.7416 - mse: 2.3766e-04\n",
      "Epoch 291: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.7151 - bpp: 0.7416 - mse: 2.3766e-04\n",
      "Epoch 292/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8310 - bpp: 0.7745 - mse: 2.5795e-04\n",
      "Epoch 292: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8310 - bpp: 0.7745 - mse: 2.5795e-04\n",
      "Epoch 293/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9880 - bpp: 0.7742 - mse: 2.9635e-04\n",
      "Epoch 293: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.9880 - bpp: 0.7742 - mse: 2.9635e-04\n",
      "Epoch 294/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7716 - bpp: 0.7665 - mse: 2.4537e-04\n",
      "Epoch 294: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 1.7716 - bpp: 0.7665 - mse: 2.4537e-04\n",
      "Epoch 295/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6631 - bpp: 0.7513 - mse: 2.2261e-04\n",
      "Epoch 295: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6631 - bpp: 0.7513 - mse: 2.2261e-04\n",
      "Epoch 296/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7423 - bpp: 0.7606 - mse: 2.3967e-04\n",
      "Epoch 296: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7423 - bpp: 0.7606 - mse: 2.3967e-04\n",
      "Epoch 297/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7719 - bpp: 0.7526 - mse: 2.4885e-04\n",
      "Epoch 297: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.7719 - bpp: 0.7526 - mse: 2.4885e-04\n",
      "Epoch 298/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7483 - bpp: 0.7346 - mse: 2.4750e-04\n",
      "Epoch 298: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7483 - bpp: 0.7346 - mse: 2.4750e-04\n",
      "Epoch 299/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7441 - bpp: 0.7578 - mse: 2.4080e-04\n",
      "Epoch 299: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.7441 - bpp: 0.7578 - mse: 2.4080e-04\n",
      "Epoch 300/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6884 - bpp: 0.7550 - mse: 2.2790e-04\n",
      "Epoch 300: loss did not improve from 1.58539\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6884 - bpp: 0.7550 - mse: 2.2790e-04\n",
      "Epoch 301/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5677 - bpp: 0.7319 - mse: 2.0406e-04\n",
      "Epoch 301: loss improved from 1.58539 to 1.56775, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5677 - bpp: 0.7319 - mse: 2.0406e-04\n",
      "Epoch 302/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8013 - bpp: 0.7606 - mse: 2.5409e-04\n",
      "Epoch 302: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8013 - bpp: 0.7606 - mse: 2.5409e-04\n",
      "Epoch 303/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6613 - bpp: 0.7440 - mse: 2.2395e-04\n",
      "Epoch 303: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6613 - bpp: 0.7440 - mse: 2.2395e-04\n",
      "Epoch 304/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7081 - bpp: 0.7523 - mse: 2.3334e-04\n",
      "Epoch 304: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.7081 - bpp: 0.7523 - mse: 2.3334e-04\n",
      "Epoch 305/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6238 - bpp: 0.7377 - mse: 2.1631e-04\n",
      "Epoch 305: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6238 - bpp: 0.7377 - mse: 2.1631e-04\n",
      "Epoch 306/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7686 - bpp: 0.7506 - mse: 2.4853e-04\n",
      "Epoch 306: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7686 - bpp: 0.7506 - mse: 2.4853e-04\n",
      "Epoch 307/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8305 - bpp: 0.7561 - mse: 2.6231e-04\n",
      "Epoch 307: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.8305 - bpp: 0.7561 - mse: 2.6231e-04\n",
      "Epoch 308/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6793 - bpp: 0.7516 - mse: 2.2649e-04\n",
      "Epoch 308: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6793 - bpp: 0.7516 - mse: 2.2649e-04\n",
      "Epoch 309/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8681 - bpp: 0.7796 - mse: 2.6573e-04\n",
      "Epoch 309: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8681 - bpp: 0.7796 - mse: 2.6573e-04\n",
      "Epoch 310/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6457 - bpp: 0.7461 - mse: 2.1964e-04\n",
      "Epoch 310: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.6457 - bpp: 0.7461 - mse: 2.1964e-04\n",
      "Epoch 311/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7751 - bpp: 0.7537 - mse: 2.4935e-04\n",
      "Epoch 311: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7751 - bpp: 0.7537 - mse: 2.4935e-04\n",
      "Epoch 312/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6892 - bpp: 0.7454 - mse: 2.3044e-04\n",
      "Epoch 312: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6892 - bpp: 0.7454 - mse: 2.3044e-04\n",
      "Epoch 313/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6299 - bpp: 0.7263 - mse: 2.2059e-04\n",
      "Epoch 313: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6299 - bpp: 0.7263 - mse: 2.2059e-04\n",
      "Epoch 314/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7680 - bpp: 0.7596 - mse: 2.4619e-04\n",
      "Epoch 314: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7680 - bpp: 0.7596 - mse: 2.4619e-04\n",
      "Epoch 315/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7620 - bpp: 0.7571 - mse: 2.4536e-04\n",
      "Epoch 315: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.7620 - bpp: 0.7571 - mse: 2.4536e-04\n",
      "Epoch 316/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8336 - bpp: 0.7684 - mse: 2.6006e-04\n",
      "Epoch 316: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8336 - bpp: 0.7684 - mse: 2.6006e-04\n",
      "Epoch 317/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6425 - bpp: 0.7468 - mse: 2.1869e-04\n",
      "Epoch 317: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6425 - bpp: 0.7468 - mse: 2.1869e-04\n",
      "Epoch 318/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8574 - bpp: 0.7815 - mse: 2.6267e-04\n",
      "Epoch 318: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.8574 - bpp: 0.7815 - mse: 2.6267e-04\n",
      "Epoch 319/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5864 - bpp: 0.7308 - mse: 2.0888e-04\n",
      "Epoch 319: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5864 - bpp: 0.7308 - mse: 2.0888e-04\n",
      "Epoch 320/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6059 - bpp: 0.7379 - mse: 2.1192e-04\n",
      "Epoch 320: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6059 - bpp: 0.7379 - mse: 2.1192e-04\n",
      "Epoch 321/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8174 - bpp: 0.7631 - mse: 2.5738e-04\n",
      "Epoch 321: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 1.8174 - bpp: 0.7631 - mse: 2.5738e-04\n",
      "Epoch 322/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6757 - bpp: 0.7533 - mse: 2.2520e-04\n",
      "Epoch 322: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6757 - bpp: 0.7533 - mse: 2.2520e-04\n",
      "Epoch 323/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7363 - bpp: 0.7442 - mse: 2.4223e-04\n",
      "Epoch 323: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.7363 - bpp: 0.7442 - mse: 2.4223e-04\n",
      "Epoch 324/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6983 - bpp: 0.7505 - mse: 2.3139e-04\n",
      "Epoch 324: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6983 - bpp: 0.7505 - mse: 2.3139e-04\n",
      "Epoch 325/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5816 - bpp: 0.7330 - mse: 2.0719e-04\n",
      "Epoch 325: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.5816 - bpp: 0.7330 - mse: 2.0719e-04\n",
      "Epoch 326/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7722 - bpp: 0.7432 - mse: 2.5123e-04\n",
      "Epoch 326: loss did not improve from 1.56775\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.7722 - bpp: 0.7432 - mse: 2.5123e-04\n",
      "Epoch 327/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5562 - bpp: 0.7165 - mse: 2.0500e-04\n",
      "Epoch 327: loss improved from 1.56775 to 1.55616, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.5562 - bpp: 0.7165 - mse: 2.0500e-04\n",
      "Epoch 328/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6473 - bpp: 0.7409 - mse: 2.2130e-04\n",
      "Epoch 328: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6473 - bpp: 0.7409 - mse: 2.2130e-04\n",
      "Epoch 329/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6495 - bpp: 0.7420 - mse: 2.2155e-04\n",
      "Epoch 329: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6495 - bpp: 0.7420 - mse: 2.2155e-04\n",
      "Epoch 330/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6033 - bpp: 0.7331 - mse: 2.1244e-04\n",
      "Epoch 330: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6033 - bpp: 0.7331 - mse: 2.1244e-04\n",
      "Epoch 331/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6144 - bpp: 0.7376 - mse: 2.1406e-04\n",
      "Epoch 331: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6144 - bpp: 0.7376 - mse: 2.1406e-04\n",
      "Epoch 332/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7662 - bpp: 0.7532 - mse: 2.4731e-04\n",
      "Epoch 332: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7662 - bpp: 0.7532 - mse: 2.4731e-04\n",
      "Epoch 333/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8670 - bpp: 0.7767 - mse: 2.6618e-04\n",
      "Epoch 333: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.8670 - bpp: 0.7767 - mse: 2.6618e-04\n",
      "Epoch 334/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7418 - bpp: 0.7646 - mse: 2.3859e-04\n",
      "Epoch 334: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.7418 - bpp: 0.7646 - mse: 2.3859e-04\n",
      "Epoch 335/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6370 - bpp: 0.7394 - mse: 2.1914e-04\n",
      "Epoch 335: loss did not improve from 1.55616\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6370 - bpp: 0.7394 - mse: 2.1914e-04\n",
      "Epoch 336/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5164 - bpp: 0.7237 - mse: 1.9355e-04\n",
      "Epoch 336: loss improved from 1.55616 to 1.51642, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5164 - bpp: 0.7237 - mse: 1.9355e-04\n",
      "Epoch 337/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6451 - bpp: 0.7486 - mse: 2.1887e-04\n",
      "Epoch 337: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6451 - bpp: 0.7486 - mse: 2.1887e-04\n",
      "Epoch 338/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5271 - bpp: 0.7238 - mse: 1.9612e-04\n",
      "Epoch 338: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.5271 - bpp: 0.7238 - mse: 1.9612e-04\n",
      "Epoch 339/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8862 - bpp: 0.7536 - mse: 2.7649e-04\n",
      "Epoch 339: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.8862 - bpp: 0.7536 - mse: 2.7649e-04\n",
      "Epoch 340/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0016 - bpp: 0.7713 - mse: 3.0038e-04\n",
      "Epoch 340: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0016 - bpp: 0.7713 - mse: 3.0038e-04\n",
      "Epoch 341/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7836 - bpp: 0.7650 - mse: 2.4867e-04\n",
      "Epoch 341: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7836 - bpp: 0.7650 - mse: 2.4867e-04\n",
      "Epoch 342/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6431 - bpp: 0.7340 - mse: 2.2197e-04\n",
      "Epoch 342: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6431 - bpp: 0.7340 - mse: 2.2197e-04\n",
      "Epoch 343/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5338 - bpp: 0.7108 - mse: 2.0093e-04\n",
      "Epoch 343: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.5338 - bpp: 0.7108 - mse: 2.0093e-04\n",
      "Epoch 344/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5312 - bpp: 0.7224 - mse: 1.9748e-04\n",
      "Epoch 344: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5312 - bpp: 0.7224 - mse: 1.9748e-04\n",
      "Epoch 345/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6467 - bpp: 0.7353 - mse: 2.2251e-04\n",
      "Epoch 345: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6467 - bpp: 0.7353 - mse: 2.2251e-04\n",
      "Epoch 346/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6429 - bpp: 0.7318 - mse: 2.2245e-04\n",
      "Epoch 346: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6429 - bpp: 0.7318 - mse: 2.2245e-04\n",
      "Epoch 347/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6323 - bpp: 0.7267 - mse: 2.2108e-04\n",
      "Epoch 347: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.6323 - bpp: 0.7267 - mse: 2.2108e-04\n",
      "Epoch 348/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7431 - bpp: 0.7603 - mse: 2.3995e-04\n",
      "Epoch 348: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7431 - bpp: 0.7603 - mse: 2.3995e-04\n",
      "Epoch 349/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8477 - bpp: 0.7708 - mse: 2.6292e-04\n",
      "Epoch 349: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8477 - bpp: 0.7708 - mse: 2.6292e-04\n",
      "Epoch 350/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7528 - bpp: 0.7545 - mse: 2.4373e-04\n",
      "Epoch 350: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7528 - bpp: 0.7545 - mse: 2.4373e-04\n",
      "Epoch 351/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5185 - bpp: 0.7225 - mse: 1.9432e-04\n",
      "Epoch 351: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5185 - bpp: 0.7225 - mse: 1.9432e-04\n",
      "Epoch 352/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5583 - bpp: 0.7178 - mse: 2.0521e-04\n",
      "Epoch 352: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.5583 - bpp: 0.7178 - mse: 2.0521e-04\n",
      "Epoch 353/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7695 - bpp: 0.7456 - mse: 2.4998e-04\n",
      "Epoch 353: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.7695 - bpp: 0.7456 - mse: 2.4998e-04\n",
      "Epoch 354/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8216 - bpp: 0.7748 - mse: 2.5557e-04\n",
      "Epoch 354: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.8216 - bpp: 0.7748 - mse: 2.5557e-04\n",
      "Epoch 355/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6285 - bpp: 0.7274 - mse: 2.1999e-04\n",
      "Epoch 355: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6285 - bpp: 0.7274 - mse: 2.1999e-04\n",
      "Epoch 356/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6023 - bpp: 0.7344 - mse: 2.1190e-04\n",
      "Epoch 356: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.6023 - bpp: 0.7344 - mse: 2.1190e-04\n",
      "Epoch 357/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6466 - bpp: 0.7426 - mse: 2.2069e-04\n",
      "Epoch 357: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6466 - bpp: 0.7426 - mse: 2.2069e-04\n",
      "Epoch 358/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6594 - bpp: 0.7425 - mse: 2.2386e-04\n",
      "Epoch 358: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6594 - bpp: 0.7425 - mse: 2.2386e-04\n",
      "Epoch 359/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5820 - bpp: 0.7285 - mse: 2.0839e-04\n",
      "Epoch 359: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5820 - bpp: 0.7285 - mse: 2.0839e-04\n",
      "Epoch 360/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5450 - bpp: 0.7180 - mse: 2.0191e-04\n",
      "Epoch 360: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.5450 - bpp: 0.7180 - mse: 2.0191e-04\n",
      "Epoch 361/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6766 - bpp: 0.7385 - mse: 2.2903e-04\n",
      "Epoch 361: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6766 - bpp: 0.7385 - mse: 2.2903e-04\n",
      "Epoch 362/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6716 - bpp: 0.7191 - mse: 2.3254e-04\n",
      "Epoch 362: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6716 - bpp: 0.7191 - mse: 2.3254e-04\n",
      "Epoch 363/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8342 - bpp: 0.7487 - mse: 2.6503e-04\n",
      "Epoch 363: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.8342 - bpp: 0.7487 - mse: 2.6503e-04\n",
      "Epoch 364/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5909 - bpp: 0.7332 - mse: 2.0941e-04\n",
      "Epoch 364: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.5909 - bpp: 0.7332 - mse: 2.0941e-04\n",
      "Epoch 365/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6325 - bpp: 0.7358 - mse: 2.1892e-04\n",
      "Epoch 365: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.6325 - bpp: 0.7358 - mse: 2.1892e-04\n",
      "Epoch 366/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7630 - bpp: 0.7615 - mse: 2.4452e-04\n",
      "Epoch 366: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7630 - bpp: 0.7615 - mse: 2.4452e-04\n",
      "Epoch 367/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6588 - bpp: 0.7566 - mse: 2.2027e-04\n",
      "Epoch 367: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6588 - bpp: 0.7566 - mse: 2.2027e-04\n",
      "Epoch 368/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5302 - bpp: 0.7148 - mse: 1.9907e-04\n",
      "Epoch 368: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.5302 - bpp: 0.7148 - mse: 1.9907e-04\n",
      "Epoch 369/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5963 - bpp: 0.7445 - mse: 2.0796e-04\n",
      "Epoch 369: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5963 - bpp: 0.7445 - mse: 2.0796e-04\n",
      "Epoch 370/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5664 - bpp: 0.7275 - mse: 2.0480e-04\n",
      "Epoch 370: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5664 - bpp: 0.7275 - mse: 2.0480e-04\n",
      "Epoch 371/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7395 - bpp: 0.7578 - mse: 2.3967e-04\n",
      "Epoch 371: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7395 - bpp: 0.7578 - mse: 2.3967e-04\n",
      "Epoch 372/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5379 - bpp: 0.7203 - mse: 1.9963e-04\n",
      "Epoch 372: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5379 - bpp: 0.7203 - mse: 1.9963e-04\n",
      "Epoch 373/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5428 - bpp: 0.7246 - mse: 1.9977e-04\n",
      "Epoch 373: loss did not improve from 1.51642\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5428 - bpp: 0.7246 - mse: 1.9977e-04\n",
      "Epoch 374/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4403 - bpp: 0.7037 - mse: 1.7982e-04\n",
      "Epoch 374: loss improved from 1.51642 to 1.44026, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4403 - bpp: 0.7037 - mse: 1.7982e-04\n",
      "Epoch 375/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6858 - bpp: 0.7538 - mse: 2.2753e-04\n",
      "Epoch 375: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6858 - bpp: 0.7538 - mse: 2.2753e-04\n",
      "Epoch 376/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8036 - bpp: 0.7399 - mse: 2.5969e-04\n",
      "Epoch 376: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.8036 - bpp: 0.7399 - mse: 2.5969e-04\n",
      "Epoch 377/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5874 - bpp: 0.7254 - mse: 2.1045e-04\n",
      "Epoch 377: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5874 - bpp: 0.7254 - mse: 2.1045e-04\n",
      "Epoch 378/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5130 - bpp: 0.7164 - mse: 1.9449e-04\n",
      "Epoch 378: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5130 - bpp: 0.7164 - mse: 1.9449e-04\n",
      "Epoch 379/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6924 - bpp: 0.7575 - mse: 2.2825e-04\n",
      "Epoch 379: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6924 - bpp: 0.7575 - mse: 2.2825e-04\n",
      "Epoch 380/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4818 - bpp: 0.7025 - mse: 1.9025e-04\n",
      "Epoch 380: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.4818 - bpp: 0.7025 - mse: 1.9025e-04\n",
      "Epoch 381/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5342 - bpp: 0.7215 - mse: 1.9839e-04\n",
      "Epoch 381: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.5342 - bpp: 0.7215 - mse: 1.9839e-04\n",
      "Epoch 382/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7900 - bpp: 0.7630 - mse: 2.5074e-04\n",
      "Epoch 382: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.7900 - bpp: 0.7630 - mse: 2.5074e-04\n",
      "Epoch 383/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8966 - bpp: 0.7543 - mse: 2.7888e-04\n",
      "Epoch 383: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.8966 - bpp: 0.7543 - mse: 2.7888e-04\n",
      "Epoch 384/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7065 - bpp: 0.7569 - mse: 2.3185e-04\n",
      "Epoch 384: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.7065 - bpp: 0.7569 - mse: 2.3185e-04\n",
      "Epoch 385/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6112 - bpp: 0.7184 - mse: 2.1797e-04\n",
      "Epoch 385: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6112 - bpp: 0.7184 - mse: 2.1797e-04\n",
      "Epoch 386/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7117 - bpp: 0.7470 - mse: 2.3551e-04\n",
      "Epoch 386: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.7117 - bpp: 0.7470 - mse: 2.3551e-04\n",
      "Epoch 387/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5918 - bpp: 0.7331 - mse: 2.0964e-04\n",
      "Epoch 387: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5918 - bpp: 0.7331 - mse: 2.0964e-04\n",
      "Epoch 388/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5159 - bpp: 0.7238 - mse: 1.9338e-04\n",
      "Epoch 388: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5159 - bpp: 0.7238 - mse: 1.9338e-04\n",
      "Epoch 389/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5822 - bpp: 0.7310 - mse: 2.0782e-04\n",
      "Epoch 389: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5822 - bpp: 0.7310 - mse: 2.0782e-04\n",
      "Epoch 390/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7178 - bpp: 0.7601 - mse: 2.3382e-04\n",
      "Epoch 390: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7178 - bpp: 0.7601 - mse: 2.3382e-04\n",
      "Epoch 391/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5555 - bpp: 0.7251 - mse: 2.0273e-04\n",
      "Epoch 391: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5555 - bpp: 0.7251 - mse: 2.0273e-04\n",
      "Epoch 392/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6444 - bpp: 0.7337 - mse: 2.2234e-04\n",
      "Epoch 392: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6444 - bpp: 0.7337 - mse: 2.2234e-04\n",
      "Epoch 393/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6333 - bpp: 0.7313 - mse: 2.2021e-04\n",
      "Epoch 393: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6333 - bpp: 0.7313 - mse: 2.2021e-04\n",
      "Epoch 394/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6871 - bpp: 0.7349 - mse: 2.3248e-04\n",
      "Epoch 394: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6871 - bpp: 0.7349 - mse: 2.3248e-04\n",
      "Epoch 395/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5086 - bpp: 0.7156 - mse: 1.9361e-04\n",
      "Epoch 395: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.5086 - bpp: 0.7156 - mse: 1.9361e-04\n",
      "Epoch 396/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7590 - bpp: 0.7570 - mse: 2.4461e-04\n",
      "Epoch 396: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.7590 - bpp: 0.7570 - mse: 2.4461e-04\n",
      "Epoch 397/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6061 - bpp: 0.7334 - mse: 2.1305e-04\n",
      "Epoch 397: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.6061 - bpp: 0.7334 - mse: 2.1305e-04\n",
      "Epoch 398/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7739 - bpp: 0.7614 - mse: 2.4720e-04\n",
      "Epoch 398: loss did not improve from 1.44026\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7739 - bpp: 0.7614 - mse: 2.4720e-04\n",
      "Epoch 399/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3990 - bpp: 0.6964 - mse: 1.7154e-04\n",
      "Epoch 399: loss improved from 1.44026 to 1.39904, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.3990 - bpp: 0.6964 - mse: 1.7154e-04\n",
      "Epoch 400/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7259 - bpp: 0.7518 - mse: 2.3781e-04\n",
      "Epoch 400: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 1.7259 - bpp: 0.7518 - mse: 2.3781e-04\n",
      "Epoch 401/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5542 - bpp: 0.7189 - mse: 2.0393e-04\n",
      "Epoch 401: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5542 - bpp: 0.7189 - mse: 2.0393e-04\n",
      "Epoch 402/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6117 - bpp: 0.7316 - mse: 2.1485e-04\n",
      "Epoch 402: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6117 - bpp: 0.7316 - mse: 2.1485e-04\n",
      "Epoch 403/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5714 - bpp: 0.7324 - mse: 2.0483e-04\n",
      "Epoch 403: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5714 - bpp: 0.7324 - mse: 2.0483e-04\n",
      "Epoch 404/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6577 - bpp: 0.7473 - mse: 2.2228e-04\n",
      "Epoch 404: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6577 - bpp: 0.7473 - mse: 2.2228e-04\n",
      "Epoch 405/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4674 - bpp: 0.7058 - mse: 1.8596e-04\n",
      "Epoch 405: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4674 - bpp: 0.7058 - mse: 1.8596e-04\n",
      "Epoch 406/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7209 - bpp: 0.7377 - mse: 2.4003e-04\n",
      "Epoch 406: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.7209 - bpp: 0.7377 - mse: 2.4003e-04\n",
      "Epoch 407/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5554 - bpp: 0.7260 - mse: 2.0248e-04\n",
      "Epoch 407: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5554 - bpp: 0.7260 - mse: 2.0248e-04\n",
      "Epoch 408/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6055 - bpp: 0.7313 - mse: 2.1342e-04\n",
      "Epoch 408: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.6055 - bpp: 0.7313 - mse: 2.1342e-04\n",
      "Epoch 409/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5147 - bpp: 0.7221 - mse: 1.9350e-04\n",
      "Epoch 409: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5147 - bpp: 0.7221 - mse: 1.9350e-04\n",
      "Epoch 410/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6309 - bpp: 0.7354 - mse: 2.1861e-04\n",
      "Epoch 410: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.6309 - bpp: 0.7354 - mse: 2.1861e-04\n",
      "Epoch 411/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5709 - bpp: 0.7331 - mse: 2.0452e-04\n",
      "Epoch 411: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.5709 - bpp: 0.7331 - mse: 2.0452e-04\n",
      "Epoch 412/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6178 - bpp: 0.7355 - mse: 2.1540e-04\n",
      "Epoch 412: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6178 - bpp: 0.7355 - mse: 2.1540e-04\n",
      "Epoch 413/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6091 - bpp: 0.7349 - mse: 2.1342e-04\n",
      "Epoch 413: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6091 - bpp: 0.7349 - mse: 2.1342e-04\n",
      "Epoch 414/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7032 - bpp: 0.7621 - mse: 2.2977e-04\n",
      "Epoch 414: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.7032 - bpp: 0.7621 - mse: 2.2977e-04\n",
      "Epoch 415/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6360 - bpp: 0.7367 - mse: 2.1955e-04\n",
      "Epoch 415: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6360 - bpp: 0.7367 - mse: 2.1955e-04\n",
      "Epoch 416/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5535 - bpp: 0.7334 - mse: 2.0022e-04\n",
      "Epoch 416: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5535 - bpp: 0.7334 - mse: 2.0022e-04\n",
      "Epoch 417/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7539 - bpp: 0.7497 - mse: 2.4516e-04\n",
      "Epoch 417: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.7539 - bpp: 0.7497 - mse: 2.4516e-04\n",
      "Epoch 418/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5636 - bpp: 0.7177 - mse: 2.0652e-04\n",
      "Epoch 418: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.5636 - bpp: 0.7177 - mse: 2.0652e-04\n",
      "Epoch 419/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4725 - bpp: 0.7059 - mse: 1.8716e-04\n",
      "Epoch 419: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4725 - bpp: 0.7059 - mse: 1.8716e-04\n",
      "Epoch 420/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4872 - bpp: 0.7156 - mse: 1.8837e-04\n",
      "Epoch 420: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.4872 - bpp: 0.7156 - mse: 1.8837e-04\n",
      "Epoch 421/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5799 - bpp: 0.7244 - mse: 2.0885e-04\n",
      "Epoch 421: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5799 - bpp: 0.7244 - mse: 2.0885e-04\n",
      "Epoch 422/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4277 - bpp: 0.7109 - mse: 1.7500e-04\n",
      "Epoch 422: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.4277 - bpp: 0.7109 - mse: 1.7500e-04\n",
      "Epoch 423/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4914 - bpp: 0.7168 - mse: 1.8911e-04\n",
      "Epoch 423: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.4914 - bpp: 0.7168 - mse: 1.8911e-04\n",
      "Epoch 424/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6737 - bpp: 0.7526 - mse: 2.2488e-04\n",
      "Epoch 424: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.6737 - bpp: 0.7526 - mse: 2.2488e-04\n",
      "Epoch 425/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4856 - bpp: 0.7104 - mse: 1.8926e-04\n",
      "Epoch 425: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.4856 - bpp: 0.7104 - mse: 1.8926e-04\n",
      "Epoch 426/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.7445 - mse: 2.2895e-04\n",
      "Epoch 426: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6823 - bpp: 0.7445 - mse: 2.2895e-04\n",
      "Epoch 427/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5897 - bpp: 0.7333 - mse: 2.0910e-04\n",
      "Epoch 427: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5897 - bpp: 0.7333 - mse: 2.0910e-04\n",
      "Epoch 428/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4786 - bpp: 0.7094 - mse: 1.8778e-04\n",
      "Epoch 428: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4786 - bpp: 0.7094 - mse: 1.8778e-04\n",
      "Epoch 429/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4548 - bpp: 0.7039 - mse: 1.8331e-04\n",
      "Epoch 429: loss did not improve from 1.39904\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.4548 - bpp: 0.7039 - mse: 1.8331e-04\n",
      "Epoch 430/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3898 - bpp: 0.6892 - mse: 1.7104e-04\n",
      "Epoch 430: loss improved from 1.39904 to 1.38975, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.3898 - bpp: 0.6892 - mse: 1.7104e-04\n",
      "Epoch 431/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5472 - bpp: 0.7237 - mse: 2.0107e-04\n",
      "Epoch 431: loss did not improve from 1.38975\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5472 - bpp: 0.7237 - mse: 2.0107e-04\n",
      "Epoch 432/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6106 - bpp: 0.7279 - mse: 2.1549e-04\n",
      "Epoch 432: loss did not improve from 1.38975\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6106 - bpp: 0.7279 - mse: 2.1549e-04\n",
      "Epoch 433/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4628 - bpp: 0.7002 - mse: 1.8618e-04\n",
      "Epoch 433: loss did not improve from 1.38975\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4628 - bpp: 0.7002 - mse: 1.8618e-04\n",
      "Epoch 434/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4610 - bpp: 0.7165 - mse: 1.8176e-04\n",
      "Epoch 434: loss did not improve from 1.38975\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4610 - bpp: 0.7165 - mse: 1.8176e-04\n",
      "Epoch 435/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5592 - bpp: 0.7223 - mse: 2.0432e-04\n",
      "Epoch 435: loss did not improve from 1.38975\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5592 - bpp: 0.7223 - mse: 2.0432e-04\n",
      "Epoch 436/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5428 - bpp: 0.7234 - mse: 2.0006e-04\n",
      "Epoch 436: loss did not improve from 1.38975\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.5428 - bpp: 0.7234 - mse: 2.0006e-04\n",
      "Epoch 437/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3567 - bpp: 0.6844 - mse: 1.6416e-04\n",
      "Epoch 437: loss improved from 1.38975 to 1.35674, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.3567 - bpp: 0.6844 - mse: 1.6416e-04\n",
      "Epoch 438/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5588 - bpp: 0.7328 - mse: 2.0164e-04\n",
      "Epoch 438: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.5588 - bpp: 0.7328 - mse: 2.0164e-04\n",
      "Epoch 439/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5146 - bpp: 0.7238 - mse: 1.9308e-04\n",
      "Epoch 439: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5146 - bpp: 0.7238 - mse: 1.9308e-04\n",
      "Epoch 440/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5308 - bpp: 0.7264 - mse: 1.9640e-04\n",
      "Epoch 440: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5308 - bpp: 0.7264 - mse: 1.9640e-04\n",
      "Epoch 441/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5435 - bpp: 0.7129 - mse: 2.0279e-04\n",
      "Epoch 441: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5435 - bpp: 0.7129 - mse: 2.0279e-04\n",
      "Epoch 442/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6822 - bpp: 0.7195 - mse: 2.3502e-04\n",
      "Epoch 442: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6822 - bpp: 0.7195 - mse: 2.3502e-04\n",
      "Epoch 443/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5935 - bpp: 0.7387 - mse: 2.0870e-04\n",
      "Epoch 443: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.5935 - bpp: 0.7387 - mse: 2.0870e-04\n",
      "Epoch 444/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5701 - bpp: 0.7185 - mse: 2.0790e-04\n",
      "Epoch 444: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5701 - bpp: 0.7185 - mse: 2.0790e-04\n",
      "Epoch 445/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6405 - bpp: 0.7401 - mse: 2.1984e-04\n",
      "Epoch 445: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6405 - bpp: 0.7401 - mse: 2.1984e-04\n",
      "Epoch 446/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6490 - bpp: 0.7418 - mse: 2.2147e-04\n",
      "Epoch 446: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6490 - bpp: 0.7418 - mse: 2.2147e-04\n",
      "Epoch 447/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6634 - bpp: 0.7564 - mse: 2.2143e-04\n",
      "Epoch 447: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6634 - bpp: 0.7564 - mse: 2.2143e-04\n",
      "Epoch 448/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5422 - bpp: 0.7216 - mse: 2.0036e-04\n",
      "Epoch 448: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5422 - bpp: 0.7216 - mse: 2.0036e-04\n",
      "Epoch 449/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5102 - bpp: 0.7149 - mse: 1.9417e-04\n",
      "Epoch 449: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5102 - bpp: 0.7149 - mse: 1.9417e-04\n",
      "Epoch 450/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6219 - bpp: 0.7263 - mse: 2.1867e-04\n",
      "Epoch 450: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6219 - bpp: 0.7263 - mse: 2.1867e-04\n",
      "Epoch 451/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5761 - bpp: 0.7298 - mse: 2.0661e-04\n",
      "Epoch 451: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5761 - bpp: 0.7298 - mse: 2.0661e-04\n",
      "Epoch 452/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4893 - bpp: 0.7213 - mse: 1.8750e-04\n",
      "Epoch 452: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4893 - bpp: 0.7213 - mse: 1.8750e-04\n",
      "Epoch 453/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6605 - bpp: 0.7368 - mse: 2.2551e-04\n",
      "Epoch 453: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6605 - bpp: 0.7368 - mse: 2.2551e-04\n",
      "Epoch 454/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3761 - bpp: 0.6942 - mse: 1.6649e-04\n",
      "Epoch 454: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.3761 - bpp: 0.6942 - mse: 1.6649e-04\n",
      "Epoch 455/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5340 - bpp: 0.7233 - mse: 1.9793e-04\n",
      "Epoch 455: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5340 - bpp: 0.7233 - mse: 1.9793e-04\n",
      "Epoch 456/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5728 - bpp: 0.7378 - mse: 2.0384e-04\n",
      "Epoch 456: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5728 - bpp: 0.7378 - mse: 2.0384e-04\n",
      "Epoch 457/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4936 - bpp: 0.7114 - mse: 1.9096e-04\n",
      "Epoch 457: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.4936 - bpp: 0.7114 - mse: 1.9096e-04\n",
      "Epoch 458/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5107 - bpp: 0.7160 - mse: 1.9401e-04\n",
      "Epoch 458: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5107 - bpp: 0.7160 - mse: 1.9401e-04\n",
      "Epoch 459/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4497 - bpp: 0.7047 - mse: 1.8188e-04\n",
      "Epoch 459: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.4497 - bpp: 0.7047 - mse: 1.8188e-04\n",
      "Epoch 460/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5273 - bpp: 0.7276 - mse: 1.9525e-04\n",
      "Epoch 460: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5273 - bpp: 0.7276 - mse: 1.9525e-04\n",
      "Epoch 461/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4163 - bpp: 0.6890 - mse: 1.7755e-04\n",
      "Epoch 461: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4163 - bpp: 0.6890 - mse: 1.7755e-04\n",
      "Epoch 462/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5501 - bpp: 0.7284 - mse: 2.0060e-04\n",
      "Epoch 462: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5501 - bpp: 0.7284 - mse: 2.0060e-04\n",
      "Epoch 463/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5459 - bpp: 0.7111 - mse: 2.0379e-04\n",
      "Epoch 463: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.5459 - bpp: 0.7111 - mse: 2.0379e-04\n",
      "Epoch 464/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5091 - bpp: 0.7141 - mse: 1.9408e-04\n",
      "Epoch 464: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5091 - bpp: 0.7141 - mse: 1.9408e-04\n",
      "Epoch 465/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5308 - bpp: 0.7217 - mse: 1.9752e-04\n",
      "Epoch 465: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5308 - bpp: 0.7217 - mse: 1.9752e-04\n",
      "Epoch 466/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6109 - bpp: 0.7363 - mse: 2.1353e-04\n",
      "Epoch 466: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6109 - bpp: 0.7363 - mse: 2.1353e-04\n",
      "Epoch 467/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5893 - bpp: 0.7244 - mse: 2.1115e-04\n",
      "Epoch 467: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.5893 - bpp: 0.7244 - mse: 2.1115e-04\n",
      "Epoch 468/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6292 - bpp: 0.7358 - mse: 2.1812e-04\n",
      "Epoch 468: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6292 - bpp: 0.7358 - mse: 2.1812e-04\n",
      "Epoch 469/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4599 - bpp: 0.7125 - mse: 1.8247e-04\n",
      "Epoch 469: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.4599 - bpp: 0.7125 - mse: 1.8247e-04\n",
      "Epoch 470/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5198 - bpp: 0.7226 - mse: 1.9463e-04\n",
      "Epoch 470: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5198 - bpp: 0.7226 - mse: 1.9463e-04\n",
      "Epoch 471/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4836 - bpp: 0.7078 - mse: 1.8940e-04\n",
      "Epoch 471: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.4836 - bpp: 0.7078 - mse: 1.8940e-04\n",
      "Epoch 472/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5818 - bpp: 0.7375 - mse: 2.0613e-04\n",
      "Epoch 472: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5818 - bpp: 0.7375 - mse: 2.0613e-04\n",
      "Epoch 473/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7328 - bpp: 0.7464 - mse: 2.4081e-04\n",
      "Epoch 473: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.7328 - bpp: 0.7464 - mse: 2.4081e-04\n",
      "Epoch 474/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4746 - bpp: 0.7158 - mse: 1.8526e-04\n",
      "Epoch 474: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4746 - bpp: 0.7158 - mse: 1.8526e-04\n",
      "Epoch 475/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5830 - bpp: 0.7299 - mse: 2.0828e-04\n",
      "Epoch 475: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5830 - bpp: 0.7299 - mse: 2.0828e-04\n",
      "Epoch 476/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3592 - bpp: 0.6892 - mse: 1.6359e-04\n",
      "Epoch 476: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.3592 - bpp: 0.6892 - mse: 1.6359e-04\n",
      "Epoch 477/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4313 - bpp: 0.6986 - mse: 1.7890e-04\n",
      "Epoch 477: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4313 - bpp: 0.6986 - mse: 1.7890e-04\n",
      "Epoch 478/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5212 - bpp: 0.7116 - mse: 1.9767e-04\n",
      "Epoch 478: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5212 - bpp: 0.7116 - mse: 1.9767e-04\n",
      "Epoch 479/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5726 - bpp: 0.7366 - mse: 2.0409e-04\n",
      "Epoch 479: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5726 - bpp: 0.7366 - mse: 2.0409e-04\n",
      "Epoch 480/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4563 - bpp: 0.7171 - mse: 1.8046e-04\n",
      "Epoch 480: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4563 - bpp: 0.7171 - mse: 1.8046e-04\n",
      "Epoch 481/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4879 - bpp: 0.7017 - mse: 1.9194e-04\n",
      "Epoch 481: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4879 - bpp: 0.7017 - mse: 1.9194e-04\n",
      "Epoch 482/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4954 - bpp: 0.7118 - mse: 1.9130e-04\n",
      "Epoch 482: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 1.4954 - bpp: 0.7118 - mse: 1.9130e-04\n",
      "Epoch 483/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5632 - bpp: 0.7188 - mse: 2.0614e-04\n",
      "Epoch 483: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5632 - bpp: 0.7188 - mse: 2.0614e-04\n",
      "Epoch 484/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4845 - bpp: 0.7105 - mse: 1.8898e-04\n",
      "Epoch 484: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4845 - bpp: 0.7105 - mse: 1.8898e-04\n",
      "Epoch 485/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3847 - bpp: 0.6907 - mse: 1.6944e-04\n",
      "Epoch 485: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.3847 - bpp: 0.6907 - mse: 1.6944e-04\n",
      "Epoch 486/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5127 - bpp: 0.7250 - mse: 1.9231e-04\n",
      "Epoch 486: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5127 - bpp: 0.7250 - mse: 1.9231e-04\n",
      "Epoch 487/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6032 - bpp: 0.7374 - mse: 2.1137e-04\n",
      "Epoch 487: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.6032 - bpp: 0.7374 - mse: 2.1137e-04\n",
      "Epoch 488/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5838 - bpp: 0.7259 - mse: 2.0946e-04\n",
      "Epoch 488: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5838 - bpp: 0.7259 - mse: 2.0946e-04\n",
      "Epoch 489/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5659 - bpp: 0.7342 - mse: 2.0306e-04\n",
      "Epoch 489: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5659 - bpp: 0.7342 - mse: 2.0306e-04\n",
      "Epoch 490/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6277 - bpp: 0.7322 - mse: 2.1864e-04\n",
      "Epoch 490: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.6277 - bpp: 0.7322 - mse: 2.1864e-04\n",
      "Epoch 491/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5387 - bpp: 0.7276 - mse: 1.9801e-04\n",
      "Epoch 491: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.5387 - bpp: 0.7276 - mse: 1.9801e-04\n",
      "Epoch 492/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4965 - bpp: 0.7108 - mse: 1.9182e-04\n",
      "Epoch 492: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4965 - bpp: 0.7108 - mse: 1.9182e-04\n",
      "Epoch 493/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4251 - bpp: 0.7144 - mse: 1.7352e-04\n",
      "Epoch 493: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4251 - bpp: 0.7144 - mse: 1.7352e-04\n",
      "Epoch 494/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6151 - bpp: 0.7273 - mse: 2.1674e-04\n",
      "Epoch 494: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6151 - bpp: 0.7273 - mse: 2.1674e-04\n",
      "Epoch 495/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5782 - bpp: 0.7363 - mse: 2.0555e-04\n",
      "Epoch 495: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5782 - bpp: 0.7363 - mse: 2.0555e-04\n",
      "Epoch 496/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4599 - bpp: 0.7108 - mse: 1.8287e-04\n",
      "Epoch 496: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4599 - bpp: 0.7108 - mse: 1.8287e-04\n",
      "Epoch 497/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5037 - bpp: 0.7113 - mse: 1.9345e-04\n",
      "Epoch 497: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5037 - bpp: 0.7113 - mse: 1.9345e-04\n",
      "Epoch 498/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3913 - bpp: 0.6889 - mse: 1.7149e-04\n",
      "Epoch 498: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.3913 - bpp: 0.6889 - mse: 1.7149e-04\n",
      "Epoch 499/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3883 - bpp: 0.6989 - mse: 1.6830e-04\n",
      "Epoch 499: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.3883 - bpp: 0.6989 - mse: 1.6830e-04\n",
      "Epoch 500/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5339 - bpp: 0.7326 - mse: 1.9564e-04\n",
      "Epoch 500: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5339 - bpp: 0.7326 - mse: 1.9564e-04\n",
      "Epoch 501/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6682 - bpp: 0.7449 - mse: 2.2541e-04\n",
      "Epoch 501: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6682 - bpp: 0.7449 - mse: 2.2541e-04\n",
      "Epoch 502/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5894 - bpp: 0.7285 - mse: 2.1019e-04\n",
      "Epoch 502: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5894 - bpp: 0.7285 - mse: 2.1019e-04\n",
      "Epoch 503/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4584 - bpp: 0.7106 - mse: 1.8257e-04\n",
      "Epoch 503: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4584 - bpp: 0.7106 - mse: 1.8257e-04\n",
      "Epoch 504/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6435 - bpp: 0.7342 - mse: 2.2200e-04\n",
      "Epoch 504: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6435 - bpp: 0.7342 - mse: 2.2200e-04\n",
      "Epoch 505/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4293 - bpp: 0.7089 - mse: 1.7588e-04\n",
      "Epoch 505: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.4293 - bpp: 0.7089 - mse: 1.7588e-04\n",
      "Epoch 506/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6337 - bpp: 0.7315 - mse: 2.2027e-04\n",
      "Epoch 506: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.6337 - bpp: 0.7315 - mse: 2.2027e-04\n",
      "Epoch 507/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4206 - bpp: 0.7067 - mse: 1.7428e-04\n",
      "Epoch 507: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4206 - bpp: 0.7067 - mse: 1.7428e-04\n",
      "Epoch 508/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4449 - bpp: 0.7043 - mse: 1.8079e-04\n",
      "Epoch 508: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4449 - bpp: 0.7043 - mse: 1.8079e-04\n",
      "Epoch 509/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5233 - bpp: 0.7205 - mse: 1.9598e-04\n",
      "Epoch 509: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5233 - bpp: 0.7205 - mse: 1.9598e-04\n",
      "Epoch 510/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5403 - bpp: 0.7362 - mse: 1.9633e-04\n",
      "Epoch 510: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5403 - bpp: 0.7362 - mse: 1.9633e-04\n",
      "Epoch 511/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5435 - bpp: 0.7196 - mse: 2.0117e-04\n",
      "Epoch 511: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5435 - bpp: 0.7196 - mse: 2.0117e-04\n",
      "Epoch 512/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5159 - bpp: 0.7167 - mse: 1.9512e-04\n",
      "Epoch 512: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5159 - bpp: 0.7167 - mse: 1.9512e-04\n",
      "Epoch 513/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4134 - bpp: 0.6949 - mse: 1.7540e-04\n",
      "Epoch 513: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4134 - bpp: 0.6949 - mse: 1.7540e-04\n",
      "Epoch 514/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5233 - bpp: 0.7236 - mse: 1.9524e-04\n",
      "Epoch 514: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.5233 - bpp: 0.7236 - mse: 1.9524e-04\n",
      "Epoch 515/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4565 - bpp: 0.7070 - mse: 1.8299e-04\n",
      "Epoch 515: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.4565 - bpp: 0.7070 - mse: 1.8299e-04\n",
      "Epoch 516/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5410 - bpp: 0.7160 - mse: 2.0142e-04\n",
      "Epoch 516: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5410 - bpp: 0.7160 - mse: 2.0142e-04\n",
      "Epoch 517/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4156 - bpp: 0.6972 - mse: 1.7538e-04\n",
      "Epoch 517: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 1.4156 - bpp: 0.6972 - mse: 1.7538e-04\n",
      "Epoch 518/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5338 - bpp: 0.7241 - mse: 1.9767e-04\n",
      "Epoch 518: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5338 - bpp: 0.7241 - mse: 1.9767e-04\n",
      "Epoch 519/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5848 - bpp: 0.7359 - mse: 2.0724e-04\n",
      "Epoch 519: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.5848 - bpp: 0.7359 - mse: 2.0724e-04\n",
      "Epoch 520/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4756 - bpp: 0.7056 - mse: 1.8799e-04\n",
      "Epoch 520: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4756 - bpp: 0.7056 - mse: 1.8799e-04\n",
      "Epoch 521/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4471 - bpp: 0.6982 - mse: 1.8285e-04\n",
      "Epoch 521: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 1.4471 - bpp: 0.6982 - mse: 1.8285e-04\n",
      "Epoch 522/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6752 - bpp: 0.7553 - mse: 2.2457e-04\n",
      "Epoch 522: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6752 - bpp: 0.7553 - mse: 2.2457e-04\n",
      "Epoch 523/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6633 - bpp: 0.7430 - mse: 2.2468e-04\n",
      "Epoch 523: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.6633 - bpp: 0.7430 - mse: 2.2468e-04\n",
      "Epoch 524/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5284 - bpp: 0.7222 - mse: 1.9682e-04\n",
      "Epoch 524: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5284 - bpp: 0.7222 - mse: 1.9682e-04\n",
      "Epoch 525/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5409 - bpp: 0.7203 - mse: 2.0035e-04\n",
      "Epoch 525: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5409 - bpp: 0.7203 - mse: 2.0035e-04\n",
      "Epoch 526/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4918 - bpp: 0.7167 - mse: 1.8921e-04\n",
      "Epoch 526: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4918 - bpp: 0.7167 - mse: 1.8921e-04\n",
      "Epoch 527/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5052 - bpp: 0.7239 - mse: 1.9074e-04\n",
      "Epoch 527: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5052 - bpp: 0.7239 - mse: 1.9074e-04\n",
      "Epoch 528/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5461 - bpp: 0.7284 - mse: 1.9963e-04\n",
      "Epoch 528: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.5461 - bpp: 0.7284 - mse: 1.9963e-04\n",
      "Epoch 529/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3855 - bpp: 0.6927 - mse: 1.6916e-04\n",
      "Epoch 529: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.3855 - bpp: 0.6927 - mse: 1.6916e-04\n",
      "Epoch 530/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4341 - bpp: 0.7014 - mse: 1.7888e-04\n",
      "Epoch 530: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.4341 - bpp: 0.7014 - mse: 1.7888e-04\n",
      "Epoch 531/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4873 - bpp: 0.7122 - mse: 1.8924e-04\n",
      "Epoch 531: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4873 - bpp: 0.7122 - mse: 1.8924e-04\n",
      "Epoch 532/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5785 - bpp: 0.7320 - mse: 2.0667e-04\n",
      "Epoch 532: loss did not improve from 1.35674\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5785 - bpp: 0.7320 - mse: 2.0667e-04\n",
      "Epoch 533/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3374 - bpp: 0.6808 - mse: 1.6030e-04\n",
      "Epoch 533: loss improved from 1.35674 to 1.33738, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 1.3374 - bpp: 0.6808 - mse: 1.6030e-04\n",
      "Epoch 534/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5089 - bpp: 0.7266 - mse: 1.9099e-04\n",
      "Epoch 534: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.5089 - bpp: 0.7266 - mse: 1.9099e-04\n",
      "Epoch 535/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5626 - bpp: 0.7219 - mse: 2.0525e-04\n",
      "Epoch 535: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5626 - bpp: 0.7219 - mse: 2.0525e-04\n",
      "Epoch 536/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5045 - bpp: 0.7104 - mse: 1.9387e-04\n",
      "Epoch 536: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.5045 - bpp: 0.7104 - mse: 1.9387e-04\n",
      "Epoch 537/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4929 - bpp: 0.7181 - mse: 1.8915e-04\n",
      "Epoch 537: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.4929 - bpp: 0.7181 - mse: 1.8915e-04\n",
      "Epoch 538/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4344 - bpp: 0.7037 - mse: 1.7840e-04\n",
      "Epoch 538: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4344 - bpp: 0.7037 - mse: 1.7840e-04\n",
      "Epoch 539/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6088 - bpp: 0.7220 - mse: 2.1649e-04\n",
      "Epoch 539: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 1.6088 - bpp: 0.7220 - mse: 2.1649e-04\n",
      "Epoch 540/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4869 - bpp: 0.7152 - mse: 1.8841e-04\n",
      "Epoch 540: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4869 - bpp: 0.7152 - mse: 1.8841e-04\n",
      "Epoch 541/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6160 - bpp: 0.7330 - mse: 2.1558e-04\n",
      "Epoch 541: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6160 - bpp: 0.7330 - mse: 2.1558e-04\n",
      "Epoch 542/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4999 - bpp: 0.7096 - mse: 1.9293e-04\n",
      "Epoch 542: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.4999 - bpp: 0.7096 - mse: 1.9293e-04\n",
      "Epoch 543/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4493 - bpp: 0.6985 - mse: 1.8329e-04\n",
      "Epoch 543: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.4493 - bpp: 0.6985 - mse: 1.8329e-04\n",
      "Epoch 544/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4969 - bpp: 0.7123 - mse: 1.9155e-04\n",
      "Epoch 544: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4969 - bpp: 0.7123 - mse: 1.9155e-04\n",
      "Epoch 545/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4537 - bpp: 0.7068 - mse: 1.8235e-04\n",
      "Epoch 545: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4537 - bpp: 0.7068 - mse: 1.8235e-04\n",
      "Epoch 546/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5339 - bpp: 0.7239 - mse: 1.9774e-04\n",
      "Epoch 546: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5339 - bpp: 0.7239 - mse: 1.9774e-04\n",
      "Epoch 547/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5318 - bpp: 0.7164 - mse: 1.9909e-04\n",
      "Epoch 547: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 1.5318 - bpp: 0.7164 - mse: 1.9909e-04\n",
      "Epoch 548/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4986 - bpp: 0.7131 - mse: 1.9175e-04\n",
      "Epoch 548: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4986 - bpp: 0.7131 - mse: 1.9175e-04\n",
      "Epoch 549/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5250 - bpp: 0.7222 - mse: 1.9600e-04\n",
      "Epoch 549: loss did not improve from 1.33738\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5250 - bpp: 0.7222 - mse: 1.9600e-04\n",
      "Epoch 550/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3174 - bpp: 0.6771 - mse: 1.5633e-04\n",
      "Epoch 550: loss improved from 1.33738 to 1.31745, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.3174 - bpp: 0.6771 - mse: 1.5633e-04\n",
      "Epoch 551/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6551 - bpp: 0.7392 - mse: 2.2360e-04\n",
      "Epoch 551: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6551 - bpp: 0.7392 - mse: 2.2360e-04\n",
      "Epoch 552/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4034 - bpp: 0.6973 - mse: 1.7240e-04\n",
      "Epoch 552: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4034 - bpp: 0.6973 - mse: 1.7240e-04\n",
      "Epoch 553/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4508 - bpp: 0.7042 - mse: 1.8228e-04\n",
      "Epoch 553: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4508 - bpp: 0.7042 - mse: 1.8228e-04\n",
      "Epoch 554/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4519 - bpp: 0.7067 - mse: 1.8193e-04\n",
      "Epoch 554: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4519 - bpp: 0.7067 - mse: 1.8193e-04\n",
      "Epoch 555/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5427 - bpp: 0.7176 - mse: 2.0145e-04\n",
      "Epoch 555: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5427 - bpp: 0.7176 - mse: 2.0145e-04\n",
      "Epoch 556/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5042 - bpp: 0.7274 - mse: 1.8963e-04\n",
      "Epoch 556: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.5042 - bpp: 0.7274 - mse: 1.8963e-04\n",
      "Epoch 557/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4982 - bpp: 0.7131 - mse: 1.9168e-04\n",
      "Epoch 557: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.4982 - bpp: 0.7131 - mse: 1.9168e-04\n",
      "Epoch 558/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5331 - bpp: 0.7091 - mse: 2.0116e-04\n",
      "Epoch 558: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5331 - bpp: 0.7091 - mse: 2.0116e-04\n",
      "Epoch 559/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5140 - bpp: 0.7122 - mse: 1.9575e-04\n",
      "Epoch 559: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5140 - bpp: 0.7122 - mse: 1.9575e-04\n",
      "Epoch 560/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5311 - bpp: 0.7298 - mse: 1.9562e-04\n",
      "Epoch 560: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5311 - bpp: 0.7298 - mse: 1.9562e-04\n",
      "Epoch 561/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5911 - bpp: 0.7352 - mse: 2.0897e-04\n",
      "Epoch 561: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5911 - bpp: 0.7352 - mse: 2.0897e-04\n",
      "Epoch 562/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6442 - bpp: 0.7640 - mse: 2.1489e-04\n",
      "Epoch 562: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6442 - bpp: 0.7640 - mse: 2.1489e-04\n",
      "Epoch 563/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4355 - bpp: 0.7040 - mse: 1.7858e-04\n",
      "Epoch 563: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4355 - bpp: 0.7040 - mse: 1.7858e-04\n",
      "Epoch 564/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5104 - bpp: 0.7186 - mse: 1.9331e-04\n",
      "Epoch 564: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 1.5104 - bpp: 0.7186 - mse: 1.9331e-04\n",
      "Epoch 565/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4276 - bpp: 0.7050 - mse: 1.7641e-04\n",
      "Epoch 565: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4276 - bpp: 0.7050 - mse: 1.7641e-04\n",
      "Epoch 566/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4727 - bpp: 0.7129 - mse: 1.8549e-04\n",
      "Epoch 566: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4727 - bpp: 0.7129 - mse: 1.8549e-04\n",
      "Epoch 567/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4650 - bpp: 0.7156 - mse: 1.8294e-04\n",
      "Epoch 567: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4650 - bpp: 0.7156 - mse: 1.8294e-04\n",
      "Epoch 568/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4841 - bpp: 0.7155 - mse: 1.8766e-04\n",
      "Epoch 568: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4841 - bpp: 0.7155 - mse: 1.8766e-04\n",
      "Epoch 569/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4938 - bpp: 0.7187 - mse: 1.8924e-04\n",
      "Epoch 569: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4938 - bpp: 0.7187 - mse: 1.8924e-04\n",
      "Epoch 570/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5508 - bpp: 0.7236 - mse: 2.0195e-04\n",
      "Epoch 570: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5508 - bpp: 0.7236 - mse: 2.0195e-04\n",
      "Epoch 571/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5195 - bpp: 0.7184 - mse: 1.9557e-04\n",
      "Epoch 571: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5195 - bpp: 0.7184 - mse: 1.9557e-04\n",
      "Epoch 572/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4366 - bpp: 0.7087 - mse: 1.7771e-04\n",
      "Epoch 572: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4366 - bpp: 0.7087 - mse: 1.7771e-04\n",
      "Epoch 573/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4388 - bpp: 0.7017 - mse: 1.7995e-04\n",
      "Epoch 573: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.4388 - bpp: 0.7017 - mse: 1.7995e-04\n",
      "Epoch 574/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5260 - bpp: 0.7239 - mse: 1.9584e-04\n",
      "Epoch 574: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5260 - bpp: 0.7239 - mse: 1.9584e-04\n",
      "Epoch 575/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5575 - bpp: 0.7297 - mse: 2.0210e-04\n",
      "Epoch 575: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5575 - bpp: 0.7297 - mse: 2.0210e-04\n",
      "Epoch 576/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4427 - bpp: 0.7062 - mse: 1.7980e-04\n",
      "Epoch 576: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4427 - bpp: 0.7062 - mse: 1.7980e-04\n",
      "Epoch 577/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5916 - bpp: 0.7394 - mse: 2.0804e-04\n",
      "Epoch 577: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5916 - bpp: 0.7394 - mse: 2.0804e-04\n",
      "Epoch 578/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5287 - bpp: 0.7127 - mse: 1.9923e-04\n",
      "Epoch 578: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5287 - bpp: 0.7127 - mse: 1.9923e-04\n",
      "Epoch 579/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4797 - bpp: 0.7039 - mse: 1.8940e-04\n",
      "Epoch 579: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4797 - bpp: 0.7039 - mse: 1.8940e-04\n",
      "Epoch 580/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5490 - bpp: 0.7242 - mse: 2.0136e-04\n",
      "Epoch 580: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.5490 - bpp: 0.7242 - mse: 2.0136e-04\n",
      "Epoch 581/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5794 - bpp: 0.7404 - mse: 2.0482e-04\n",
      "Epoch 581: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5794 - bpp: 0.7404 - mse: 2.0482e-04\n",
      "Epoch 582/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3902 - bpp: 0.6988 - mse: 1.6878e-04\n",
      "Epoch 582: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.3902 - bpp: 0.6988 - mse: 1.6878e-04\n",
      "Epoch 583/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4688 - bpp: 0.7063 - mse: 1.8616e-04\n",
      "Epoch 583: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.4688 - bpp: 0.7063 - mse: 1.8616e-04\n",
      "Epoch 584/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4737 - bpp: 0.7137 - mse: 1.8556e-04\n",
      "Epoch 584: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.4737 - bpp: 0.7137 - mse: 1.8556e-04\n",
      "Epoch 585/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4864 - bpp: 0.7185 - mse: 1.8747e-04\n",
      "Epoch 585: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.4864 - bpp: 0.7185 - mse: 1.8747e-04\n",
      "Epoch 586/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5687 - bpp: 0.7266 - mse: 2.0559e-04\n",
      "Epoch 586: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 1.5687 - bpp: 0.7266 - mse: 2.0559e-04\n",
      "Epoch 587/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4726 - bpp: 0.7100 - mse: 1.8618e-04\n",
      "Epoch 587: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4726 - bpp: 0.7100 - mse: 1.8618e-04\n",
      "Epoch 588/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4833 - bpp: 0.7235 - mse: 1.8551e-04\n",
      "Epoch 588: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 1.4833 - bpp: 0.7235 - mse: 1.8551e-04\n",
      "Epoch 589/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6324 - bpp: 0.7407 - mse: 2.1770e-04\n",
      "Epoch 589: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6324 - bpp: 0.7407 - mse: 2.1770e-04\n",
      "Epoch 590/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4797 - bpp: 0.7058 - mse: 1.8893e-04\n",
      "Epoch 590: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4797 - bpp: 0.7058 - mse: 1.8893e-04\n",
      "Epoch 591/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4284 - bpp: 0.7050 - mse: 1.7660e-04\n",
      "Epoch 591: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4284 - bpp: 0.7050 - mse: 1.7660e-04\n",
      "Epoch 592/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4354 - bpp: 0.7016 - mse: 1.7914e-04\n",
      "Epoch 592: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4354 - bpp: 0.7016 - mse: 1.7914e-04\n",
      "Epoch 593/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5415 - bpp: 0.7156 - mse: 2.0163e-04\n",
      "Epoch 593: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5415 - bpp: 0.7156 - mse: 2.0163e-04\n",
      "Epoch 594/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5961 - bpp: 0.7206 - mse: 2.1375e-04\n",
      "Epoch 594: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5961 - bpp: 0.7206 - mse: 2.1375e-04\n",
      "Epoch 595/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4538 - bpp: 0.6996 - mse: 1.8413e-04\n",
      "Epoch 595: loss did not improve from 1.31745\n",
      "200/200 [==============================] - 27s 132ms/step - loss: 1.4538 - bpp: 0.6996 - mse: 1.8413e-04\n",
      "Epoch 596/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2913 - bpp: 0.6712 - mse: 1.5137e-04\n",
      "Epoch 596: loss improved from 1.31745 to 1.29126, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.2913 - bpp: 0.6712 - mse: 1.5137e-04\n",
      "Epoch 597/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5091 - bpp: 0.7238 - mse: 1.9171e-04\n",
      "Epoch 597: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.5091 - bpp: 0.7238 - mse: 1.9171e-04\n",
      "Epoch 598/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5316 - bpp: 0.7195 - mse: 1.9825e-04\n",
      "Epoch 598: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5316 - bpp: 0.7195 - mse: 1.9825e-04\n",
      "Epoch 599/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4494 - bpp: 0.7123 - mse: 1.7995e-04\n",
      "Epoch 599: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4494 - bpp: 0.7123 - mse: 1.7995e-04\n",
      "Epoch 600/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4987 - bpp: 0.7132 - mse: 1.9177e-04\n",
      "Epoch 600: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4987 - bpp: 0.7132 - mse: 1.9177e-04\n",
      "Epoch 601/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4293 - bpp: 0.6980 - mse: 1.7854e-04\n",
      "Epoch 601: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4293 - bpp: 0.6980 - mse: 1.7854e-04\n",
      "Epoch 602/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4775 - bpp: 0.7082 - mse: 1.8783e-04\n",
      "Epoch 602: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4775 - bpp: 0.7082 - mse: 1.8783e-04\n",
      "Epoch 603/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5213 - bpp: 0.7091 - mse: 1.9829e-04\n",
      "Epoch 603: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5213 - bpp: 0.7091 - mse: 1.9829e-04\n",
      "Epoch 604/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4434 - bpp: 0.7166 - mse: 1.7744e-04\n",
      "Epoch 604: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4434 - bpp: 0.7166 - mse: 1.7744e-04\n",
      "Epoch 605/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4566 - bpp: 0.7098 - mse: 1.8233e-04\n",
      "Epoch 605: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 1.4566 - bpp: 0.7098 - mse: 1.8233e-04\n",
      "Epoch 606/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4781 - bpp: 0.7148 - mse: 1.8636e-04\n",
      "Epoch 606: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.4781 - bpp: 0.7148 - mse: 1.8636e-04\n",
      "Epoch 607/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4762 - bpp: 0.7078 - mse: 1.8759e-04\n",
      "Epoch 607: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4762 - bpp: 0.7078 - mse: 1.8759e-04\n",
      "Epoch 608/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3627 - bpp: 0.6834 - mse: 1.6582e-04\n",
      "Epoch 608: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.3627 - bpp: 0.6834 - mse: 1.6582e-04\n",
      "Epoch 609/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4728 - bpp: 0.7058 - mse: 1.8726e-04\n",
      "Epoch 609: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 1.4728 - bpp: 0.7058 - mse: 1.8726e-04\n",
      "Epoch 610/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5926 - bpp: 0.7163 - mse: 2.1394e-04\n",
      "Epoch 610: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5926 - bpp: 0.7163 - mse: 2.1394e-04\n",
      "Epoch 611/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4608 - bpp: 0.7126 - mse: 1.8266e-04\n",
      "Epoch 611: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4608 - bpp: 0.7126 - mse: 1.8266e-04\n",
      "Epoch 612/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4382 - bpp: 0.7060 - mse: 1.7876e-04\n",
      "Epoch 612: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4382 - bpp: 0.7060 - mse: 1.7876e-04\n",
      "Epoch 613/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3915 - bpp: 0.7007 - mse: 1.6864e-04\n",
      "Epoch 613: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.3915 - bpp: 0.7007 - mse: 1.6864e-04\n",
      "Epoch 614/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5604 - bpp: 0.7248 - mse: 2.0401e-04\n",
      "Epoch 614: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 1.5604 - bpp: 0.7248 - mse: 2.0401e-04\n",
      "Epoch 615/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5278 - bpp: 0.7184 - mse: 1.9761e-04\n",
      "Epoch 615: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5278 - bpp: 0.7184 - mse: 1.9761e-04\n",
      "Epoch 616/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5832 - bpp: 0.7307 - mse: 2.0813e-04\n",
      "Epoch 616: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5832 - bpp: 0.7307 - mse: 2.0813e-04\n",
      "Epoch 617/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5541 - bpp: 0.7175 - mse: 2.0424e-04\n",
      "Epoch 617: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5541 - bpp: 0.7175 - mse: 2.0424e-04\n",
      "Epoch 618/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6529 - bpp: 0.7491 - mse: 2.2065e-04\n",
      "Epoch 618: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.6529 - bpp: 0.7491 - mse: 2.2065e-04\n",
      "Epoch 619/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4361 - bpp: 0.7074 - mse: 1.7791e-04\n",
      "Epoch 619: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.4361 - bpp: 0.7074 - mse: 1.7791e-04\n",
      "Epoch 620/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4626 - bpp: 0.7084 - mse: 1.8413e-04\n",
      "Epoch 620: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.4626 - bpp: 0.7084 - mse: 1.8413e-04\n",
      "Epoch 621/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4905 - bpp: 0.7169 - mse: 1.8886e-04\n",
      "Epoch 621: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4905 - bpp: 0.7169 - mse: 1.8886e-04\n",
      "Epoch 622/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4989 - bpp: 0.7220 - mse: 1.8967e-04\n",
      "Epoch 622: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 1.4989 - bpp: 0.7220 - mse: 1.8967e-04\n",
      "Epoch 623/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5080 - bpp: 0.7057 - mse: 1.9586e-04\n",
      "Epoch 623: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5080 - bpp: 0.7057 - mse: 1.9586e-04\n",
      "Epoch 624/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3844 - bpp: 0.6868 - mse: 1.7030e-04\n",
      "Epoch 624: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.3844 - bpp: 0.6868 - mse: 1.7030e-04\n",
      "Epoch 625/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6305 - bpp: 0.7436 - mse: 2.1655e-04\n",
      "Epoch 625: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.6305 - bpp: 0.7436 - mse: 2.1655e-04\n",
      "Epoch 626/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4591 - bpp: 0.7099 - mse: 1.8293e-04\n",
      "Epoch 626: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.4591 - bpp: 0.7099 - mse: 1.8293e-04\n",
      "Epoch 627/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4937 - bpp: 0.7116 - mse: 1.9093e-04\n",
      "Epoch 627: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4937 - bpp: 0.7116 - mse: 1.9093e-04\n",
      "Epoch 628/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4308 - bpp: 0.7011 - mse: 1.7815e-04\n",
      "Epoch 628: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.4308 - bpp: 0.7011 - mse: 1.7815e-04\n",
      "Epoch 629/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5173 - bpp: 0.7209 - mse: 1.9443e-04\n",
      "Epoch 629: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5173 - bpp: 0.7209 - mse: 1.9443e-04\n",
      "Epoch 630/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4910 - bpp: 0.7032 - mse: 1.9234e-04\n",
      "Epoch 630: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.4910 - bpp: 0.7032 - mse: 1.9234e-04\n",
      "Epoch 631/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5865 - bpp: 0.7243 - mse: 2.1049e-04\n",
      "Epoch 631: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5865 - bpp: 0.7243 - mse: 2.1049e-04\n",
      "Epoch 632/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5397 - bpp: 0.7311 - mse: 1.9742e-04\n",
      "Epoch 632: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5397 - bpp: 0.7311 - mse: 1.9742e-04\n",
      "Epoch 633/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4534 - bpp: 0.7071 - mse: 1.8220e-04\n",
      "Epoch 633: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4534 - bpp: 0.7071 - mse: 1.8220e-04\n",
      "Epoch 634/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5056 - bpp: 0.7223 - mse: 1.9125e-04\n",
      "Epoch 634: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.5056 - bpp: 0.7223 - mse: 1.9125e-04\n",
      "Epoch 635/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5525 - bpp: 0.7382 - mse: 1.9880e-04\n",
      "Epoch 635: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5525 - bpp: 0.7382 - mse: 1.9880e-04\n",
      "Epoch 636/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4564 - bpp: 0.7024 - mse: 1.8409e-04\n",
      "Epoch 636: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.4564 - bpp: 0.7024 - mse: 1.8409e-04\n",
      "Epoch 637/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4465 - bpp: 0.7044 - mse: 1.8119e-04\n",
      "Epoch 637: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.4465 - bpp: 0.7044 - mse: 1.8119e-04\n",
      "Epoch 638/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4969 - bpp: 0.7139 - mse: 1.9116e-04\n",
      "Epoch 638: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4969 - bpp: 0.7139 - mse: 1.9116e-04\n",
      "Epoch 639/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4069 - bpp: 0.7067 - mse: 1.7096e-04\n",
      "Epoch 639: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4069 - bpp: 0.7067 - mse: 1.7096e-04\n",
      "Epoch 640/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4660 - bpp: 0.7104 - mse: 1.8447e-04\n",
      "Epoch 640: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.4660 - bpp: 0.7104 - mse: 1.8447e-04\n",
      "Epoch 641/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5363 - bpp: 0.7392 - mse: 1.9460e-04\n",
      "Epoch 641: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.5363 - bpp: 0.7392 - mse: 1.9460e-04\n",
      "Epoch 642/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4132 - bpp: 0.7034 - mse: 1.7328e-04\n",
      "Epoch 642: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4132 - bpp: 0.7034 - mse: 1.7328e-04\n",
      "Epoch 643/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4384 - bpp: 0.7035 - mse: 1.7942e-04\n",
      "Epoch 643: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4384 - bpp: 0.7035 - mse: 1.7942e-04\n",
      "Epoch 644/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3752 - bpp: 0.6919 - mse: 1.6681e-04\n",
      "Epoch 644: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.3752 - bpp: 0.6919 - mse: 1.6681e-04\n",
      "Epoch 645/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5337 - bpp: 0.7338 - mse: 1.9527e-04\n",
      "Epoch 645: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5337 - bpp: 0.7338 - mse: 1.9527e-04\n",
      "Epoch 646/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4604 - bpp: 0.7238 - mse: 1.7982e-04\n",
      "Epoch 646: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4604 - bpp: 0.7238 - mse: 1.7982e-04\n",
      "Epoch 647/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3886 - bpp: 0.7008 - mse: 1.6793e-04\n",
      "Epoch 647: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.3886 - bpp: 0.7008 - mse: 1.6793e-04\n",
      "Epoch 648/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3539 - bpp: 0.6837 - mse: 1.6363e-04\n",
      "Epoch 648: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.3539 - bpp: 0.6837 - mse: 1.6363e-04\n",
      "Epoch 649/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4266 - bpp: 0.7076 - mse: 1.7554e-04\n",
      "Epoch 649: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4266 - bpp: 0.7076 - mse: 1.7554e-04\n",
      "Epoch 650/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3818 - bpp: 0.6982 - mse: 1.6688e-04\n",
      "Epoch 650: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.3818 - bpp: 0.6982 - mse: 1.6688e-04\n",
      "Epoch 651/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3854 - bpp: 0.6869 - mse: 1.7051e-04\n",
      "Epoch 651: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.3854 - bpp: 0.6869 - mse: 1.7051e-04\n",
      "Epoch 652/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4462 - bpp: 0.6984 - mse: 1.8258e-04\n",
      "Epoch 652: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.4462 - bpp: 0.6984 - mse: 1.8258e-04\n",
      "Epoch 653/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4502 - bpp: 0.7011 - mse: 1.8289e-04\n",
      "Epoch 653: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4502 - bpp: 0.7011 - mse: 1.8289e-04\n",
      "Epoch 654/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3826 - bpp: 0.6925 - mse: 1.6849e-04\n",
      "Epoch 654: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.3826 - bpp: 0.6925 - mse: 1.6849e-04\n",
      "Epoch 655/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5326 - bpp: 0.7179 - mse: 1.9889e-04\n",
      "Epoch 655: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5326 - bpp: 0.7179 - mse: 1.9889e-04\n",
      "Epoch 656/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4172 - bpp: 0.7075 - mse: 1.7327e-04\n",
      "Epoch 656: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4172 - bpp: 0.7075 - mse: 1.7327e-04\n",
      "Epoch 657/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4657 - bpp: 0.7116 - mse: 1.8411e-04\n",
      "Epoch 657: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4657 - bpp: 0.7116 - mse: 1.8411e-04\n",
      "Epoch 658/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4771 - bpp: 0.7063 - mse: 1.8820e-04\n",
      "Epoch 658: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4771 - bpp: 0.7063 - mse: 1.8820e-04\n",
      "Epoch 659/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4516 - bpp: 0.7046 - mse: 1.8237e-04\n",
      "Epoch 659: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 1.4516 - bpp: 0.7046 - mse: 1.8237e-04\n",
      "Epoch 660/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5007 - bpp: 0.7161 - mse: 1.9154e-04\n",
      "Epoch 660: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5007 - bpp: 0.7161 - mse: 1.9154e-04\n",
      "Epoch 661/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5885 - bpp: 0.7230 - mse: 2.1130e-04\n",
      "Epoch 661: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5885 - bpp: 0.7230 - mse: 2.1130e-04\n",
      "Epoch 662/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4865 - bpp: 0.7100 - mse: 1.8957e-04\n",
      "Epoch 662: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4865 - bpp: 0.7100 - mse: 1.8957e-04\n",
      "Epoch 663/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6391 - bpp: 0.7391 - mse: 2.1972e-04\n",
      "Epoch 663: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.6391 - bpp: 0.7391 - mse: 2.1972e-04\n",
      "Epoch 664/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5675 - bpp: 0.7413 - mse: 2.0172e-04\n",
      "Epoch 664: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.5675 - bpp: 0.7413 - mse: 2.0172e-04\n",
      "Epoch 665/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4019 - bpp: 0.6948 - mse: 1.7262e-04\n",
      "Epoch 665: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4019 - bpp: 0.6948 - mse: 1.7262e-04\n",
      "Epoch 666/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4331 - bpp: 0.7014 - mse: 1.7863e-04\n",
      "Epoch 666: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4331 - bpp: 0.7014 - mse: 1.7863e-04\n",
      "Epoch 667/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5272 - bpp: 0.7238 - mse: 1.9614e-04\n",
      "Epoch 667: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5272 - bpp: 0.7238 - mse: 1.9614e-04\n",
      "Epoch 668/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4205 - bpp: 0.7099 - mse: 1.7349e-04\n",
      "Epoch 668: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4205 - bpp: 0.7099 - mse: 1.7349e-04\n",
      "Epoch 669/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5100 - bpp: 0.7245 - mse: 1.9179e-04\n",
      "Epoch 669: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.5100 - bpp: 0.7245 - mse: 1.9179e-04\n",
      "Epoch 670/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5458 - bpp: 0.7289 - mse: 1.9944e-04\n",
      "Epoch 670: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 1.5458 - bpp: 0.7289 - mse: 1.9944e-04\n",
      "Epoch 671/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4584 - bpp: 0.7092 - mse: 1.8292e-04\n",
      "Epoch 671: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4584 - bpp: 0.7092 - mse: 1.8292e-04\n",
      "Epoch 672/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5478 - bpp: 0.7245 - mse: 2.0101e-04\n",
      "Epoch 672: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5478 - bpp: 0.7245 - mse: 2.0101e-04\n",
      "Epoch 673/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4450 - bpp: 0.7091 - mse: 1.7965e-04\n",
      "Epoch 673: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4450 - bpp: 0.7091 - mse: 1.7965e-04\n",
      "Epoch 674/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4677 - bpp: 0.7037 - mse: 1.8654e-04\n",
      "Epoch 674: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4677 - bpp: 0.7037 - mse: 1.8654e-04\n",
      "Epoch 675/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5933 - bpp: 0.7262 - mse: 2.1171e-04\n",
      "Epoch 675: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 1.5933 - bpp: 0.7262 - mse: 2.1171e-04\n",
      "Epoch 676/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5577 - bpp: 0.7291 - mse: 2.0229e-04\n",
      "Epoch 676: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.5577 - bpp: 0.7291 - mse: 2.0229e-04\n",
      "Epoch 677/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4471 - bpp: 0.7098 - mse: 1.8000e-04\n",
      "Epoch 677: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4471 - bpp: 0.7098 - mse: 1.8000e-04\n",
      "Epoch 678/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4605 - bpp: 0.6962 - mse: 1.8660e-04\n",
      "Epoch 678: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4605 - bpp: 0.6962 - mse: 1.8660e-04\n",
      "Epoch 679/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4050 - bpp: 0.6942 - mse: 1.7354e-04\n",
      "Epoch 679: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4050 - bpp: 0.6942 - mse: 1.7354e-04\n",
      "Epoch 680/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3690 - bpp: 0.6964 - mse: 1.6419e-04\n",
      "Epoch 680: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.3690 - bpp: 0.6964 - mse: 1.6419e-04\n",
      "Epoch 681/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4980 - bpp: 0.7146 - mse: 1.9128e-04\n",
      "Epoch 681: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4980 - bpp: 0.7146 - mse: 1.9128e-04\n",
      "Epoch 682/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4104 - bpp: 0.7023 - mse: 1.7289e-04\n",
      "Epoch 682: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4104 - bpp: 0.7023 - mse: 1.7289e-04\n",
      "Epoch 683/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3428 - bpp: 0.6841 - mse: 1.6082e-04\n",
      "Epoch 683: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.3428 - bpp: 0.6841 - mse: 1.6082e-04\n",
      "Epoch 684/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5338 - bpp: 0.7159 - mse: 1.9968e-04\n",
      "Epoch 684: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.5338 - bpp: 0.7159 - mse: 1.9968e-04\n",
      "Epoch 685/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3356 - bpp: 0.6838 - mse: 1.5914e-04\n",
      "Epoch 685: loss did not improve from 1.29126\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 1.3356 - bpp: 0.6838 - mse: 1.5914e-04\n",
      "Epoch 686/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2852 - bpp: 0.6752 - mse: 1.4891e-04\n",
      "Epoch 686: loss improved from 1.29126 to 1.28516, saving model to checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.2852 - bpp: 0.6752 - mse: 1.4891e-04\n",
      "Epoch 687/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4935 - bpp: 0.7116 - mse: 1.9090e-04\n",
      "Epoch 687: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4935 - bpp: 0.7116 - mse: 1.9090e-04\n",
      "Epoch 688/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4550 - bpp: 0.7175 - mse: 1.8005e-04\n",
      "Epoch 688: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4550 - bpp: 0.7175 - mse: 1.8005e-04\n",
      "Epoch 689/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5451 - bpp: 0.7216 - mse: 2.0105e-04\n",
      "Epoch 689: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.5451 - bpp: 0.7216 - mse: 2.0105e-04\n",
      "Epoch 690/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4740 - bpp: 0.7158 - mse: 1.8512e-04\n",
      "Epoch 690: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 1.4740 - bpp: 0.7158 - mse: 1.8512e-04\n",
      "Epoch 691/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3862 - bpp: 0.7001 - mse: 1.6750e-04\n",
      "Epoch 691: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.3862 - bpp: 0.7001 - mse: 1.6750e-04\n",
      "Epoch 692/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5053 - bpp: 0.7186 - mse: 1.9207e-04\n",
      "Epoch 692: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 1.5053 - bpp: 0.7186 - mse: 1.9207e-04\n",
      "Epoch 693/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5775 - bpp: 0.7422 - mse: 2.0393e-04\n",
      "Epoch 693: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5775 - bpp: 0.7422 - mse: 2.0393e-04\n",
      "Epoch 694/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4901 - bpp: 0.7211 - mse: 1.8773e-04\n",
      "Epoch 694: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4901 - bpp: 0.7211 - mse: 1.8773e-04\n",
      "Epoch 695/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3998 - bpp: 0.6931 - mse: 1.7252e-04\n",
      "Epoch 695: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 1.3998 - bpp: 0.6931 - mse: 1.7252e-04\n",
      "Epoch 696/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4407 - bpp: 0.7070 - mse: 1.7912e-04\n",
      "Epoch 696: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.4407 - bpp: 0.7070 - mse: 1.7912e-04\n",
      "Epoch 697/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5937 - bpp: 0.7473 - mse: 2.0665e-04\n",
      "Epoch 697: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.5937 - bpp: 0.7473 - mse: 2.0665e-04\n",
      "Epoch 698/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4717 - bpp: 0.7168 - mse: 1.8430e-04\n",
      "Epoch 698: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 1.4717 - bpp: 0.7168 - mse: 1.8430e-04\n",
      "Epoch 699/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4332 - bpp: 0.7135 - mse: 1.7571e-04\n",
      "Epoch 699: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4332 - bpp: 0.7135 - mse: 1.7571e-04\n",
      "Epoch 700/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4062 - bpp: 0.7038 - mse: 1.7149e-04\n",
      "Epoch 700: loss did not improve from 1.28516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.4062 - bpp: 0.7038 - mse: 1.7149e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_1_layer_call_fn, optical_flow_loss_1_layer_call_and_return_conditional_losses, dwt_1_layer_call_fn, dwt_1_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_4096_epcs_700_I_QP_27_240x240_CosineDecay_20220531-105154/assets\n"
     ]
    }
   ],
   "source": [
    "I_QP=27\n",
    "lmbda = 4096\n",
    "trainer_12 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_12.compile()\n",
    "trainer_12.fit()\n",
    "trainer_12.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 112.6048 - bpp: 5.3018 - mse: 0.0131\n",
      "Epoch 1: loss improved from inf to 112.60483, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 55s 125ms/step - loss: 112.6048 - bpp: 5.3018 - mse: 0.0131\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.1184 - bpp: 5.1640 - mse: 0.0026\n",
      "Epoch 2: loss improved from 112.60483 to 26.11839, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 26.1184 - bpp: 5.1640 - mse: 0.0026\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.2161 - bpp: 5.0296 - mse: 0.0022\n",
      "Epoch 3: loss improved from 26.11839 to 23.21610, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 23.2161 - bpp: 5.0296 - mse: 0.0022\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.2556 - bpp: 4.8979 - mse: 0.0015\n",
      "Epoch 4: loss improved from 23.21610 to 17.25557, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 17.2556 - bpp: 4.8979 - mse: 0.0015\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.3494 - bpp: 4.7685 - mse: 0.0014\n",
      "Epoch 5: loss improved from 17.25557 to 16.34938, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 16.3494 - bpp: 4.7685 - mse: 0.0014\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.4555 - bpp: 4.6417 - mse: 0.0016\n",
      "Epoch 6: loss did not improve from 16.34938\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 17.4555 - bpp: 4.6417 - mse: 0.0016\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.0568 - bpp: 4.5165 - mse: 0.0012\n",
      "Epoch 7: loss improved from 16.34938 to 14.05682, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 14.0568 - bpp: 4.5165 - mse: 0.0012\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.0686 - bpp: 4.3937 - mse: 0.0011\n",
      "Epoch 8: loss improved from 14.05682 to 13.06861, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 13.0686 - bpp: 4.3937 - mse: 0.0011\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.1707 - bpp: 4.2736 - mse: 0.0013\n",
      "Epoch 9: loss did not improve from 13.06861\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 15.1707 - bpp: 4.2736 - mse: 0.0013\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2632 - bpp: 4.1552 - mse: 9.8975e-04\n",
      "Epoch 10: loss improved from 13.06861 to 12.26324, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 12.2632 - bpp: 4.1552 - mse: 9.8975e-04\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6512 - bpp: 4.0380 - mse: 9.2934e-04\n",
      "Epoch 11: loss improved from 12.26324 to 11.65120, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 11.6512 - bpp: 4.0380 - mse: 9.2934e-04\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0077 - bpp: 3.9251 - mse: 8.6457e-04\n",
      "Epoch 12: loss improved from 11.65120 to 11.00765, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 11.0077 - bpp: 3.9251 - mse: 8.6457e-04\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.5517 - bpp: 3.8132 - mse: 8.2258e-04\n",
      "Epoch 13: loss improved from 11.00765 to 10.55173, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 10.5517 - bpp: 3.8132 - mse: 8.2258e-04\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.7002 - bpp: 3.7050 - mse: 9.7598e-04\n",
      "Epoch 14: loss did not improve from 10.55173\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 11.7002 - bpp: 3.7050 - mse: 9.7598e-04\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.7277 - bpp: 3.5969 - mse: 9.9252e-04\n",
      "Epoch 15: loss did not improve from 10.55173\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 11.7277 - bpp: 3.5969 - mse: 9.9252e-04\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.3530 - bpp: 3.4973 - mse: 0.0017\n",
      "Epoch 16: loss did not improve from 10.55173\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 17.3530 - bpp: 3.4973 - mse: 0.0017\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.4064 - bpp: 3.3968 - mse: 0.0012\n",
      "Epoch 17: loss did not improve from 10.55173\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 13.4064 - bpp: 3.3968 - mse: 0.0012\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4197 - bpp: 3.2966 - mse: 8.6952e-04\n",
      "Epoch 18: loss improved from 10.55173 to 10.41966, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 10.4197 - bpp: 3.2966 - mse: 8.6952e-04\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3130 - bpp: 3.1944 - mse: 7.4690e-04\n",
      "Epoch 19: loss improved from 10.41966 to 9.31303, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 9.3130 - bpp: 3.1944 - mse: 7.4690e-04\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5072 - bpp: 3.1064 - mse: 7.8135e-04\n",
      "Epoch 20: loss did not improve from 9.31303\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.5072 - bpp: 3.1064 - mse: 7.8135e-04\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.5950 - bpp: 3.0150 - mse: 9.2530e-04\n",
      "Epoch 21: loss did not improve from 9.31303\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 10.5950 - bpp: 3.0150 - mse: 9.2530e-04\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8814 - bpp: 2.9200 - mse: 7.2772e-04\n",
      "Epoch 22: loss improved from 9.31303 to 8.88144, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 8.8814 - bpp: 2.9200 - mse: 7.2772e-04\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6288 - bpp: 2.8412 - mse: 8.2856e-04\n",
      "Epoch 23: loss did not improve from 8.88144\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 9.6288 - bpp: 2.8412 - mse: 8.2856e-04\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3785 - bpp: 2.7577 - mse: 9.3027e-04\n",
      "Epoch 24: loss did not improve from 8.88144\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 10.3785 - bpp: 2.7577 - mse: 9.3027e-04\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5034 - bpp: 2.6756 - mse: 7.1140e-04\n",
      "Epoch 25: loss improved from 8.88144 to 8.50338, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 8.5034 - bpp: 2.6756 - mse: 7.1140e-04\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0425 - bpp: 2.6029 - mse: 7.8609e-04\n",
      "Epoch 26: loss did not improve from 8.50338\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.0425 - bpp: 2.6029 - mse: 7.8609e-04\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2758 - bpp: 2.5299 - mse: 8.2348e-04\n",
      "Epoch 27: loss did not improve from 8.50338\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 9.2758 - bpp: 2.5299 - mse: 8.2348e-04\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3694 - bpp: 2.4521 - mse: 6.0026e-04\n",
      "Epoch 28: loss improved from 8.50338 to 7.36943, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 7.3694 - bpp: 2.4521 - mse: 6.0026e-04\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4423 - bpp: 2.3782 - mse: 6.1818e-04\n",
      "Epoch 29: loss did not improve from 7.36943\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.4423 - bpp: 2.3782 - mse: 6.1818e-04\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6973 - bpp: 2.3238 - mse: 6.5594e-04\n",
      "Epoch 30: loss did not improve from 7.36943\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.6973 - bpp: 2.3238 - mse: 6.5594e-04\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0618 - bpp: 2.2521 - mse: 5.8713e-04\n",
      "Epoch 31: loss improved from 7.36943 to 7.06185, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 7.0618 - bpp: 2.2521 - mse: 5.8713e-04\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5833 - bpp: 2.2022 - mse: 6.5687e-04\n",
      "Epoch 32: loss did not improve from 7.06185\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.5833 - bpp: 2.2022 - mse: 6.5687e-04\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7066 - bpp: 2.1230 - mse: 5.5952e-04\n",
      "Epoch 33: loss improved from 7.06185 to 6.70661, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 6.7066 - bpp: 2.1230 - mse: 5.5952e-04\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0267 - bpp: 2.0825 - mse: 6.0354e-04\n",
      "Epoch 34: loss did not improve from 6.70661\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.0267 - bpp: 2.0825 - mse: 6.0354e-04\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.1584 - bpp: 2.0573 - mse: 0.0016\n",
      "Epoch 35: loss did not improve from 6.70661\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 15.1584 - bpp: 2.0573 - mse: 0.0016\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9038 - bpp: 1.9714 - mse: 7.2417e-04\n",
      "Epoch 36: loss did not improve from 6.70661\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.9038 - bpp: 1.9714 - mse: 7.2417e-04\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9456 - bpp: 1.9355 - mse: 6.1159e-04\n",
      "Epoch 37: loss did not improve from 6.70661\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.9456 - bpp: 1.9355 - mse: 6.1159e-04\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3786 - bpp: 1.8812 - mse: 5.4900e-04\n",
      "Epoch 38: loss improved from 6.70661 to 6.37860, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 6.3786 - bpp: 1.8812 - mse: 5.4900e-04\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1336 - bpp: 1.8276 - mse: 5.2563e-04\n",
      "Epoch 39: loss improved from 6.37860 to 6.13358, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 6.1336 - bpp: 1.8276 - mse: 5.2563e-04\n",
      "Epoch 40/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1669 - bpp: 1.8198 - mse: 6.5271e-04\n",
      "Epoch 40: loss did not improve from 6.13358\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.1669 - bpp: 1.8198 - mse: 6.5271e-04\n",
      "Epoch 41/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3323 - bpp: 1.7688 - mse: 5.5707e-04\n",
      "Epoch 41: loss did not improve from 6.13358\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.3323 - bpp: 1.7688 - mse: 5.5707e-04\n",
      "Epoch 42/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8870 - bpp: 1.7211 - mse: 5.0853e-04\n",
      "Epoch 42: loss improved from 6.13358 to 5.88698, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.8870 - bpp: 1.7211 - mse: 5.0853e-04\n",
      "Epoch 43/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3925 - bpp: 1.7172 - mse: 6.9278e-04\n",
      "Epoch 43: loss did not improve from 5.88698\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.3925 - bpp: 1.7172 - mse: 6.9278e-04\n",
      "Epoch 44/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2576 - bpp: 1.6708 - mse: 5.5991e-04\n",
      "Epoch 44: loss did not improve from 5.88698\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.2576 - bpp: 1.6708 - mse: 5.5991e-04\n",
      "Epoch 45/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8375 - bpp: 1.6301 - mse: 5.1360e-04\n",
      "Epoch 45: loss improved from 5.88698 to 5.83754, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 5.8375 - bpp: 1.6301 - mse: 5.1360e-04\n",
      "Epoch 46/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3667 - bpp: 1.5988 - mse: 4.5995e-04\n",
      "Epoch 46: loss improved from 5.83754 to 5.36670, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 5.3667 - bpp: 1.5988 - mse: 4.5995e-04\n",
      "Epoch 47/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6250 - bpp: 1.6068 - mse: 6.1258e-04\n",
      "Epoch 47: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.6250 - bpp: 1.6068 - mse: 6.1258e-04\n",
      "Epoch 48/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9231 - bpp: 1.5836 - mse: 6.5178e-04\n",
      "Epoch 48: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 6.9231 - bpp: 1.5836 - mse: 6.5178e-04\n",
      "Epoch 49/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1659 - bpp: 1.5543 - mse: 6.8502e-04\n",
      "Epoch 49: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 7.1659 - bpp: 1.5543 - mse: 6.8502e-04\n",
      "Epoch 50/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7675 - bpp: 1.4874 - mse: 5.2248e-04\n",
      "Epoch 50: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.7675 - bpp: 1.4874 - mse: 5.2248e-04\n",
      "Epoch 51/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3270 - bpp: 1.5028 - mse: 5.8889e-04\n",
      "Epoch 51: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3270 - bpp: 1.5028 - mse: 5.8889e-04\n",
      "Epoch 52/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0572 - bpp: 1.4789 - mse: 5.5888e-04\n",
      "Epoch 52: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0572 - bpp: 1.4789 - mse: 5.5888e-04\n",
      "Epoch 53/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5170 - bpp: 1.4617 - mse: 4.9504e-04\n",
      "Epoch 53: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.5170 - bpp: 1.4617 - mse: 4.9504e-04\n",
      "Epoch 54/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3742 - bpp: 1.4594 - mse: 4.7788e-04\n",
      "Epoch 54: loss did not improve from 5.36670\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.3742 - bpp: 1.4594 - mse: 4.7788e-04\n",
      "Epoch 55/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6682 - bpp: 1.3939 - mse: 3.9968e-04\n",
      "Epoch 55: loss improved from 5.36670 to 4.66816, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 4.6682 - bpp: 1.3939 - mse: 3.9968e-04\n",
      "Epoch 56/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3355 - bpp: 1.4535 - mse: 5.9595e-04\n",
      "Epoch 56: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3355 - bpp: 1.4535 - mse: 5.9595e-04\n",
      "Epoch 57/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8239 - bpp: 1.4485 - mse: 6.5618e-04\n",
      "Epoch 57: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.8239 - bpp: 1.4485 - mse: 6.5618e-04\n",
      "Epoch 58/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7284 - bpp: 1.4134 - mse: 5.2673e-04\n",
      "Epoch 58: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 5.7284 - bpp: 1.4134 - mse: 5.2673e-04\n",
      "Epoch 59/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6301 - bpp: 1.3830 - mse: 5.1845e-04\n",
      "Epoch 59: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.6301 - bpp: 1.3830 - mse: 5.1845e-04\n",
      "Epoch 60/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9398 - bpp: 1.3863 - mse: 5.5585e-04\n",
      "Epoch 60: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 5.9398 - bpp: 1.3863 - mse: 5.5585e-04\n",
      "Epoch 61/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0376 - bpp: 1.3535 - mse: 4.4972e-04\n",
      "Epoch 61: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.0376 - bpp: 1.3535 - mse: 4.4972e-04\n",
      "Epoch 62/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2905 - bpp: 1.3946 - mse: 9.6385e-04\n",
      "Epoch 62: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 9.2905 - bpp: 1.3946 - mse: 9.6385e-04\n",
      "Epoch 63/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8632 - bpp: 1.3304 - mse: 4.3125e-04\n",
      "Epoch 63: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.8632 - bpp: 1.3304 - mse: 4.3125e-04\n",
      "Epoch 64/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4116 - bpp: 1.3247 - mse: 4.9889e-04\n",
      "Epoch 64: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.4116 - bpp: 1.3247 - mse: 4.9889e-04\n",
      "Epoch 65/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9672 - bpp: 1.3181 - mse: 4.4545e-04\n",
      "Epoch 65: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.9672 - bpp: 1.3181 - mse: 4.4545e-04\n",
      "Epoch 66/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7854 - bpp: 1.3049 - mse: 4.2486e-04\n",
      "Epoch 66: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.7854 - bpp: 1.3049 - mse: 4.2486e-04\n",
      "Epoch 67/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3272 - bpp: 1.3253 - mse: 4.8852e-04\n",
      "Epoch 67: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.3272 - bpp: 1.3253 - mse: 4.8852e-04\n",
      "Epoch 68/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7168 - bpp: 1.2935 - mse: 4.1788e-04\n",
      "Epoch 68: loss did not improve from 4.66816\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.7168 - bpp: 1.2935 - mse: 4.1788e-04\n",
      "Epoch 69/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3957 - bpp: 1.2572 - mse: 3.8313e-04\n",
      "Epoch 69: loss improved from 4.66816 to 4.39575, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 4.3957 - bpp: 1.2572 - mse: 3.8313e-04\n",
      "Epoch 70/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9159 - bpp: 1.3053 - mse: 6.8489e-04\n",
      "Epoch 70: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.9159 - bpp: 1.3053 - mse: 6.8489e-04\n",
      "Epoch 71/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6631 - bpp: 1.2436 - mse: 4.1742e-04\n",
      "Epoch 71: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.6631 - bpp: 1.2436 - mse: 4.1742e-04\n",
      "Epoch 72/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6347 - bpp: 1.2518 - mse: 4.1295e-04\n",
      "Epoch 72: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.6347 - bpp: 1.2518 - mse: 4.1295e-04\n",
      "Epoch 73/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5972 - bpp: 1.2671 - mse: 4.0650e-04\n",
      "Epoch 73: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.5972 - bpp: 1.2671 - mse: 4.0650e-04\n",
      "Epoch 74/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0242 - bpp: 1.2522 - mse: 4.6045e-04\n",
      "Epoch 74: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.0242 - bpp: 1.2522 - mse: 4.6045e-04\n",
      "Epoch 75/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6962 - bpp: 1.3188 - mse: 6.5641e-04\n",
      "Epoch 75: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 6.6962 - bpp: 1.3188 - mse: 6.5641e-04\n",
      "Epoch 76/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9285 - bpp: 1.2210 - mse: 4.5258e-04\n",
      "Epoch 76: loss did not improve from 4.39575\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.9285 - bpp: 1.2210 - mse: 4.5258e-04\n",
      "Epoch 77/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2450 - bpp: 1.2184 - mse: 3.6946e-04\n",
      "Epoch 77: loss improved from 4.39575 to 4.24499, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 4.2450 - bpp: 1.2184 - mse: 3.6946e-04\n",
      "Epoch 78/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4868 - bpp: 1.2225 - mse: 3.9848e-04\n",
      "Epoch 78: loss did not improve from 4.24499\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.4868 - bpp: 1.2225 - mse: 3.9848e-04\n",
      "Epoch 79/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5165 - bpp: 1.2187 - mse: 4.0256e-04\n",
      "Epoch 79: loss did not improve from 4.24499\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 4.5165 - bpp: 1.2187 - mse: 4.0256e-04\n",
      "Epoch 80/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6285 - bpp: 1.2202 - mse: 4.1605e-04\n",
      "Epoch 80: loss did not improve from 4.24499\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.6285 - bpp: 1.2202 - mse: 4.1605e-04\n",
      "Epoch 81/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1331 - bpp: 1.1997 - mse: 3.5807e-04\n",
      "Epoch 81: loss improved from 4.24499 to 4.13305, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 4.1331 - bpp: 1.1997 - mse: 3.5807e-04\n",
      "Epoch 82/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9284 - bpp: 1.2230 - mse: 4.5232e-04\n",
      "Epoch 82: loss did not improve from 4.13305\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.9284 - bpp: 1.2230 - mse: 4.5232e-04\n",
      "Epoch 83/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3448 - bpp: 1.2017 - mse: 3.8368e-04\n",
      "Epoch 83: loss did not improve from 4.13305\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.3448 - bpp: 1.2017 - mse: 3.8368e-04\n",
      "Epoch 84/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7402 - bpp: 1.2062 - mse: 4.3139e-04\n",
      "Epoch 84: loss did not improve from 4.13305\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.7402 - bpp: 1.2062 - mse: 4.3139e-04\n",
      "Epoch 85/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3104 - bpp: 1.2217 - mse: 6.2118e-04\n",
      "Epoch 85: loss did not improve from 4.13305\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.3104 - bpp: 1.2217 - mse: 6.2118e-04\n",
      "Epoch 86/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2632 - bpp: 1.2540 - mse: 4.8940e-04\n",
      "Epoch 86: loss did not improve from 4.13305\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 5.2632 - bpp: 1.2540 - mse: 4.8940e-04\n",
      "Epoch 87/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8593 - bpp: 1.2000 - mse: 3.2462e-04\n",
      "Epoch 87: loss improved from 4.13305 to 3.85927, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.8593 - bpp: 1.2000 - mse: 3.2462e-04\n",
      "Epoch 88/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0418 - bpp: 1.1735 - mse: 3.5014e-04\n",
      "Epoch 88: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.0418 - bpp: 1.1735 - mse: 3.5014e-04\n",
      "Epoch 89/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8678 - bpp: 1.1680 - mse: 3.2957e-04\n",
      "Epoch 89: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 3.8678 - bpp: 1.1680 - mse: 3.2957e-04\n",
      "Epoch 90/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3443 - bpp: 1.2380 - mse: 5.0126e-04\n",
      "Epoch 90: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.3443 - bpp: 1.2380 - mse: 5.0126e-04\n",
      "Epoch 91/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6078 - bpp: 1.2004 - mse: 4.1595e-04\n",
      "Epoch 91: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.6078 - bpp: 1.2004 - mse: 4.1595e-04\n",
      "Epoch 92/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8793 - bpp: 1.1867 - mse: 3.2868e-04\n",
      "Epoch 92: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.8793 - bpp: 1.1867 - mse: 3.2868e-04\n",
      "Epoch 93/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1027 - bpp: 1.1682 - mse: 3.5822e-04\n",
      "Epoch 93: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.1027 - bpp: 1.1682 - mse: 3.5822e-04\n",
      "Epoch 94/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6035 - bpp: 1.2108 - mse: 4.1414e-04\n",
      "Epoch 94: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 4.6035 - bpp: 1.2108 - mse: 4.1414e-04\n",
      "Epoch 95/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9521 - bpp: 1.2254 - mse: 5.7699e-04\n",
      "Epoch 95: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.9521 - bpp: 1.2254 - mse: 5.7699e-04\n",
      "Epoch 96/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4295 - bpp: 1.2117 - mse: 6.3694e-04\n",
      "Epoch 96: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.4295 - bpp: 1.2117 - mse: 6.3694e-04\n",
      "Epoch 97/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9855 - bpp: 1.1731 - mse: 3.4331e-04\n",
      "Epoch 97: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9855 - bpp: 1.1731 - mse: 3.4331e-04\n",
      "Epoch 98/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4413 - bpp: 1.1870 - mse: 3.9725e-04\n",
      "Epoch 98: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 4.4413 - bpp: 1.1870 - mse: 3.9725e-04\n",
      "Epoch 99/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9976 - bpp: 1.1521 - mse: 3.4735e-04\n",
      "Epoch 99: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9976 - bpp: 1.1521 - mse: 3.4735e-04\n",
      "Epoch 100/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2237 - bpp: 1.1927 - mse: 3.6999e-04\n",
      "Epoch 100: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2237 - bpp: 1.1927 - mse: 3.6999e-04\n",
      "Epoch 101/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2064 - bpp: 1.1921 - mse: 3.6796e-04\n",
      "Epoch 101: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2064 - bpp: 1.1921 - mse: 3.6796e-04\n",
      "Epoch 102/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4802 - bpp: 1.1965 - mse: 4.0084e-04\n",
      "Epoch 102: loss did not improve from 3.85927\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.4802 - bpp: 1.1965 - mse: 4.0084e-04\n",
      "Epoch 103/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8158 - bpp: 1.1731 - mse: 3.2260e-04\n",
      "Epoch 103: loss improved from 3.85927 to 3.81584, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 3.8158 - bpp: 1.1731 - mse: 3.2260e-04\n",
      "Epoch 104/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7405 - bpp: 1.2256 - mse: 6.7321e-04\n",
      "Epoch 104: loss did not improve from 3.81584\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 6.7405 - bpp: 1.2256 - mse: 6.7321e-04\n",
      "Epoch 105/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5821 - bpp: 1.1634 - mse: 4.1733e-04\n",
      "Epoch 105: loss did not improve from 3.81584\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.5821 - bpp: 1.1634 - mse: 4.1733e-04\n",
      "Epoch 106/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6276 - bpp: 1.1606 - mse: 3.0114e-04\n",
      "Epoch 106: loss improved from 3.81584 to 3.62758, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.6276 - bpp: 1.1606 - mse: 3.0114e-04\n",
      "Epoch 107/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2950 - bpp: 1.1411 - mse: 3.8500e-04\n",
      "Epoch 107: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2950 - bpp: 1.1411 - mse: 3.8500e-04\n",
      "Epoch 108/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8115 - bpp: 1.1366 - mse: 3.2653e-04\n",
      "Epoch 108: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 3.8115 - bpp: 1.1366 - mse: 3.2653e-04\n",
      "Epoch 109/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0517 - bpp: 1.1800 - mse: 3.5055e-04\n",
      "Epoch 109: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 4.0517 - bpp: 1.1800 - mse: 3.5055e-04\n",
      "Epoch 110/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7920 - bpp: 1.1570 - mse: 3.2166e-04\n",
      "Epoch 110: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7920 - bpp: 1.1570 - mse: 3.2166e-04\n",
      "Epoch 111/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5807 - bpp: 1.1741 - mse: 4.1585e-04\n",
      "Epoch 111: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 4.5807 - bpp: 1.1741 - mse: 4.1585e-04\n",
      "Epoch 112/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7108 - bpp: 1.1459 - mse: 3.1310e-04\n",
      "Epoch 112: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.7108 - bpp: 1.1459 - mse: 3.1310e-04\n",
      "Epoch 113/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3258 - bpp: 1.1822 - mse: 3.8374e-04\n",
      "Epoch 113: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 4.3258 - bpp: 1.1822 - mse: 3.8374e-04\n",
      "Epoch 114/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2052 - bpp: 1.1809 - mse: 3.6917e-04\n",
      "Epoch 114: loss did not improve from 3.62758\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 4.2052 - bpp: 1.1809 - mse: 3.6917e-04\n",
      "Epoch 115/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6181 - bpp: 1.1540 - mse: 3.0080e-04\n",
      "Epoch 115: loss improved from 3.62758 to 3.61807, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.6181 - bpp: 1.1540 - mse: 3.0080e-04\n",
      "Epoch 116/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6965 - bpp: 1.1549 - mse: 3.1025e-04\n",
      "Epoch 116: loss did not improve from 3.61807\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.6965 - bpp: 1.1549 - mse: 3.1025e-04\n",
      "Epoch 117/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5932 - bpp: 1.1348 - mse: 3.0009e-04\n",
      "Epoch 117: loss improved from 3.61807 to 3.59317, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 27s 132ms/step - loss: 3.5932 - bpp: 1.1348 - mse: 3.0009e-04\n",
      "Epoch 118/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5327 - bpp: 1.1361 - mse: 2.9256e-04\n",
      "Epoch 118: loss improved from 3.59317 to 3.53274, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.5327 - bpp: 1.1361 - mse: 2.9256e-04\n",
      "Epoch 119/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6107 - bpp: 1.1867 - mse: 5.4004e-04\n",
      "Epoch 119: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 5.6107 - bpp: 1.1867 - mse: 5.4004e-04\n",
      "Epoch 120/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9393 - bpp: 1.1797 - mse: 3.3687e-04\n",
      "Epoch 120: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.9393 - bpp: 1.1797 - mse: 3.3687e-04\n",
      "Epoch 121/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1482 - bpp: 1.1591 - mse: 3.6489e-04\n",
      "Epoch 121: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.1482 - bpp: 1.1591 - mse: 3.6489e-04\n",
      "Epoch 122/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7822 - bpp: 1.1593 - mse: 3.2018e-04\n",
      "Epoch 122: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7822 - bpp: 1.1593 - mse: 3.2018e-04\n",
      "Epoch 123/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7711 - bpp: 1.1644 - mse: 3.1820e-04\n",
      "Epoch 123: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 3.7711 - bpp: 1.1644 - mse: 3.1820e-04\n",
      "Epoch 124/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9709 - bpp: 1.1727 - mse: 3.4157e-04\n",
      "Epoch 124: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9709 - bpp: 1.1727 - mse: 3.4157e-04\n",
      "Epoch 125/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0787 - bpp: 1.1730 - mse: 3.5470e-04\n",
      "Epoch 125: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.0787 - bpp: 1.1730 - mse: 3.5470e-04\n",
      "Epoch 126/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1380 - bpp: 1.1995 - mse: 0.0013\n",
      "Epoch 126: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 12.1380 - bpp: 1.1995 - mse: 0.0013\n",
      "Epoch 127/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9233 - bpp: 1.1449 - mse: 3.3916e-04\n",
      "Epoch 127: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 3.9233 - bpp: 1.1449 - mse: 3.3916e-04\n",
      "Epoch 128/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6821 - bpp: 1.1406 - mse: 3.1025e-04\n",
      "Epoch 128: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6821 - bpp: 1.1406 - mse: 3.1025e-04\n",
      "Epoch 129/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6996 - bpp: 1.1294 - mse: 3.1375e-04\n",
      "Epoch 129: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6996 - bpp: 1.1294 - mse: 3.1375e-04\n",
      "Epoch 130/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7884 - bpp: 1.1446 - mse: 3.2273e-04\n",
      "Epoch 130: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7884 - bpp: 1.1446 - mse: 3.2273e-04\n",
      "Epoch 131/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2456 - bpp: 1.1674 - mse: 3.7576e-04\n",
      "Epoch 131: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2456 - bpp: 1.1674 - mse: 3.7576e-04\n",
      "Epoch 132/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6270 - bpp: 1.1583 - mse: 3.0135e-04\n",
      "Epoch 132: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6270 - bpp: 1.1583 - mse: 3.0135e-04\n",
      "Epoch 133/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6234 - bpp: 1.1546 - mse: 3.0136e-04\n",
      "Epoch 133: loss did not improve from 3.53274\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.6234 - bpp: 1.1546 - mse: 3.0136e-04\n",
      "Epoch 134/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3435 - bpp: 1.1028 - mse: 2.7352e-04\n",
      "Epoch 134: loss improved from 3.53274 to 3.34346, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.3435 - bpp: 1.1028 - mse: 2.7352e-04\n",
      "Epoch 135/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4922 - bpp: 1.1237 - mse: 2.8913e-04\n",
      "Epoch 135: loss did not improve from 3.34346\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 3.4922 - bpp: 1.1237 - mse: 2.8913e-04\n",
      "Epoch 136/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2429 - bpp: 1.1217 - mse: 2.5894e-04\n",
      "Epoch 136: loss improved from 3.34346 to 3.24294, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 27s 132ms/step - loss: 3.2429 - bpp: 1.1217 - mse: 2.5894e-04\n",
      "Epoch 137/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9024 - bpp: 1.1394 - mse: 3.3729e-04\n",
      "Epoch 137: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.9024 - bpp: 1.1394 - mse: 3.3729e-04\n",
      "Epoch 138/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5398 - bpp: 1.1788 - mse: 4.1029e-04\n",
      "Epoch 138: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.5398 - bpp: 1.1788 - mse: 4.1029e-04\n",
      "Epoch 139/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9822 - bpp: 1.1351 - mse: 3.4754e-04\n",
      "Epoch 139: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.9822 - bpp: 1.1351 - mse: 3.4754e-04\n",
      "Epoch 140/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4664 - bpp: 1.1318 - mse: 2.8498e-04\n",
      "Epoch 140: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.4664 - bpp: 1.1318 - mse: 2.8498e-04\n",
      "Epoch 141/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7454 - bpp: 1.1492 - mse: 3.1692e-04\n",
      "Epoch 141: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.7454 - bpp: 1.1492 - mse: 3.1692e-04\n",
      "Epoch 142/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7264 - bpp: 1.1324 - mse: 3.1664e-04\n",
      "Epoch 142: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7264 - bpp: 1.1324 - mse: 3.1664e-04\n",
      "Epoch 143/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9565 - bpp: 1.1269 - mse: 3.4541e-04\n",
      "Epoch 143: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9565 - bpp: 1.1269 - mse: 3.4541e-04\n",
      "Epoch 144/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5924 - bpp: 1.1291 - mse: 3.0069e-04\n",
      "Epoch 144: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.5924 - bpp: 1.1291 - mse: 3.0069e-04\n",
      "Epoch 145/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3531 - bpp: 1.1171 - mse: 2.7295e-04\n",
      "Epoch 145: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3531 - bpp: 1.1171 - mse: 2.7295e-04\n",
      "Epoch 146/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2752 - bpp: 1.1126 - mse: 2.6398e-04\n",
      "Epoch 146: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.2752 - bpp: 1.1126 - mse: 2.6398e-04\n",
      "Epoch 147/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6752 - bpp: 1.1599 - mse: 3.0704e-04\n",
      "Epoch 147: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.6752 - bpp: 1.1599 - mse: 3.0704e-04\n",
      "Epoch 148/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0475 - bpp: 1.1413 - mse: 3.5476e-04\n",
      "Epoch 148: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 4.0475 - bpp: 1.1413 - mse: 3.5476e-04\n",
      "Epoch 149/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8996 - bpp: 1.1312 - mse: 3.3794e-04\n",
      "Epoch 149: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.8996 - bpp: 1.1312 - mse: 3.3794e-04\n",
      "Epoch 150/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8476 - bpp: 1.1411 - mse: 3.3039e-04\n",
      "Epoch 150: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.8476 - bpp: 1.1411 - mse: 3.3039e-04\n",
      "Epoch 151/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7071 - bpp: 1.1346 - mse: 3.1403e-04\n",
      "Epoch 151: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.7071 - bpp: 1.1346 - mse: 3.1403e-04\n",
      "Epoch 152/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5334 - bpp: 1.1374 - mse: 2.9249e-04\n",
      "Epoch 152: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.5334 - bpp: 1.1374 - mse: 2.9249e-04\n",
      "Epoch 153/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6152 - bpp: 1.1395 - mse: 3.0222e-04\n",
      "Epoch 153: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6152 - bpp: 1.1395 - mse: 3.0222e-04\n",
      "Epoch 154/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9360 - bpp: 1.1939 - mse: 5.7887e-04\n",
      "Epoch 154: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.9360 - bpp: 1.1939 - mse: 5.7887e-04\n",
      "Epoch 155/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0778 - bpp: 1.1332 - mse: 3.5945e-04\n",
      "Epoch 155: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.0778 - bpp: 1.1332 - mse: 3.5945e-04\n",
      "Epoch 156/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3314 - bpp: 1.1168 - mse: 2.7033e-04\n",
      "Epoch 156: loss did not improve from 3.24294\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.3314 - bpp: 1.1168 - mse: 2.7033e-04\n",
      "Epoch 157/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0464 - bpp: 1.1230 - mse: 2.3479e-04\n",
      "Epoch 157: loss improved from 3.24294 to 3.04639, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.0464 - bpp: 1.1230 - mse: 2.3479e-04\n",
      "Epoch 158/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7702 - bpp: 1.1402 - mse: 3.2105e-04\n",
      "Epoch 158: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.7702 - bpp: 1.1402 - mse: 3.2105e-04\n",
      "Epoch 159/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5070 - bpp: 1.1140 - mse: 2.9211e-04\n",
      "Epoch 159: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.5070 - bpp: 1.1140 - mse: 2.9211e-04\n",
      "Epoch 160/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4865 - bpp: 1.1186 - mse: 2.8904e-04\n",
      "Epoch 160: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.4865 - bpp: 1.1186 - mse: 2.8904e-04\n",
      "Epoch 161/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9831 - bpp: 1.1405 - mse: 3.4700e-04\n",
      "Epoch 161: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.9831 - bpp: 1.1405 - mse: 3.4700e-04\n",
      "Epoch 162/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1878 - bpp: 1.1438 - mse: 3.7158e-04\n",
      "Epoch 162: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 4.1878 - bpp: 1.1438 - mse: 3.7158e-04\n",
      "Epoch 163/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2903 - bpp: 1.0947 - mse: 2.6802e-04\n",
      "Epoch 163: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.2903 - bpp: 1.0947 - mse: 2.6802e-04\n",
      "Epoch 164/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5908 - bpp: 1.1395 - mse: 2.9923e-04\n",
      "Epoch 164: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 3.5908 - bpp: 1.1395 - mse: 2.9923e-04\n",
      "Epoch 165/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7421 - bpp: 1.1495 - mse: 3.1647e-04\n",
      "Epoch 165: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7421 - bpp: 1.1495 - mse: 3.1647e-04\n",
      "Epoch 166/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5783 - bpp: 1.1252 - mse: 2.9945e-04\n",
      "Epoch 166: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.5783 - bpp: 1.1252 - mse: 2.9945e-04\n",
      "Epoch 167/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3465 - bpp: 1.1066 - mse: 2.7343e-04\n",
      "Epoch 167: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3465 - bpp: 1.1066 - mse: 2.7343e-04\n",
      "Epoch 168/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2570 - bpp: 1.1030 - mse: 2.6294e-04\n",
      "Epoch 168: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.2570 - bpp: 1.1030 - mse: 2.6294e-04\n",
      "Epoch 169/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1639 - bpp: 1.1401 - mse: 3.6911e-04\n",
      "Epoch 169: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.1639 - bpp: 1.1401 - mse: 3.6911e-04\n",
      "Epoch 170/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3227 - bpp: 1.1172 - mse: 2.6923e-04\n",
      "Epoch 170: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.3227 - bpp: 1.1172 - mse: 2.6923e-04\n",
      "Epoch 171/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6940 - bpp: 1.1110 - mse: 3.1531e-04\n",
      "Epoch 171: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6940 - bpp: 1.1110 - mse: 3.1531e-04\n",
      "Epoch 172/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3750 - bpp: 1.1277 - mse: 2.7433e-04\n",
      "Epoch 172: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3750 - bpp: 1.1277 - mse: 2.7433e-04\n",
      "Epoch 173/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0654 - bpp: 1.1068 - mse: 2.3908e-04\n",
      "Epoch 173: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.0654 - bpp: 1.1068 - mse: 2.3908e-04\n",
      "Epoch 174/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7638 - bpp: 1.1412 - mse: 3.2013e-04\n",
      "Epoch 174: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 3.7638 - bpp: 1.1412 - mse: 3.2013e-04\n",
      "Epoch 175/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3192 - bpp: 1.0902 - mse: 2.7209e-04\n",
      "Epoch 175: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3192 - bpp: 1.0902 - mse: 2.7209e-04\n",
      "Epoch 176/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2101 - bpp: 1.0976 - mse: 2.5787e-04\n",
      "Epoch 176: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.2101 - bpp: 1.0976 - mse: 2.5787e-04\n",
      "Epoch 177/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7276 - bpp: 1.1315 - mse: 3.1691e-04\n",
      "Epoch 177: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.7276 - bpp: 1.1315 - mse: 3.1691e-04\n",
      "Epoch 178/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3185 - bpp: 1.1124 - mse: 2.6930e-04\n",
      "Epoch 178: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 3.3185 - bpp: 1.1124 - mse: 2.6930e-04\n",
      "Epoch 179/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2183 - bpp: 1.1073 - mse: 2.5770e-04\n",
      "Epoch 179: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2183 - bpp: 1.1073 - mse: 2.5770e-04\n",
      "Epoch 180/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9029 - bpp: 1.1616 - mse: 3.3463e-04\n",
      "Epoch 180: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.9029 - bpp: 1.1616 - mse: 3.3463e-04\n",
      "Epoch 181/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3708 - bpp: 1.1224 - mse: 2.7447e-04\n",
      "Epoch 181: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.3708 - bpp: 1.1224 - mse: 2.7447e-04\n",
      "Epoch 182/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7220 - bpp: 1.1387 - mse: 3.1535e-04\n",
      "Epoch 182: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.7220 - bpp: 1.1387 - mse: 3.1535e-04\n",
      "Epoch 183/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4073 - bpp: 1.1402 - mse: 2.7674e-04\n",
      "Epoch 183: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.4073 - bpp: 1.1402 - mse: 2.7674e-04\n",
      "Epoch 184/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1363 - bpp: 1.1145 - mse: 2.4680e-04\n",
      "Epoch 184: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.1363 - bpp: 1.1145 - mse: 2.4680e-04\n",
      "Epoch 185/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2112 - bpp: 1.1152 - mse: 2.5586e-04\n",
      "Epoch 185: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2112 - bpp: 1.1152 - mse: 2.5586e-04\n",
      "Epoch 186/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4172 - bpp: 1.1326 - mse: 2.7889e-04\n",
      "Epoch 186: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.4172 - bpp: 1.1326 - mse: 2.7889e-04\n",
      "Epoch 187/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3380 - bpp: 1.1317 - mse: 2.6932e-04\n",
      "Epoch 187: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.3380 - bpp: 1.1317 - mse: 2.6932e-04\n",
      "Epoch 188/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4575 - bpp: 1.1125 - mse: 2.8625e-04\n",
      "Epoch 188: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.4575 - bpp: 1.1125 - mse: 2.8625e-04\n",
      "Epoch 189/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3814 - bpp: 1.1499 - mse: 3.9448e-04\n",
      "Epoch 189: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.3814 - bpp: 1.1499 - mse: 3.9448e-04\n",
      "Epoch 190/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9722 - bpp: 1.1524 - mse: 3.4421e-04\n",
      "Epoch 190: loss did not improve from 3.04639\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.9722 - bpp: 1.1524 - mse: 3.4421e-04\n",
      "Epoch 191/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9112 - bpp: 1.0824 - mse: 2.2324e-04\n",
      "Epoch 191: loss improved from 3.04639 to 2.91116, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 2.9112 - bpp: 1.0824 - mse: 2.2324e-04\n",
      "Epoch 192/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8986 - bpp: 1.1619 - mse: 3.3408e-04\n",
      "Epoch 192: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.8986 - bpp: 1.1619 - mse: 3.3408e-04\n",
      "Epoch 193/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4400 - bpp: 1.1056 - mse: 2.8497e-04\n",
      "Epoch 193: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.4400 - bpp: 1.1056 - mse: 2.8497e-04\n",
      "Epoch 194/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2016 - bpp: 1.1132 - mse: 2.5493e-04\n",
      "Epoch 194: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.2016 - bpp: 1.1132 - mse: 2.5493e-04\n",
      "Epoch 195/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2815 - bpp: 1.1352 - mse: 2.6200e-04\n",
      "Epoch 195: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.2815 - bpp: 1.1352 - mse: 2.6200e-04\n",
      "Epoch 196/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9548 - bpp: 1.0871 - mse: 2.2799e-04\n",
      "Epoch 196: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9548 - bpp: 1.0871 - mse: 2.2799e-04\n",
      "Epoch 197/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3690 - bpp: 1.1263 - mse: 2.7378e-04\n",
      "Epoch 197: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.3690 - bpp: 1.1263 - mse: 2.7378e-04\n",
      "Epoch 198/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1655 - bpp: 1.1099 - mse: 2.5093e-04\n",
      "Epoch 198: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 3.1655 - bpp: 1.1099 - mse: 2.5093e-04\n",
      "Epoch 199/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7610 - bpp: 1.1171 - mse: 4.4481e-04\n",
      "Epoch 199: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 4.7610 - bpp: 1.1171 - mse: 4.4481e-04\n",
      "Epoch 200/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5690 - bpp: 1.1034 - mse: 3.0098e-04\n",
      "Epoch 200: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.5690 - bpp: 1.1034 - mse: 3.0098e-04\n",
      "Epoch 201/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1172 - bpp: 1.0982 - mse: 2.4646e-04\n",
      "Epoch 201: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.1172 - bpp: 1.0982 - mse: 2.4646e-04\n",
      "Epoch 202/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0943 - bpp: 1.0993 - mse: 2.4353e-04\n",
      "Epoch 202: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.0943 - bpp: 1.0993 - mse: 2.4353e-04\n",
      "Epoch 203/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2183 - bpp: 1.1170 - mse: 2.5650e-04\n",
      "Epoch 203: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 3.2183 - bpp: 1.1170 - mse: 2.5650e-04\n",
      "Epoch 204/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0100 - bpp: 1.0967 - mse: 2.3356e-04\n",
      "Epoch 204: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.0100 - bpp: 1.0967 - mse: 2.3356e-04\n",
      "Epoch 205/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1655 - bpp: 1.1210 - mse: 2.4957e-04\n",
      "Epoch 205: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 3.1655 - bpp: 1.1210 - mse: 2.4957e-04\n",
      "Epoch 206/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1677 - bpp: 1.0994 - mse: 2.5247e-04\n",
      "Epoch 206: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 3.1677 - bpp: 1.0994 - mse: 2.5247e-04\n",
      "Epoch 207/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3192 - bpp: 1.1156 - mse: 2.6899e-04\n",
      "Epoch 207: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3192 - bpp: 1.1156 - mse: 2.6899e-04\n",
      "Epoch 208/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0432 - bpp: 1.0951 - mse: 2.3781e-04\n",
      "Epoch 208: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.0432 - bpp: 1.0951 - mse: 2.3781e-04\n",
      "Epoch 209/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5597 - bpp: 1.1283 - mse: 2.9680e-04\n",
      "Epoch 209: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.5597 - bpp: 1.1283 - mse: 2.9680e-04\n",
      "Epoch 210/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0552 - bpp: 1.0960 - mse: 2.3916e-04\n",
      "Epoch 210: loss did not improve from 2.91116\n",
      "200/200 [==============================] - 25s 117ms/step - loss: 3.0552 - bpp: 1.0960 - mse: 2.3916e-04\n",
      "Epoch 211/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6437 - bpp: 1.0728 - mse: 1.9177e-04\n",
      "Epoch 211: loss improved from 2.91116 to 2.64370, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6437 - bpp: 1.0728 - mse: 1.9177e-04\n",
      "Epoch 212/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1697 - bpp: 1.0815 - mse: 2.5492e-04\n",
      "Epoch 212: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.1697 - bpp: 1.0815 - mse: 2.5492e-04\n",
      "Epoch 213/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9311 - bpp: 1.0833 - mse: 2.2556e-04\n",
      "Epoch 213: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9311 - bpp: 1.0833 - mse: 2.2556e-04\n",
      "Epoch 214/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0052 - bpp: 1.0961 - mse: 2.3305e-04\n",
      "Epoch 214: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.0052 - bpp: 1.0961 - mse: 2.3305e-04\n",
      "Epoch 215/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8240 - bpp: 1.0873 - mse: 2.1199e-04\n",
      "Epoch 215: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 26s 122ms/step - loss: 2.8240 - bpp: 1.0873 - mse: 2.1199e-04\n",
      "Epoch 216/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1666 - bpp: 1.1061 - mse: 2.5152e-04\n",
      "Epoch 216: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 3.1666 - bpp: 1.1061 - mse: 2.5152e-04\n",
      "Epoch 217/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2671 - bpp: 1.1045 - mse: 2.6399e-04\n",
      "Epoch 217: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 3.2671 - bpp: 1.1045 - mse: 2.6399e-04\n",
      "Epoch 218/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1311 - bpp: 1.0839 - mse: 2.4990e-04\n",
      "Epoch 218: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.1311 - bpp: 1.0839 - mse: 2.4990e-04\n",
      "Epoch 219/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1245 - bpp: 1.1045 - mse: 2.4658e-04\n",
      "Epoch 219: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.1245 - bpp: 1.1045 - mse: 2.4658e-04\n",
      "Epoch 220/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6882 - bpp: 1.0706 - mse: 1.9746e-04\n",
      "Epoch 220: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.6882 - bpp: 1.0706 - mse: 1.9746e-04\n",
      "Epoch 221/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0517 - bpp: 1.0739 - mse: 2.4143e-04\n",
      "Epoch 221: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.0517 - bpp: 1.0739 - mse: 2.4143e-04\n",
      "Epoch 222/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0306 - bpp: 1.0951 - mse: 2.3628e-04\n",
      "Epoch 222: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.0306 - bpp: 1.0951 - mse: 2.3628e-04\n",
      "Epoch 223/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1997 - bpp: 1.1228 - mse: 2.5352e-04\n",
      "Epoch 223: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 3.1997 - bpp: 1.1228 - mse: 2.5352e-04\n",
      "Epoch 224/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4298 - bpp: 1.1169 - mse: 2.8233e-04\n",
      "Epoch 224: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.4298 - bpp: 1.1169 - mse: 2.8233e-04\n",
      "Epoch 225/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1356 - bpp: 1.0983 - mse: 2.4869e-04\n",
      "Epoch 225: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.1356 - bpp: 1.0983 - mse: 2.4869e-04\n",
      "Epoch 226/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9364 - bpp: 1.0924 - mse: 2.2509e-04\n",
      "Epoch 226: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.9364 - bpp: 1.0924 - mse: 2.2509e-04\n",
      "Epoch 227/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8865 - bpp: 1.1007 - mse: 2.1799e-04\n",
      "Epoch 227: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.8865 - bpp: 1.1007 - mse: 2.1799e-04\n",
      "Epoch 228/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2281 - bpp: 1.0955 - mse: 2.6032e-04\n",
      "Epoch 228: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 3.2281 - bpp: 1.0955 - mse: 2.6032e-04\n",
      "Epoch 229/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9806 - bpp: 1.1067 - mse: 2.2875e-04\n",
      "Epoch 229: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 2.9806 - bpp: 1.1067 - mse: 2.2875e-04\n",
      "Epoch 230/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8236 - bpp: 1.0730 - mse: 2.1370e-04\n",
      "Epoch 230: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 115ms/step - loss: 2.8236 - bpp: 1.0730 - mse: 2.1370e-04\n",
      "Epoch 231/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4059 - bpp: 1.1160 - mse: 2.7953e-04\n",
      "Epoch 231: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.4059 - bpp: 1.1160 - mse: 2.7953e-04\n",
      "Epoch 232/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1507 - bpp: 1.0836 - mse: 2.5233e-04\n",
      "Epoch 232: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1507 - bpp: 1.0836 - mse: 2.5233e-04\n",
      "Epoch 233/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7176 - bpp: 1.0450 - mse: 2.0418e-04\n",
      "Epoch 233: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.7176 - bpp: 1.0450 - mse: 2.0418e-04\n",
      "Epoch 234/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9564 - bpp: 1.0810 - mse: 2.2894e-04\n",
      "Epoch 234: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.9564 - bpp: 1.0810 - mse: 2.2894e-04\n",
      "Epoch 235/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3098 - bpp: 1.0954 - mse: 2.7031e-04\n",
      "Epoch 235: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.3098 - bpp: 1.0954 - mse: 2.7031e-04\n",
      "Epoch 236/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0738 - bpp: 1.1003 - mse: 2.4091e-04\n",
      "Epoch 236: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.0738 - bpp: 1.1003 - mse: 2.4091e-04\n",
      "Epoch 237/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6613 - bpp: 1.0590 - mse: 1.9559e-04\n",
      "Epoch 237: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.6613 - bpp: 1.0590 - mse: 1.9559e-04\n",
      "Epoch 238/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8398 - bpp: 1.0856 - mse: 2.1413e-04\n",
      "Epoch 238: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8398 - bpp: 1.0856 - mse: 2.1413e-04\n",
      "Epoch 239/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5633 - bpp: 1.1242 - mse: 2.9773e-04\n",
      "Epoch 239: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.5633 - bpp: 1.1242 - mse: 2.9773e-04\n",
      "Epoch 240/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1678 - bpp: 1.0836 - mse: 2.5443e-04\n",
      "Epoch 240: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.1678 - bpp: 1.0836 - mse: 2.5443e-04\n",
      "Epoch 241/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7977 - bpp: 1.0797 - mse: 2.0971e-04\n",
      "Epoch 241: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.7977 - bpp: 1.0797 - mse: 2.0971e-04\n",
      "Epoch 242/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7882 - bpp: 1.0658 - mse: 2.1026e-04\n",
      "Epoch 242: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.7882 - bpp: 1.0658 - mse: 2.1026e-04\n",
      "Epoch 243/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1370 - bpp: 1.1010 - mse: 2.4854e-04\n",
      "Epoch 243: loss did not improve from 2.64370\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 3.1370 - bpp: 1.1010 - mse: 2.4854e-04\n",
      "Epoch 244/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5353 - bpp: 1.0515 - mse: 1.8113e-04\n",
      "Epoch 244: loss improved from 2.64370 to 2.53527, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5353 - bpp: 1.0515 - mse: 1.8113e-04\n",
      "Epoch 245/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8756 - bpp: 1.0768 - mse: 2.1958e-04\n",
      "Epoch 245: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8756 - bpp: 1.0768 - mse: 2.1958e-04\n",
      "Epoch 246/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0933 - bpp: 1.0757 - mse: 2.4629e-04\n",
      "Epoch 246: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.0933 - bpp: 1.0757 - mse: 2.4629e-04\n",
      "Epoch 247/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8111 - bpp: 1.0836 - mse: 2.1087e-04\n",
      "Epoch 247: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.8111 - bpp: 1.0836 - mse: 2.1087e-04\n",
      "Epoch 248/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6921 - bpp: 1.0526 - mse: 2.0014e-04\n",
      "Epoch 248: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.6921 - bpp: 1.0526 - mse: 2.0014e-04\n",
      "Epoch 249/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9662 - bpp: 1.0738 - mse: 2.3101e-04\n",
      "Epoch 249: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.9662 - bpp: 1.0738 - mse: 2.3101e-04\n",
      "Epoch 250/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9323 - bpp: 1.0811 - mse: 2.2597e-04\n",
      "Epoch 250: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9323 - bpp: 1.0811 - mse: 2.2597e-04\n",
      "Epoch 251/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1016 - bpp: 1.0925 - mse: 2.4526e-04\n",
      "Epoch 251: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.1016 - bpp: 1.0925 - mse: 2.4526e-04\n",
      "Epoch 252/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9355 - bpp: 1.0922 - mse: 2.2500e-04\n",
      "Epoch 252: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.9355 - bpp: 1.0922 - mse: 2.2500e-04\n",
      "Epoch 253/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3840 - bpp: 1.0920 - mse: 2.7978e-04\n",
      "Epoch 253: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3840 - bpp: 1.0920 - mse: 2.7978e-04\n",
      "Epoch 254/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7477 - bpp: 1.0588 - mse: 2.0616e-04\n",
      "Epoch 254: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.7477 - bpp: 1.0588 - mse: 2.0616e-04\n",
      "Epoch 255/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8893 - bpp: 1.0700 - mse: 2.2209e-04\n",
      "Epoch 255: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8893 - bpp: 1.0700 - mse: 2.2209e-04\n",
      "Epoch 256/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0749 - bpp: 1.1053 - mse: 2.4043e-04\n",
      "Epoch 256: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.0749 - bpp: 1.1053 - mse: 2.4043e-04\n",
      "Epoch 257/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8063 - bpp: 1.0822 - mse: 2.1047e-04\n",
      "Epoch 257: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.8063 - bpp: 1.0822 - mse: 2.1047e-04\n",
      "Epoch 258/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1203 - bpp: 1.0874 - mse: 2.4815e-04\n",
      "Epoch 258: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1203 - bpp: 1.0874 - mse: 2.4815e-04\n",
      "Epoch 259/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7170 - bpp: 1.0862 - mse: 1.9908e-04\n",
      "Epoch 259: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.7170 - bpp: 1.0862 - mse: 1.9908e-04\n",
      "Epoch 260/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9895 - bpp: 1.0771 - mse: 2.3345e-04\n",
      "Epoch 260: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9895 - bpp: 1.0771 - mse: 2.3345e-04\n",
      "Epoch 261/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6330 - bpp: 1.1135 - mse: 3.0756e-04\n",
      "Epoch 261: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 3.6330 - bpp: 1.1135 - mse: 3.0756e-04\n",
      "Epoch 262/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7974 - bpp: 1.0544 - mse: 2.1277e-04\n",
      "Epoch 262: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 2.7974 - bpp: 1.0544 - mse: 2.1277e-04\n",
      "Epoch 263/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8591 - bpp: 1.0789 - mse: 2.1731e-04\n",
      "Epoch 263: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8591 - bpp: 1.0789 - mse: 2.1731e-04\n",
      "Epoch 264/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9702 - bpp: 1.0841 - mse: 2.3024e-04\n",
      "Epoch 264: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9702 - bpp: 1.0841 - mse: 2.3024e-04\n",
      "Epoch 265/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2007 - bpp: 1.0934 - mse: 2.5724e-04\n",
      "Epoch 265: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2007 - bpp: 1.0934 - mse: 2.5724e-04\n",
      "Epoch 266/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9243 - bpp: 1.0797 - mse: 2.2518e-04\n",
      "Epoch 266: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.9243 - bpp: 1.0797 - mse: 2.2518e-04\n",
      "Epoch 267/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7533 - bpp: 1.0611 - mse: 2.0656e-04\n",
      "Epoch 267: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.7533 - bpp: 1.0611 - mse: 2.0656e-04\n",
      "Epoch 268/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1253 - bpp: 1.1117 - mse: 2.4579e-04\n",
      "Epoch 268: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.1253 - bpp: 1.1117 - mse: 2.4579e-04\n",
      "Epoch 269/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7713 - bpp: 1.0461 - mse: 2.1060e-04\n",
      "Epoch 269: loss did not improve from 2.53527\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.7713 - bpp: 1.0461 - mse: 2.1060e-04\n",
      "Epoch 270/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5098 - bpp: 1.0329 - mse: 1.8028e-04\n",
      "Epoch 270: loss improved from 2.53527 to 2.50978, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5098 - bpp: 1.0329 - mse: 1.8028e-04\n",
      "Epoch 271/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7671 - bpp: 1.0689 - mse: 2.0730e-04\n",
      "Epoch 271: loss did not improve from 2.50978\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 2.7671 - bpp: 1.0689 - mse: 2.0730e-04\n",
      "Epoch 272/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8559 - bpp: 1.0800 - mse: 2.1679e-04\n",
      "Epoch 272: loss did not improve from 2.50978\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.8559 - bpp: 1.0800 - mse: 2.1679e-04\n",
      "Epoch 273/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4831 - bpp: 1.0485 - mse: 1.7513e-04\n",
      "Epoch 273: loss improved from 2.50978 to 2.48314, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4831 - bpp: 1.0485 - mse: 1.7513e-04\n",
      "Epoch 274/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9767 - bpp: 1.0991 - mse: 2.2920e-04\n",
      "Epoch 274: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.9767 - bpp: 1.0991 - mse: 2.2920e-04\n",
      "Epoch 275/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8910 - bpp: 1.0887 - mse: 2.2001e-04\n",
      "Epoch 275: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.8910 - bpp: 1.0887 - mse: 2.2001e-04\n",
      "Epoch 276/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8240 - bpp: 1.0898 - mse: 2.1169e-04\n",
      "Epoch 276: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8240 - bpp: 1.0898 - mse: 2.1169e-04\n",
      "Epoch 277/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8131 - bpp: 1.0784 - mse: 2.1175e-04\n",
      "Epoch 277: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8131 - bpp: 1.0784 - mse: 2.1175e-04\n",
      "Epoch 278/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9545 - bpp: 1.0875 - mse: 2.2789e-04\n",
      "Epoch 278: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.9545 - bpp: 1.0875 - mse: 2.2789e-04\n",
      "Epoch 279/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8170 - bpp: 1.0637 - mse: 2.1403e-04\n",
      "Epoch 279: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8170 - bpp: 1.0637 - mse: 2.1403e-04\n",
      "Epoch 280/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2184 - bpp: 1.1030 - mse: 2.5822e-04\n",
      "Epoch 280: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 3.2184 - bpp: 1.1030 - mse: 2.5822e-04\n",
      "Epoch 281/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8922 - bpp: 1.0751 - mse: 2.2182e-04\n",
      "Epoch 281: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.8922 - bpp: 1.0751 - mse: 2.2182e-04\n",
      "Epoch 282/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7584 - bpp: 1.0644 - mse: 2.0679e-04\n",
      "Epoch 282: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.7584 - bpp: 1.0644 - mse: 2.0679e-04\n",
      "Epoch 283/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6950 - bpp: 1.0628 - mse: 1.9924e-04\n",
      "Epoch 283: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.6950 - bpp: 1.0628 - mse: 1.9924e-04\n",
      "Epoch 284/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5613 - bpp: 1.0545 - mse: 1.8393e-04\n",
      "Epoch 284: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5613 - bpp: 1.0545 - mse: 1.8393e-04\n",
      "Epoch 285/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0715 - bpp: 1.1353 - mse: 2.3635e-04\n",
      "Epoch 285: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 3.0715 - bpp: 1.1353 - mse: 2.3635e-04\n",
      "Epoch 286/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1582 - bpp: 1.1154 - mse: 2.4936e-04\n",
      "Epoch 286: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.1582 - bpp: 1.1154 - mse: 2.4936e-04\n",
      "Epoch 287/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8185 - bpp: 1.0716 - mse: 2.1325e-04\n",
      "Epoch 287: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8185 - bpp: 1.0716 - mse: 2.1325e-04\n",
      "Epoch 288/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9169 - bpp: 1.0740 - mse: 2.2496e-04\n",
      "Epoch 288: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.9169 - bpp: 1.0740 - mse: 2.2496e-04\n",
      "Epoch 289/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8770 - bpp: 1.0559 - mse: 2.2231e-04\n",
      "Epoch 289: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8770 - bpp: 1.0559 - mse: 2.2231e-04\n",
      "Epoch 290/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8678 - bpp: 1.0556 - mse: 2.2122e-04\n",
      "Epoch 290: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.8678 - bpp: 1.0556 - mse: 2.2122e-04\n",
      "Epoch 291/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6677 - bpp: 1.0706 - mse: 1.9496e-04\n",
      "Epoch 291: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.6677 - bpp: 1.0706 - mse: 1.9496e-04\n",
      "Epoch 292/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5798 - bpp: 1.0539 - mse: 1.8627e-04\n",
      "Epoch 292: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.5798 - bpp: 1.0539 - mse: 1.8627e-04\n",
      "Epoch 293/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9411 - bpp: 1.0783 - mse: 2.2740e-04\n",
      "Epoch 293: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9411 - bpp: 1.0783 - mse: 2.2740e-04\n",
      "Epoch 294/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8481 - bpp: 1.0758 - mse: 2.1634e-04\n",
      "Epoch 294: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.8481 - bpp: 1.0758 - mse: 2.1634e-04\n",
      "Epoch 295/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6012 - bpp: 1.0410 - mse: 1.9045e-04\n",
      "Epoch 295: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.6012 - bpp: 1.0410 - mse: 1.9045e-04\n",
      "Epoch 296/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7465 - bpp: 1.0845 - mse: 2.0288e-04\n",
      "Epoch 296: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.7465 - bpp: 1.0845 - mse: 2.0288e-04\n",
      "Epoch 297/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9245 - bpp: 1.0848 - mse: 2.2457e-04\n",
      "Epoch 297: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.9245 - bpp: 1.0848 - mse: 2.2457e-04\n",
      "Epoch 298/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6115 - bpp: 1.0549 - mse: 1.9001e-04\n",
      "Epoch 298: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.6115 - bpp: 1.0549 - mse: 1.9001e-04\n",
      "Epoch 299/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5834 - bpp: 1.0630 - mse: 1.8559e-04\n",
      "Epoch 299: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5834 - bpp: 1.0630 - mse: 1.8559e-04\n",
      "Epoch 300/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7047 - bpp: 1.0595 - mse: 2.0083e-04\n",
      "Epoch 300: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.7047 - bpp: 1.0595 - mse: 2.0083e-04\n",
      "Epoch 301/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7194 - bpp: 1.0562 - mse: 2.0303e-04\n",
      "Epoch 301: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.7194 - bpp: 1.0562 - mse: 2.0303e-04\n",
      "Epoch 302/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6906 - bpp: 1.0672 - mse: 1.9817e-04\n",
      "Epoch 302: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.6906 - bpp: 1.0672 - mse: 1.9817e-04\n",
      "Epoch 303/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0201 - bpp: 1.1085 - mse: 2.3335e-04\n",
      "Epoch 303: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.0201 - bpp: 1.1085 - mse: 2.3335e-04\n",
      "Epoch 304/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4855 - bpp: 1.0637 - mse: 1.7357e-04\n",
      "Epoch 304: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.4855 - bpp: 1.0637 - mse: 1.7357e-04\n",
      "Epoch 305/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8511 - bpp: 1.0594 - mse: 2.1871e-04\n",
      "Epoch 305: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.8511 - bpp: 1.0594 - mse: 2.1871e-04\n",
      "Epoch 306/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7994 - bpp: 1.0642 - mse: 2.1182e-04\n",
      "Epoch 306: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.7994 - bpp: 1.0642 - mse: 2.1182e-04\n",
      "Epoch 307/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5772 - bpp: 1.0313 - mse: 1.8871e-04\n",
      "Epoch 307: loss did not improve from 2.48314\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.5772 - bpp: 1.0313 - mse: 1.8871e-04\n",
      "Epoch 308/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4781 - bpp: 1.0382 - mse: 1.7577e-04\n",
      "Epoch 308: loss improved from 2.48314 to 2.47808, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4781 - bpp: 1.0382 - mse: 1.7577e-04\n",
      "Epoch 309/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6334 - bpp: 1.0582 - mse: 1.9229e-04\n",
      "Epoch 309: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 2.6334 - bpp: 1.0582 - mse: 1.9229e-04\n",
      "Epoch 310/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8982 - bpp: 1.0710 - mse: 2.2304e-04\n",
      "Epoch 310: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.8982 - bpp: 1.0710 - mse: 2.2304e-04\n",
      "Epoch 311/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8344 - bpp: 1.0595 - mse: 2.1667e-04\n",
      "Epoch 311: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.8344 - bpp: 1.0595 - mse: 2.1667e-04\n",
      "Epoch 312/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7730 - bpp: 1.0596 - mse: 2.0915e-04\n",
      "Epoch 312: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.7730 - bpp: 1.0596 - mse: 2.0915e-04\n",
      "Epoch 313/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7060 - bpp: 1.0753 - mse: 1.9906e-04\n",
      "Epoch 313: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.7060 - bpp: 1.0753 - mse: 1.9906e-04\n",
      "Epoch 314/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5358 - bpp: 1.0284 - mse: 1.8400e-04\n",
      "Epoch 314: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 2.5358 - bpp: 1.0284 - mse: 1.8400e-04\n",
      "Epoch 315/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9108 - bpp: 1.0867 - mse: 2.2267e-04\n",
      "Epoch 315: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.9108 - bpp: 1.0867 - mse: 2.2267e-04\n",
      "Epoch 316/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5987 - bpp: 1.0572 - mse: 1.8818e-04\n",
      "Epoch 316: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 2.5987 - bpp: 1.0572 - mse: 1.8818e-04\n",
      "Epoch 317/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7901 - bpp: 1.0675 - mse: 2.1027e-04\n",
      "Epoch 317: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.7901 - bpp: 1.0675 - mse: 2.1027e-04\n",
      "Epoch 318/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7219 - bpp: 1.0533 - mse: 2.0368e-04\n",
      "Epoch 318: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.7219 - bpp: 1.0533 - mse: 2.0368e-04\n",
      "Epoch 319/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5721 - bpp: 1.0419 - mse: 1.8679e-04\n",
      "Epoch 319: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5721 - bpp: 1.0419 - mse: 1.8679e-04\n",
      "Epoch 320/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9398 - bpp: 1.0708 - mse: 2.2814e-04\n",
      "Epoch 320: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9398 - bpp: 1.0708 - mse: 2.2814e-04\n",
      "Epoch 321/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6314 - bpp: 1.0557 - mse: 1.9234e-04\n",
      "Epoch 321: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 2.6314 - bpp: 1.0557 - mse: 1.9234e-04\n",
      "Epoch 322/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6915 - bpp: 1.0775 - mse: 1.9702e-04\n",
      "Epoch 322: loss did not improve from 2.47808\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.6915 - bpp: 1.0775 - mse: 1.9702e-04\n",
      "Epoch 323/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4648 - bpp: 1.0386 - mse: 1.7410e-04\n",
      "Epoch 323: loss improved from 2.47808 to 2.46484, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4648 - bpp: 1.0386 - mse: 1.7410e-04\n",
      "Epoch 324/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9223 - bpp: 1.0564 - mse: 2.2777e-04\n",
      "Epoch 324: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.9223 - bpp: 1.0564 - mse: 2.2777e-04\n",
      "Epoch 325/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9389 - bpp: 1.0658 - mse: 2.2865e-04\n",
      "Epoch 325: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9389 - bpp: 1.0658 - mse: 2.2865e-04\n",
      "Epoch 326/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8267 - bpp: 1.0420 - mse: 2.1786e-04\n",
      "Epoch 326: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8267 - bpp: 1.0420 - mse: 2.1786e-04\n",
      "Epoch 327/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6616 - bpp: 1.0688 - mse: 1.9443e-04\n",
      "Epoch 327: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6616 - bpp: 1.0688 - mse: 1.9443e-04\n",
      "Epoch 328/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8574 - bpp: 1.0645 - mse: 2.1886e-04\n",
      "Epoch 328: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8574 - bpp: 1.0645 - mse: 2.1886e-04\n",
      "Epoch 329/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0219 - bpp: 1.0963 - mse: 2.3506e-04\n",
      "Epoch 329: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 3.0219 - bpp: 1.0963 - mse: 2.3506e-04\n",
      "Epoch 330/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5278 - bpp: 1.0427 - mse: 1.8130e-04\n",
      "Epoch 330: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5278 - bpp: 1.0427 - mse: 1.8130e-04\n",
      "Epoch 331/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6360 - bpp: 1.0373 - mse: 1.9515e-04\n",
      "Epoch 331: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6360 - bpp: 1.0373 - mse: 1.9515e-04\n",
      "Epoch 332/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7190 - bpp: 1.0286 - mse: 2.0634e-04\n",
      "Epoch 332: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7190 - bpp: 1.0286 - mse: 2.0634e-04\n",
      "Epoch 333/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6413 - bpp: 1.0453 - mse: 1.9482e-04\n",
      "Epoch 333: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.6413 - bpp: 1.0453 - mse: 1.9482e-04\n",
      "Epoch 334/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5004 - bpp: 1.0499 - mse: 1.7706e-04\n",
      "Epoch 334: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5004 - bpp: 1.0499 - mse: 1.7706e-04\n",
      "Epoch 335/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4694 - bpp: 1.0008 - mse: 1.7928e-04\n",
      "Epoch 335: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4694 - bpp: 1.0008 - mse: 1.7928e-04\n",
      "Epoch 336/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8934 - bpp: 1.0770 - mse: 2.2173e-04\n",
      "Epoch 336: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8934 - bpp: 1.0770 - mse: 2.2173e-04\n",
      "Epoch 337/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5840 - bpp: 1.0361 - mse: 1.8896e-04\n",
      "Epoch 337: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5840 - bpp: 1.0361 - mse: 1.8896e-04\n",
      "Epoch 338/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7196 - bpp: 1.0598 - mse: 2.0261e-04\n",
      "Epoch 338: loss did not improve from 2.46484\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.7196 - bpp: 1.0598 - mse: 2.0261e-04\n",
      "Epoch 339/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4601 - bpp: 1.0395 - mse: 1.7342e-04\n",
      "Epoch 339: loss improved from 2.46484 to 2.46011, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4601 - bpp: 1.0395 - mse: 1.7342e-04\n",
      "Epoch 340/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7329 - bpp: 1.0371 - mse: 2.0701e-04\n",
      "Epoch 340: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7329 - bpp: 1.0371 - mse: 2.0701e-04\n",
      "Epoch 341/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7634 - bpp: 1.0627 - mse: 2.0762e-04\n",
      "Epoch 341: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.7634 - bpp: 1.0627 - mse: 2.0762e-04\n",
      "Epoch 342/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6899 - bpp: 1.0589 - mse: 1.9909e-04\n",
      "Epoch 342: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6899 - bpp: 1.0589 - mse: 1.9909e-04\n",
      "Epoch 343/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5310 - bpp: 1.0411 - mse: 1.8188e-04\n",
      "Epoch 343: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5310 - bpp: 1.0411 - mse: 1.8188e-04\n",
      "Epoch 344/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7131 - bpp: 1.0525 - mse: 2.0271e-04\n",
      "Epoch 344: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7131 - bpp: 1.0525 - mse: 2.0271e-04\n",
      "Epoch 345/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6095 - bpp: 1.0649 - mse: 1.8856e-04\n",
      "Epoch 345: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6095 - bpp: 1.0649 - mse: 1.8856e-04\n",
      "Epoch 346/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4719 - bpp: 1.0421 - mse: 1.7454e-04\n",
      "Epoch 346: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4719 - bpp: 1.0421 - mse: 1.7454e-04\n",
      "Epoch 347/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4907 - bpp: 1.0320 - mse: 1.7805e-04\n",
      "Epoch 347: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.4907 - bpp: 1.0320 - mse: 1.7805e-04\n",
      "Epoch 348/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5970 - bpp: 1.0215 - mse: 1.9232e-04\n",
      "Epoch 348: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5970 - bpp: 1.0215 - mse: 1.9232e-04\n",
      "Epoch 349/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8641 - bpp: 1.0629 - mse: 2.1987e-04\n",
      "Epoch 349: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8641 - bpp: 1.0629 - mse: 2.1987e-04\n",
      "Epoch 350/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5831 - bpp: 1.0561 - mse: 1.8641e-04\n",
      "Epoch 350: loss did not improve from 2.46011\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.5831 - bpp: 1.0561 - mse: 1.8641e-04\n",
      "Epoch 351/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3819 - bpp: 1.0035 - mse: 1.6827e-04\n",
      "Epoch 351: loss improved from 2.46011 to 2.38190, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3819 - bpp: 1.0035 - mse: 1.6827e-04\n",
      "Epoch 352/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4502 - bpp: 1.0525 - mse: 1.7062e-04\n",
      "Epoch 352: loss did not improve from 2.38190\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4502 - bpp: 1.0525 - mse: 1.7062e-04\n",
      "Epoch 353/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5632 - bpp: 1.0461 - mse: 1.8520e-04\n",
      "Epoch 353: loss did not improve from 2.38190\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5632 - bpp: 1.0461 - mse: 1.8520e-04\n",
      "Epoch 354/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4626 - bpp: 1.0347 - mse: 1.7430e-04\n",
      "Epoch 354: loss did not improve from 2.38190\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4626 - bpp: 1.0347 - mse: 1.7430e-04\n",
      "Epoch 355/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3594 - bpp: 1.0184 - mse: 1.6370e-04\n",
      "Epoch 355: loss improved from 2.38190 to 2.35940, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 2.3594 - bpp: 1.0184 - mse: 1.6370e-04\n",
      "Epoch 356/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5414 - bpp: 1.0347 - mse: 1.8391e-04\n",
      "Epoch 356: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5414 - bpp: 1.0347 - mse: 1.8391e-04\n",
      "Epoch 357/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5305 - bpp: 1.0435 - mse: 1.8152e-04\n",
      "Epoch 357: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5305 - bpp: 1.0435 - mse: 1.8152e-04\n",
      "Epoch 358/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5412 - bpp: 1.0428 - mse: 1.8291e-04\n",
      "Epoch 358: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5412 - bpp: 1.0428 - mse: 1.8291e-04\n",
      "Epoch 359/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3996 - bpp: 1.0336 - mse: 1.6675e-04\n",
      "Epoch 359: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.3996 - bpp: 1.0336 - mse: 1.6675e-04\n",
      "Epoch 360/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6011 - bpp: 1.0376 - mse: 1.9086e-04\n",
      "Epoch 360: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6011 - bpp: 1.0376 - mse: 1.9086e-04\n",
      "Epoch 361/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9121 - bpp: 1.0809 - mse: 2.2353e-04\n",
      "Epoch 361: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9121 - bpp: 1.0809 - mse: 2.2353e-04\n",
      "Epoch 362/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4208 - bpp: 1.0296 - mse: 1.6982e-04\n",
      "Epoch 362: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4208 - bpp: 1.0296 - mse: 1.6982e-04\n",
      "Epoch 363/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8578 - bpp: 1.0494 - mse: 2.2076e-04\n",
      "Epoch 363: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8578 - bpp: 1.0494 - mse: 2.2076e-04\n",
      "Epoch 364/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5227 - bpp: 1.0229 - mse: 1.8308e-04\n",
      "Epoch 364: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.5227 - bpp: 1.0229 - mse: 1.8308e-04\n",
      "Epoch 365/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6034 - bpp: 1.0271 - mse: 1.9242e-04\n",
      "Epoch 365: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6034 - bpp: 1.0271 - mse: 1.9242e-04\n",
      "Epoch 366/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4730 - bpp: 1.0011 - mse: 1.7968e-04\n",
      "Epoch 366: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.4730 - bpp: 1.0011 - mse: 1.7968e-04\n",
      "Epoch 367/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5683 - bpp: 1.0289 - mse: 1.8792e-04\n",
      "Epoch 367: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5683 - bpp: 1.0289 - mse: 1.8792e-04\n",
      "Epoch 368/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5690 - bpp: 1.0409 - mse: 1.8654e-04\n",
      "Epoch 368: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.5690 - bpp: 1.0409 - mse: 1.8654e-04\n",
      "Epoch 369/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8137 - bpp: 1.0722 - mse: 2.1258e-04\n",
      "Epoch 369: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.8137 - bpp: 1.0722 - mse: 2.1258e-04\n",
      "Epoch 370/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6662 - bpp: 1.0569 - mse: 1.9644e-04\n",
      "Epoch 370: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6662 - bpp: 1.0569 - mse: 1.9644e-04\n",
      "Epoch 371/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5587 - bpp: 1.0235 - mse: 1.8740e-04\n",
      "Epoch 371: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5587 - bpp: 1.0235 - mse: 1.8740e-04\n",
      "Epoch 372/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4501 - bpp: 1.0308 - mse: 1.7325e-04\n",
      "Epoch 372: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4501 - bpp: 1.0308 - mse: 1.7325e-04\n",
      "Epoch 373/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5103 - bpp: 1.0225 - mse: 1.8162e-04\n",
      "Epoch 373: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5103 - bpp: 1.0225 - mse: 1.8162e-04\n",
      "Epoch 374/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4694 - bpp: 1.0119 - mse: 1.7792e-04\n",
      "Epoch 374: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 2.4694 - bpp: 1.0119 - mse: 1.7792e-04\n",
      "Epoch 375/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5007 - bpp: 1.0264 - mse: 1.7996e-04\n",
      "Epoch 375: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5007 - bpp: 1.0264 - mse: 1.7996e-04\n",
      "Epoch 376/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4030 - bpp: 1.0239 - mse: 1.6835e-04\n",
      "Epoch 376: loss did not improve from 2.35940\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4030 - bpp: 1.0239 - mse: 1.6835e-04\n",
      "Epoch 377/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2916 - bpp: 0.9999 - mse: 1.5769e-04\n",
      "Epoch 377: loss improved from 2.35940 to 2.29165, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.2916 - bpp: 0.9999 - mse: 1.5769e-04\n",
      "Epoch 378/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4268 - bpp: 1.0198 - mse: 1.7175e-04\n",
      "Epoch 378: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4268 - bpp: 1.0198 - mse: 1.7175e-04\n",
      "Epoch 379/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4763 - bpp: 1.0104 - mse: 1.7894e-04\n",
      "Epoch 379: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4763 - bpp: 1.0104 - mse: 1.7894e-04\n",
      "Epoch 380/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4972 - bpp: 1.0279 - mse: 1.7936e-04\n",
      "Epoch 380: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4972 - bpp: 1.0279 - mse: 1.7936e-04\n",
      "Epoch 381/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3504 - bpp: 0.9990 - mse: 1.6497e-04\n",
      "Epoch 381: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3504 - bpp: 0.9990 - mse: 1.6497e-04\n",
      "Epoch 382/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5744 - bpp: 1.0380 - mse: 1.8755e-04\n",
      "Epoch 382: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5744 - bpp: 1.0380 - mse: 1.8755e-04\n",
      "Epoch 383/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3778 - bpp: 1.0003 - mse: 1.6815e-04\n",
      "Epoch 383: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.3778 - bpp: 1.0003 - mse: 1.6815e-04\n",
      "Epoch 384/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4551 - bpp: 1.0367 - mse: 1.7315e-04\n",
      "Epoch 384: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4551 - bpp: 1.0367 - mse: 1.7315e-04\n",
      "Epoch 385/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5096 - bpp: 1.0378 - mse: 1.7967e-04\n",
      "Epoch 385: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5096 - bpp: 1.0378 - mse: 1.7967e-04\n",
      "Epoch 386/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4822 - bpp: 1.0309 - mse: 1.7715e-04\n",
      "Epoch 386: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4822 - bpp: 1.0309 - mse: 1.7715e-04\n",
      "Epoch 387/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6321 - bpp: 1.0244 - mse: 1.9626e-04\n",
      "Epoch 387: loss did not improve from 2.29165\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6321 - bpp: 1.0244 - mse: 1.9626e-04\n",
      "Epoch 388/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0281 - bpp: 0.9663 - mse: 1.2962e-04\n",
      "Epoch 388: loss improved from 2.29165 to 2.02808, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.0281 - bpp: 0.9663 - mse: 1.2962e-04\n",
      "Epoch 389/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8008 - bpp: 1.0829 - mse: 2.0970e-04\n",
      "Epoch 389: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8008 - bpp: 1.0829 - mse: 2.0970e-04\n",
      "Epoch 390/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3438 - bpp: 1.0145 - mse: 1.6227e-04\n",
      "Epoch 390: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3438 - bpp: 1.0145 - mse: 1.6227e-04\n",
      "Epoch 391/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7219 - bpp: 1.0595 - mse: 2.0293e-04\n",
      "Epoch 391: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7219 - bpp: 1.0595 - mse: 2.0293e-04\n",
      "Epoch 392/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5791 - bpp: 1.0325 - mse: 1.8879e-04\n",
      "Epoch 392: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5791 - bpp: 1.0325 - mse: 1.8879e-04\n",
      "Epoch 393/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5606 - bpp: 1.0221 - mse: 1.8780e-04\n",
      "Epoch 393: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.5606 - bpp: 1.0221 - mse: 1.8780e-04\n",
      "Epoch 394/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5405 - bpp: 1.0279 - mse: 1.8465e-04\n",
      "Epoch 394: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5405 - bpp: 1.0279 - mse: 1.8465e-04\n",
      "Epoch 395/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8961 - bpp: 1.0548 - mse: 2.2476e-04\n",
      "Epoch 395: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.8961 - bpp: 1.0548 - mse: 2.2476e-04\n",
      "Epoch 396/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4642 - bpp: 1.0255 - mse: 1.7562e-04\n",
      "Epoch 396: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4642 - bpp: 1.0255 - mse: 1.7562e-04\n",
      "Epoch 397/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3240 - bpp: 1.0016 - mse: 1.6143e-04\n",
      "Epoch 397: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3240 - bpp: 1.0016 - mse: 1.6143e-04\n",
      "Epoch 398/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8512 - bpp: 1.0585 - mse: 2.1883e-04\n",
      "Epoch 398: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8512 - bpp: 1.0585 - mse: 2.1883e-04\n",
      "Epoch 399/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2803 - bpp: 0.9906 - mse: 1.5743e-04\n",
      "Epoch 399: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 27s 131ms/step - loss: 2.2803 - bpp: 0.9906 - mse: 1.5743e-04\n",
      "Epoch 400/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4917 - bpp: 1.0274 - mse: 1.7874e-04\n",
      "Epoch 400: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4917 - bpp: 1.0274 - mse: 1.7874e-04\n",
      "Epoch 401/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4849 - bpp: 0.9991 - mse: 1.8137e-04\n",
      "Epoch 401: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4849 - bpp: 0.9991 - mse: 1.8137e-04\n",
      "Epoch 402/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4203 - bpp: 1.0106 - mse: 1.7208e-04\n",
      "Epoch 402: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4203 - bpp: 1.0106 - mse: 1.7208e-04\n",
      "Epoch 403/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3051 - bpp: 1.0036 - mse: 1.5887e-04\n",
      "Epoch 403: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.3051 - bpp: 1.0036 - mse: 1.5887e-04\n",
      "Epoch 404/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2364 - bpp: 0.9898 - mse: 1.5216e-04\n",
      "Epoch 404: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2364 - bpp: 0.9898 - mse: 1.5216e-04\n",
      "Epoch 405/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2954 - bpp: 1.0136 - mse: 1.5646e-04\n",
      "Epoch 405: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.2954 - bpp: 1.0136 - mse: 1.5646e-04\n",
      "Epoch 406/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3985 - bpp: 1.0235 - mse: 1.6785e-04\n",
      "Epoch 406: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3985 - bpp: 1.0235 - mse: 1.6785e-04\n",
      "Epoch 407/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2694 - bpp: 1.0054 - mse: 1.5430e-04\n",
      "Epoch 407: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2694 - bpp: 1.0054 - mse: 1.5430e-04\n",
      "Epoch 408/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2718 - bpp: 0.9789 - mse: 1.5783e-04\n",
      "Epoch 408: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2718 - bpp: 0.9789 - mse: 1.5783e-04\n",
      "Epoch 409/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3609 - bpp: 1.0226 - mse: 1.6337e-04\n",
      "Epoch 409: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3609 - bpp: 1.0226 - mse: 1.6337e-04\n",
      "Epoch 410/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1022 - bpp: 0.9713 - mse: 1.3806e-04\n",
      "Epoch 410: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.1022 - bpp: 0.9713 - mse: 1.3806e-04\n",
      "Epoch 411/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3475 - bpp: 1.0060 - mse: 1.6376e-04\n",
      "Epoch 411: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3475 - bpp: 1.0060 - mse: 1.6376e-04\n",
      "Epoch 412/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3662 - bpp: 1.0073 - mse: 1.6588e-04\n",
      "Epoch 412: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3662 - bpp: 1.0073 - mse: 1.6588e-04\n",
      "Epoch 413/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5106 - bpp: 1.0269 - mse: 1.8111e-04\n",
      "Epoch 413: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5106 - bpp: 1.0269 - mse: 1.8111e-04\n",
      "Epoch 414/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3916 - bpp: 1.0101 - mse: 1.6865e-04\n",
      "Epoch 414: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3916 - bpp: 1.0101 - mse: 1.6865e-04\n",
      "Epoch 415/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3396 - bpp: 0.9922 - mse: 1.6448e-04\n",
      "Epoch 415: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3396 - bpp: 0.9922 - mse: 1.6448e-04\n",
      "Epoch 416/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3059 - bpp: 0.9709 - mse: 1.6297e-04\n",
      "Epoch 416: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3059 - bpp: 0.9709 - mse: 1.6297e-04\n",
      "Epoch 417/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4651 - bpp: 1.0303 - mse: 1.7515e-04\n",
      "Epoch 417: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4651 - bpp: 1.0303 - mse: 1.7515e-04\n",
      "Epoch 418/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3043 - bpp: 0.9966 - mse: 1.5963e-04\n",
      "Epoch 418: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.3043 - bpp: 0.9966 - mse: 1.5963e-04\n",
      "Epoch 419/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4903 - bpp: 1.0108 - mse: 1.8061e-04\n",
      "Epoch 419: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4903 - bpp: 1.0108 - mse: 1.8061e-04\n",
      "Epoch 420/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3786 - bpp: 1.0249 - mse: 1.6524e-04\n",
      "Epoch 420: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3786 - bpp: 1.0249 - mse: 1.6524e-04\n",
      "Epoch 421/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2302 - bpp: 0.9738 - mse: 1.5337e-04\n",
      "Epoch 421: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2302 - bpp: 0.9738 - mse: 1.5337e-04\n",
      "Epoch 422/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4176 - bpp: 1.0223 - mse: 1.7033e-04\n",
      "Epoch 422: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4176 - bpp: 1.0223 - mse: 1.7033e-04\n",
      "Epoch 423/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3709 - bpp: 0.9840 - mse: 1.6930e-04\n",
      "Epoch 423: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3709 - bpp: 0.9840 - mse: 1.6930e-04\n",
      "Epoch 424/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4312 - bpp: 1.0124 - mse: 1.7320e-04\n",
      "Epoch 424: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4312 - bpp: 1.0124 - mse: 1.7320e-04\n",
      "Epoch 425/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2619 - bpp: 1.0072 - mse: 1.5316e-04\n",
      "Epoch 425: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.2619 - bpp: 1.0072 - mse: 1.5316e-04\n",
      "Epoch 426/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4063 - bpp: 1.0287 - mse: 1.6816e-04\n",
      "Epoch 426: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4063 - bpp: 1.0287 - mse: 1.6816e-04\n",
      "Epoch 427/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3774 - bpp: 1.0023 - mse: 1.6786e-04\n",
      "Epoch 427: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3774 - bpp: 1.0023 - mse: 1.6786e-04\n",
      "Epoch 428/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5038 - bpp: 1.0173 - mse: 1.8145e-04\n",
      "Epoch 428: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5038 - bpp: 1.0173 - mse: 1.8145e-04\n",
      "Epoch 429/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4535 - bpp: 1.0282 - mse: 1.7399e-04\n",
      "Epoch 429: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4535 - bpp: 1.0282 - mse: 1.7399e-04\n",
      "Epoch 430/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4363 - bpp: 1.0246 - mse: 1.7232e-04\n",
      "Epoch 430: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4363 - bpp: 1.0246 - mse: 1.7232e-04\n",
      "Epoch 431/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5453 - bpp: 1.0215 - mse: 1.8601e-04\n",
      "Epoch 431: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5453 - bpp: 1.0215 - mse: 1.8601e-04\n",
      "Epoch 432/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3615 - bpp: 0.9949 - mse: 1.6682e-04\n",
      "Epoch 432: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3615 - bpp: 0.9949 - mse: 1.6682e-04\n",
      "Epoch 433/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3919 - bpp: 1.0196 - mse: 1.6752e-04\n",
      "Epoch 433: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.3919 - bpp: 1.0196 - mse: 1.6752e-04\n",
      "Epoch 434/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6266 - bpp: 1.0244 - mse: 1.9557e-04\n",
      "Epoch 434: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6266 - bpp: 1.0244 - mse: 1.9557e-04\n",
      "Epoch 435/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0781 - bpp: 0.9628 - mse: 1.3614e-04\n",
      "Epoch 435: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.0781 - bpp: 0.9628 - mse: 1.3614e-04\n",
      "Epoch 436/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3573 - bpp: 1.0093 - mse: 1.6455e-04\n",
      "Epoch 436: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.3573 - bpp: 1.0093 - mse: 1.6455e-04\n",
      "Epoch 437/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2696 - bpp: 0.9851 - mse: 1.5680e-04\n",
      "Epoch 437: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2696 - bpp: 0.9851 - mse: 1.5680e-04\n",
      "Epoch 438/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3979 - bpp: 0.9980 - mse: 1.7089e-04\n",
      "Epoch 438: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3979 - bpp: 0.9980 - mse: 1.7089e-04\n",
      "Epoch 439/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3288 - bpp: 0.9952 - mse: 1.6280e-04\n",
      "Epoch 439: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3288 - bpp: 0.9952 - mse: 1.6280e-04\n",
      "Epoch 440/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4889 - bpp: 1.0243 - mse: 1.7878e-04\n",
      "Epoch 440: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4889 - bpp: 1.0243 - mse: 1.7878e-04\n",
      "Epoch 441/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5235 - bpp: 1.0140 - mse: 1.8427e-04\n",
      "Epoch 441: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5235 - bpp: 1.0140 - mse: 1.8427e-04\n",
      "Epoch 442/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3773 - bpp: 1.0211 - mse: 1.6555e-04\n",
      "Epoch 442: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3773 - bpp: 1.0211 - mse: 1.6555e-04\n",
      "Epoch 443/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3213 - bpp: 0.9978 - mse: 1.6156e-04\n",
      "Epoch 443: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.3213 - bpp: 0.9978 - mse: 1.6156e-04\n",
      "Epoch 444/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5489 - bpp: 1.0383 - mse: 1.8440e-04\n",
      "Epoch 444: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5489 - bpp: 1.0383 - mse: 1.8440e-04\n",
      "Epoch 445/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5388 - bpp: 1.0150 - mse: 1.8602e-04\n",
      "Epoch 445: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5388 - bpp: 1.0150 - mse: 1.8602e-04\n",
      "Epoch 446/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3490 - bpp: 1.0102 - mse: 1.6343e-04\n",
      "Epoch 446: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3490 - bpp: 1.0102 - mse: 1.6343e-04\n",
      "Epoch 447/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5870 - bpp: 1.0146 - mse: 1.9194e-04\n",
      "Epoch 447: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5870 - bpp: 1.0146 - mse: 1.9194e-04\n",
      "Epoch 448/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2001 - bpp: 0.9860 - mse: 1.4821e-04\n",
      "Epoch 448: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2001 - bpp: 0.9860 - mse: 1.4821e-04\n",
      "Epoch 449/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1846 - bpp: 0.9726 - mse: 1.4795e-04\n",
      "Epoch 449: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1846 - bpp: 0.9726 - mse: 1.4795e-04\n",
      "Epoch 450/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3546 - bpp: 0.9913 - mse: 1.6641e-04\n",
      "Epoch 450: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3546 - bpp: 0.9913 - mse: 1.6641e-04\n",
      "Epoch 451/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2932 - bpp: 1.0035 - mse: 1.5744e-04\n",
      "Epoch 451: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2932 - bpp: 1.0035 - mse: 1.5744e-04\n",
      "Epoch 452/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2712 - bpp: 0.9906 - mse: 1.5633e-04\n",
      "Epoch 452: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2712 - bpp: 0.9906 - mse: 1.5633e-04\n",
      "Epoch 453/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3097 - bpp: 0.9927 - mse: 1.6078e-04\n",
      "Epoch 453: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.3097 - bpp: 0.9927 - mse: 1.6078e-04\n",
      "Epoch 454/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2688 - bpp: 0.9910 - mse: 1.5598e-04\n",
      "Epoch 454: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.2688 - bpp: 0.9910 - mse: 1.5598e-04\n",
      "Epoch 455/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5644 - bpp: 1.0283 - mse: 1.8751e-04\n",
      "Epoch 455: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.5644 - bpp: 1.0283 - mse: 1.8751e-04\n",
      "Epoch 456/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4326 - bpp: 1.0288 - mse: 1.7137e-04\n",
      "Epoch 456: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4326 - bpp: 1.0288 - mse: 1.7137e-04\n",
      "Epoch 457/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4024 - bpp: 1.0039 - mse: 1.7072e-04\n",
      "Epoch 457: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4024 - bpp: 1.0039 - mse: 1.7072e-04\n",
      "Epoch 458/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2840 - bpp: 0.9796 - mse: 1.5922e-04\n",
      "Epoch 458: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.2840 - bpp: 0.9796 - mse: 1.5922e-04\n",
      "Epoch 459/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4963 - bpp: 1.0178 - mse: 1.8048e-04\n",
      "Epoch 459: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4963 - bpp: 1.0178 - mse: 1.8048e-04\n",
      "Epoch 460/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4248 - bpp: 1.0177 - mse: 1.7176e-04\n",
      "Epoch 460: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4248 - bpp: 1.0177 - mse: 1.7176e-04\n",
      "Epoch 461/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5026 - bpp: 1.0205 - mse: 1.8092e-04\n",
      "Epoch 461: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.5026 - bpp: 1.0205 - mse: 1.8092e-04\n",
      "Epoch 462/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4418 - bpp: 1.0122 - mse: 1.7451e-04\n",
      "Epoch 462: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4418 - bpp: 1.0122 - mse: 1.7451e-04\n",
      "Epoch 463/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2743 - bpp: 0.9954 - mse: 1.5612e-04\n",
      "Epoch 463: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2743 - bpp: 0.9954 - mse: 1.5612e-04\n",
      "Epoch 464/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3113 - bpp: 0.9870 - mse: 1.6167e-04\n",
      "Epoch 464: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3113 - bpp: 0.9870 - mse: 1.6167e-04\n",
      "Epoch 465/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3203 - bpp: 1.0109 - mse: 1.5983e-04\n",
      "Epoch 465: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3203 - bpp: 1.0109 - mse: 1.5983e-04\n",
      "Epoch 466/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2832 - bpp: 0.9938 - mse: 1.5740e-04\n",
      "Epoch 466: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2832 - bpp: 0.9938 - mse: 1.5740e-04\n",
      "Epoch 467/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2356 - bpp: 0.9951 - mse: 1.5144e-04\n",
      "Epoch 467: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.2356 - bpp: 0.9951 - mse: 1.5144e-04\n",
      "Epoch 468/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3177 - bpp: 1.0036 - mse: 1.6040e-04\n",
      "Epoch 468: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3177 - bpp: 1.0036 - mse: 1.6040e-04\n",
      "Epoch 469/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2244 - bpp: 0.9909 - mse: 1.5058e-04\n",
      "Epoch 469: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.2244 - bpp: 0.9909 - mse: 1.5058e-04\n",
      "Epoch 470/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2812 - bpp: 0.9820 - mse: 1.5859e-04\n",
      "Epoch 470: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2812 - bpp: 0.9820 - mse: 1.5859e-04\n",
      "Epoch 471/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3296 - bpp: 1.0173 - mse: 1.6020e-04\n",
      "Epoch 471: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3296 - bpp: 1.0173 - mse: 1.6020e-04\n",
      "Epoch 472/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5012 - bpp: 1.0064 - mse: 1.8247e-04\n",
      "Epoch 472: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5012 - bpp: 1.0064 - mse: 1.8247e-04\n",
      "Epoch 473/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2876 - bpp: 0.9919 - mse: 1.5817e-04\n",
      "Epoch 473: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2876 - bpp: 0.9919 - mse: 1.5817e-04\n",
      "Epoch 474/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0800 - bpp: 0.9746 - mse: 1.3494e-04\n",
      "Epoch 474: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.0800 - bpp: 0.9746 - mse: 1.3494e-04\n",
      "Epoch 475/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1439 - bpp: 0.9716 - mse: 1.4310e-04\n",
      "Epoch 475: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.1439 - bpp: 0.9716 - mse: 1.4310e-04\n",
      "Epoch 476/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4433 - bpp: 1.0165 - mse: 1.7417e-04\n",
      "Epoch 476: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4433 - bpp: 1.0165 - mse: 1.7417e-04\n",
      "Epoch 477/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0940 - bpp: 0.9542 - mse: 1.3914e-04\n",
      "Epoch 477: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.0940 - bpp: 0.9542 - mse: 1.3914e-04\n",
      "Epoch 478/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5573 - bpp: 1.0245 - mse: 1.8711e-04\n",
      "Epoch 478: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5573 - bpp: 1.0245 - mse: 1.8711e-04\n",
      "Epoch 479/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3752 - bpp: 0.9994 - mse: 1.6794e-04\n",
      "Epoch 479: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3752 - bpp: 0.9994 - mse: 1.6794e-04\n",
      "Epoch 480/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4704 - bpp: 1.0245 - mse: 1.7649e-04\n",
      "Epoch 480: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4704 - bpp: 1.0245 - mse: 1.7649e-04\n",
      "Epoch 481/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4504 - bpp: 1.0234 - mse: 1.7420e-04\n",
      "Epoch 481: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4504 - bpp: 1.0234 - mse: 1.7420e-04\n",
      "Epoch 482/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3627 - bpp: 0.9993 - mse: 1.6644e-04\n",
      "Epoch 482: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3627 - bpp: 0.9993 - mse: 1.6644e-04\n",
      "Epoch 483/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3386 - bpp: 0.9916 - mse: 1.6444e-04\n",
      "Epoch 483: loss did not improve from 2.02808\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3386 - bpp: 0.9916 - mse: 1.6444e-04\n",
      "Epoch 484/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9918 - bpp: 0.9475 - mse: 1.2747e-04\n",
      "Epoch 484: loss improved from 2.02808 to 1.99178, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 1.9918 - bpp: 0.9475 - mse: 1.2747e-04\n",
      "Epoch 485/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4570 - bpp: 1.0000 - mse: 1.7786e-04\n",
      "Epoch 485: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.4570 - bpp: 1.0000 - mse: 1.7786e-04\n",
      "Epoch 486/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3543 - bpp: 1.0082 - mse: 1.6431e-04\n",
      "Epoch 486: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3543 - bpp: 1.0082 - mse: 1.6431e-04\n",
      "Epoch 487/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3456 - bpp: 0.9956 - mse: 1.6480e-04\n",
      "Epoch 487: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3456 - bpp: 0.9956 - mse: 1.6480e-04\n",
      "Epoch 488/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3522 - bpp: 1.0056 - mse: 1.6439e-04\n",
      "Epoch 488: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3522 - bpp: 1.0056 - mse: 1.6439e-04\n",
      "Epoch 489/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3335 - bpp: 0.9980 - mse: 1.6302e-04\n",
      "Epoch 489: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3335 - bpp: 0.9980 - mse: 1.6302e-04\n",
      "Epoch 490/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4946 - bpp: 1.0208 - mse: 1.7991e-04\n",
      "Epoch 490: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4946 - bpp: 1.0208 - mse: 1.7991e-04\n",
      "Epoch 491/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3014 - bpp: 1.0004 - mse: 1.5881e-04\n",
      "Epoch 491: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3014 - bpp: 1.0004 - mse: 1.5881e-04\n",
      "Epoch 492/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2720 - bpp: 0.9812 - mse: 1.5756e-04\n",
      "Epoch 492: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2720 - bpp: 0.9812 - mse: 1.5756e-04\n",
      "Epoch 493/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4454 - bpp: 0.9983 - mse: 1.7664e-04\n",
      "Epoch 493: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4454 - bpp: 0.9983 - mse: 1.7664e-04\n",
      "Epoch 494/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2433 - bpp: 0.9970 - mse: 1.5213e-04\n",
      "Epoch 494: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 2.2433 - bpp: 0.9970 - mse: 1.5213e-04\n",
      "Epoch 495/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4184 - bpp: 1.0135 - mse: 1.7150e-04\n",
      "Epoch 495: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4184 - bpp: 1.0135 - mse: 1.7150e-04\n",
      "Epoch 496/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3280 - bpp: 0.9932 - mse: 1.6293e-04\n",
      "Epoch 496: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3280 - bpp: 0.9932 - mse: 1.6293e-04\n",
      "Epoch 497/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3302 - bpp: 0.9934 - mse: 1.6319e-04\n",
      "Epoch 497: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3302 - bpp: 0.9934 - mse: 1.6319e-04\n",
      "Epoch 498/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2729 - bpp: 0.9754 - mse: 1.5839e-04\n",
      "Epoch 498: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2729 - bpp: 0.9754 - mse: 1.5839e-04\n",
      "Epoch 499/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4687 - bpp: 1.0422 - mse: 1.7413e-04\n",
      "Epoch 499: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4687 - bpp: 1.0422 - mse: 1.7413e-04\n",
      "Epoch 500/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1939 - bpp: 0.9755 - mse: 1.4873e-04\n",
      "Epoch 500: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1939 - bpp: 0.9755 - mse: 1.4873e-04\n",
      "Epoch 501/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3309 - bpp: 0.9998 - mse: 1.6249e-04\n",
      "Epoch 501: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3309 - bpp: 0.9998 - mse: 1.6249e-04\n",
      "Epoch 502/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4122 - bpp: 1.0084 - mse: 1.7136e-04\n",
      "Epoch 502: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4122 - bpp: 1.0084 - mse: 1.7136e-04\n",
      "Epoch 503/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2241 - bpp: 0.9785 - mse: 1.5205e-04\n",
      "Epoch 503: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.2241 - bpp: 0.9785 - mse: 1.5205e-04\n",
      "Epoch 504/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3615 - bpp: 0.9955 - mse: 1.6675e-04\n",
      "Epoch 504: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3615 - bpp: 0.9955 - mse: 1.6675e-04\n",
      "Epoch 505/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2229 - bpp: 0.9904 - mse: 1.5044e-04\n",
      "Epoch 505: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2229 - bpp: 0.9904 - mse: 1.5044e-04\n",
      "Epoch 506/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2540 - bpp: 0.9852 - mse: 1.5488e-04\n",
      "Epoch 506: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.2540 - bpp: 0.9852 - mse: 1.5488e-04\n",
      "Epoch 507/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2027 - bpp: 0.9824 - mse: 1.4896e-04\n",
      "Epoch 507: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2027 - bpp: 0.9824 - mse: 1.4896e-04\n",
      "Epoch 508/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1323 - bpp: 0.9848 - mse: 1.4009e-04\n",
      "Epoch 508: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1323 - bpp: 0.9848 - mse: 1.4009e-04\n",
      "Epoch 509/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4337 - bpp: 1.0060 - mse: 1.7428e-04\n",
      "Epoch 509: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4337 - bpp: 1.0060 - mse: 1.7428e-04\n",
      "Epoch 510/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2581 - bpp: 1.0054 - mse: 1.5292e-04\n",
      "Epoch 510: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2581 - bpp: 1.0054 - mse: 1.5292e-04\n",
      "Epoch 511/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4857 - bpp: 1.0288 - mse: 1.7785e-04\n",
      "Epoch 511: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.4857 - bpp: 1.0288 - mse: 1.7785e-04\n",
      "Epoch 512/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2630 - bpp: 0.9887 - mse: 1.5555e-04\n",
      "Epoch 512: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2630 - bpp: 0.9887 - mse: 1.5555e-04\n",
      "Epoch 513/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1589 - bpp: 0.9684 - mse: 1.4533e-04\n",
      "Epoch 513: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 2.1589 - bpp: 0.9684 - mse: 1.4533e-04\n",
      "Epoch 514/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1506 - bpp: 0.9703 - mse: 1.4408e-04\n",
      "Epoch 514: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1506 - bpp: 0.9703 - mse: 1.4408e-04\n",
      "Epoch 515/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3779 - bpp: 1.0216 - mse: 1.6556e-04\n",
      "Epoch 515: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3779 - bpp: 1.0216 - mse: 1.6556e-04\n",
      "Epoch 516/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5209 - bpp: 1.0112 - mse: 1.8429e-04\n",
      "Epoch 516: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5209 - bpp: 1.0112 - mse: 1.8429e-04\n",
      "Epoch 517/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2651 - bpp: 0.9785 - mse: 1.5705e-04\n",
      "Epoch 517: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.2651 - bpp: 0.9785 - mse: 1.5705e-04\n",
      "Epoch 518/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1228 - bpp: 0.9576 - mse: 1.4225e-04\n",
      "Epoch 518: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1228 - bpp: 0.9576 - mse: 1.4225e-04\n",
      "Epoch 519/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2249 - bpp: 0.9838 - mse: 1.5150e-04\n",
      "Epoch 519: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.2249 - bpp: 0.9838 - mse: 1.5150e-04\n",
      "Epoch 520/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3003 - bpp: 0.9832 - mse: 1.6077e-04\n",
      "Epoch 520: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.3003 - bpp: 0.9832 - mse: 1.6077e-04\n",
      "Epoch 521/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3432 - bpp: 1.0114 - mse: 1.6256e-04\n",
      "Epoch 521: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3432 - bpp: 1.0114 - mse: 1.6256e-04\n",
      "Epoch 522/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3551 - bpp: 0.9785 - mse: 1.6803e-04\n",
      "Epoch 522: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3551 - bpp: 0.9785 - mse: 1.6803e-04\n",
      "Epoch 523/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2965 - bpp: 0.9819 - mse: 1.6047e-04\n",
      "Epoch 523: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2965 - bpp: 0.9819 - mse: 1.6047e-04\n",
      "Epoch 524/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2964 - bpp: 0.9891 - mse: 1.5958e-04\n",
      "Epoch 524: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2964 - bpp: 0.9891 - mse: 1.5958e-04\n",
      "Epoch 525/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2023 - bpp: 0.9680 - mse: 1.5068e-04\n",
      "Epoch 525: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2023 - bpp: 0.9680 - mse: 1.5068e-04\n",
      "Epoch 526/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4144 - bpp: 1.0024 - mse: 1.7237e-04\n",
      "Epoch 526: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4144 - bpp: 1.0024 - mse: 1.7237e-04\n",
      "Epoch 527/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1206 - bpp: 0.9964 - mse: 1.3723e-04\n",
      "Epoch 527: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1206 - bpp: 0.9964 - mse: 1.3723e-04\n",
      "Epoch 528/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1705 - bpp: 0.9758 - mse: 1.4583e-04\n",
      "Epoch 528: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.1705 - bpp: 0.9758 - mse: 1.4583e-04\n",
      "Epoch 529/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2778 - bpp: 1.0031 - mse: 1.5560e-04\n",
      "Epoch 529: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2778 - bpp: 1.0031 - mse: 1.5560e-04\n",
      "Epoch 530/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2971 - bpp: 0.9838 - mse: 1.6033e-04\n",
      "Epoch 530: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2971 - bpp: 0.9838 - mse: 1.6033e-04\n",
      "Epoch 531/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1111 - bpp: 0.9836 - mse: 1.3764e-04\n",
      "Epoch 531: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1111 - bpp: 0.9836 - mse: 1.3764e-04\n",
      "Epoch 532/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0353 - bpp: 0.9462 - mse: 1.3294e-04\n",
      "Epoch 532: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0353 - bpp: 0.9462 - mse: 1.3294e-04\n",
      "Epoch 533/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1608 - bpp: 0.9643 - mse: 1.4606e-04\n",
      "Epoch 533: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1608 - bpp: 0.9643 - mse: 1.4606e-04\n",
      "Epoch 534/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2051 - bpp: 0.9818 - mse: 1.4934e-04\n",
      "Epoch 534: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2051 - bpp: 0.9818 - mse: 1.4934e-04\n",
      "Epoch 535/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2618 - bpp: 0.9939 - mse: 1.5477e-04\n",
      "Epoch 535: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.2618 - bpp: 0.9939 - mse: 1.5477e-04\n",
      "Epoch 536/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5433 - bpp: 1.0247 - mse: 1.8538e-04\n",
      "Epoch 536: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5433 - bpp: 1.0247 - mse: 1.8538e-04\n",
      "Epoch 537/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3735 - bpp: 1.0052 - mse: 1.6703e-04\n",
      "Epoch 537: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3735 - bpp: 1.0052 - mse: 1.6703e-04\n",
      "Epoch 538/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2634 - bpp: 0.9903 - mse: 1.5541e-04\n",
      "Epoch 538: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2634 - bpp: 0.9903 - mse: 1.5541e-04\n",
      "Epoch 539/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3072 - bpp: 0.9730 - mse: 1.6287e-04\n",
      "Epoch 539: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.3072 - bpp: 0.9730 - mse: 1.6287e-04\n",
      "Epoch 540/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3206 - bpp: 0.9913 - mse: 1.6227e-04\n",
      "Epoch 540: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.3206 - bpp: 0.9913 - mse: 1.6227e-04\n",
      "Epoch 541/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2193 - bpp: 0.9821 - mse: 1.5102e-04\n",
      "Epoch 541: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2193 - bpp: 0.9821 - mse: 1.5102e-04\n",
      "Epoch 542/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3307 - bpp: 1.0023 - mse: 1.6215e-04\n",
      "Epoch 542: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3307 - bpp: 1.0023 - mse: 1.6215e-04\n",
      "Epoch 543/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3280 - bpp: 0.9916 - mse: 1.6313e-04\n",
      "Epoch 543: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.3280 - bpp: 0.9916 - mse: 1.6313e-04\n",
      "Epoch 544/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3158 - bpp: 0.9903 - mse: 1.6181e-04\n",
      "Epoch 544: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3158 - bpp: 0.9903 - mse: 1.6181e-04\n",
      "Epoch 545/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3168 - bpp: 1.0068 - mse: 1.5992e-04\n",
      "Epoch 545: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3168 - bpp: 1.0068 - mse: 1.5992e-04\n",
      "Epoch 546/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1998 - bpp: 0.9719 - mse: 1.4988e-04\n",
      "Epoch 546: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1998 - bpp: 0.9719 - mse: 1.4988e-04\n",
      "Epoch 547/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4419 - bpp: 1.0177 - mse: 1.7385e-04\n",
      "Epoch 547: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.4419 - bpp: 1.0177 - mse: 1.7385e-04\n",
      "Epoch 548/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1583 - bpp: 0.9885 - mse: 1.4279e-04\n",
      "Epoch 548: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1583 - bpp: 0.9885 - mse: 1.4279e-04\n",
      "Epoch 549/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4951 - bpp: 1.0204 - mse: 1.8002e-04\n",
      "Epoch 549: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4951 - bpp: 1.0204 - mse: 1.8002e-04\n",
      "Epoch 550/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2755 - bpp: 1.0009 - mse: 1.5559e-04\n",
      "Epoch 550: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2755 - bpp: 1.0009 - mse: 1.5559e-04\n",
      "Epoch 551/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4155 - bpp: 0.9947 - mse: 1.7344e-04\n",
      "Epoch 551: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.4155 - bpp: 0.9947 - mse: 1.7344e-04\n",
      "Epoch 552/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2013 - bpp: 0.9749 - mse: 1.4970e-04\n",
      "Epoch 552: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2013 - bpp: 0.9749 - mse: 1.4970e-04\n",
      "Epoch 553/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3326 - bpp: 0.9929 - mse: 1.6353e-04\n",
      "Epoch 553: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3326 - bpp: 0.9929 - mse: 1.6353e-04\n",
      "Epoch 554/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3276 - bpp: 1.0047 - mse: 1.6149e-04\n",
      "Epoch 554: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3276 - bpp: 1.0047 - mse: 1.6149e-04\n",
      "Epoch 555/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3022 - bpp: 0.9911 - mse: 1.6006e-04\n",
      "Epoch 555: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3022 - bpp: 0.9911 - mse: 1.6006e-04\n",
      "Epoch 556/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2164 - bpp: 0.9895 - mse: 1.4977e-04\n",
      "Epoch 556: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.2164 - bpp: 0.9895 - mse: 1.4977e-04\n",
      "Epoch 557/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3225 - bpp: 1.0015 - mse: 1.6125e-04\n",
      "Epoch 557: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3225 - bpp: 1.0015 - mse: 1.6125e-04\n",
      "Epoch 558/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3534 - bpp: 0.9955 - mse: 1.6575e-04\n",
      "Epoch 558: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3534 - bpp: 0.9955 - mse: 1.6575e-04\n",
      "Epoch 559/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2808 - bpp: 0.9751 - mse: 1.5938e-04\n",
      "Epoch 559: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.2808 - bpp: 0.9751 - mse: 1.5938e-04\n",
      "Epoch 560/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2681 - bpp: 1.0003 - mse: 1.5476e-04\n",
      "Epoch 560: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2681 - bpp: 1.0003 - mse: 1.5476e-04\n",
      "Epoch 561/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4983 - bpp: 1.0116 - mse: 1.8149e-04\n",
      "Epoch 561: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4983 - bpp: 1.0116 - mse: 1.8149e-04\n",
      "Epoch 562/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2495 - bpp: 0.9853 - mse: 1.5432e-04\n",
      "Epoch 562: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2495 - bpp: 0.9853 - mse: 1.5432e-04\n",
      "Epoch 563/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2727 - bpp: 0.9795 - mse: 1.5786e-04\n",
      "Epoch 563: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2727 - bpp: 0.9795 - mse: 1.5786e-04\n",
      "Epoch 564/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4501 - bpp: 1.0199 - mse: 1.7459e-04\n",
      "Epoch 564: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4501 - bpp: 1.0199 - mse: 1.7459e-04\n",
      "Epoch 565/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1314 - bpp: 0.9730 - mse: 1.4140e-04\n",
      "Epoch 565: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.1314 - bpp: 0.9730 - mse: 1.4140e-04\n",
      "Epoch 566/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4003 - bpp: 0.9982 - mse: 1.7116e-04\n",
      "Epoch 566: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4003 - bpp: 0.9982 - mse: 1.7116e-04\n",
      "Epoch 567/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2996 - bpp: 0.9994 - mse: 1.5872e-04\n",
      "Epoch 567: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2996 - bpp: 0.9994 - mse: 1.5872e-04\n",
      "Epoch 568/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2724 - bpp: 0.9966 - mse: 1.5573e-04\n",
      "Epoch 568: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.2724 - bpp: 0.9966 - mse: 1.5573e-04\n",
      "Epoch 569/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3410 - bpp: 0.9986 - mse: 1.6386e-04\n",
      "Epoch 569: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3410 - bpp: 0.9986 - mse: 1.6386e-04\n",
      "Epoch 570/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3610 - bpp: 0.9960 - mse: 1.6663e-04\n",
      "Epoch 570: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3610 - bpp: 0.9960 - mse: 1.6663e-04\n",
      "Epoch 571/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6177 - bpp: 1.0324 - mse: 1.9352e-04\n",
      "Epoch 571: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6177 - bpp: 1.0324 - mse: 1.9352e-04\n",
      "Epoch 572/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1572 - bpp: 0.9902 - mse: 1.4245e-04\n",
      "Epoch 572: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1572 - bpp: 0.9902 - mse: 1.4245e-04\n",
      "Epoch 573/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1741 - bpp: 0.9568 - mse: 1.4860e-04\n",
      "Epoch 573: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1741 - bpp: 0.9568 - mse: 1.4860e-04\n",
      "Epoch 574/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2519 - bpp: 0.9715 - mse: 1.5630e-04\n",
      "Epoch 574: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.2519 - bpp: 0.9715 - mse: 1.5630e-04\n",
      "Epoch 575/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2996 - bpp: 0.9846 - mse: 1.6052e-04\n",
      "Epoch 575: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2996 - bpp: 0.9846 - mse: 1.6052e-04\n",
      "Epoch 576/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1866 - bpp: 0.9570 - mse: 1.5010e-04\n",
      "Epoch 576: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1866 - bpp: 0.9570 - mse: 1.5010e-04\n",
      "Epoch 577/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3194 - bpp: 1.0022 - mse: 1.6078e-04\n",
      "Epoch 577: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3194 - bpp: 1.0022 - mse: 1.6078e-04\n",
      "Epoch 578/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3217 - bpp: 0.9909 - mse: 1.6245e-04\n",
      "Epoch 578: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3217 - bpp: 0.9909 - mse: 1.6245e-04\n",
      "Epoch 579/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5465 - bpp: 1.0162 - mse: 1.8681e-04\n",
      "Epoch 579: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5465 - bpp: 1.0162 - mse: 1.8681e-04\n",
      "Epoch 580/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1434 - bpp: 0.9758 - mse: 1.4253e-04\n",
      "Epoch 580: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1434 - bpp: 0.9758 - mse: 1.4253e-04\n",
      "Epoch 581/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3174 - bpp: 1.0001 - mse: 1.6080e-04\n",
      "Epoch 581: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3174 - bpp: 1.0001 - mse: 1.6080e-04\n",
      "Epoch 582/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5714 - bpp: 1.0366 - mse: 1.8736e-04\n",
      "Epoch 582: loss did not improve from 1.99178\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5714 - bpp: 1.0366 - mse: 1.8736e-04\n",
      "Epoch 583/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9271 - bpp: 0.9410 - mse: 1.2038e-04\n",
      "Epoch 583: loss improved from 1.99178 to 1.92710, saving model to checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 1.9271 - bpp: 0.9410 - mse: 1.2038e-04\n",
      "Epoch 584/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1542 - bpp: 0.9646 - mse: 1.4521e-04\n",
      "Epoch 584: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1542 - bpp: 0.9646 - mse: 1.4521e-04\n",
      "Epoch 585/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0834 - bpp: 0.9501 - mse: 1.3834e-04\n",
      "Epoch 585: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.0834 - bpp: 0.9501 - mse: 1.3834e-04\n",
      "Epoch 586/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1725 - bpp: 0.9798 - mse: 1.4559e-04\n",
      "Epoch 586: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1725 - bpp: 0.9798 - mse: 1.4559e-04\n",
      "Epoch 587/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3572 - bpp: 0.9967 - mse: 1.6607e-04\n",
      "Epoch 587: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.3572 - bpp: 0.9967 - mse: 1.6607e-04\n",
      "Epoch 588/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3780 - bpp: 1.0075 - mse: 1.6730e-04\n",
      "Epoch 588: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.3780 - bpp: 1.0075 - mse: 1.6730e-04\n",
      "Epoch 589/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1305 - bpp: 0.9831 - mse: 1.4006e-04\n",
      "Epoch 589: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.1305 - bpp: 0.9831 - mse: 1.4006e-04\n",
      "Epoch 590/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1142 - bpp: 0.9693 - mse: 1.3976e-04\n",
      "Epoch 590: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1142 - bpp: 0.9693 - mse: 1.3976e-04\n",
      "Epoch 591/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4171 - bpp: 1.0196 - mse: 1.7059e-04\n",
      "Epoch 591: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4171 - bpp: 1.0196 - mse: 1.7059e-04\n",
      "Epoch 592/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1750 - bpp: 0.9885 - mse: 1.4484e-04\n",
      "Epoch 592: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1750 - bpp: 0.9885 - mse: 1.4484e-04\n",
      "Epoch 593/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4109 - bpp: 0.9997 - mse: 1.7227e-04\n",
      "Epoch 593: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4109 - bpp: 0.9997 - mse: 1.7227e-04\n",
      "Epoch 594/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5727 - bpp: 1.0134 - mse: 1.9034e-04\n",
      "Epoch 594: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.5727 - bpp: 1.0134 - mse: 1.9034e-04\n",
      "Epoch 595/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1377 - bpp: 0.9816 - mse: 1.4113e-04\n",
      "Epoch 595: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1377 - bpp: 0.9816 - mse: 1.4113e-04\n",
      "Epoch 596/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6403 - bpp: 1.0264 - mse: 1.9701e-04\n",
      "Epoch 596: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6403 - bpp: 1.0264 - mse: 1.9701e-04\n",
      "Epoch 597/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1624 - bpp: 0.9605 - mse: 1.4671e-04\n",
      "Epoch 597: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1624 - bpp: 0.9605 - mse: 1.4671e-04\n",
      "Epoch 598/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0312 - bpp: 0.9553 - mse: 1.3133e-04\n",
      "Epoch 598: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.0312 - bpp: 0.9553 - mse: 1.3133e-04\n",
      "Epoch 599/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3244 - bpp: 0.9904 - mse: 1.6284e-04\n",
      "Epoch 599: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3244 - bpp: 0.9904 - mse: 1.6284e-04\n",
      "Epoch 600/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2276 - bpp: 0.9933 - mse: 1.5067e-04\n",
      "Epoch 600: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2276 - bpp: 0.9933 - mse: 1.5067e-04\n",
      "Epoch 601/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2041 - bpp: 0.9860 - mse: 1.4869e-04\n",
      "Epoch 601: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.2041 - bpp: 0.9860 - mse: 1.4869e-04\n",
      "Epoch 602/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2415 - bpp: 0.9856 - mse: 1.5331e-04\n",
      "Epoch 602: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 2.2415 - bpp: 0.9856 - mse: 1.5331e-04\n",
      "Epoch 603/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3555 - bpp: 0.9882 - mse: 1.6691e-04\n",
      "Epoch 603: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3555 - bpp: 0.9882 - mse: 1.6691e-04\n",
      "Epoch 604/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1516 - bpp: 0.9671 - mse: 1.4459e-04\n",
      "Epoch 604: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1516 - bpp: 0.9671 - mse: 1.4459e-04\n",
      "Epoch 605/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5168 - bpp: 1.0159 - mse: 1.8321e-04\n",
      "Epoch 605: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5168 - bpp: 1.0159 - mse: 1.8321e-04\n",
      "Epoch 606/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3301 - bpp: 0.9982 - mse: 1.6258e-04\n",
      "Epoch 606: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3301 - bpp: 0.9982 - mse: 1.6258e-04\n",
      "Epoch 607/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0526 - bpp: 0.9434 - mse: 1.3541e-04\n",
      "Epoch 607: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.0526 - bpp: 0.9434 - mse: 1.3541e-04\n",
      "Epoch 608/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1226 - bpp: 0.9678 - mse: 1.4096e-04\n",
      "Epoch 608: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.1226 - bpp: 0.9678 - mse: 1.4096e-04\n",
      "Epoch 609/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3295 - bpp: 0.9865 - mse: 1.6394e-04\n",
      "Epoch 609: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3295 - bpp: 0.9865 - mse: 1.6394e-04\n",
      "Epoch 610/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1525 - bpp: 0.9739 - mse: 1.4387e-04\n",
      "Epoch 610: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1525 - bpp: 0.9739 - mse: 1.4387e-04\n",
      "Epoch 611/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1400 - bpp: 0.9796 - mse: 1.4166e-04\n",
      "Epoch 611: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.1400 - bpp: 0.9796 - mse: 1.4166e-04\n",
      "Epoch 612/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3384 - bpp: 0.9888 - mse: 1.6474e-04\n",
      "Epoch 612: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3384 - bpp: 0.9888 - mse: 1.6474e-04\n",
      "Epoch 613/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2392 - bpp: 0.9841 - mse: 1.5321e-04\n",
      "Epoch 613: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2392 - bpp: 0.9841 - mse: 1.5321e-04\n",
      "Epoch 614/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3052 - bpp: 1.0036 - mse: 1.5889e-04\n",
      "Epoch 614: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3052 - bpp: 1.0036 - mse: 1.5889e-04\n",
      "Epoch 615/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0318 - bpp: 0.9573 - mse: 1.3117e-04\n",
      "Epoch 615: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0318 - bpp: 0.9573 - mse: 1.3117e-04\n",
      "Epoch 616/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2581 - bpp: 0.9918 - mse: 1.5458e-04\n",
      "Epoch 616: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2581 - bpp: 0.9918 - mse: 1.5458e-04\n",
      "Epoch 617/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1659 - bpp: 0.9817 - mse: 1.4456e-04\n",
      "Epoch 617: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1659 - bpp: 0.9817 - mse: 1.4456e-04\n",
      "Epoch 618/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2122 - bpp: 0.9775 - mse: 1.5072e-04\n",
      "Epoch 618: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2122 - bpp: 0.9775 - mse: 1.5072e-04\n",
      "Epoch 619/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3044 - bpp: 0.9927 - mse: 1.6012e-04\n",
      "Epoch 619: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3044 - bpp: 0.9927 - mse: 1.6012e-04\n",
      "Epoch 620/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1218 - bpp: 0.9677 - mse: 1.4089e-04\n",
      "Epoch 620: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.1218 - bpp: 0.9677 - mse: 1.4089e-04\n",
      "Epoch 621/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1908 - bpp: 0.9897 - mse: 1.4662e-04\n",
      "Epoch 621: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1908 - bpp: 0.9897 - mse: 1.4662e-04\n",
      "Epoch 622/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3676 - bpp: 0.9929 - mse: 1.6780e-04\n",
      "Epoch 622: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3676 - bpp: 0.9929 - mse: 1.6780e-04\n",
      "Epoch 623/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1207 - bpp: 0.9582 - mse: 1.4190e-04\n",
      "Epoch 623: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1207 - bpp: 0.9582 - mse: 1.4190e-04\n",
      "Epoch 624/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9787 - bpp: 0.9563 - mse: 1.2481e-04\n",
      "Epoch 624: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.9787 - bpp: 0.9563 - mse: 1.2481e-04\n",
      "Epoch 625/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0867 - bpp: 0.9679 - mse: 1.3657e-04\n",
      "Epoch 625: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.0867 - bpp: 0.9679 - mse: 1.3657e-04\n",
      "Epoch 626/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2062 - bpp: 0.9829 - mse: 1.4933e-04\n",
      "Epoch 626: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2062 - bpp: 0.9829 - mse: 1.4933e-04\n",
      "Epoch 627/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1496 - bpp: 0.9707 - mse: 1.4391e-04\n",
      "Epoch 627: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1496 - bpp: 0.9707 - mse: 1.4391e-04\n",
      "Epoch 628/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1346 - bpp: 0.9680 - mse: 1.4240e-04\n",
      "Epoch 628: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1346 - bpp: 0.9680 - mse: 1.4240e-04\n",
      "Epoch 629/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3111 - bpp: 0.9927 - mse: 1.6093e-04\n",
      "Epoch 629: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 2.3111 - bpp: 0.9927 - mse: 1.6093e-04\n",
      "Epoch 630/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1715 - bpp: 0.9767 - mse: 1.4585e-04\n",
      "Epoch 630: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1715 - bpp: 0.9767 - mse: 1.4585e-04\n",
      "Epoch 631/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1928 - bpp: 0.9851 - mse: 1.4741e-04\n",
      "Epoch 631: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1928 - bpp: 0.9851 - mse: 1.4741e-04\n",
      "Epoch 632/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5096 - bpp: 1.0093 - mse: 1.8314e-04\n",
      "Epoch 632: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5096 - bpp: 1.0093 - mse: 1.8314e-04\n",
      "Epoch 633/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1384 - bpp: 0.9662 - mse: 1.4309e-04\n",
      "Epoch 633: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.1384 - bpp: 0.9662 - mse: 1.4309e-04\n",
      "Epoch 634/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4583 - bpp: 1.0150 - mse: 1.7618e-04\n",
      "Epoch 634: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4583 - bpp: 1.0150 - mse: 1.7618e-04\n",
      "Epoch 635/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1138 - bpp: 0.9800 - mse: 1.3840e-04\n",
      "Epoch 635: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.1138 - bpp: 0.9800 - mse: 1.3840e-04\n",
      "Epoch 636/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0912 - bpp: 0.9602 - mse: 1.3805e-04\n",
      "Epoch 636: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.0912 - bpp: 0.9602 - mse: 1.3805e-04\n",
      "Epoch 637/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2351 - bpp: 0.9782 - mse: 1.5343e-04\n",
      "Epoch 637: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.2351 - bpp: 0.9782 - mse: 1.5343e-04\n",
      "Epoch 638/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9611 - bpp: 0.9504 - mse: 1.2337e-04\n",
      "Epoch 638: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 1.9611 - bpp: 0.9504 - mse: 1.2337e-04\n",
      "Epoch 639/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1833 - bpp: 0.9829 - mse: 1.4654e-04\n",
      "Epoch 639: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1833 - bpp: 0.9829 - mse: 1.4654e-04\n",
      "Epoch 640/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1403 - bpp: 0.9786 - mse: 1.4181e-04\n",
      "Epoch 640: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1403 - bpp: 0.9786 - mse: 1.4181e-04\n",
      "Epoch 641/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2929 - bpp: 0.9745 - mse: 1.6094e-04\n",
      "Epoch 641: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.2929 - bpp: 0.9745 - mse: 1.6094e-04\n",
      "Epoch 642/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1817 - bpp: 0.9816 - mse: 1.4649e-04\n",
      "Epoch 642: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1817 - bpp: 0.9816 - mse: 1.4649e-04\n",
      "Epoch 643/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2024 - bpp: 0.9738 - mse: 1.4997e-04\n",
      "Epoch 643: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2024 - bpp: 0.9738 - mse: 1.4997e-04\n",
      "Epoch 644/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3903 - bpp: 0.9962 - mse: 1.7018e-04\n",
      "Epoch 644: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.3903 - bpp: 0.9962 - mse: 1.7018e-04\n",
      "Epoch 645/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4019 - bpp: 1.0006 - mse: 1.7106e-04\n",
      "Epoch 645: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4019 - bpp: 1.0006 - mse: 1.7106e-04\n",
      "Epoch 646/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1242 - bpp: 0.9725 - mse: 1.4059e-04\n",
      "Epoch 646: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1242 - bpp: 0.9725 - mse: 1.4059e-04\n",
      "Epoch 647/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2598 - bpp: 0.9803 - mse: 1.5619e-04\n",
      "Epoch 647: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2598 - bpp: 0.9803 - mse: 1.5619e-04\n",
      "Epoch 648/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1631 - bpp: 0.9843 - mse: 1.4390e-04\n",
      "Epoch 648: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.1631 - bpp: 0.9843 - mse: 1.4390e-04\n",
      "Epoch 649/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1213 - bpp: 0.9767 - mse: 1.3973e-04\n",
      "Epoch 649: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.1213 - bpp: 0.9767 - mse: 1.3973e-04\n",
      "Epoch 650/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3070 - bpp: 0.9866 - mse: 1.6118e-04\n",
      "Epoch 650: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3070 - bpp: 0.9866 - mse: 1.6118e-04\n",
      "Epoch 651/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1091 - bpp: 0.9796 - mse: 1.3788e-04\n",
      "Epoch 651: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1091 - bpp: 0.9796 - mse: 1.3788e-04\n",
      "Epoch 652/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1559 - bpp: 0.9886 - mse: 1.4249e-04\n",
      "Epoch 652: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1559 - bpp: 0.9886 - mse: 1.4249e-04\n",
      "Epoch 653/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2981 - bpp: 0.9856 - mse: 1.6022e-04\n",
      "Epoch 653: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.2981 - bpp: 0.9856 - mse: 1.6022e-04\n",
      "Epoch 654/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1886 - bpp: 0.9770 - mse: 1.4789e-04\n",
      "Epoch 654: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1886 - bpp: 0.9770 - mse: 1.4789e-04\n",
      "Epoch 655/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3898 - bpp: 0.9905 - mse: 1.7081e-04\n",
      "Epoch 655: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3898 - bpp: 0.9905 - mse: 1.7081e-04\n",
      "Epoch 656/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0262 - bpp: 0.9574 - mse: 1.3047e-04\n",
      "Epoch 656: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0262 - bpp: 0.9574 - mse: 1.3047e-04\n",
      "Epoch 657/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1648 - bpp: 0.9742 - mse: 1.4535e-04\n",
      "Epoch 657: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1648 - bpp: 0.9742 - mse: 1.4535e-04\n",
      "Epoch 658/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4256 - bpp: 0.9839 - mse: 1.7599e-04\n",
      "Epoch 658: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.4256 - bpp: 0.9839 - mse: 1.7599e-04\n",
      "Epoch 659/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4982 - bpp: 0.9956 - mse: 1.8342e-04\n",
      "Epoch 659: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4982 - bpp: 0.9956 - mse: 1.8342e-04\n",
      "Epoch 660/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9883 - bpp: 0.9432 - mse: 1.2758e-04\n",
      "Epoch 660: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 1.9883 - bpp: 0.9432 - mse: 1.2758e-04\n",
      "Epoch 661/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1489 - bpp: 0.9775 - mse: 1.4300e-04\n",
      "Epoch 661: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1489 - bpp: 0.9775 - mse: 1.4300e-04\n",
      "Epoch 662/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3298 - bpp: 1.0049 - mse: 1.6173e-04\n",
      "Epoch 662: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 26s 121ms/step - loss: 2.3298 - bpp: 1.0049 - mse: 1.6173e-04\n",
      "Epoch 663/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3273 - bpp: 1.0095 - mse: 1.6086e-04\n",
      "Epoch 663: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3273 - bpp: 1.0095 - mse: 1.6086e-04\n",
      "Epoch 664/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2792 - bpp: 0.9961 - mse: 1.5662e-04\n",
      "Epoch 664: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2792 - bpp: 0.9961 - mse: 1.5662e-04\n",
      "Epoch 665/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0825 - bpp: 0.9778 - mse: 1.3485e-04\n",
      "Epoch 665: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0825 - bpp: 0.9778 - mse: 1.3485e-04\n",
      "Epoch 666/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2219 - bpp: 0.9809 - mse: 1.5149e-04\n",
      "Epoch 666: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2219 - bpp: 0.9809 - mse: 1.5149e-04\n",
      "Epoch 667/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1716 - bpp: 0.9809 - mse: 1.4535e-04\n",
      "Epoch 667: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1716 - bpp: 0.9809 - mse: 1.4535e-04\n",
      "Epoch 668/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2130 - bpp: 0.9845 - mse: 1.4996e-04\n",
      "Epoch 668: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2130 - bpp: 0.9845 - mse: 1.4996e-04\n",
      "Epoch 669/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0890 - bpp: 0.9760 - mse: 1.3586e-04\n",
      "Epoch 669: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 2.0890 - bpp: 0.9760 - mse: 1.3586e-04\n",
      "Epoch 670/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2199 - bpp: 0.9879 - mse: 1.5039e-04\n",
      "Epoch 670: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2199 - bpp: 0.9879 - mse: 1.5039e-04\n",
      "Epoch 671/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2224 - bpp: 0.9835 - mse: 1.5123e-04\n",
      "Epoch 671: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2224 - bpp: 0.9835 - mse: 1.5123e-04\n",
      "Epoch 672/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2319 - bpp: 0.9928 - mse: 1.5126e-04\n",
      "Epoch 672: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.2319 - bpp: 0.9928 - mse: 1.5126e-04\n",
      "Epoch 673/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3707 - bpp: 0.9914 - mse: 1.6837e-04\n",
      "Epoch 673: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.3707 - bpp: 0.9914 - mse: 1.6837e-04\n",
      "Epoch 674/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2314 - bpp: 0.9972 - mse: 1.5066e-04\n",
      "Epoch 674: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2314 - bpp: 0.9972 - mse: 1.5066e-04\n",
      "Epoch 675/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2189 - bpp: 0.9916 - mse: 1.4981e-04\n",
      "Epoch 675: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.2189 - bpp: 0.9916 - mse: 1.4981e-04\n",
      "Epoch 676/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1468 - bpp: 0.9709 - mse: 1.4355e-04\n",
      "Epoch 676: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 118ms/step - loss: 2.1468 - bpp: 0.9709 - mse: 1.4355e-04\n",
      "Epoch 677/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2048 - bpp: 0.9634 - mse: 1.5154e-04\n",
      "Epoch 677: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.2048 - bpp: 0.9634 - mse: 1.5154e-04\n",
      "Epoch 678/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0862 - bpp: 0.9613 - mse: 1.3732e-04\n",
      "Epoch 678: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.0862 - bpp: 0.9613 - mse: 1.3732e-04\n",
      "Epoch 679/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2217 - bpp: 0.9738 - mse: 1.5233e-04\n",
      "Epoch 679: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2217 - bpp: 0.9738 - mse: 1.5233e-04\n",
      "Epoch 680/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1397 - bpp: 0.9668 - mse: 1.4318e-04\n",
      "Epoch 680: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 26s 125ms/step - loss: 2.1397 - bpp: 0.9668 - mse: 1.4318e-04\n",
      "Epoch 681/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3399 - bpp: 0.9930 - mse: 1.6441e-04\n",
      "Epoch 681: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3399 - bpp: 0.9930 - mse: 1.6441e-04\n",
      "Epoch 682/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2727 - bpp: 0.9801 - mse: 1.5780e-04\n",
      "Epoch 682: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2727 - bpp: 0.9801 - mse: 1.5780e-04\n",
      "Epoch 683/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2068 - bpp: 0.9728 - mse: 1.5063e-04\n",
      "Epoch 683: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2068 - bpp: 0.9728 - mse: 1.5063e-04\n",
      "Epoch 684/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1657 - bpp: 0.9863 - mse: 1.4396e-04\n",
      "Epoch 684: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.1657 - bpp: 0.9863 - mse: 1.4396e-04\n",
      "Epoch 685/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1917 - bpp: 0.9814 - mse: 1.4774e-04\n",
      "Epoch 685: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1917 - bpp: 0.9814 - mse: 1.4774e-04\n",
      "Epoch 686/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1593 - bpp: 0.9776 - mse: 1.4425e-04\n",
      "Epoch 686: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.1593 - bpp: 0.9776 - mse: 1.4425e-04\n",
      "Epoch 687/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3867 - bpp: 0.9983 - mse: 1.6948e-04\n",
      "Epoch 687: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3867 - bpp: 0.9983 - mse: 1.6948e-04\n",
      "Epoch 688/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2880 - bpp: 0.9945 - mse: 1.5790e-04\n",
      "Epoch 688: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2880 - bpp: 0.9945 - mse: 1.5790e-04\n",
      "Epoch 689/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2075 - bpp: 0.9919 - mse: 1.4840e-04\n",
      "Epoch 689: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2075 - bpp: 0.9919 - mse: 1.4840e-04\n",
      "Epoch 690/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1158 - bpp: 0.9652 - mse: 1.4046e-04\n",
      "Epoch 690: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1158 - bpp: 0.9652 - mse: 1.4046e-04\n",
      "Epoch 691/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3528 - bpp: 0.9892 - mse: 1.6646e-04\n",
      "Epoch 691: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.3528 - bpp: 0.9892 - mse: 1.6646e-04\n",
      "Epoch 692/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0671 - bpp: 0.9746 - mse: 1.3337e-04\n",
      "Epoch 692: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.0671 - bpp: 0.9746 - mse: 1.3337e-04\n",
      "Epoch 693/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2507 - bpp: 0.9841 - mse: 1.5462e-04\n",
      "Epoch 693: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2507 - bpp: 0.9841 - mse: 1.5462e-04\n",
      "Epoch 694/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2514 - bpp: 0.9842 - mse: 1.5469e-04\n",
      "Epoch 694: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2514 - bpp: 0.9842 - mse: 1.5469e-04\n",
      "Epoch 695/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2594 - bpp: 0.9775 - mse: 1.5648e-04\n",
      "Epoch 695: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 2.2594 - bpp: 0.9775 - mse: 1.5648e-04\n",
      "Epoch 696/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1188 - bpp: 0.9502 - mse: 1.4265e-04\n",
      "Epoch 696: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1188 - bpp: 0.9502 - mse: 1.4265e-04\n",
      "Epoch 697/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0744 - bpp: 0.9608 - mse: 1.3594e-04\n",
      "Epoch 697: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.0744 - bpp: 0.9608 - mse: 1.3594e-04\n",
      "Epoch 698/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1929 - bpp: 0.9746 - mse: 1.4871e-04\n",
      "Epoch 698: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.1929 - bpp: 0.9746 - mse: 1.4871e-04\n",
      "Epoch 699/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1114 - bpp: 0.9775 - mse: 1.3842e-04\n",
      "Epoch 699: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.1114 - bpp: 0.9775 - mse: 1.3842e-04\n",
      "Epoch 700/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2439 - bpp: 0.9796 - mse: 1.5433e-04\n",
      "Epoch 700: loss did not improve from 1.92710\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2439 - bpp: 0.9796 - mse: 1.5433e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_2_layer_call_fn, optical_flow_loss_2_layer_call_and_return_conditional_losses, dwt_2_layer_call_fn, dwt_2_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_8192_epcs_700_I_QP_30_240x240_CosineDecay_20220531-180109/assets\n"
     ]
    }
   ],
   "source": [
    "I_QP=30\n",
    "lmbda = 8192\n",
    "trainer_13 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_13.compile()\n",
    "trainer_13.fit()\n",
    "trainer_13.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 252.7375 - bpp: 5.3042 - mse: 0.0151\n",
      "Epoch 1: loss improved from inf to 252.73753, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 54s 125ms/step - loss: 252.7375 - bpp: 5.3042 - mse: 0.0151\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 72.4131 - bpp: 5.1661 - mse: 0.0041\n",
      "Epoch 2: loss improved from 252.73753 to 72.41314, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 72.4131 - bpp: 5.1661 - mse: 0.0041\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 41.9071 - bpp: 5.0304 - mse: 0.0023\n",
      "Epoch 3: loss improved from 72.41314 to 41.90710, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 41.9071 - bpp: 5.0304 - mse: 0.0023\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 38.4388 - bpp: 4.8979 - mse: 0.0020\n",
      "Epoch 4: loss improved from 41.90710 to 38.43877, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 38.4388 - bpp: 4.8979 - mse: 0.0020\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 29.6522 - bpp: 4.7679 - mse: 0.0015\n",
      "Epoch 5: loss improved from 38.43877 to 29.65223, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 29.6522 - bpp: 4.7679 - mse: 0.0015\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 31.1787 - bpp: 4.6403 - mse: 0.0016\n",
      "Epoch 6: loss did not improve from 29.65223\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 31.1787 - bpp: 4.6403 - mse: 0.0016\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.3143 - bpp: 4.5151 - mse: 0.0013\n",
      "Epoch 7: loss improved from 29.65223 to 26.31425, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 26.3143 - bpp: 4.5151 - mse: 0.0013\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.2448 - bpp: 4.3920 - mse: 0.0013\n",
      "Epoch 8: loss improved from 26.31425 to 26.24483, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 26.2448 - bpp: 4.3920 - mse: 0.0013\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.6194 - bpp: 4.2723 - mse: 0.0013\n",
      "Epoch 9: loss improved from 26.24483 to 25.61941, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 25.6194 - bpp: 4.2723 - mse: 0.0013\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.7489 - bpp: 4.1571 - mse: 0.0011\n",
      "Epoch 10: loss improved from 25.61941 to 21.74891, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 21.7489 - bpp: 4.1571 - mse: 0.0011\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.2940 - bpp: 4.0424 - mse: 9.3088e-04\n",
      "Epoch 11: loss improved from 21.74891 to 19.29398, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 19.2940 - bpp: 4.0424 - mse: 9.3088e-04\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4315 - bpp: 3.9288 - mse: 7.6311e-04\n",
      "Epoch 12: loss improved from 19.29398 to 16.43153, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 16.4315 - bpp: 3.9288 - mse: 7.6311e-04\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.8794 - bpp: 3.8212 - mse: 7.9701e-04\n",
      "Epoch 13: loss did not improve from 16.43153\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 16.8794 - bpp: 3.8212 - mse: 7.9701e-04\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.2570 - bpp: 3.7121 - mse: 6.4361e-04\n",
      "Epoch 14: loss improved from 16.43153 to 14.25698, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 14.2570 - bpp: 3.7121 - mse: 6.4361e-04\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3636 - bpp: 3.6055 - mse: 5.9559e-04\n",
      "Epoch 15: loss improved from 14.25698 to 13.36362, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 13.3636 - bpp: 3.6055 - mse: 5.9559e-04\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.0576 - bpp: 3.5085 - mse: 6.4387e-04\n",
      "Epoch 16: loss did not improve from 13.36362\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 14.0576 - bpp: 3.5085 - mse: 6.4387e-04\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.4125 - bpp: 3.4056 - mse: 5.4974e-04\n",
      "Epoch 17: loss improved from 13.36362 to 12.41249, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 12.4125 - bpp: 3.4056 - mse: 5.4974e-04\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.2989 - bpp: 3.3103 - mse: 4.8758e-04\n",
      "Epoch 18: loss improved from 12.41249 to 11.29885, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 11.2989 - bpp: 3.3103 - mse: 4.8758e-04\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4765 - bpp: 3.2106 - mse: 4.4347e-04\n",
      "Epoch 19: loss improved from 11.29885 to 10.47649, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 10.4765 - bpp: 3.2106 - mse: 4.4347e-04\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1908 - bpp: 3.1220 - mse: 4.3144e-04\n",
      "Epoch 20: loss improved from 10.47649 to 10.19078, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 10.1908 - bpp: 3.1220 - mse: 4.3144e-04\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3801 - bpp: 3.0336 - mse: 3.8736e-04\n",
      "Epoch 21: loss improved from 10.19078 to 9.38006, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 9.3801 - bpp: 3.0336 - mse: 3.8736e-04\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9517 - bpp: 2.9529 - mse: 4.2717e-04\n",
      "Epoch 22: loss did not improve from 9.38006\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.9517 - bpp: 2.9529 - mse: 4.2717e-04\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2362 - bpp: 2.8782 - mse: 3.8806e-04\n",
      "Epoch 23: loss improved from 9.38006 to 9.23620, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 9.2362 - bpp: 2.8782 - mse: 3.8806e-04\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0841 - bpp: 2.7968 - mse: 3.8374e-04\n",
      "Epoch 24: loss improved from 9.23620 to 9.08407, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 9.0841 - bpp: 2.7968 - mse: 3.8374e-04\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9642 - bpp: 2.7117 - mse: 3.2059e-04\n",
      "Epoch 25: loss improved from 9.08407 to 7.96416, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 7.9642 - bpp: 2.7117 - mse: 3.2059e-04\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3810 - bpp: 2.6624 - mse: 4.1007e-04\n",
      "Epoch 26: loss did not improve from 7.96416\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 9.3810 - bpp: 2.6624 - mse: 4.1007e-04\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.5125 - bpp: 2.6180 - mse: 8.4805e-04\n",
      "Epoch 27: loss did not improve from 7.96416\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 16.5125 - bpp: 2.6180 - mse: 8.4805e-04\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8566 - bpp: 2.5084 - mse: 3.8746e-04\n",
      "Epoch 28: loss did not improve from 7.96416\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 8.8566 - bpp: 2.5084 - mse: 3.8746e-04\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6860 - bpp: 2.4436 - mse: 3.1997e-04\n",
      "Epoch 29: loss improved from 7.96416 to 7.68603, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 7.6860 - bpp: 2.4436 - mse: 3.1997e-04\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6682 - bpp: 2.3887 - mse: 3.2223e-04\n",
      "Epoch 30: loss improved from 7.68603 to 7.66817, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 7.6682 - bpp: 2.3887 - mse: 3.2223e-04\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5942 - bpp: 2.3379 - mse: 3.2082e-04\n",
      "Epoch 31: loss improved from 7.66817 to 7.59422, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 7.5942 - bpp: 2.3379 - mse: 3.2082e-04\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1487 - bpp: 2.2962 - mse: 3.5721e-04\n",
      "Epoch 32: loss did not improve from 7.59422\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 8.1487 - bpp: 2.2962 - mse: 3.5721e-04\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3288 - bpp: 2.2265 - mse: 3.1142e-04\n",
      "Epoch 33: loss improved from 7.59422 to 7.32881, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 7.3288 - bpp: 2.2265 - mse: 3.1142e-04\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8580 - bpp: 2.1809 - mse: 2.8546e-04\n",
      "Epoch 34: loss improved from 7.32881 to 6.85797, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.8580 - bpp: 2.1809 - mse: 2.8546e-04\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5942 - bpp: 2.1301 - mse: 2.7247e-04\n",
      "Epoch 35: loss improved from 6.85797 to 6.59419, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 6.5942 - bpp: 2.1301 - mse: 2.7247e-04\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3553 - bpp: 2.1016 - mse: 2.5963e-04\n",
      "Epoch 36: loss improved from 6.59419 to 6.35534, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.3553 - bpp: 2.1016 - mse: 2.5963e-04\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2460 - bpp: 2.0659 - mse: 2.5514e-04\n",
      "Epoch 37: loss improved from 6.35534 to 6.24603, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.2460 - bpp: 2.0659 - mse: 2.5514e-04\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0483 - bpp: 2.0603 - mse: 3.0445e-04\n",
      "Epoch 38: loss did not improve from 6.24603\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 7.0483 - bpp: 2.0603 - mse: 3.0445e-04\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3764 - bpp: 1.9944 - mse: 2.6745e-04\n",
      "Epoch 39: loss did not improve from 6.24603\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3764 - bpp: 1.9944 - mse: 2.6745e-04\n",
      "Epoch 40/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2898 - bpp: 1.9809 - mse: 3.2403e-04\n",
      "Epoch 40: loss did not improve from 6.24603\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.2898 - bpp: 1.9809 - mse: 3.2403e-04\n",
      "Epoch 41/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1276 - bpp: 1.9502 - mse: 2.5497e-04\n",
      "Epoch 41: loss improved from 6.24603 to 6.12764, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 6.1276 - bpp: 1.9502 - mse: 2.5497e-04\n",
      "Epoch 42/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9747 - bpp: 1.9047 - mse: 2.4841e-04\n",
      "Epoch 42: loss improved from 6.12764 to 5.97470, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.9747 - bpp: 1.9047 - mse: 2.4841e-04\n",
      "Epoch 43/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.9678 - bpp: 1.9667 - mse: 0.0013\n",
      "Epoch 43: loss did not improve from 5.97470\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 22.9678 - bpp: 1.9667 - mse: 0.0013\n",
      "Epoch 44/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.2537 - bpp: 2.0611 - mse: 0.0012\n",
      "Epoch 44: loss did not improve from 5.97470\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 22.2537 - bpp: 2.0611 - mse: 0.0012\n",
      "Epoch 45/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2234 - bpp: 1.9032 - mse: 3.2472e-04\n",
      "Epoch 45: loss did not improve from 5.97470\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.2234 - bpp: 1.9032 - mse: 3.2472e-04\n",
      "Epoch 46/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4049 - bpp: 1.8106 - mse: 2.8042e-04\n",
      "Epoch 46: loss did not improve from 5.97470\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 6.4049 - bpp: 1.8106 - mse: 2.8042e-04\n",
      "Epoch 47/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2938 - bpp: 1.8221 - mse: 2.7293e-04\n",
      "Epoch 47: loss did not improve from 5.97470\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.2938 - bpp: 1.8221 - mse: 2.7293e-04\n",
      "Epoch 48/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1789 - bpp: 1.7899 - mse: 2.6788e-04\n",
      "Epoch 48: loss did not improve from 5.97470\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.1789 - bpp: 1.7899 - mse: 2.6788e-04\n",
      "Epoch 49/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9674 - bpp: 1.7400 - mse: 2.5802e-04\n",
      "Epoch 49: loss improved from 5.97470 to 5.96737, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 5.9674 - bpp: 1.7400 - mse: 2.5802e-04\n",
      "Epoch 50/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2571 - bpp: 1.8221 - mse: 2.7069e-04\n",
      "Epoch 50: loss did not improve from 5.96737\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.2571 - bpp: 1.8221 - mse: 2.7069e-04\n",
      "Epoch 51/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3805 - bpp: 1.7119 - mse: 2.2391e-04\n",
      "Epoch 51: loss improved from 5.96737 to 5.38055, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 5.3805 - bpp: 1.7119 - mse: 2.2391e-04\n",
      "Epoch 52/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5170 - bpp: 1.7036 - mse: 2.3275e-04\n",
      "Epoch 52: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.5170 - bpp: 1.7036 - mse: 2.3275e-04\n",
      "Epoch 53/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0670 - bpp: 1.7194 - mse: 2.6536e-04\n",
      "Epoch 53: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.0670 - bpp: 1.7194 - mse: 2.6536e-04\n",
      "Epoch 54/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9331 - bpp: 1.7297 - mse: 2.5656e-04\n",
      "Epoch 54: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 5.9331 - bpp: 1.7297 - mse: 2.5656e-04\n",
      "Epoch 55/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9566 - bpp: 1.7101 - mse: 2.5918e-04\n",
      "Epoch 55: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.9566 - bpp: 1.7101 - mse: 2.5918e-04\n",
      "Epoch 56/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4718 - bpp: 1.6959 - mse: 2.3047e-04\n",
      "Epoch 56: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4718 - bpp: 1.6959 - mse: 2.3047e-04\n",
      "Epoch 57/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4457 - bpp: 1.7219 - mse: 2.2728e-04\n",
      "Epoch 57: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4457 - bpp: 1.7219 - mse: 2.2728e-04\n",
      "Epoch 58/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4691 - bpp: 1.7111 - mse: 2.2937e-04\n",
      "Epoch 58: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4691 - bpp: 1.7111 - mse: 2.2937e-04\n",
      "Epoch 59/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7685 - bpp: 1.6830 - mse: 2.4936e-04\n",
      "Epoch 59: loss did not improve from 5.38055\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.7685 - bpp: 1.6830 - mse: 2.4936e-04\n",
      "Epoch 60/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2365 - bpp: 1.6862 - mse: 2.1669e-04\n",
      "Epoch 60: loss improved from 5.38055 to 5.23654, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.2365 - bpp: 1.6862 - mse: 2.1669e-04\n",
      "Epoch 61/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2620 - bpp: 1.6840 - mse: 2.1839e-04\n",
      "Epoch 61: loss did not improve from 5.23654\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.2620 - bpp: 1.6840 - mse: 2.1839e-04\n",
      "Epoch 62/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1074 - bpp: 1.6807 - mse: 2.0915e-04\n",
      "Epoch 62: loss improved from 5.23654 to 5.10744, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 5.1074 - bpp: 1.6807 - mse: 2.0915e-04\n",
      "Epoch 63/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8188 - bpp: 1.6401 - mse: 1.9401e-04\n",
      "Epoch 63: loss improved from 5.10744 to 4.81877, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 4.8188 - bpp: 1.6401 - mse: 1.9401e-04\n",
      "Epoch 64/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8805 - bpp: 1.6403 - mse: 1.9777e-04\n",
      "Epoch 64: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.8805 - bpp: 1.6403 - mse: 1.9777e-04\n",
      "Epoch 65/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4831 - bpp: 1.7224 - mse: 2.2953e-04\n",
      "Epoch 65: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.4831 - bpp: 1.7224 - mse: 2.2953e-04\n",
      "Epoch 66/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1983 - bpp: 1.6383 - mse: 2.1728e-04\n",
      "Epoch 66: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.1983 - bpp: 1.6383 - mse: 2.1728e-04\n",
      "Epoch 67/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5952 - bpp: 1.7487 - mse: 2.3477e-04\n",
      "Epoch 67: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5952 - bpp: 1.7487 - mse: 2.3477e-04\n",
      "Epoch 68/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.1152 - bpp: 1.7700 - mse: 8.1453e-04\n",
      "Epoch 68: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 15.1152 - bpp: 1.7700 - mse: 8.1453e-04\n",
      "Epoch 69/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0951 - bpp: 1.7759 - mse: 3.8570e-04\n",
      "Epoch 69: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.0951 - bpp: 1.7759 - mse: 3.8570e-04\n",
      "Epoch 70/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0722 - bpp: 1.6839 - mse: 2.6784e-04\n",
      "Epoch 70: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0722 - bpp: 1.6839 - mse: 2.6784e-04\n",
      "Epoch 71/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6336 - bpp: 1.6783 - mse: 2.4141e-04\n",
      "Epoch 71: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 5.6336 - bpp: 1.6783 - mse: 2.4141e-04\n",
      "Epoch 72/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6431 - bpp: 1.6445 - mse: 2.4406e-04\n",
      "Epoch 72: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.6431 - bpp: 1.6445 - mse: 2.4406e-04\n",
      "Epoch 73/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2637 - bpp: 1.6420 - mse: 2.2105e-04\n",
      "Epoch 73: loss did not improve from 4.81877\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.2637 - bpp: 1.6420 - mse: 2.2105e-04\n",
      "Epoch 74/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6298 - bpp: 1.6178 - mse: 1.8384e-04\n",
      "Epoch 74: loss improved from 4.81877 to 4.62984, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 4.6298 - bpp: 1.6178 - mse: 1.8384e-04\n",
      "Epoch 75/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7866 - bpp: 1.6046 - mse: 1.9422e-04\n",
      "Epoch 75: loss did not improve from 4.62984\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.7866 - bpp: 1.6046 - mse: 1.9422e-04\n",
      "Epoch 76/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1273 - bpp: 1.6764 - mse: 2.1063e-04\n",
      "Epoch 76: loss did not improve from 4.62984\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.1273 - bpp: 1.6764 - mse: 2.1063e-04\n",
      "Epoch 77/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7352 - bpp: 1.6300 - mse: 1.8953e-04\n",
      "Epoch 77: loss did not improve from 4.62984\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.7352 - bpp: 1.6300 - mse: 1.8953e-04\n",
      "Epoch 78/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3636 - bpp: 1.5722 - mse: 1.7037e-04\n",
      "Epoch 78: loss improved from 4.62984 to 4.36361, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 4.3636 - bpp: 1.5722 - mse: 1.7037e-04\n",
      "Epoch 79/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3441 - bpp: 1.6055 - mse: 1.6715e-04\n",
      "Epoch 79: loss improved from 4.36361 to 4.34408, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 4.3441 - bpp: 1.6055 - mse: 1.6715e-04\n",
      "Epoch 80/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7783 - bpp: 1.6642 - mse: 1.9007e-04\n",
      "Epoch 80: loss did not improve from 4.34408\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.7783 - bpp: 1.6642 - mse: 1.9007e-04\n",
      "Epoch 81/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2273 - bpp: 1.5903 - mse: 1.6095e-04\n",
      "Epoch 81: loss improved from 4.34408 to 4.22729, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.2273 - bpp: 1.5903 - mse: 1.6095e-04\n",
      "Epoch 82/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7689 - bpp: 1.6147 - mse: 1.9252e-04\n",
      "Epoch 82: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.7689 - bpp: 1.6147 - mse: 1.9252e-04\n",
      "Epoch 83/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3089 - bpp: 1.5839 - mse: 1.6632e-04\n",
      "Epoch 83: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.3089 - bpp: 1.5839 - mse: 1.6632e-04\n",
      "Epoch 84/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6386 - bpp: 1.6093 - mse: 1.8489e-04\n",
      "Epoch 84: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.6386 - bpp: 1.6093 - mse: 1.8489e-04\n",
      "Epoch 85/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6991 - bpp: 1.5895 - mse: 1.8980e-04\n",
      "Epoch 85: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.6991 - bpp: 1.5895 - mse: 1.8980e-04\n",
      "Epoch 86/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5173 - bpp: 1.5909 - mse: 1.7861e-04\n",
      "Epoch 86: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.5173 - bpp: 1.5909 - mse: 1.7861e-04\n",
      "Epoch 87/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5841 - bpp: 1.7511 - mse: 3.5602e-04\n",
      "Epoch 87: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.5841 - bpp: 1.7511 - mse: 3.5602e-04\n",
      "Epoch 88/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6297 - bpp: 1.6242 - mse: 1.8344e-04\n",
      "Epoch 88: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 4.6297 - bpp: 1.6242 - mse: 1.8344e-04\n",
      "Epoch 89/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6109 - bpp: 1.5727 - mse: 1.8544e-04\n",
      "Epoch 89: loss did not improve from 4.22729\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.6109 - bpp: 1.5727 - mse: 1.8544e-04\n",
      "Epoch 90/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7668 - bpp: 1.4866 - mse: 1.3917e-04\n",
      "Epoch 90: loss improved from 4.22729 to 3.76678, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 3.7668 - bpp: 1.4866 - mse: 1.3917e-04\n",
      "Epoch 91/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1077 - bpp: 1.5499 - mse: 1.5611e-04\n",
      "Epoch 91: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.1077 - bpp: 1.5499 - mse: 1.5611e-04\n",
      "Epoch 92/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0946 - bpp: 1.5487 - mse: 1.5539e-04\n",
      "Epoch 92: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.0946 - bpp: 1.5487 - mse: 1.5539e-04\n",
      "Epoch 93/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1359 - bpp: 1.5515 - mse: 1.5774e-04\n",
      "Epoch 93: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.1359 - bpp: 1.5515 - mse: 1.5774e-04\n",
      "Epoch 94/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5412 - bpp: 1.5944 - mse: 1.7986e-04\n",
      "Epoch 94: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.5412 - bpp: 1.5944 - mse: 1.7986e-04\n",
      "Epoch 95/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2617 - bpp: 1.5531 - mse: 1.6532e-04\n",
      "Epoch 95: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.2617 - bpp: 1.5531 - mse: 1.6532e-04\n",
      "Epoch 96/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0182 - bpp: 1.5426 - mse: 1.5110e-04\n",
      "Epoch 96: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 4.0182 - bpp: 1.5426 - mse: 1.5110e-04\n",
      "Epoch 97/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0457 - bpp: 1.5530 - mse: 1.5214e-04\n",
      "Epoch 97: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.0457 - bpp: 1.5530 - mse: 1.5214e-04\n",
      "Epoch 98/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2792 - bpp: 1.6068 - mse: 1.6311e-04\n",
      "Epoch 98: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2792 - bpp: 1.6068 - mse: 1.6311e-04\n",
      "Epoch 99/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 33.1320 - bpp: 1.8811 - mse: 0.0019\n",
      "Epoch 99: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 33.1320 - bpp: 1.8811 - mse: 0.0019\n",
      "Epoch 100/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0595 - bpp: 1.7106 - mse: 2.6544e-04\n",
      "Epoch 100: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.0595 - bpp: 1.7106 - mse: 2.6544e-04\n",
      "Epoch 101/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1965 - bpp: 1.6432 - mse: 2.1688e-04\n",
      "Epoch 101: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.1965 - bpp: 1.6432 - mse: 2.1688e-04\n",
      "Epoch 102/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7169 - bpp: 1.5713 - mse: 1.9200e-04\n",
      "Epoch 102: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.7169 - bpp: 1.5713 - mse: 1.9200e-04\n",
      "Epoch 103/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5088 - bpp: 1.5724 - mse: 1.7922e-04\n",
      "Epoch 103: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.5088 - bpp: 1.5724 - mse: 1.7922e-04\n",
      "Epoch 104/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2110 - bpp: 1.5547 - mse: 1.6212e-04\n",
      "Epoch 104: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2110 - bpp: 1.5547 - mse: 1.6212e-04\n",
      "Epoch 105/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5198 - bpp: 1.5750 - mse: 1.7974e-04\n",
      "Epoch 105: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 4.5198 - bpp: 1.5750 - mse: 1.7974e-04\n",
      "Epoch 106/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3692 - bpp: 1.5983 - mse: 1.6912e-04\n",
      "Epoch 106: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.3692 - bpp: 1.5983 - mse: 1.6912e-04\n",
      "Epoch 107/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9049 - bpp: 1.4887 - mse: 1.4747e-04\n",
      "Epoch 107: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9049 - bpp: 1.4887 - mse: 1.4747e-04\n",
      "Epoch 108/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0894 - bpp: 1.5632 - mse: 1.5419e-04\n",
      "Epoch 108: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.0894 - bpp: 1.5632 - mse: 1.5419e-04\n",
      "Epoch 109/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8601 - bpp: 1.5424 - mse: 1.4146e-04\n",
      "Epoch 109: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 3.8601 - bpp: 1.5424 - mse: 1.4146e-04\n",
      "Epoch 110/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0414 - bpp: 1.5628 - mse: 1.5128e-04\n",
      "Epoch 110: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 4.0414 - bpp: 1.5628 - mse: 1.5128e-04\n",
      "Epoch 111/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2286 - bpp: 1.5704 - mse: 1.6224e-04\n",
      "Epoch 111: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.2286 - bpp: 1.5704 - mse: 1.6224e-04\n",
      "Epoch 112/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1009 - bpp: 1.5665 - mse: 1.5468e-04\n",
      "Epoch 112: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 4.1009 - bpp: 1.5665 - mse: 1.5468e-04\n",
      "Epoch 113/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0624 - bpp: 1.5547 - mse: 1.5306e-04\n",
      "Epoch 113: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.0624 - bpp: 1.5547 - mse: 1.5306e-04\n",
      "Epoch 114/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0835 - bpp: 1.5583 - mse: 1.5412e-04\n",
      "Epoch 114: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 4.0835 - bpp: 1.5583 - mse: 1.5412e-04\n",
      "Epoch 115/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7872 - bpp: 1.5159 - mse: 1.3863e-04\n",
      "Epoch 115: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.7872 - bpp: 1.5159 - mse: 1.3863e-04\n",
      "Epoch 116/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9057 - bpp: 1.5347 - mse: 1.4471e-04\n",
      "Epoch 116: loss did not improve from 3.76678\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.9057 - bpp: 1.5347 - mse: 1.4471e-04\n",
      "Epoch 117/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6772 - bpp: 1.5155 - mse: 1.3193e-04\n",
      "Epoch 117: loss improved from 3.76678 to 3.67715, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.6772 - bpp: 1.5155 - mse: 1.3193e-04\n",
      "Epoch 118/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0078 - bpp: 1.5493 - mse: 1.5005e-04\n",
      "Epoch 118: loss did not improve from 3.67715\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.0078 - bpp: 1.5493 - mse: 1.5005e-04\n",
      "Epoch 119/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0058 - bpp: 1.5450 - mse: 1.5020e-04\n",
      "Epoch 119: loss did not improve from 3.67715\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.0058 - bpp: 1.5450 - mse: 1.5020e-04\n",
      "Epoch 120/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5911 - bpp: 1.4946 - mse: 1.2795e-04\n",
      "Epoch 120: loss improved from 3.67715 to 3.59106, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.5911 - bpp: 1.4946 - mse: 1.2795e-04\n",
      "Epoch 121/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8688 - bpp: 1.5260 - mse: 1.4299e-04\n",
      "Epoch 121: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.8688 - bpp: 1.5260 - mse: 1.4299e-04\n",
      "Epoch 122/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9717 - bpp: 1.5290 - mse: 1.4909e-04\n",
      "Epoch 122: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9717 - bpp: 1.5290 - mse: 1.4909e-04\n",
      "Epoch 123/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3046 - bpp: 1.5326 - mse: 1.6919e-04\n",
      "Epoch 123: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 4.3046 - bpp: 1.5326 - mse: 1.6919e-04\n",
      "Epoch 124/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3303 - bpp: 1.5422 - mse: 1.7017e-04\n",
      "Epoch 124: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.3303 - bpp: 1.5422 - mse: 1.7017e-04\n",
      "Epoch 125/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6755 - bpp: 1.5632 - mse: 1.8996e-04\n",
      "Epoch 125: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.6755 - bpp: 1.5632 - mse: 1.8996e-04\n",
      "Epoch 126/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6418 - bpp: 1.4785 - mse: 1.3204e-04\n",
      "Epoch 126: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.6418 - bpp: 1.4785 - mse: 1.3204e-04\n",
      "Epoch 127/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0233 - bpp: 1.5230 - mse: 1.5261e-04\n",
      "Epoch 127: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.0233 - bpp: 1.5230 - mse: 1.5261e-04\n",
      "Epoch 128/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8527 - bpp: 1.5237 - mse: 1.4216e-04\n",
      "Epoch 128: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.8527 - bpp: 1.5237 - mse: 1.4216e-04\n",
      "Epoch 129/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7963 - bpp: 1.5114 - mse: 1.3946e-04\n",
      "Epoch 129: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.7963 - bpp: 1.5114 - mse: 1.3946e-04\n",
      "Epoch 130/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0986 - bpp: 1.5191 - mse: 1.5744e-04\n",
      "Epoch 130: loss did not improve from 3.59106\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 4.0986 - bpp: 1.5191 - mse: 1.5744e-04\n",
      "Epoch 131/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2922 - bpp: 1.4367 - mse: 1.1325e-04\n",
      "Epoch 131: loss improved from 3.59106 to 3.29218, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.2922 - bpp: 1.4367 - mse: 1.1325e-04\n",
      "Epoch 132/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9950 - bpp: 1.5146 - mse: 1.5139e-04\n",
      "Epoch 132: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9950 - bpp: 1.5146 - mse: 1.5139e-04\n",
      "Epoch 133/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8677 - bpp: 1.6161 - mse: 1.9846e-04\n",
      "Epoch 133: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.8677 - bpp: 1.6161 - mse: 1.9846e-04\n",
      "Epoch 134/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8351 - bpp: 1.5118 - mse: 1.4180e-04\n",
      "Epoch 134: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.8351 - bpp: 1.5118 - mse: 1.4180e-04\n",
      "Epoch 135/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9609 - bpp: 1.5286 - mse: 1.4845e-04\n",
      "Epoch 135: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.9609 - bpp: 1.5286 - mse: 1.4845e-04\n",
      "Epoch 136/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9344 - bpp: 1.5510 - mse: 1.4547e-04\n",
      "Epoch 136: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.9344 - bpp: 1.5510 - mse: 1.4547e-04\n",
      "Epoch 137/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0937 - bpp: 1.5111 - mse: 1.5763e-04\n",
      "Epoch 137: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.0937 - bpp: 1.5111 - mse: 1.5763e-04\n",
      "Epoch 138/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7417 - bpp: 1.5759 - mse: 1.9322e-04\n",
      "Epoch 138: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.7417 - bpp: 1.5759 - mse: 1.9322e-04\n",
      "Epoch 139/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3237 - bpp: 1.5890 - mse: 1.6691e-04\n",
      "Epoch 139: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.3237 - bpp: 1.5890 - mse: 1.6691e-04\n",
      "Epoch 140/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5306 - bpp: 1.5832 - mse: 1.7989e-04\n",
      "Epoch 140: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.5306 - bpp: 1.5832 - mse: 1.7989e-04\n",
      "Epoch 141/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9988 - bpp: 1.5379 - mse: 1.5020e-04\n",
      "Epoch 141: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 3.9988 - bpp: 1.5379 - mse: 1.5020e-04\n",
      "Epoch 142/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6665 - bpp: 1.4878 - mse: 1.3298e-04\n",
      "Epoch 142: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.6665 - bpp: 1.4878 - mse: 1.3298e-04\n",
      "Epoch 143/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4951 - bpp: 1.4596 - mse: 1.2424e-04\n",
      "Epoch 143: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.4951 - bpp: 1.4596 - mse: 1.2424e-04\n",
      "Epoch 144/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2327 - bpp: 1.5657 - mse: 1.6278e-04\n",
      "Epoch 144: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.2327 - bpp: 1.5657 - mse: 1.6278e-04\n",
      "Epoch 145/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4996 - bpp: 1.4896 - mse: 1.2268e-04\n",
      "Epoch 145: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 3.4996 - bpp: 1.4896 - mse: 1.2268e-04\n",
      "Epoch 146/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6147 - bpp: 1.4689 - mse: 1.3097e-04\n",
      "Epoch 146: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.6147 - bpp: 1.4689 - mse: 1.3097e-04\n",
      "Epoch 147/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7885 - bpp: 1.5319 - mse: 1.3773e-04\n",
      "Epoch 147: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7885 - bpp: 1.5319 - mse: 1.3773e-04\n",
      "Epoch 148/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6423 - bpp: 1.4706 - mse: 1.3255e-04\n",
      "Epoch 148: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.6423 - bpp: 1.4706 - mse: 1.3255e-04\n",
      "Epoch 149/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3753 - bpp: 1.4597 - mse: 1.1692e-04\n",
      "Epoch 149: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.3753 - bpp: 1.4597 - mse: 1.1692e-04\n",
      "Epoch 150/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5960 - bpp: 1.4895 - mse: 1.2857e-04\n",
      "Epoch 150: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.5960 - bpp: 1.4895 - mse: 1.2857e-04\n",
      "Epoch 151/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5621 - bpp: 1.4534 - mse: 1.2871e-04\n",
      "Epoch 151: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.5621 - bpp: 1.4534 - mse: 1.2871e-04\n",
      "Epoch 152/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8925 - bpp: 1.5369 - mse: 1.4378e-04\n",
      "Epoch 152: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 3.8925 - bpp: 1.5369 - mse: 1.4378e-04\n",
      "Epoch 153/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1808 - bpp: 1.5603 - mse: 4.0408e-04\n",
      "Epoch 153: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.1808 - bpp: 1.5603 - mse: 4.0408e-04\n",
      "Epoch 154/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4822 - bpp: 1.8246 - mse: 3.4531e-04\n",
      "Epoch 154: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 7.4822 - bpp: 1.8246 - mse: 3.4531e-04\n",
      "Epoch 155/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1194 - bpp: 1.6164 - mse: 1.5277e-04\n",
      "Epoch 155: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.1194 - bpp: 1.6164 - mse: 1.5277e-04\n",
      "Epoch 156/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6502 - bpp: 1.5569 - mse: 1.2777e-04\n",
      "Epoch 156: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.6502 - bpp: 1.5569 - mse: 1.2777e-04\n",
      "Epoch 157/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5286 - bpp: 1.5122 - mse: 1.2307e-04\n",
      "Epoch 157: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.5286 - bpp: 1.5122 - mse: 1.2307e-04\n",
      "Epoch 158/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8351 - bpp: 1.5347 - mse: 1.4041e-04\n",
      "Epoch 158: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.8351 - bpp: 1.5347 - mse: 1.4041e-04\n",
      "Epoch 159/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4522 - bpp: 1.5031 - mse: 1.1896e-04\n",
      "Epoch 159: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.4522 - bpp: 1.5031 - mse: 1.1896e-04\n",
      "Epoch 160/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8505 - bpp: 1.5254 - mse: 1.4191e-04\n",
      "Epoch 160: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.8505 - bpp: 1.5254 - mse: 1.4191e-04\n",
      "Epoch 161/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4344 - bpp: 1.4978 - mse: 1.1820e-04\n",
      "Epoch 161: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 3.4344 - bpp: 1.4978 - mse: 1.1820e-04\n",
      "Epoch 162/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6187 - bpp: 1.5452 - mse: 1.2656e-04\n",
      "Epoch 162: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.6187 - bpp: 1.5452 - mse: 1.2656e-04\n",
      "Epoch 163/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8780 - bpp: 1.5377 - mse: 1.4284e-04\n",
      "Epoch 163: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.8780 - bpp: 1.5377 - mse: 1.4284e-04\n",
      "Epoch 164/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5568 - bpp: 1.4829 - mse: 1.2658e-04\n",
      "Epoch 164: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.5568 - bpp: 1.4829 - mse: 1.2658e-04\n",
      "Epoch 165/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7977 - bpp: 1.4932 - mse: 1.4065e-04\n",
      "Epoch 165: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.7977 - bpp: 1.4932 - mse: 1.4065e-04\n",
      "Epoch 166/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8802 - bpp: 1.5039 - mse: 1.4504e-04\n",
      "Epoch 166: loss did not improve from 3.29218\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.8802 - bpp: 1.5039 - mse: 1.4504e-04\n",
      "Epoch 167/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2859 - bpp: 1.4521 - mse: 1.1193e-04\n",
      "Epoch 167: loss improved from 3.29218 to 3.28589, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.2859 - bpp: 1.4521 - mse: 1.1193e-04\n",
      "Epoch 168/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5496 - bpp: 1.4950 - mse: 1.2540e-04\n",
      "Epoch 168: loss did not improve from 3.28589\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.5496 - bpp: 1.4950 - mse: 1.2540e-04\n",
      "Epoch 169/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1490 - bpp: 1.3995 - mse: 1.0678e-04\n",
      "Epoch 169: loss improved from 3.28589 to 3.14902, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.1490 - bpp: 1.3995 - mse: 1.0678e-04\n",
      "Epoch 170/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7982 - bpp: 1.5144 - mse: 1.3939e-04\n",
      "Epoch 170: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.7982 - bpp: 1.5144 - mse: 1.3939e-04\n",
      "Epoch 171/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4418 - bpp: 1.4658 - mse: 1.2061e-04\n",
      "Epoch 171: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.4418 - bpp: 1.4658 - mse: 1.2061e-04\n",
      "Epoch 172/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8426 - bpp: 1.5253 - mse: 1.4144e-04\n",
      "Epoch 172: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.8426 - bpp: 1.5253 - mse: 1.4144e-04\n",
      "Epoch 173/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3771 - bpp: 1.4480 - mse: 1.1774e-04\n",
      "Epoch 173: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3771 - bpp: 1.4480 - mse: 1.1774e-04\n",
      "Epoch 174/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5238 - bpp: 1.4605 - mse: 1.2594e-04\n",
      "Epoch 174: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.5238 - bpp: 1.4605 - mse: 1.2594e-04\n",
      "Epoch 175/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3311 - bpp: 1.4288 - mse: 1.1611e-04\n",
      "Epoch 175: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.3311 - bpp: 1.4288 - mse: 1.1611e-04\n",
      "Epoch 176/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1000 - bpp: 1.5587 - mse: 1.5511e-04\n",
      "Epoch 176: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.1000 - bpp: 1.5587 - mse: 1.5511e-04\n",
      "Epoch 177/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2139 - bpp: 1.4189 - mse: 1.0956e-04\n",
      "Epoch 177: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2139 - bpp: 1.4189 - mse: 1.0956e-04\n",
      "Epoch 178/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2118 - bpp: 1.4155 - mse: 1.0964e-04\n",
      "Epoch 178: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2118 - bpp: 1.4155 - mse: 1.0964e-04\n",
      "Epoch 179/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7141 - bpp: 1.5154 - mse: 1.3420e-04\n",
      "Epoch 179: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 3.7141 - bpp: 1.5154 - mse: 1.3420e-04\n",
      "Epoch 180/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3092 - bpp: 1.4512 - mse: 1.1340e-04\n",
      "Epoch 180: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3092 - bpp: 1.4512 - mse: 1.1340e-04\n",
      "Epoch 181/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3336 - bpp: 1.4340 - mse: 1.1594e-04\n",
      "Epoch 181: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 3.3336 - bpp: 1.4340 - mse: 1.1594e-04\n",
      "Epoch 182/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4407 - bpp: 1.4626 - mse: 1.2073e-04\n",
      "Epoch 182: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.4407 - bpp: 1.4626 - mse: 1.2073e-04\n",
      "Epoch 183/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1549 - bpp: 1.4140 - mse: 1.0626e-04\n",
      "Epoch 183: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.1549 - bpp: 1.4140 - mse: 1.0626e-04\n",
      "Epoch 184/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3828 - bpp: 1.4502 - mse: 1.1796e-04\n",
      "Epoch 184: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3828 - bpp: 1.4502 - mse: 1.1796e-04\n",
      "Epoch 185/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2611 - bpp: 1.4294 - mse: 1.1180e-04\n",
      "Epoch 185: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 3.2611 - bpp: 1.4294 - mse: 1.1180e-04\n",
      "Epoch 186/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3537 - bpp: 1.4610 - mse: 1.1552e-04\n",
      "Epoch 186: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3537 - bpp: 1.4610 - mse: 1.1552e-04\n",
      "Epoch 187/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7003 - bpp: 1.5078 - mse: 1.3382e-04\n",
      "Epoch 187: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.7003 - bpp: 1.5078 - mse: 1.3382e-04\n",
      "Epoch 188/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4774 - bpp: 1.4517 - mse: 1.2364e-04\n",
      "Epoch 188: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 3.4774 - bpp: 1.4517 - mse: 1.2364e-04\n",
      "Epoch 189/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4297 - bpp: 1.4806 - mse: 1.1896e-04\n",
      "Epoch 189: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.4297 - bpp: 1.4806 - mse: 1.1896e-04\n",
      "Epoch 190/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7744 - bpp: 1.5446 - mse: 1.3609e-04\n",
      "Epoch 190: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 3.7744 - bpp: 1.5446 - mse: 1.3609e-04\n",
      "Epoch 191/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5429 - bpp: 1.4631 - mse: 1.2694e-04\n",
      "Epoch 191: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 3.5429 - bpp: 1.4631 - mse: 1.2694e-04\n",
      "Epoch 192/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4035 - bpp: 1.4849 - mse: 1.1710e-04\n",
      "Epoch 192: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.4035 - bpp: 1.4849 - mse: 1.1710e-04\n",
      "Epoch 193/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2777 - bpp: 1.4528 - mse: 1.1139e-04\n",
      "Epoch 193: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.2777 - bpp: 1.4528 - mse: 1.1139e-04\n",
      "Epoch 194/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2226 - bpp: 1.5164 - mse: 2.8724e-04\n",
      "Epoch 194: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.2226 - bpp: 1.5164 - mse: 2.8724e-04\n",
      "Epoch 195/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1197 - bpp: 1.5888 - mse: 2.1551e-04\n",
      "Epoch 195: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 5.1197 - bpp: 1.5888 - mse: 2.1551e-04\n",
      "Epoch 196/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3444 - bpp: 1.5003 - mse: 1.1255e-04\n",
      "Epoch 196: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.3444 - bpp: 1.5003 - mse: 1.1255e-04\n",
      "Epoch 197/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2988 - bpp: 1.5336 - mse: 1.6877e-04\n",
      "Epoch 197: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 4.2988 - bpp: 1.5336 - mse: 1.6877e-04\n",
      "Epoch 198/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1850 - bpp: 1.4481 - mse: 1.0601e-04\n",
      "Epoch 198: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.1850 - bpp: 1.4481 - mse: 1.0601e-04\n",
      "Epoch 199/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1997 - bpp: 1.4370 - mse: 1.0758e-04\n",
      "Epoch 199: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.1997 - bpp: 1.4370 - mse: 1.0758e-04\n",
      "Epoch 200/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2974 - bpp: 1.4620 - mse: 1.1202e-04\n",
      "Epoch 200: loss did not improve from 3.14902\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2974 - bpp: 1.4620 - mse: 1.1202e-04\n",
      "Epoch 201/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1289 - bpp: 1.4272 - mse: 1.0386e-04\n",
      "Epoch 201: loss improved from 3.14902 to 3.12888, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.1289 - bpp: 1.4272 - mse: 1.0386e-04\n",
      "Epoch 202/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2892 - bpp: 1.4694 - mse: 1.1107e-04\n",
      "Epoch 202: loss did not improve from 3.12888\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.2892 - bpp: 1.4694 - mse: 1.1107e-04\n",
      "Epoch 203/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6172 - bpp: 1.4519 - mse: 1.3216e-04\n",
      "Epoch 203: loss did not improve from 3.12888\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.6172 - bpp: 1.4519 - mse: 1.3216e-04\n",
      "Epoch 204/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3441 - bpp: 1.4304 - mse: 1.1680e-04\n",
      "Epoch 204: loss did not improve from 3.12888\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.3441 - bpp: 1.4304 - mse: 1.1680e-04\n",
      "Epoch 205/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0622 - bpp: 1.3988 - mse: 1.0152e-04\n",
      "Epoch 205: loss improved from 3.12888 to 3.06220, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.0622 - bpp: 1.3988 - mse: 1.0152e-04\n",
      "Epoch 206/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3241 - bpp: 1.4330 - mse: 1.1542e-04\n",
      "Epoch 206: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3241 - bpp: 1.4330 - mse: 1.1542e-04\n",
      "Epoch 207/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1317 - bpp: 1.4021 - mse: 1.0557e-04\n",
      "Epoch 207: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1317 - bpp: 1.4021 - mse: 1.0557e-04\n",
      "Epoch 208/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0716 - bpp: 1.3959 - mse: 1.0228e-04\n",
      "Epoch 208: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.0716 - bpp: 1.3959 - mse: 1.0228e-04\n",
      "Epoch 209/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0799 - bpp: 1.4097 - mse: 1.0194e-04\n",
      "Epoch 209: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 3.0799 - bpp: 1.4097 - mse: 1.0194e-04\n",
      "Epoch 210/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4035 - bpp: 1.4402 - mse: 1.1983e-04\n",
      "Epoch 210: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.4035 - bpp: 1.4402 - mse: 1.1983e-04\n",
      "Epoch 211/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3495 - bpp: 1.4414 - mse: 1.1646e-04\n",
      "Epoch 211: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3495 - bpp: 1.4414 - mse: 1.1646e-04\n",
      "Epoch 212/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1086 - bpp: 1.4138 - mse: 1.0344e-04\n",
      "Epoch 212: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.1086 - bpp: 1.4138 - mse: 1.0344e-04\n",
      "Epoch 213/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2371 - bpp: 1.4184 - mse: 1.1101e-04\n",
      "Epoch 213: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.2371 - bpp: 1.4184 - mse: 1.1101e-04\n",
      "Epoch 214/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1750 - bpp: 1.4337 - mse: 1.0628e-04\n",
      "Epoch 214: loss did not improve from 3.06220\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.1750 - bpp: 1.4337 - mse: 1.0628e-04\n",
      "Epoch 215/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9591 - bpp: 1.3940 - mse: 9.5530e-05\n",
      "Epoch 215: loss improved from 3.06220 to 2.95914, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.9591 - bpp: 1.3940 - mse: 9.5530e-05\n",
      "Epoch 216/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0078 - bpp: 1.3822 - mse: 9.9216e-05\n",
      "Epoch 216: loss did not improve from 2.95914\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.0078 - bpp: 1.3822 - mse: 9.9216e-05\n",
      "Epoch 217/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9501 - bpp: 1.3990 - mse: 9.4669e-05\n",
      "Epoch 217: loss improved from 2.95914 to 2.95011, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.9501 - bpp: 1.3990 - mse: 9.4669e-05\n",
      "Epoch 218/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7064 - bpp: 1.4724 - mse: 1.3636e-04\n",
      "Epoch 218: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.7064 - bpp: 1.4724 - mse: 1.3636e-04\n",
      "Epoch 219/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3713 - bpp: 1.4540 - mse: 1.1702e-04\n",
      "Epoch 219: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.3713 - bpp: 1.4540 - mse: 1.1702e-04\n",
      "Epoch 220/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0330 - bpp: 1.3825 - mse: 1.0073e-04\n",
      "Epoch 220: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.0330 - bpp: 1.3825 - mse: 1.0073e-04\n",
      "Epoch 221/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2884 - bpp: 1.4341 - mse: 1.1318e-04\n",
      "Epoch 221: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.2884 - bpp: 1.4341 - mse: 1.1318e-04\n",
      "Epoch 222/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3408 - bpp: 1.4549 - mse: 1.7614e-04\n",
      "Epoch 222: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 4.3408 - bpp: 1.4549 - mse: 1.7614e-04\n",
      "Epoch 223/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2528 - bpp: 1.4399 - mse: 1.1065e-04\n",
      "Epoch 223: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 3.2528 - bpp: 1.4399 - mse: 1.1065e-04\n",
      "Epoch 224/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0187 - bpp: 1.4356 - mse: 9.6628e-05\n",
      "Epoch 224: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.0187 - bpp: 1.4356 - mse: 9.6628e-05\n",
      "Epoch 225/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3751 - bpp: 1.4522 - mse: 1.1737e-04\n",
      "Epoch 225: loss did not improve from 2.95011\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.3751 - bpp: 1.4522 - mse: 1.1737e-04\n",
      "Epoch 226/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8230 - bpp: 1.3690 - mse: 8.8743e-05\n",
      "Epoch 226: loss improved from 2.95011 to 2.82300, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.8230 - bpp: 1.3690 - mse: 8.8743e-05\n",
      "Epoch 227/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2057 - bpp: 1.4276 - mse: 1.0853e-04\n",
      "Epoch 227: loss did not improve from 2.82300\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.2057 - bpp: 1.4276 - mse: 1.0853e-04\n",
      "Epoch 228/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3108 - bpp: 1.4425 - mse: 1.1403e-04\n",
      "Epoch 228: loss did not improve from 2.82300\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 3.3108 - bpp: 1.4425 - mse: 1.1403e-04\n",
      "Epoch 229/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9922 - bpp: 1.4002 - mse: 9.7167e-05\n",
      "Epoch 229: loss did not improve from 2.82300\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.9922 - bpp: 1.4002 - mse: 9.7167e-05\n",
      "Epoch 230/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8789 - bpp: 1.3658 - mse: 9.2349e-05\n",
      "Epoch 230: loss did not improve from 2.82300\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.8789 - bpp: 1.3658 - mse: 9.2349e-05\n",
      "Epoch 231/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7424 - bpp: 1.3458 - mse: 8.5245e-05\n",
      "Epoch 231: loss improved from 2.82300 to 2.74244, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.7424 - bpp: 1.3458 - mse: 8.5245e-05\n",
      "Epoch 232/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9406 - bpp: 1.3816 - mse: 9.5157e-05\n",
      "Epoch 232: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9406 - bpp: 1.3816 - mse: 9.5157e-05\n",
      "Epoch 233/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1616 - bpp: 1.4277 - mse: 1.0582e-04\n",
      "Epoch 233: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1616 - bpp: 1.4277 - mse: 1.0582e-04\n",
      "Epoch 234/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1426 - bpp: 1.4140 - mse: 1.0551e-04\n",
      "Epoch 234: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.1426 - bpp: 1.4140 - mse: 1.0551e-04\n",
      "Epoch 235/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1201 - bpp: 1.4133 - mse: 1.0418e-04\n",
      "Epoch 235: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.1201 - bpp: 1.4133 - mse: 1.0418e-04\n",
      "Epoch 236/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9023 - bpp: 1.3734 - mse: 9.3314e-05\n",
      "Epoch 236: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.9023 - bpp: 1.3734 - mse: 9.3314e-05\n",
      "Epoch 237/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4243 - bpp: 1.4700 - mse: 1.1929e-04\n",
      "Epoch 237: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.4243 - bpp: 1.4700 - mse: 1.1929e-04\n",
      "Epoch 238/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9727 - bpp: 1.3636 - mse: 9.8208e-05\n",
      "Epoch 238: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9727 - bpp: 1.3636 - mse: 9.8208e-05\n",
      "Epoch 239/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0023 - bpp: 1.3769 - mse: 9.9210e-05\n",
      "Epoch 239: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.0023 - bpp: 1.3769 - mse: 9.9210e-05\n",
      "Epoch 240/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9838 - bpp: 1.3819 - mse: 9.7772e-05\n",
      "Epoch 240: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9838 - bpp: 1.3819 - mse: 9.7772e-05\n",
      "Epoch 241/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8867 - bpp: 1.3523 - mse: 9.3654e-05\n",
      "Epoch 241: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.8867 - bpp: 1.3523 - mse: 9.3654e-05\n",
      "Epoch 242/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8839 - bpp: 1.3437 - mse: 9.4006e-05\n",
      "Epoch 242: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8839 - bpp: 1.3437 - mse: 9.4006e-05\n",
      "Epoch 243/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1144 - bpp: 1.4241 - mse: 1.0317e-04\n",
      "Epoch 243: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1144 - bpp: 1.4241 - mse: 1.0317e-04\n",
      "Epoch 244/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2741 - bpp: 1.4454 - mse: 1.1162e-04\n",
      "Epoch 244: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 3.2741 - bpp: 1.4454 - mse: 1.1162e-04\n",
      "Epoch 245/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9441 - bpp: 1.3902 - mse: 9.4845e-05\n",
      "Epoch 245: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.9441 - bpp: 1.3902 - mse: 9.4845e-05\n",
      "Epoch 246/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6265 - bpp: 1.5796 - mse: 4.3011e-04\n",
      "Epoch 246: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.6265 - bpp: 1.5796 - mse: 4.3011e-04\n",
      "Epoch 247/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1396 - bpp: 1.6002 - mse: 1.5500e-04\n",
      "Epoch 247: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.1396 - bpp: 1.6002 - mse: 1.5500e-04\n",
      "Epoch 248/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2665 - bpp: 1.4655 - mse: 1.0993e-04\n",
      "Epoch 248: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.2665 - bpp: 1.4655 - mse: 1.0993e-04\n",
      "Epoch 249/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1691 - bpp: 1.4510 - mse: 1.0486e-04\n",
      "Epoch 249: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1691 - bpp: 1.4510 - mse: 1.0486e-04\n",
      "Epoch 250/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9710 - bpp: 1.3984 - mse: 9.5985e-05\n",
      "Epoch 250: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.9710 - bpp: 1.3984 - mse: 9.5985e-05\n",
      "Epoch 251/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7462 - bpp: 1.3661 - mse: 8.4234e-05\n",
      "Epoch 251: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.7462 - bpp: 1.3661 - mse: 8.4234e-05\n",
      "Epoch 252/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9891 - bpp: 1.4246 - mse: 9.5489e-05\n",
      "Epoch 252: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 2.9891 - bpp: 1.4246 - mse: 9.5489e-05\n",
      "Epoch 253/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1274 - bpp: 1.4300 - mse: 1.0360e-04\n",
      "Epoch 253: loss did not improve from 2.74244\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.1274 - bpp: 1.4300 - mse: 1.0360e-04\n",
      "Epoch 254/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7266 - bpp: 1.3480 - mse: 8.4143e-05\n",
      "Epoch 254: loss improved from 2.74244 to 2.72657, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.7266 - bpp: 1.3480 - mse: 8.4143e-05\n",
      "Epoch 255/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1374 - bpp: 1.4427 - mse: 1.0343e-04\n",
      "Epoch 255: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 3.1374 - bpp: 1.4427 - mse: 1.0343e-04\n",
      "Epoch 256/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7682 - bpp: 1.3858 - mse: 8.4374e-05\n",
      "Epoch 256: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.7682 - bpp: 1.3858 - mse: 8.4374e-05\n",
      "Epoch 257/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9404 - bpp: 1.3722 - mse: 9.5714e-05\n",
      "Epoch 257: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9404 - bpp: 1.3722 - mse: 9.5714e-05\n",
      "Epoch 258/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9111 - bpp: 1.4067 - mse: 9.1818e-05\n",
      "Epoch 258: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9111 - bpp: 1.4067 - mse: 9.1818e-05\n",
      "Epoch 259/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9653 - bpp: 1.3569 - mse: 9.8167e-05\n",
      "Epoch 259: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.9653 - bpp: 1.3569 - mse: 9.8167e-05\n",
      "Epoch 260/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8137 - bpp: 1.3731 - mse: 8.7931e-05\n",
      "Epoch 260: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8137 - bpp: 1.3731 - mse: 8.7931e-05\n",
      "Epoch 261/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8222 - bpp: 1.3689 - mse: 8.8705e-05\n",
      "Epoch 261: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.8222 - bpp: 1.3689 - mse: 8.8705e-05\n",
      "Epoch 262/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9485 - bpp: 1.4079 - mse: 9.4033e-05\n",
      "Epoch 262: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9485 - bpp: 1.4079 - mse: 9.4033e-05\n",
      "Epoch 263/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0374 - bpp: 1.4311 - mse: 9.8036e-05\n",
      "Epoch 263: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.0374 - bpp: 1.4311 - mse: 9.8036e-05\n",
      "Epoch 264/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9932 - bpp: 1.4099 - mse: 9.6640e-05\n",
      "Epoch 264: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9932 - bpp: 1.4099 - mse: 9.6640e-05\n",
      "Epoch 265/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9170 - bpp: 1.3818 - mse: 9.3701e-05\n",
      "Epoch 265: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9170 - bpp: 1.3818 - mse: 9.3701e-05\n",
      "Epoch 266/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9705 - bpp: 1.3800 - mse: 9.7078e-05\n",
      "Epoch 266: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 2.9705 - bpp: 1.3800 - mse: 9.7078e-05\n",
      "Epoch 267/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0903 - bpp: 1.4079 - mse: 1.0268e-04\n",
      "Epoch 267: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.0903 - bpp: 1.4079 - mse: 1.0268e-04\n",
      "Epoch 268/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9577 - bpp: 1.3925 - mse: 9.5531e-05\n",
      "Epoch 268: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.9577 - bpp: 1.3925 - mse: 9.5531e-05\n",
      "Epoch 269/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8191 - bpp: 1.3735 - mse: 8.8236e-05\n",
      "Epoch 269: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.8191 - bpp: 1.3735 - mse: 8.8236e-05\n",
      "Epoch 270/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1294 - bpp: 1.4139 - mse: 1.0470e-04\n",
      "Epoch 270: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1294 - bpp: 1.4139 - mse: 1.0470e-04\n",
      "Epoch 271/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0276 - bpp: 1.4003 - mse: 9.9326e-05\n",
      "Epoch 271: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 3.0276 - bpp: 1.4003 - mse: 9.9326e-05\n",
      "Epoch 272/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8095 - bpp: 1.3608 - mse: 8.8422e-05\n",
      "Epoch 272: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.8095 - bpp: 1.3608 - mse: 8.8422e-05\n",
      "Epoch 273/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9548 - bpp: 1.3581 - mse: 9.7458e-05\n",
      "Epoch 273: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9548 - bpp: 1.3581 - mse: 9.7458e-05\n",
      "Epoch 274/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1014 - bpp: 1.4127 - mse: 1.0307e-04\n",
      "Epoch 274: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.1014 - bpp: 1.4127 - mse: 1.0307e-04\n",
      "Epoch 275/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8867 - bpp: 1.3671 - mse: 9.2748e-05\n",
      "Epoch 275: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.8867 - bpp: 1.3671 - mse: 9.2748e-05\n",
      "Epoch 276/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1311 - bpp: 1.3986 - mse: 1.0574e-04\n",
      "Epoch 276: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 3.1311 - bpp: 1.3986 - mse: 1.0574e-04\n",
      "Epoch 277/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5606 - bpp: 1.4692 - mse: 1.2765e-04\n",
      "Epoch 277: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 3.5606 - bpp: 1.4692 - mse: 1.2765e-04\n",
      "Epoch 278/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7355 - bpp: 1.3732 - mse: 8.3149e-05\n",
      "Epoch 278: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7355 - bpp: 1.3732 - mse: 8.3149e-05\n",
      "Epoch 279/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8997 - bpp: 1.3702 - mse: 9.3353e-05\n",
      "Epoch 279: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8997 - bpp: 1.3702 - mse: 9.3353e-05\n",
      "Epoch 280/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0056 - bpp: 1.3769 - mse: 9.9408e-05\n",
      "Epoch 280: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.0056 - bpp: 1.3769 - mse: 9.9408e-05\n",
      "Epoch 281/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8323 - bpp: 1.3663 - mse: 8.9482e-05\n",
      "Epoch 281: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8323 - bpp: 1.3663 - mse: 8.9482e-05\n",
      "Epoch 282/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9178 - bpp: 1.3939 - mse: 9.3013e-05\n",
      "Epoch 282: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9178 - bpp: 1.3939 - mse: 9.3013e-05\n",
      "Epoch 283/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2539 - bpp: 1.3899 - mse: 1.1376e-04\n",
      "Epoch 283: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.2539 - bpp: 1.3899 - mse: 1.1376e-04\n",
      "Epoch 284/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9822 - bpp: 1.3881 - mse: 9.7300e-05\n",
      "Epoch 284: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 2.9822 - bpp: 1.3881 - mse: 9.7300e-05\n",
      "Epoch 285/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7466 - bpp: 1.3583 - mse: 8.4734e-05\n",
      "Epoch 285: loss did not improve from 2.72657\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.7466 - bpp: 1.3583 - mse: 8.4734e-05\n",
      "Epoch 286/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6864 - bpp: 1.3229 - mse: 8.3224e-05\n",
      "Epoch 286: loss improved from 2.72657 to 2.68644, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.6864 - bpp: 1.3229 - mse: 8.3224e-05\n",
      "Epoch 287/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8905 - bpp: 1.3519 - mse: 9.3910e-05\n",
      "Epoch 287: loss did not improve from 2.68644\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8905 - bpp: 1.3519 - mse: 9.3910e-05\n",
      "Epoch 288/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8631 - bpp: 1.3660 - mse: 9.1379e-05\n",
      "Epoch 288: loss did not improve from 2.68644\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.8631 - bpp: 1.3660 - mse: 9.1379e-05\n",
      "Epoch 289/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8695 - bpp: 1.3831 - mse: 9.0720e-05\n",
      "Epoch 289: loss did not improve from 2.68644\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8695 - bpp: 1.3831 - mse: 9.0720e-05\n",
      "Epoch 290/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9738 - bpp: 1.3847 - mse: 9.6991e-05\n",
      "Epoch 290: loss did not improve from 2.68644\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9738 - bpp: 1.3847 - mse: 9.6991e-05\n",
      "Epoch 291/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1211 - bpp: 1.3968 - mse: 1.0524e-04\n",
      "Epoch 291: loss did not improve from 2.68644\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 3.1211 - bpp: 1.3968 - mse: 1.0524e-04\n",
      "Epoch 292/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0687 - bpp: 1.3967 - mse: 1.0205e-04\n",
      "Epoch 292: loss did not improve from 2.68644\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.0687 - bpp: 1.3967 - mse: 1.0205e-04\n",
      "Epoch 293/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5324 - bpp: 1.3107 - mse: 7.4567e-05\n",
      "Epoch 293: loss improved from 2.68644 to 2.53238, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5324 - bpp: 1.3107 - mse: 7.4567e-05\n",
      "Epoch 294/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6622 - bpp: 1.3246 - mse: 8.1643e-05\n",
      "Epoch 294: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6622 - bpp: 1.3246 - mse: 8.1643e-05\n",
      "Epoch 295/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5888 - bpp: 1.3195 - mse: 7.7475e-05\n",
      "Epoch 295: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5888 - bpp: 1.3195 - mse: 7.7475e-05\n",
      "Epoch 296/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8437 - bpp: 1.3457 - mse: 9.1434e-05\n",
      "Epoch 296: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.8437 - bpp: 1.3457 - mse: 9.1434e-05\n",
      "Epoch 297/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9193 - bpp: 1.3881 - mse: 9.3452e-05\n",
      "Epoch 297: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9193 - bpp: 1.3881 - mse: 9.3452e-05\n",
      "Epoch 298/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9446 - bpp: 1.3940 - mse: 9.4640e-05\n",
      "Epoch 298: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9446 - bpp: 1.3940 - mse: 9.4640e-05\n",
      "Epoch 299/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8897 - bpp: 1.3849 - mse: 9.1843e-05\n",
      "Epoch 299: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.8897 - bpp: 1.3849 - mse: 9.1843e-05\n",
      "Epoch 300/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9730 - bpp: 1.3803 - mse: 9.7212e-05\n",
      "Epoch 300: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9730 - bpp: 1.3803 - mse: 9.7212e-05\n",
      "Epoch 301/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8048 - bpp: 1.3781 - mse: 8.7081e-05\n",
      "Epoch 301: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.8048 - bpp: 1.3781 - mse: 8.7081e-05\n",
      "Epoch 302/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7885 - bpp: 1.3558 - mse: 8.7443e-05\n",
      "Epoch 302: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.7885 - bpp: 1.3558 - mse: 8.7443e-05\n",
      "Epoch 303/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1794 - bpp: 1.4145 - mse: 1.0772e-04\n",
      "Epoch 303: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.1794 - bpp: 1.4145 - mse: 1.0772e-04\n",
      "Epoch 304/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9626 - bpp: 1.4059 - mse: 9.5008e-05\n",
      "Epoch 304: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9626 - bpp: 1.4059 - mse: 9.5008e-05\n",
      "Epoch 305/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6067 - bpp: 1.3291 - mse: 7.7980e-05\n",
      "Epoch 305: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6067 - bpp: 1.3291 - mse: 7.7980e-05\n",
      "Epoch 306/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7659 - bpp: 1.3694 - mse: 8.5235e-05\n",
      "Epoch 306: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7659 - bpp: 1.3694 - mse: 8.5235e-05\n",
      "Epoch 307/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7894 - bpp: 1.3366 - mse: 8.8676e-05\n",
      "Epoch 307: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.7894 - bpp: 1.3366 - mse: 8.8676e-05\n",
      "Epoch 308/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9900 - bpp: 1.4025 - mse: 9.6894e-05\n",
      "Epoch 308: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9900 - bpp: 1.4025 - mse: 9.6894e-05\n",
      "Epoch 309/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8872 - bpp: 1.3761 - mse: 9.2228e-05\n",
      "Epoch 309: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.8872 - bpp: 1.3761 - mse: 9.2228e-05\n",
      "Epoch 310/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7194 - bpp: 1.3494 - mse: 8.3617e-05\n",
      "Epoch 310: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.7194 - bpp: 1.3494 - mse: 8.3617e-05\n",
      "Epoch 311/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7756 - bpp: 1.3624 - mse: 8.6256e-05\n",
      "Epoch 311: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7756 - bpp: 1.3624 - mse: 8.6256e-05\n",
      "Epoch 312/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7307 - bpp: 1.3720 - mse: 8.2927e-05\n",
      "Epoch 312: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7307 - bpp: 1.3720 - mse: 8.2927e-05\n",
      "Epoch 313/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0008 - bpp: 1.3512 - mse: 1.0069e-04\n",
      "Epoch 313: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 3.0008 - bpp: 1.3512 - mse: 1.0069e-04\n",
      "Epoch 314/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6609 - bpp: 1.3295 - mse: 8.1263e-05\n",
      "Epoch 314: loss did not improve from 2.53238\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6609 - bpp: 1.3295 - mse: 8.1263e-05\n",
      "Epoch 315/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5231 - bpp: 1.2948 - mse: 7.4969e-05\n",
      "Epoch 315: loss improved from 2.53238 to 2.52309, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5231 - bpp: 1.2948 - mse: 7.4969e-05\n",
      "Epoch 316/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6754 - bpp: 1.3138 - mse: 8.3108e-05\n",
      "Epoch 316: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6754 - bpp: 1.3138 - mse: 8.3108e-05\n",
      "Epoch 317/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7380 - bpp: 1.3388 - mse: 8.5397e-05\n",
      "Epoch 317: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.7380 - bpp: 1.3388 - mse: 8.5397e-05\n",
      "Epoch 318/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7042 - bpp: 1.3316 - mse: 8.3777e-05\n",
      "Epoch 318: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.7042 - bpp: 1.3316 - mse: 8.3777e-05\n",
      "Epoch 319/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9478 - bpp: 1.4112 - mse: 9.3787e-05\n",
      "Epoch 319: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.9478 - bpp: 1.4112 - mse: 9.3787e-05\n",
      "Epoch 320/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8475 - bpp: 1.3681 - mse: 9.0291e-05\n",
      "Epoch 320: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.8475 - bpp: 1.3681 - mse: 9.0291e-05\n",
      "Epoch 321/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2054 - bpp: 1.3931 - mse: 1.1061e-04\n",
      "Epoch 321: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 3.2054 - bpp: 1.3931 - mse: 1.1061e-04\n",
      "Epoch 322/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0043 - bpp: 1.4087 - mse: 9.7386e-05\n",
      "Epoch 322: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 3.0043 - bpp: 1.4087 - mse: 9.7386e-05\n",
      "Epoch 323/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7210 - bpp: 1.3381 - mse: 8.4409e-05\n",
      "Epoch 323: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7210 - bpp: 1.3381 - mse: 8.4409e-05\n",
      "Epoch 324/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7670 - bpp: 1.3493 - mse: 8.6534e-05\n",
      "Epoch 324: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7670 - bpp: 1.3493 - mse: 8.6534e-05\n",
      "Epoch 325/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6717 - bpp: 1.3191 - mse: 8.2560e-05\n",
      "Epoch 325: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6717 - bpp: 1.3191 - mse: 8.2560e-05\n",
      "Epoch 326/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6513 - bpp: 1.3363 - mse: 8.0260e-05\n",
      "Epoch 326: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6513 - bpp: 1.3363 - mse: 8.0260e-05\n",
      "Epoch 327/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6505 - bpp: 1.3246 - mse: 8.0931e-05\n",
      "Epoch 327: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6505 - bpp: 1.3246 - mse: 8.0931e-05\n",
      "Epoch 328/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8298 - bpp: 1.3712 - mse: 8.9024e-05\n",
      "Epoch 328: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.8298 - bpp: 1.3712 - mse: 8.9024e-05\n",
      "Epoch 329/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6213 - bpp: 1.3171 - mse: 7.9606e-05\n",
      "Epoch 329: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6213 - bpp: 1.3171 - mse: 7.9606e-05\n",
      "Epoch 330/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6703 - bpp: 1.3202 - mse: 8.2401e-05\n",
      "Epoch 330: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6703 - bpp: 1.3202 - mse: 8.2401e-05\n",
      "Epoch 331/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8722 - bpp: 1.3830 - mse: 9.0894e-05\n",
      "Epoch 331: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8722 - bpp: 1.3830 - mse: 9.0894e-05\n",
      "Epoch 332/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5510 - bpp: 1.3123 - mse: 7.5608e-05\n",
      "Epoch 332: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5510 - bpp: 1.3123 - mse: 7.5608e-05\n",
      "Epoch 333/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7093 - bpp: 1.3264 - mse: 8.4404e-05\n",
      "Epoch 333: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7093 - bpp: 1.3264 - mse: 8.4404e-05\n",
      "Epoch 334/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8393 - bpp: 1.3744 - mse: 8.9411e-05\n",
      "Epoch 334: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8393 - bpp: 1.3744 - mse: 8.9411e-05\n",
      "Epoch 335/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6398 - bpp: 1.3246 - mse: 8.0275e-05\n",
      "Epoch 335: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.6398 - bpp: 1.3246 - mse: 8.0275e-05\n",
      "Epoch 336/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6843 - bpp: 1.3142 - mse: 8.3621e-05\n",
      "Epoch 336: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.6843 - bpp: 1.3142 - mse: 8.3621e-05\n",
      "Epoch 337/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8355 - bpp: 1.3649 - mse: 8.9758e-05\n",
      "Epoch 337: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8355 - bpp: 1.3649 - mse: 8.9758e-05\n",
      "Epoch 338/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8585 - bpp: 1.3626 - mse: 9.1301e-05\n",
      "Epoch 338: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.8585 - bpp: 1.3626 - mse: 9.1301e-05\n",
      "Epoch 339/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6907 - bpp: 1.3443 - mse: 8.2172e-05\n",
      "Epoch 339: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6907 - bpp: 1.3443 - mse: 8.2172e-05\n",
      "Epoch 340/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6062 - bpp: 1.3038 - mse: 7.9489e-05\n",
      "Epoch 340: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6062 - bpp: 1.3038 - mse: 7.9489e-05\n",
      "Epoch 341/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6930 - bpp: 1.3548 - mse: 8.1676e-05\n",
      "Epoch 341: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6930 - bpp: 1.3548 - mse: 8.1676e-05\n",
      "Epoch 342/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7887 - bpp: 1.3426 - mse: 8.8265e-05\n",
      "Epoch 342: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7887 - bpp: 1.3426 - mse: 8.8265e-05\n",
      "Epoch 343/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1998 - bpp: 1.3667 - mse: 1.1188e-04\n",
      "Epoch 343: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 3.1998 - bpp: 1.3667 - mse: 1.1188e-04\n",
      "Epoch 344/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7812 - bpp: 1.3699 - mse: 8.6139e-05\n",
      "Epoch 344: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.7812 - bpp: 1.3699 - mse: 8.6139e-05\n",
      "Epoch 345/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6605 - bpp: 1.3345 - mse: 8.0936e-05\n",
      "Epoch 345: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.6605 - bpp: 1.3345 - mse: 8.0936e-05\n",
      "Epoch 346/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7297 - bpp: 1.3600 - mse: 8.3599e-05\n",
      "Epoch 346: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7297 - bpp: 1.3600 - mse: 8.3599e-05\n",
      "Epoch 347/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8386 - bpp: 1.3644 - mse: 8.9982e-05\n",
      "Epoch 347: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.8386 - bpp: 1.3644 - mse: 8.9982e-05\n",
      "Epoch 348/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6945 - bpp: 1.3490 - mse: 8.2122e-05\n",
      "Epoch 348: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6945 - bpp: 1.3490 - mse: 8.2122e-05\n",
      "Epoch 349/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6208 - bpp: 1.3133 - mse: 7.9801e-05\n",
      "Epoch 349: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6208 - bpp: 1.3133 - mse: 7.9801e-05\n",
      "Epoch 350/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6284 - bpp: 1.3266 - mse: 7.9455e-05\n",
      "Epoch 350: loss did not improve from 2.52309\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6284 - bpp: 1.3266 - mse: 7.9455e-05\n",
      "Epoch 351/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4925 - bpp: 1.2927 - mse: 7.3234e-05\n",
      "Epoch 351: loss improved from 2.52309 to 2.49254, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4925 - bpp: 1.2927 - mse: 7.3234e-05\n",
      "Epoch 352/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7065 - bpp: 1.3469 - mse: 8.2978e-05\n",
      "Epoch 352: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.7065 - bpp: 1.3469 - mse: 8.2978e-05\n",
      "Epoch 353/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5476 - bpp: 1.3035 - mse: 7.5935e-05\n",
      "Epoch 353: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5476 - bpp: 1.3035 - mse: 7.5935e-05\n",
      "Epoch 354/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7536 - bpp: 1.3676 - mse: 8.4591e-05\n",
      "Epoch 354: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.7536 - bpp: 1.3676 - mse: 8.4591e-05\n",
      "Epoch 355/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6817 - bpp: 1.3378 - mse: 8.2026e-05\n",
      "Epoch 355: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6817 - bpp: 1.3378 - mse: 8.2026e-05\n",
      "Epoch 356/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5889 - bpp: 1.3145 - mse: 7.7782e-05\n",
      "Epoch 356: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5889 - bpp: 1.3145 - mse: 7.7782e-05\n",
      "Epoch 357/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9651 - bpp: 1.3688 - mse: 9.7432e-05\n",
      "Epoch 357: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.9651 - bpp: 1.3688 - mse: 9.7432e-05\n",
      "Epoch 358/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9167 - bpp: 1.3713 - mse: 9.4322e-05\n",
      "Epoch 358: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.9167 - bpp: 1.3713 - mse: 9.4322e-05\n",
      "Epoch 359/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8496 - bpp: 1.3718 - mse: 9.0197e-05\n",
      "Epoch 359: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.8496 - bpp: 1.3718 - mse: 9.0197e-05\n",
      "Epoch 360/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5812 - bpp: 1.3112 - mse: 7.7513e-05\n",
      "Epoch 360: loss did not improve from 2.49254\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.5812 - bpp: 1.3112 - mse: 7.7513e-05\n",
      "Epoch 361/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4808 - bpp: 1.2841 - mse: 7.3041e-05\n",
      "Epoch 361: loss improved from 2.49254 to 2.48084, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4808 - bpp: 1.2841 - mse: 7.3041e-05\n",
      "Epoch 362/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6979 - bpp: 1.3307 - mse: 8.3451e-05\n",
      "Epoch 362: loss did not improve from 2.48084\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6979 - bpp: 1.3307 - mse: 8.3451e-05\n",
      "Epoch 363/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7828 - bpp: 1.3525 - mse: 8.7304e-05\n",
      "Epoch 363: loss did not improve from 2.48084\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7828 - bpp: 1.3525 - mse: 8.7304e-05\n",
      "Epoch 364/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7488 - bpp: 1.3482 - mse: 8.5488e-05\n",
      "Epoch 364: loss did not improve from 2.48084\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.7488 - bpp: 1.3482 - mse: 8.5488e-05\n",
      "Epoch 365/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4677 - bpp: 1.2747 - mse: 7.2817e-05\n",
      "Epoch 365: loss improved from 2.48084 to 2.46770, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4677 - bpp: 1.2747 - mse: 7.2817e-05\n",
      "Epoch 366/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9525 - bpp: 1.3879 - mse: 9.5498e-05\n",
      "Epoch 366: loss did not improve from 2.46770\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.9525 - bpp: 1.3879 - mse: 9.5498e-05\n",
      "Epoch 367/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7331 - bpp: 1.3748 - mse: 8.2900e-05\n",
      "Epoch 367: loss did not improve from 2.46770\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.7331 - bpp: 1.3748 - mse: 8.2900e-05\n",
      "Epoch 368/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4041 - bpp: 1.2850 - mse: 6.8305e-05\n",
      "Epoch 368: loss improved from 2.46770 to 2.40411, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 2.4041 - bpp: 1.2850 - mse: 6.8305e-05\n",
      "Epoch 369/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4920 - bpp: 1.2869 - mse: 7.3554e-05\n",
      "Epoch 369: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4920 - bpp: 1.2869 - mse: 7.3554e-05\n",
      "Epoch 370/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5893 - bpp: 1.3255 - mse: 7.7136e-05\n",
      "Epoch 370: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5893 - bpp: 1.3255 - mse: 7.7136e-05\n",
      "Epoch 371/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5836 - bpp: 1.3061 - mse: 7.7977e-05\n",
      "Epoch 371: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5836 - bpp: 1.3061 - mse: 7.7977e-05\n",
      "Epoch 372/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6054 - bpp: 1.3227 - mse: 7.8290e-05\n",
      "Epoch 372: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.6054 - bpp: 1.3227 - mse: 7.8290e-05\n",
      "Epoch 373/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7854 - bpp: 1.3521 - mse: 8.7480e-05\n",
      "Epoch 373: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 2.7854 - bpp: 1.3521 - mse: 8.7480e-05\n",
      "Epoch 374/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8232 - bpp: 1.3523 - mse: 8.9779e-05\n",
      "Epoch 374: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8232 - bpp: 1.3523 - mse: 8.9779e-05\n",
      "Epoch 375/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6894 - bpp: 1.3288 - mse: 8.3049e-05\n",
      "Epoch 375: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6894 - bpp: 1.3288 - mse: 8.3049e-05\n",
      "Epoch 376/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4350 - bpp: 1.2667 - mse: 7.1308e-05\n",
      "Epoch 376: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4350 - bpp: 1.2667 - mse: 7.1308e-05\n",
      "Epoch 377/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6779 - bpp: 1.3323 - mse: 8.2130e-05\n",
      "Epoch 377: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6779 - bpp: 1.3323 - mse: 8.2130e-05\n",
      "Epoch 378/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7023 - bpp: 1.3540 - mse: 8.2297e-05\n",
      "Epoch 378: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7023 - bpp: 1.3540 - mse: 8.2297e-05\n",
      "Epoch 379/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8510 - bpp: 1.3666 - mse: 9.0597e-05\n",
      "Epoch 379: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8510 - bpp: 1.3666 - mse: 9.0597e-05\n",
      "Epoch 380/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5133 - bpp: 1.3041 - mse: 7.3809e-05\n",
      "Epoch 380: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5133 - bpp: 1.3041 - mse: 7.3809e-05\n",
      "Epoch 381/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5695 - bpp: 1.3048 - mse: 7.7191e-05\n",
      "Epoch 381: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5695 - bpp: 1.3048 - mse: 7.7191e-05\n",
      "Epoch 382/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6514 - bpp: 1.3462 - mse: 7.9661e-05\n",
      "Epoch 382: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6514 - bpp: 1.3462 - mse: 7.9661e-05\n",
      "Epoch 383/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7387 - bpp: 1.3537 - mse: 8.4534e-05\n",
      "Epoch 383: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7387 - bpp: 1.3537 - mse: 8.4534e-05\n",
      "Epoch 384/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6729 - bpp: 1.3362 - mse: 8.1586e-05\n",
      "Epoch 384: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6729 - bpp: 1.3362 - mse: 8.1586e-05\n",
      "Epoch 385/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4539 - bpp: 1.2916 - mse: 7.0937e-05\n",
      "Epoch 385: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.4539 - bpp: 1.2916 - mse: 7.0937e-05\n",
      "Epoch 386/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6755 - bpp: 1.3503 - mse: 8.0883e-05\n",
      "Epoch 386: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.6755 - bpp: 1.3503 - mse: 8.0883e-05\n",
      "Epoch 387/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6412 - bpp: 1.3266 - mse: 8.0237e-05\n",
      "Epoch 387: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6412 - bpp: 1.3266 - mse: 8.0237e-05\n",
      "Epoch 388/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6823 - bpp: 1.3515 - mse: 8.1224e-05\n",
      "Epoch 388: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6823 - bpp: 1.3515 - mse: 8.1224e-05\n",
      "Epoch 389/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7666 - bpp: 1.3652 - mse: 8.5536e-05\n",
      "Epoch 389: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7666 - bpp: 1.3652 - mse: 8.5536e-05\n",
      "Epoch 390/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6258 - bpp: 1.3238 - mse: 7.9471e-05\n",
      "Epoch 390: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6258 - bpp: 1.3238 - mse: 7.9471e-05\n",
      "Epoch 391/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6318 - bpp: 1.3229 - mse: 7.9884e-05\n",
      "Epoch 391: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.6318 - bpp: 1.3229 - mse: 7.9884e-05\n",
      "Epoch 392/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6864 - bpp: 1.3352 - mse: 8.2472e-05\n",
      "Epoch 392: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6864 - bpp: 1.3352 - mse: 8.2472e-05\n",
      "Epoch 393/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5828 - bpp: 1.2936 - mse: 7.8689e-05\n",
      "Epoch 393: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5828 - bpp: 1.2936 - mse: 7.8689e-05\n",
      "Epoch 394/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5725 - bpp: 1.3153 - mse: 7.6731e-05\n",
      "Epoch 394: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5725 - bpp: 1.3153 - mse: 7.6731e-05\n",
      "Epoch 395/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8332 - bpp: 1.3501 - mse: 9.0522e-05\n",
      "Epoch 395: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.8332 - bpp: 1.3501 - mse: 9.0522e-05\n",
      "Epoch 396/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6359 - bpp: 1.3127 - mse: 8.0762e-05\n",
      "Epoch 396: loss did not improve from 2.40411\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6359 - bpp: 1.3127 - mse: 8.0762e-05\n",
      "Epoch 397/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3915 - bpp: 1.2766 - mse: 6.8049e-05\n",
      "Epoch 397: loss improved from 2.40411 to 2.39153, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 2.3915 - bpp: 1.2766 - mse: 6.8049e-05\n",
      "Epoch 398/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6019 - bpp: 1.2950 - mse: 7.9763e-05\n",
      "Epoch 398: loss did not improve from 2.39153\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6019 - bpp: 1.2950 - mse: 7.9763e-05\n",
      "Epoch 399/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3783 - bpp: 1.2538 - mse: 6.8636e-05\n",
      "Epoch 399: loss improved from 2.39153 to 2.37835, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3783 - bpp: 1.2538 - mse: 6.8636e-05\n",
      "Epoch 400/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6284 - bpp: 1.3292 - mse: 7.9293e-05\n",
      "Epoch 400: loss did not improve from 2.37835\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6284 - bpp: 1.3292 - mse: 7.9293e-05\n",
      "Epoch 401/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4979 - bpp: 1.2851 - mse: 7.4027e-05\n",
      "Epoch 401: loss did not improve from 2.37835\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.4979 - bpp: 1.2851 - mse: 7.4027e-05\n",
      "Epoch 402/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2759 - bpp: 1.2466 - mse: 6.2818e-05\n",
      "Epoch 402: loss improved from 2.37835 to 2.27585, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.2759 - bpp: 1.2466 - mse: 6.2818e-05\n",
      "Epoch 403/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7374 - bpp: 1.3261 - mse: 8.6143e-05\n",
      "Epoch 403: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.7374 - bpp: 1.3261 - mse: 8.6143e-05\n",
      "Epoch 404/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5608 - bpp: 1.3086 - mse: 7.6426e-05\n",
      "Epoch 404: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5608 - bpp: 1.3086 - mse: 7.6426e-05\n",
      "Epoch 405/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4511 - bpp: 1.2884 - mse: 7.0969e-05\n",
      "Epoch 405: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4511 - bpp: 1.2884 - mse: 7.0969e-05\n",
      "Epoch 406/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6622 - bpp: 1.3400 - mse: 8.0701e-05\n",
      "Epoch 406: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6622 - bpp: 1.3400 - mse: 8.0701e-05\n",
      "Epoch 407/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5016 - bpp: 1.3045 - mse: 7.3066e-05\n",
      "Epoch 407: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5016 - bpp: 1.3045 - mse: 7.3066e-05\n",
      "Epoch 408/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8011 - bpp: 1.3625 - mse: 8.7801e-05\n",
      "Epoch 408: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8011 - bpp: 1.3625 - mse: 8.7801e-05\n",
      "Epoch 409/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4446 - bpp: 1.2992 - mse: 6.9906e-05\n",
      "Epoch 409: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4446 - bpp: 1.2992 - mse: 6.9906e-05\n",
      "Epoch 410/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5492 - bpp: 1.3030 - mse: 7.6061e-05\n",
      "Epoch 410: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5492 - bpp: 1.3030 - mse: 7.6061e-05\n",
      "Epoch 411/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4885 - bpp: 1.3049 - mse: 7.2238e-05\n",
      "Epoch 411: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4885 - bpp: 1.3049 - mse: 7.2238e-05\n",
      "Epoch 412/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6235 - bpp: 1.3538 - mse: 7.7497e-05\n",
      "Epoch 412: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6235 - bpp: 1.3538 - mse: 7.7497e-05\n",
      "Epoch 413/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6331 - bpp: 1.3163 - mse: 8.0372e-05\n",
      "Epoch 413: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.6331 - bpp: 1.3163 - mse: 8.0372e-05\n",
      "Epoch 414/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6715 - bpp: 1.3415 - mse: 8.1179e-05\n",
      "Epoch 414: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6715 - bpp: 1.3415 - mse: 8.1179e-05\n",
      "Epoch 415/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5778 - bpp: 1.3059 - mse: 7.7634e-05\n",
      "Epoch 415: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5778 - bpp: 1.3059 - mse: 7.7634e-05\n",
      "Epoch 416/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5842 - bpp: 1.3041 - mse: 7.8129e-05\n",
      "Epoch 416: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5842 - bpp: 1.3041 - mse: 7.8129e-05\n",
      "Epoch 417/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6239 - bpp: 1.3233 - mse: 7.9382e-05\n",
      "Epoch 417: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.6239 - bpp: 1.3233 - mse: 7.9382e-05\n",
      "Epoch 418/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6636 - bpp: 1.3444 - mse: 8.0519e-05\n",
      "Epoch 418: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6636 - bpp: 1.3444 - mse: 8.0519e-05\n",
      "Epoch 419/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5309 - bpp: 1.3010 - mse: 7.5071e-05\n",
      "Epoch 419: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5309 - bpp: 1.3010 - mse: 7.5071e-05\n",
      "Epoch 420/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5868 - bpp: 1.3389 - mse: 7.6171e-05\n",
      "Epoch 420: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5868 - bpp: 1.3389 - mse: 7.6171e-05\n",
      "Epoch 421/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5713 - bpp: 1.3088 - mse: 7.7052e-05\n",
      "Epoch 421: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 2.5713 - bpp: 1.3088 - mse: 7.7052e-05\n",
      "Epoch 422/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5558 - bpp: 1.3131 - mse: 7.5849e-05\n",
      "Epoch 422: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5558 - bpp: 1.3131 - mse: 7.5849e-05\n",
      "Epoch 423/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4874 - bpp: 1.3088 - mse: 7.1937e-05\n",
      "Epoch 423: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.4874 - bpp: 1.3088 - mse: 7.1937e-05\n",
      "Epoch 424/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5854 - bpp: 1.3128 - mse: 7.7672e-05\n",
      "Epoch 424: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5854 - bpp: 1.3128 - mse: 7.7672e-05\n",
      "Epoch 425/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5624 - bpp: 1.3094 - mse: 7.6478e-05\n",
      "Epoch 425: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5624 - bpp: 1.3094 - mse: 7.6478e-05\n",
      "Epoch 426/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5781 - bpp: 1.3269 - mse: 7.6366e-05\n",
      "Epoch 426: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5781 - bpp: 1.3269 - mse: 7.6366e-05\n",
      "Epoch 427/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4655 - bpp: 1.2899 - mse: 7.1754e-05\n",
      "Epoch 427: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4655 - bpp: 1.2899 - mse: 7.1754e-05\n",
      "Epoch 428/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5702 - bpp: 1.3099 - mse: 7.6924e-05\n",
      "Epoch 428: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5702 - bpp: 1.3099 - mse: 7.6924e-05\n",
      "Epoch 429/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6290 - bpp: 1.3225 - mse: 7.9738e-05\n",
      "Epoch 429: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6290 - bpp: 1.3225 - mse: 7.9738e-05\n",
      "Epoch 430/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6633 - bpp: 1.3519 - mse: 8.0042e-05\n",
      "Epoch 430: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6633 - bpp: 1.3519 - mse: 8.0042e-05\n",
      "Epoch 431/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4295 - bpp: 1.2655 - mse: 7.1043e-05\n",
      "Epoch 431: loss did not improve from 2.27585\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4295 - bpp: 1.2655 - mse: 7.1043e-05\n",
      "Epoch 432/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2334 - bpp: 1.2430 - mse: 6.0445e-05\n",
      "Epoch 432: loss improved from 2.27585 to 2.23337, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.2334 - bpp: 1.2430 - mse: 6.0445e-05\n",
      "Epoch 433/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5480 - bpp: 1.3140 - mse: 7.5316e-05\n",
      "Epoch 433: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5480 - bpp: 1.3140 - mse: 7.5316e-05\n",
      "Epoch 434/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6110 - bpp: 1.3167 - mse: 7.8998e-05\n",
      "Epoch 434: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6110 - bpp: 1.3167 - mse: 7.8998e-05\n",
      "Epoch 435/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4965 - bpp: 1.2898 - mse: 7.3648e-05\n",
      "Epoch 435: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4965 - bpp: 1.2898 - mse: 7.3648e-05\n",
      "Epoch 436/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8393 - bpp: 1.3338 - mse: 9.1893e-05\n",
      "Epoch 436: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.8393 - bpp: 1.3338 - mse: 9.1893e-05\n",
      "Epoch 437/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6358 - bpp: 1.3371 - mse: 7.9269e-05\n",
      "Epoch 437: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6358 - bpp: 1.3371 - mse: 7.9269e-05\n",
      "Epoch 438/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5806 - bpp: 1.3178 - mse: 7.7076e-05\n",
      "Epoch 438: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5806 - bpp: 1.3178 - mse: 7.7076e-05\n",
      "Epoch 439/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5930 - bpp: 1.3245 - mse: 7.7420e-05\n",
      "Epoch 439: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5930 - bpp: 1.3245 - mse: 7.7420e-05\n",
      "Epoch 440/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6113 - bpp: 1.3364 - mse: 7.7814e-05\n",
      "Epoch 440: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6113 - bpp: 1.3364 - mse: 7.7814e-05\n",
      "Epoch 441/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5060 - bpp: 1.3002 - mse: 7.3595e-05\n",
      "Epoch 441: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5060 - bpp: 1.3002 - mse: 7.3595e-05\n",
      "Epoch 442/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6502 - bpp: 1.3322 - mse: 8.0441e-05\n",
      "Epoch 442: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6502 - bpp: 1.3322 - mse: 8.0441e-05\n",
      "Epoch 443/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3813 - bpp: 1.2705 - mse: 6.7794e-05\n",
      "Epoch 443: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.3813 - bpp: 1.2705 - mse: 6.7794e-05\n",
      "Epoch 444/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6387 - bpp: 1.3266 - mse: 8.0082e-05\n",
      "Epoch 444: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6387 - bpp: 1.3266 - mse: 8.0082e-05\n",
      "Epoch 445/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5704 - bpp: 1.2967 - mse: 7.7745e-05\n",
      "Epoch 445: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 29s 142ms/step - loss: 2.5704 - bpp: 1.2967 - mse: 7.7745e-05\n",
      "Epoch 446/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5058 - bpp: 1.3057 - mse: 7.3250e-05\n",
      "Epoch 446: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5058 - bpp: 1.3057 - mse: 7.3250e-05\n",
      "Epoch 447/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4610 - bpp: 1.2862 - mse: 7.1708e-05\n",
      "Epoch 447: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4610 - bpp: 1.2862 - mse: 7.1708e-05\n",
      "Epoch 448/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3595 - bpp: 1.2707 - mse: 6.6458e-05\n",
      "Epoch 448: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3595 - bpp: 1.2707 - mse: 6.6458e-05\n",
      "Epoch 449/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4321 - bpp: 1.2864 - mse: 6.9923e-05\n",
      "Epoch 449: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4321 - bpp: 1.2864 - mse: 6.9923e-05\n",
      "Epoch 450/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6410 - bpp: 1.3174 - mse: 8.0784e-05\n",
      "Epoch 450: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6410 - bpp: 1.3174 - mse: 8.0784e-05\n",
      "Epoch 451/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4650 - bpp: 1.2914 - mse: 7.1633e-05\n",
      "Epoch 451: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4650 - bpp: 1.2914 - mse: 7.1633e-05\n",
      "Epoch 452/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5583 - bpp: 1.3214 - mse: 7.5495e-05\n",
      "Epoch 452: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5583 - bpp: 1.3214 - mse: 7.5495e-05\n",
      "Epoch 453/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4426 - bpp: 1.2834 - mse: 7.0754e-05\n",
      "Epoch 453: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4426 - bpp: 1.2834 - mse: 7.0754e-05\n",
      "Epoch 454/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3792 - bpp: 1.2664 - mse: 6.7921e-05\n",
      "Epoch 454: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3792 - bpp: 1.2664 - mse: 6.7921e-05\n",
      "Epoch 455/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4121 - bpp: 1.2679 - mse: 6.9841e-05\n",
      "Epoch 455: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4121 - bpp: 1.2679 - mse: 6.9841e-05\n",
      "Epoch 456/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5953 - bpp: 1.3133 - mse: 7.8252e-05\n",
      "Epoch 456: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5953 - bpp: 1.3133 - mse: 7.8252e-05\n",
      "Epoch 457/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6458 - bpp: 1.3326 - mse: 8.0148e-05\n",
      "Epoch 457: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6458 - bpp: 1.3326 - mse: 8.0148e-05\n",
      "Epoch 458/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5013 - bpp: 1.2966 - mse: 7.3527e-05\n",
      "Epoch 458: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.5013 - bpp: 1.2966 - mse: 7.3527e-05\n",
      "Epoch 459/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7190 - bpp: 1.3386 - mse: 8.4254e-05\n",
      "Epoch 459: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.7190 - bpp: 1.3386 - mse: 8.4254e-05\n",
      "Epoch 460/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9267 - bpp: 1.3996 - mse: 9.3209e-05\n",
      "Epoch 460: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.9267 - bpp: 1.3996 - mse: 9.3209e-05\n",
      "Epoch 461/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3367 - bpp: 1.2595 - mse: 6.5750e-05\n",
      "Epoch 461: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3367 - bpp: 1.2595 - mse: 6.5750e-05\n",
      "Epoch 462/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7236 - bpp: 1.3353 - mse: 8.4734e-05\n",
      "Epoch 462: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.7236 - bpp: 1.3353 - mse: 8.4734e-05\n",
      "Epoch 463/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2843 - bpp: 1.2400 - mse: 6.3736e-05\n",
      "Epoch 463: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.2843 - bpp: 1.2400 - mse: 6.3736e-05\n",
      "Epoch 464/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5426 - bpp: 1.3252 - mse: 7.4301e-05\n",
      "Epoch 464: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 26s 125ms/step - loss: 2.5426 - bpp: 1.3252 - mse: 7.4301e-05\n",
      "Epoch 465/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6821 - bpp: 1.3346 - mse: 8.2243e-05\n",
      "Epoch 465: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6821 - bpp: 1.3346 - mse: 8.2243e-05\n",
      "Epoch 466/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5419 - bpp: 1.3090 - mse: 7.5252e-05\n",
      "Epoch 466: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5419 - bpp: 1.3090 - mse: 7.5252e-05\n",
      "Epoch 467/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3145 - bpp: 1.2543 - mse: 6.4709e-05\n",
      "Epoch 467: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3145 - bpp: 1.2543 - mse: 6.4709e-05\n",
      "Epoch 468/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3830 - bpp: 1.2740 - mse: 6.7688e-05\n",
      "Epoch 468: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3830 - bpp: 1.2740 - mse: 6.7688e-05\n",
      "Epoch 469/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6081 - bpp: 1.3188 - mse: 7.8692e-05\n",
      "Epoch 469: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.6081 - bpp: 1.3188 - mse: 7.8692e-05\n",
      "Epoch 470/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6052 - bpp: 1.3381 - mse: 7.7333e-05\n",
      "Epoch 470: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6052 - bpp: 1.3381 - mse: 7.7333e-05\n",
      "Epoch 471/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6797 - bpp: 1.3404 - mse: 8.1744e-05\n",
      "Epoch 471: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6797 - bpp: 1.3404 - mse: 8.1744e-05\n",
      "Epoch 472/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6765 - bpp: 1.3501 - mse: 8.0962e-05\n",
      "Epoch 472: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.6765 - bpp: 1.3501 - mse: 8.0962e-05\n",
      "Epoch 473/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4394 - bpp: 1.2970 - mse: 6.9728e-05\n",
      "Epoch 473: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4394 - bpp: 1.2970 - mse: 6.9728e-05\n",
      "Epoch 474/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6170 - bpp: 1.3232 - mse: 7.8970e-05\n",
      "Epoch 474: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6170 - bpp: 1.3232 - mse: 7.8970e-05\n",
      "Epoch 475/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5156 - bpp: 1.3154 - mse: 7.3257e-05\n",
      "Epoch 475: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5156 - bpp: 1.3154 - mse: 7.3257e-05\n",
      "Epoch 476/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3652 - bpp: 1.2821 - mse: 6.6110e-05\n",
      "Epoch 476: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3652 - bpp: 1.2821 - mse: 6.6110e-05\n",
      "Epoch 477/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6419 - bpp: 1.3484 - mse: 7.8946e-05\n",
      "Epoch 477: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.6419 - bpp: 1.3484 - mse: 7.8946e-05\n",
      "Epoch 478/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5057 - bpp: 1.3219 - mse: 7.2252e-05\n",
      "Epoch 478: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5057 - bpp: 1.3219 - mse: 7.2252e-05\n",
      "Epoch 479/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3308 - bpp: 1.2612 - mse: 6.5283e-05\n",
      "Epoch 479: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3308 - bpp: 1.2612 - mse: 6.5283e-05\n",
      "Epoch 480/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5920 - bpp: 1.3401 - mse: 7.6408e-05\n",
      "Epoch 480: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5920 - bpp: 1.3401 - mse: 7.6408e-05\n",
      "Epoch 481/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3689 - bpp: 1.2843 - mse: 6.6202e-05\n",
      "Epoch 481: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3689 - bpp: 1.2843 - mse: 6.6202e-05\n",
      "Epoch 482/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4222 - bpp: 1.2783 - mse: 6.9822e-05\n",
      "Epoch 482: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4222 - bpp: 1.2783 - mse: 6.9822e-05\n",
      "Epoch 483/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5334 - bpp: 1.2995 - mse: 7.5313e-05\n",
      "Epoch 483: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5334 - bpp: 1.2995 - mse: 7.5313e-05\n",
      "Epoch 484/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5358 - bpp: 1.3215 - mse: 7.4112e-05\n",
      "Epoch 484: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5358 - bpp: 1.3215 - mse: 7.4112e-05\n",
      "Epoch 485/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4786 - bpp: 1.2881 - mse: 7.2661e-05\n",
      "Epoch 485: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4786 - bpp: 1.2881 - mse: 7.2661e-05\n",
      "Epoch 486/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3201 - bpp: 1.2550 - mse: 6.5008e-05\n",
      "Epoch 486: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 2.3201 - bpp: 1.2550 - mse: 6.5008e-05\n",
      "Epoch 487/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5643 - bpp: 1.3187 - mse: 7.6027e-05\n",
      "Epoch 487: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5643 - bpp: 1.3187 - mse: 7.6027e-05\n",
      "Epoch 488/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6232 - bpp: 1.3141 - mse: 7.9896e-05\n",
      "Epoch 488: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.6232 - bpp: 1.3141 - mse: 7.9896e-05\n",
      "Epoch 489/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3915 - bpp: 1.2628 - mse: 6.8890e-05\n",
      "Epoch 489: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3915 - bpp: 1.2628 - mse: 6.8890e-05\n",
      "Epoch 490/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3994 - bpp: 1.2861 - mse: 6.7951e-05\n",
      "Epoch 490: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3994 - bpp: 1.2861 - mse: 6.7951e-05\n",
      "Epoch 491/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3944 - bpp: 1.2613 - mse: 6.9163e-05\n",
      "Epoch 491: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3944 - bpp: 1.2613 - mse: 6.9163e-05\n",
      "Epoch 492/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7152 - bpp: 1.3328 - mse: 8.4377e-05\n",
      "Epoch 492: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7152 - bpp: 1.3328 - mse: 8.4377e-05\n",
      "Epoch 493/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5291 - bpp: 1.3012 - mse: 7.4941e-05\n",
      "Epoch 493: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.5291 - bpp: 1.3012 - mse: 7.4941e-05\n",
      "Epoch 494/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5308 - bpp: 1.3148 - mse: 7.4220e-05\n",
      "Epoch 494: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5308 - bpp: 1.3148 - mse: 7.4220e-05\n",
      "Epoch 495/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6141 - bpp: 1.3190 - mse: 7.9045e-05\n",
      "Epoch 495: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6141 - bpp: 1.3190 - mse: 7.9045e-05\n",
      "Epoch 496/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5945 - bpp: 1.3306 - mse: 7.7142e-05\n",
      "Epoch 496: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5945 - bpp: 1.3306 - mse: 7.7142e-05\n",
      "Epoch 497/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3474 - bpp: 1.2651 - mse: 6.6056e-05\n",
      "Epoch 497: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3474 - bpp: 1.2651 - mse: 6.6056e-05\n",
      "Epoch 498/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5902 - bpp: 1.3034 - mse: 7.8539e-05\n",
      "Epoch 498: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5902 - bpp: 1.3034 - mse: 7.8539e-05\n",
      "Epoch 499/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2974 - bpp: 1.2414 - mse: 6.4452e-05\n",
      "Epoch 499: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.2974 - bpp: 1.2414 - mse: 6.4452e-05\n",
      "Epoch 500/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3580 - bpp: 1.2755 - mse: 6.6071e-05\n",
      "Epoch 500: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3580 - bpp: 1.2755 - mse: 6.6071e-05\n",
      "Epoch 501/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3842 - bpp: 1.2661 - mse: 6.8247e-05\n",
      "Epoch 501: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.3842 - bpp: 1.2661 - mse: 6.8247e-05\n",
      "Epoch 502/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5361 - bpp: 1.3082 - mse: 7.4945e-05\n",
      "Epoch 502: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5361 - bpp: 1.3082 - mse: 7.4945e-05\n",
      "Epoch 503/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4910 - bpp: 1.2969 - mse: 7.2881e-05\n",
      "Epoch 503: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.4910 - bpp: 1.2969 - mse: 7.2881e-05\n",
      "Epoch 504/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3566 - bpp: 1.2654 - mse: 6.6598e-05\n",
      "Epoch 504: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3566 - bpp: 1.2654 - mse: 6.6598e-05\n",
      "Epoch 505/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4907 - bpp: 1.2971 - mse: 7.2848e-05\n",
      "Epoch 505: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.4907 - bpp: 1.2971 - mse: 7.2848e-05\n",
      "Epoch 506/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3444 - bpp: 1.2502 - mse: 6.6785e-05\n",
      "Epoch 506: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3444 - bpp: 1.2502 - mse: 6.6785e-05\n",
      "Epoch 507/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5550 - bpp: 1.3071 - mse: 7.6169e-05\n",
      "Epoch 507: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5550 - bpp: 1.3071 - mse: 7.6169e-05\n",
      "Epoch 508/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4516 - bpp: 1.2791 - mse: 7.1563e-05\n",
      "Epoch 508: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.4516 - bpp: 1.2791 - mse: 7.1563e-05\n",
      "Epoch 509/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4578 - bpp: 1.2847 - mse: 7.1599e-05\n",
      "Epoch 509: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4578 - bpp: 1.2847 - mse: 7.1599e-05\n",
      "Epoch 510/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5920 - bpp: 1.3351 - mse: 7.6716e-05\n",
      "Epoch 510: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5920 - bpp: 1.3351 - mse: 7.6716e-05\n",
      "Epoch 511/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5850 - bpp: 1.3266 - mse: 7.6810e-05\n",
      "Epoch 511: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.5850 - bpp: 1.3266 - mse: 7.6810e-05\n",
      "Epoch 512/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5383 - bpp: 1.3166 - mse: 7.4564e-05\n",
      "Epoch 512: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5383 - bpp: 1.3166 - mse: 7.4564e-05\n",
      "Epoch 513/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3889 - bpp: 1.2610 - mse: 6.8844e-05\n",
      "Epoch 513: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3889 - bpp: 1.2610 - mse: 6.8844e-05\n",
      "Epoch 514/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4683 - bpp: 1.2965 - mse: 7.1519e-05\n",
      "Epoch 514: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 2.4683 - bpp: 1.2965 - mse: 7.1519e-05\n",
      "Epoch 515/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4836 - bpp: 1.3024 - mse: 7.2096e-05\n",
      "Epoch 515: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4836 - bpp: 1.3024 - mse: 7.2096e-05\n",
      "Epoch 516/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4798 - bpp: 1.2906 - mse: 7.2583e-05\n",
      "Epoch 516: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4798 - bpp: 1.2906 - mse: 7.2583e-05\n",
      "Epoch 517/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5893 - bpp: 1.2724 - mse: 8.0375e-05\n",
      "Epoch 517: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5893 - bpp: 1.2724 - mse: 8.0375e-05\n",
      "Epoch 518/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7297 - bpp: 1.3562 - mse: 8.3836e-05\n",
      "Epoch 518: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.7297 - bpp: 1.3562 - mse: 8.3836e-05\n",
      "Epoch 519/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4564 - bpp: 1.3024 - mse: 7.0434e-05\n",
      "Epoch 519: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4564 - bpp: 1.3024 - mse: 7.0434e-05\n",
      "Epoch 520/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3748 - bpp: 1.2658 - mse: 6.7686e-05\n",
      "Epoch 520: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3748 - bpp: 1.2658 - mse: 6.7686e-05\n",
      "Epoch 521/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5460 - bpp: 1.2916 - mse: 7.6563e-05\n",
      "Epoch 521: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5460 - bpp: 1.2916 - mse: 7.6563e-05\n",
      "Epoch 522/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2632 - bpp: 1.2149 - mse: 6.3985e-05\n",
      "Epoch 522: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2632 - bpp: 1.2149 - mse: 6.3985e-05\n",
      "Epoch 523/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2937 - bpp: 1.2562 - mse: 6.3329e-05\n",
      "Epoch 523: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2937 - bpp: 1.2562 - mse: 6.3329e-05\n",
      "Epoch 524/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4211 - bpp: 1.2684 - mse: 7.0352e-05\n",
      "Epoch 524: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4211 - bpp: 1.2684 - mse: 7.0352e-05\n",
      "Epoch 525/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6348 - bpp: 1.3326 - mse: 7.9476e-05\n",
      "Epoch 525: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.6348 - bpp: 1.3326 - mse: 7.9476e-05\n",
      "Epoch 526/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5271 - bpp: 1.3121 - mse: 7.4154e-05\n",
      "Epoch 526: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5271 - bpp: 1.3121 - mse: 7.4154e-05\n",
      "Epoch 527/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3588 - bpp: 1.2564 - mse: 6.7284e-05\n",
      "Epoch 527: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3588 - bpp: 1.2564 - mse: 6.7284e-05\n",
      "Epoch 528/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5134 - bpp: 1.3003 - mse: 7.4040e-05\n",
      "Epoch 528: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5134 - bpp: 1.3003 - mse: 7.4040e-05\n",
      "Epoch 529/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5588 - bpp: 1.3287 - mse: 7.5082e-05\n",
      "Epoch 529: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5588 - bpp: 1.3287 - mse: 7.5082e-05\n",
      "Epoch 530/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4401 - bpp: 1.2820 - mse: 7.0681e-05\n",
      "Epoch 530: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4401 - bpp: 1.2820 - mse: 7.0681e-05\n",
      "Epoch 531/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3612 - bpp: 1.2605 - mse: 6.7183e-05\n",
      "Epoch 531: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.3612 - bpp: 1.2605 - mse: 6.7183e-05\n",
      "Epoch 532/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4119 - bpp: 1.2827 - mse: 6.8921e-05\n",
      "Epoch 532: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4119 - bpp: 1.2827 - mse: 6.8921e-05\n",
      "Epoch 533/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4630 - bpp: 1.3056 - mse: 7.0642e-05\n",
      "Epoch 533: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4630 - bpp: 1.3056 - mse: 7.0642e-05\n",
      "Epoch 534/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3336 - bpp: 1.2669 - mse: 6.5107e-05\n",
      "Epoch 534: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.3336 - bpp: 1.2669 - mse: 6.5107e-05\n",
      "Epoch 535/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3319 - bpp: 1.2604 - mse: 6.5401e-05\n",
      "Epoch 535: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3319 - bpp: 1.2604 - mse: 6.5401e-05\n",
      "Epoch 536/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4542 - bpp: 1.3016 - mse: 7.0353e-05\n",
      "Epoch 536: loss did not improve from 2.23337\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4542 - bpp: 1.3016 - mse: 7.0353e-05\n",
      "Epoch 537/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2047 - bpp: 1.2418 - mse: 5.8774e-05\n",
      "Epoch 537: loss improved from 2.23337 to 2.20472, saving model to checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.2047 - bpp: 1.2418 - mse: 5.8774e-05\n",
      "Epoch 538/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5594 - bpp: 1.3290 - mse: 7.5094e-05\n",
      "Epoch 538: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5594 - bpp: 1.3290 - mse: 7.5094e-05\n",
      "Epoch 539/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6104 - bpp: 1.3482 - mse: 7.7037e-05\n",
      "Epoch 539: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6104 - bpp: 1.3482 - mse: 7.7037e-05\n",
      "Epoch 540/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8521 - bpp: 1.3770 - mse: 9.0036e-05\n",
      "Epoch 540: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.8521 - bpp: 1.3770 - mse: 9.0036e-05\n",
      "Epoch 541/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5085 - bpp: 1.2955 - mse: 7.4039e-05\n",
      "Epoch 541: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5085 - bpp: 1.2955 - mse: 7.4039e-05\n",
      "Epoch 542/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4486 - bpp: 1.2912 - mse: 7.0646e-05\n",
      "Epoch 542: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4486 - bpp: 1.2912 - mse: 7.0646e-05\n",
      "Epoch 543/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4147 - bpp: 1.2751 - mse: 6.9559e-05\n",
      "Epoch 543: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4147 - bpp: 1.2751 - mse: 6.9559e-05\n",
      "Epoch 544/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4730 - bpp: 1.3030 - mse: 7.1414e-05\n",
      "Epoch 544: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4730 - bpp: 1.3030 - mse: 7.1414e-05\n",
      "Epoch 545/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3917 - bpp: 1.2727 - mse: 6.8299e-05\n",
      "Epoch 545: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3917 - bpp: 1.2727 - mse: 6.8299e-05\n",
      "Epoch 546/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4769 - bpp: 1.2980 - mse: 7.1955e-05\n",
      "Epoch 546: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.4769 - bpp: 1.2980 - mse: 7.1955e-05\n",
      "Epoch 547/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4092 - bpp: 1.2710 - mse: 6.9468e-05\n",
      "Epoch 547: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4092 - bpp: 1.2710 - mse: 6.9468e-05\n",
      "Epoch 548/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4563 - bpp: 1.2965 - mse: 7.0791e-05\n",
      "Epoch 548: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4563 - bpp: 1.2965 - mse: 7.0791e-05\n",
      "Epoch 549/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2627 - bpp: 1.2438 - mse: 6.2194e-05\n",
      "Epoch 549: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2627 - bpp: 1.2438 - mse: 6.2194e-05\n",
      "Epoch 550/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5277 - bpp: 1.3028 - mse: 7.4765e-05\n",
      "Epoch 550: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.5277 - bpp: 1.3028 - mse: 7.4765e-05\n",
      "Epoch 551/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4448 - bpp: 1.2861 - mse: 7.0726e-05\n",
      "Epoch 551: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4448 - bpp: 1.2861 - mse: 7.0726e-05\n",
      "Epoch 552/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2688 - bpp: 1.2459 - mse: 6.2433e-05\n",
      "Epoch 552: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.2688 - bpp: 1.2459 - mse: 6.2433e-05\n",
      "Epoch 553/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5556 - bpp: 1.3297 - mse: 7.4819e-05\n",
      "Epoch 553: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5556 - bpp: 1.3297 - mse: 7.4819e-05\n",
      "Epoch 554/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3425 - bpp: 1.2648 - mse: 6.5778e-05\n",
      "Epoch 554: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3425 - bpp: 1.2648 - mse: 6.5778e-05\n",
      "Epoch 555/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6920 - bpp: 1.3321 - mse: 8.3004e-05\n",
      "Epoch 555: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6920 - bpp: 1.3321 - mse: 8.3004e-05\n",
      "Epoch 556/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3400 - bpp: 1.2596 - mse: 6.5942e-05\n",
      "Epoch 556: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3400 - bpp: 1.2596 - mse: 6.5942e-05\n",
      "Epoch 557/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4480 - bpp: 1.3014 - mse: 6.9981e-05\n",
      "Epoch 557: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4480 - bpp: 1.3014 - mse: 6.9981e-05\n",
      "Epoch 558/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4179 - bpp: 1.2870 - mse: 6.9022e-05\n",
      "Epoch 558: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4179 - bpp: 1.2870 - mse: 6.9022e-05\n",
      "Epoch 559/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4550 - bpp: 1.2795 - mse: 7.1750e-05\n",
      "Epoch 559: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4550 - bpp: 1.2795 - mse: 7.1750e-05\n",
      "Epoch 560/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5302 - bpp: 1.3149 - mse: 7.4179e-05\n",
      "Epoch 560: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.5302 - bpp: 1.3149 - mse: 7.4179e-05\n",
      "Epoch 561/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3498 - bpp: 1.2788 - mse: 6.5369e-05\n",
      "Epoch 561: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3498 - bpp: 1.2788 - mse: 6.5369e-05\n",
      "Epoch 562/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3607 - bpp: 1.2482 - mse: 6.7902e-05\n",
      "Epoch 562: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3607 - bpp: 1.2482 - mse: 6.7902e-05\n",
      "Epoch 563/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4189 - bpp: 1.2905 - mse: 6.8871e-05\n",
      "Epoch 563: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4189 - bpp: 1.2905 - mse: 6.8871e-05\n",
      "Epoch 564/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3199 - bpp: 1.2527 - mse: 6.5139e-05\n",
      "Epoch 564: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 2.3199 - bpp: 1.2527 - mse: 6.5139e-05\n",
      "Epoch 565/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2993 - bpp: 1.2623 - mse: 6.3297e-05\n",
      "Epoch 565: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.2993 - bpp: 1.2623 - mse: 6.3297e-05\n",
      "Epoch 566/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4673 - bpp: 1.2857 - mse: 7.2117e-05\n",
      "Epoch 566: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4673 - bpp: 1.2857 - mse: 7.2117e-05\n",
      "Epoch 567/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3023 - bpp: 1.2359 - mse: 6.5089e-05\n",
      "Epoch 567: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3023 - bpp: 1.2359 - mse: 6.5089e-05\n",
      "Epoch 568/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6100 - bpp: 1.3229 - mse: 7.8559e-05\n",
      "Epoch 568: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6100 - bpp: 1.3229 - mse: 7.8559e-05\n",
      "Epoch 569/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5383 - bpp: 1.3137 - mse: 7.4743e-05\n",
      "Epoch 569: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.5383 - bpp: 1.3137 - mse: 7.4743e-05\n",
      "Epoch 570/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3372 - bpp: 1.2478 - mse: 6.6495e-05\n",
      "Epoch 570: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3372 - bpp: 1.2478 - mse: 6.6495e-05\n",
      "Epoch 571/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3553 - bpp: 1.2524 - mse: 6.7313e-05\n",
      "Epoch 571: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3553 - bpp: 1.2524 - mse: 6.7313e-05\n",
      "Epoch 572/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5134 - bpp: 1.3005 - mse: 7.4029e-05\n",
      "Epoch 572: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5134 - bpp: 1.3005 - mse: 7.4029e-05\n",
      "Epoch 573/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3400 - bpp: 1.2554 - mse: 6.6202e-05\n",
      "Epoch 573: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3400 - bpp: 1.2554 - mse: 6.6202e-05\n",
      "Epoch 574/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5204 - bpp: 1.3316 - mse: 7.2557e-05\n",
      "Epoch 574: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5204 - bpp: 1.3316 - mse: 7.2557e-05\n",
      "Epoch 575/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3983 - bpp: 1.2709 - mse: 6.8808e-05\n",
      "Epoch 575: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3983 - bpp: 1.2709 - mse: 6.8808e-05\n",
      "Epoch 576/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5164 - bpp: 1.3087 - mse: 7.3711e-05\n",
      "Epoch 576: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5164 - bpp: 1.3087 - mse: 7.3711e-05\n",
      "Epoch 577/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3480 - bpp: 1.2588 - mse: 6.6479e-05\n",
      "Epoch 577: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3480 - bpp: 1.2588 - mse: 6.6479e-05\n",
      "Epoch 578/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3291 - bpp: 1.2496 - mse: 6.5887e-05\n",
      "Epoch 578: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3291 - bpp: 1.2496 - mse: 6.5887e-05\n",
      "Epoch 579/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2954 - bpp: 1.2451 - mse: 6.4100e-05\n",
      "Epoch 579: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2954 - bpp: 1.2451 - mse: 6.4100e-05\n",
      "Epoch 580/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4590 - bpp: 1.2844 - mse: 7.1689e-05\n",
      "Epoch 580: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.4590 - bpp: 1.2844 - mse: 7.1689e-05\n",
      "Epoch 581/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4705 - bpp: 1.3009 - mse: 7.1385e-05\n",
      "Epoch 581: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.4705 - bpp: 1.3009 - mse: 7.1385e-05\n",
      "Epoch 582/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4385 - bpp: 1.2968 - mse: 6.9684e-05\n",
      "Epoch 582: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4385 - bpp: 1.2968 - mse: 6.9684e-05\n",
      "Epoch 583/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5341 - bpp: 1.3191 - mse: 7.4157e-05\n",
      "Epoch 583: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5341 - bpp: 1.3191 - mse: 7.4157e-05\n",
      "Epoch 584/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5631 - bpp: 1.3207 - mse: 7.5831e-05\n",
      "Epoch 584: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5631 - bpp: 1.3207 - mse: 7.5831e-05\n",
      "Epoch 585/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4541 - bpp: 1.2914 - mse: 7.0970e-05\n",
      "Epoch 585: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.4541 - bpp: 1.2914 - mse: 7.0970e-05\n",
      "Epoch 586/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3607 - bpp: 1.2693 - mse: 6.6612e-05\n",
      "Epoch 586: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3607 - bpp: 1.2693 - mse: 6.6612e-05\n",
      "Epoch 587/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4885 - bpp: 1.3053 - mse: 7.2216e-05\n",
      "Epoch 587: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4885 - bpp: 1.3053 - mse: 7.2216e-05\n",
      "Epoch 588/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2621 - bpp: 1.2260 - mse: 6.3238e-05\n",
      "Epoch 588: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2621 - bpp: 1.2260 - mse: 6.3238e-05\n",
      "Epoch 589/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3347 - bpp: 1.2742 - mse: 6.4733e-05\n",
      "Epoch 589: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 2.3347 - bpp: 1.2742 - mse: 6.4733e-05\n",
      "Epoch 590/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4399 - bpp: 1.2633 - mse: 7.1816e-05\n",
      "Epoch 590: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4399 - bpp: 1.2633 - mse: 7.1816e-05\n",
      "Epoch 591/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4787 - bpp: 1.2909 - mse: 7.2494e-05\n",
      "Epoch 591: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4787 - bpp: 1.2909 - mse: 7.2494e-05\n",
      "Epoch 592/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3508 - bpp: 1.2646 - mse: 6.6296e-05\n",
      "Epoch 592: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.3508 - bpp: 1.2646 - mse: 6.6296e-05\n",
      "Epoch 593/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2835 - bpp: 1.2582 - mse: 6.2581e-05\n",
      "Epoch 593: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2835 - bpp: 1.2582 - mse: 6.2581e-05\n",
      "Epoch 594/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3231 - bpp: 1.2641 - mse: 6.4638e-05\n",
      "Epoch 594: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3231 - bpp: 1.2641 - mse: 6.4638e-05\n",
      "Epoch 595/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3796 - bpp: 1.2575 - mse: 6.8490e-05\n",
      "Epoch 595: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3796 - bpp: 1.2575 - mse: 6.8490e-05\n",
      "Epoch 596/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6099 - bpp: 1.3270 - mse: 7.8304e-05\n",
      "Epoch 596: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.6099 - bpp: 1.3270 - mse: 7.8304e-05\n",
      "Epoch 597/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4378 - bpp: 1.2965 - mse: 6.9661e-05\n",
      "Epoch 597: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.4378 - bpp: 1.2965 - mse: 6.9661e-05\n",
      "Epoch 598/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3929 - bpp: 1.2494 - mse: 6.9793e-05\n",
      "Epoch 598: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3929 - bpp: 1.2494 - mse: 6.9793e-05\n",
      "Epoch 599/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4265 - bpp: 1.2889 - mse: 6.9435e-05\n",
      "Epoch 599: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4265 - bpp: 1.2889 - mse: 6.9435e-05\n",
      "Epoch 600/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2344 - bpp: 1.2182 - mse: 6.2025e-05\n",
      "Epoch 600: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.2344 - bpp: 1.2182 - mse: 6.2025e-05\n",
      "Epoch 601/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4410 - bpp: 1.3072 - mse: 6.9202e-05\n",
      "Epoch 601: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4410 - bpp: 1.3072 - mse: 6.9202e-05\n",
      "Epoch 602/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2642 - bpp: 1.2401 - mse: 6.2505e-05\n",
      "Epoch 602: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 2.2642 - bpp: 1.2401 - mse: 6.2505e-05\n",
      "Epoch 603/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3851 - bpp: 1.2756 - mse: 6.7721e-05\n",
      "Epoch 603: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3851 - bpp: 1.2756 - mse: 6.7721e-05\n",
      "Epoch 604/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4339 - bpp: 1.2931 - mse: 6.9628e-05\n",
      "Epoch 604: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4339 - bpp: 1.2931 - mse: 6.9628e-05\n",
      "Epoch 605/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3215 - bpp: 1.2526 - mse: 6.5242e-05\n",
      "Epoch 605: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.3215 - bpp: 1.2526 - mse: 6.5242e-05\n",
      "Epoch 606/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6626 - bpp: 1.3134 - mse: 8.2346e-05\n",
      "Epoch 606: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6626 - bpp: 1.3134 - mse: 8.2346e-05\n",
      "Epoch 607/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2464 - bpp: 1.2324 - mse: 6.1893e-05\n",
      "Epoch 607: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2464 - bpp: 1.2324 - mse: 6.1893e-05\n",
      "Epoch 608/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5132 - bpp: 1.3083 - mse: 7.3542e-05\n",
      "Epoch 608: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5132 - bpp: 1.3083 - mse: 7.3542e-05\n",
      "Epoch 609/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5383 - bpp: 1.3224 - mse: 7.4213e-05\n",
      "Epoch 609: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5383 - bpp: 1.3224 - mse: 7.4213e-05\n",
      "Epoch 610/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4761 - bpp: 1.3014 - mse: 7.1701e-05\n",
      "Epoch 610: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4761 - bpp: 1.3014 - mse: 7.1701e-05\n",
      "Epoch 611/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3688 - bpp: 1.2808 - mse: 6.6406e-05\n",
      "Epoch 611: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3688 - bpp: 1.2808 - mse: 6.6406e-05\n",
      "Epoch 612/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5698 - bpp: 1.3249 - mse: 7.5981e-05\n",
      "Epoch 612: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 2.5698 - bpp: 1.3249 - mse: 7.5981e-05\n",
      "Epoch 613/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6288 - bpp: 1.3253 - mse: 7.9558e-05\n",
      "Epoch 613: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.6288 - bpp: 1.3253 - mse: 7.9558e-05\n",
      "Epoch 614/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2233 - bpp: 1.2330 - mse: 6.0441e-05\n",
      "Epoch 614: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2233 - bpp: 1.2330 - mse: 6.0441e-05\n",
      "Epoch 615/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5272 - bpp: 1.3146 - mse: 7.4009e-05\n",
      "Epoch 615: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5272 - bpp: 1.3146 - mse: 7.4009e-05\n",
      "Epoch 616/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4179 - bpp: 1.2651 - mse: 7.0360e-05\n",
      "Epoch 616: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4179 - bpp: 1.2651 - mse: 7.0360e-05\n",
      "Epoch 617/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4735 - bpp: 1.2972 - mse: 7.1796e-05\n",
      "Epoch 617: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.4735 - bpp: 1.2972 - mse: 7.1796e-05\n",
      "Epoch 618/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4098 - bpp: 1.2952 - mse: 6.8029e-05\n",
      "Epoch 618: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4098 - bpp: 1.2952 - mse: 6.8029e-05\n",
      "Epoch 619/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4780 - bpp: 1.3132 - mse: 7.1091e-05\n",
      "Epoch 619: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4780 - bpp: 1.3132 - mse: 7.1091e-05\n",
      "Epoch 620/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4687 - bpp: 1.3067 - mse: 7.0923e-05\n",
      "Epoch 620: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4687 - bpp: 1.3067 - mse: 7.0923e-05\n",
      "Epoch 621/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3740 - bpp: 1.2783 - mse: 6.6880e-05\n",
      "Epoch 621: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3740 - bpp: 1.2783 - mse: 6.6880e-05\n",
      "Epoch 622/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4015 - bpp: 1.2786 - mse: 6.8536e-05\n",
      "Epoch 622: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4015 - bpp: 1.2786 - mse: 6.8536e-05\n",
      "Epoch 623/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4977 - bpp: 1.3044 - mse: 7.2835e-05\n",
      "Epoch 623: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4977 - bpp: 1.3044 - mse: 7.2835e-05\n",
      "Epoch 624/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4014 - bpp: 1.2714 - mse: 6.8970e-05\n",
      "Epoch 624: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4014 - bpp: 1.2714 - mse: 6.8970e-05\n",
      "Epoch 625/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7645 - bpp: 1.3811 - mse: 8.4434e-05\n",
      "Epoch 625: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.7645 - bpp: 1.3811 - mse: 8.4434e-05\n",
      "Epoch 626/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4076 - bpp: 1.2859 - mse: 6.8463e-05\n",
      "Epoch 626: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 2.4076 - bpp: 1.2859 - mse: 6.8463e-05\n",
      "Epoch 627/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5560 - bpp: 1.3064 - mse: 7.6268e-05\n",
      "Epoch 627: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.5560 - bpp: 1.3064 - mse: 7.6268e-05\n",
      "Epoch 628/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4486 - bpp: 1.2838 - mse: 7.1097e-05\n",
      "Epoch 628: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 27s 131ms/step - loss: 2.4486 - bpp: 1.2838 - mse: 7.1097e-05\n",
      "Epoch 629/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3202 - bpp: 1.2703 - mse: 6.4084e-05\n",
      "Epoch 629: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3202 - bpp: 1.2703 - mse: 6.4084e-05\n",
      "Epoch 630/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3673 - bpp: 1.2902 - mse: 6.5744e-05\n",
      "Epoch 630: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3673 - bpp: 1.2902 - mse: 6.5744e-05\n",
      "Epoch 631/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4169 - bpp: 1.2671 - mse: 7.0178e-05\n",
      "Epoch 631: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4169 - bpp: 1.2671 - mse: 7.0178e-05\n",
      "Epoch 632/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2690 - bpp: 1.2447 - mse: 6.2514e-05\n",
      "Epoch 632: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2690 - bpp: 1.2447 - mse: 6.2514e-05\n",
      "Epoch 633/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5397 - bpp: 1.3191 - mse: 7.4501e-05\n",
      "Epoch 633: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5397 - bpp: 1.3191 - mse: 7.4501e-05\n",
      "Epoch 634/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5059 - bpp: 1.3169 - mse: 7.2573e-05\n",
      "Epoch 634: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.5059 - bpp: 1.3169 - mse: 7.2573e-05\n",
      "Epoch 635/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4112 - bpp: 1.2566 - mse: 7.0472e-05\n",
      "Epoch 635: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4112 - bpp: 1.2566 - mse: 7.0472e-05\n",
      "Epoch 636/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4446 - bpp: 1.2804 - mse: 7.1053e-05\n",
      "Epoch 636: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 2.4446 - bpp: 1.2804 - mse: 7.1053e-05\n",
      "Epoch 637/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3460 - bpp: 1.2850 - mse: 6.4757e-05\n",
      "Epoch 637: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3460 - bpp: 1.2850 - mse: 6.4757e-05\n",
      "Epoch 638/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4837 - bpp: 1.3101 - mse: 7.1634e-05\n",
      "Epoch 638: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4837 - bpp: 1.3101 - mse: 7.1634e-05\n",
      "Epoch 639/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3763 - bpp: 1.2760 - mse: 6.7161e-05\n",
      "Epoch 639: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3763 - bpp: 1.2760 - mse: 6.7161e-05\n",
      "Epoch 640/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3307 - bpp: 1.2605 - mse: 6.5320e-05\n",
      "Epoch 640: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3307 - bpp: 1.2605 - mse: 6.5320e-05\n",
      "Epoch 641/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3457 - bpp: 1.2466 - mse: 6.7086e-05\n",
      "Epoch 641: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3457 - bpp: 1.2466 - mse: 6.7086e-05\n",
      "Epoch 642/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4364 - bpp: 1.2928 - mse: 6.9796e-05\n",
      "Epoch 642: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.4364 - bpp: 1.2928 - mse: 6.9796e-05\n",
      "Epoch 643/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5833 - bpp: 1.3131 - mse: 7.7530e-05\n",
      "Epoch 643: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.5833 - bpp: 1.3131 - mse: 7.7530e-05\n",
      "Epoch 644/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5523 - bpp: 1.3170 - mse: 7.5398e-05\n",
      "Epoch 644: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5523 - bpp: 1.3170 - mse: 7.5398e-05\n",
      "Epoch 645/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3216 - bpp: 1.2607 - mse: 6.4755e-05\n",
      "Epoch 645: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3216 - bpp: 1.2607 - mse: 6.4755e-05\n",
      "Epoch 646/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2618 - bpp: 1.2446 - mse: 6.2081e-05\n",
      "Epoch 646: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2618 - bpp: 1.2446 - mse: 6.2081e-05\n",
      "Epoch 647/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4119 - bpp: 1.2632 - mse: 7.0117e-05\n",
      "Epoch 647: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4119 - bpp: 1.2632 - mse: 7.0117e-05\n",
      "Epoch 648/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4553 - bpp: 1.3033 - mse: 7.0312e-05\n",
      "Epoch 648: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4553 - bpp: 1.3033 - mse: 7.0312e-05\n",
      "Epoch 649/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4185 - bpp: 1.2975 - mse: 6.8420e-05\n",
      "Epoch 649: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.4185 - bpp: 1.2975 - mse: 6.8420e-05\n",
      "Epoch 650/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5132 - bpp: 1.3108 - mse: 7.3387e-05\n",
      "Epoch 650: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 2.5132 - bpp: 1.3108 - mse: 7.3387e-05\n",
      "Epoch 651/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3112 - bpp: 1.2628 - mse: 6.3989e-05\n",
      "Epoch 651: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3112 - bpp: 1.2628 - mse: 6.3989e-05\n",
      "Epoch 652/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3649 - bpp: 1.2778 - mse: 6.6351e-05\n",
      "Epoch 652: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 2.3649 - bpp: 1.2778 - mse: 6.6351e-05\n",
      "Epoch 653/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5036 - bpp: 1.3244 - mse: 7.1977e-05\n",
      "Epoch 653: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5036 - bpp: 1.3244 - mse: 7.1977e-05\n",
      "Epoch 654/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2889 - bpp: 1.2405 - mse: 6.3991e-05\n",
      "Epoch 654: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2889 - bpp: 1.2405 - mse: 6.3991e-05\n",
      "Epoch 655/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3832 - bpp: 1.2821 - mse: 6.7205e-05\n",
      "Epoch 655: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3832 - bpp: 1.2821 - mse: 6.7205e-05\n",
      "Epoch 656/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3883 - bpp: 1.2801 - mse: 6.7644e-05\n",
      "Epoch 656: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3883 - bpp: 1.2801 - mse: 6.7644e-05\n",
      "Epoch 657/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3884 - bpp: 1.2834 - mse: 6.7443e-05\n",
      "Epoch 657: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3884 - bpp: 1.2834 - mse: 6.7443e-05\n",
      "Epoch 658/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3228 - bpp: 1.2503 - mse: 6.5459e-05\n",
      "Epoch 658: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3228 - bpp: 1.2503 - mse: 6.5459e-05\n",
      "Epoch 659/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5437 - bpp: 1.3027 - mse: 7.5748e-05\n",
      "Epoch 659: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5437 - bpp: 1.3027 - mse: 7.5748e-05\n",
      "Epoch 660/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3041 - bpp: 1.2337 - mse: 6.5334e-05\n",
      "Epoch 660: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3041 - bpp: 1.2337 - mse: 6.5334e-05\n",
      "Epoch 661/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2872 - bpp: 1.2474 - mse: 6.3461e-05\n",
      "Epoch 661: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2872 - bpp: 1.2474 - mse: 6.3461e-05\n",
      "Epoch 662/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5156 - bpp: 1.3017 - mse: 7.4088e-05\n",
      "Epoch 662: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5156 - bpp: 1.3017 - mse: 7.4088e-05\n",
      "Epoch 663/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2278 - bpp: 1.2289 - mse: 6.0965e-05\n",
      "Epoch 663: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2278 - bpp: 1.2289 - mse: 6.0965e-05\n",
      "Epoch 664/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2561 - bpp: 1.2326 - mse: 6.2466e-05\n",
      "Epoch 664: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.2561 - bpp: 1.2326 - mse: 6.2466e-05\n",
      "Epoch 665/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3649 - bpp: 1.2627 - mse: 6.7272e-05\n",
      "Epoch 665: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3649 - bpp: 1.2627 - mse: 6.7272e-05\n",
      "Epoch 666/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4292 - bpp: 1.2925 - mse: 6.9376e-05\n",
      "Epoch 666: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4292 - bpp: 1.2925 - mse: 6.9376e-05\n",
      "Epoch 667/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5171 - bpp: 1.2920 - mse: 7.4774e-05\n",
      "Epoch 667: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.5171 - bpp: 1.2920 - mse: 7.4774e-05\n",
      "Epoch 668/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5515 - bpp: 1.3315 - mse: 7.4464e-05\n",
      "Epoch 668: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 2.5515 - bpp: 1.3315 - mse: 7.4464e-05\n",
      "Epoch 669/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4633 - bpp: 1.2938 - mse: 7.1381e-05\n",
      "Epoch 669: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4633 - bpp: 1.2938 - mse: 7.1381e-05\n",
      "Epoch 670/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3653 - bpp: 1.2803 - mse: 6.6226e-05\n",
      "Epoch 670: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3653 - bpp: 1.2803 - mse: 6.6226e-05\n",
      "Epoch 671/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4453 - bpp: 1.2954 - mse: 7.0182e-05\n",
      "Epoch 671: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4453 - bpp: 1.2954 - mse: 7.0182e-05\n",
      "Epoch 672/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3270 - bpp: 1.2454 - mse: 6.6019e-05\n",
      "Epoch 672: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.3270 - bpp: 1.2454 - mse: 6.6019e-05\n",
      "Epoch 673/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3497 - bpp: 1.2534 - mse: 6.6911e-05\n",
      "Epoch 673: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3497 - bpp: 1.2534 - mse: 6.6911e-05\n",
      "Epoch 674/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2072 - bpp: 1.2148 - mse: 6.0576e-05\n",
      "Epoch 674: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.2072 - bpp: 1.2148 - mse: 6.0576e-05\n",
      "Epoch 675/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3838 - bpp: 1.2715 - mse: 6.7890e-05\n",
      "Epoch 675: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 2.3838 - bpp: 1.2715 - mse: 6.7890e-05\n",
      "Epoch 676/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3682 - bpp: 1.2731 - mse: 6.6839e-05\n",
      "Epoch 676: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3682 - bpp: 1.2731 - mse: 6.6839e-05\n",
      "Epoch 677/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5103 - bpp: 1.3347 - mse: 7.1747e-05\n",
      "Epoch 677: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 2.5103 - bpp: 1.3347 - mse: 7.1747e-05\n",
      "Epoch 678/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4541 - bpp: 1.2921 - mse: 7.0920e-05\n",
      "Epoch 678: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4541 - bpp: 1.2921 - mse: 7.0920e-05\n",
      "Epoch 679/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5005 - bpp: 1.3258 - mse: 7.1701e-05\n",
      "Epoch 679: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5005 - bpp: 1.3258 - mse: 7.1701e-05\n",
      "Epoch 680/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4182 - bpp: 1.2838 - mse: 6.9239e-05\n",
      "Epoch 680: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.4182 - bpp: 1.2838 - mse: 6.9239e-05\n",
      "Epoch 681/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4199 - bpp: 1.2789 - mse: 6.9643e-05\n",
      "Epoch 681: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4199 - bpp: 1.2789 - mse: 6.9643e-05\n",
      "Epoch 682/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3309 - bpp: 1.2478 - mse: 6.6108e-05\n",
      "Epoch 682: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3309 - bpp: 1.2478 - mse: 6.6108e-05\n",
      "Epoch 683/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4421 - bpp: 1.2851 - mse: 7.0618e-05\n",
      "Epoch 683: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.4421 - bpp: 1.2851 - mse: 7.0618e-05\n",
      "Epoch 684/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5429 - bpp: 1.3095 - mse: 7.5278e-05\n",
      "Epoch 684: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5429 - bpp: 1.3095 - mse: 7.5278e-05\n",
      "Epoch 685/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3819 - bpp: 1.2655 - mse: 6.8146e-05\n",
      "Epoch 685: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 27s 132ms/step - loss: 2.3819 - bpp: 1.2655 - mse: 6.8146e-05\n",
      "Epoch 686/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4362 - bpp: 1.2923 - mse: 6.9818e-05\n",
      "Epoch 686: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 2.4362 - bpp: 1.2923 - mse: 6.9818e-05\n",
      "Epoch 687/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6822 - bpp: 1.3520 - mse: 8.1186e-05\n",
      "Epoch 687: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.6822 - bpp: 1.3520 - mse: 8.1186e-05\n",
      "Epoch 688/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3213 - bpp: 1.2118 - mse: 6.7720e-05\n",
      "Epoch 688: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.3213 - bpp: 1.2118 - mse: 6.7720e-05\n",
      "Epoch 689/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5011 - bpp: 1.3009 - mse: 7.3255e-05\n",
      "Epoch 689: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 2.5011 - bpp: 1.3009 - mse: 7.3255e-05\n",
      "Epoch 690/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3452 - bpp: 1.2723 - mse: 6.5486e-05\n",
      "Epoch 690: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3452 - bpp: 1.2723 - mse: 6.5486e-05\n",
      "Epoch 691/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5160 - bpp: 1.3191 - mse: 7.3049e-05\n",
      "Epoch 691: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.5160 - bpp: 1.3191 - mse: 7.3049e-05\n",
      "Epoch 692/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4834 - bpp: 1.3093 - mse: 7.1658e-05\n",
      "Epoch 692: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.4834 - bpp: 1.3093 - mse: 7.1658e-05\n",
      "Epoch 693/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4793 - bpp: 1.3065 - mse: 7.1586e-05\n",
      "Epoch 693: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 2.4793 - bpp: 1.3065 - mse: 7.1586e-05\n",
      "Epoch 694/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4145 - bpp: 1.2962 - mse: 6.8256e-05\n",
      "Epoch 694: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 2.4145 - bpp: 1.2962 - mse: 6.8256e-05\n",
      "Epoch 695/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3007 - bpp: 1.2468 - mse: 6.4323e-05\n",
      "Epoch 695: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 2.3007 - bpp: 1.2468 - mse: 6.4323e-05\n",
      "Epoch 696/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2340 - bpp: 1.2482 - mse: 6.0165e-05\n",
      "Epoch 696: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 2.2340 - bpp: 1.2482 - mse: 6.0165e-05\n",
      "Epoch 697/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3234 - bpp: 1.2793 - mse: 6.3731e-05\n",
      "Epoch 697: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.3234 - bpp: 1.2793 - mse: 6.3731e-05\n",
      "Epoch 698/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2686 - bpp: 1.2270 - mse: 6.3577e-05\n",
      "Epoch 698: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2686 - bpp: 1.2270 - mse: 6.3577e-05\n",
      "Epoch 699/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2777 - bpp: 1.2531 - mse: 6.2539e-05\n",
      "Epoch 699: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 2.2777 - bpp: 1.2531 - mse: 6.2539e-05\n",
      "Epoch 700/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4065 - bpp: 1.2924 - mse: 6.7998e-05\n",
      "Epoch 700: loss did not improve from 2.20472\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 2.4065 - bpp: 1.2924 - mse: 6.7998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_3_layer_call_fn, optical_flow_loss_3_layer_call_and_return_conditional_losses, dwt_3_layer_call_fn, dwt_3_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_16384_epcs_700_I_QP_35_240x240_CosineDecay_20220601-010119/assets\n"
     ]
    }
   ],
   "source": [
    "I_QP=35\n",
    "lmbda = 16384\n",
    "trainer_14 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_14.compile()\n",
    "trainer_14.fit()\n",
    "trainer_14.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 337.8401 - bpp: 5.3101 - mse: 0.0101\n",
      "Epoch 1: loss improved from inf to 337.84012, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 51s 122ms/step - loss: 337.8401 - bpp: 5.3101 - mse: 0.0101\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 94.1596 - bpp: 5.1704 - mse: 0.0027\n",
      "Epoch 2: loss improved from 337.84012 to 94.15957, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 94.1596 - bpp: 5.1704 - mse: 0.0027\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 64.5439 - bpp: 5.0348 - mse: 0.0018\n",
      "Epoch 3: loss improved from 94.15957 to 64.54388, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 64.5439 - bpp: 5.0348 - mse: 0.0018\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 52.0982 - bpp: 4.9020 - mse: 0.0014\n",
      "Epoch 4: loss improved from 64.54388 to 52.09822, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 52.0982 - bpp: 4.9020 - mse: 0.0014\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 53.6734 - bpp: 4.7720 - mse: 0.0015\n",
      "Epoch 5: loss did not improve from 52.09822\n",
      "200/200 [==============================] - 27s 132ms/step - loss: 53.6734 - bpp: 4.7720 - mse: 0.0015\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 44.8345 - bpp: 4.6439 - mse: 0.0012\n",
      "Epoch 6: loss improved from 52.09822 to 44.83446, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 44.8345 - bpp: 4.6439 - mse: 0.0012\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 44.3918 - bpp: 4.5183 - mse: 0.0012\n",
      "Epoch 7: loss improved from 44.83446 to 44.39178, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 44.3918 - bpp: 4.5183 - mse: 0.0012\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 41.8540 - bpp: 4.3945 - mse: 0.0011\n",
      "Epoch 8: loss improved from 44.39178 to 41.85404, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 41.8540 - bpp: 4.3945 - mse: 0.0011\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 54.0686 - bpp: 4.2743 - mse: 0.0015\n",
      "Epoch 9: loss did not improve from 41.85404\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 54.0686 - bpp: 4.2743 - mse: 0.0015\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 45.3340 - bpp: 4.1552 - mse: 0.0013\n",
      "Epoch 10: loss did not improve from 41.85404\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 45.3340 - bpp: 4.1552 - mse: 0.0013\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 31.1076 - bpp: 4.0384 - mse: 8.2608e-04\n",
      "Epoch 11: loss improved from 41.85404 to 31.10755, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 31.1076 - bpp: 4.0384 - mse: 8.2608e-04\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 43.5999 - bpp: 3.9250 - mse: 0.0012\n",
      "Epoch 12: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 43.5999 - bpp: 3.9250 - mse: 0.0012\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 39.1516 - bpp: 3.8131 - mse: 0.0011\n",
      "Epoch 13: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 39.1516 - bpp: 3.8131 - mse: 0.0011\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 35.5504 - bpp: 3.7023 - mse: 9.7193e-04\n",
      "Epoch 14: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 35.5504 - bpp: 3.7023 - mse: 9.7193e-04\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 39.1636 - bpp: 3.5953 - mse: 0.0011\n",
      "Epoch 15: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 39.1636 - bpp: 3.5953 - mse: 0.0011\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 46.2702 - bpp: 3.4930 - mse: 0.0013\n",
      "Epoch 16: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 46.2702 - bpp: 3.4930 - mse: 0.0013\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.0370 - bpp: 3.3889 - mse: 8.7427e-04\n",
      "Epoch 17: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 32.0370 - bpp: 3.3889 - mse: 8.7427e-04\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 33.3668 - bpp: 3.2909 - mse: 9.1784e-04\n",
      "Epoch 18: loss did not improve from 31.10755\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 33.3668 - bpp: 3.2909 - mse: 9.1784e-04\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 29.8068 - bpp: 3.1904 - mse: 8.1227e-04\n",
      "Epoch 19: loss improved from 31.10755 to 29.80681, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 29.8068 - bpp: 3.1904 - mse: 8.1227e-04\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 30.9356 - bpp: 3.0984 - mse: 8.4952e-04\n",
      "Epoch 20: loss did not improve from 29.80681\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 30.9356 - bpp: 3.0984 - mse: 8.4952e-04\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.9700 - bpp: 3.0160 - mse: 9.1412e-04\n",
      "Epoch 21: loss did not improve from 29.80681\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 32.9700 - bpp: 3.0160 - mse: 9.1412e-04\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.0833 - bpp: 2.9254 - mse: 8.8983e-04\n",
      "Epoch 22: loss did not improve from 29.80681\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 32.0833 - bpp: 2.9254 - mse: 8.8983e-04\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 27.9350 - bpp: 2.8310 - mse: 7.6611e-04\n",
      "Epoch 23: loss improved from 29.80681 to 27.93496, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 27.9350 - bpp: 2.8310 - mse: 7.6611e-04\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 27.5062 - bpp: 2.7480 - mse: 7.5556e-04\n",
      "Epoch 24: loss improved from 27.93496 to 27.50616, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 27.5062 - bpp: 2.7480 - mse: 7.5556e-04\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 27.9440 - bpp: 2.6738 - mse: 7.7119e-04\n",
      "Epoch 25: loss did not improve from 27.50616\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 27.9440 - bpp: 2.6738 - mse: 7.7119e-04\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 59.0051 - bpp: 2.5957 - mse: 0.0017\n",
      "Epoch 26: loss did not improve from 27.50616\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 59.0051 - bpp: 2.5957 - mse: 0.0017\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.8831 - bpp: 2.5172 - mse: 7.1307e-04\n",
      "Epoch 27: loss improved from 27.50616 to 25.88307, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 25.8831 - bpp: 2.5172 - mse: 7.1307e-04\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.2431 - bpp: 2.4443 - mse: 6.9577e-04\n",
      "Epoch 28: loss improved from 25.88307 to 25.24312, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 25.2431 - bpp: 2.4443 - mse: 6.9577e-04\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 24.7604 - bpp: 2.3785 - mse: 6.8304e-04\n",
      "Epoch 29: loss improved from 25.24312 to 24.76039, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 24.7604 - bpp: 2.3785 - mse: 6.8304e-04\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.2814 - bpp: 2.3081 - mse: 6.0954e-04\n",
      "Epoch 30: loss improved from 24.76039 to 22.28142, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 22.2814 - bpp: 2.3081 - mse: 6.0954e-04\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.8949 - bpp: 2.2467 - mse: 6.6065e-04\n",
      "Epoch 31: loss did not improve from 22.28142\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 23.8949 - bpp: 2.2467 - mse: 6.6065e-04\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.0706 - bpp: 2.1892 - mse: 5.7622e-04\n",
      "Epoch 32: loss improved from 22.28142 to 21.07060, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 21.0706 - bpp: 2.1892 - mse: 5.7622e-04\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.4168 - bpp: 2.1629 - mse: 7.0965e-04\n",
      "Epoch 33: loss did not improve from 21.07060\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 25.4168 - bpp: 2.1629 - mse: 7.0965e-04\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 37.2758 - bpp: 2.1013 - mse: 0.0011\n",
      "Epoch 34: loss did not improve from 21.07060\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 37.2758 - bpp: 2.1013 - mse: 0.0011\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.7548 - bpp: 2.0370 - mse: 6.3226e-04\n",
      "Epoch 35: loss did not improve from 21.07060\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 22.7548 - bpp: 2.0370 - mse: 6.3226e-04\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.0560 - bpp: 1.9655 - mse: 5.5208e-04\n",
      "Epoch 36: loss improved from 21.07060 to 20.05596, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 20.0560 - bpp: 1.9655 - mse: 5.5208e-04\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.3687 - bpp: 1.9402 - mse: 6.2343e-04\n",
      "Epoch 37: loss did not improve from 20.05596\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 22.3687 - bpp: 1.9402 - mse: 6.2343e-04\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.9372 - bpp: 1.9127 - mse: 5.1955e-04\n",
      "Epoch 38: loss improved from 20.05596 to 18.93719, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 18.9372 - bpp: 1.9127 - mse: 5.1955e-04\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.3614 - bpp: 1.8753 - mse: 6.2518e-04\n",
      "Epoch 39: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 22.3614 - bpp: 1.8753 - mse: 6.2518e-04\n",
      "Epoch 40/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 36.0673 - bpp: 1.8834 - mse: 0.0010\n",
      "Epoch 40: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 36.0673 - bpp: 1.8834 - mse: 0.0010\n",
      "Epoch 41/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.1472 - bpp: 1.8153 - mse: 6.5100e-04\n",
      "Epoch 41: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 23.1472 - bpp: 1.8153 - mse: 6.5100e-04\n",
      "Epoch 42/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.8076 - bpp: 1.8035 - mse: 7.6306e-04\n",
      "Epoch 42: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 26.8076 - bpp: 1.8035 - mse: 7.6306e-04\n",
      "Epoch 43/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.8780 - bpp: 1.7582 - mse: 6.1401e-04\n",
      "Epoch 43: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 21.8780 - bpp: 1.7582 - mse: 6.1401e-04\n",
      "Epoch 44/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.3276 - bpp: 1.7392 - mse: 5.6727e-04\n",
      "Epoch 44: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 20.3276 - bpp: 1.7392 - mse: 5.6727e-04\n",
      "Epoch 45/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.2404 - bpp: 1.7300 - mse: 5.6489e-04\n",
      "Epoch 45: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 20.2404 - bpp: 1.7300 - mse: 5.6489e-04\n",
      "Epoch 46/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.0959 - bpp: 1.6846 - mse: 5.9239e-04\n",
      "Epoch 46: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 21.0959 - bpp: 1.6846 - mse: 5.9239e-04\n",
      "Epoch 47/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.9819 - bpp: 1.6889 - mse: 6.8033e-04\n",
      "Epoch 47: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 23.9819 - bpp: 1.6889 - mse: 6.8033e-04\n",
      "Epoch 48/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.4115 - bpp: 1.6444 - mse: 6.0325e-04\n",
      "Epoch 48: loss did not improve from 18.93719\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 21.4115 - bpp: 1.6444 - mse: 6.0325e-04\n",
      "Epoch 49/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.3284 - bpp: 1.6436 - mse: 5.0918e-04\n",
      "Epoch 49: loss improved from 18.93719 to 18.32839, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 18.3284 - bpp: 1.6436 - mse: 5.0918e-04\n",
      "Epoch 50/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.2391 - bpp: 1.6065 - mse: 5.0759e-04\n",
      "Epoch 50: loss improved from 18.32839 to 18.23908, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 18.2391 - bpp: 1.6065 - mse: 5.0759e-04\n",
      "Epoch 51/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.2434 - bpp: 1.6433 - mse: 9.3384e-04\n",
      "Epoch 51: loss did not improve from 18.23908\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 32.2434 - bpp: 1.6433 - mse: 9.3384e-04\n",
      "Epoch 52/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.0615 - bpp: 1.6454 - mse: 9.2823e-04\n",
      "Epoch 52: loss did not improve from 18.23908\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 32.0615 - bpp: 1.6454 - mse: 9.2823e-04\n",
      "Epoch 53/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.5537 - bpp: 1.5368 - mse: 5.4983e-04\n",
      "Epoch 53: loss did not improve from 18.23908\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 19.5537 - bpp: 1.5368 - mse: 5.4983e-04\n",
      "Epoch 54/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.5019 - bpp: 1.5447 - mse: 5.1749e-04\n",
      "Epoch 54: loss did not improve from 18.23908\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 18.5019 - bpp: 1.5447 - mse: 5.1749e-04\n",
      "Epoch 55/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.0438 - bpp: 1.5502 - mse: 5.0334e-04\n",
      "Epoch 55: loss improved from 18.23908 to 18.04378, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 18.0438 - bpp: 1.5502 - mse: 5.0334e-04\n",
      "Epoch 56/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.5122 - bpp: 1.5363 - mse: 5.7910e-04\n",
      "Epoch 56: loss did not improve from 18.04378\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 20.5122 - bpp: 1.5363 - mse: 5.7910e-04\n",
      "Epoch 57/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.5697 - bpp: 1.5000 - mse: 4.9041e-04\n",
      "Epoch 57: loss improved from 18.04378 to 17.56968, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 17.5697 - bpp: 1.5000 - mse: 4.9041e-04\n",
      "Epoch 58/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.2787 - bpp: 1.5060 - mse: 4.5083e-04\n",
      "Epoch 58: loss improved from 17.56968 to 16.27870, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 16.2787 - bpp: 1.5060 - mse: 4.5083e-04\n",
      "Epoch 59/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.1328 - bpp: 1.5093 - mse: 5.3783e-04\n",
      "Epoch 59: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 19.1328 - bpp: 1.5093 - mse: 5.3783e-04\n",
      "Epoch 60/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4370 - bpp: 1.4779 - mse: 4.5651e-04\n",
      "Epoch 60: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 16.4370 - bpp: 1.4779 - mse: 4.5651e-04\n",
      "Epoch 61/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.1766 - bpp: 1.4702 - mse: 4.7932e-04\n",
      "Epoch 61: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 17.1766 - bpp: 1.4702 - mse: 4.7932e-04\n",
      "Epoch 62/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 28.0428 - bpp: 1.4918 - mse: 8.1027e-04\n",
      "Epoch 62: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 28.0428 - bpp: 1.4918 - mse: 8.1027e-04\n",
      "Epoch 63/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.4081 - bpp: 1.5270 - mse: 6.3724e-04\n",
      "Epoch 63: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 22.4081 - bpp: 1.5270 - mse: 6.3724e-04\n",
      "Epoch 64/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.5444 - bpp: 1.4716 - mse: 5.2102e-04\n",
      "Epoch 64: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 18.5444 - bpp: 1.4716 - mse: 5.2102e-04\n",
      "Epoch 65/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.7963 - bpp: 1.4636 - mse: 5.2895e-04\n",
      "Epoch 65: loss did not improve from 16.27870\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 18.7963 - bpp: 1.4636 - mse: 5.2895e-04\n",
      "Epoch 66/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.3550 - bpp: 1.3945 - mse: 3.9552e-04\n",
      "Epoch 66: loss improved from 16.27870 to 14.35497, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 14.3550 - bpp: 1.3945 - mse: 3.9552e-04\n",
      "Epoch 67/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.8291 - bpp: 1.4300 - mse: 4.6994e-04\n",
      "Epoch 67: loss did not improve from 14.35497\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 16.8291 - bpp: 1.4300 - mse: 4.6994e-04\n",
      "Epoch 68/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.9781 - bpp: 1.4188 - mse: 5.0535e-04\n",
      "Epoch 68: loss did not improve from 14.35497\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 17.9781 - bpp: 1.4188 - mse: 5.0535e-04\n",
      "Epoch 69/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.2068 - bpp: 1.4205 - mse: 5.4279e-04\n",
      "Epoch 69: loss did not improve from 14.35497\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 19.2068 - bpp: 1.4205 - mse: 5.4279e-04\n",
      "Epoch 70/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.9831 - bpp: 1.4162 - mse: 4.7506e-04\n",
      "Epoch 70: loss did not improve from 14.35497\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 16.9831 - bpp: 1.4162 - mse: 4.7506e-04\n",
      "Epoch 71/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.3845 - bpp: 1.4286 - mse: 6.3952e-04\n",
      "Epoch 71: loss did not improve from 14.35497\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 22.3845 - bpp: 1.4286 - mse: 6.3952e-04\n",
      "Epoch 72/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.7261 - bpp: 1.4228 - mse: 4.9753e-04\n",
      "Epoch 72: loss did not improve from 14.35497\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 17.7261 - bpp: 1.4228 - mse: 4.9753e-04\n",
      "Epoch 73/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.4122 - bpp: 1.3806 - mse: 3.6718e-04\n",
      "Epoch 73: loss improved from 14.35497 to 13.41223, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 13.4122 - bpp: 1.3806 - mse: 3.6718e-04\n",
      "Epoch 74/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.0172 - bpp: 1.4388 - mse: 4.4490e-04\n",
      "Epoch 74: loss did not improve from 13.41223\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 16.0172 - bpp: 1.4388 - mse: 4.4490e-04\n",
      "Epoch 75/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.9432 - bpp: 1.4105 - mse: 4.1298e-04\n",
      "Epoch 75: loss did not improve from 13.41223\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 14.9432 - bpp: 1.4105 - mse: 4.1298e-04\n",
      "Epoch 76/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2615 - bpp: 1.3674 - mse: 3.6298e-04\n",
      "Epoch 76: loss improved from 13.41223 to 13.26148, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 13.2615 - bpp: 1.3674 - mse: 3.6298e-04\n",
      "Epoch 77/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.9105 - bpp: 1.4541 - mse: 6.8531e-04\n",
      "Epoch 77: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 23.9105 - bpp: 1.4541 - mse: 6.8531e-04\n",
      "Epoch 78/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 44.5144 - bpp: 1.4654 - mse: 0.0013\n",
      "Epoch 78: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 44.5144 - bpp: 1.4654 - mse: 0.0013\n",
      "Epoch 79/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.0757 - bpp: 1.4160 - mse: 4.4738e-04\n",
      "Epoch 79: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 16.0757 - bpp: 1.4160 - mse: 4.4738e-04\n",
      "Epoch 80/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.5177 - bpp: 1.3999 - mse: 4.3084e-04\n",
      "Epoch 80: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 15.5177 - bpp: 1.3999 - mse: 4.3084e-04\n",
      "Epoch 81/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.3985 - bpp: 1.3737 - mse: 3.9748e-04\n",
      "Epoch 81: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 14.3985 - bpp: 1.3737 - mse: 3.9748e-04\n",
      "Epoch 82/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.9195 - bpp: 1.3897 - mse: 3.8238e-04\n",
      "Epoch 82: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 13.9195 - bpp: 1.3897 - mse: 3.8238e-04\n",
      "Epoch 83/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.0349 - bpp: 1.3832 - mse: 4.1662e-04\n",
      "Epoch 83: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 15.0349 - bpp: 1.3832 - mse: 4.1662e-04\n",
      "Epoch 84/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.7977 - bpp: 1.3708 - mse: 4.4027e-04\n",
      "Epoch 84: loss did not improve from 13.26148\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 15.7977 - bpp: 1.3708 - mse: 4.4027e-04\n",
      "Epoch 85/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3614 - bpp: 1.3357 - mse: 3.3648e-04\n",
      "Epoch 85: loss improved from 13.26148 to 12.36135, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 12.3614 - bpp: 1.3357 - mse: 3.3648e-04\n",
      "Epoch 86/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.2514 - bpp: 1.3583 - mse: 3.9346e-04\n",
      "Epoch 86: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 14.2514 - bpp: 1.3583 - mse: 3.9346e-04\n",
      "Epoch 87/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.7029 - bpp: 1.3271 - mse: 3.4716e-04\n",
      "Epoch 87: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 12.7029 - bpp: 1.3271 - mse: 3.4716e-04\n",
      "Epoch 88/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.4766 - bpp: 1.3659 - mse: 4.9166e-04\n",
      "Epoch 88: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 17.4766 - bpp: 1.3659 - mse: 4.9166e-04\n",
      "Epoch 89/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4662 - bpp: 1.3596 - mse: 4.6102e-04\n",
      "Epoch 89: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 16.4662 - bpp: 1.3596 - mse: 4.6102e-04\n",
      "Epoch 90/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.4819 - bpp: 1.3474 - mse: 3.7031e-04\n",
      "Epoch 90: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 13.4819 - bpp: 1.3474 - mse: 3.7031e-04\n",
      "Epoch 91/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.9802 - bpp: 1.3789 - mse: 3.8456e-04\n",
      "Epoch 91: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 13.9802 - bpp: 1.3789 - mse: 3.8456e-04\n",
      "Epoch 92/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.6834 - bpp: 1.3390 - mse: 3.7672e-04\n",
      "Epoch 92: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 25s 119ms/step - loss: 13.6834 - bpp: 1.3390 - mse: 3.7672e-04\n",
      "Epoch 93/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.5231 - bpp: 1.3601 - mse: 4.0170e-04\n",
      "Epoch 93: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 14.5231 - bpp: 1.3601 - mse: 4.0170e-04\n",
      "Epoch 94/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.6265 - bpp: 1.3699 - mse: 4.3508e-04\n",
      "Epoch 94: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 15.6265 - bpp: 1.3699 - mse: 4.3508e-04\n",
      "Epoch 95/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.7628 - bpp: 1.3544 - mse: 3.4816e-04\n",
      "Epoch 95: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 12.7628 - bpp: 1.3544 - mse: 3.4816e-04\n",
      "Epoch 96/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.8192 - bpp: 1.3766 - mse: 3.7972e-04\n",
      "Epoch 96: loss did not improve from 12.36135\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 13.8192 - bpp: 1.3766 - mse: 3.7972e-04\n",
      "Epoch 97/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7650 - bpp: 1.3492 - mse: 2.8735e-04\n",
      "Epoch 97: loss improved from 12.36135 to 10.76505, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 10.7650 - bpp: 1.3492 - mse: 2.8735e-04\n",
      "Epoch 98/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.9550 - bpp: 1.3882 - mse: 4.4454e-04\n",
      "Epoch 98: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 15.9550 - bpp: 1.3882 - mse: 4.4454e-04\n",
      "Epoch 99/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.2784 - bpp: 1.3185 - mse: 3.0395e-04\n",
      "Epoch 99: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 11.2784 - bpp: 1.3185 - mse: 3.0395e-04\n",
      "Epoch 100/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1340 - bpp: 1.3654 - mse: 3.2863e-04\n",
      "Epoch 100: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 12.1340 - bpp: 1.3654 - mse: 3.2863e-04\n",
      "Epoch 101/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.5860 - bpp: 1.3893 - mse: 4.6377e-04\n",
      "Epoch 101: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 16.5860 - bpp: 1.3893 - mse: 4.6377e-04\n",
      "Epoch 102/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.4866 - bpp: 1.3743 - mse: 4.0015e-04\n",
      "Epoch 102: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 14.4866 - bpp: 1.3743 - mse: 4.0015e-04\n",
      "Epoch 103/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.8424 - bpp: 1.3854 - mse: 3.8016e-04\n",
      "Epoch 103: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 13.8424 - bpp: 1.3854 - mse: 3.8016e-04\n",
      "Epoch 104/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.6677 - bpp: 1.3749 - mse: 3.4463e-04\n",
      "Epoch 104: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 12.6677 - bpp: 1.3749 - mse: 3.4463e-04\n",
      "Epoch 105/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0961 - bpp: 1.3410 - mse: 2.9770e-04\n",
      "Epoch 105: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 11.0961 - bpp: 1.3410 - mse: 2.9770e-04\n",
      "Epoch 106/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.0938 - bpp: 1.3653 - mse: 3.5792e-04\n",
      "Epoch 106: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 13.0938 - bpp: 1.3653 - mse: 3.5792e-04\n",
      "Epoch 107/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.6441 - bpp: 1.3918 - mse: 4.0443e-04\n",
      "Epoch 107: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 14.6441 - bpp: 1.3918 - mse: 4.0443e-04\n",
      "Epoch 108/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.9212 - bpp: 1.3822 - mse: 3.5214e-04\n",
      "Epoch 108: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 12.9212 - bpp: 1.3822 - mse: 3.5214e-04\n",
      "Epoch 109/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 54.8426 - bpp: 1.4605 - mse: 0.0016\n",
      "Epoch 109: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 54.8426 - bpp: 1.4605 - mse: 0.0016\n",
      "Epoch 110/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.8566 - bpp: 1.3769 - mse: 4.4188e-04\n",
      "Epoch 110: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 15.8566 - bpp: 1.3769 - mse: 4.4188e-04\n",
      "Epoch 111/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6344 - bpp: 1.3456 - mse: 3.1399e-04\n",
      "Epoch 111: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 11.6344 - bpp: 1.3456 - mse: 3.1399e-04\n",
      "Epoch 112/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.7991 - bpp: 1.3736 - mse: 4.0971e-04\n",
      "Epoch 112: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 14.7991 - bpp: 1.3736 - mse: 4.0971e-04\n",
      "Epoch 113/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.7023 - bpp: 1.3521 - mse: 3.4638e-04\n",
      "Epoch 113: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 12.7023 - bpp: 1.3521 - mse: 3.4638e-04\n",
      "Epoch 114/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3406 - bpp: 1.3830 - mse: 3.3440e-04\n",
      "Epoch 114: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 12.3406 - bpp: 1.3830 - mse: 3.3440e-04\n",
      "Epoch 115/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.3489 - bpp: 1.3488 - mse: 3.0518e-04\n",
      "Epoch 115: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 11.3489 - bpp: 1.3488 - mse: 3.0518e-04\n",
      "Epoch 116/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.0901 - bpp: 1.3668 - mse: 3.2725e-04\n",
      "Epoch 116: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 12.0901 - bpp: 1.3668 - mse: 3.2725e-04\n",
      "Epoch 117/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.8687 - bpp: 1.3703 - mse: 4.7297e-04\n",
      "Epoch 117: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 16.8687 - bpp: 1.3703 - mse: 4.7297e-04\n",
      "Epoch 118/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.2291 - bpp: 1.3764 - mse: 4.5327e-04\n",
      "Epoch 118: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 16.2291 - bpp: 1.3764 - mse: 4.5327e-04\n",
      "Epoch 119/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.5737 - bpp: 1.3870 - mse: 3.7191e-04\n",
      "Epoch 119: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 13.5737 - bpp: 1.3870 - mse: 3.7191e-04\n",
      "Epoch 120/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.5028 - bpp: 1.3802 - mse: 3.3943e-04\n",
      "Epoch 120: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 12.5028 - bpp: 1.3802 - mse: 3.3943e-04\n",
      "Epoch 121/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3990 - bpp: 1.3803 - mse: 3.6678e-04\n",
      "Epoch 121: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 13.3990 - bpp: 1.3803 - mse: 3.6678e-04\n",
      "Epoch 122/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6526 - bpp: 1.3693 - mse: 3.1382e-04\n",
      "Epoch 122: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 11.6526 - bpp: 1.3693 - mse: 3.1382e-04\n",
      "Epoch 123/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2721 - bpp: 1.3953 - mse: 3.3194e-04\n",
      "Epoch 123: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 12.2721 - bpp: 1.3953 - mse: 3.3194e-04\n",
      "Epoch 124/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3081 - bpp: 1.3535 - mse: 3.6482e-04\n",
      "Epoch 124: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 13.3081 - bpp: 1.3535 - mse: 3.6482e-04\n",
      "Epoch 125/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.4338 - bpp: 1.3739 - mse: 3.3752e-04\n",
      "Epoch 125: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 12.4338 - bpp: 1.3739 - mse: 3.3752e-04\n",
      "Epoch 126/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.5018 - bpp: 1.4151 - mse: 4.6041e-04\n",
      "Epoch 126: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 16.5018 - bpp: 1.4151 - mse: 4.6041e-04\n",
      "Epoch 127/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.4783 - bpp: 1.3975 - mse: 4.2971e-04\n",
      "Epoch 127: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 15.4783 - bpp: 1.3975 - mse: 4.2971e-04\n",
      "Epoch 128/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3901 - bpp: 1.4054 - mse: 4.2678e-04\n",
      "Epoch 128: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 15.3901 - bpp: 1.4054 - mse: 4.2678e-04\n",
      "Epoch 129/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8070 - bpp: 1.3289 - mse: 2.8925e-04\n",
      "Epoch 129: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 10.8070 - bpp: 1.3289 - mse: 2.8925e-04\n",
      "Epoch 130/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.0908 - bpp: 1.3587 - mse: 3.2752e-04\n",
      "Epoch 130: loss did not improve from 10.76505\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 12.0908 - bpp: 1.3587 - mse: 3.2752e-04\n",
      "Epoch 131/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6345 - bpp: 1.3463 - mse: 2.8345e-04\n",
      "Epoch 131: loss improved from 10.76505 to 10.63448, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 10.6345 - bpp: 1.3463 - mse: 2.8345e-04\n",
      "Epoch 132/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6498 - bpp: 1.3560 - mse: 3.1414e-04\n",
      "Epoch 132: loss did not improve from 10.63448\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 11.6498 - bpp: 1.3560 - mse: 3.1414e-04\n",
      "Epoch 133/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3589 - bpp: 1.3870 - mse: 2.7380e-04\n",
      "Epoch 133: loss improved from 10.63448 to 10.35892, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 10.3589 - bpp: 1.3870 - mse: 2.7380e-04\n",
      "Epoch 134/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7319 - bpp: 1.3586 - mse: 2.8605e-04\n",
      "Epoch 134: loss did not improve from 10.35892\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.7319 - bpp: 1.3586 - mse: 2.8605e-04\n",
      "Epoch 135/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1579 - bpp: 1.3479 - mse: 2.3834e-04\n",
      "Epoch 135: loss improved from 10.35892 to 9.15789, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.1579 - bpp: 1.3479 - mse: 2.3834e-04\n",
      "Epoch 136/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2248 - bpp: 1.4047 - mse: 3.6072e-04\n",
      "Epoch 136: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 13.2248 - bpp: 1.4047 - mse: 3.6072e-04\n",
      "Epoch 137/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1423 - bpp: 1.3676 - mse: 3.2882e-04\n",
      "Epoch 137: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 12.1423 - bpp: 1.3676 - mse: 3.2882e-04\n",
      "Epoch 138/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4574 - bpp: 1.3730 - mse: 2.7723e-04\n",
      "Epoch 138: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 10.4574 - bpp: 1.3730 - mse: 2.7723e-04\n",
      "Epoch 139/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.1959 - bpp: 1.3436 - mse: 4.5326e-04\n",
      "Epoch 139: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 16.1959 - bpp: 1.3436 - mse: 4.5326e-04\n",
      "Epoch 140/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.8382 - bpp: 1.3569 - mse: 3.1986e-04\n",
      "Epoch 140: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 11.8382 - bpp: 1.3569 - mse: 3.1986e-04\n",
      "Epoch 141/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.2628 - bpp: 1.3654 - mse: 3.0205e-04\n",
      "Epoch 141: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 11.2628 - bpp: 1.3654 - mse: 3.0205e-04\n",
      "Epoch 142/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6408 - bpp: 1.3585 - mse: 2.8327e-04\n",
      "Epoch 142: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 10.6408 - bpp: 1.3585 - mse: 2.8327e-04\n",
      "Epoch 143/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.3674 - bpp: 1.3920 - mse: 3.0443e-04\n",
      "Epoch 143: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 11.3674 - bpp: 1.3920 - mse: 3.0443e-04\n",
      "Epoch 144/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3864 - bpp: 1.3848 - mse: 2.7471e-04\n",
      "Epoch 144: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.3864 - bpp: 1.3848 - mse: 2.7471e-04\n",
      "Epoch 145/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2231 - bpp: 1.3779 - mse: 2.6994e-04\n",
      "Epoch 145: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 10.2231 - bpp: 1.3779 - mse: 2.6994e-04\n",
      "Epoch 146/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1689 - bpp: 1.3702 - mse: 2.6851e-04\n",
      "Epoch 146: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 10.1689 - bpp: 1.3702 - mse: 2.6851e-04\n",
      "Epoch 147/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.0990 - bpp: 1.4291 - mse: 3.2562e-04\n",
      "Epoch 147: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 12.0990 - bpp: 1.4291 - mse: 3.2562e-04\n",
      "Epoch 148/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4205 - bpp: 1.4016 - mse: 3.0576e-04\n",
      "Epoch 148: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 11.4205 - bpp: 1.4016 - mse: 3.0576e-04\n",
      "Epoch 149/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.1480 - bpp: 1.4020 - mse: 3.8898e-04\n",
      "Epoch 149: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 14.1480 - bpp: 1.4020 - mse: 3.8898e-04\n",
      "Epoch 150/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.2032 - bpp: 1.4336 - mse: 3.8970e-04\n",
      "Epoch 150: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 14.2032 - bpp: 1.4336 - mse: 3.8970e-04\n",
      "Epoch 151/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.2783 - bpp: 1.4260 - mse: 3.0067e-04\n",
      "Epoch 151: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 11.2783 - bpp: 1.4260 - mse: 3.0067e-04\n",
      "Epoch 152/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0806 - bpp: 1.3989 - mse: 2.9546e-04\n",
      "Epoch 152: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 11.0806 - bpp: 1.3989 - mse: 2.9546e-04\n",
      "Epoch 153/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7455 - bpp: 1.3913 - mse: 2.8547e-04\n",
      "Epoch 153: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 10.7455 - bpp: 1.3913 - mse: 2.8547e-04\n",
      "Epoch 154/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.9408 - bpp: 1.3778 - mse: 2.9184e-04\n",
      "Epoch 154: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 10.9408 - bpp: 1.3778 - mse: 2.9184e-04\n",
      "Epoch 155/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3330 - bpp: 1.4069 - mse: 3.3344e-04\n",
      "Epoch 155: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 12.3330 - bpp: 1.4069 - mse: 3.3344e-04\n",
      "Epoch 156/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3587 - bpp: 1.3741 - mse: 2.7419e-04\n",
      "Epoch 156: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.3587 - bpp: 1.3741 - mse: 2.7419e-04\n",
      "Epoch 157/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3587 - bpp: 1.4298 - mse: 3.3352e-04\n",
      "Epoch 157: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 12.3587 - bpp: 1.4298 - mse: 3.3352e-04\n",
      "Epoch 158/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.5582 - bpp: 1.3928 - mse: 2.7971e-04\n",
      "Epoch 158: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 10.5582 - bpp: 1.3928 - mse: 2.7971e-04\n",
      "Epoch 159/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.7278 - bpp: 1.4152 - mse: 6.5041e-04\n",
      "Epoch 159: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 22.7278 - bpp: 1.4152 - mse: 6.5041e-04\n",
      "Epoch 160/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0399 - bpp: 1.4080 - mse: 2.9394e-04\n",
      "Epoch 160: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 11.0399 - bpp: 1.4080 - mse: 2.9394e-04\n",
      "Epoch 161/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0182 - bpp: 1.3724 - mse: 2.6385e-04\n",
      "Epoch 161: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.0182 - bpp: 1.3724 - mse: 2.6385e-04\n",
      "Epoch 162/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5918 - bpp: 1.4117 - mse: 2.4964e-04\n",
      "Epoch 162: loss did not improve from 9.15789\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 9.5918 - bpp: 1.4117 - mse: 2.4964e-04\n",
      "Epoch 163/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6812 - bpp: 1.3548 - mse: 2.2358e-04\n",
      "Epoch 163: loss improved from 9.15789 to 8.68125, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 8.6812 - bpp: 1.3548 - mse: 2.2358e-04\n",
      "Epoch 164/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2403 - bpp: 1.3343 - mse: 2.4127e-04\n",
      "Epoch 164: loss did not improve from 8.68125\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 9.2403 - bpp: 1.3343 - mse: 2.4127e-04\n",
      "Epoch 165/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2514 - bpp: 1.4051 - mse: 2.6997e-04\n",
      "Epoch 165: loss did not improve from 8.68125\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 10.2514 - bpp: 1.4051 - mse: 2.6997e-04\n",
      "Epoch 166/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1823 - bpp: 1.3866 - mse: 2.6842e-04\n",
      "Epoch 166: loss did not improve from 8.68125\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 10.1823 - bpp: 1.3866 - mse: 2.6842e-04\n",
      "Epoch 167/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1780 - bpp: 1.3810 - mse: 2.0743e-04\n",
      "Epoch 167: loss improved from 8.68125 to 8.17801, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 8.1780 - bpp: 1.3810 - mse: 2.0743e-04\n",
      "Epoch 168/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.0779 - bpp: 1.4446 - mse: 3.8554e-04\n",
      "Epoch 168: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 14.0779 - bpp: 1.4446 - mse: 3.8554e-04\n",
      "Epoch 169/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0820 - bpp: 1.4209 - mse: 2.9483e-04\n",
      "Epoch 169: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 11.0820 - bpp: 1.4209 - mse: 2.9483e-04\n",
      "Epoch 170/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0162 - bpp: 1.4057 - mse: 2.6277e-04\n",
      "Epoch 170: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.0162 - bpp: 1.4057 - mse: 2.6277e-04\n",
      "Epoch 171/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7078 - bpp: 1.4119 - mse: 2.2265e-04\n",
      "Epoch 171: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.7078 - bpp: 1.4119 - mse: 2.2265e-04\n",
      "Epoch 172/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8645 - bpp: 1.4056 - mse: 2.5815e-04\n",
      "Epoch 172: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 9.8645 - bpp: 1.4056 - mse: 2.5815e-04\n",
      "Epoch 173/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8980 - bpp: 1.3639 - mse: 2.2992e-04\n",
      "Epoch 173: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.8980 - bpp: 1.3639 - mse: 2.2992e-04\n",
      "Epoch 174/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3530 - bpp: 1.4174 - mse: 2.4218e-04\n",
      "Epoch 174: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 9.3530 - bpp: 1.4174 - mse: 2.4218e-04\n",
      "Epoch 175/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1254 - bpp: 1.3934 - mse: 2.6648e-04\n",
      "Epoch 175: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 10.1254 - bpp: 1.3934 - mse: 2.6648e-04\n",
      "Epoch 176/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.1436 - bpp: 1.4629 - mse: 3.5647e-04\n",
      "Epoch 176: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 13.1436 - bpp: 1.4629 - mse: 3.5647e-04\n",
      "Epoch 177/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.1375 - bpp: 1.4062 - mse: 2.9698e-04\n",
      "Epoch 177: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 11.1375 - bpp: 1.4062 - mse: 2.9698e-04\n",
      "Epoch 178/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1736 - bpp: 1.4196 - mse: 2.6715e-04\n",
      "Epoch 178: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 10.1736 - bpp: 1.4196 - mse: 2.6715e-04\n",
      "Epoch 179/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6660 - bpp: 1.3800 - mse: 2.5287e-04\n",
      "Epoch 179: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 9.6660 - bpp: 1.3800 - mse: 2.5287e-04\n",
      "Epoch 180/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.2028 - bpp: 1.4410 - mse: 4.1998e-04\n",
      "Epoch 180: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 15.2028 - bpp: 1.4410 - mse: 4.1998e-04\n",
      "Epoch 181/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7114 - bpp: 1.3801 - mse: 2.2373e-04\n",
      "Epoch 181: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.7114 - bpp: 1.3801 - mse: 2.2373e-04\n",
      "Epoch 182/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.9648 - bpp: 1.4436 - mse: 2.9056e-04\n",
      "Epoch 182: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 10.9648 - bpp: 1.4436 - mse: 2.9056e-04\n",
      "Epoch 183/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0936 - bpp: 1.4271 - mse: 2.6448e-04\n",
      "Epoch 183: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 10.0936 - bpp: 1.4271 - mse: 2.6448e-04\n",
      "Epoch 184/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.4497 - bpp: 1.4340 - mse: 6.7187e-04\n",
      "Epoch 184: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 23.4497 - bpp: 1.4340 - mse: 6.7187e-04\n",
      "Epoch 185/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8373 - bpp: 1.3954 - mse: 2.5763e-04\n",
      "Epoch 185: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 9.8373 - bpp: 1.3954 - mse: 2.5763e-04\n",
      "Epoch 186/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2358 - bpp: 1.4160 - mse: 2.3864e-04\n",
      "Epoch 186: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 9.2358 - bpp: 1.4160 - mse: 2.3864e-04\n",
      "Epoch 187/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7170 - bpp: 1.3886 - mse: 2.2365e-04\n",
      "Epoch 187: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.7170 - bpp: 1.3886 - mse: 2.2365e-04\n",
      "Epoch 188/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9910 - bpp: 1.4204 - mse: 2.3103e-04\n",
      "Epoch 188: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 8.9910 - bpp: 1.4204 - mse: 2.3103e-04\n",
      "Epoch 189/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6644 - bpp: 1.3875 - mse: 2.2207e-04\n",
      "Epoch 189: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.6644 - bpp: 1.3875 - mse: 2.2207e-04\n",
      "Epoch 190/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5616 - bpp: 1.3822 - mse: 2.1910e-04\n",
      "Epoch 190: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 8.5616 - bpp: 1.3822 - mse: 2.1910e-04\n",
      "Epoch 191/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6973 - bpp: 1.4263 - mse: 2.5241e-04\n",
      "Epoch 191: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 9.6973 - bpp: 1.4263 - mse: 2.5241e-04\n",
      "Epoch 192/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5402 - bpp: 1.4079 - mse: 2.1766e-04\n",
      "Epoch 192: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 8.5402 - bpp: 1.4079 - mse: 2.1766e-04\n",
      "Epoch 193/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.8856 - bpp: 1.4155 - mse: 3.8056e-04\n",
      "Epoch 193: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 13.8856 - bpp: 1.4155 - mse: 3.8056e-04\n",
      "Epoch 194/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4620 - bpp: 1.4297 - mse: 2.7564e-04\n",
      "Epoch 194: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 10.4620 - bpp: 1.4297 - mse: 2.7564e-04\n",
      "Epoch 195/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1988 - bpp: 1.4301 - mse: 2.3708e-04\n",
      "Epoch 195: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 9.1988 - bpp: 1.4301 - mse: 2.3708e-04\n",
      "Epoch 196/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4915 - bpp: 1.3918 - mse: 2.1667e-04\n",
      "Epoch 196: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.4915 - bpp: 1.3918 - mse: 2.1667e-04\n",
      "Epoch 197/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3495 - bpp: 1.4376 - mse: 2.1094e-04\n",
      "Epoch 197: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.3495 - bpp: 1.4376 - mse: 2.1094e-04\n",
      "Epoch 198/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2960 - bpp: 1.4375 - mse: 2.3982e-04\n",
      "Epoch 198: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 9.2960 - bpp: 1.4375 - mse: 2.3982e-04\n",
      "Epoch 199/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3622 - bpp: 1.4362 - mse: 2.7240e-04\n",
      "Epoch 199: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 10.3622 - bpp: 1.4362 - mse: 2.7240e-04\n",
      "Epoch 200/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7174 - bpp: 1.4082 - mse: 2.2306e-04\n",
      "Epoch 200: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.7174 - bpp: 1.4082 - mse: 2.2306e-04\n",
      "Epoch 201/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.1936 - bpp: 1.5012 - mse: 5.7045e-04\n",
      "Epoch 201: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 20.1936 - bpp: 1.5012 - mse: 5.7045e-04\n",
      "Epoch 202/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7842 - bpp: 1.4194 - mse: 2.2476e-04\n",
      "Epoch 202: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.7842 - bpp: 1.4194 - mse: 2.2476e-04\n",
      "Epoch 203/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0465 - bpp: 1.4183 - mse: 2.3279e-04\n",
      "Epoch 203: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 9.0465 - bpp: 1.4183 - mse: 2.3279e-04\n",
      "Epoch 204/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.7294 - bpp: 1.4343 - mse: 2.5315e-04\n",
      "Epoch 204: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 9.7294 - bpp: 1.4343 - mse: 2.5315e-04\n",
      "Epoch 205/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5464 - bpp: 1.4101 - mse: 2.1778e-04\n",
      "Epoch 205: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.5464 - bpp: 1.4101 - mse: 2.1778e-04\n",
      "Epoch 206/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6382 - bpp: 1.4294 - mse: 2.2000e-04\n",
      "Epoch 206: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.6382 - bpp: 1.4294 - mse: 2.2000e-04\n",
      "Epoch 207/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9291 - bpp: 1.4320 - mse: 2.2879e-04\n",
      "Epoch 207: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.9291 - bpp: 1.4320 - mse: 2.2879e-04\n",
      "Epoch 208/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0212 - bpp: 1.4266 - mse: 2.3177e-04\n",
      "Epoch 208: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 9.0212 - bpp: 1.4266 - mse: 2.3177e-04\n",
      "Epoch 209/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.9217 - bpp: 1.4912 - mse: 2.8780e-04\n",
      "Epoch 209: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 10.9217 - bpp: 1.4912 - mse: 2.8780e-04\n",
      "Epoch 210/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7181 - bpp: 1.4357 - mse: 2.2224e-04\n",
      "Epoch 210: loss did not improve from 8.17801\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 8.7181 - bpp: 1.4357 - mse: 2.2224e-04\n",
      "Epoch 211/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5263 - bpp: 1.3951 - mse: 1.8711e-04\n",
      "Epoch 211: loss improved from 8.17801 to 7.52628, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 7.5263 - bpp: 1.3951 - mse: 1.8711e-04\n",
      "Epoch 212/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1975 - bpp: 1.4013 - mse: 2.0740e-04\n",
      "Epoch 212: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.1975 - bpp: 1.4013 - mse: 2.0740e-04\n",
      "Epoch 213/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.2745 - bpp: 1.4574 - mse: 2.9959e-04\n",
      "Epoch 213: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 11.2745 - bpp: 1.4574 - mse: 2.9959e-04\n",
      "Epoch 214/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1270 - bpp: 1.4902 - mse: 3.2461e-04\n",
      "Epoch 214: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 12.1270 - bpp: 1.4902 - mse: 3.2461e-04\n",
      "Epoch 215/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4445 - bpp: 1.4144 - mse: 2.1454e-04\n",
      "Epoch 215: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.4445 - bpp: 1.4144 - mse: 2.1454e-04\n",
      "Epoch 216/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1186 - bpp: 1.4452 - mse: 2.3417e-04\n",
      "Epoch 216: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 9.1186 - bpp: 1.4452 - mse: 2.3417e-04\n",
      "Epoch 217/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8095 - bpp: 1.4247 - mse: 1.9485e-04\n",
      "Epoch 217: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 7.8095 - bpp: 1.4247 - mse: 1.9485e-04\n",
      "Epoch 218/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2435 - bpp: 1.4704 - mse: 2.3721e-04\n",
      "Epoch 218: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 9.2435 - bpp: 1.4704 - mse: 2.3721e-04\n",
      "Epoch 219/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2616 - bpp: 1.4406 - mse: 2.0816e-04\n",
      "Epoch 219: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.2616 - bpp: 1.4406 - mse: 2.0816e-04\n",
      "Epoch 220/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.7213 - bpp: 1.4383 - mse: 2.5278e-04\n",
      "Epoch 220: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 9.7213 - bpp: 1.4383 - mse: 2.5278e-04\n",
      "Epoch 221/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2501 - bpp: 1.4681 - mse: 2.6801e-04\n",
      "Epoch 221: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.2501 - bpp: 1.4681 - mse: 2.6801e-04\n",
      "Epoch 222/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6523 - bpp: 1.4579 - mse: 2.1956e-04\n",
      "Epoch 222: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.6523 - bpp: 1.4579 - mse: 2.1956e-04\n",
      "Epoch 223/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4906 - bpp: 1.4624 - mse: 3.0604e-04\n",
      "Epoch 223: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 11.4906 - bpp: 1.4624 - mse: 3.0604e-04\n",
      "Epoch 224/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1504 - bpp: 1.4349 - mse: 2.0494e-04\n",
      "Epoch 224: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.1504 - bpp: 1.4349 - mse: 2.0494e-04\n",
      "Epoch 225/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4340 - bpp: 1.4689 - mse: 2.4308e-04\n",
      "Epoch 225: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 9.4340 - bpp: 1.4689 - mse: 2.4308e-04\n",
      "Epoch 226/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4088 - bpp: 1.4214 - mse: 2.1324e-04\n",
      "Epoch 226: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.4088 - bpp: 1.4214 - mse: 2.1324e-04\n",
      "Epoch 227/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0379 - bpp: 1.4613 - mse: 2.3122e-04\n",
      "Epoch 227: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 9.0379 - bpp: 1.4613 - mse: 2.3122e-04\n",
      "Epoch 228/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9435 - bpp: 1.4335 - mse: 2.2918e-04\n",
      "Epoch 228: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.9435 - bpp: 1.4335 - mse: 2.2918e-04\n",
      "Epoch 229/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.2249 - bpp: 1.4812 - mse: 3.8891e-04\n",
      "Epoch 229: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 14.2249 - bpp: 1.4812 - mse: 3.8891e-04\n",
      "Epoch 230/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4828 - bpp: 1.4725 - mse: 2.4445e-04\n",
      "Epoch 230: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 9.4828 - bpp: 1.4725 - mse: 2.4445e-04\n",
      "Epoch 231/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9687 - bpp: 1.4294 - mse: 1.9956e-04\n",
      "Epoch 231: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.9687 - bpp: 1.4294 - mse: 1.9956e-04\n",
      "Epoch 232/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3192 - bpp: 1.4713 - mse: 2.0898e-04\n",
      "Epoch 232: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 8.3192 - bpp: 1.4713 - mse: 2.0898e-04\n",
      "Epoch 233/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6448 - bpp: 1.4590 - mse: 2.1930e-04\n",
      "Epoch 233: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 8.6448 - bpp: 1.4590 - mse: 2.1930e-04\n",
      "Epoch 234/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8631 - bpp: 1.4994 - mse: 2.5524e-04\n",
      "Epoch 234: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 115ms/step - loss: 9.8631 - bpp: 1.4994 - mse: 2.5524e-04\n",
      "Epoch 235/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7179 - bpp: 1.4192 - mse: 1.9222e-04\n",
      "Epoch 235: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.7179 - bpp: 1.4192 - mse: 1.9222e-04\n",
      "Epoch 236/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4572 - bpp: 1.4747 - mse: 2.1309e-04\n",
      "Epoch 236: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.4572 - bpp: 1.4747 - mse: 2.1309e-04\n",
      "Epoch 237/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0754 - bpp: 1.4741 - mse: 2.3197e-04\n",
      "Epoch 237: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.0754 - bpp: 1.4741 - mse: 2.3197e-04\n",
      "Epoch 238/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2881 - bpp: 1.4490 - mse: 2.0871e-04\n",
      "Epoch 238: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.2881 - bpp: 1.4490 - mse: 2.0871e-04\n",
      "Epoch 239/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2765 - bpp: 1.4339 - mse: 2.0882e-04\n",
      "Epoch 239: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.2765 - bpp: 1.4339 - mse: 2.0882e-04\n",
      "Epoch 240/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1941 - bpp: 1.4590 - mse: 2.0554e-04\n",
      "Epoch 240: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 8.1941 - bpp: 1.4590 - mse: 2.0554e-04\n",
      "Epoch 241/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0046 - bpp: 1.4444 - mse: 2.0020e-04\n",
      "Epoch 241: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.0046 - bpp: 1.4444 - mse: 2.0020e-04\n",
      "Epoch 242/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1609 - bpp: 1.4611 - mse: 2.0446e-04\n",
      "Epoch 242: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 8.1609 - bpp: 1.4611 - mse: 2.0446e-04\n",
      "Epoch 243/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5790 - bpp: 1.4678 - mse: 2.1701e-04\n",
      "Epoch 243: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.5790 - bpp: 1.4678 - mse: 2.1701e-04\n",
      "Epoch 244/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2706 - bpp: 1.4792 - mse: 2.0726e-04\n",
      "Epoch 244: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.2706 - bpp: 1.4792 - mse: 2.0726e-04\n",
      "Epoch 245/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4606 - bpp: 1.4721 - mse: 2.4379e-04\n",
      "Epoch 245: loss did not improve from 7.52628\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 9.4606 - bpp: 1.4721 - mse: 2.4379e-04\n",
      "Epoch 246/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2950 - bpp: 1.4655 - mse: 1.7790e-04\n",
      "Epoch 246: loss improved from 7.52628 to 7.29503, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 7.2950 - bpp: 1.4655 - mse: 1.7790e-04\n",
      "Epoch 247/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7837 - bpp: 1.4566 - mse: 2.2361e-04\n",
      "Epoch 247: loss did not improve from 7.29503\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.7837 - bpp: 1.4566 - mse: 2.2361e-04\n",
      "Epoch 248/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6031 - bpp: 1.5493 - mse: 3.0682e-04\n",
      "Epoch 248: loss did not improve from 7.29503\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 11.6031 - bpp: 1.5493 - mse: 3.0682e-04\n",
      "Epoch 249/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2930 - bpp: 1.4647 - mse: 1.7787e-04\n",
      "Epoch 249: loss improved from 7.29503 to 7.29303, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.2930 - bpp: 1.4647 - mse: 1.7787e-04\n",
      "Epoch 250/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4761 - bpp: 1.4509 - mse: 1.8387e-04\n",
      "Epoch 250: loss did not improve from 7.29303\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.4761 - bpp: 1.4509 - mse: 1.8387e-04\n",
      "Epoch 251/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7387 - bpp: 1.4856 - mse: 1.9083e-04\n",
      "Epoch 251: loss did not improve from 7.29303\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.7387 - bpp: 1.4856 - mse: 1.9083e-04\n",
      "Epoch 252/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0201 - bpp: 1.4757 - mse: 1.9972e-04\n",
      "Epoch 252: loss did not improve from 7.29303\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.0201 - bpp: 1.4757 - mse: 1.9972e-04\n",
      "Epoch 253/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2243 - bpp: 1.4905 - mse: 2.0550e-04\n",
      "Epoch 253: loss did not improve from 7.29303\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.2243 - bpp: 1.4905 - mse: 2.0550e-04\n",
      "Epoch 254/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1133 - bpp: 1.4577 - mse: 1.7260e-04\n",
      "Epoch 254: loss improved from 7.29303 to 7.11333, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 7.1133 - bpp: 1.4577 - mse: 1.7260e-04\n",
      "Epoch 255/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4846 - bpp: 1.4942 - mse: 2.4385e-04\n",
      "Epoch 255: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 9.4846 - bpp: 1.4942 - mse: 2.4385e-04\n",
      "Epoch 256/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8586 - bpp: 1.4778 - mse: 1.9473e-04\n",
      "Epoch 256: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.8586 - bpp: 1.4778 - mse: 1.9473e-04\n",
      "Epoch 257/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6531 - bpp: 1.4670 - mse: 1.8878e-04\n",
      "Epoch 257: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 7.6531 - bpp: 1.4670 - mse: 1.8878e-04\n",
      "Epoch 258/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.9515 - bpp: 1.5283 - mse: 3.4861e-04\n",
      "Epoch 258: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 12.9515 - bpp: 1.5283 - mse: 3.4861e-04\n",
      "Epoch 259/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3138 - bpp: 1.4910 - mse: 2.0821e-04\n",
      "Epoch 259: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 8.3138 - bpp: 1.4910 - mse: 2.0821e-04\n",
      "Epoch 260/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2151 - bpp: 1.4668 - mse: 1.7543e-04\n",
      "Epoch 260: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.2151 - bpp: 1.4668 - mse: 1.7543e-04\n",
      "Epoch 261/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7020 - bpp: 1.4939 - mse: 2.1997e-04\n",
      "Epoch 261: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.7020 - bpp: 1.4939 - mse: 2.1997e-04\n",
      "Epoch 262/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3719 - bpp: 1.4581 - mse: 1.8048e-04\n",
      "Epoch 262: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 7.3719 - bpp: 1.4581 - mse: 1.8048e-04\n",
      "Epoch 263/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8853 - bpp: 1.4758 - mse: 1.9560e-04\n",
      "Epoch 263: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.8853 - bpp: 1.4758 - mse: 1.9560e-04\n",
      "Epoch 264/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7890 - bpp: 1.4819 - mse: 1.9248e-04\n",
      "Epoch 264: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.7890 - bpp: 1.4819 - mse: 1.9248e-04\n",
      "Epoch 265/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1632 - bpp: 1.4892 - mse: 2.0368e-04\n",
      "Epoch 265: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 8.1632 - bpp: 1.4892 - mse: 2.0368e-04\n",
      "Epoch 266/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2080 - bpp: 1.5242 - mse: 2.0397e-04\n",
      "Epoch 266: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 8.2080 - bpp: 1.5242 - mse: 2.0397e-04\n",
      "Epoch 267/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5743 - bpp: 1.4804 - mse: 1.8597e-04\n",
      "Epoch 267: loss did not improve from 7.11333\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.5743 - bpp: 1.4804 - mse: 1.8597e-04\n",
      "Epoch 268/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8759 - bpp: 1.4346 - mse: 1.6606e-04\n",
      "Epoch 268: loss improved from 7.11333 to 6.87593, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.8759 - bpp: 1.4346 - mse: 1.6606e-04\n",
      "Epoch 269/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.5431 - bpp: 1.4918 - mse: 2.7623e-04\n",
      "Epoch 269: loss did not improve from 6.87593\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 10.5431 - bpp: 1.4918 - mse: 2.7623e-04\n",
      "Epoch 270/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9340 - bpp: 1.5105 - mse: 2.5707e-04\n",
      "Epoch 270: loss did not improve from 6.87593\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 9.9340 - bpp: 1.5105 - mse: 2.5707e-04\n",
      "Epoch 271/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8248 - bpp: 1.4987 - mse: 2.2357e-04\n",
      "Epoch 271: loss did not improve from 6.87593\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.8248 - bpp: 1.4987 - mse: 2.2357e-04\n",
      "Epoch 272/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9406 - bpp: 1.4870 - mse: 1.6643e-04\n",
      "Epoch 272: loss did not improve from 6.87593\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 6.9406 - bpp: 1.4870 - mse: 1.6643e-04\n",
      "Epoch 273/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4462 - bpp: 1.5071 - mse: 2.4228e-04\n",
      "Epoch 273: loss did not improve from 6.87593\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 9.4462 - bpp: 1.5071 - mse: 2.4228e-04\n",
      "Epoch 274/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8317 - bpp: 1.4803 - mse: 1.6331e-04\n",
      "Epoch 274: loss improved from 6.87593 to 6.83175, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.8317 - bpp: 1.4803 - mse: 1.6331e-04\n",
      "Epoch 275/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4712 - bpp: 1.4962 - mse: 2.1286e-04\n",
      "Epoch 275: loss did not improve from 6.83175\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 8.4712 - bpp: 1.4962 - mse: 2.1286e-04\n",
      "Epoch 276/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0197 - bpp: 1.4599 - mse: 1.6967e-04\n",
      "Epoch 276: loss did not improve from 6.83175\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.0197 - bpp: 1.4599 - mse: 1.6967e-04\n",
      "Epoch 277/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0507 - bpp: 1.4767 - mse: 1.7011e-04\n",
      "Epoch 277: loss did not improve from 6.83175\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.0507 - bpp: 1.4767 - mse: 1.7011e-04\n",
      "Epoch 278/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0106 - bpp: 1.5102 - mse: 2.2889e-04\n",
      "Epoch 278: loss did not improve from 6.83175\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 9.0106 - bpp: 1.5102 - mse: 2.2889e-04\n",
      "Epoch 279/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4792 - bpp: 1.4437 - mse: 1.5367e-04\n",
      "Epoch 279: loss improved from 6.83175 to 6.47916, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.4792 - bpp: 1.4437 - mse: 1.5367e-04\n",
      "Epoch 280/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5111 - bpp: 1.4858 - mse: 1.8388e-04\n",
      "Epoch 280: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.5111 - bpp: 1.4858 - mse: 1.8388e-04\n",
      "Epoch 281/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6053 - bpp: 1.4906 - mse: 1.8661e-04\n",
      "Epoch 281: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 7.6053 - bpp: 1.4906 - mse: 1.8661e-04\n",
      "Epoch 282/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3604 - bpp: 1.5175 - mse: 2.0883e-04\n",
      "Epoch 282: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.3604 - bpp: 1.5175 - mse: 2.0883e-04\n",
      "Epoch 283/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4920 - bpp: 1.4840 - mse: 1.8335e-04\n",
      "Epoch 283: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.4920 - bpp: 1.4840 - mse: 1.8335e-04\n",
      "Epoch 284/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9893 - bpp: 1.4872 - mse: 1.9843e-04\n",
      "Epoch 284: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.9893 - bpp: 1.4872 - mse: 1.9843e-04\n",
      "Epoch 285/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5305 - bpp: 1.4888 - mse: 1.8438e-04\n",
      "Epoch 285: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.5305 - bpp: 1.4888 - mse: 1.8438e-04\n",
      "Epoch 286/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8047 - bpp: 1.4959 - mse: 1.9253e-04\n",
      "Epoch 286: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.8047 - bpp: 1.4959 - mse: 1.9253e-04\n",
      "Epoch 287/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4178 - bpp: 1.5356 - mse: 2.4055e-04\n",
      "Epoch 287: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.4178 - bpp: 1.5356 - mse: 2.4055e-04\n",
      "Epoch 288/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8405 - bpp: 1.5072 - mse: 2.2379e-04\n",
      "Epoch 288: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 8.8405 - bpp: 1.5072 - mse: 2.2379e-04\n",
      "Epoch 289/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0556 - bpp: 1.5101 - mse: 1.9975e-04\n",
      "Epoch 289: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 8.0556 - bpp: 1.5101 - mse: 1.9975e-04\n",
      "Epoch 290/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9935 - bpp: 1.4937 - mse: 1.9836e-04\n",
      "Epoch 290: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.9935 - bpp: 1.4937 - mse: 1.9836e-04\n",
      "Epoch 291/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5547 - bpp: 1.4922 - mse: 1.8501e-04\n",
      "Epoch 291: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 7.5547 - bpp: 1.4922 - mse: 1.8501e-04\n",
      "Epoch 292/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0590 - bpp: 1.5238 - mse: 2.2995e-04\n",
      "Epoch 292: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 9.0590 - bpp: 1.5238 - mse: 2.2995e-04\n",
      "Epoch 293/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8574 - bpp: 1.4956 - mse: 1.6363e-04\n",
      "Epoch 293: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.8574 - bpp: 1.4956 - mse: 1.6363e-04\n",
      "Epoch 294/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8935 - bpp: 1.4890 - mse: 1.9545e-04\n",
      "Epoch 294: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.8935 - bpp: 1.4890 - mse: 1.9545e-04\n",
      "Epoch 295/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9191 - bpp: 1.4948 - mse: 2.2657e-04\n",
      "Epoch 295: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.9191 - bpp: 1.4948 - mse: 2.2657e-04\n",
      "Epoch 296/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3871 - bpp: 1.4837 - mse: 1.8016e-04\n",
      "Epoch 296: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.3871 - bpp: 1.4837 - mse: 1.8016e-04\n",
      "Epoch 297/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4204 - bpp: 1.4767 - mse: 1.8139e-04\n",
      "Epoch 297: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.4204 - bpp: 1.4767 - mse: 1.8139e-04\n",
      "Epoch 298/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4450 - bpp: 1.5125 - mse: 1.8105e-04\n",
      "Epoch 298: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.4450 - bpp: 1.5125 - mse: 1.8105e-04\n",
      "Epoch 299/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7408 - bpp: 1.4602 - mse: 1.6115e-04\n",
      "Epoch 299: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 6.7408 - bpp: 1.4602 - mse: 1.6115e-04\n",
      "Epoch 300/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7234 - bpp: 1.5084 - mse: 1.8967e-04\n",
      "Epoch 300: loss did not improve from 6.47916\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.7234 - bpp: 1.5084 - mse: 1.8967e-04\n",
      "Epoch 301/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4233 - bpp: 1.4724 - mse: 1.5109e-04\n",
      "Epoch 301: loss improved from 6.47916 to 6.42330, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 6.4233 - bpp: 1.4724 - mse: 1.5109e-04\n",
      "Epoch 302/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1678 - bpp: 1.5010 - mse: 1.7294e-04\n",
      "Epoch 302: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.1678 - bpp: 1.5010 - mse: 1.7294e-04\n",
      "Epoch 303/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8126 - bpp: 1.5185 - mse: 1.9208e-04\n",
      "Epoch 303: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.8126 - bpp: 1.5185 - mse: 1.9208e-04\n",
      "Epoch 304/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1743 - bpp: 1.5235 - mse: 1.7245e-04\n",
      "Epoch 304: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.1743 - bpp: 1.5235 - mse: 1.7245e-04\n",
      "Epoch 305/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6692 - bpp: 1.5071 - mse: 1.8805e-04\n",
      "Epoch 305: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.6692 - bpp: 1.5071 - mse: 1.8805e-04\n",
      "Epoch 306/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2508 - bpp: 1.4911 - mse: 1.7577e-04\n",
      "Epoch 306: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.2508 - bpp: 1.4911 - mse: 1.7577e-04\n",
      "Epoch 307/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2795 - bpp: 1.5104 - mse: 1.7606e-04\n",
      "Epoch 307: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.2795 - bpp: 1.5104 - mse: 1.7606e-04\n",
      "Epoch 308/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1145 - bpp: 1.5126 - mse: 1.7096e-04\n",
      "Epoch 308: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.1145 - bpp: 1.5126 - mse: 1.7096e-04\n",
      "Epoch 309/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6672 - bpp: 1.5664 - mse: 2.1670e-04\n",
      "Epoch 309: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.6672 - bpp: 1.5664 - mse: 2.1670e-04\n",
      "Epoch 310/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2317 - bpp: 1.5017 - mse: 2.3590e-04\n",
      "Epoch 310: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 9.2317 - bpp: 1.5017 - mse: 2.3590e-04\n",
      "Epoch 311/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1547 - bpp: 1.5153 - mse: 2.0262e-04\n",
      "Epoch 311: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.1547 - bpp: 1.5153 - mse: 2.0262e-04\n",
      "Epoch 312/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4333 - bpp: 1.4730 - mse: 1.5137e-04\n",
      "Epoch 312: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.4333 - bpp: 1.4730 - mse: 1.5137e-04\n",
      "Epoch 313/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9776 - bpp: 1.4963 - mse: 1.6728e-04\n",
      "Epoch 313: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.9776 - bpp: 1.4963 - mse: 1.6728e-04\n",
      "Epoch 314/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9743 - bpp: 1.5113 - mse: 1.6672e-04\n",
      "Epoch 314: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.9743 - bpp: 1.5113 - mse: 1.6672e-04\n",
      "Epoch 315/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3671 - bpp: 1.4913 - mse: 1.7932e-04\n",
      "Epoch 315: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.3671 - bpp: 1.4913 - mse: 1.7932e-04\n",
      "Epoch 316/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9054 - bpp: 1.4905 - mse: 1.6525e-04\n",
      "Epoch 316: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.9054 - bpp: 1.4905 - mse: 1.6525e-04\n",
      "Epoch 317/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2512 - bpp: 1.4979 - mse: 1.7558e-04\n",
      "Epoch 317: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.2512 - bpp: 1.4979 - mse: 1.7558e-04\n",
      "Epoch 318/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9916 - bpp: 1.5446 - mse: 1.9675e-04\n",
      "Epoch 318: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.9916 - bpp: 1.5446 - mse: 1.9675e-04\n",
      "Epoch 319/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8436 - bpp: 1.5315 - mse: 1.9263e-04\n",
      "Epoch 319: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.8436 - bpp: 1.5315 - mse: 1.9263e-04\n",
      "Epoch 320/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5433 - bpp: 1.4784 - mse: 1.5457e-04\n",
      "Epoch 320: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.5433 - bpp: 1.4784 - mse: 1.5457e-04\n",
      "Epoch 321/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6179 - bpp: 1.5164 - mse: 1.5569e-04\n",
      "Epoch 321: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 6.6179 - bpp: 1.5164 - mse: 1.5569e-04\n",
      "Epoch 322/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4116 - bpp: 1.5474 - mse: 2.0948e-04\n",
      "Epoch 322: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 8.4116 - bpp: 1.5474 - mse: 2.0948e-04\n",
      "Epoch 323/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0218 - bpp: 1.5231 - mse: 1.9832e-04\n",
      "Epoch 323: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 8.0218 - bpp: 1.5231 - mse: 1.9832e-04\n",
      "Epoch 324/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9260 - bpp: 1.4923 - mse: 1.6582e-04\n",
      "Epoch 324: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.9260 - bpp: 1.4923 - mse: 1.6582e-04\n",
      "Epoch 325/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9685 - bpp: 1.5098 - mse: 1.6659e-04\n",
      "Epoch 325: loss did not improve from 6.42330\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.9685 - bpp: 1.5098 - mse: 1.6659e-04\n",
      "Epoch 326/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2614 - bpp: 1.4789 - mse: 1.4595e-04\n",
      "Epoch 326: loss improved from 6.42330 to 6.26144, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.2614 - bpp: 1.4789 - mse: 1.4595e-04\n",
      "Epoch 327/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3757 - bpp: 1.5082 - mse: 1.7906e-04\n",
      "Epoch 327: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 7.3757 - bpp: 1.5082 - mse: 1.7906e-04\n",
      "Epoch 328/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5495 - bpp: 1.5391 - mse: 1.8342e-04\n",
      "Epoch 328: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.5495 - bpp: 1.5391 - mse: 1.8342e-04\n",
      "Epoch 329/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7674 - bpp: 1.4990 - mse: 1.6078e-04\n",
      "Epoch 329: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.7674 - bpp: 1.4990 - mse: 1.6078e-04\n",
      "Epoch 330/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9715 - bpp: 1.5249 - mse: 1.6622e-04\n",
      "Epoch 330: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.9715 - bpp: 1.5249 - mse: 1.6622e-04\n",
      "Epoch 331/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8215 - bpp: 1.4858 - mse: 1.6283e-04\n",
      "Epoch 331: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.8215 - bpp: 1.4858 - mse: 1.6283e-04\n",
      "Epoch 332/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0406 - bpp: 1.4898 - mse: 1.6940e-04\n",
      "Epoch 332: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.0406 - bpp: 1.4898 - mse: 1.6940e-04\n",
      "Epoch 333/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5555 - bpp: 1.4969 - mse: 1.5438e-04\n",
      "Epoch 333: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 6.5555 - bpp: 1.4969 - mse: 1.5438e-04\n",
      "Epoch 334/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2286 - bpp: 1.5324 - mse: 1.7383e-04\n",
      "Epoch 334: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.2286 - bpp: 1.5324 - mse: 1.7383e-04\n",
      "Epoch 335/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4207 - bpp: 1.5362 - mse: 1.7958e-04\n",
      "Epoch 335: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.4207 - bpp: 1.5362 - mse: 1.7958e-04\n",
      "Epoch 336/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2377 - bpp: 1.5258 - mse: 1.7431e-04\n",
      "Epoch 336: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.2377 - bpp: 1.5258 - mse: 1.7431e-04\n",
      "Epoch 337/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3812 - bpp: 1.5019 - mse: 1.7942e-04\n",
      "Epoch 337: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.3812 - bpp: 1.5019 - mse: 1.7942e-04\n",
      "Epoch 338/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0916 - bpp: 1.4882 - mse: 1.7100e-04\n",
      "Epoch 338: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.0916 - bpp: 1.4882 - mse: 1.7100e-04\n",
      "Epoch 339/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7603 - bpp: 1.5514 - mse: 1.8948e-04\n",
      "Epoch 339: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.7603 - bpp: 1.5514 - mse: 1.8948e-04\n",
      "Epoch 340/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0098 - bpp: 1.5262 - mse: 1.9786e-04\n",
      "Epoch 340: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 8.0098 - bpp: 1.5262 - mse: 1.9786e-04\n",
      "Epoch 341/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7001 - bpp: 1.5017 - mse: 1.5864e-04\n",
      "Epoch 341: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.7001 - bpp: 1.5017 - mse: 1.5864e-04\n",
      "Epoch 342/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7278 - bpp: 1.5187 - mse: 1.5897e-04\n",
      "Epoch 342: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 6.7278 - bpp: 1.5187 - mse: 1.5897e-04\n",
      "Epoch 343/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3411 - bpp: 1.5270 - mse: 1.7743e-04\n",
      "Epoch 343: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.3411 - bpp: 1.5270 - mse: 1.7743e-04\n",
      "Epoch 344/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7433 - bpp: 1.5275 - mse: 1.8969e-04\n",
      "Epoch 344: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.7433 - bpp: 1.5275 - mse: 1.8969e-04\n",
      "Epoch 345/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5609 - bpp: 1.5567 - mse: 1.8323e-04\n",
      "Epoch 345: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.5609 - bpp: 1.5567 - mse: 1.8323e-04\n",
      "Epoch 346/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3598 - bpp: 1.4927 - mse: 1.4853e-04\n",
      "Epoch 346: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.3598 - bpp: 1.4927 - mse: 1.4853e-04\n",
      "Epoch 347/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8038 - bpp: 1.5285 - mse: 1.9151e-04\n",
      "Epoch 347: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 7.8038 - bpp: 1.5285 - mse: 1.9151e-04\n",
      "Epoch 348/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8076 - bpp: 1.5097 - mse: 1.6168e-04\n",
      "Epoch 348: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.8076 - bpp: 1.5097 - mse: 1.6168e-04\n",
      "Epoch 349/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8764 - bpp: 1.5296 - mse: 1.6317e-04\n",
      "Epoch 349: loss did not improve from 6.26144\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.8764 - bpp: 1.5296 - mse: 1.6317e-04\n",
      "Epoch 350/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0852 - bpp: 1.4987 - mse: 1.3997e-04\n",
      "Epoch 350: loss improved from 6.26144 to 6.08516, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 6.0852 - bpp: 1.4987 - mse: 1.3997e-04\n",
      "Epoch 351/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5648 - bpp: 1.5119 - mse: 1.5420e-04\n",
      "Epoch 351: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.5648 - bpp: 1.5119 - mse: 1.5420e-04\n",
      "Epoch 352/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6820 - bpp: 1.5404 - mse: 1.8743e-04\n",
      "Epoch 352: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.6820 - bpp: 1.5404 - mse: 1.8743e-04\n",
      "Epoch 353/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8730 - bpp: 1.5027 - mse: 1.6389e-04\n",
      "Epoch 353: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.8730 - bpp: 1.5027 - mse: 1.6389e-04\n",
      "Epoch 354/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0680 - bpp: 1.5241 - mse: 1.6919e-04\n",
      "Epoch 354: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 7.0680 - bpp: 1.5241 - mse: 1.6919e-04\n",
      "Epoch 355/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7176 - bpp: 1.5288 - mse: 1.5835e-04\n",
      "Epoch 355: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.7176 - bpp: 1.5288 - mse: 1.5835e-04\n",
      "Epoch 356/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6283 - bpp: 1.5318 - mse: 1.5553e-04\n",
      "Epoch 356: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.6283 - bpp: 1.5318 - mse: 1.5553e-04\n",
      "Epoch 357/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2004 - bpp: 1.5101 - mse: 1.4314e-04\n",
      "Epoch 357: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.2004 - bpp: 1.5101 - mse: 1.4314e-04\n",
      "Epoch 358/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8128 - bpp: 1.5016 - mse: 1.6208e-04\n",
      "Epoch 358: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.8128 - bpp: 1.5016 - mse: 1.6208e-04\n",
      "Epoch 359/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0906 - bpp: 1.5271 - mse: 1.6978e-04\n",
      "Epoch 359: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.0906 - bpp: 1.5271 - mse: 1.6978e-04\n",
      "Epoch 360/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5522 - bpp: 1.5028 - mse: 1.5409e-04\n",
      "Epoch 360: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 6.5522 - bpp: 1.5028 - mse: 1.5409e-04\n",
      "Epoch 361/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7314 - bpp: 1.5381 - mse: 1.5849e-04\n",
      "Epoch 361: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.7314 - bpp: 1.5381 - mse: 1.5849e-04\n",
      "Epoch 362/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6151 - bpp: 1.5458 - mse: 1.5470e-04\n",
      "Epoch 362: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.6151 - bpp: 1.5458 - mse: 1.5470e-04\n",
      "Epoch 363/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7859 - bpp: 1.5218 - mse: 1.6065e-04\n",
      "Epoch 363: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.7859 - bpp: 1.5218 - mse: 1.6065e-04\n",
      "Epoch 364/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3888 - bpp: 1.5102 - mse: 1.4888e-04\n",
      "Epoch 364: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.3888 - bpp: 1.5102 - mse: 1.4888e-04\n",
      "Epoch 365/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7208 - bpp: 1.5314 - mse: 1.5837e-04\n",
      "Epoch 365: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.7208 - bpp: 1.5314 - mse: 1.5837e-04\n",
      "Epoch 366/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6027 - bpp: 1.5358 - mse: 1.5463e-04\n",
      "Epoch 366: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.6027 - bpp: 1.5358 - mse: 1.5463e-04\n",
      "Epoch 367/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2496 - bpp: 1.5463 - mse: 1.7405e-04\n",
      "Epoch 367: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.2496 - bpp: 1.5463 - mse: 1.7405e-04\n",
      "Epoch 368/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7643 - bpp: 1.5108 - mse: 1.6033e-04\n",
      "Epoch 368: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.7643 - bpp: 1.5108 - mse: 1.6033e-04\n",
      "Epoch 369/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5784 - bpp: 1.4919 - mse: 1.5523e-04\n",
      "Epoch 369: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.5784 - bpp: 1.4919 - mse: 1.5523e-04\n",
      "Epoch 370/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9749 - bpp: 1.5570 - mse: 1.6534e-04\n",
      "Epoch 370: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.9749 - bpp: 1.5570 - mse: 1.6534e-04\n",
      "Epoch 371/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5123 - bpp: 1.5401 - mse: 1.5174e-04\n",
      "Epoch 371: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.5123 - bpp: 1.5401 - mse: 1.5174e-04\n",
      "Epoch 372/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1386 - bpp: 1.5138 - mse: 1.4114e-04\n",
      "Epoch 372: loss did not improve from 6.08516\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1386 - bpp: 1.5138 - mse: 1.4114e-04\n",
      "Epoch 373/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6755 - bpp: 1.5095 - mse: 1.2714e-04\n",
      "Epoch 373: loss improved from 6.08516 to 5.67547, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 5.6755 - bpp: 1.5095 - mse: 1.2714e-04\n",
      "Epoch 374/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0344 - bpp: 1.5288 - mse: 1.6802e-04\n",
      "Epoch 374: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.0344 - bpp: 1.5288 - mse: 1.6802e-04\n",
      "Epoch 375/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4232 - bpp: 1.5185 - mse: 1.4968e-04\n",
      "Epoch 375: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.4232 - bpp: 1.5185 - mse: 1.4968e-04\n",
      "Epoch 376/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3563 - bpp: 1.5213 - mse: 1.4755e-04\n",
      "Epoch 376: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.3563 - bpp: 1.5213 - mse: 1.4755e-04\n",
      "Epoch 377/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2453 - bpp: 1.5495 - mse: 2.0434e-04\n",
      "Epoch 377: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 8.2453 - bpp: 1.5495 - mse: 2.0434e-04\n",
      "Epoch 378/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0354 - bpp: 1.5488 - mse: 1.6744e-04\n",
      "Epoch 378: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.0354 - bpp: 1.5488 - mse: 1.6744e-04\n",
      "Epoch 379/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3508 - bpp: 1.5113 - mse: 1.4769e-04\n",
      "Epoch 379: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.3508 - bpp: 1.5113 - mse: 1.4769e-04\n",
      "Epoch 380/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2409 - bpp: 1.5290 - mse: 2.0483e-04\n",
      "Epoch 380: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 8.2409 - bpp: 1.5290 - mse: 2.0483e-04\n",
      "Epoch 381/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0432 - bpp: 1.5424 - mse: 1.6787e-04\n",
      "Epoch 381: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 7.0432 - bpp: 1.5424 - mse: 1.6787e-04\n",
      "Epoch 382/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9225 - bpp: 1.5033 - mse: 1.3486e-04\n",
      "Epoch 382: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.9225 - bpp: 1.5033 - mse: 1.3486e-04\n",
      "Epoch 383/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7338 - bpp: 1.5200 - mse: 1.5911e-04\n",
      "Epoch 383: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.7338 - bpp: 1.5200 - mse: 1.5911e-04\n",
      "Epoch 384/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9152 - bpp: 1.5683 - mse: 1.6317e-04\n",
      "Epoch 384: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.9152 - bpp: 1.5683 - mse: 1.6317e-04\n",
      "Epoch 385/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1182 - bpp: 1.5256 - mse: 1.4015e-04\n",
      "Epoch 385: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1182 - bpp: 1.5256 - mse: 1.4015e-04\n",
      "Epoch 386/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0082 - bpp: 1.5093 - mse: 1.3730e-04\n",
      "Epoch 386: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.0082 - bpp: 1.5093 - mse: 1.3730e-04\n",
      "Epoch 387/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1665 - bpp: 1.5173 - mse: 1.4188e-04\n",
      "Epoch 387: loss did not improve from 5.67547\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1665 - bpp: 1.5173 - mse: 1.4188e-04\n",
      "Epoch 388/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4091 - bpp: 1.4983 - mse: 1.1935e-04\n",
      "Epoch 388: loss improved from 5.67547 to 5.40913, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 5.4091 - bpp: 1.4983 - mse: 1.1935e-04\n",
      "Epoch 389/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1766 - bpp: 1.5306 - mse: 1.4178e-04\n",
      "Epoch 389: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1766 - bpp: 1.5306 - mse: 1.4178e-04\n",
      "Epoch 390/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4859 - bpp: 1.5108 - mse: 1.5183e-04\n",
      "Epoch 390: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.4859 - bpp: 1.5108 - mse: 1.5183e-04\n",
      "Epoch 391/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9937 - bpp: 1.5486 - mse: 1.6617e-04\n",
      "Epoch 391: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.9937 - bpp: 1.5486 - mse: 1.6617e-04\n",
      "Epoch 392/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2711 - bpp: 1.5070 - mse: 1.4539e-04\n",
      "Epoch 392: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.2711 - bpp: 1.5070 - mse: 1.4539e-04\n",
      "Epoch 393/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6499 - bpp: 1.5437 - mse: 1.5583e-04\n",
      "Epoch 393: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 26s 126ms/step - loss: 6.6499 - bpp: 1.5437 - mse: 1.5583e-04\n",
      "Epoch 394/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6434 - bpp: 1.5232 - mse: 1.5626e-04\n",
      "Epoch 394: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.6434 - bpp: 1.5232 - mse: 1.5626e-04\n",
      "Epoch 395/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3791 - bpp: 1.5527 - mse: 1.7781e-04\n",
      "Epoch 395: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.3791 - bpp: 1.5527 - mse: 1.7781e-04\n",
      "Epoch 396/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9206 - bpp: 1.4946 - mse: 1.3507e-04\n",
      "Epoch 396: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.9206 - bpp: 1.4946 - mse: 1.3507e-04\n",
      "Epoch 397/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9575 - bpp: 1.5134 - mse: 1.3562e-04\n",
      "Epoch 397: loss did not improve from 5.40913\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.9575 - bpp: 1.5134 - mse: 1.3562e-04\n",
      "Epoch 398/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3502 - bpp: 1.4982 - mse: 1.1755e-04\n",
      "Epoch 398: loss improved from 5.40913 to 5.35017, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 5.3502 - bpp: 1.4982 - mse: 1.1755e-04\n",
      "Epoch 399/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2743 - bpp: 1.5673 - mse: 1.7416e-04\n",
      "Epoch 399: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 7.2743 - bpp: 1.5673 - mse: 1.7416e-04\n",
      "Epoch 400/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7777 - bpp: 1.5148 - mse: 1.6061e-04\n",
      "Epoch 400: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.7777 - bpp: 1.5148 - mse: 1.6061e-04\n",
      "Epoch 401/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4986 - bpp: 1.5541 - mse: 1.8141e-04\n",
      "Epoch 401: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 7.4986 - bpp: 1.5541 - mse: 1.8141e-04\n",
      "Epoch 402/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3270 - bpp: 1.5359 - mse: 1.4621e-04\n",
      "Epoch 402: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3270 - bpp: 1.5359 - mse: 1.4621e-04\n",
      "Epoch 403/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0155 - bpp: 1.5585 - mse: 1.6654e-04\n",
      "Epoch 403: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 7.0155 - bpp: 1.5585 - mse: 1.6654e-04\n",
      "Epoch 404/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6469 - bpp: 1.5375 - mse: 1.5592e-04\n",
      "Epoch 404: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.6469 - bpp: 1.5375 - mse: 1.5592e-04\n",
      "Epoch 405/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9562 - bpp: 1.5263 - mse: 1.3519e-04\n",
      "Epoch 405: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.9562 - bpp: 1.5263 - mse: 1.3519e-04\n",
      "Epoch 406/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3273 - bpp: 1.5372 - mse: 1.4618e-04\n",
      "Epoch 406: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.3273 - bpp: 1.5372 - mse: 1.4618e-04\n",
      "Epoch 407/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5576 - bpp: 1.5307 - mse: 1.5341e-04\n",
      "Epoch 407: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.5576 - bpp: 1.5307 - mse: 1.5341e-04\n",
      "Epoch 408/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7736 - bpp: 1.5074 - mse: 1.3019e-04\n",
      "Epoch 408: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.7736 - bpp: 1.5074 - mse: 1.3019e-04\n",
      "Epoch 409/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5028 - bpp: 1.4950 - mse: 1.2231e-04\n",
      "Epoch 409: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.5028 - bpp: 1.4950 - mse: 1.2231e-04\n",
      "Epoch 410/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0091 - bpp: 1.5768 - mse: 1.6578e-04\n",
      "Epoch 410: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.0091 - bpp: 1.5768 - mse: 1.6578e-04\n",
      "Epoch 411/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4089 - bpp: 1.5233 - mse: 1.4910e-04\n",
      "Epoch 411: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.4089 - bpp: 1.5233 - mse: 1.4910e-04\n",
      "Epoch 412/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5737 - bpp: 1.5361 - mse: 1.5374e-04\n",
      "Epoch 412: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.5737 - bpp: 1.5361 - mse: 1.5374e-04\n",
      "Epoch 413/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5796 - bpp: 1.5404 - mse: 1.5379e-04\n",
      "Epoch 413: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.5796 - bpp: 1.5404 - mse: 1.5379e-04\n",
      "Epoch 414/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9425 - bpp: 1.5349 - mse: 1.3451e-04\n",
      "Epoch 414: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.9425 - bpp: 1.5349 - mse: 1.3451e-04\n",
      "Epoch 415/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8494 - bpp: 1.5418 - mse: 1.6198e-04\n",
      "Epoch 415: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.8494 - bpp: 1.5418 - mse: 1.6198e-04\n",
      "Epoch 416/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5131 - bpp: 1.5504 - mse: 1.5145e-04\n",
      "Epoch 416: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.5131 - bpp: 1.5504 - mse: 1.5145e-04\n",
      "Epoch 417/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6944 - bpp: 1.5412 - mse: 1.5726e-04\n",
      "Epoch 417: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 6.6944 - bpp: 1.5412 - mse: 1.5726e-04\n",
      "Epoch 418/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9789 - bpp: 1.5451 - mse: 1.6583e-04\n",
      "Epoch 418: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.9789 - bpp: 1.5451 - mse: 1.6583e-04\n",
      "Epoch 419/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7677 - bpp: 1.5201 - mse: 1.2963e-04\n",
      "Epoch 419: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.7677 - bpp: 1.5201 - mse: 1.2963e-04\n",
      "Epoch 420/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9590 - bpp: 1.5547 - mse: 1.6493e-04\n",
      "Epoch 420: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.9590 - bpp: 1.5547 - mse: 1.6493e-04\n",
      "Epoch 421/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0387 - bpp: 1.5429 - mse: 1.6772e-04\n",
      "Epoch 421: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.0387 - bpp: 1.5429 - mse: 1.6772e-04\n",
      "Epoch 422/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0776 - bpp: 1.5461 - mse: 1.3829e-04\n",
      "Epoch 422: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0776 - bpp: 1.5461 - mse: 1.3829e-04\n",
      "Epoch 423/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8746 - bpp: 1.5456 - mse: 1.3211e-04\n",
      "Epoch 423: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.8746 - bpp: 1.5456 - mse: 1.3211e-04\n",
      "Epoch 424/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8227 - bpp: 1.5376 - mse: 1.6129e-04\n",
      "Epoch 424: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.8227 - bpp: 1.5376 - mse: 1.6129e-04\n",
      "Epoch 425/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2557 - bpp: 1.5185 - mse: 1.4457e-04\n",
      "Epoch 425: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 6.2557 - bpp: 1.5185 - mse: 1.4457e-04\n",
      "Epoch 426/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7048 - bpp: 1.5496 - mse: 1.5732e-04\n",
      "Epoch 426: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.7048 - bpp: 1.5496 - mse: 1.5732e-04\n",
      "Epoch 427/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5649 - bpp: 1.5474 - mse: 1.5312e-04\n",
      "Epoch 427: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.5649 - bpp: 1.5474 - mse: 1.5312e-04\n",
      "Epoch 428/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6241 - bpp: 1.5288 - mse: 1.5550e-04\n",
      "Epoch 428: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.6241 - bpp: 1.5288 - mse: 1.5550e-04\n",
      "Epoch 429/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5960 - bpp: 1.4834 - mse: 1.2551e-04\n",
      "Epoch 429: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5960 - bpp: 1.4834 - mse: 1.2551e-04\n",
      "Epoch 430/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5818 - bpp: 1.5365 - mse: 1.5397e-04\n",
      "Epoch 430: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.5818 - bpp: 1.5365 - mse: 1.5397e-04\n",
      "Epoch 431/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6706 - bpp: 1.5792 - mse: 1.5538e-04\n",
      "Epoch 431: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.6706 - bpp: 1.5792 - mse: 1.5538e-04\n",
      "Epoch 432/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3447 - bpp: 1.5598 - mse: 1.4602e-04\n",
      "Epoch 432: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.3447 - bpp: 1.5598 - mse: 1.4602e-04\n",
      "Epoch 433/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5854 - bpp: 1.5382 - mse: 1.2351e-04\n",
      "Epoch 433: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5854 - bpp: 1.5382 - mse: 1.2351e-04\n",
      "Epoch 434/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7297 - bpp: 1.5199 - mse: 1.2847e-04\n",
      "Epoch 434: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 5.7297 - bpp: 1.5199 - mse: 1.2847e-04\n",
      "Epoch 435/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1515 - bpp: 1.5421 - mse: 1.4067e-04\n",
      "Epoch 435: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1515 - bpp: 1.5421 - mse: 1.4067e-04\n",
      "Epoch 436/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3666 - bpp: 1.5385 - mse: 1.4734e-04\n",
      "Epoch 436: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 115ms/step - loss: 6.3666 - bpp: 1.5385 - mse: 1.4734e-04\n",
      "Epoch 437/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8498 - bpp: 1.5293 - mse: 1.3185e-04\n",
      "Epoch 437: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.8498 - bpp: 1.5293 - mse: 1.3185e-04\n",
      "Epoch 438/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1420 - bpp: 1.5406 - mse: 1.4042e-04\n",
      "Epoch 438: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.1420 - bpp: 1.5406 - mse: 1.4042e-04\n",
      "Epoch 439/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1516 - bpp: 1.5836 - mse: 1.6992e-04\n",
      "Epoch 439: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 7.1516 - bpp: 1.5836 - mse: 1.6992e-04\n",
      "Epoch 440/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3243 - bpp: 1.5384 - mse: 1.4605e-04\n",
      "Epoch 440: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.3243 - bpp: 1.5384 - mse: 1.4605e-04\n",
      "Epoch 441/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1831 - bpp: 1.5470 - mse: 1.4148e-04\n",
      "Epoch 441: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 6.1831 - bpp: 1.5470 - mse: 1.4148e-04\n",
      "Epoch 442/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7975 - bpp: 1.5483 - mse: 1.6019e-04\n",
      "Epoch 442: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.7975 - bpp: 1.5483 - mse: 1.6019e-04\n",
      "Epoch 443/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8446 - bpp: 1.5252 - mse: 1.3182e-04\n",
      "Epoch 443: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.8446 - bpp: 1.5252 - mse: 1.3182e-04\n",
      "Epoch 444/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5502 - bpp: 1.5399 - mse: 1.5290e-04\n",
      "Epoch 444: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.5502 - bpp: 1.5399 - mse: 1.5290e-04\n",
      "Epoch 445/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1972 - bpp: 1.5501 - mse: 1.4182e-04\n",
      "Epoch 445: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1972 - bpp: 1.5501 - mse: 1.4182e-04\n",
      "Epoch 446/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6784 - bpp: 1.5272 - mse: 1.2668e-04\n",
      "Epoch 446: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 5.6784 - bpp: 1.5272 - mse: 1.2668e-04\n",
      "Epoch 447/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8550 - bpp: 1.5578 - mse: 1.3114e-04\n",
      "Epoch 447: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.8550 - bpp: 1.5578 - mse: 1.3114e-04\n",
      "Epoch 448/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0757 - bpp: 1.5805 - mse: 1.9822e-04\n",
      "Epoch 448: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 8.0757 - bpp: 1.5805 - mse: 1.9822e-04\n",
      "Epoch 449/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0659 - bpp: 1.5402 - mse: 1.3811e-04\n",
      "Epoch 449: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.0659 - bpp: 1.5402 - mse: 1.3811e-04\n",
      "Epoch 450/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9820 - bpp: 1.5398 - mse: 1.3556e-04\n",
      "Epoch 450: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.9820 - bpp: 1.5398 - mse: 1.3556e-04\n",
      "Epoch 451/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4481 - bpp: 1.5627 - mse: 1.4909e-04\n",
      "Epoch 451: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.4481 - bpp: 1.5627 - mse: 1.4909e-04\n",
      "Epoch 452/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8121 - bpp: 1.5831 - mse: 1.5958e-04\n",
      "Epoch 452: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.8121 - bpp: 1.5831 - mse: 1.5958e-04\n",
      "Epoch 453/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7032 - bpp: 1.5652 - mse: 1.5680e-04\n",
      "Epoch 453: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 6.7032 - bpp: 1.5652 - mse: 1.5680e-04\n",
      "Epoch 454/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2144 - bpp: 1.5635 - mse: 1.4193e-04\n",
      "Epoch 454: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.2144 - bpp: 1.5635 - mse: 1.4193e-04\n",
      "Epoch 455/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0777 - bpp: 1.5113 - mse: 1.3936e-04\n",
      "Epoch 455: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.0777 - bpp: 1.5113 - mse: 1.3936e-04\n",
      "Epoch 456/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5264 - bpp: 1.5734 - mse: 1.5116e-04\n",
      "Epoch 456: loss did not improve from 5.35017\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.5264 - bpp: 1.5734 - mse: 1.5116e-04\n",
      "Epoch 457/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2763 - bpp: 1.5200 - mse: 1.1463e-04\n",
      "Epoch 457: loss improved from 5.35017 to 5.27632, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.2763 - bpp: 1.5200 - mse: 1.1463e-04\n",
      "Epoch 458/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2225 - bpp: 1.5476 - mse: 1.4267e-04\n",
      "Epoch 458: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.2225 - bpp: 1.5476 - mse: 1.4267e-04\n",
      "Epoch 459/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2865 - bpp: 1.5156 - mse: 1.1508e-04\n",
      "Epoch 459: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.2865 - bpp: 1.5156 - mse: 1.1508e-04\n",
      "Epoch 460/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5063 - bpp: 1.5828 - mse: 1.5025e-04\n",
      "Epoch 460: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.5063 - bpp: 1.5828 - mse: 1.5025e-04\n",
      "Epoch 461/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7237 - bpp: 1.5341 - mse: 1.2786e-04\n",
      "Epoch 461: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.7237 - bpp: 1.5341 - mse: 1.2786e-04\n",
      "Epoch 462/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3947 - bpp: 1.5335 - mse: 1.1784e-04\n",
      "Epoch 462: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.3947 - bpp: 1.5335 - mse: 1.1784e-04\n",
      "Epoch 463/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7239 - bpp: 1.5368 - mse: 1.2778e-04\n",
      "Epoch 463: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.7239 - bpp: 1.5368 - mse: 1.2778e-04\n",
      "Epoch 464/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0439 - bpp: 1.5532 - mse: 1.3704e-04\n",
      "Epoch 464: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.0439 - bpp: 1.5532 - mse: 1.3704e-04\n",
      "Epoch 465/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9304 - bpp: 1.5612 - mse: 1.6386e-04\n",
      "Epoch 465: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.9304 - bpp: 1.5612 - mse: 1.6386e-04\n",
      "Epoch 466/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1284 - bpp: 1.5529 - mse: 1.3964e-04\n",
      "Epoch 466: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1284 - bpp: 1.5529 - mse: 1.3964e-04\n",
      "Epoch 467/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7622 - bpp: 1.5633 - mse: 1.2814e-04\n",
      "Epoch 467: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 5.7622 - bpp: 1.5633 - mse: 1.2814e-04\n",
      "Epoch 468/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9728 - bpp: 1.5456 - mse: 1.3511e-04\n",
      "Epoch 468: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.9728 - bpp: 1.5456 - mse: 1.3511e-04\n",
      "Epoch 469/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7322 - bpp: 1.5438 - mse: 1.5834e-04\n",
      "Epoch 469: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.7322 - bpp: 1.5438 - mse: 1.5834e-04\n",
      "Epoch 470/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3523 - bpp: 1.5671 - mse: 1.4603e-04\n",
      "Epoch 470: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.3523 - bpp: 1.5671 - mse: 1.4603e-04\n",
      "Epoch 471/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8836 - bpp: 1.5325 - mse: 1.3279e-04\n",
      "Epoch 471: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.8836 - bpp: 1.5325 - mse: 1.3279e-04\n",
      "Epoch 472/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2478 - bpp: 1.5343 - mse: 1.4385e-04\n",
      "Epoch 472: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 6.2478 - bpp: 1.5343 - mse: 1.4385e-04\n",
      "Epoch 473/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7947 - bpp: 1.5449 - mse: 1.2969e-04\n",
      "Epoch 473: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.7947 - bpp: 1.5449 - mse: 1.2969e-04\n",
      "Epoch 474/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7053 - bpp: 1.5515 - mse: 1.2676e-04\n",
      "Epoch 474: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 5.7053 - bpp: 1.5515 - mse: 1.2676e-04\n",
      "Epoch 475/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9554 - bpp: 1.5272 - mse: 1.3514e-04\n",
      "Epoch 475: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.9554 - bpp: 1.5272 - mse: 1.3514e-04\n",
      "Epoch 476/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1299 - bpp: 1.5435 - mse: 1.3997e-04\n",
      "Epoch 476: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1299 - bpp: 1.5435 - mse: 1.3997e-04\n",
      "Epoch 477/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4913 - bpp: 1.6040 - mse: 1.7966e-04\n",
      "Epoch 477: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 7.4913 - bpp: 1.6040 - mse: 1.7966e-04\n",
      "Epoch 478/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8205 - bpp: 1.5938 - mse: 1.5951e-04\n",
      "Epoch 478: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.8205 - bpp: 1.5938 - mse: 1.5951e-04\n",
      "Epoch 479/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0150 - bpp: 1.5310 - mse: 1.3684e-04\n",
      "Epoch 479: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.0150 - bpp: 1.5310 - mse: 1.3684e-04\n",
      "Epoch 480/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0715 - bpp: 1.5447 - mse: 1.3815e-04\n",
      "Epoch 480: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0715 - bpp: 1.5447 - mse: 1.3815e-04\n",
      "Epoch 481/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4568 - bpp: 1.5532 - mse: 1.4965e-04\n",
      "Epoch 481: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.4568 - bpp: 1.5532 - mse: 1.4965e-04\n",
      "Epoch 482/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4596 - bpp: 1.4803 - mse: 1.2144e-04\n",
      "Epoch 482: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.4596 - bpp: 1.4803 - mse: 1.2144e-04\n",
      "Epoch 483/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1745 - bpp: 1.5527 - mse: 1.4105e-04\n",
      "Epoch 483: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.1745 - bpp: 1.5527 - mse: 1.4105e-04\n",
      "Epoch 484/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6258 - bpp: 1.5155 - mse: 1.2544e-04\n",
      "Epoch 484: loss did not improve from 5.27632\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.6258 - bpp: 1.5155 - mse: 1.2544e-04\n",
      "Epoch 485/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2586 - bpp: 1.5083 - mse: 1.1445e-04\n",
      "Epoch 485: loss improved from 5.27632 to 5.25858, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 121ms/step - loss: 5.2586 - bpp: 1.5083 - mse: 1.1445e-04\n",
      "Epoch 486/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6467 - bpp: 1.5319 - mse: 1.2557e-04\n",
      "Epoch 486: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.6467 - bpp: 1.5319 - mse: 1.2557e-04\n",
      "Epoch 487/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5344 - bpp: 1.5692 - mse: 1.5153e-04\n",
      "Epoch 487: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.5344 - bpp: 1.5692 - mse: 1.5153e-04\n",
      "Epoch 488/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5000 - bpp: 1.6015 - mse: 1.4949e-04\n",
      "Epoch 488: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.5000 - bpp: 1.6015 - mse: 1.4949e-04\n",
      "Epoch 489/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9334 - bpp: 1.5389 - mse: 1.3411e-04\n",
      "Epoch 489: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.9334 - bpp: 1.5389 - mse: 1.3411e-04\n",
      "Epoch 490/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0697 - bpp: 1.5558 - mse: 1.3775e-04\n",
      "Epoch 490: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0697 - bpp: 1.5558 - mse: 1.3775e-04\n",
      "Epoch 491/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7825 - bpp: 1.5250 - mse: 1.2993e-04\n",
      "Epoch 491: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.7825 - bpp: 1.5250 - mse: 1.2993e-04\n",
      "Epoch 492/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0049 - bpp: 1.5442 - mse: 1.3613e-04\n",
      "Epoch 492: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 6.0049 - bpp: 1.5442 - mse: 1.3613e-04\n",
      "Epoch 493/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7586 - bpp: 1.5844 - mse: 1.5790e-04\n",
      "Epoch 493: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.7586 - bpp: 1.5844 - mse: 1.5790e-04\n",
      "Epoch 494/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5879 - bpp: 1.5286 - mse: 1.2388e-04\n",
      "Epoch 494: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.5879 - bpp: 1.5286 - mse: 1.2388e-04\n",
      "Epoch 495/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1690 - bpp: 1.5662 - mse: 1.4046e-04\n",
      "Epoch 495: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1690 - bpp: 1.5662 - mse: 1.4046e-04\n",
      "Epoch 496/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2900 - bpp: 1.5643 - mse: 1.4422e-04\n",
      "Epoch 496: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 26s 125ms/step - loss: 6.2900 - bpp: 1.5643 - mse: 1.4422e-04\n",
      "Epoch 497/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9305 - bpp: 1.5357 - mse: 1.3412e-04\n",
      "Epoch 497: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.9305 - bpp: 1.5357 - mse: 1.3412e-04\n",
      "Epoch 498/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3061 - bpp: 1.5571 - mse: 1.4493e-04\n",
      "Epoch 498: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.3061 - bpp: 1.5571 - mse: 1.4493e-04\n",
      "Epoch 499/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2113 - bpp: 1.5656 - mse: 1.7229e-04\n",
      "Epoch 499: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 7.2113 - bpp: 1.5656 - mse: 1.7229e-04\n",
      "Epoch 500/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5180 - bpp: 1.5632 - mse: 1.5121e-04\n",
      "Epoch 500: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.5180 - bpp: 1.5632 - mse: 1.5121e-04\n",
      "Epoch 501/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9471 - bpp: 1.5384 - mse: 1.3454e-04\n",
      "Epoch 501: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 5.9471 - bpp: 1.5384 - mse: 1.3454e-04\n",
      "Epoch 502/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1715 - bpp: 1.5813 - mse: 1.4008e-04\n",
      "Epoch 502: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1715 - bpp: 1.5813 - mse: 1.4008e-04\n",
      "Epoch 503/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5315 - bpp: 1.5176 - mse: 1.2249e-04\n",
      "Epoch 503: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.5315 - bpp: 1.5176 - mse: 1.2249e-04\n",
      "Epoch 504/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8444 - bpp: 1.5496 - mse: 1.3107e-04\n",
      "Epoch 504: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.8444 - bpp: 1.5496 - mse: 1.3107e-04\n",
      "Epoch 505/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5474 - bpp: 1.5348 - mse: 1.2245e-04\n",
      "Epoch 505: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.5474 - bpp: 1.5348 - mse: 1.2245e-04\n",
      "Epoch 506/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5195 - bpp: 1.5591 - mse: 1.2086e-04\n",
      "Epoch 506: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.5195 - bpp: 1.5591 - mse: 1.2086e-04\n",
      "Epoch 507/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6566 - bpp: 1.5403 - mse: 1.2562e-04\n",
      "Epoch 507: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.6566 - bpp: 1.5403 - mse: 1.2562e-04\n",
      "Epoch 508/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0113 - bpp: 1.5892 - mse: 1.3495e-04\n",
      "Epoch 508: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.0113 - bpp: 1.5892 - mse: 1.3495e-04\n",
      "Epoch 509/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0189 - bpp: 1.5607 - mse: 1.3605e-04\n",
      "Epoch 509: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.0189 - bpp: 1.5607 - mse: 1.3605e-04\n",
      "Epoch 510/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8664 - bpp: 1.5327 - mse: 1.3225e-04\n",
      "Epoch 510: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.8664 - bpp: 1.5327 - mse: 1.3225e-04\n",
      "Epoch 511/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0507 - bpp: 1.5637 - mse: 1.3693e-04\n",
      "Epoch 511: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.0507 - bpp: 1.5637 - mse: 1.3693e-04\n",
      "Epoch 512/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0523 - bpp: 1.5647 - mse: 1.3695e-04\n",
      "Epoch 512: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.0523 - bpp: 1.5647 - mse: 1.3695e-04\n",
      "Epoch 513/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1816 - bpp: 1.5590 - mse: 1.4107e-04\n",
      "Epoch 513: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.1816 - bpp: 1.5590 - mse: 1.4107e-04\n",
      "Epoch 514/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3180 - bpp: 1.5114 - mse: 1.1617e-04\n",
      "Epoch 514: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.3180 - bpp: 1.5114 - mse: 1.1617e-04\n",
      "Epoch 515/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7731 - bpp: 1.5698 - mse: 1.5879e-04\n",
      "Epoch 515: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.7731 - bpp: 1.5698 - mse: 1.5879e-04\n",
      "Epoch 516/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9049 - bpp: 1.5485 - mse: 1.3295e-04\n",
      "Epoch 516: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.9049 - bpp: 1.5485 - mse: 1.3295e-04\n",
      "Epoch 517/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4966 - bpp: 1.5081 - mse: 1.2172e-04\n",
      "Epoch 517: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4966 - bpp: 1.5081 - mse: 1.2172e-04\n",
      "Epoch 518/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1115 - bpp: 1.5388 - mse: 1.3955e-04\n",
      "Epoch 518: loss did not improve from 5.25858\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 6.1115 - bpp: 1.5388 - mse: 1.3955e-04\n",
      "Epoch 519/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2172 - bpp: 1.5104 - mse: 1.1312e-04\n",
      "Epoch 519: loss improved from 5.25858 to 5.21719, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.2172 - bpp: 1.5104 - mse: 1.1312e-04\n",
      "Epoch 520/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0643 - bpp: 1.5652 - mse: 1.3730e-04\n",
      "Epoch 520: loss did not improve from 5.21719\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0643 - bpp: 1.5652 - mse: 1.3730e-04\n",
      "Epoch 521/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2256 - bpp: 1.5481 - mse: 1.4274e-04\n",
      "Epoch 521: loss did not improve from 5.21719\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.2256 - bpp: 1.5481 - mse: 1.4274e-04\n",
      "Epoch 522/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9967 - bpp: 1.5345 - mse: 1.3618e-04\n",
      "Epoch 522: loss did not improve from 5.21719\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.9967 - bpp: 1.5345 - mse: 1.3618e-04\n",
      "Epoch 523/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2979 - bpp: 1.5416 - mse: 1.1463e-04\n",
      "Epoch 523: loss did not improve from 5.21719\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.2979 - bpp: 1.5416 - mse: 1.1463e-04\n",
      "Epoch 524/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3160 - bpp: 1.5637 - mse: 1.4503e-04\n",
      "Epoch 524: loss did not improve from 5.21719\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.3160 - bpp: 1.5637 - mse: 1.4503e-04\n",
      "Epoch 525/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1779 - bpp: 1.5012 - mse: 1.1220e-04\n",
      "Epoch 525: loss improved from 5.21719 to 5.17790, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 5.1779 - bpp: 1.5012 - mse: 1.1220e-04\n",
      "Epoch 526/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4567 - bpp: 1.5738 - mse: 1.4901e-04\n",
      "Epoch 526: loss did not improve from 5.17790\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.4567 - bpp: 1.5738 - mse: 1.4901e-04\n",
      "Epoch 527/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9444 - bpp: 1.5435 - mse: 1.3431e-04\n",
      "Epoch 527: loss did not improve from 5.17790\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.9444 - bpp: 1.5435 - mse: 1.3431e-04\n",
      "Epoch 528/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9580 - bpp: 1.5363 - mse: 1.3494e-04\n",
      "Epoch 528: loss did not improve from 5.17790\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.9580 - bpp: 1.5363 - mse: 1.3494e-04\n",
      "Epoch 529/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1380 - bpp: 1.5645 - mse: 1.3957e-04\n",
      "Epoch 529: loss did not improve from 5.17790\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1380 - bpp: 1.5645 - mse: 1.3957e-04\n",
      "Epoch 530/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1348 - bpp: 1.5155 - mse: 1.1045e-04\n",
      "Epoch 530: loss improved from 5.17790 to 5.13481, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.1348 - bpp: 1.5155 - mse: 1.1045e-04\n",
      "Epoch 531/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6965 - bpp: 1.5599 - mse: 1.2624e-04\n",
      "Epoch 531: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.6965 - bpp: 1.5599 - mse: 1.2624e-04\n",
      "Epoch 532/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9402 - bpp: 1.5626 - mse: 1.3359e-04\n",
      "Epoch 532: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 5.9402 - bpp: 1.5626 - mse: 1.3359e-04\n",
      "Epoch 533/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3100 - bpp: 1.5632 - mse: 1.4486e-04\n",
      "Epoch 533: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3100 - bpp: 1.5632 - mse: 1.4486e-04\n",
      "Epoch 534/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4334 - bpp: 1.5244 - mse: 1.1929e-04\n",
      "Epoch 534: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.4334 - bpp: 1.5244 - mse: 1.1929e-04\n",
      "Epoch 535/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3849 - bpp: 1.5434 - mse: 1.1723e-04\n",
      "Epoch 535: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.3849 - bpp: 1.5434 - mse: 1.1723e-04\n",
      "Epoch 536/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9020 - bpp: 1.5531 - mse: 1.3272e-04\n",
      "Epoch 536: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.9020 - bpp: 1.5531 - mse: 1.3272e-04\n",
      "Epoch 537/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0492 - bpp: 1.5532 - mse: 1.3721e-04\n",
      "Epoch 537: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.0492 - bpp: 1.5532 - mse: 1.3721e-04\n",
      "Epoch 538/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9060 - bpp: 1.5247 - mse: 1.3371e-04\n",
      "Epoch 538: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.9060 - bpp: 1.5247 - mse: 1.3371e-04\n",
      "Epoch 539/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4917 - bpp: 1.5652 - mse: 1.5034e-04\n",
      "Epoch 539: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.4917 - bpp: 1.5652 - mse: 1.5034e-04\n",
      "Epoch 540/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5945 - bpp: 1.5383 - mse: 1.2379e-04\n",
      "Epoch 540: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5945 - bpp: 1.5383 - mse: 1.2379e-04\n",
      "Epoch 541/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2474 - bpp: 1.5425 - mse: 1.1306e-04\n",
      "Epoch 541: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.2474 - bpp: 1.5425 - mse: 1.1306e-04\n",
      "Epoch 542/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4846 - bpp: 1.5275 - mse: 1.2076e-04\n",
      "Epoch 542: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.4846 - bpp: 1.5275 - mse: 1.2076e-04\n",
      "Epoch 543/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7414 - bpp: 1.5761 - mse: 1.2711e-04\n",
      "Epoch 543: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.7414 - bpp: 1.5761 - mse: 1.2711e-04\n",
      "Epoch 544/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1059 - bpp: 1.5545 - mse: 1.3890e-04\n",
      "Epoch 544: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1059 - bpp: 1.5545 - mse: 1.3890e-04\n",
      "Epoch 545/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2526 - bpp: 1.5472 - mse: 1.1308e-04\n",
      "Epoch 545: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.2526 - bpp: 1.5472 - mse: 1.1308e-04\n",
      "Epoch 546/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6349 - bpp: 1.5841 - mse: 1.5414e-04\n",
      "Epoch 546: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.6349 - bpp: 1.5841 - mse: 1.5414e-04\n",
      "Epoch 547/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3754 - bpp: 1.5416 - mse: 1.1700e-04\n",
      "Epoch 547: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 5.3754 - bpp: 1.5416 - mse: 1.1700e-04\n",
      "Epoch 548/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2728 - bpp: 1.5174 - mse: 1.1461e-04\n",
      "Epoch 548: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.2728 - bpp: 1.5174 - mse: 1.1461e-04\n",
      "Epoch 549/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1056 - bpp: 1.5714 - mse: 1.3837e-04\n",
      "Epoch 549: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1056 - bpp: 1.5714 - mse: 1.3837e-04\n",
      "Epoch 550/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9434 - bpp: 1.5679 - mse: 1.3353e-04\n",
      "Epoch 550: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.9434 - bpp: 1.5679 - mse: 1.3353e-04\n",
      "Epoch 551/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9348 - bpp: 1.5520 - mse: 1.3375e-04\n",
      "Epoch 551: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.9348 - bpp: 1.5520 - mse: 1.3375e-04\n",
      "Epoch 552/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5432 - bpp: 1.5398 - mse: 1.2217e-04\n",
      "Epoch 552: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5432 - bpp: 1.5398 - mse: 1.2217e-04\n",
      "Epoch 553/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7457 - bpp: 1.5568 - mse: 1.2784e-04\n",
      "Epoch 553: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.7457 - bpp: 1.5568 - mse: 1.2784e-04\n",
      "Epoch 554/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8677 - bpp: 1.5851 - mse: 1.3069e-04\n",
      "Epoch 554: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.8677 - bpp: 1.5851 - mse: 1.3069e-04\n",
      "Epoch 555/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5630 - bpp: 1.5236 - mse: 1.2327e-04\n",
      "Epoch 555: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.5630 - bpp: 1.5236 - mse: 1.2327e-04\n",
      "Epoch 556/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6559 - bpp: 1.5433 - mse: 1.2551e-04\n",
      "Epoch 556: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.6559 - bpp: 1.5433 - mse: 1.2551e-04\n",
      "Epoch 557/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3039 - bpp: 1.5416 - mse: 1.1482e-04\n",
      "Epoch 557: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 5.3039 - bpp: 1.5416 - mse: 1.1482e-04\n",
      "Epoch 558/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0863 - bpp: 1.5619 - mse: 1.3807e-04\n",
      "Epoch 558: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 6.0863 - bpp: 1.5619 - mse: 1.3807e-04\n",
      "Epoch 559/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1491 - bpp: 1.5343 - mse: 1.1031e-04\n",
      "Epoch 559: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.1491 - bpp: 1.5343 - mse: 1.1031e-04\n",
      "Epoch 560/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8524 - bpp: 1.5405 - mse: 1.3159e-04\n",
      "Epoch 560: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.8524 - bpp: 1.5405 - mse: 1.3159e-04\n",
      "Epoch 561/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1724 - bpp: 1.5360 - mse: 1.1097e-04\n",
      "Epoch 561: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.1724 - bpp: 1.5360 - mse: 1.1097e-04\n",
      "Epoch 562/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6925 - bpp: 1.5447 - mse: 1.2658e-04\n",
      "Epoch 562: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 5.6925 - bpp: 1.5447 - mse: 1.2658e-04\n",
      "Epoch 563/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4281 - bpp: 1.5461 - mse: 1.1847e-04\n",
      "Epoch 563: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.4281 - bpp: 1.5461 - mse: 1.1847e-04\n",
      "Epoch 564/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3481 - bpp: 1.5727 - mse: 1.4573e-04\n",
      "Epoch 564: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3481 - bpp: 1.5727 - mse: 1.4573e-04\n",
      "Epoch 565/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9741 - bpp: 1.5635 - mse: 1.3460e-04\n",
      "Epoch 565: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.9741 - bpp: 1.5635 - mse: 1.3460e-04\n",
      "Epoch 566/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4780 - bpp: 1.5867 - mse: 1.4927e-04\n",
      "Epoch 566: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.4780 - bpp: 1.5867 - mse: 1.4927e-04\n",
      "Epoch 567/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8633 - bpp: 1.5550 - mse: 1.3148e-04\n",
      "Epoch 567: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.8633 - bpp: 1.5550 - mse: 1.3148e-04\n",
      "Epoch 568/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6467 - bpp: 1.5224 - mse: 1.2586e-04\n",
      "Epoch 568: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.6467 - bpp: 1.5224 - mse: 1.2586e-04\n",
      "Epoch 569/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0258 - bpp: 1.5509 - mse: 1.3656e-04\n",
      "Epoch 569: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.0258 - bpp: 1.5509 - mse: 1.3656e-04\n",
      "Epoch 570/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6582 - bpp: 1.5670 - mse: 1.5537e-04\n",
      "Epoch 570: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.6582 - bpp: 1.5670 - mse: 1.5537e-04\n",
      "Epoch 571/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1749 - bpp: 1.5668 - mse: 1.4063e-04\n",
      "Epoch 571: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1749 - bpp: 1.5668 - mse: 1.4063e-04\n",
      "Epoch 572/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8483 - bpp: 1.5585 - mse: 1.3092e-04\n",
      "Epoch 572: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 5.8483 - bpp: 1.5585 - mse: 1.3092e-04\n",
      "Epoch 573/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5584 - bpp: 1.5573 - mse: 1.2210e-04\n",
      "Epoch 573: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5584 - bpp: 1.5573 - mse: 1.2210e-04\n",
      "Epoch 574/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6221 - bpp: 1.5051 - mse: 1.2564e-04\n",
      "Epoch 574: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.6221 - bpp: 1.5051 - mse: 1.2564e-04\n",
      "Epoch 575/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4466 - bpp: 1.5278 - mse: 1.1959e-04\n",
      "Epoch 575: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.4466 - bpp: 1.5278 - mse: 1.1959e-04\n",
      "Epoch 576/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8944 - bpp: 1.5575 - mse: 1.3235e-04\n",
      "Epoch 576: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 5.8944 - bpp: 1.5575 - mse: 1.3235e-04\n",
      "Epoch 577/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9073 - bpp: 1.5557 - mse: 1.3280e-04\n",
      "Epoch 577: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 5.9073 - bpp: 1.5557 - mse: 1.3280e-04\n",
      "Epoch 578/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6906 - bpp: 1.5533 - mse: 1.2626e-04\n",
      "Epoch 578: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.6906 - bpp: 1.5533 - mse: 1.2626e-04\n",
      "Epoch 579/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5791 - bpp: 1.5411 - mse: 1.2323e-04\n",
      "Epoch 579: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5791 - bpp: 1.5411 - mse: 1.2323e-04\n",
      "Epoch 580/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5122 - bpp: 1.5379 - mse: 1.2129e-04\n",
      "Epoch 580: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5122 - bpp: 1.5379 - mse: 1.2129e-04\n",
      "Epoch 581/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5048 - bpp: 1.5347 - mse: 1.2116e-04\n",
      "Epoch 581: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 5.5048 - bpp: 1.5347 - mse: 1.2116e-04\n",
      "Epoch 582/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5854 - bpp: 1.5712 - mse: 1.5302e-04\n",
      "Epoch 582: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.5854 - bpp: 1.5712 - mse: 1.5302e-04\n",
      "Epoch 583/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8046 - bpp: 1.5658 - mse: 1.2936e-04\n",
      "Epoch 583: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 5.8046 - bpp: 1.5658 - mse: 1.2936e-04\n",
      "Epoch 584/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9963 - bpp: 1.5724 - mse: 1.3500e-04\n",
      "Epoch 584: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.9963 - bpp: 1.5724 - mse: 1.3500e-04\n",
      "Epoch 585/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5829 - bpp: 1.5487 - mse: 1.2311e-04\n",
      "Epoch 585: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.5829 - bpp: 1.5487 - mse: 1.2311e-04\n",
      "Epoch 586/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6477 - bpp: 1.5296 - mse: 1.2567e-04\n",
      "Epoch 586: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.6477 - bpp: 1.5296 - mse: 1.2567e-04\n",
      "Epoch 587/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1229 - bpp: 1.5551 - mse: 1.3940e-04\n",
      "Epoch 587: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1229 - bpp: 1.5551 - mse: 1.3940e-04\n",
      "Epoch 588/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8635 - bpp: 1.5396 - mse: 1.3196e-04\n",
      "Epoch 588: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.8635 - bpp: 1.5396 - mse: 1.3196e-04\n",
      "Epoch 589/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3231 - bpp: 1.5268 - mse: 1.1586e-04\n",
      "Epoch 589: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 25s 122ms/step - loss: 5.3231 - bpp: 1.5268 - mse: 1.1586e-04\n",
      "Epoch 590/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7142 - bpp: 1.5445 - mse: 1.2725e-04\n",
      "Epoch 590: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.7142 - bpp: 1.5445 - mse: 1.2725e-04\n",
      "Epoch 591/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8154 - bpp: 1.5598 - mse: 1.2987e-04\n",
      "Epoch 591: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.8154 - bpp: 1.5598 - mse: 1.2987e-04\n",
      "Epoch 592/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5323 - bpp: 1.5415 - mse: 1.2179e-04\n",
      "Epoch 592: loss did not improve from 5.13481\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5323 - bpp: 1.5415 - mse: 1.2179e-04\n",
      "Epoch 593/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9470 - bpp: 1.5082 - mse: 1.0494e-04\n",
      "Epoch 593: loss improved from 5.13481 to 4.94696, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 4.9470 - bpp: 1.5082 - mse: 1.0494e-04\n",
      "Epoch 594/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3432 - bpp: 1.5458 - mse: 1.1589e-04\n",
      "Epoch 594: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 5.3432 - bpp: 1.5458 - mse: 1.1589e-04\n",
      "Epoch 595/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6629 - bpp: 1.5578 - mse: 1.2528e-04\n",
      "Epoch 595: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.6629 - bpp: 1.5578 - mse: 1.2528e-04\n",
      "Epoch 596/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4157 - bpp: 1.5602 - mse: 1.4818e-04\n",
      "Epoch 596: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.4157 - bpp: 1.5602 - mse: 1.4818e-04\n",
      "Epoch 597/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0325 - bpp: 1.5510 - mse: 1.3676e-04\n",
      "Epoch 597: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.0325 - bpp: 1.5510 - mse: 1.3676e-04\n",
      "Epoch 598/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2873 - bpp: 1.5648 - mse: 1.4412e-04\n",
      "Epoch 598: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.2873 - bpp: 1.5648 - mse: 1.4412e-04\n",
      "Epoch 599/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2923 - bpp: 1.5196 - mse: 1.1514e-04\n",
      "Epoch 599: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.2923 - bpp: 1.5196 - mse: 1.1514e-04\n",
      "Epoch 600/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7959 - bpp: 1.5594 - mse: 1.2929e-04\n",
      "Epoch 600: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.7959 - bpp: 1.5594 - mse: 1.2929e-04\n",
      "Epoch 601/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6585 - bpp: 1.5725 - mse: 1.2470e-04\n",
      "Epoch 601: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.6585 - bpp: 1.5725 - mse: 1.2470e-04\n",
      "Epoch 602/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0447 - bpp: 1.5239 - mse: 1.0745e-04\n",
      "Epoch 602: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.0447 - bpp: 1.5239 - mse: 1.0745e-04\n",
      "Epoch 603/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7245 - bpp: 1.5535 - mse: 1.2729e-04\n",
      "Epoch 603: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.7245 - bpp: 1.5535 - mse: 1.2729e-04\n",
      "Epoch 604/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4853 - bpp: 1.5363 - mse: 1.2051e-04\n",
      "Epoch 604: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.4853 - bpp: 1.5363 - mse: 1.2051e-04\n",
      "Epoch 605/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3016 - bpp: 1.5594 - mse: 1.4472e-04\n",
      "Epoch 605: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 6.3016 - bpp: 1.5594 - mse: 1.4472e-04\n",
      "Epoch 606/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5010 - bpp: 1.5686 - mse: 1.5052e-04\n",
      "Epoch 606: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.5010 - bpp: 1.5686 - mse: 1.5052e-04\n",
      "Epoch 607/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3461 - bpp: 1.5765 - mse: 1.4556e-04\n",
      "Epoch 607: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.3461 - bpp: 1.5765 - mse: 1.4556e-04\n",
      "Epoch 608/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6727 - bpp: 1.5302 - mse: 1.2642e-04\n",
      "Epoch 608: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.6727 - bpp: 1.5302 - mse: 1.2642e-04\n",
      "Epoch 609/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2280 - bpp: 1.5618 - mse: 1.4240e-04\n",
      "Epoch 609: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.2280 - bpp: 1.5618 - mse: 1.4240e-04\n",
      "Epoch 610/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7694 - bpp: 1.5596 - mse: 1.2847e-04\n",
      "Epoch 610: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 5.7694 - bpp: 1.5596 - mse: 1.2847e-04\n",
      "Epoch 611/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5203 - bpp: 1.5446 - mse: 1.2133e-04\n",
      "Epoch 611: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5203 - bpp: 1.5446 - mse: 1.2133e-04\n",
      "Epoch 612/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6149 - bpp: 1.5524 - mse: 1.2398e-04\n",
      "Epoch 612: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.6149 - bpp: 1.5524 - mse: 1.2398e-04\n",
      "Epoch 613/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2368 - bpp: 1.5381 - mse: 1.1287e-04\n",
      "Epoch 613: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.2368 - bpp: 1.5381 - mse: 1.1287e-04\n",
      "Epoch 614/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6308 - bpp: 1.5308 - mse: 1.2512e-04\n",
      "Epoch 614: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.6308 - bpp: 1.5308 - mse: 1.2512e-04\n",
      "Epoch 615/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5747 - bpp: 1.5169 - mse: 1.2383e-04\n",
      "Epoch 615: loss did not improve from 4.94696\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5747 - bpp: 1.5169 - mse: 1.2383e-04\n",
      "Epoch 616/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8571 - bpp: 1.5108 - mse: 1.0212e-04\n",
      "Epoch 616: loss improved from 4.94696 to 4.85714, saving model to checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 4.8571 - bpp: 1.5108 - mse: 1.0212e-04\n",
      "Epoch 617/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4665 - bpp: 1.5289 - mse: 1.2017e-04\n",
      "Epoch 617: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.4665 - bpp: 1.5289 - mse: 1.2017e-04\n",
      "Epoch 618/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0015 - bpp: 1.5527 - mse: 1.3577e-04\n",
      "Epoch 618: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.0015 - bpp: 1.5527 - mse: 1.3577e-04\n",
      "Epoch 619/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9552 - bpp: 1.5631 - mse: 1.3404e-04\n",
      "Epoch 619: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 5.9552 - bpp: 1.5631 - mse: 1.3404e-04\n",
      "Epoch 620/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9536 - bpp: 1.5358 - mse: 1.3482e-04\n",
      "Epoch 620: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.9536 - bpp: 1.5358 - mse: 1.3482e-04\n",
      "Epoch 621/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4001 - bpp: 1.5833 - mse: 1.4700e-04\n",
      "Epoch 621: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 6.4001 - bpp: 1.5833 - mse: 1.4700e-04\n",
      "Epoch 622/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4781 - bpp: 1.5331 - mse: 1.2039e-04\n",
      "Epoch 622: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.4781 - bpp: 1.5331 - mse: 1.2039e-04\n",
      "Epoch 623/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1493 - bpp: 1.5180 - mse: 1.1082e-04\n",
      "Epoch 623: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.1493 - bpp: 1.5180 - mse: 1.1082e-04\n",
      "Epoch 624/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1511 - bpp: 1.5700 - mse: 1.3980e-04\n",
      "Epoch 624: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1511 - bpp: 1.5700 - mse: 1.3980e-04\n",
      "Epoch 625/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1675 - bpp: 1.5484 - mse: 1.1045e-04\n",
      "Epoch 625: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.1675 - bpp: 1.5484 - mse: 1.1045e-04\n",
      "Epoch 626/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2849 - bpp: 1.5747 - mse: 1.4374e-04\n",
      "Epoch 626: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.2849 - bpp: 1.5747 - mse: 1.4374e-04\n",
      "Epoch 627/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9911 - bpp: 1.5386 - mse: 1.3588e-04\n",
      "Epoch 627: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.9911 - bpp: 1.5386 - mse: 1.3588e-04\n",
      "Epoch 628/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7989 - bpp: 1.5527 - mse: 1.2958e-04\n",
      "Epoch 628: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.7989 - bpp: 1.5527 - mse: 1.2958e-04\n",
      "Epoch 629/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9411 - bpp: 1.5681 - mse: 1.3345e-04\n",
      "Epoch 629: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.9411 - bpp: 1.5681 - mse: 1.3345e-04\n",
      "Epoch 630/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5852 - bpp: 1.5714 - mse: 1.2249e-04\n",
      "Epoch 630: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5852 - bpp: 1.5714 - mse: 1.2249e-04\n",
      "Epoch 631/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1546 - bpp: 1.5466 - mse: 1.4063e-04\n",
      "Epoch 631: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1546 - bpp: 1.5466 - mse: 1.4063e-04\n",
      "Epoch 632/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5609 - bpp: 1.5364 - mse: 1.2282e-04\n",
      "Epoch 632: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.5609 - bpp: 1.5364 - mse: 1.2282e-04\n",
      "Epoch 633/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5018 - bpp: 1.5876 - mse: 1.4997e-04\n",
      "Epoch 633: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.5018 - bpp: 1.5876 - mse: 1.4997e-04\n",
      "Epoch 634/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0303 - bpp: 1.5600 - mse: 1.3642e-04\n",
      "Epoch 634: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.0303 - bpp: 1.5600 - mse: 1.3642e-04\n",
      "Epoch 635/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2695 - bpp: 1.5696 - mse: 1.4343e-04\n",
      "Epoch 635: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 6.2695 - bpp: 1.5696 - mse: 1.4343e-04\n",
      "Epoch 636/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4652 - bpp: 1.5206 - mse: 1.2038e-04\n",
      "Epoch 636: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.4652 - bpp: 1.5206 - mse: 1.2038e-04\n",
      "Epoch 637/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6305 - bpp: 1.5293 - mse: 1.2516e-04\n",
      "Epoch 637: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.6305 - bpp: 1.5293 - mse: 1.2516e-04\n",
      "Epoch 638/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4257 - bpp: 1.5321 - mse: 1.1882e-04\n",
      "Epoch 638: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.4257 - bpp: 1.5321 - mse: 1.1882e-04\n",
      "Epoch 639/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8813 - bpp: 1.5547 - mse: 1.3204e-04\n",
      "Epoch 639: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.8813 - bpp: 1.5547 - mse: 1.3204e-04\n",
      "Epoch 640/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1409 - bpp: 1.5838 - mse: 1.3907e-04\n",
      "Epoch 640: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1409 - bpp: 1.5838 - mse: 1.3907e-04\n",
      "Epoch 641/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1895 - bpp: 1.5865 - mse: 1.4047e-04\n",
      "Epoch 641: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1895 - bpp: 1.5865 - mse: 1.4047e-04\n",
      "Epoch 642/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2847 - bpp: 1.5314 - mse: 1.1454e-04\n",
      "Epoch 642: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.2847 - bpp: 1.5314 - mse: 1.1454e-04\n",
      "Epoch 643/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5843 - bpp: 1.5735 - mse: 1.2240e-04\n",
      "Epoch 643: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 5.5843 - bpp: 1.5735 - mse: 1.2240e-04\n",
      "Epoch 644/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7699 - bpp: 1.5582 - mse: 1.2853e-04\n",
      "Epoch 644: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.7699 - bpp: 1.5582 - mse: 1.2853e-04\n",
      "Epoch 645/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5685 - bpp: 1.5406 - mse: 1.2292e-04\n",
      "Epoch 645: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5685 - bpp: 1.5406 - mse: 1.2292e-04\n",
      "Epoch 646/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3436 - bpp: 1.5010 - mse: 1.1726e-04\n",
      "Epoch 646: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.3436 - bpp: 1.5010 - mse: 1.1726e-04\n",
      "Epoch 647/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2851 - bpp: 1.5259 - mse: 1.1472e-04\n",
      "Epoch 647: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 116ms/step - loss: 5.2851 - bpp: 1.5259 - mse: 1.1472e-04\n",
      "Epoch 648/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7094 - bpp: 1.5456 - mse: 1.2707e-04\n",
      "Epoch 648: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.7094 - bpp: 1.5456 - mse: 1.2707e-04\n",
      "Epoch 649/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1003 - bpp: 1.5641 - mse: 1.3843e-04\n",
      "Epoch 649: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.1003 - bpp: 1.5641 - mse: 1.3843e-04\n",
      "Epoch 650/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0153 - bpp: 1.5017 - mse: 1.0723e-04\n",
      "Epoch 650: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 5.0153 - bpp: 1.5017 - mse: 1.0723e-04\n",
      "Epoch 651/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5841 - bpp: 1.5609 - mse: 1.2278e-04\n",
      "Epoch 651: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5841 - bpp: 1.5609 - mse: 1.2278e-04\n",
      "Epoch 652/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7813 - bpp: 1.5518 - mse: 1.2908e-04\n",
      "Epoch 652: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.7813 - bpp: 1.5518 - mse: 1.2908e-04\n",
      "Epoch 653/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2068 - bpp: 1.5733 - mse: 1.4140e-04\n",
      "Epoch 653: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 6.2068 - bpp: 1.5733 - mse: 1.4140e-04\n",
      "Epoch 654/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5768 - bpp: 1.5579 - mse: 1.2265e-04\n",
      "Epoch 654: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5768 - bpp: 1.5579 - mse: 1.2265e-04\n",
      "Epoch 655/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3335 - bpp: 1.5695 - mse: 1.1487e-04\n",
      "Epoch 655: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.3335 - bpp: 1.5695 - mse: 1.1487e-04\n",
      "Epoch 656/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3231 - bpp: 1.5323 - mse: 1.1569e-04\n",
      "Epoch 656: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.3231 - bpp: 1.5323 - mse: 1.1569e-04\n",
      "Epoch 657/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3713 - bpp: 1.5490 - mse: 1.1665e-04\n",
      "Epoch 657: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.3713 - bpp: 1.5490 - mse: 1.1665e-04\n",
      "Epoch 658/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5498 - bpp: 1.5353 - mse: 1.2251e-04\n",
      "Epoch 658: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.5498 - bpp: 1.5353 - mse: 1.2251e-04\n",
      "Epoch 659/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4049 - bpp: 1.5675 - mse: 1.1711e-04\n",
      "Epoch 659: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4049 - bpp: 1.5675 - mse: 1.1711e-04\n",
      "Epoch 660/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1119 - bpp: 1.5603 - mse: 1.3891e-04\n",
      "Epoch 660: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.1119 - bpp: 1.5603 - mse: 1.3891e-04\n",
      "Epoch 661/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2963 - bpp: 1.5154 - mse: 1.1538e-04\n",
      "Epoch 661: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 25s 120ms/step - loss: 5.2963 - bpp: 1.5154 - mse: 1.1538e-04\n",
      "Epoch 662/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8174 - bpp: 1.5454 - mse: 1.3037e-04\n",
      "Epoch 662: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.8174 - bpp: 1.5454 - mse: 1.3037e-04\n",
      "Epoch 663/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2424 - bpp: 1.5911 - mse: 1.4195e-04\n",
      "Epoch 663: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.2424 - bpp: 1.5911 - mse: 1.4195e-04\n",
      "Epoch 664/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8454 - bpp: 1.5477 - mse: 1.3116e-04\n",
      "Epoch 664: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.8454 - bpp: 1.5477 - mse: 1.3116e-04\n",
      "Epoch 665/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9874 - bpp: 1.5371 - mse: 1.0530e-04\n",
      "Epoch 665: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 4.9874 - bpp: 1.5371 - mse: 1.0530e-04\n",
      "Epoch 666/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6148 - bpp: 1.5903 - mse: 1.5333e-04\n",
      "Epoch 666: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.6148 - bpp: 1.5903 - mse: 1.5333e-04\n",
      "Epoch 667/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8887 - bpp: 1.4956 - mse: 1.0355e-04\n",
      "Epoch 667: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 4.8887 - bpp: 1.4956 - mse: 1.0355e-04\n",
      "Epoch 668/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3907 - bpp: 1.5454 - mse: 1.1735e-04\n",
      "Epoch 668: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.3907 - bpp: 1.5454 - mse: 1.1735e-04\n",
      "Epoch 669/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3803 - bpp: 1.5347 - mse: 1.1736e-04\n",
      "Epoch 669: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 5.3803 - bpp: 1.5347 - mse: 1.1736e-04\n",
      "Epoch 670/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3789 - bpp: 1.4898 - mse: 1.1869e-04\n",
      "Epoch 670: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.3789 - bpp: 1.4898 - mse: 1.1869e-04\n",
      "Epoch 671/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1234 - bpp: 1.5365 - mse: 1.3998e-04\n",
      "Epoch 671: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 6.1234 - bpp: 1.5365 - mse: 1.3998e-04\n",
      "Epoch 672/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7595 - bpp: 1.5601 - mse: 1.2815e-04\n",
      "Epoch 672: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.7595 - bpp: 1.5601 - mse: 1.2815e-04\n",
      "Epoch 673/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3754 - bpp: 1.5293 - mse: 1.1737e-04\n",
      "Epoch 673: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 5.3754 - bpp: 1.5293 - mse: 1.1737e-04\n",
      "Epoch 674/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2543 - bpp: 1.5297 - mse: 1.1367e-04\n",
      "Epoch 674: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 5.2543 - bpp: 1.5297 - mse: 1.1367e-04\n",
      "Epoch 675/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7751 - bpp: 1.5410 - mse: 1.2922e-04\n",
      "Epoch 675: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.7751 - bpp: 1.5410 - mse: 1.2922e-04\n",
      "Epoch 676/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6984 - bpp: 1.5444 - mse: 1.2677e-04\n",
      "Epoch 676: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.6984 - bpp: 1.5444 - mse: 1.2677e-04\n",
      "Epoch 677/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2130 - bpp: 1.5347 - mse: 1.1225e-04\n",
      "Epoch 677: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.2130 - bpp: 1.5347 - mse: 1.1225e-04\n",
      "Epoch 678/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7111 - bpp: 1.5516 - mse: 1.2694e-04\n",
      "Epoch 678: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.7111 - bpp: 1.5516 - mse: 1.2694e-04\n",
      "Epoch 679/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3439 - bpp: 1.5360 - mse: 1.1621e-04\n",
      "Epoch 679: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.3439 - bpp: 1.5360 - mse: 1.1621e-04\n",
      "Epoch 680/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9815 - bpp: 1.5476 - mse: 1.3531e-04\n",
      "Epoch 680: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.9815 - bpp: 1.5476 - mse: 1.3531e-04\n",
      "Epoch 681/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2885 - bpp: 1.5525 - mse: 1.1401e-04\n",
      "Epoch 681: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.2885 - bpp: 1.5525 - mse: 1.1401e-04\n",
      "Epoch 682/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0696 - bpp: 1.5908 - mse: 1.3668e-04\n",
      "Epoch 682: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 115ms/step - loss: 6.0696 - bpp: 1.5908 - mse: 1.3668e-04\n",
      "Epoch 683/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4083 - bpp: 1.5365 - mse: 1.1816e-04\n",
      "Epoch 683: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.4083 - bpp: 1.5365 - mse: 1.1816e-04\n",
      "Epoch 684/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1735 - bpp: 1.5689 - mse: 1.4052e-04\n",
      "Epoch 684: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 6.1735 - bpp: 1.5689 - mse: 1.4052e-04\n",
      "Epoch 685/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8496 - bpp: 1.5593 - mse: 1.3093e-04\n",
      "Epoch 685: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 5.8496 - bpp: 1.5593 - mse: 1.3093e-04\n",
      "Epoch 686/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4793 - bpp: 1.5343 - mse: 1.2039e-04\n",
      "Epoch 686: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 5.4793 - bpp: 1.5343 - mse: 1.2039e-04\n",
      "Epoch 687/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5682 - bpp: 1.5631 - mse: 1.2223e-04\n",
      "Epoch 687: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.5682 - bpp: 1.5631 - mse: 1.2223e-04\n",
      "Epoch 688/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4716 - bpp: 1.5389 - mse: 1.2001e-04\n",
      "Epoch 688: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4716 - bpp: 1.5389 - mse: 1.2001e-04\n",
      "Epoch 689/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8094 - bpp: 1.5281 - mse: 1.3066e-04\n",
      "Epoch 689: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 5.8094 - bpp: 1.5281 - mse: 1.3066e-04\n",
      "Epoch 690/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2113 - bpp: 1.5357 - mse: 1.1217e-04\n",
      "Epoch 690: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.2113 - bpp: 1.5357 - mse: 1.1217e-04\n",
      "Epoch 691/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2500 - bpp: 1.5360 - mse: 1.1334e-04\n",
      "Epoch 691: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 5.2500 - bpp: 1.5360 - mse: 1.1334e-04\n",
      "Epoch 692/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1881 - bpp: 1.5528 - mse: 1.4146e-04\n",
      "Epoch 692: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 6.1881 - bpp: 1.5528 - mse: 1.4146e-04\n",
      "Epoch 693/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5194 - bpp: 1.5328 - mse: 1.2166e-04\n",
      "Epoch 693: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 5.5194 - bpp: 1.5328 - mse: 1.2166e-04\n",
      "Epoch 694/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8691 - bpp: 1.5606 - mse: 1.3148e-04\n",
      "Epoch 694: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 5.8691 - bpp: 1.5606 - mse: 1.3148e-04\n",
      "Epoch 695/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0837 - bpp: 1.5227 - mse: 1.0867e-04\n",
      "Epoch 695: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.0837 - bpp: 1.5227 - mse: 1.0867e-04\n",
      "Epoch 696/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2758 - bpp: 1.5546 - mse: 1.4408e-04\n",
      "Epoch 696: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 6.2758 - bpp: 1.5546 - mse: 1.4408e-04\n",
      "Epoch 697/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5174 - bpp: 1.5314 - mse: 1.2164e-04\n",
      "Epoch 697: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 5.5174 - bpp: 1.5314 - mse: 1.2164e-04\n",
      "Epoch 698/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4162 - bpp: 1.5453 - mse: 1.1813e-04\n",
      "Epoch 698: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.4162 - bpp: 1.5453 - mse: 1.1813e-04\n",
      "Epoch 699/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8740 - bpp: 1.5240 - mse: 1.0223e-04\n",
      "Epoch 699: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 117ms/step - loss: 4.8740 - bpp: 1.5240 - mse: 1.0223e-04\n",
      "Epoch 700/700\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8439 - bpp: 1.5689 - mse: 1.3046e-04\n",
      "Epoch 700: loss did not improve from 4.85714\n",
      "200/200 [==============================] - 24s 119ms/step - loss: 5.8439 - bpp: 1.5689 - mse: 1.3046e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_4_layer_call_fn, optical_flow_loss_4_layer_call_and_return_conditional_losses, dwt_4_layer_call_fn, dwt_4_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_bior1.3_Lmbd_32768_epcs_700_I_QP_40_240x240_CosineDecay_20220601-080236/assets\n"
     ]
    }
   ],
   "source": [
    "I_QP=40\n",
    "lmbda = 32768\n",
    "trainer_15 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_15.compile()\n",
    "trainer_15.fit()\n",
    "trainer_15.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load\n",
    "import OpenDVCW\n",
    "\n",
    "# img_path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "img_path = \"/mnt/WindowsDev/DataSets/Beauty_1920x1080_120fps_420_8bit_YUV_RAW/\"\n",
    "i_frame = img_path + 'im0' + '.png'\n",
    "p_frame = img_path + 'im1' + '.png'\n",
    "out_bin = \"Test_com/test{}.bin\".format(0)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(0)\n",
    "\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(0)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(0)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, Width, Height))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, Width, Height))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  2515 psnr:  37.010536430258554 bpp:  0.014554398148148148\n",
      "compress\n",
      "decompress\n",
      "bin size:  4016 psnr:  37.845215806154556 bpp:  0.023240740740740742\n",
      "compress\n",
      "decompress\n",
      "bin size:  6129 psnr:  38.45107393645732 bpp:  0.03546875\n",
      "compress\n",
      "decompress\n",
      "bin size:  6717 psnr:  40.01848739363824 bpp:  0.038871527777777776\n",
      "compress\n",
      "decompress\n",
      "bin size:  10386 psnr:  38.83272494757646 bpp:  0.06010416666666667\n"
     ]
    }
   ],
   "source": [
    "trainer_11.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_12.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_13.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_14.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_15.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
