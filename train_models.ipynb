{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "from train import TrainOpenDVCW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1500\n",
    "STEPS_PER_EPOCH = 200\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "NUM_FILTERS = 128\n",
    "lmbda = 2**11 # 2048\n",
    "lr_init = 1e-4\n",
    "lr_alpha = 1e-8\n",
    "early_stop = 800\n",
    "I_QP=27\n",
    "wavelet_name = \"haar\"\n",
    "np_folder = \"folder_cloud_test.npy\"\n",
    "checkponts_prev_path = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 20:53:03.123634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:03.170580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:03.171516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:03.175396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 20:53:03.179967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:03.180832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:03.181603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:05.978636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:05.979557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:05.980322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 20:53:05.981268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 20:53:33.826604: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-05-06 20:54:08.312035: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 41.3161 - bpp: 5.3104 - mse: 0.0176\n",
      "Epoch 1: loss improved from inf to 41.31607, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 112s 293ms/step - loss: 41.3161 - bpp: 5.3104 - mse: 0.0176\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.5169 - bpp: 5.1709 - mse: 0.0026\n",
      "Epoch 2: loss improved from 41.31607 to 10.51686, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 65s 323ms/step - loss: 10.5169 - bpp: 5.1709 - mse: 0.0026\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4264 - bpp: 5.0347 - mse: 0.0021\n",
      "Epoch 3: loss improved from 10.51686 to 9.42642, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 9.4264 - bpp: 5.0347 - mse: 0.0021\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8659 - bpp: 4.9010 - mse: 0.0019\n",
      "Epoch 4: loss improved from 9.42642 to 8.86585, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 8.8659 - bpp: 4.9010 - mse: 0.0019\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5044 - bpp: 4.7696 - mse: 0.0013\n",
      "Epoch 5: loss improved from 8.86585 to 7.50438, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 7.5044 - bpp: 4.7696 - mse: 0.0013\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0689 - bpp: 4.6412 - mse: 0.0017\n",
      "Epoch 6: loss did not improve from 7.50438\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 8.0689 - bpp: 4.6412 - mse: 0.0017\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1298 - bpp: 4.5148 - mse: 0.0013\n",
      "Epoch 7: loss improved from 7.50438 to 7.12977, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 7.1298 - bpp: 4.5148 - mse: 0.0013\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8632 - bpp: 4.3917 - mse: 0.0012\n",
      "Epoch 8: loss improved from 7.12977 to 6.86315, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 70s 349ms/step - loss: 6.8632 - bpp: 4.3917 - mse: 0.0012\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1077 - bpp: 4.2702 - mse: 0.0019\n",
      "Epoch 9: loss did not improve from 6.86315\n",
      "200/200 [==============================] - 63s 314ms/step - loss: 8.1077 - bpp: 4.2702 - mse: 0.0019\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5221 - bpp: 4.1512 - mse: 0.0012\n",
      "Epoch 10: loss improved from 6.86315 to 6.52213, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 319ms/step - loss: 6.5221 - bpp: 4.1512 - mse: 0.0012\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3562 - bpp: 4.0356 - mse: 0.0011\n",
      "Epoch 11: loss improved from 6.52213 to 6.35623, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 314ms/step - loss: 6.3562 - bpp: 4.0356 - mse: 0.0011\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8688 - bpp: 3.9209 - mse: 9.5111e-04\n",
      "Epoch 12: loss improved from 6.35623 to 5.86876, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 66s 327ms/step - loss: 5.8688 - bpp: 3.9209 - mse: 9.5111e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6921 - bpp: 3.8083 - mse: 9.1980e-04\n",
      "Epoch 13: loss improved from 5.86876 to 5.69205, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 315ms/step - loss: 5.6921 - bpp: 3.8083 - mse: 9.1980e-04\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.7422 - bpp: 3.7033 - mse: 0.0029\n",
      "Epoch 14: loss did not improve from 5.69205\n",
      "200/200 [==============================] - 63s 312ms/step - loss: 9.7422 - bpp: 3.7033 - mse: 0.0029\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8478 - bpp: 3.5907 - mse: 0.0011\n",
      "Epoch 15: loss did not improve from 5.69205\n",
      "200/200 [==============================] - 62s 306ms/step - loss: 5.8478 - bpp: 3.5907 - mse: 0.0011\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1490 - bpp: 3.4826 - mse: 8.1364e-04\n",
      "Epoch 16: loss improved from 5.69205 to 5.14896, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 317ms/step - loss: 5.1490 - bpp: 3.4826 - mse: 8.1364e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0337 - bpp: 3.3793 - mse: 8.0784e-04\n",
      "Epoch 17: loss improved from 5.14896 to 5.03373, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 65s 323ms/step - loss: 5.0337 - bpp: 3.3793 - mse: 8.0784e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8018 - bpp: 3.2764 - mse: 7.4485e-04\n",
      "Epoch 18: loss improved from 5.03373 to 4.80181, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 65s 321ms/step - loss: 4.8018 - bpp: 3.2764 - mse: 7.4485e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9941 - bpp: 3.1817 - mse: 8.8498e-04\n",
      "Epoch 19: loss did not improve from 4.80181\n",
      "200/200 [==============================] - 63s 310ms/step - loss: 4.9941 - bpp: 3.1817 - mse: 8.8498e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8162 - bpp: 3.0813 - mse: 8.4715e-04\n",
      "Epoch 20: loss did not improve from 4.80181\n",
      "200/200 [==============================] - 62s 310ms/step - loss: 4.8162 - bpp: 3.0813 - mse: 8.4715e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6717 - bpp: 2.9854 - mse: 8.2338e-04\n",
      "Epoch 21: loss improved from 4.80181 to 4.67166, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 318ms/step - loss: 4.6717 - bpp: 2.9854 - mse: 8.2338e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2376 - bpp: 2.8884 - mse: 6.5880e-04\n",
      "Epoch 22: loss improved from 4.67166 to 4.23759, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 316ms/step - loss: 4.2376 - bpp: 2.8884 - mse: 6.5880e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3606 - bpp: 2.8097 - mse: 7.5726e-04\n",
      "Epoch 23: loss did not improve from 4.23759\n",
      "200/200 [==============================] - 62s 310ms/step - loss: 4.3606 - bpp: 2.8097 - mse: 7.5726e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4369 - bpp: 2.7254 - mse: 0.0013\n",
      "Epoch 24: loss did not improve from 4.23759\n",
      "200/200 [==============================] - 64s 303ms/step - loss: 5.4369 - bpp: 2.7254 - mse: 0.0013\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3228 - bpp: 2.6395 - mse: 8.2196e-04\n",
      "Epoch 25: loss did not improve from 4.23759\n",
      "200/200 [==============================] - 64s 314ms/step - loss: 4.3228 - bpp: 2.6395 - mse: 8.2196e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1456 - bpp: 2.5583 - mse: 7.7508e-04\n",
      "Epoch 26: loss improved from 4.23759 to 4.14564, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 4.1456 - bpp: 2.5583 - mse: 7.7508e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9636 - bpp: 2.4787 - mse: 7.2504e-04\n",
      "Epoch 27: loss improved from 4.14564 to 3.96361, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 315ms/step - loss: 3.9636 - bpp: 2.4787 - mse: 7.2504e-04\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7350 - bpp: 2.3961 - mse: 6.5373e-04\n",
      "Epoch 28: loss improved from 3.96361 to 3.73497, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 3.7350 - bpp: 2.3961 - mse: 6.5373e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2193 - bpp: 2.3244 - mse: 9.2524e-04\n",
      "Epoch 29: loss did not improve from 3.73497\n",
      "200/200 [==============================] - 63s 310ms/step - loss: 4.2193 - bpp: 2.3244 - mse: 9.2524e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8204 - bpp: 2.2496 - mse: 7.6698e-04\n",
      "Epoch 30: loss did not improve from 3.73497\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 3.8204 - bpp: 2.2496 - mse: 7.6698e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.5583 - bpp: 2.3090 - mse: 0.0055\n",
      "Epoch 31: loss did not improve from 3.73497\n",
      "200/200 [==============================] - 62s 306ms/step - loss: 13.5583 - bpp: 2.3090 - mse: 0.0055\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8056 - bpp: 2.2024 - mse: 0.0018\n",
      "Epoch 32: loss did not improve from 3.73497\n",
      "200/200 [==============================] - 60s 294ms/step - loss: 5.8056 - bpp: 2.2024 - mse: 0.0018\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6672 - bpp: 2.0862 - mse: 7.7198e-04\n",
      "Epoch 33: loss improved from 3.73497 to 3.66722, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 320ms/step - loss: 3.6672 - bpp: 2.0862 - mse: 7.7198e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3565 - bpp: 2.0047 - mse: 6.6003e-04\n",
      "Epoch 34: loss improved from 3.66722 to 3.35649, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 3.3565 - bpp: 2.0047 - mse: 6.6003e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2350 - bpp: 1.9365 - mse: 6.3404e-04\n",
      "Epoch 35: loss improved from 3.35649 to 3.23502, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 68s 337ms/step - loss: 3.2350 - bpp: 1.9365 - mse: 6.3404e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2356 - bpp: 1.8830 - mse: 6.6042e-04\n",
      "Epoch 36: loss did not improve from 3.23502\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 3.2356 - bpp: 1.8830 - mse: 6.6042e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1390 - bpp: 1.8190 - mse: 6.4454e-04\n",
      "Epoch 37: loss improved from 3.23502 to 3.13905, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 312ms/step - loss: 3.1390 - bpp: 1.8190 - mse: 6.4454e-04\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0958 - bpp: 1.7623 - mse: 6.5115e-04\n",
      "Epoch 38: loss improved from 3.13905 to 3.09581, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 313ms/step - loss: 3.0958 - bpp: 1.7623 - mse: 6.5115e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0319 - bpp: 1.6981 - mse: 6.5125e-04\n",
      "Epoch 39: loss improved from 3.09581 to 3.03188, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 67s 332ms/step - loss: 3.0319 - bpp: 1.6981 - mse: 6.5125e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2569 - bpp: 1.6767 - mse: 7.7157e-04\n",
      "Epoch 40: loss did not improve from 3.03188\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 3.2569 - bpp: 1.6767 - mse: 7.7157e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0646 - bpp: 1.6371 - mse: 6.9702e-04\n",
      "Epoch 41: loss did not improve from 3.03188\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 3.0646 - bpp: 1.6371 - mse: 6.9702e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9422 - bpp: 1.5713 - mse: 6.6939e-04\n",
      "Epoch 42: loss improved from 3.03188 to 2.94225, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 314ms/step - loss: 2.9422 - bpp: 1.5713 - mse: 6.6939e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9083 - bpp: 1.5249 - mse: 6.7546e-04\n",
      "Epoch 43: loss improved from 2.94225 to 2.90828, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 66s 326ms/step - loss: 2.9083 - bpp: 1.5249 - mse: 6.7546e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5046 - bpp: 1.4649 - mse: 5.0768e-04\n",
      "Epoch 44: loss improved from 2.90828 to 2.50459, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 64s 313ms/step - loss: 2.5046 - bpp: 1.4649 - mse: 5.0768e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7530 - bpp: 1.4508 - mse: 6.3587e-04\n",
      "Epoch 45: loss did not improve from 2.50459\n",
      "200/200 [==============================] - 61s 301ms/step - loss: 2.7530 - bpp: 1.4508 - mse: 6.3587e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9056 - bpp: 1.4207 - mse: 7.2504e-04\n",
      "Epoch 46: loss did not improve from 2.50459\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 2.9056 - bpp: 1.4207 - mse: 7.2504e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8211 - bpp: 1.3732 - mse: 7.0700e-04\n",
      "Epoch 47: loss did not improve from 2.50459\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 2.8211 - bpp: 1.3732 - mse: 7.0700e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6172 - bpp: 1.3331 - mse: 6.2704e-04\n",
      "Epoch 48: loss did not improve from 2.50459\n",
      "200/200 [==============================] - 61s 301ms/step - loss: 2.6172 - bpp: 1.3331 - mse: 6.2704e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7152 - bpp: 1.3103 - mse: 6.8599e-04\n",
      "Epoch 49: loss did not improve from 2.50459\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 2.7152 - bpp: 1.3103 - mse: 6.8599e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3644 - bpp: 1.2633 - mse: 5.3766e-04\n",
      "Epoch 50: loss improved from 2.50459 to 2.36441, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 296ms/step - loss: 2.3644 - bpp: 1.2633 - mse: 5.3766e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4855 - bpp: 1.2413 - mse: 6.0755e-04\n",
      "Epoch 51: loss did not improve from 2.36441\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 2.4855 - bpp: 1.2413 - mse: 6.0755e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6132 - bpp: 1.2388 - mse: 6.7109e-04\n",
      "Epoch 52: loss did not improve from 2.36441\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 2.6132 - bpp: 1.2388 - mse: 6.7109e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5811 - bpp: 1.2164 - mse: 6.6637e-04\n",
      "Epoch 53: loss did not improve from 2.36441\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 2.5811 - bpp: 1.2164 - mse: 6.6637e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1932 - bpp: 1.1514 - mse: 5.0867e-04\n",
      "Epoch 54: loss improved from 2.36441 to 2.19315, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 2.1932 - bpp: 1.1514 - mse: 5.0867e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4075 - bpp: 1.1494 - mse: 6.1432e-04\n",
      "Epoch 55: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 62s 307ms/step - loss: 2.4075 - bpp: 1.1494 - mse: 6.1432e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3094 - bpp: 1.1172 - mse: 5.8213e-04\n",
      "Epoch 56: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 61s 302ms/step - loss: 2.3094 - bpp: 1.1172 - mse: 5.8213e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2733 - bpp: 1.1091 - mse: 5.6844e-04\n",
      "Epoch 57: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 60s 296ms/step - loss: 2.2733 - bpp: 1.1091 - mse: 5.6844e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3929 - bpp: 1.1742 - mse: 0.0011\n",
      "Epoch 58: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 61s 302ms/step - loss: 3.3929 - bpp: 1.1742 - mse: 0.0011\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6031 - bpp: 1.1043 - mse: 7.3183e-04\n",
      "Epoch 59: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 2.6031 - bpp: 1.1043 - mse: 7.3183e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4277 - bpp: 1.0822 - mse: 6.5699e-04\n",
      "Epoch 60: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 2.4277 - bpp: 1.0822 - mse: 6.5699e-04\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3342 - bpp: 1.0772 - mse: 6.1379e-04\n",
      "Epoch 61: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 59s 290ms/step - loss: 2.3342 - bpp: 1.0772 - mse: 6.1379e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1593 - bpp: 1.0776 - mse: 0.0010\n",
      "Epoch 62: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 3.1593 - bpp: 1.0776 - mse: 0.0010\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2854 - bpp: 1.0324 - mse: 6.1181e-04\n",
      "Epoch 63: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 2.2854 - bpp: 1.0324 - mse: 6.1181e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4834 - bpp: 1.0389 - mse: 7.0533e-04\n",
      "Epoch 64: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 2.4834 - bpp: 1.0389 - mse: 7.0533e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2241 - bpp: 0.9976 - mse: 5.9887e-04\n",
      "Epoch 65: loss did not improve from 2.19315\n",
      "200/200 [==============================] - 61s 302ms/step - loss: 2.2241 - bpp: 0.9976 - mse: 5.9887e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1429 - bpp: 0.9680 - mse: 5.7369e-04\n",
      "Epoch 66: loss improved from 2.19315 to 2.14293, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 2.1429 - bpp: 0.9680 - mse: 5.7369e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5891 - bpp: 0.9990 - mse: 7.7639e-04\n",
      "Epoch 67: loss did not improve from 2.14293\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 2.5891 - bpp: 0.9990 - mse: 7.7639e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2337 - bpp: 0.9826 - mse: 6.1092e-04\n",
      "Epoch 68: loss did not improve from 2.14293\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 2.2337 - bpp: 0.9826 - mse: 6.1092e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1434 - bpp: 0.9551 - mse: 5.8022e-04\n",
      "Epoch 69: loss did not improve from 2.14293\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 2.1434 - bpp: 0.9551 - mse: 5.8022e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0928 - bpp: 0.9596 - mse: 5.5329e-04\n",
      "Epoch 70: loss improved from 2.14293 to 2.09277, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 2.0928 - bpp: 0.9596 - mse: 5.5329e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1391 - bpp: 0.9400 - mse: 5.8548e-04\n",
      "Epoch 71: loss did not improve from 2.09277\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 2.1391 - bpp: 0.9400 - mse: 5.8548e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1210 - bpp: 0.9352 - mse: 5.7900e-04\n",
      "Epoch 72: loss did not improve from 2.09277\n",
      "200/200 [==============================] - 59s 290ms/step - loss: 2.1210 - bpp: 0.9352 - mse: 5.7900e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2003 - bpp: 0.9298 - mse: 6.2036e-04\n",
      "Epoch 73: loss did not improve from 2.09277\n",
      "200/200 [==============================] - 61s 302ms/step - loss: 2.2003 - bpp: 0.9298 - mse: 6.2036e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2717 - bpp: 0.9964 - mse: 0.0011\n",
      "Epoch 74: loss did not improve from 2.09277\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 3.2717 - bpp: 0.9964 - mse: 0.0011\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3926 - bpp: 0.9438 - mse: 7.0744e-04\n",
      "Epoch 75: loss did not improve from 2.09277\n",
      "200/200 [==============================] - 58s 286ms/step - loss: 2.3926 - bpp: 0.9438 - mse: 7.0744e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9929 - bpp: 0.8894 - mse: 5.3885e-04\n",
      "Epoch 76: loss improved from 2.09277 to 1.99293, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 299ms/step - loss: 1.9929 - bpp: 0.8894 - mse: 5.3885e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9943 - bpp: 0.9009 - mse: 5.3389e-04\n",
      "Epoch 77: loss did not improve from 1.99293\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 1.9943 - bpp: 0.9009 - mse: 5.3389e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9564 - bpp: 0.8717 - mse: 5.2966e-04\n",
      "Epoch 78: loss improved from 1.99293 to 1.95639, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 299ms/step - loss: 1.9564 - bpp: 0.8717 - mse: 5.2966e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9956 - bpp: 0.8570 - mse: 5.5595e-04\n",
      "Epoch 79: loss did not improve from 1.95639\n",
      "200/200 [==============================] - 61s 299ms/step - loss: 1.9956 - bpp: 0.8570 - mse: 5.5595e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1914 - bpp: 0.8889 - mse: 6.3598e-04\n",
      "Epoch 80: loss did not improve from 1.95639\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 2.1914 - bpp: 0.8889 - mse: 6.3598e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1413 - bpp: 0.8846 - mse: 6.1363e-04\n",
      "Epoch 81: loss did not improve from 1.95639\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 2.1413 - bpp: 0.8846 - mse: 6.1363e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0030 - bpp: 0.8757 - mse: 5.5046e-04\n",
      "Epoch 82: loss did not improve from 1.95639\n",
      "200/200 [==============================] - 58s 287ms/step - loss: 2.0030 - bpp: 0.8757 - mse: 5.5046e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9366 - bpp: 0.8619 - mse: 5.2479e-04\n",
      "Epoch 83: loss improved from 1.95639 to 1.93664, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 296ms/step - loss: 1.9366 - bpp: 0.8619 - mse: 5.2479e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1173 - bpp: 0.9622 - mse: 0.0015\n",
      "Epoch 84: loss did not improve from 1.93664\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 4.1173 - bpp: 0.9622 - mse: 0.0015\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0096 - bpp: 0.8462 - mse: 5.6806e-04\n",
      "Epoch 85: loss did not improve from 1.93664\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 2.0096 - bpp: 0.8462 - mse: 5.6806e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9005 - bpp: 0.8371 - mse: 5.1927e-04\n",
      "Epoch 86: loss improved from 1.93664 to 1.90055, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 1.9005 - bpp: 0.8371 - mse: 5.1927e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9944 - bpp: 0.8591 - mse: 5.5433e-04\n",
      "Epoch 87: loss did not improve from 1.90055\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 1.9944 - bpp: 0.8591 - mse: 5.5433e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9074 - bpp: 0.8258 - mse: 5.2809e-04\n",
      "Epoch 88: loss did not improve from 1.90055\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 1.9074 - bpp: 0.8258 - mse: 5.2809e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8746 - bpp: 0.8344 - mse: 5.0795e-04\n",
      "Epoch 89: loss improved from 1.90055 to 1.87463, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 60s 296ms/step - loss: 1.8746 - bpp: 0.8344 - mse: 5.0795e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7735 - bpp: 0.8043 - mse: 4.7325e-04\n",
      "Epoch 90: loss improved from 1.87463 to 1.77354, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 1.7735 - bpp: 0.8043 - mse: 4.7325e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7443 - bpp: 0.8086 - mse: 4.5691e-04\n",
      "Epoch 91: loss improved from 1.77354 to 1.74433, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 1.7443 - bpp: 0.8086 - mse: 4.5691e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9621 - bpp: 0.8394 - mse: 5.4816e-04\n",
      "Epoch 92: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 64s 316ms/step - loss: 1.9621 - bpp: 0.8394 - mse: 5.4816e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9763 - bpp: 0.8079 - mse: 5.7051e-04\n",
      "Epoch 93: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 64s 316ms/step - loss: 1.9763 - bpp: 0.8079 - mse: 5.7051e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9717 - bpp: 0.8229 - mse: 5.6095e-04\n",
      "Epoch 94: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 62s 307ms/step - loss: 1.9717 - bpp: 0.8229 - mse: 5.6095e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0998 - bpp: 0.8343 - mse: 6.1790e-04\n",
      "Epoch 95: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 60s 301ms/step - loss: 2.0998 - bpp: 0.8343 - mse: 6.1790e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1259 - bpp: 0.8113 - mse: 6.4189e-04\n",
      "Epoch 96: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 65s 320ms/step - loss: 2.1259 - bpp: 0.8113 - mse: 6.4189e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7858 - bpp: 0.7803 - mse: 4.9096e-04\n",
      "Epoch 97: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 1.7858 - bpp: 0.7803 - mse: 4.9096e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8316 - bpp: 0.7881 - mse: 5.0948e-04\n",
      "Epoch 98: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 59s 291ms/step - loss: 1.8316 - bpp: 0.7881 - mse: 5.0948e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8736 - bpp: 0.7954 - mse: 5.2649e-04\n",
      "Epoch 99: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 1.8736 - bpp: 0.7954 - mse: 5.2649e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8318 - bpp: 0.7921 - mse: 5.0765e-04\n",
      "Epoch 100: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 63s 312ms/step - loss: 1.8318 - bpp: 0.7921 - mse: 5.0765e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0734 - bpp: 0.7958 - mse: 6.2384e-04\n",
      "Epoch 101: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 2.0734 - bpp: 0.7958 - mse: 6.2384e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8483 - bpp: 0.7781 - mse: 5.2258e-04\n",
      "Epoch 102: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 1.8483 - bpp: 0.7781 - mse: 5.2258e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7724 - bpp: 0.7516 - mse: 4.9842e-04\n",
      "Epoch 103: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 1.7724 - bpp: 0.7516 - mse: 4.9842e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9447 - bpp: 0.7613 - mse: 5.7781e-04\n",
      "Epoch 104: loss did not improve from 1.74433\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 1.9447 - bpp: 0.7613 - mse: 5.7781e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6696 - bpp: 0.7360 - mse: 4.5587e-04\n",
      "Epoch 105: loss improved from 1.74433 to 1.66960, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 61s 302ms/step - loss: 1.6696 - bpp: 0.7360 - mse: 4.5587e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8409 - bpp: 0.7587 - mse: 5.2841e-04\n",
      "Epoch 106: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 58s 286ms/step - loss: 1.8409 - bpp: 0.7587 - mse: 5.2841e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9515 - bpp: 0.7600 - mse: 5.8180e-04\n",
      "Epoch 107: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 60s 295ms/step - loss: 1.9515 - bpp: 0.7600 - mse: 5.8180e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8481 - bpp: 0.7495 - mse: 5.3642e-04\n",
      "Epoch 108: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 1.8481 - bpp: 0.7495 - mse: 5.3642e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7840 - bpp: 0.7471 - mse: 5.0630e-04\n",
      "Epoch 109: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 62s 307ms/step - loss: 1.7840 - bpp: 0.7471 - mse: 5.0630e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9000 - bpp: 0.7474 - mse: 5.6276e-04\n",
      "Epoch 110: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 57s 281ms/step - loss: 1.9000 - bpp: 0.7474 - mse: 5.6276e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8086 - bpp: 0.7376 - mse: 5.2293e-04\n",
      "Epoch 111: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 1.8086 - bpp: 0.7376 - mse: 5.2293e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7264 - bpp: 0.7286 - mse: 4.8718e-04\n",
      "Epoch 112: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.7264 - bpp: 0.7286 - mse: 4.8718e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7246 - bpp: 0.7322 - mse: 4.8458e-04\n",
      "Epoch 113: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 62s 307ms/step - loss: 1.7246 - bpp: 0.7322 - mse: 4.8458e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7607 - bpp: 0.7374 - mse: 4.9965e-04\n",
      "Epoch 114: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 1.7607 - bpp: 0.7374 - mse: 4.9965e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7616 - bpp: 0.7330 - mse: 5.0225e-04\n",
      "Epoch 115: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 1.7616 - bpp: 0.7330 - mse: 5.0225e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1719 - bpp: 0.7491 - mse: 6.9477e-04\n",
      "Epoch 116: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 58s 287ms/step - loss: 2.1719 - bpp: 0.7491 - mse: 6.9477e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7457 - bpp: 0.6975 - mse: 5.1183e-04\n",
      "Epoch 117: loss did not improve from 1.66960\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 1.7457 - bpp: 0.6975 - mse: 5.1183e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6113 - bpp: 0.6768 - mse: 4.5634e-04\n",
      "Epoch 118: loss improved from 1.66960 to 1.61134, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 311ms/step - loss: 1.6113 - bpp: 0.6768 - mse: 4.5634e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6772 - bpp: 0.6949 - mse: 4.7965e-04\n",
      "Epoch 119: loss did not improve from 1.61134\n",
      "200/200 [==============================] - 61s 297ms/step - loss: 1.6772 - bpp: 0.6949 - mse: 4.7965e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6215 - bpp: 0.6977 - mse: 4.5108e-04\n",
      "Epoch 120: loss did not improve from 1.61134\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 1.6215 - bpp: 0.6977 - mse: 4.5108e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9794 - bpp: 0.7123 - mse: 6.1870e-04\n",
      "Epoch 121: loss did not improve from 1.61134\n",
      "200/200 [==============================] - 60s 297ms/step - loss: 1.9794 - bpp: 0.7123 - mse: 6.1870e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6237 - bpp: 0.6854 - mse: 4.5814e-04\n",
      "Epoch 122: loss did not improve from 1.61134\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 1.6237 - bpp: 0.6854 - mse: 4.5814e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7129 - bpp: 0.7153 - mse: 4.8708e-04\n",
      "Epoch 123: loss did not improve from 1.61134\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 1.7129 - bpp: 0.7153 - mse: 4.8708e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5195 - bpp: 0.6762 - mse: 4.1178e-04\n",
      "Epoch 124: loss improved from 1.61134 to 1.51952, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 63s 312ms/step - loss: 1.5195 - bpp: 0.6762 - mse: 4.1178e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5824 - bpp: 0.6809 - mse: 4.4016e-04\n",
      "Epoch 125: loss did not improve from 1.51952\n",
      "200/200 [==============================] - 62s 305ms/step - loss: 1.5824 - bpp: 0.6809 - mse: 4.4016e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6902 - bpp: 0.6817 - mse: 4.9242e-04\n",
      "Epoch 126: loss did not improve from 1.51952\n",
      "200/200 [==============================] - 64s 316ms/step - loss: 1.6902 - bpp: 0.6817 - mse: 4.9242e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9372 - bpp: 0.6995 - mse: 6.0436e-04\n",
      "Epoch 127: loss did not improve from 1.51952\n",
      "200/200 [==============================] - 64s 317ms/step - loss: 1.9372 - bpp: 0.6995 - mse: 6.0436e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4915 - bpp: 0.6625 - mse: 4.0480e-04\n",
      "Epoch 128: loss improved from 1.51952 to 1.49153, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 61s 302ms/step - loss: 1.4915 - bpp: 0.6625 - mse: 4.0480e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5926 - bpp: 0.6764 - mse: 4.4737e-04\n",
      "Epoch 129: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 1.5926 - bpp: 0.6764 - mse: 4.4737e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7014 - bpp: 0.6676 - mse: 5.0478e-04\n",
      "Epoch 130: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7014 - bpp: 0.6676 - mse: 5.0478e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7323 - bpp: 0.6654 - mse: 5.2094e-04\n",
      "Epoch 131: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.7323 - bpp: 0.6654 - mse: 5.2094e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7000 - bpp: 0.6738 - mse: 5.0108e-04\n",
      "Epoch 132: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7000 - bpp: 0.6738 - mse: 5.0108e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6631 - bpp: 0.6630 - mse: 4.8833e-04\n",
      "Epoch 133: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6631 - bpp: 0.6630 - mse: 4.8833e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7129 - bpp: 0.6518 - mse: 5.1808e-04\n",
      "Epoch 134: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7129 - bpp: 0.6518 - mse: 5.1808e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5860 - bpp: 0.6469 - mse: 4.5851e-04\n",
      "Epoch 135: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.5860 - bpp: 0.6469 - mse: 4.5851e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6818 - bpp: 0.6791 - mse: 4.8963e-04\n",
      "Epoch 136: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6818 - bpp: 0.6791 - mse: 4.8963e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6551 - bpp: 0.6629 - mse: 4.8447e-04\n",
      "Epoch 137: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6551 - bpp: 0.6629 - mse: 4.8447e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7001 - bpp: 0.6659 - mse: 5.0496e-04\n",
      "Epoch 138: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.7001 - bpp: 0.6659 - mse: 5.0496e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5589 - bpp: 0.6567 - mse: 4.4056e-04\n",
      "Epoch 139: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5589 - bpp: 0.6567 - mse: 4.4056e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4982 - bpp: 0.6403 - mse: 4.1891e-04\n",
      "Epoch 140: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.4982 - bpp: 0.6403 - mse: 4.1891e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6866 - bpp: 0.6451 - mse: 5.0856e-04\n",
      "Epoch 141: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6866 - bpp: 0.6451 - mse: 5.0856e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6098 - bpp: 0.6420 - mse: 4.7257e-04\n",
      "Epoch 142: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6098 - bpp: 0.6420 - mse: 4.7257e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6724 - bpp: 0.6408 - mse: 5.0369e-04\n",
      "Epoch 143: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6724 - bpp: 0.6408 - mse: 5.0369e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5509 - bpp: 0.6379 - mse: 4.4581e-04\n",
      "Epoch 144: loss did not improve from 1.49153\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.5509 - bpp: 0.6379 - mse: 4.4581e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4752 - bpp: 0.6309 - mse: 4.1226e-04\n",
      "Epoch 145: loss improved from 1.49153 to 1.47523, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.4752 - bpp: 0.6309 - mse: 4.1226e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5496 - bpp: 0.6362 - mse: 4.4601e-04\n",
      "Epoch 146: loss did not improve from 1.47523\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.5496 - bpp: 0.6362 - mse: 4.4601e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6564 - bpp: 0.6468 - mse: 4.9300e-04\n",
      "Epoch 147: loss did not improve from 1.47523\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6564 - bpp: 0.6468 - mse: 4.9300e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4578 - bpp: 0.6195 - mse: 4.0928e-04\n",
      "Epoch 148: loss improved from 1.47523 to 1.45775, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.4578 - bpp: 0.6195 - mse: 4.0928e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6864 - bpp: 0.6401 - mse: 5.1091e-04\n",
      "Epoch 149: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6864 - bpp: 0.6401 - mse: 5.1091e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1915 - bpp: 0.6479 - mse: 7.5372e-04\n",
      "Epoch 150: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.1915 - bpp: 0.6479 - mse: 7.5372e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5088 - bpp: 0.6220 - mse: 4.3297e-04\n",
      "Epoch 151: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.5088 - bpp: 0.6220 - mse: 4.3297e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5287 - bpp: 0.6256 - mse: 4.4100e-04\n",
      "Epoch 152: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.5287 - bpp: 0.6256 - mse: 4.4100e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5529 - bpp: 0.6225 - mse: 4.5428e-04\n",
      "Epoch 153: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5529 - bpp: 0.6225 - mse: 4.5428e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4744 - bpp: 0.6093 - mse: 4.2240e-04\n",
      "Epoch 154: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.4744 - bpp: 0.6093 - mse: 4.2240e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5053 - bpp: 0.6247 - mse: 4.2999e-04\n",
      "Epoch 155: loss did not improve from 1.45775\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5053 - bpp: 0.6247 - mse: 4.2999e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4269 - bpp: 0.6188 - mse: 3.9461e-04\n",
      "Epoch 156: loss improved from 1.45775 to 1.42694, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.4269 - bpp: 0.6188 - mse: 3.9461e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4781 - bpp: 0.6111 - mse: 4.2336e-04\n",
      "Epoch 157: loss did not improve from 1.42694\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.4781 - bpp: 0.6111 - mse: 4.2336e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4318 - bpp: 0.6142 - mse: 3.9922e-04\n",
      "Epoch 158: loss did not improve from 1.42694\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.4318 - bpp: 0.6142 - mse: 3.9922e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5142 - bpp: 0.6319 - mse: 4.3083e-04\n",
      "Epoch 159: loss did not improve from 1.42694\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5142 - bpp: 0.6319 - mse: 4.3083e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3925 - bpp: 0.6039 - mse: 3.8509e-04\n",
      "Epoch 160: loss improved from 1.42694 to 1.39254, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.3925 - bpp: 0.6039 - mse: 3.8509e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4638 - bpp: 0.6035 - mse: 4.2007e-04\n",
      "Epoch 161: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4638 - bpp: 0.6035 - mse: 4.2007e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4769 - bpp: 0.6035 - mse: 4.2648e-04\n",
      "Epoch 162: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.4769 - bpp: 0.6035 - mse: 4.2648e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5188 - bpp: 0.6114 - mse: 4.4304e-04\n",
      "Epoch 163: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5188 - bpp: 0.6114 - mse: 4.4304e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5479 - bpp: 0.6172 - mse: 4.5445e-04\n",
      "Epoch 164: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5479 - bpp: 0.6172 - mse: 4.5445e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6862 - bpp: 0.6268 - mse: 5.1728e-04\n",
      "Epoch 165: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.6862 - bpp: 0.6268 - mse: 5.1728e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5726 - bpp: 0.6177 - mse: 4.6623e-04\n",
      "Epoch 166: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5726 - bpp: 0.6177 - mse: 4.6623e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4005 - bpp: 0.5982 - mse: 3.9175e-04\n",
      "Epoch 167: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4005 - bpp: 0.5982 - mse: 3.9175e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6405 - bpp: 0.6185 - mse: 4.9904e-04\n",
      "Epoch 168: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.6405 - bpp: 0.6185 - mse: 4.9904e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4262 - bpp: 0.5941 - mse: 4.0629e-04\n",
      "Epoch 169: loss did not improve from 1.39254\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.4262 - bpp: 0.5941 - mse: 4.0629e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3622 - bpp: 0.6009 - mse: 3.7173e-04\n",
      "Epoch 170: loss improved from 1.39254 to 1.36219, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.3622 - bpp: 0.6009 - mse: 3.7173e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5032 - bpp: 0.6192 - mse: 4.3164e-04\n",
      "Epoch 171: loss did not improve from 1.36219\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.5032 - bpp: 0.6192 - mse: 4.3164e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8561 - bpp: 0.6201 - mse: 6.0354e-04\n",
      "Epoch 172: loss did not improve from 1.36219\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.8561 - bpp: 0.6201 - mse: 6.0354e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4510 - bpp: 0.6017 - mse: 4.1469e-04\n",
      "Epoch 173: loss did not improve from 1.36219\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.4510 - bpp: 0.6017 - mse: 4.1469e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4619 - bpp: 0.6078 - mse: 4.1703e-04\n",
      "Epoch 174: loss did not improve from 1.36219\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.4619 - bpp: 0.6078 - mse: 4.1703e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3716 - bpp: 0.5844 - mse: 3.8439e-04\n",
      "Epoch 175: loss did not improve from 1.36219\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.3716 - bpp: 0.5844 - mse: 3.8439e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6787 - bpp: 0.6251 - mse: 5.1444e-04\n",
      "Epoch 176: loss did not improve from 1.36219\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6787 - bpp: 0.6251 - mse: 5.1444e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3539 - bpp: 0.5864 - mse: 3.7475e-04\n",
      "Epoch 177: loss improved from 1.36219 to 1.35393, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.3539 - bpp: 0.5864 - mse: 3.7475e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2203 - bpp: 0.5767 - mse: 3.1424e-04\n",
      "Epoch 178: loss improved from 1.35393 to 1.22027, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.2203 - bpp: 0.5767 - mse: 3.1424e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4415 - bpp: 0.6043 - mse: 4.0882e-04\n",
      "Epoch 179: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.4415 - bpp: 0.6043 - mse: 4.0882e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5537 - bpp: 0.6065 - mse: 4.6249e-04\n",
      "Epoch 180: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.5537 - bpp: 0.6065 - mse: 4.6249e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6690 - bpp: 0.6135 - mse: 5.1537e-04\n",
      "Epoch 181: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6690 - bpp: 0.6135 - mse: 5.1537e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3381 - bpp: 0.5841 - mse: 3.6816e-04\n",
      "Epoch 182: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.3381 - bpp: 0.5841 - mse: 3.6816e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4072 - bpp: 0.5889 - mse: 3.9957e-04\n",
      "Epoch 183: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.4072 - bpp: 0.5889 - mse: 3.9957e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3883 - bpp: 0.5928 - mse: 3.8843e-04\n",
      "Epoch 184: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.3883 - bpp: 0.5928 - mse: 3.8843e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0410 - bpp: 0.6031 - mse: 7.0209e-04\n",
      "Epoch 185: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0410 - bpp: 0.6031 - mse: 7.0209e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5435 - bpp: 0.6082 - mse: 4.5667e-04\n",
      "Epoch 186: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.5435 - bpp: 0.6082 - mse: 4.5667e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2837 - bpp: 0.5747 - mse: 3.4621e-04\n",
      "Epoch 187: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.2837 - bpp: 0.5747 - mse: 3.4621e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5103 - bpp: 0.5813 - mse: 4.5360e-04\n",
      "Epoch 188: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5103 - bpp: 0.5813 - mse: 4.5360e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4233 - bpp: 0.5854 - mse: 4.0910e-04\n",
      "Epoch 189: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4233 - bpp: 0.5854 - mse: 4.0910e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5144 - bpp: 0.5893 - mse: 4.5169e-04\n",
      "Epoch 190: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.5144 - bpp: 0.5893 - mse: 4.5169e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3151 - bpp: 0.5567 - mse: 3.7031e-04\n",
      "Epoch 191: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.3151 - bpp: 0.5567 - mse: 3.7031e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3781 - bpp: 0.5875 - mse: 3.8603e-04\n",
      "Epoch 192: loss did not improve from 1.22027\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.3781 - bpp: 0.5875 - mse: 3.8603e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1987 - bpp: 0.5554 - mse: 3.1408e-04\n",
      "Epoch 193: loss improved from 1.22027 to 1.19866, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1987 - bpp: 0.5554 - mse: 3.1408e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3069 - bpp: 0.5685 - mse: 3.6054e-04\n",
      "Epoch 194: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.3069 - bpp: 0.5685 - mse: 3.6054e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3587 - bpp: 0.5770 - mse: 3.8171e-04\n",
      "Epoch 195: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.3587 - bpp: 0.5770 - mse: 3.8171e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3013 - bpp: 0.5669 - mse: 3.5861e-04\n",
      "Epoch 196: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.3013 - bpp: 0.5669 - mse: 3.5861e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3949 - bpp: 0.6172 - mse: 8.6803e-04\n",
      "Epoch 197: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.3949 - bpp: 0.6172 - mse: 8.6803e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4283 - bpp: 0.6095 - mse: 3.9981e-04\n",
      "Epoch 198: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.4283 - bpp: 0.6095 - mse: 3.9981e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4130 - bpp: 0.5985 - mse: 3.9767e-04\n",
      "Epoch 199: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.4130 - bpp: 0.5985 - mse: 3.9767e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3212 - bpp: 0.5714 - mse: 3.6615e-04\n",
      "Epoch 200: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.3212 - bpp: 0.5714 - mse: 3.6615e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3869 - bpp: 0.5948 - mse: 3.8675e-04\n",
      "Epoch 201: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.3869 - bpp: 0.5948 - mse: 3.8675e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3160 - bpp: 0.5744 - mse: 3.6209e-04\n",
      "Epoch 202: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.3160 - bpp: 0.5744 - mse: 3.6209e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3501 - bpp: 0.5764 - mse: 3.7779e-04\n",
      "Epoch 203: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.3501 - bpp: 0.5764 - mse: 3.7779e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3152 - bpp: 0.5588 - mse: 3.6933e-04\n",
      "Epoch 204: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.3152 - bpp: 0.5588 - mse: 3.6933e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3873 - bpp: 0.5719 - mse: 3.9813e-04\n",
      "Epoch 205: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.3873 - bpp: 0.5719 - mse: 3.9813e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2239 - bpp: 0.5601 - mse: 3.2413e-04\n",
      "Epoch 206: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.2239 - bpp: 0.5601 - mse: 3.2413e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2083 - bpp: 0.5555 - mse: 3.1879e-04\n",
      "Epoch 207: loss did not improve from 1.19866\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.2083 - bpp: 0.5555 - mse: 3.1879e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1575 - bpp: 0.5440 - mse: 2.9954e-04\n",
      "Epoch 208: loss improved from 1.19866 to 1.15748, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1575 - bpp: 0.5440 - mse: 2.9954e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3077 - bpp: 0.5692 - mse: 3.6059e-04\n",
      "Epoch 209: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.3077 - bpp: 0.5692 - mse: 3.6059e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3423 - bpp: 0.5681 - mse: 3.7804e-04\n",
      "Epoch 210: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.3423 - bpp: 0.5681 - mse: 3.7804e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.5542 - mse: 3.6605e-04\n",
      "Epoch 211: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.3039 - bpp: 0.5542 - mse: 3.6605e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4007 - bpp: 0.5700 - mse: 4.0563e-04\n",
      "Epoch 212: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 1.4007 - bpp: 0.5700 - mse: 4.0563e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5117 - bpp: 0.5683 - mse: 4.6062e-04\n",
      "Epoch 213: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5117 - bpp: 0.5683 - mse: 4.6062e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2751 - bpp: 0.5630 - mse: 3.4771e-04\n",
      "Epoch 214: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.2751 - bpp: 0.5630 - mse: 3.4771e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3497 - bpp: 0.5689 - mse: 3.8126e-04\n",
      "Epoch 215: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.3497 - bpp: 0.5689 - mse: 3.8126e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1887 - bpp: 0.5430 - mse: 3.1529e-04\n",
      "Epoch 216: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.1887 - bpp: 0.5430 - mse: 3.1529e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3984 - bpp: 0.5610 - mse: 4.0890e-04\n",
      "Epoch 217: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.3984 - bpp: 0.5610 - mse: 4.0890e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3248 - bpp: 0.5580 - mse: 3.7442e-04\n",
      "Epoch 218: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.3248 - bpp: 0.5580 - mse: 3.7442e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2790 - bpp: 0.5619 - mse: 3.5012e-04\n",
      "Epoch 219: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 1.2790 - bpp: 0.5619 - mse: 3.5012e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2706 - bpp: 0.5600 - mse: 3.4696e-04\n",
      "Epoch 220: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.2706 - bpp: 0.5600 - mse: 3.4696e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2915 - bpp: 0.5685 - mse: 3.5302e-04\n",
      "Epoch 221: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.2915 - bpp: 0.5685 - mse: 3.5302e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2874 - bpp: 0.5532 - mse: 3.5847e-04\n",
      "Epoch 222: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.2874 - bpp: 0.5532 - mse: 3.5847e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2843 - bpp: 0.5483 - mse: 3.5936e-04\n",
      "Epoch 223: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.2843 - bpp: 0.5483 - mse: 3.5936e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2710 - bpp: 0.5486 - mse: 3.5272e-04\n",
      "Epoch 224: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.2710 - bpp: 0.5486 - mse: 3.5272e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3040 - bpp: 0.5550 - mse: 3.6573e-04\n",
      "Epoch 225: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.3040 - bpp: 0.5550 - mse: 3.6573e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3307 - bpp: 0.5607 - mse: 3.7598e-04\n",
      "Epoch 226: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.3307 - bpp: 0.5607 - mse: 3.7598e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2183 - bpp: 0.5384 - mse: 3.3201e-04\n",
      "Epoch 227: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2183 - bpp: 0.5384 - mse: 3.3201e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3052 - bpp: 0.5567 - mse: 3.6549e-04\n",
      "Epoch 228: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.3052 - bpp: 0.5567 - mse: 3.6549e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3631 - bpp: 0.5677 - mse: 3.8837e-04\n",
      "Epoch 229: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.3631 - bpp: 0.5677 - mse: 3.8837e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3237 - bpp: 0.5356 - mse: 3.8480e-04\n",
      "Epoch 230: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 1.3237 - bpp: 0.5356 - mse: 3.8480e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2407 - bpp: 0.5459 - mse: 3.3923e-04\n",
      "Epoch 231: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.2407 - bpp: 0.5459 - mse: 3.3923e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4403 - bpp: 0.5654 - mse: 4.2722e-04\n",
      "Epoch 232: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.4403 - bpp: 0.5654 - mse: 4.2722e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2902 - bpp: 0.5475 - mse: 3.6265e-04\n",
      "Epoch 233: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.2902 - bpp: 0.5475 - mse: 3.6265e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3735 - bpp: 0.5545 - mse: 3.9988e-04\n",
      "Epoch 234: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.3735 - bpp: 0.5545 - mse: 3.9988e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2651 - bpp: 0.5494 - mse: 3.4942e-04\n",
      "Epoch 235: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.2651 - bpp: 0.5494 - mse: 3.4942e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2335 - bpp: 0.5384 - mse: 3.3940e-04\n",
      "Epoch 236: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.2335 - bpp: 0.5384 - mse: 3.3940e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3775 - bpp: 0.5559 - mse: 4.0117e-04\n",
      "Epoch 237: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.3775 - bpp: 0.5559 - mse: 4.0117e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3566 - bpp: 0.5620 - mse: 3.8798e-04\n",
      "Epoch 238: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.3566 - bpp: 0.5620 - mse: 3.8798e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2683 - bpp: 0.5401 - mse: 3.5554e-04\n",
      "Epoch 239: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.2683 - bpp: 0.5401 - mse: 3.5554e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3184 - bpp: 0.5570 - mse: 3.7180e-04\n",
      "Epoch 240: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.3184 - bpp: 0.5570 - mse: 3.7180e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2175 - bpp: 0.5452 - mse: 3.2830e-04\n",
      "Epoch 241: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.2175 - bpp: 0.5452 - mse: 3.2830e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3424 - bpp: 0.5664 - mse: 3.7890e-04\n",
      "Epoch 242: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.3424 - bpp: 0.5664 - mse: 3.7890e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5249 - bpp: 0.5671 - mse: 4.6767e-04\n",
      "Epoch 243: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.5249 - bpp: 0.5671 - mse: 4.6767e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4203 - bpp: 0.5628 - mse: 4.1870e-04\n",
      "Epoch 244: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.4203 - bpp: 0.5628 - mse: 4.1870e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1972 - bpp: 0.5362 - mse: 3.2277e-04\n",
      "Epoch 245: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1972 - bpp: 0.5362 - mse: 3.2277e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3263 - bpp: 0.5447 - mse: 3.8160e-04\n",
      "Epoch 246: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.3263 - bpp: 0.5447 - mse: 3.8160e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2644 - bpp: 0.5455 - mse: 3.5103e-04\n",
      "Epoch 247: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.2644 - bpp: 0.5455 - mse: 3.5103e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2329 - bpp: 0.5340 - mse: 3.4127e-04\n",
      "Epoch 248: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.2329 - bpp: 0.5340 - mse: 3.4127e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3378 - bpp: 0.5528 - mse: 3.8331e-04\n",
      "Epoch 249: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.3378 - bpp: 0.5528 - mse: 3.8331e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3149 - bpp: 0.5492 - mse: 3.7392e-04\n",
      "Epoch 250: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.3149 - bpp: 0.5492 - mse: 3.7392e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2176 - bpp: 0.5260 - mse: 3.3772e-04\n",
      "Epoch 251: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.2176 - bpp: 0.5260 - mse: 3.3772e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2602 - bpp: 0.5530 - mse: 3.4530e-04\n",
      "Epoch 252: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.2602 - bpp: 0.5530 - mse: 3.4530e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3513 - bpp: 0.5609 - mse: 3.8594e-04\n",
      "Epoch 253: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.3513 - bpp: 0.5609 - mse: 3.8594e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2277 - bpp: 0.5466 - mse: 3.3256e-04\n",
      "Epoch 254: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.2277 - bpp: 0.5466 - mse: 3.3256e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4865 - bpp: 0.5624 - mse: 4.5121e-04\n",
      "Epoch 255: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.4865 - bpp: 0.5624 - mse: 4.5121e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3394 - bpp: 0.5579 - mse: 3.8161e-04\n",
      "Epoch 256: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.3394 - bpp: 0.5579 - mse: 3.8161e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2945 - bpp: 0.5645 - mse: 3.5643e-04\n",
      "Epoch 257: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2945 - bpp: 0.5645 - mse: 3.5643e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2255 - bpp: 0.5429 - mse: 3.3330e-04\n",
      "Epoch 258: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.2255 - bpp: 0.5429 - mse: 3.3330e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1751 - bpp: 0.5318 - mse: 3.1413e-04\n",
      "Epoch 259: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1751 - bpp: 0.5318 - mse: 3.1413e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2589 - bpp: 0.5313 - mse: 3.5530e-04\n",
      "Epoch 260: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.2589 - bpp: 0.5313 - mse: 3.5530e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2398 - bpp: 0.5391 - mse: 3.4215e-04\n",
      "Epoch 261: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.2398 - bpp: 0.5391 - mse: 3.4215e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2414 - bpp: 0.5374 - mse: 3.4375e-04\n",
      "Epoch 262: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.2414 - bpp: 0.5374 - mse: 3.4375e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2563 - bpp: 0.5497 - mse: 3.4505e-04\n",
      "Epoch 263: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2563 - bpp: 0.5497 - mse: 3.4505e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1673 - bpp: 0.5221 - mse: 3.1503e-04\n",
      "Epoch 264: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1673 - bpp: 0.5221 - mse: 3.1503e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2986 - bpp: 0.5424 - mse: 3.6927e-04\n",
      "Epoch 265: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.2986 - bpp: 0.5424 - mse: 3.6927e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2997 - bpp: 0.5511 - mse: 3.6551e-04\n",
      "Epoch 266: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2997 - bpp: 0.5511 - mse: 3.6551e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3878 - bpp: 0.5673 - mse: 4.0064e-04\n",
      "Epoch 267: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.3878 - bpp: 0.5673 - mse: 4.0064e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3476 - bpp: 0.5517 - mse: 3.8862e-04\n",
      "Epoch 268: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.3476 - bpp: 0.5517 - mse: 3.8862e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2517 - bpp: 0.5400 - mse: 3.4752e-04\n",
      "Epoch 269: loss did not improve from 1.15748\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2517 - bpp: 0.5400 - mse: 3.4752e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1490 - bpp: 0.5290 - mse: 3.0275e-04\n",
      "Epoch 270: loss improved from 1.15748 to 1.14901, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1490 - bpp: 0.5290 - mse: 3.0275e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3306 - bpp: 0.5508 - mse: 3.8077e-04\n",
      "Epoch 271: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.3306 - bpp: 0.5508 - mse: 3.8077e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2828 - bpp: 0.5406 - mse: 3.6244e-04\n",
      "Epoch 272: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.2828 - bpp: 0.5406 - mse: 3.6244e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2207 - bpp: 0.5416 - mse: 3.3159e-04\n",
      "Epoch 273: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.2207 - bpp: 0.5416 - mse: 3.3159e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3436 - bpp: 0.5481 - mse: 3.8844e-04\n",
      "Epoch 274: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.3436 - bpp: 0.5481 - mse: 3.8844e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2843 - bpp: 0.5558 - mse: 3.5569e-04\n",
      "Epoch 275: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2843 - bpp: 0.5558 - mse: 3.5569e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1997 - bpp: 0.5318 - mse: 3.2610e-04\n",
      "Epoch 276: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1997 - bpp: 0.5318 - mse: 3.2610e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1497 - bpp: 0.5255 - mse: 3.0480e-04\n",
      "Epoch 277: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 1.1497 - bpp: 0.5255 - mse: 3.0480e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1785 - bpp: 0.5356 - mse: 3.1391e-04\n",
      "Epoch 278: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1785 - bpp: 0.5356 - mse: 3.1391e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2114 - bpp: 0.5277 - mse: 3.3387e-04\n",
      "Epoch 279: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2114 - bpp: 0.5277 - mse: 3.3387e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2495 - bpp: 0.5400 - mse: 3.4644e-04\n",
      "Epoch 280: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 52s 250ms/step - loss: 1.2495 - bpp: 0.5400 - mse: 3.4644e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4579 - bpp: 0.5329 - mse: 4.5165e-04\n",
      "Epoch 281: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.4579 - bpp: 0.5329 - mse: 4.5165e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3315 - bpp: 0.5479 - mse: 3.8266e-04\n",
      "Epoch 282: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.3315 - bpp: 0.5479 - mse: 3.8266e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2039 - bpp: 0.5271 - mse: 3.3045e-04\n",
      "Epoch 283: loss did not improve from 1.14901\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2039 - bpp: 0.5271 - mse: 3.3045e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1476 - bpp: 0.5210 - mse: 3.0598e-04\n",
      "Epoch 284: loss improved from 1.14901 to 1.14761, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.1476 - bpp: 0.5210 - mse: 3.0598e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1907 - bpp: 0.5373 - mse: 3.1904e-04\n",
      "Epoch 285: loss did not improve from 1.14761\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.1907 - bpp: 0.5373 - mse: 3.1904e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2247 - bpp: 0.5376 - mse: 3.3554e-04\n",
      "Epoch 286: loss did not improve from 1.14761\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.2247 - bpp: 0.5376 - mse: 3.3554e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2766 - bpp: 0.5413 - mse: 3.5904e-04\n",
      "Epoch 287: loss did not improve from 1.14761\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.2766 - bpp: 0.5413 - mse: 3.5904e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2629 - bpp: 0.5432 - mse: 3.5143e-04\n",
      "Epoch 288: loss did not improve from 1.14761\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.2629 - bpp: 0.5432 - mse: 3.5143e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0672 - bpp: 0.5108 - mse: 2.7168e-04\n",
      "Epoch 289: loss improved from 1.14761 to 1.06720, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0672 - bpp: 0.5108 - mse: 2.7168e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1798 - bpp: 0.5252 - mse: 3.1963e-04\n",
      "Epoch 290: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.1798 - bpp: 0.5252 - mse: 3.1963e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1641 - bpp: 0.5211 - mse: 3.1394e-04\n",
      "Epoch 291: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.1641 - bpp: 0.5211 - mse: 3.1394e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2821 - bpp: 0.5365 - mse: 3.6402e-04\n",
      "Epoch 292: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.2821 - bpp: 0.5365 - mse: 3.6402e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2385 - bpp: 0.5298 - mse: 3.4604e-04\n",
      "Epoch 293: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.2385 - bpp: 0.5298 - mse: 3.4604e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2040 - bpp: 0.5393 - mse: 3.2455e-04\n",
      "Epoch 294: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.2040 - bpp: 0.5393 - mse: 3.2455e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2297 - bpp: 0.5369 - mse: 3.3832e-04\n",
      "Epoch 295: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.2297 - bpp: 0.5369 - mse: 3.3832e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1902 - bpp: 0.5282 - mse: 3.2321e-04\n",
      "Epoch 296: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1902 - bpp: 0.5282 - mse: 3.2321e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4468 - bpp: 0.5494 - mse: 4.3817e-04\n",
      "Epoch 297: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.4468 - bpp: 0.5494 - mse: 4.3817e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2798 - bpp: 0.5475 - mse: 3.5756e-04\n",
      "Epoch 298: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2798 - bpp: 0.5475 - mse: 3.5756e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3111 - bpp: 0.5486 - mse: 3.7233e-04\n",
      "Epoch 299: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.3111 - bpp: 0.5486 - mse: 3.7233e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3290 - bpp: 0.5406 - mse: 3.8496e-04\n",
      "Epoch 300: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.3290 - bpp: 0.5406 - mse: 3.8496e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2323 - bpp: 0.5454 - mse: 3.3541e-04\n",
      "Epoch 301: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.2323 - bpp: 0.5454 - mse: 3.3541e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2537 - bpp: 0.5488 - mse: 3.4421e-04\n",
      "Epoch 302: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2537 - bpp: 0.5488 - mse: 3.4421e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3396 - bpp: 0.5403 - mse: 3.9027e-04\n",
      "Epoch 303: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.3396 - bpp: 0.5403 - mse: 3.9027e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1972 - bpp: 0.5327 - mse: 3.2444e-04\n",
      "Epoch 304: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1972 - bpp: 0.5327 - mse: 3.2444e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1287 - bpp: 0.5237 - mse: 2.9541e-04\n",
      "Epoch 305: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1287 - bpp: 0.5237 - mse: 2.9541e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3009 - bpp: 0.5523 - mse: 3.6554e-04\n",
      "Epoch 306: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.3009 - bpp: 0.5523 - mse: 3.6554e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1892 - bpp: 0.5128 - mse: 3.3023e-04\n",
      "Epoch 307: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1892 - bpp: 0.5128 - mse: 3.3023e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3546 - bpp: 0.5380 - mse: 3.9872e-04\n",
      "Epoch 308: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.3546 - bpp: 0.5380 - mse: 3.9872e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1383 - bpp: 0.5286 - mse: 2.9768e-04\n",
      "Epoch 309: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1383 - bpp: 0.5286 - mse: 2.9768e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5272 - mse: 3.0698e-04\n",
      "Epoch 310: loss did not improve from 1.06720\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1559 - bpp: 0.5272 - mse: 3.0698e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0572 - bpp: 0.5127 - mse: 2.6591e-04\n",
      "Epoch 311: loss improved from 1.06720 to 1.05724, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0572 - bpp: 0.5127 - mse: 2.6591e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2039 - bpp: 0.5289 - mse: 3.2958e-04\n",
      "Epoch 312: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2039 - bpp: 0.5289 - mse: 3.2958e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1698 - bpp: 0.5353 - mse: 3.0978e-04\n",
      "Epoch 313: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.1698 - bpp: 0.5353 - mse: 3.0978e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1769 - bpp: 0.5335 - mse: 3.1419e-04\n",
      "Epoch 314: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1769 - bpp: 0.5335 - mse: 3.1419e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1119 - bpp: 0.5156 - mse: 2.9119e-04\n",
      "Epoch 315: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1119 - bpp: 0.5156 - mse: 2.9119e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3269 - bpp: 0.5299 - mse: 3.8915e-04\n",
      "Epoch 316: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.3269 - bpp: 0.5299 - mse: 3.8915e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0906 - bpp: 0.5169 - mse: 2.8016e-04\n",
      "Epoch 317: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0906 - bpp: 0.5169 - mse: 2.8016e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2238 - bpp: 0.5385 - mse: 3.3465e-04\n",
      "Epoch 318: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2238 - bpp: 0.5385 - mse: 3.3465e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2337 - bpp: 0.5371 - mse: 3.4014e-04\n",
      "Epoch 319: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2337 - bpp: 0.5371 - mse: 3.4014e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2149 - bpp: 0.5386 - mse: 3.3027e-04\n",
      "Epoch 320: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.2149 - bpp: 0.5386 - mse: 3.3027e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1278 - bpp: 0.5180 - mse: 2.9780e-04\n",
      "Epoch 321: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.1278 - bpp: 0.5180 - mse: 2.9780e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2594 - bpp: 0.5466 - mse: 3.4805e-04\n",
      "Epoch 322: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.2594 - bpp: 0.5466 - mse: 3.4805e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1550 - bpp: 0.5279 - mse: 3.0620e-04\n",
      "Epoch 323: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1550 - bpp: 0.5279 - mse: 3.0620e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1947 - bpp: 0.5322 - mse: 3.2345e-04\n",
      "Epoch 324: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1947 - bpp: 0.5322 - mse: 3.2345e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0958 - bpp: 0.5159 - mse: 2.8316e-04\n",
      "Epoch 325: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.0958 - bpp: 0.5159 - mse: 2.8316e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0896 - bpp: 0.5143 - mse: 2.8090e-04\n",
      "Epoch 326: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0896 - bpp: 0.5143 - mse: 2.8090e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4391 - bpp: 0.5392 - mse: 4.3941e-04\n",
      "Epoch 327: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.4391 - bpp: 0.5392 - mse: 4.3941e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2107 - bpp: 0.5347 - mse: 3.3010e-04\n",
      "Epoch 328: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2107 - bpp: 0.5347 - mse: 3.3010e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2120 - bpp: 0.5369 - mse: 3.2965e-04\n",
      "Epoch 329: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.2120 - bpp: 0.5369 - mse: 3.2965e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1919 - bpp: 0.5286 - mse: 3.2387e-04\n",
      "Epoch 330: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.1919 - bpp: 0.5286 - mse: 3.2387e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1996 - bpp: 0.5400 - mse: 3.2206e-04\n",
      "Epoch 331: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 252ms/step - loss: 1.1996 - bpp: 0.5400 - mse: 3.2206e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1365 - bpp: 0.5186 - mse: 3.0169e-04\n",
      "Epoch 332: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1365 - bpp: 0.5186 - mse: 3.0169e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1486 - bpp: 0.5240 - mse: 3.0498e-04\n",
      "Epoch 333: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1486 - bpp: 0.5240 - mse: 3.0498e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1703 - bpp: 0.5290 - mse: 3.1310e-04\n",
      "Epoch 334: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1703 - bpp: 0.5290 - mse: 3.1310e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1493 - bpp: 0.5238 - mse: 3.0539e-04\n",
      "Epoch 335: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1493 - bpp: 0.5238 - mse: 3.0539e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2224 - bpp: 0.5515 - mse: 3.2759e-04\n",
      "Epoch 336: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.2224 - bpp: 0.5515 - mse: 3.2759e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2901 - bpp: 0.5375 - mse: 3.6750e-04\n",
      "Epoch 337: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2901 - bpp: 0.5375 - mse: 3.6750e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1843 - bpp: 0.5272 - mse: 3.2086e-04\n",
      "Epoch 338: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1843 - bpp: 0.5272 - mse: 3.2086e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3519 - bpp: 0.5445 - mse: 3.9421e-04\n",
      "Epoch 339: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.3519 - bpp: 0.5445 - mse: 3.9421e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1737 - bpp: 0.5300 - mse: 3.1430e-04\n",
      "Epoch 340: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1737 - bpp: 0.5300 - mse: 3.1430e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1538 - bpp: 0.5298 - mse: 3.0466e-04\n",
      "Epoch 341: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.1538 - bpp: 0.5298 - mse: 3.0466e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0583 - bpp: 0.5099 - mse: 2.6780e-04\n",
      "Epoch 342: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0583 - bpp: 0.5099 - mse: 2.6780e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1537 - bpp: 0.5314 - mse: 3.0388e-04\n",
      "Epoch 343: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1537 - bpp: 0.5314 - mse: 3.0388e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1116 - bpp: 0.5132 - mse: 2.9218e-04\n",
      "Epoch 344: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1116 - bpp: 0.5132 - mse: 2.9218e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2571 - bpp: 0.5266 - mse: 3.5667e-04\n",
      "Epoch 345: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.2571 - bpp: 0.5266 - mse: 3.5667e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1739 - bpp: 0.5350 - mse: 3.1195e-04\n",
      "Epoch 346: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 1.1739 - bpp: 0.5350 - mse: 3.1195e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1152 - bpp: 0.5186 - mse: 2.9129e-04\n",
      "Epoch 347: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.1152 - bpp: 0.5186 - mse: 2.9129e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1939 - bpp: 0.5374 - mse: 3.2053e-04\n",
      "Epoch 348: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1939 - bpp: 0.5374 - mse: 3.2053e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2392 - bpp: 0.5298 - mse: 3.4639e-04\n",
      "Epoch 349: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2392 - bpp: 0.5298 - mse: 3.4639e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1096 - bpp: 0.5106 - mse: 2.9247e-04\n",
      "Epoch 350: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1096 - bpp: 0.5106 - mse: 2.9247e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2936 - bpp: 0.5471 - mse: 3.6452e-04\n",
      "Epoch 351: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.2936 - bpp: 0.5471 - mse: 3.6452e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.5334 - mse: 3.2389e-04\n",
      "Epoch 352: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1967 - bpp: 0.5334 - mse: 3.2389e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1798 - bpp: 0.5306 - mse: 3.1700e-04\n",
      "Epoch 353: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.1798 - bpp: 0.5306 - mse: 3.1700e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1776 - bpp: 0.5339 - mse: 3.1429e-04\n",
      "Epoch 354: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1776 - bpp: 0.5339 - mse: 3.1429e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4413 - bpp: 0.5384 - mse: 4.4089e-04\n",
      "Epoch 355: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.4413 - bpp: 0.5384 - mse: 4.4089e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2765 - bpp: 0.5437 - mse: 3.5779e-04\n",
      "Epoch 356: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2765 - bpp: 0.5437 - mse: 3.5779e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1701 - bpp: 0.5181 - mse: 3.1837e-04\n",
      "Epoch 357: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1701 - bpp: 0.5181 - mse: 3.1837e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1950 - bpp: 0.5231 - mse: 3.2809e-04\n",
      "Epoch 358: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1950 - bpp: 0.5231 - mse: 3.2809e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1862 - bpp: 0.5378 - mse: 3.1661e-04\n",
      "Epoch 359: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1862 - bpp: 0.5378 - mse: 3.1661e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1844 - bpp: 0.5350 - mse: 3.1708e-04\n",
      "Epoch 360: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1844 - bpp: 0.5350 - mse: 3.1708e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1247 - bpp: 0.5223 - mse: 2.9414e-04\n",
      "Epoch 361: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1247 - bpp: 0.5223 - mse: 2.9414e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1923 - bpp: 0.5349 - mse: 3.2101e-04\n",
      "Epoch 362: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.1923 - bpp: 0.5349 - mse: 3.2101e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0884 - bpp: 0.5215 - mse: 2.7681e-04\n",
      "Epoch 363: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0884 - bpp: 0.5215 - mse: 2.7681e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0769 - bpp: 0.5170 - mse: 2.7336e-04\n",
      "Epoch 364: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0769 - bpp: 0.5170 - mse: 2.7336e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1677 - bpp: 0.5289 - mse: 3.1194e-04\n",
      "Epoch 365: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1677 - bpp: 0.5289 - mse: 3.1194e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1100 - bpp: 0.5270 - mse: 2.8465e-04\n",
      "Epoch 366: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1100 - bpp: 0.5270 - mse: 2.8465e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2003 - bpp: 0.5279 - mse: 3.2835e-04\n",
      "Epoch 367: loss did not improve from 1.05724\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.2003 - bpp: 0.5279 - mse: 3.2835e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0469 - bpp: 0.5071 - mse: 2.6359e-04\n",
      "Epoch 368: loss improved from 1.05724 to 1.04689, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0469 - bpp: 0.5071 - mse: 2.6359e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0908 - bpp: 0.5166 - mse: 2.8036e-04\n",
      "Epoch 369: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.0908 - bpp: 0.5166 - mse: 2.8036e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2702 - bpp: 0.5384 - mse: 3.5733e-04\n",
      "Epoch 370: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.2702 - bpp: 0.5384 - mse: 3.5733e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1768 - bpp: 0.5252 - mse: 3.1817e-04\n",
      "Epoch 371: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1768 - bpp: 0.5252 - mse: 3.1817e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0612 - bpp: 0.5072 - mse: 2.7053e-04\n",
      "Epoch 372: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0612 - bpp: 0.5072 - mse: 2.7053e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0812 - bpp: 0.5109 - mse: 2.7847e-04\n",
      "Epoch 373: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0812 - bpp: 0.5109 - mse: 2.7847e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1913 - bpp: 0.5276 - mse: 3.2408e-04\n",
      "Epoch 374: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.1913 - bpp: 0.5276 - mse: 3.2408e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1710 - bpp: 0.5326 - mse: 3.1170e-04\n",
      "Epoch 375: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1710 - bpp: 0.5326 - mse: 3.1170e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2203 - bpp: 0.5243 - mse: 3.3988e-04\n",
      "Epoch 376: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2203 - bpp: 0.5243 - mse: 3.3988e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1707 - bpp: 0.5321 - mse: 3.1178e-04\n",
      "Epoch 377: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1707 - bpp: 0.5321 - mse: 3.1178e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2182 - bpp: 0.5342 - mse: 3.3397e-04\n",
      "Epoch 378: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.2182 - bpp: 0.5342 - mse: 3.3397e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0999 - bpp: 0.5062 - mse: 2.8993e-04\n",
      "Epoch 379: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0999 - bpp: 0.5062 - mse: 2.8993e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1721 - bpp: 0.5333 - mse: 3.1192e-04\n",
      "Epoch 380: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1721 - bpp: 0.5333 - mse: 3.1192e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1242 - bpp: 0.5253 - mse: 2.9245e-04\n",
      "Epoch 381: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1242 - bpp: 0.5253 - mse: 2.9245e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1361 - bpp: 0.5234 - mse: 2.9918e-04\n",
      "Epoch 382: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1361 - bpp: 0.5234 - mse: 2.9918e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1102 - bpp: 0.5170 - mse: 2.8964e-04\n",
      "Epoch 383: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1102 - bpp: 0.5170 - mse: 2.8964e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1572 - bpp: 0.5332 - mse: 3.0466e-04\n",
      "Epoch 384: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1572 - bpp: 0.5332 - mse: 3.0466e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1215 - bpp: 0.5312 - mse: 2.8824e-04\n",
      "Epoch 385: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1215 - bpp: 0.5312 - mse: 2.8824e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0950 - bpp: 0.5153 - mse: 2.8309e-04\n",
      "Epoch 386: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0950 - bpp: 0.5153 - mse: 2.8309e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2205 - bpp: 0.5379 - mse: 3.3331e-04\n",
      "Epoch 387: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 1.2205 - bpp: 0.5379 - mse: 3.3331e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1683 - bpp: 0.5292 - mse: 3.1207e-04\n",
      "Epoch 388: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1683 - bpp: 0.5292 - mse: 3.1207e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1684 - bpp: 0.5321 - mse: 3.1073e-04\n",
      "Epoch 389: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1684 - bpp: 0.5321 - mse: 3.1073e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2122 - bpp: 0.5302 - mse: 3.3302e-04\n",
      "Epoch 390: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.2122 - bpp: 0.5302 - mse: 3.3302e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1351 - bpp: 0.5251 - mse: 2.9784e-04\n",
      "Epoch 391: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1351 - bpp: 0.5251 - mse: 2.9784e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1449 - bpp: 0.5246 - mse: 3.0290e-04\n",
      "Epoch 392: loss did not improve from 1.04689\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1449 - bpp: 0.5246 - mse: 3.0290e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0366 - bpp: 0.5055 - mse: 2.5934e-04\n",
      "Epoch 393: loss improved from 1.04689 to 1.03663, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0366 - bpp: 0.5055 - mse: 2.5934e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1355 - bpp: 0.5223 - mse: 2.9945e-04\n",
      "Epoch 394: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.1355 - bpp: 0.5223 - mse: 2.9945e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1129 - bpp: 0.5231 - mse: 2.8799e-04\n",
      "Epoch 395: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1129 - bpp: 0.5231 - mse: 2.8799e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0614 - bpp: 0.5105 - mse: 2.6900e-04\n",
      "Epoch 396: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.0614 - bpp: 0.5105 - mse: 2.6900e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1231 - bpp: 0.5227 - mse: 2.9313e-04\n",
      "Epoch 397: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1231 - bpp: 0.5227 - mse: 2.9313e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2155 - bpp: 0.5333 - mse: 3.3309e-04\n",
      "Epoch 398: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.2155 - bpp: 0.5333 - mse: 3.3309e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2125 - bpp: 0.5358 - mse: 3.3042e-04\n",
      "Epoch 399: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.2125 - bpp: 0.5358 - mse: 3.3042e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1109 - bpp: 0.5092 - mse: 2.9379e-04\n",
      "Epoch 400: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1109 - bpp: 0.5092 - mse: 2.9379e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1686 - bpp: 0.5263 - mse: 3.1362e-04\n",
      "Epoch 401: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1686 - bpp: 0.5263 - mse: 3.1362e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1313 - bpp: 0.5098 - mse: 3.0348e-04\n",
      "Epoch 402: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1313 - bpp: 0.5098 - mse: 3.0348e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0568 - bpp: 0.5051 - mse: 2.6938e-04\n",
      "Epoch 403: loss did not improve from 1.03663\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0568 - bpp: 0.5051 - mse: 2.6938e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0138 - bpp: 0.5041 - mse: 2.4889e-04\n",
      "Epoch 404: loss improved from 1.03663 to 1.01382, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0138 - bpp: 0.5041 - mse: 2.4889e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1751 - bpp: 0.5277 - mse: 3.1611e-04\n",
      "Epoch 405: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1751 - bpp: 0.5277 - mse: 3.1611e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1289 - bpp: 0.5083 - mse: 3.0307e-04\n",
      "Epoch 406: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1289 - bpp: 0.5083 - mse: 3.0307e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2766 - bpp: 0.5425 - mse: 3.5847e-04\n",
      "Epoch 407: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.2766 - bpp: 0.5425 - mse: 3.5847e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1361 - bpp: 0.5168 - mse: 3.0239e-04\n",
      "Epoch 408: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.1361 - bpp: 0.5168 - mse: 3.0239e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2017 - bpp: 0.5394 - mse: 3.2335e-04\n",
      "Epoch 409: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.2017 - bpp: 0.5394 - mse: 3.2335e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1405 - bpp: 0.5225 - mse: 3.0173e-04\n",
      "Epoch 410: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1405 - bpp: 0.5225 - mse: 3.0173e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0796 - bpp: 0.5053 - mse: 2.8040e-04\n",
      "Epoch 411: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0796 - bpp: 0.5053 - mse: 2.8040e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1359 - bpp: 0.5217 - mse: 2.9990e-04\n",
      "Epoch 412: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1359 - bpp: 0.5217 - mse: 2.9990e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1140 - bpp: 0.5192 - mse: 2.9045e-04\n",
      "Epoch 413: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1140 - bpp: 0.5192 - mse: 2.9045e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1257 - bpp: 0.5287 - mse: 2.9150e-04\n",
      "Epoch 414: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1257 - bpp: 0.5287 - mse: 2.9150e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1653 - bpp: 0.5361 - mse: 3.0718e-04\n",
      "Epoch 415: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.1653 - bpp: 0.5361 - mse: 3.0718e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1045 - bpp: 0.5210 - mse: 2.8494e-04\n",
      "Epoch 416: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1045 - bpp: 0.5210 - mse: 2.8494e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1512 - bpp: 0.5267 - mse: 3.0491e-04\n",
      "Epoch 417: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1512 - bpp: 0.5267 - mse: 3.0491e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0897 - bpp: 0.5123 - mse: 2.8195e-04\n",
      "Epoch 418: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0897 - bpp: 0.5123 - mse: 2.8195e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1410 - bpp: 0.5272 - mse: 2.9971e-04\n",
      "Epoch 419: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1410 - bpp: 0.5272 - mse: 2.9971e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1385 - bpp: 0.5226 - mse: 3.0071e-04\n",
      "Epoch 420: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1385 - bpp: 0.5226 - mse: 3.0071e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1923 - bpp: 0.5208 - mse: 3.2789e-04\n",
      "Epoch 421: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1923 - bpp: 0.5208 - mse: 3.2789e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1463 - bpp: 0.5337 - mse: 2.9915e-04\n",
      "Epoch 422: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1463 - bpp: 0.5337 - mse: 2.9915e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1291 - bpp: 0.5230 - mse: 2.9596e-04\n",
      "Epoch 423: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1291 - bpp: 0.5230 - mse: 2.9596e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1738 - bpp: 0.5270 - mse: 3.1582e-04\n",
      "Epoch 424: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1738 - bpp: 0.5270 - mse: 3.1582e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0853 - bpp: 0.5079 - mse: 2.8195e-04\n",
      "Epoch 425: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0853 - bpp: 0.5079 - mse: 2.8195e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0664 - bpp: 0.5177 - mse: 2.6795e-04\n",
      "Epoch 426: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0664 - bpp: 0.5177 - mse: 2.6795e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1291 - bpp: 0.5218 - mse: 2.9655e-04\n",
      "Epoch 427: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1291 - bpp: 0.5218 - mse: 2.9655e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2138 - bpp: 0.5370 - mse: 3.3047e-04\n",
      "Epoch 428: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2138 - bpp: 0.5370 - mse: 3.3047e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1835 - bpp: 0.5305 - mse: 3.1888e-04\n",
      "Epoch 429: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1835 - bpp: 0.5305 - mse: 3.1888e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2161 - bpp: 0.5488 - mse: 3.2584e-04\n",
      "Epoch 430: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.2161 - bpp: 0.5488 - mse: 3.2584e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2130 - bpp: 0.5404 - mse: 3.2845e-04\n",
      "Epoch 431: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.2130 - bpp: 0.5404 - mse: 3.2845e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1341 - bpp: 0.5197 - mse: 3.0001e-04\n",
      "Epoch 432: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.1341 - bpp: 0.5197 - mse: 3.0001e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1556 - bpp: 0.5246 - mse: 3.0815e-04\n",
      "Epoch 433: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1556 - bpp: 0.5246 - mse: 3.0815e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1084 - bpp: 0.5157 - mse: 2.8942e-04\n",
      "Epoch 434: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1084 - bpp: 0.5157 - mse: 2.8942e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0426 - bpp: 0.5118 - mse: 2.5917e-04\n",
      "Epoch 435: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0426 - bpp: 0.5118 - mse: 2.5917e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1788 - bpp: 0.5190 - mse: 3.2218e-04\n",
      "Epoch 436: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1788 - bpp: 0.5190 - mse: 3.2218e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1024 - bpp: 0.5154 - mse: 2.8665e-04\n",
      "Epoch 437: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1024 - bpp: 0.5154 - mse: 2.8665e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0831 - bpp: 0.5176 - mse: 2.7609e-04\n",
      "Epoch 438: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0831 - bpp: 0.5176 - mse: 2.7609e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1095 - bpp: 0.5134 - mse: 2.9104e-04\n",
      "Epoch 439: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1095 - bpp: 0.5134 - mse: 2.9104e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0964 - bpp: 0.5204 - mse: 2.8127e-04\n",
      "Epoch 440: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0964 - bpp: 0.5204 - mse: 2.8127e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0568 - bpp: 0.5148 - mse: 2.6466e-04\n",
      "Epoch 441: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0568 - bpp: 0.5148 - mse: 2.6466e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0979 - bpp: 0.5126 - mse: 2.8578e-04\n",
      "Epoch 442: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0979 - bpp: 0.5126 - mse: 2.8578e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0611 - bpp: 0.5041 - mse: 2.7197e-04\n",
      "Epoch 443: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0611 - bpp: 0.5041 - mse: 2.7197e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.5156 - mse: 2.7660e-04\n",
      "Epoch 444: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0821 - bpp: 0.5156 - mse: 2.7660e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1515 - bpp: 0.5292 - mse: 3.0385e-04\n",
      "Epoch 445: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1515 - bpp: 0.5292 - mse: 3.0385e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0885 - bpp: 0.5082 - mse: 2.8334e-04\n",
      "Epoch 446: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0885 - bpp: 0.5082 - mse: 2.8334e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1037 - bpp: 0.5133 - mse: 2.8827e-04\n",
      "Epoch 447: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1037 - bpp: 0.5133 - mse: 2.8827e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0625 - bpp: 0.5032 - mse: 2.7310e-04\n",
      "Epoch 448: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0625 - bpp: 0.5032 - mse: 2.7310e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1022 - bpp: 0.5160 - mse: 2.8620e-04\n",
      "Epoch 449: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1022 - bpp: 0.5160 - mse: 2.8620e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1892 - bpp: 0.5326 - mse: 3.2058e-04\n",
      "Epoch 450: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1892 - bpp: 0.5326 - mse: 3.2058e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0720 - bpp: 0.5063 - mse: 2.7620e-04\n",
      "Epoch 451: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0720 - bpp: 0.5063 - mse: 2.7620e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0838 - bpp: 0.5089 - mse: 2.8075e-04\n",
      "Epoch 452: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0838 - bpp: 0.5089 - mse: 2.8075e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0415 - bpp: 0.5018 - mse: 2.6356e-04\n",
      "Epoch 453: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0415 - bpp: 0.5018 - mse: 2.6356e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5157 - mse: 2.9440e-04\n",
      "Epoch 454: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1186 - bpp: 0.5157 - mse: 2.9440e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0472 - bpp: 0.5044 - mse: 2.6503e-04\n",
      "Epoch 455: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0472 - bpp: 0.5044 - mse: 2.6503e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1750 - bpp: 0.5175 - mse: 3.2105e-04\n",
      "Epoch 456: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1750 - bpp: 0.5175 - mse: 3.2105e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1143 - bpp: 0.5133 - mse: 2.9347e-04\n",
      "Epoch 457: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1143 - bpp: 0.5133 - mse: 2.9347e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0298 - bpp: 0.5048 - mse: 2.5637e-04\n",
      "Epoch 458: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0298 - bpp: 0.5048 - mse: 2.5637e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0525 - bpp: 0.5052 - mse: 2.6726e-04\n",
      "Epoch 459: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0525 - bpp: 0.5052 - mse: 2.6726e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1314 - bpp: 0.5208 - mse: 2.9814e-04\n",
      "Epoch 460: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1314 - bpp: 0.5208 - mse: 2.9814e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1085 - bpp: 0.5237 - mse: 2.8556e-04\n",
      "Epoch 461: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1085 - bpp: 0.5237 - mse: 2.8556e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0996 - bpp: 0.5164 - mse: 2.8477e-04\n",
      "Epoch 462: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0996 - bpp: 0.5164 - mse: 2.8477e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1298 - bpp: 0.5242 - mse: 2.9569e-04\n",
      "Epoch 463: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1298 - bpp: 0.5242 - mse: 2.9569e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2997 - bpp: 0.5220 - mse: 3.7975e-04\n",
      "Epoch 464: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.2997 - bpp: 0.5220 - mse: 3.7975e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1132 - bpp: 0.5073 - mse: 2.9583e-04\n",
      "Epoch 465: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1132 - bpp: 0.5073 - mse: 2.9583e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1114 - bpp: 0.5157 - mse: 2.9089e-04\n",
      "Epoch 466: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1114 - bpp: 0.5157 - mse: 2.9089e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0906 - bpp: 0.5105 - mse: 2.8326e-04\n",
      "Epoch 467: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0906 - bpp: 0.5105 - mse: 2.8326e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0665 - bpp: 0.5091 - mse: 2.7220e-04\n",
      "Epoch 468: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0665 - bpp: 0.5091 - mse: 2.7220e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1547 - bpp: 0.5232 - mse: 3.0834e-04\n",
      "Epoch 469: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1547 - bpp: 0.5232 - mse: 3.0834e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1250 - bpp: 0.5137 - mse: 2.9849e-04\n",
      "Epoch 470: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1250 - bpp: 0.5137 - mse: 2.9849e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2580 - bpp: 0.5417 - mse: 3.4974e-04\n",
      "Epoch 471: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.2580 - bpp: 0.5417 - mse: 3.4974e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2613 - bpp: 0.5358 - mse: 3.5427e-04\n",
      "Epoch 472: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.2613 - bpp: 0.5358 - mse: 3.5427e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0217 - bpp: 0.4991 - mse: 2.5514e-04\n",
      "Epoch 473: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0217 - bpp: 0.4991 - mse: 2.5514e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1498 - bpp: 0.5223 - mse: 3.0640e-04\n",
      "Epoch 474: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1498 - bpp: 0.5223 - mse: 3.0640e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1071 - bpp: 0.5230 - mse: 2.8518e-04\n",
      "Epoch 475: loss did not improve from 1.01382\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1071 - bpp: 0.5230 - mse: 2.8518e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9390 - bpp: 0.4836 - mse: 2.2237e-04\n",
      "Epoch 476: loss improved from 1.01382 to 0.93904, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9390 - bpp: 0.4836 - mse: 2.2237e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1351 - bpp: 0.5136 - mse: 3.0350e-04\n",
      "Epoch 477: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.1351 - bpp: 0.5136 - mse: 3.0350e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2095 - bpp: 0.5210 - mse: 3.3620e-04\n",
      "Epoch 478: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.2095 - bpp: 0.5210 - mse: 3.3620e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0894 - bpp: 0.5142 - mse: 2.8084e-04\n",
      "Epoch 479: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0894 - bpp: 0.5142 - mse: 2.8084e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1389 - bpp: 0.5203 - mse: 3.0204e-04\n",
      "Epoch 480: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1389 - bpp: 0.5203 - mse: 3.0204e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1764 - bpp: 0.5219 - mse: 3.1957e-04\n",
      "Epoch 481: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1764 - bpp: 0.5219 - mse: 3.1957e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9546 - bpp: 0.4896 - mse: 2.2709e-04\n",
      "Epoch 482: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9546 - bpp: 0.4896 - mse: 2.2709e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1563 - bpp: 0.5049 - mse: 3.1806e-04\n",
      "Epoch 483: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1563 - bpp: 0.5049 - mse: 3.1806e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0668 - bpp: 0.5127 - mse: 2.7054e-04\n",
      "Epoch 484: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0668 - bpp: 0.5127 - mse: 2.7054e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0993 - bpp: 0.5167 - mse: 2.8448e-04\n",
      "Epoch 485: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0993 - bpp: 0.5167 - mse: 2.8448e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1056 - bpp: 0.5085 - mse: 2.9158e-04\n",
      "Epoch 486: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1056 - bpp: 0.5085 - mse: 2.9158e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0609 - bpp: 0.5037 - mse: 2.7208e-04\n",
      "Epoch 487: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0609 - bpp: 0.5037 - mse: 2.7208e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0880 - bpp: 0.5123 - mse: 2.8113e-04\n",
      "Epoch 488: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0880 - bpp: 0.5123 - mse: 2.8113e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1337 - bpp: 0.5209 - mse: 2.9922e-04\n",
      "Epoch 489: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1337 - bpp: 0.5209 - mse: 2.9922e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1121 - bpp: 0.5177 - mse: 2.9023e-04\n",
      "Epoch 490: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.1121 - bpp: 0.5177 - mse: 2.9023e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0443 - bpp: 0.5038 - mse: 2.6391e-04\n",
      "Epoch 491: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0443 - bpp: 0.5038 - mse: 2.6391e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0923 - bpp: 0.5158 - mse: 2.8150e-04\n",
      "Epoch 492: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0923 - bpp: 0.5158 - mse: 2.8150e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1176 - bpp: 0.5232 - mse: 2.9023e-04\n",
      "Epoch 493: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1176 - bpp: 0.5232 - mse: 2.9023e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1754 - bpp: 0.5353 - mse: 3.1255e-04\n",
      "Epoch 494: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.1754 - bpp: 0.5353 - mse: 3.1255e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2285 - bpp: 0.5348 - mse: 3.3872e-04\n",
      "Epoch 495: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.2285 - bpp: 0.5348 - mse: 3.3872e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0813 - bpp: 0.5206 - mse: 2.7379e-04\n",
      "Epoch 496: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0813 - bpp: 0.5206 - mse: 2.7379e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1002 - bpp: 0.4990 - mse: 2.9354e-04\n",
      "Epoch 497: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.1002 - bpp: 0.4990 - mse: 2.9354e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1059 - bpp: 0.5249 - mse: 2.8371e-04\n",
      "Epoch 498: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.1059 - bpp: 0.5249 - mse: 2.8371e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0265 - bpp: 0.5105 - mse: 2.5194e-04\n",
      "Epoch 499: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0265 - bpp: 0.5105 - mse: 2.5194e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0254 - bpp: 0.4967 - mse: 2.5818e-04\n",
      "Epoch 500: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0254 - bpp: 0.4967 - mse: 2.5818e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0327 - bpp: 0.5019 - mse: 2.5914e-04\n",
      "Epoch 501: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0327 - bpp: 0.5019 - mse: 2.5914e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0833 - bpp: 0.5076 - mse: 2.8112e-04\n",
      "Epoch 502: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0833 - bpp: 0.5076 - mse: 2.8112e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0868 - bpp: 0.5133 - mse: 2.8001e-04\n",
      "Epoch 503: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0868 - bpp: 0.5133 - mse: 2.8001e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0436 - bpp: 0.5003 - mse: 2.6527e-04\n",
      "Epoch 504: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0436 - bpp: 0.5003 - mse: 2.6527e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3618 - bpp: 0.5318 - mse: 4.0527e-04\n",
      "Epoch 505: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.3618 - bpp: 0.5318 - mse: 4.0527e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1334 - bpp: 0.5205 - mse: 2.9925e-04\n",
      "Epoch 506: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1334 - bpp: 0.5205 - mse: 2.9925e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0602 - bpp: 0.5148 - mse: 2.6633e-04\n",
      "Epoch 507: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0602 - bpp: 0.5148 - mse: 2.6633e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0456 - bpp: 0.5003 - mse: 2.6626e-04\n",
      "Epoch 508: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0456 - bpp: 0.5003 - mse: 2.6626e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0442 - bpp: 0.4966 - mse: 2.6736e-04\n",
      "Epoch 509: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0442 - bpp: 0.4966 - mse: 2.6736e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5007 - mse: 2.8778e-04\n",
      "Epoch 510: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0901 - bpp: 0.5007 - mse: 2.8778e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1216 - bpp: 0.5221 - mse: 2.9269e-04\n",
      "Epoch 511: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1216 - bpp: 0.5221 - mse: 2.9269e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1718 - bpp: 0.5268 - mse: 3.1493e-04\n",
      "Epoch 512: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1718 - bpp: 0.5268 - mse: 3.1493e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1067 - bpp: 0.5105 - mse: 2.9111e-04\n",
      "Epoch 513: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1067 - bpp: 0.5105 - mse: 2.9111e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1467 - bpp: 0.5290 - mse: 3.0160e-04\n",
      "Epoch 514: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1467 - bpp: 0.5290 - mse: 3.0160e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0358 - bpp: 0.5068 - mse: 2.5828e-04\n",
      "Epoch 515: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 238ms/step - loss: 1.0358 - bpp: 0.5068 - mse: 2.5828e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0312 - bpp: 0.5050 - mse: 2.5694e-04\n",
      "Epoch 516: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0312 - bpp: 0.5050 - mse: 2.5694e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0998 - bpp: 0.5180 - mse: 2.8412e-04\n",
      "Epoch 517: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.0998 - bpp: 0.5180 - mse: 2.8412e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0795 - bpp: 0.5067 - mse: 2.7968e-04\n",
      "Epoch 518: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0795 - bpp: 0.5067 - mse: 2.7968e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0557 - bpp: 0.5091 - mse: 2.6690e-04\n",
      "Epoch 519: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0557 - bpp: 0.5091 - mse: 2.6690e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0182 - bpp: 0.5012 - mse: 2.5244e-04\n",
      "Epoch 520: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.0182 - bpp: 0.5012 - mse: 2.5244e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1105 - bpp: 0.5267 - mse: 2.8505e-04\n",
      "Epoch 521: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1105 - bpp: 0.5267 - mse: 2.8505e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0375 - bpp: 0.4981 - mse: 2.6339e-04\n",
      "Epoch 522: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0375 - bpp: 0.4981 - mse: 2.6339e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1375 - bpp: 0.5249 - mse: 2.9911e-04\n",
      "Epoch 523: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1375 - bpp: 0.5249 - mse: 2.9911e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0659 - bpp: 0.5108 - mse: 2.7105e-04\n",
      "Epoch 524: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0659 - bpp: 0.5108 - mse: 2.7105e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0099 - bpp: 0.4989 - mse: 2.4954e-04\n",
      "Epoch 525: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 1.0099 - bpp: 0.4989 - mse: 2.4954e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1603 - bpp: 0.5239 - mse: 3.1071e-04\n",
      "Epoch 526: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1603 - bpp: 0.5239 - mse: 3.1071e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0662 - bpp: 0.5093 - mse: 2.7193e-04\n",
      "Epoch 527: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0662 - bpp: 0.5093 - mse: 2.7193e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.4988 - mse: 2.5865e-04\n",
      "Epoch 528: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0285 - bpp: 0.4988 - mse: 2.5865e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1514 - bpp: 0.5164 - mse: 3.1005e-04\n",
      "Epoch 529: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.1514 - bpp: 0.5164 - mse: 3.1005e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9938 - bpp: 0.4929 - mse: 2.4458e-04\n",
      "Epoch 530: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 0.9938 - bpp: 0.4929 - mse: 2.4458e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0987 - bpp: 0.5141 - mse: 2.8546e-04\n",
      "Epoch 531: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0987 - bpp: 0.5141 - mse: 2.8546e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0307 - bpp: 0.4938 - mse: 2.6218e-04\n",
      "Epoch 532: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0307 - bpp: 0.4938 - mse: 2.6218e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0278 - bpp: 0.5007 - mse: 2.5739e-04\n",
      "Epoch 533: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0278 - bpp: 0.5007 - mse: 2.5739e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9759 - bpp: 0.4909 - mse: 2.3684e-04\n",
      "Epoch 534: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9759 - bpp: 0.4909 - mse: 2.3684e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0363 - bpp: 0.4974 - mse: 2.6315e-04\n",
      "Epoch 535: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0363 - bpp: 0.4974 - mse: 2.6315e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1468 - bpp: 0.5234 - mse: 3.0443e-04\n",
      "Epoch 536: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.1468 - bpp: 0.5234 - mse: 3.0443e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0663 - bpp: 0.4975 - mse: 2.7773e-04\n",
      "Epoch 537: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0663 - bpp: 0.4975 - mse: 2.7773e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0869 - bpp: 0.5147 - mse: 2.7941e-04\n",
      "Epoch 538: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0869 - bpp: 0.5147 - mse: 2.7941e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0740 - bpp: 0.5066 - mse: 2.7704e-04\n",
      "Epoch 539: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0740 - bpp: 0.5066 - mse: 2.7704e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0934 - bpp: 0.5178 - mse: 2.8105e-04\n",
      "Epoch 540: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0934 - bpp: 0.5178 - mse: 2.8105e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5149 - mse: 2.6811e-04\n",
      "Epoch 541: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0640 - bpp: 0.5149 - mse: 2.6811e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0213 - bpp: 0.5007 - mse: 2.5420e-04\n",
      "Epoch 542: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0213 - bpp: 0.5007 - mse: 2.5420e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0931 - bpp: 0.5090 - mse: 2.8520e-04\n",
      "Epoch 543: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0931 - bpp: 0.5090 - mse: 2.8520e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0427 - bpp: 0.4993 - mse: 2.6535e-04\n",
      "Epoch 544: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0427 - bpp: 0.4993 - mse: 2.6535e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1002 - bpp: 0.5045 - mse: 2.9086e-04\n",
      "Epoch 545: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1002 - bpp: 0.5045 - mse: 2.9086e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0820 - bpp: 0.5051 - mse: 2.8170e-04\n",
      "Epoch 546: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.0820 - bpp: 0.5051 - mse: 2.8170e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0797 - bpp: 0.5110 - mse: 2.7768e-04\n",
      "Epoch 547: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.0797 - bpp: 0.5110 - mse: 2.7768e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1047 - bpp: 0.5063 - mse: 2.9220e-04\n",
      "Epoch 548: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.1047 - bpp: 0.5063 - mse: 2.9220e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1295 - bpp: 0.5140 - mse: 3.0054e-04\n",
      "Epoch 549: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1295 - bpp: 0.5140 - mse: 3.0054e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0375 - bpp: 0.5011 - mse: 2.6193e-04\n",
      "Epoch 550: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0375 - bpp: 0.5011 - mse: 2.6193e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0108 - bpp: 0.4962 - mse: 2.5124e-04\n",
      "Epoch 551: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0108 - bpp: 0.4962 - mse: 2.5124e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1101 - bpp: 0.5156 - mse: 2.9027e-04\n",
      "Epoch 552: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1101 - bpp: 0.5156 - mse: 2.9027e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1455 - bpp: 0.5229 - mse: 3.0402e-04\n",
      "Epoch 553: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.1455 - bpp: 0.5229 - mse: 3.0402e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1609 - bpp: 0.5193 - mse: 3.1331e-04\n",
      "Epoch 554: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1609 - bpp: 0.5193 - mse: 3.1331e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0258 - bpp: 0.4950 - mse: 2.5916e-04\n",
      "Epoch 555: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0258 - bpp: 0.4950 - mse: 2.5916e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0525 - bpp: 0.4993 - mse: 2.7015e-04\n",
      "Epoch 556: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0525 - bpp: 0.4993 - mse: 2.7015e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0628 - bpp: 0.5115 - mse: 2.6916e-04\n",
      "Epoch 557: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0628 - bpp: 0.5115 - mse: 2.6916e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0632 - bpp: 0.5047 - mse: 2.7269e-04\n",
      "Epoch 558: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.0632 - bpp: 0.5047 - mse: 2.7269e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9819 - bpp: 0.4830 - mse: 2.4360e-04\n",
      "Epoch 559: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9819 - bpp: 0.4830 - mse: 2.4360e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0446 - bpp: 0.5021 - mse: 2.6489e-04\n",
      "Epoch 560: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0446 - bpp: 0.5021 - mse: 2.6489e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0925 - bpp: 0.5139 - mse: 2.8253e-04\n",
      "Epoch 561: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0925 - bpp: 0.5139 - mse: 2.8253e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0368 - bpp: 0.5022 - mse: 2.6103e-04\n",
      "Epoch 562: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0368 - bpp: 0.5022 - mse: 2.6103e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1133 - bpp: 0.5084 - mse: 2.9539e-04\n",
      "Epoch 563: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1133 - bpp: 0.5084 - mse: 2.9539e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0707 - bpp: 0.4947 - mse: 2.8124e-04\n",
      "Epoch 564: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0707 - bpp: 0.4947 - mse: 2.8124e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1261 - bpp: 0.5235 - mse: 2.9424e-04\n",
      "Epoch 565: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1261 - bpp: 0.5235 - mse: 2.9424e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0571 - bpp: 0.5002 - mse: 2.7190e-04\n",
      "Epoch 566: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0571 - bpp: 0.5002 - mse: 2.7190e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0152 - bpp: 0.4978 - mse: 2.5266e-04\n",
      "Epoch 567: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0152 - bpp: 0.4978 - mse: 2.5266e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0275 - bpp: 0.4993 - mse: 2.5789e-04\n",
      "Epoch 568: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0275 - bpp: 0.4993 - mse: 2.5789e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9825 - bpp: 0.4952 - mse: 2.3796e-04\n",
      "Epoch 569: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.9825 - bpp: 0.4952 - mse: 2.3796e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0756 - bpp: 0.5191 - mse: 2.7174e-04\n",
      "Epoch 570: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0756 - bpp: 0.5191 - mse: 2.7174e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0967 - bpp: 0.5184 - mse: 2.8237e-04\n",
      "Epoch 571: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0967 - bpp: 0.5184 - mse: 2.8237e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0767 - bpp: 0.5051 - mse: 2.7910e-04\n",
      "Epoch 572: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0767 - bpp: 0.5051 - mse: 2.7910e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1077 - bpp: 0.5141 - mse: 2.8982e-04\n",
      "Epoch 573: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1077 - bpp: 0.5141 - mse: 2.8982e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0176 - bpp: 0.5023 - mse: 2.5161e-04\n",
      "Epoch 574: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0176 - bpp: 0.5023 - mse: 2.5161e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0743 - bpp: 0.5092 - mse: 2.7592e-04\n",
      "Epoch 575: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0743 - bpp: 0.5092 - mse: 2.7592e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0604 - bpp: 0.5107 - mse: 2.6840e-04\n",
      "Epoch 576: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0604 - bpp: 0.5107 - mse: 2.6840e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5012 - mse: 2.6171e-04\n",
      "Epoch 577: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0372 - bpp: 0.5012 - mse: 2.6171e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0554 - bpp: 0.5004 - mse: 2.7099e-04\n",
      "Epoch 578: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0554 - bpp: 0.5004 - mse: 2.7099e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0054 - bpp: 0.4935 - mse: 2.4996e-04\n",
      "Epoch 579: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0054 - bpp: 0.4935 - mse: 2.4996e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0989 - bpp: 0.5119 - mse: 2.8664e-04\n",
      "Epoch 580: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0989 - bpp: 0.5119 - mse: 2.8664e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9618 - bpp: 0.4908 - mse: 2.2995e-04\n",
      "Epoch 581: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9618 - bpp: 0.4908 - mse: 2.2995e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0743 - bpp: 0.5074 - mse: 2.7681e-04\n",
      "Epoch 582: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0743 - bpp: 0.5074 - mse: 2.7681e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0534 - bpp: 0.5046 - mse: 2.6797e-04\n",
      "Epoch 583: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0534 - bpp: 0.5046 - mse: 2.6797e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2615 - bpp: 0.5347 - mse: 3.5487e-04\n",
      "Epoch 584: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.2615 - bpp: 0.5347 - mse: 3.5487e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1339 - bpp: 0.5117 - mse: 3.0381e-04\n",
      "Epoch 585: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1339 - bpp: 0.5117 - mse: 3.0381e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9992 - bpp: 0.4934 - mse: 2.4697e-04\n",
      "Epoch 586: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9992 - bpp: 0.4934 - mse: 2.4697e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0016 - bpp: 0.4954 - mse: 2.4718e-04\n",
      "Epoch 587: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0016 - bpp: 0.4954 - mse: 2.4718e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9806 - bpp: 0.4900 - mse: 2.3956e-04\n",
      "Epoch 588: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9806 - bpp: 0.4900 - mse: 2.3956e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0623 - bpp: 0.5024 - mse: 2.7340e-04\n",
      "Epoch 589: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0623 - bpp: 0.5024 - mse: 2.7340e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0435 - bpp: 0.5072 - mse: 2.6183e-04\n",
      "Epoch 590: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0435 - bpp: 0.5072 - mse: 2.6183e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9932 - bpp: 0.4905 - mse: 2.4546e-04\n",
      "Epoch 591: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9932 - bpp: 0.4905 - mse: 2.4546e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0185 - bpp: 0.4907 - mse: 2.5770e-04\n",
      "Epoch 592: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0185 - bpp: 0.4907 - mse: 2.5770e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1288 - bpp: 0.5151 - mse: 2.9969e-04\n",
      "Epoch 593: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1288 - bpp: 0.5151 - mse: 2.9969e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0436 - bpp: 0.5041 - mse: 2.6343e-04\n",
      "Epoch 594: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0436 - bpp: 0.5041 - mse: 2.6343e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0906 - bpp: 0.5052 - mse: 2.8581e-04\n",
      "Epoch 595: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0906 - bpp: 0.5052 - mse: 2.8581e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0912 - bpp: 0.5102 - mse: 2.8370e-04\n",
      "Epoch 596: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0912 - bpp: 0.5102 - mse: 2.8370e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0645 - bpp: 0.5028 - mse: 2.7428e-04\n",
      "Epoch 597: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0645 - bpp: 0.5028 - mse: 2.7428e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9579 - bpp: 0.4867 - mse: 2.3006e-04\n",
      "Epoch 598: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9579 - bpp: 0.4867 - mse: 2.3006e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9840 - bpp: 0.4864 - mse: 2.4293e-04\n",
      "Epoch 599: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 0.9840 - bpp: 0.4864 - mse: 2.4293e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0373 - bpp: 0.5003 - mse: 2.6221e-04\n",
      "Epoch 600: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0373 - bpp: 0.5003 - mse: 2.6221e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9917 - bpp: 0.4927 - mse: 2.4369e-04\n",
      "Epoch 601: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9917 - bpp: 0.4927 - mse: 2.4369e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9975 - bpp: 0.4874 - mse: 2.4907e-04\n",
      "Epoch 602: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.9975 - bpp: 0.4874 - mse: 2.4907e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9731 - bpp: 0.4855 - mse: 2.3808e-04\n",
      "Epoch 603: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9731 - bpp: 0.4855 - mse: 2.3808e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0573 - bpp: 0.5000 - mse: 2.7215e-04\n",
      "Epoch 604: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0573 - bpp: 0.5000 - mse: 2.7215e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1359 - bpp: 0.5246 - mse: 2.9850e-04\n",
      "Epoch 605: loss did not improve from 0.93904\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1359 - bpp: 0.5246 - mse: 2.9850e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9120 - bpp: 0.4748 - mse: 2.1348e-04\n",
      "Epoch 606: loss improved from 0.93904 to 0.91205, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9120 - bpp: 0.4748 - mse: 2.1348e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0430 - bpp: 0.4943 - mse: 2.6792e-04\n",
      "Epoch 607: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0430 - bpp: 0.4943 - mse: 2.6792e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1457 - bpp: 0.5094 - mse: 3.1069e-04\n",
      "Epoch 608: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1457 - bpp: 0.5094 - mse: 3.1069e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9437 - bpp: 0.4773 - mse: 2.2778e-04\n",
      "Epoch 609: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9437 - bpp: 0.4773 - mse: 2.2778e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0399 - bpp: 0.5036 - mse: 2.6185e-04\n",
      "Epoch 610: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0399 - bpp: 0.5036 - mse: 2.6185e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0878 - bpp: 0.5045 - mse: 2.8480e-04\n",
      "Epoch 611: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0878 - bpp: 0.5045 - mse: 2.8480e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0402 - bpp: 0.4984 - mse: 2.6455e-04\n",
      "Epoch 612: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0402 - bpp: 0.4984 - mse: 2.6455e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1453 - bpp: 0.5229 - mse: 3.0389e-04\n",
      "Epoch 613: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1453 - bpp: 0.5229 - mse: 3.0389e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0837 - bpp: 0.5075 - mse: 2.8134e-04\n",
      "Epoch 614: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0837 - bpp: 0.5075 - mse: 2.8134e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9985 - bpp: 0.4929 - mse: 2.4688e-04\n",
      "Epoch 615: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9985 - bpp: 0.4929 - mse: 2.4688e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0254 - bpp: 0.4972 - mse: 2.5790e-04\n",
      "Epoch 616: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0254 - bpp: 0.4972 - mse: 2.5790e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1115 - bpp: 0.5150 - mse: 2.9123e-04\n",
      "Epoch 617: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1115 - bpp: 0.5150 - mse: 2.9123e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1012 - bpp: 0.5045 - mse: 2.9134e-04\n",
      "Epoch 618: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.1012 - bpp: 0.5045 - mse: 2.9134e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0307 - bpp: 0.5004 - mse: 2.5896e-04\n",
      "Epoch 619: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0307 - bpp: 0.5004 - mse: 2.5896e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1703 - bpp: 0.5189 - mse: 3.1803e-04\n",
      "Epoch 620: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.1703 - bpp: 0.5189 - mse: 3.1803e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9893 - bpp: 0.4879 - mse: 2.4482e-04\n",
      "Epoch 621: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9893 - bpp: 0.4879 - mse: 2.4482e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9838 - bpp: 0.4913 - mse: 2.4048e-04\n",
      "Epoch 622: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 0.9838 - bpp: 0.4913 - mse: 2.4048e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0284 - bpp: 0.5009 - mse: 2.5757e-04\n",
      "Epoch 623: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0284 - bpp: 0.5009 - mse: 2.5757e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9911 - bpp: 0.4847 - mse: 2.4727e-04\n",
      "Epoch 624: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9911 - bpp: 0.4847 - mse: 2.4727e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0619 - bpp: 0.5011 - mse: 2.7378e-04\n",
      "Epoch 625: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0619 - bpp: 0.5011 - mse: 2.7378e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1304 - bpp: 0.5230 - mse: 2.9657e-04\n",
      "Epoch 626: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1304 - bpp: 0.5230 - mse: 2.9657e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1245 - bpp: 0.5122 - mse: 2.9893e-04\n",
      "Epoch 627: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1245 - bpp: 0.5122 - mse: 2.9893e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0802 - bpp: 0.5057 - mse: 2.8051e-04\n",
      "Epoch 628: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0802 - bpp: 0.5057 - mse: 2.8051e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1419 - bpp: 0.5214 - mse: 3.0298e-04\n",
      "Epoch 629: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1419 - bpp: 0.5214 - mse: 3.0298e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0398 - bpp: 0.5016 - mse: 2.6279e-04\n",
      "Epoch 630: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0398 - bpp: 0.5016 - mse: 2.6279e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0137 - bpp: 0.4958 - mse: 2.5291e-04\n",
      "Epoch 631: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0137 - bpp: 0.4958 - mse: 2.5291e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9868 - bpp: 0.4825 - mse: 2.4628e-04\n",
      "Epoch 632: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 0.9868 - bpp: 0.4825 - mse: 2.4628e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1140 - bpp: 0.5173 - mse: 2.9137e-04\n",
      "Epoch 633: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1140 - bpp: 0.5173 - mse: 2.9137e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0439 - bpp: 0.4968 - mse: 2.6715e-04\n",
      "Epoch 634: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0439 - bpp: 0.4968 - mse: 2.6715e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9937 - bpp: 0.4941 - mse: 2.4394e-04\n",
      "Epoch 635: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9937 - bpp: 0.4941 - mse: 2.4394e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0120 - bpp: 0.4962 - mse: 2.5187e-04\n",
      "Epoch 636: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0120 - bpp: 0.4962 - mse: 2.5187e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9657 - bpp: 0.4799 - mse: 2.3719e-04\n",
      "Epoch 637: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9657 - bpp: 0.4799 - mse: 2.3719e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0310 - bpp: 0.4870 - mse: 2.6566e-04\n",
      "Epoch 638: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0310 - bpp: 0.4870 - mse: 2.6566e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9782 - bpp: 0.4815 - mse: 2.4252e-04\n",
      "Epoch 639: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9782 - bpp: 0.4815 - mse: 2.4252e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9839 - bpp: 0.4867 - mse: 2.4273e-04\n",
      "Epoch 640: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9839 - bpp: 0.4867 - mse: 2.4273e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9930 - bpp: 0.4881 - mse: 2.4655e-04\n",
      "Epoch 641: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9930 - bpp: 0.4881 - mse: 2.4655e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0997 - bpp: 0.5134 - mse: 2.8629e-04\n",
      "Epoch 642: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0997 - bpp: 0.5134 - mse: 2.8629e-04\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0446 - bpp: 0.5055 - mse: 2.6328e-04\n",
      "Epoch 643: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0446 - bpp: 0.5055 - mse: 2.6328e-04\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0498 - bpp: 0.5039 - mse: 2.6653e-04\n",
      "Epoch 644: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.0498 - bpp: 0.5039 - mse: 2.6653e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0420 - bpp: 0.5067 - mse: 2.6135e-04\n",
      "Epoch 645: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 258ms/step - loss: 1.0420 - bpp: 0.5067 - mse: 2.6135e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0271 - bpp: 0.4959 - mse: 2.5937e-04\n",
      "Epoch 646: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0271 - bpp: 0.4959 - mse: 2.5937e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9944 - bpp: 0.4856 - mse: 2.4842e-04\n",
      "Epoch 647: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9944 - bpp: 0.4856 - mse: 2.4842e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0928 - bpp: 0.5119 - mse: 2.8362e-04\n",
      "Epoch 648: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0928 - bpp: 0.5119 - mse: 2.8362e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0560 - bpp: 0.4912 - mse: 2.7581e-04\n",
      "Epoch 649: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0560 - bpp: 0.4912 - mse: 2.7581e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1268 - bpp: 0.5127 - mse: 2.9982e-04\n",
      "Epoch 650: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1268 - bpp: 0.5127 - mse: 2.9982e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9369 - bpp: 0.4772 - mse: 2.2446e-04\n",
      "Epoch 651: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9369 - bpp: 0.4772 - mse: 2.2446e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0150 - bpp: 0.4903 - mse: 2.5619e-04\n",
      "Epoch 652: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0150 - bpp: 0.4903 - mse: 2.5619e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0935 - bpp: 0.5096 - mse: 2.8514e-04\n",
      "Epoch 653: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.0935 - bpp: 0.5096 - mse: 2.8514e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0724 - bpp: 0.5058 - mse: 2.7667e-04\n",
      "Epoch 654: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0724 - bpp: 0.5058 - mse: 2.7667e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9640 - bpp: 0.4832 - mse: 2.3481e-04\n",
      "Epoch 655: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9640 - bpp: 0.4832 - mse: 2.3481e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9650 - bpp: 0.4860 - mse: 2.3388e-04\n",
      "Epoch 656: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9650 - bpp: 0.4860 - mse: 2.3388e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0117 - bpp: 0.4975 - mse: 2.5105e-04\n",
      "Epoch 657: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0117 - bpp: 0.4975 - mse: 2.5105e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9829 - bpp: 0.4850 - mse: 2.4310e-04\n",
      "Epoch 658: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9829 - bpp: 0.4850 - mse: 2.4310e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0247 - bpp: 0.4923 - mse: 2.5993e-04\n",
      "Epoch 659: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0247 - bpp: 0.4923 - mse: 2.5993e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0015 - bpp: 0.4934 - mse: 2.4807e-04\n",
      "Epoch 660: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0015 - bpp: 0.4934 - mse: 2.4807e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0003 - bpp: 0.4940 - mse: 2.4722e-04\n",
      "Epoch 661: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0003 - bpp: 0.4940 - mse: 2.4722e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0555 - bpp: 0.5020 - mse: 2.7027e-04\n",
      "Epoch 662: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.0555 - bpp: 0.5020 - mse: 2.7027e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9998 - bpp: 0.4860 - mse: 2.5086e-04\n",
      "Epoch 663: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9998 - bpp: 0.4860 - mse: 2.5086e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0155 - bpp: 0.4968 - mse: 2.5326e-04\n",
      "Epoch 664: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0155 - bpp: 0.4968 - mse: 2.5326e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9916 - bpp: 0.4863 - mse: 2.4672e-04\n",
      "Epoch 665: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9916 - bpp: 0.4863 - mse: 2.4672e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0425 - bpp: 0.4953 - mse: 2.6716e-04\n",
      "Epoch 666: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0425 - bpp: 0.4953 - mse: 2.6716e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1364 - bpp: 0.5075 - mse: 3.0707e-04\n",
      "Epoch 667: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.1364 - bpp: 0.5075 - mse: 3.0707e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0772 - bpp: 0.5034 - mse: 2.8015e-04\n",
      "Epoch 668: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.0772 - bpp: 0.5034 - mse: 2.8015e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0289 - bpp: 0.5026 - mse: 2.5697e-04\n",
      "Epoch 669: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0289 - bpp: 0.5026 - mse: 2.5697e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9914 - bpp: 0.4858 - mse: 2.4689e-04\n",
      "Epoch 670: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9914 - bpp: 0.4858 - mse: 2.4689e-04\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9492 - bpp: 0.4782 - mse: 2.2996e-04\n",
      "Epoch 671: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9492 - bpp: 0.4782 - mse: 2.2996e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0914 - bpp: 0.5020 - mse: 2.8779e-04\n",
      "Epoch 672: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0914 - bpp: 0.5020 - mse: 2.8779e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1594 - bpp: 0.5262 - mse: 3.0919e-04\n",
      "Epoch 673: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1594 - bpp: 0.5262 - mse: 3.0919e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0023 - bpp: 0.4901 - mse: 2.5013e-04\n",
      "Epoch 674: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0023 - bpp: 0.4901 - mse: 2.5013e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1392 - bpp: 0.5161 - mse: 3.0426e-04\n",
      "Epoch 675: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1392 - bpp: 0.5161 - mse: 3.0426e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0329 - bpp: 0.5005 - mse: 2.5996e-04\n",
      "Epoch 676: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0329 - bpp: 0.5005 - mse: 2.5996e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0378 - bpp: 0.5072 - mse: 2.5907e-04\n",
      "Epoch 677: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0378 - bpp: 0.5072 - mse: 2.5907e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0375 - bpp: 0.4916 - mse: 2.6652e-04\n",
      "Epoch 678: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0375 - bpp: 0.4916 - mse: 2.6652e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.4954 - mse: 2.6004e-04\n",
      "Epoch 679: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0279 - bpp: 0.4954 - mse: 2.6004e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0647 - bpp: 0.4977 - mse: 2.7688e-04\n",
      "Epoch 680: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0647 - bpp: 0.4977 - mse: 2.7688e-04\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0073 - bpp: 0.4990 - mse: 2.4819e-04\n",
      "Epoch 681: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0073 - bpp: 0.4990 - mse: 2.4819e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9904 - bpp: 0.4906 - mse: 2.4405e-04\n",
      "Epoch 682: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9904 - bpp: 0.4906 - mse: 2.4405e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9804 - bpp: 0.4898 - mse: 2.3955e-04\n",
      "Epoch 683: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 0.9804 - bpp: 0.4898 - mse: 2.3955e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0656 - bpp: 0.5034 - mse: 2.7451e-04\n",
      "Epoch 684: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0656 - bpp: 0.5034 - mse: 2.7451e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0520 - bpp: 0.5066 - mse: 2.6630e-04\n",
      "Epoch 685: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0520 - bpp: 0.5066 - mse: 2.6630e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9727 - bpp: 0.4875 - mse: 2.3694e-04\n",
      "Epoch 686: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9727 - bpp: 0.4875 - mse: 2.3694e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1702 - bpp: 0.5280 - mse: 3.1358e-04\n",
      "Epoch 687: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1702 - bpp: 0.5280 - mse: 3.1358e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0063 - bpp: 0.4906 - mse: 2.5182e-04\n",
      "Epoch 688: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0063 - bpp: 0.4906 - mse: 2.5182e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0541 - bpp: 0.4942 - mse: 2.7340e-04\n",
      "Epoch 689: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0541 - bpp: 0.4942 - mse: 2.7340e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0221 - bpp: 0.4916 - mse: 2.5906e-04\n",
      "Epoch 690: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0221 - bpp: 0.4916 - mse: 2.5906e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0240 - bpp: 0.4962 - mse: 2.5773e-04\n",
      "Epoch 691: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0240 - bpp: 0.4962 - mse: 2.5773e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9861 - bpp: 0.4892 - mse: 2.4263e-04\n",
      "Epoch 692: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9861 - bpp: 0.4892 - mse: 2.4263e-04\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0519 - bpp: 0.4962 - mse: 2.7135e-04\n",
      "Epoch 693: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0519 - bpp: 0.4962 - mse: 2.7135e-04\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0597 - bpp: 0.5025 - mse: 2.7204e-04\n",
      "Epoch 694: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0597 - bpp: 0.5025 - mse: 2.7204e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0665 - bpp: 0.5092 - mse: 2.7213e-04\n",
      "Epoch 695: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.0665 - bpp: 0.5092 - mse: 2.7213e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9177 - bpp: 0.4729 - mse: 2.1717e-04\n",
      "Epoch 696: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9177 - bpp: 0.4729 - mse: 2.1717e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0231 - bpp: 0.4977 - mse: 2.5657e-04\n",
      "Epoch 697: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0231 - bpp: 0.4977 - mse: 2.5657e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1859 - bpp: 0.5175 - mse: 3.2639e-04\n",
      "Epoch 698: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1859 - bpp: 0.5175 - mse: 3.2639e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1240 - bpp: 0.5222 - mse: 2.9384e-04\n",
      "Epoch 699: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1240 - bpp: 0.5222 - mse: 2.9384e-04\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0185 - bpp: 0.4970 - mse: 2.5466e-04\n",
      "Epoch 700: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.0185 - bpp: 0.4970 - mse: 2.5466e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9969 - bpp: 0.4871 - mse: 2.4891e-04\n",
      "Epoch 701: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9969 - bpp: 0.4871 - mse: 2.4891e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0123 - bpp: 0.4941 - mse: 2.5305e-04\n",
      "Epoch 702: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0123 - bpp: 0.4941 - mse: 2.5305e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0419 - bpp: 0.4966 - mse: 2.6626e-04\n",
      "Epoch 703: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0419 - bpp: 0.4966 - mse: 2.6626e-04\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0825 - bpp: 0.5094 - mse: 2.7984e-04\n",
      "Epoch 704: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0825 - bpp: 0.5094 - mse: 2.7984e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1398 - bpp: 0.5153 - mse: 3.0496e-04\n",
      "Epoch 705: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.1398 - bpp: 0.5153 - mse: 3.0496e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0386 - bpp: 0.5016 - mse: 2.6223e-04\n",
      "Epoch 706: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0386 - bpp: 0.5016 - mse: 2.6223e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0817 - bpp: 0.5174 - mse: 2.7555e-04\n",
      "Epoch 707: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0817 - bpp: 0.5174 - mse: 2.7555e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0288 - bpp: 0.4972 - mse: 2.5956e-04\n",
      "Epoch 708: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0288 - bpp: 0.4972 - mse: 2.5956e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9286 - bpp: 0.4789 - mse: 2.1959e-04\n",
      "Epoch 709: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.9286 - bpp: 0.4789 - mse: 2.1959e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0028 - bpp: 0.4954 - mse: 2.4775e-04\n",
      "Epoch 710: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0028 - bpp: 0.4954 - mse: 2.4775e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0517 - bpp: 0.5099 - mse: 2.6453e-04\n",
      "Epoch 711: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0517 - bpp: 0.5099 - mse: 2.6453e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0706 - bpp: 0.5026 - mse: 2.7735e-04\n",
      "Epoch 712: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0706 - bpp: 0.5026 - mse: 2.7735e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9948 - bpp: 0.4835 - mse: 2.4963e-04\n",
      "Epoch 713: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9948 - bpp: 0.4835 - mse: 2.4963e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9759 - bpp: 0.4763 - mse: 2.4392e-04\n",
      "Epoch 714: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 0.9759 - bpp: 0.4763 - mse: 2.4392e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9575 - bpp: 0.4849 - mse: 2.3075e-04\n",
      "Epoch 715: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9575 - bpp: 0.4849 - mse: 2.3075e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9506 - bpp: 0.4808 - mse: 2.2941e-04\n",
      "Epoch 716: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9506 - bpp: 0.4808 - mse: 2.2941e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0474 - bpp: 0.4987 - mse: 2.6790e-04\n",
      "Epoch 717: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.0474 - bpp: 0.4987 - mse: 2.6790e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9642 - bpp: 0.4865 - mse: 2.3324e-04\n",
      "Epoch 718: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9642 - bpp: 0.4865 - mse: 2.3324e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9811 - bpp: 0.4799 - mse: 2.4469e-04\n",
      "Epoch 719: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9811 - bpp: 0.4799 - mse: 2.4469e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0452 - bpp: 0.5037 - mse: 2.6438e-04\n",
      "Epoch 720: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0452 - bpp: 0.5037 - mse: 2.6438e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9412 - bpp: 0.4820 - mse: 2.2423e-04\n",
      "Epoch 721: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.9412 - bpp: 0.4820 - mse: 2.2423e-04\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0770 - bpp: 0.5037 - mse: 2.7993e-04\n",
      "Epoch 722: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0770 - bpp: 0.5037 - mse: 2.7993e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0702 - bpp: 0.5069 - mse: 2.7504e-04\n",
      "Epoch 723: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0702 - bpp: 0.5069 - mse: 2.7504e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0646 - bpp: 0.4899 - mse: 2.8065e-04\n",
      "Epoch 724: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0646 - bpp: 0.4899 - mse: 2.8065e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0269 - bpp: 0.4937 - mse: 2.6038e-04\n",
      "Epoch 725: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0269 - bpp: 0.4937 - mse: 2.6038e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0024 - bpp: 0.4968 - mse: 2.4687e-04\n",
      "Epoch 726: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0024 - bpp: 0.4968 - mse: 2.4687e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9959 - bpp: 0.4891 - mse: 2.4747e-04\n",
      "Epoch 727: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9959 - bpp: 0.4891 - mse: 2.4747e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9910 - bpp: 0.4907 - mse: 2.4431e-04\n",
      "Epoch 728: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9910 - bpp: 0.4907 - mse: 2.4431e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9812 - bpp: 0.4904 - mse: 2.3965e-04\n",
      "Epoch 729: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 0.9812 - bpp: 0.4904 - mse: 2.3965e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9890 - bpp: 0.4882 - mse: 2.4456e-04\n",
      "Epoch 730: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9890 - bpp: 0.4882 - mse: 2.4456e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9736 - bpp: 0.4871 - mse: 2.3757e-04\n",
      "Epoch 731: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9736 - bpp: 0.4871 - mse: 2.3757e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0057 - bpp: 0.4908 - mse: 2.5143e-04\n",
      "Epoch 732: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0057 - bpp: 0.4908 - mse: 2.5143e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9269 - bpp: 0.4662 - mse: 2.2491e-04\n",
      "Epoch 733: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9269 - bpp: 0.4662 - mse: 2.2491e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9797 - bpp: 0.4838 - mse: 2.4213e-04\n",
      "Epoch 734: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 56s 273ms/step - loss: 0.9797 - bpp: 0.4838 - mse: 2.4213e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1370 - bpp: 0.5245 - mse: 2.9910e-04\n",
      "Epoch 735: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1370 - bpp: 0.5245 - mse: 2.9910e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0606 - bpp: 0.5047 - mse: 2.7139e-04\n",
      "Epoch 736: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0606 - bpp: 0.5047 - mse: 2.7139e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9872 - bpp: 0.4899 - mse: 2.4280e-04\n",
      "Epoch 737: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9872 - bpp: 0.4899 - mse: 2.4280e-04\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9794 - bpp: 0.4833 - mse: 2.4222e-04\n",
      "Epoch 738: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9794 - bpp: 0.4833 - mse: 2.4222e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9470 - bpp: 0.4817 - mse: 2.2720e-04\n",
      "Epoch 739: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9470 - bpp: 0.4817 - mse: 2.2720e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0722 - bpp: 0.4965 - mse: 2.8110e-04\n",
      "Epoch 740: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0722 - bpp: 0.4965 - mse: 2.8110e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0447 - bpp: 0.4938 - mse: 2.6900e-04\n",
      "Epoch 741: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0447 - bpp: 0.4938 - mse: 2.6900e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0699 - bpp: 0.5062 - mse: 2.7523e-04\n",
      "Epoch 742: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0699 - bpp: 0.5062 - mse: 2.7523e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0978 - bpp: 0.5140 - mse: 2.8505e-04\n",
      "Epoch 743: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0978 - bpp: 0.5140 - mse: 2.8505e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0462 - bpp: 0.5009 - mse: 2.6622e-04\n",
      "Epoch 744: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0462 - bpp: 0.5009 - mse: 2.6622e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9853 - bpp: 0.4927 - mse: 2.4055e-04\n",
      "Epoch 745: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9853 - bpp: 0.4927 - mse: 2.4055e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9554 - bpp: 0.4775 - mse: 2.3339e-04\n",
      "Epoch 746: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9554 - bpp: 0.4775 - mse: 2.3339e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0542 - bpp: 0.4972 - mse: 2.7197e-04\n",
      "Epoch 747: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0542 - bpp: 0.4972 - mse: 2.7197e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1073 - bpp: 0.5129 - mse: 2.9025e-04\n",
      "Epoch 748: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1073 - bpp: 0.5129 - mse: 2.9025e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9355 - bpp: 0.4806 - mse: 2.2214e-04\n",
      "Epoch 749: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9355 - bpp: 0.4806 - mse: 2.2214e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0112 - bpp: 0.4918 - mse: 2.5360e-04\n",
      "Epoch 750: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0112 - bpp: 0.4918 - mse: 2.5360e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0118 - bpp: 0.4952 - mse: 2.5226e-04\n",
      "Epoch 751: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0118 - bpp: 0.4952 - mse: 2.5226e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0442 - bpp: 0.4931 - mse: 2.6909e-04\n",
      "Epoch 752: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0442 - bpp: 0.4931 - mse: 2.6909e-04\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9975 - bpp: 0.4872 - mse: 2.4915e-04\n",
      "Epoch 753: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9975 - bpp: 0.4872 - mse: 2.4915e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9741 - bpp: 0.4874 - mse: 2.3763e-04\n",
      "Epoch 754: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9741 - bpp: 0.4874 - mse: 2.3763e-04\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0073 - bpp: 0.4866 - mse: 2.5424e-04\n",
      "Epoch 755: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0073 - bpp: 0.4866 - mse: 2.5424e-04\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9694 - bpp: 0.4825 - mse: 2.3775e-04\n",
      "Epoch 756: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 0.9694 - bpp: 0.4825 - mse: 2.3775e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1183 - bpp: 0.5199 - mse: 2.9219e-04\n",
      "Epoch 757: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1183 - bpp: 0.5199 - mse: 2.9219e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9664 - bpp: 0.4843 - mse: 2.3539e-04\n",
      "Epoch 758: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9664 - bpp: 0.4843 - mse: 2.3539e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0445 - bpp: 0.5033 - mse: 2.6423e-04\n",
      "Epoch 759: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0445 - bpp: 0.5033 - mse: 2.6423e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0219 - bpp: 0.4968 - mse: 2.5640e-04\n",
      "Epoch 760: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0219 - bpp: 0.4968 - mse: 2.5640e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.4995 - mse: 2.6257e-04\n",
      "Epoch 761: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0372 - bpp: 0.4995 - mse: 2.6257e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9602 - bpp: 0.4801 - mse: 2.3440e-04\n",
      "Epoch 762: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 0.9602 - bpp: 0.4801 - mse: 2.3440e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9726 - bpp: 0.4842 - mse: 2.3849e-04\n",
      "Epoch 763: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.9726 - bpp: 0.4842 - mse: 2.3849e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0784 - bpp: 0.5136 - mse: 2.7577e-04\n",
      "Epoch 764: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0784 - bpp: 0.5136 - mse: 2.7577e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0163 - bpp: 0.4896 - mse: 2.5717e-04\n",
      "Epoch 765: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0163 - bpp: 0.4896 - mse: 2.5717e-04\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0173 - bpp: 0.4898 - mse: 2.5758e-04\n",
      "Epoch 766: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0173 - bpp: 0.4898 - mse: 2.5758e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0020 - bpp: 0.4755 - mse: 2.5707e-04\n",
      "Epoch 767: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0020 - bpp: 0.4755 - mse: 2.5707e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9742 - bpp: 0.4791 - mse: 2.4175e-04\n",
      "Epoch 768: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9742 - bpp: 0.4791 - mse: 2.4175e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9151 - bpp: 0.4669 - mse: 2.1886e-04\n",
      "Epoch 769: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9151 - bpp: 0.4669 - mse: 2.1886e-04\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0315 - bpp: 0.4945 - mse: 2.6220e-04\n",
      "Epoch 770: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0315 - bpp: 0.4945 - mse: 2.6220e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0957 - bpp: 0.5184 - mse: 2.8187e-04\n",
      "Epoch 771: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0957 - bpp: 0.5184 - mse: 2.8187e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0438 - bpp: 0.4933 - mse: 2.6880e-04\n",
      "Epoch 772: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0438 - bpp: 0.4933 - mse: 2.6880e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0364 - bpp: 0.4917 - mse: 2.6598e-04\n",
      "Epoch 773: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0364 - bpp: 0.4917 - mse: 2.6598e-04\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0295 - bpp: 0.4948 - mse: 2.6107e-04\n",
      "Epoch 774: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0295 - bpp: 0.4948 - mse: 2.6107e-04\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9326 - bpp: 0.4728 - mse: 2.2452e-04\n",
      "Epoch 775: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9326 - bpp: 0.4728 - mse: 2.2452e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9200 - bpp: 0.4779 - mse: 2.1589e-04\n",
      "Epoch 776: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9200 - bpp: 0.4779 - mse: 2.1589e-04\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0462 - bpp: 0.4958 - mse: 2.6873e-04\n",
      "Epoch 777: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0462 - bpp: 0.4958 - mse: 2.6873e-04\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0687 - bpp: 0.5038 - mse: 2.7583e-04\n",
      "Epoch 778: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0687 - bpp: 0.5038 - mse: 2.7583e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9991 - bpp: 0.4889 - mse: 2.4916e-04\n",
      "Epoch 779: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9991 - bpp: 0.4889 - mse: 2.4916e-04\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9925 - bpp: 0.4927 - mse: 2.4404e-04\n",
      "Epoch 780: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9925 - bpp: 0.4927 - mse: 2.4404e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0360 - bpp: 0.5015 - mse: 2.6098e-04\n",
      "Epoch 781: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0360 - bpp: 0.5015 - mse: 2.6098e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9981 - bpp: 0.4929 - mse: 2.4666e-04\n",
      "Epoch 782: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9981 - bpp: 0.4929 - mse: 2.4666e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9164 - bpp: 0.4704 - mse: 2.1777e-04\n",
      "Epoch 783: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9164 - bpp: 0.4704 - mse: 2.1777e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9658 - bpp: 0.4801 - mse: 2.3715e-04\n",
      "Epoch 784: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9658 - bpp: 0.4801 - mse: 2.3715e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0764 - bpp: 0.5155 - mse: 2.7384e-04\n",
      "Epoch 785: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.0764 - bpp: 0.5155 - mse: 2.7384e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9475 - bpp: 0.4755 - mse: 2.3049e-04\n",
      "Epoch 786: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9475 - bpp: 0.4755 - mse: 2.3049e-04\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0058 - bpp: 0.4866 - mse: 2.5354e-04\n",
      "Epoch 787: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0058 - bpp: 0.4866 - mse: 2.5354e-04\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9847 - bpp: 0.4870 - mse: 2.4303e-04\n",
      "Epoch 788: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9847 - bpp: 0.4870 - mse: 2.4303e-04\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9522 - bpp: 0.4800 - mse: 2.3057e-04\n",
      "Epoch 789: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9522 - bpp: 0.4800 - mse: 2.3057e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0341 - bpp: 0.4914 - mse: 2.6498e-04\n",
      "Epoch 790: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0341 - bpp: 0.4914 - mse: 2.6498e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0818 - bpp: 0.4996 - mse: 2.8429e-04\n",
      "Epoch 791: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0818 - bpp: 0.4996 - mse: 2.8429e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9273 - bpp: 0.4699 - mse: 2.2332e-04\n",
      "Epoch 792: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9273 - bpp: 0.4699 - mse: 2.2332e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9771 - bpp: 0.4847 - mse: 2.4041e-04\n",
      "Epoch 793: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9771 - bpp: 0.4847 - mse: 2.4041e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0080 - bpp: 0.4943 - mse: 2.5080e-04\n",
      "Epoch 794: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0080 - bpp: 0.4943 - mse: 2.5080e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0413 - bpp: 0.5007 - mse: 2.6398e-04\n",
      "Epoch 795: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0413 - bpp: 0.5007 - mse: 2.6398e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0060 - bpp: 0.4927 - mse: 2.5061e-04\n",
      "Epoch 796: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0060 - bpp: 0.4927 - mse: 2.5061e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9738 - bpp: 0.4893 - mse: 2.3655e-04\n",
      "Epoch 797: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 0.9738 - bpp: 0.4893 - mse: 2.3655e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0374 - bpp: 0.4966 - mse: 2.6407e-04\n",
      "Epoch 798: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0374 - bpp: 0.4966 - mse: 2.6407e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0260 - bpp: 0.4918 - mse: 2.6084e-04\n",
      "Epoch 799: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0260 - bpp: 0.4918 - mse: 2.6084e-04\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9934 - bpp: 0.4887 - mse: 2.4642e-04\n",
      "Epoch 800: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9934 - bpp: 0.4887 - mse: 2.4642e-04\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9365 - bpp: 0.4760 - mse: 2.2490e-04\n",
      "Epoch 801: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9365 - bpp: 0.4760 - mse: 2.2490e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9154 - bpp: 0.4702 - mse: 2.1738e-04\n",
      "Epoch 802: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.9154 - bpp: 0.4702 - mse: 2.1738e-04\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0311 - bpp: 0.4904 - mse: 2.6402e-04\n",
      "Epoch 803: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.0311 - bpp: 0.4904 - mse: 2.6402e-04\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0797 - bpp: 0.5094 - mse: 2.7844e-04\n",
      "Epoch 804: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.0797 - bpp: 0.5094 - mse: 2.7844e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0286 - bpp: 0.4887 - mse: 2.6360e-04\n",
      "Epoch 805: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0286 - bpp: 0.4887 - mse: 2.6360e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0019 - bpp: 0.4830 - mse: 2.5336e-04\n",
      "Epoch 806: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0019 - bpp: 0.4830 - mse: 2.5336e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0642 - bpp: 0.4991 - mse: 2.7594e-04\n",
      "Epoch 807: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0642 - bpp: 0.4991 - mse: 2.7594e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0156 - bpp: 0.4897 - mse: 2.5678e-04\n",
      "Epoch 808: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.0156 - bpp: 0.4897 - mse: 2.5678e-04\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9871 - bpp: 0.4898 - mse: 2.4280e-04\n",
      "Epoch 809: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9871 - bpp: 0.4898 - mse: 2.4280e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0762 - bpp: 0.5032 - mse: 2.7980e-04\n",
      "Epoch 810: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0762 - bpp: 0.5032 - mse: 2.7980e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9847 - bpp: 0.4883 - mse: 2.4242e-04\n",
      "Epoch 811: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9847 - bpp: 0.4883 - mse: 2.4242e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9700 - bpp: 0.4857 - mse: 2.3651e-04\n",
      "Epoch 812: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9700 - bpp: 0.4857 - mse: 2.3651e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0000 - bpp: 0.4877 - mse: 2.5014e-04\n",
      "Epoch 813: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0000 - bpp: 0.4877 - mse: 2.5014e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0051 - bpp: 0.4930 - mse: 2.5003e-04\n",
      "Epoch 814: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0051 - bpp: 0.4930 - mse: 2.5003e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0035 - bpp: 0.4908 - mse: 2.5037e-04\n",
      "Epoch 815: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0035 - bpp: 0.4908 - mse: 2.5037e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0205 - bpp: 0.4940 - mse: 2.5705e-04\n",
      "Epoch 816: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0205 - bpp: 0.4940 - mse: 2.5705e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.5018 - mse: 2.6885e-04\n",
      "Epoch 817: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0524 - bpp: 0.5018 - mse: 2.6885e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0859 - bpp: 0.5056 - mse: 2.8334e-04\n",
      "Epoch 818: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 1.0859 - bpp: 0.5056 - mse: 2.8334e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9805 - bpp: 0.4915 - mse: 2.3880e-04\n",
      "Epoch 819: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9805 - bpp: 0.4915 - mse: 2.3880e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0324 - bpp: 0.5013 - mse: 2.5933e-04\n",
      "Epoch 820: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0324 - bpp: 0.5013 - mse: 2.5933e-04\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0246 - bpp: 0.4991 - mse: 2.5659e-04\n",
      "Epoch 821: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0246 - bpp: 0.4991 - mse: 2.5659e-04\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9840 - bpp: 0.4771 - mse: 2.4753e-04\n",
      "Epoch 822: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9840 - bpp: 0.4771 - mse: 2.4753e-04\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0342 - bpp: 0.4963 - mse: 2.6264e-04\n",
      "Epoch 823: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0342 - bpp: 0.4963 - mse: 2.6264e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0589 - bpp: 0.4989 - mse: 2.7344e-04\n",
      "Epoch 824: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.0589 - bpp: 0.4989 - mse: 2.7344e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9870 - bpp: 0.4891 - mse: 2.4314e-04\n",
      "Epoch 825: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9870 - bpp: 0.4891 - mse: 2.4314e-04\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0584 - bpp: 0.4975 - mse: 2.7384e-04\n",
      "Epoch 826: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0584 - bpp: 0.4975 - mse: 2.7384e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9367 - bpp: 0.4784 - mse: 2.2380e-04\n",
      "Epoch 827: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9367 - bpp: 0.4784 - mse: 2.2380e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0192 - bpp: 0.4990 - mse: 2.5400e-04\n",
      "Epoch 828: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0192 - bpp: 0.4990 - mse: 2.5400e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9695 - bpp: 0.4791 - mse: 2.3942e-04\n",
      "Epoch 829: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9695 - bpp: 0.4791 - mse: 2.3942e-04\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9838 - bpp: 0.4771 - mse: 2.4742e-04\n",
      "Epoch 830: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9838 - bpp: 0.4771 - mse: 2.4742e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0379 - bpp: 0.4975 - mse: 2.6388e-04\n",
      "Epoch 831: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0379 - bpp: 0.4975 - mse: 2.6388e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0143 - bpp: 0.4906 - mse: 2.5575e-04\n",
      "Epoch 832: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0143 - bpp: 0.4906 - mse: 2.5575e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0039 - bpp: 0.4928 - mse: 2.4957e-04\n",
      "Epoch 833: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0039 - bpp: 0.4928 - mse: 2.4957e-04\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9946 - bpp: 0.4893 - mse: 2.4674e-04\n",
      "Epoch 834: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9946 - bpp: 0.4893 - mse: 2.4674e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9308 - bpp: 0.4785 - mse: 2.2086e-04\n",
      "Epoch 835: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9308 - bpp: 0.4785 - mse: 2.2086e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9360 - bpp: 0.4737 - mse: 2.2571e-04\n",
      "Epoch 836: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9360 - bpp: 0.4737 - mse: 2.2571e-04\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0510 - bpp: 0.4983 - mse: 2.6989e-04\n",
      "Epoch 837: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0510 - bpp: 0.4983 - mse: 2.6989e-04\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9385 - bpp: 0.4819 - mse: 2.2297e-04\n",
      "Epoch 838: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9385 - bpp: 0.4819 - mse: 2.2297e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9711 - bpp: 0.4877 - mse: 2.3604e-04\n",
      "Epoch 839: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9711 - bpp: 0.4877 - mse: 2.3604e-04\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9745 - bpp: 0.4773 - mse: 2.4275e-04\n",
      "Epoch 840: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9745 - bpp: 0.4773 - mse: 2.4275e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9721 - bpp: 0.4814 - mse: 2.3959e-04\n",
      "Epoch 841: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9721 - bpp: 0.4814 - mse: 2.3959e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9798 - bpp: 0.4902 - mse: 2.3905e-04\n",
      "Epoch 842: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9798 - bpp: 0.4902 - mse: 2.3905e-04\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9370 - bpp: 0.4762 - mse: 2.2500e-04\n",
      "Epoch 843: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9370 - bpp: 0.4762 - mse: 2.2500e-04\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9454 - bpp: 0.4761 - mse: 2.2917e-04\n",
      "Epoch 844: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9454 - bpp: 0.4761 - mse: 2.2917e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9563 - bpp: 0.4823 - mse: 2.3143e-04\n",
      "Epoch 845: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9563 - bpp: 0.4823 - mse: 2.3143e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0834 - bpp: 0.5094 - mse: 2.8026e-04\n",
      "Epoch 846: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0834 - bpp: 0.5094 - mse: 2.8026e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0442 - bpp: 0.4914 - mse: 2.6992e-04\n",
      "Epoch 847: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0442 - bpp: 0.4914 - mse: 2.6992e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1039 - bpp: 0.5056 - mse: 2.9218e-04\n",
      "Epoch 848: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.1039 - bpp: 0.5056 - mse: 2.9218e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0312 - bpp: 0.4988 - mse: 2.5995e-04\n",
      "Epoch 849: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0312 - bpp: 0.4988 - mse: 2.5995e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0251 - bpp: 0.4991 - mse: 2.5684e-04\n",
      "Epoch 850: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0251 - bpp: 0.4991 - mse: 2.5684e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0428 - bpp: 0.4893 - mse: 2.7026e-04\n",
      "Epoch 851: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0428 - bpp: 0.4893 - mse: 2.7026e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0404 - bpp: 0.4928 - mse: 2.6741e-04\n",
      "Epoch 852: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0404 - bpp: 0.4928 - mse: 2.6741e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0251 - bpp: 0.4939 - mse: 2.5938e-04\n",
      "Epoch 853: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0251 - bpp: 0.4939 - mse: 2.5938e-04\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0070 - bpp: 0.4888 - mse: 2.5303e-04\n",
      "Epoch 854: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0070 - bpp: 0.4888 - mse: 2.5303e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1140 - bpp: 0.5086 - mse: 2.9561e-04\n",
      "Epoch 855: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.1140 - bpp: 0.5086 - mse: 2.9561e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0119 - bpp: 0.4857 - mse: 2.5693e-04\n",
      "Epoch 856: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0119 - bpp: 0.4857 - mse: 2.5693e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0308 - bpp: 0.4906 - mse: 2.6376e-04\n",
      "Epoch 857: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0308 - bpp: 0.4906 - mse: 2.6376e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9994 - bpp: 0.4900 - mse: 2.4874e-04\n",
      "Epoch 858: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9994 - bpp: 0.4900 - mse: 2.4874e-04\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0104 - bpp: 0.4975 - mse: 2.5044e-04\n",
      "Epoch 859: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0104 - bpp: 0.4975 - mse: 2.5044e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9918 - bpp: 0.4852 - mse: 2.4736e-04\n",
      "Epoch 860: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 0.9918 - bpp: 0.4852 - mse: 2.4736e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9180 - bpp: 0.4665 - mse: 2.2046e-04\n",
      "Epoch 861: loss did not improve from 0.91205\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9180 - bpp: 0.4665 - mse: 2.2046e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8831 - bpp: 0.4643 - mse: 2.0447e-04\n",
      "Epoch 862: loss improved from 0.91205 to 0.88309, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.8831 - bpp: 0.4643 - mse: 2.0447e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9393 - bpp: 0.4747 - mse: 2.2688e-04\n",
      "Epoch 863: loss did not improve from 0.88309\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9393 - bpp: 0.4747 - mse: 2.2688e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9880 - bpp: 0.4825 - mse: 2.4679e-04\n",
      "Epoch 864: loss did not improve from 0.88309\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9880 - bpp: 0.4825 - mse: 2.4679e-04\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1006 - bpp: 0.5111 - mse: 2.8782e-04\n",
      "Epoch 865: loss did not improve from 0.88309\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1006 - bpp: 0.5111 - mse: 2.8782e-04\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0255 - bpp: 0.4902 - mse: 2.6139e-04\n",
      "Epoch 866: loss did not improve from 0.88309\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0255 - bpp: 0.4902 - mse: 2.6139e-04\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9565 - bpp: 0.4843 - mse: 2.3056e-04\n",
      "Epoch 867: loss did not improve from 0.88309\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9565 - bpp: 0.4843 - mse: 2.3056e-04\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0658 - bpp: 0.4970 - mse: 2.7774e-04\n",
      "Epoch 868: loss did not improve from 0.88309\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0658 - bpp: 0.4970 - mse: 2.7774e-04\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8571 - bpp: 0.4574 - mse: 1.9517e-04\n",
      "Epoch 869: loss improved from 0.88309 to 0.85714, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 0.8571 - bpp: 0.4574 - mse: 1.9517e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9688 - bpp: 0.4836 - mse: 2.3692e-04\n",
      "Epoch 870: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.9688 - bpp: 0.4836 - mse: 2.3692e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0910 - bpp: 0.5031 - mse: 2.8708e-04\n",
      "Epoch 871: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.0910 - bpp: 0.5031 - mse: 2.8708e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9987 - bpp: 0.4883 - mse: 2.4919e-04\n",
      "Epoch 872: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9987 - bpp: 0.4883 - mse: 2.4919e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0093 - bpp: 0.4966 - mse: 2.5034e-04\n",
      "Epoch 873: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0093 - bpp: 0.4966 - mse: 2.5034e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0101 - bpp: 0.4929 - mse: 2.5255e-04\n",
      "Epoch 874: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0101 - bpp: 0.4929 - mse: 2.5255e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0582 - bpp: 0.5083 - mse: 2.6854e-04\n",
      "Epoch 875: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0582 - bpp: 0.5083 - mse: 2.6854e-04\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9925 - bpp: 0.4895 - mse: 2.4560e-04\n",
      "Epoch 876: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9925 - bpp: 0.4895 - mse: 2.4560e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0651 - bpp: 0.4987 - mse: 2.7658e-04\n",
      "Epoch 877: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.0651 - bpp: 0.4987 - mse: 2.7658e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0935 - bpp: 0.5048 - mse: 2.8745e-04\n",
      "Epoch 878: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0935 - bpp: 0.5048 - mse: 2.8745e-04\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9827 - bpp: 0.4814 - mse: 2.4477e-04\n",
      "Epoch 879: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9827 - bpp: 0.4814 - mse: 2.4477e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9586 - bpp: 0.4770 - mse: 2.3513e-04\n",
      "Epoch 880: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9586 - bpp: 0.4770 - mse: 2.3513e-04\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0038 - bpp: 0.4879 - mse: 2.5191e-04\n",
      "Epoch 881: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0038 - bpp: 0.4879 - mse: 2.5191e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9588 - bpp: 0.4848 - mse: 2.3144e-04\n",
      "Epoch 882: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9588 - bpp: 0.4848 - mse: 2.3144e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0839 - bpp: 0.5034 - mse: 2.8346e-04\n",
      "Epoch 883: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0839 - bpp: 0.5034 - mse: 2.8346e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0106 - bpp: 0.4938 - mse: 2.5234e-04\n",
      "Epoch 884: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0106 - bpp: 0.4938 - mse: 2.5234e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0685 - bpp: 0.5011 - mse: 2.7705e-04\n",
      "Epoch 885: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0685 - bpp: 0.5011 - mse: 2.7705e-04\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9248 - bpp: 0.4802 - mse: 2.1712e-04\n",
      "Epoch 886: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9248 - bpp: 0.4802 - mse: 2.1712e-04\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9608 - bpp: 0.4807 - mse: 2.3441e-04\n",
      "Epoch 887: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9608 - bpp: 0.4807 - mse: 2.3441e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0377 - bpp: 0.4965 - mse: 2.6428e-04\n",
      "Epoch 888: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0377 - bpp: 0.4965 - mse: 2.6428e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8850 - bpp: 0.4626 - mse: 2.0624e-04\n",
      "Epoch 889: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.8850 - bpp: 0.4626 - mse: 2.0624e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9579 - bpp: 0.4785 - mse: 2.3411e-04\n",
      "Epoch 890: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9579 - bpp: 0.4785 - mse: 2.3411e-04\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0885 - bpp: 0.5061 - mse: 2.8436e-04\n",
      "Epoch 891: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0885 - bpp: 0.5061 - mse: 2.8436e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0264 - bpp: 0.4991 - mse: 2.5745e-04\n",
      "Epoch 892: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0264 - bpp: 0.4991 - mse: 2.5745e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9958 - bpp: 0.4915 - mse: 2.4625e-04\n",
      "Epoch 893: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9958 - bpp: 0.4915 - mse: 2.4625e-04\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9722 - bpp: 0.4856 - mse: 2.3761e-04\n",
      "Epoch 894: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9722 - bpp: 0.4856 - mse: 2.3761e-04\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9529 - bpp: 0.4764 - mse: 2.3269e-04\n",
      "Epoch 895: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9529 - bpp: 0.4764 - mse: 2.3269e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0341 - bpp: 0.5008 - mse: 2.6039e-04\n",
      "Epoch 896: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0341 - bpp: 0.5008 - mse: 2.6039e-04\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9817 - bpp: 0.4837 - mse: 2.4315e-04\n",
      "Epoch 897: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9817 - bpp: 0.4837 - mse: 2.4315e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9553 - bpp: 0.4765 - mse: 2.3379e-04\n",
      "Epoch 898: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9553 - bpp: 0.4765 - mse: 2.3379e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0938 - bpp: 0.5147 - mse: 2.8275e-04\n",
      "Epoch 899: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0938 - bpp: 0.5147 - mse: 2.8275e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0025 - bpp: 0.4969 - mse: 2.4687e-04\n",
      "Epoch 900: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0025 - bpp: 0.4969 - mse: 2.4687e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0124 - bpp: 0.4868 - mse: 2.5664e-04\n",
      "Epoch 901: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0124 - bpp: 0.4868 - mse: 2.5664e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9754 - bpp: 0.4821 - mse: 2.4089e-04\n",
      "Epoch 902: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9754 - bpp: 0.4821 - mse: 2.4089e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0352 - bpp: 0.4997 - mse: 2.6146e-04\n",
      "Epoch 903: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0352 - bpp: 0.4997 - mse: 2.6146e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0711 - bpp: 0.5098 - mse: 2.7405e-04\n",
      "Epoch 904: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0711 - bpp: 0.5098 - mse: 2.7405e-04\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1179 - bpp: 0.5189 - mse: 2.9247e-04\n",
      "Epoch 905: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1179 - bpp: 0.5189 - mse: 2.9247e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9252 - bpp: 0.4735 - mse: 2.2055e-04\n",
      "Epoch 906: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9252 - bpp: 0.4735 - mse: 2.2055e-04\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0448 - bpp: 0.5014 - mse: 2.6537e-04\n",
      "Epoch 907: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0448 - bpp: 0.5014 - mse: 2.6537e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0272 - bpp: 0.4976 - mse: 2.5860e-04\n",
      "Epoch 908: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0272 - bpp: 0.4976 - mse: 2.5860e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9672 - bpp: 0.4844 - mse: 2.3575e-04\n",
      "Epoch 909: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9672 - bpp: 0.4844 - mse: 2.3575e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9932 - bpp: 0.4910 - mse: 2.4524e-04\n",
      "Epoch 910: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.9932 - bpp: 0.4910 - mse: 2.4524e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0431 - bpp: 0.5045 - mse: 2.6298e-04\n",
      "Epoch 911: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.0431 - bpp: 0.5045 - mse: 2.6298e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9755 - bpp: 0.4837 - mse: 2.4011e-04\n",
      "Epoch 912: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9755 - bpp: 0.4837 - mse: 2.4011e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9935 - bpp: 0.4820 - mse: 2.4978e-04\n",
      "Epoch 913: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9935 - bpp: 0.4820 - mse: 2.4978e-04\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9614 - bpp: 0.4824 - mse: 2.3389e-04\n",
      "Epoch 914: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9614 - bpp: 0.4824 - mse: 2.3389e-04\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9867 - bpp: 0.4912 - mse: 2.4193e-04\n",
      "Epoch 915: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9867 - bpp: 0.4912 - mse: 2.4193e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9983 - bpp: 0.4969 - mse: 2.4482e-04\n",
      "Epoch 916: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9983 - bpp: 0.4969 - mse: 2.4482e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9570 - bpp: 0.4819 - mse: 2.3198e-04\n",
      "Epoch 917: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9570 - bpp: 0.4819 - mse: 2.3198e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5084 - mse: 2.8406e-04\n",
      "Epoch 918: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0901 - bpp: 0.5084 - mse: 2.8406e-04\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9695 - bpp: 0.4862 - mse: 2.3596e-04\n",
      "Epoch 919: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9695 - bpp: 0.4862 - mse: 2.3596e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9705 - bpp: 0.4859 - mse: 2.3659e-04\n",
      "Epoch 920: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9705 - bpp: 0.4859 - mse: 2.3659e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9735 - bpp: 0.4865 - mse: 2.3780e-04\n",
      "Epoch 921: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9735 - bpp: 0.4865 - mse: 2.3780e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0099 - bpp: 0.4910 - mse: 2.5333e-04\n",
      "Epoch 922: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0099 - bpp: 0.4910 - mse: 2.5333e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9456 - bpp: 0.4750 - mse: 2.2978e-04\n",
      "Epoch 923: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9456 - bpp: 0.4750 - mse: 2.2978e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0826 - bpp: 0.4974 - mse: 2.8574e-04\n",
      "Epoch 924: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0826 - bpp: 0.4974 - mse: 2.8574e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9551 - bpp: 0.4756 - mse: 2.3412e-04\n",
      "Epoch 925: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9551 - bpp: 0.4756 - mse: 2.3412e-04\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0038 - bpp: 0.4929 - mse: 2.4946e-04\n",
      "Epoch 926: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.0038 - bpp: 0.4929 - mse: 2.4946e-04\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0338 - bpp: 0.4999 - mse: 2.6072e-04\n",
      "Epoch 927: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0338 - bpp: 0.4999 - mse: 2.6072e-04\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9914 - bpp: 0.4920 - mse: 2.4384e-04\n",
      "Epoch 928: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9914 - bpp: 0.4920 - mse: 2.4384e-04\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0466 - bpp: 0.5066 - mse: 2.6368e-04\n",
      "Epoch 929: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0466 - bpp: 0.5066 - mse: 2.6368e-04\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0849 - bpp: 0.5117 - mse: 2.7988e-04\n",
      "Epoch 930: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0849 - bpp: 0.5117 - mse: 2.7988e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9451 - bpp: 0.4827 - mse: 2.2578e-04\n",
      "Epoch 931: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9451 - bpp: 0.4827 - mse: 2.2578e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9572 - bpp: 0.4774 - mse: 2.3425e-04\n",
      "Epoch 932: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9572 - bpp: 0.4774 - mse: 2.3425e-04\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9528 - bpp: 0.4821 - mse: 2.2982e-04\n",
      "Epoch 933: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9528 - bpp: 0.4821 - mse: 2.2982e-04\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0200 - bpp: 0.4994 - mse: 2.5419e-04\n",
      "Epoch 934: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0200 - bpp: 0.4994 - mse: 2.5419e-04\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9375 - bpp: 0.4752 - mse: 2.2572e-04\n",
      "Epoch 935: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9375 - bpp: 0.4752 - mse: 2.2572e-04\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9290 - bpp: 0.4712 - mse: 2.2349e-04\n",
      "Epoch 936: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9290 - bpp: 0.4712 - mse: 2.2349e-04\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9596 - bpp: 0.4807 - mse: 2.3386e-04\n",
      "Epoch 937: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9596 - bpp: 0.4807 - mse: 2.3386e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9666 - bpp: 0.4874 - mse: 2.3398e-04\n",
      "Epoch 938: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.9666 - bpp: 0.4874 - mse: 2.3398e-04\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9622 - bpp: 0.4803 - mse: 2.3530e-04\n",
      "Epoch 939: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9622 - bpp: 0.4803 - mse: 2.3530e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9385 - bpp: 0.4730 - mse: 2.2729e-04\n",
      "Epoch 940: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 0.9385 - bpp: 0.4730 - mse: 2.2729e-04\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9923 - bpp: 0.4822 - mse: 2.4911e-04\n",
      "Epoch 941: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9923 - bpp: 0.4822 - mse: 2.4911e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0169 - bpp: 0.4934 - mse: 2.5562e-04\n",
      "Epoch 942: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0169 - bpp: 0.4934 - mse: 2.5562e-04\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9699 - bpp: 0.4808 - mse: 2.3879e-04\n",
      "Epoch 943: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9699 - bpp: 0.4808 - mse: 2.3879e-04\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0258 - bpp: 0.4893 - mse: 2.6194e-04\n",
      "Epoch 944: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 1.0258 - bpp: 0.4893 - mse: 2.6194e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0166 - bpp: 0.4981 - mse: 2.5315e-04\n",
      "Epoch 945: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0166 - bpp: 0.4981 - mse: 2.5315e-04\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9749 - bpp: 0.4848 - mse: 2.3934e-04\n",
      "Epoch 946: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.9749 - bpp: 0.4848 - mse: 2.3934e-04\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9344 - bpp: 0.4697 - mse: 2.2694e-04\n",
      "Epoch 947: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 0.9344 - bpp: 0.4697 - mse: 2.2694e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9940 - bpp: 0.4836 - mse: 2.4921e-04\n",
      "Epoch 948: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 0.9940 - bpp: 0.4836 - mse: 2.4921e-04\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9646 - bpp: 0.4719 - mse: 2.4058e-04\n",
      "Epoch 949: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 0.9646 - bpp: 0.4719 - mse: 2.4058e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0687 - bpp: 0.5085 - mse: 2.7352e-04\n",
      "Epoch 950: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0687 - bpp: 0.5085 - mse: 2.7352e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9870 - bpp: 0.4866 - mse: 2.4437e-04\n",
      "Epoch 951: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.9870 - bpp: 0.4866 - mse: 2.4437e-04\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9631 - bpp: 0.4850 - mse: 2.3342e-04\n",
      "Epoch 952: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 0.9631 - bpp: 0.4850 - mse: 2.3342e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0030 - bpp: 0.4909 - mse: 2.5004e-04\n",
      "Epoch 953: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0030 - bpp: 0.4909 - mse: 2.5004e-04\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0531 - bpp: 0.5004 - mse: 2.6989e-04\n",
      "Epoch 954: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.0531 - bpp: 0.5004 - mse: 2.6989e-04\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0164 - bpp: 0.4929 - mse: 2.5563e-04\n",
      "Epoch 955: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0164 - bpp: 0.4929 - mse: 2.5563e-04\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9537 - bpp: 0.4787 - mse: 2.3194e-04\n",
      "Epoch 956: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9537 - bpp: 0.4787 - mse: 2.3194e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0631 - bpp: 0.5057 - mse: 2.7217e-04\n",
      "Epoch 957: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 1.0631 - bpp: 0.5057 - mse: 2.7217e-04\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0282 - bpp: 0.4953 - mse: 2.6017e-04\n",
      "Epoch 958: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.0282 - bpp: 0.4953 - mse: 2.6017e-04\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9851 - bpp: 0.4841 - mse: 2.4462e-04\n",
      "Epoch 959: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 0.9851 - bpp: 0.4841 - mse: 2.4462e-04\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0043 - bpp: 0.4922 - mse: 2.5004e-04\n",
      "Epoch 960: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0043 - bpp: 0.4922 - mse: 2.5004e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9293 - bpp: 0.4703 - mse: 2.2412e-04\n",
      "Epoch 961: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9293 - bpp: 0.4703 - mse: 2.2412e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9265 - bpp: 0.4766 - mse: 2.1968e-04\n",
      "Epoch 962: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 0.9265 - bpp: 0.4766 - mse: 2.1968e-04\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9341 - bpp: 0.4788 - mse: 2.2233e-04\n",
      "Epoch 963: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9341 - bpp: 0.4788 - mse: 2.2233e-04\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9559 - bpp: 0.4746 - mse: 2.3498e-04\n",
      "Epoch 964: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9559 - bpp: 0.4746 - mse: 2.3498e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0066 - bpp: 0.4904 - mse: 2.5209e-04\n",
      "Epoch 965: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.0066 - bpp: 0.4904 - mse: 2.5209e-04\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9923 - bpp: 0.4946 - mse: 2.4302e-04\n",
      "Epoch 966: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9923 - bpp: 0.4946 - mse: 2.4302e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.5013 - mse: 2.5709e-04\n",
      "Epoch 967: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0279 - bpp: 0.5013 - mse: 2.5709e-04\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0410 - bpp: 0.4960 - mse: 2.6611e-04\n",
      "Epoch 968: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0410 - bpp: 0.4960 - mse: 2.6611e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9388 - bpp: 0.4785 - mse: 2.2472e-04\n",
      "Epoch 969: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9388 - bpp: 0.4785 - mse: 2.2472e-04\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9722 - bpp: 0.4787 - mse: 2.4099e-04\n",
      "Epoch 970: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.9722 - bpp: 0.4787 - mse: 2.4099e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0109 - bpp: 0.4973 - mse: 2.5075e-04\n",
      "Epoch 971: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.0109 - bpp: 0.4973 - mse: 2.5075e-04\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0069 - bpp: 0.4909 - mse: 2.5191e-04\n",
      "Epoch 972: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0069 - bpp: 0.4909 - mse: 2.5191e-04\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9276 - bpp: 0.4698 - mse: 2.2353e-04\n",
      "Epoch 973: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9276 - bpp: 0.4698 - mse: 2.2353e-04\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0436 - bpp: 0.4930 - mse: 2.6884e-04\n",
      "Epoch 974: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0436 - bpp: 0.4930 - mse: 2.6884e-04\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9585 - bpp: 0.4731 - mse: 2.3701e-04\n",
      "Epoch 975: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 0.9585 - bpp: 0.4731 - mse: 2.3701e-04\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0337 - bpp: 0.4979 - mse: 2.6160e-04\n",
      "Epoch 976: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.0337 - bpp: 0.4979 - mse: 2.6160e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9926 - bpp: 0.4863 - mse: 2.4721e-04\n",
      "Epoch 977: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9926 - bpp: 0.4863 - mse: 2.4721e-04\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0754 - bpp: 0.5041 - mse: 2.7894e-04\n",
      "Epoch 978: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.0754 - bpp: 0.5041 - mse: 2.7894e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9709 - bpp: 0.4795 - mse: 2.3997e-04\n",
      "Epoch 979: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9709 - bpp: 0.4795 - mse: 2.3997e-04\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9841 - bpp: 0.4832 - mse: 2.4458e-04\n",
      "Epoch 980: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9841 - bpp: 0.4832 - mse: 2.4458e-04\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9994 - bpp: 0.4832 - mse: 2.5205e-04\n",
      "Epoch 981: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9994 - bpp: 0.4832 - mse: 2.5205e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9896 - bpp: 0.4872 - mse: 2.4533e-04\n",
      "Epoch 982: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9896 - bpp: 0.4872 - mse: 2.4533e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0099 - bpp: 0.4877 - mse: 2.5497e-04\n",
      "Epoch 983: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0099 - bpp: 0.4877 - mse: 2.5497e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9845 - bpp: 0.4767 - mse: 2.4797e-04\n",
      "Epoch 984: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9845 - bpp: 0.4767 - mse: 2.4797e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0179 - bpp: 0.4889 - mse: 2.5827e-04\n",
      "Epoch 985: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.0179 - bpp: 0.4889 - mse: 2.5827e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9065 - bpp: 0.4716 - mse: 2.1235e-04\n",
      "Epoch 986: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9065 - bpp: 0.4716 - mse: 2.1235e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9845 - bpp: 0.4813 - mse: 2.4570e-04\n",
      "Epoch 987: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9845 - bpp: 0.4813 - mse: 2.4570e-04\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9199 - bpp: 0.4743 - mse: 2.1759e-04\n",
      "Epoch 988: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9199 - bpp: 0.4743 - mse: 2.1759e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0629 - bpp: 0.5015 - mse: 2.7414e-04\n",
      "Epoch 989: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.0629 - bpp: 0.5015 - mse: 2.7414e-04\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9523 - bpp: 0.4780 - mse: 2.3157e-04\n",
      "Epoch 990: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.9523 - bpp: 0.4780 - mse: 2.3157e-04\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9066 - bpp: 0.4713 - mse: 2.1257e-04\n",
      "Epoch 991: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9066 - bpp: 0.4713 - mse: 2.1257e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9556 - bpp: 0.4782 - mse: 2.3310e-04\n",
      "Epoch 992: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9556 - bpp: 0.4782 - mse: 2.3310e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9742 - bpp: 0.4806 - mse: 2.4104e-04\n",
      "Epoch 993: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9742 - bpp: 0.4806 - mse: 2.4104e-04\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0394 - bpp: 0.4965 - mse: 2.6511e-04\n",
      "Epoch 994: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0394 - bpp: 0.4965 - mse: 2.6511e-04\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0713 - bpp: 0.5067 - mse: 2.7571e-04\n",
      "Epoch 995: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0713 - bpp: 0.5067 - mse: 2.7571e-04\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0130 - bpp: 0.4959 - mse: 2.5251e-04\n",
      "Epoch 996: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 1.0130 - bpp: 0.4959 - mse: 2.5251e-04\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0140 - bpp: 0.4954 - mse: 2.5324e-04\n",
      "Epoch 997: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0140 - bpp: 0.4954 - mse: 2.5324e-04\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9785 - bpp: 0.4812 - mse: 2.4286e-04\n",
      "Epoch 998: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9785 - bpp: 0.4812 - mse: 2.4286e-04\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9702 - bpp: 0.4802 - mse: 2.3929e-04\n",
      "Epoch 999: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9702 - bpp: 0.4802 - mse: 2.3929e-04\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0223 - bpp: 0.4963 - mse: 2.5685e-04\n",
      "Epoch 1000: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.0223 - bpp: 0.4963 - mse: 2.5685e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9252 - bpp: 0.4724 - mse: 2.2112e-04\n",
      "Epoch 1001: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9252 - bpp: 0.4724 - mse: 2.2112e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9908 - bpp: 0.4856 - mse: 2.4668e-04\n",
      "Epoch 1002: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9908 - bpp: 0.4856 - mse: 2.4668e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9677 - bpp: 0.4786 - mse: 2.3882e-04\n",
      "Epoch 1003: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9677 - bpp: 0.4786 - mse: 2.3882e-04\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9949 - bpp: 0.4886 - mse: 2.4723e-04\n",
      "Epoch 1004: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.9949 - bpp: 0.4886 - mse: 2.4723e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9939 - bpp: 0.4888 - mse: 2.4664e-04\n",
      "Epoch 1005: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 0.9939 - bpp: 0.4888 - mse: 2.4664e-04\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9168 - bpp: 0.4734 - mse: 2.1652e-04\n",
      "Epoch 1006: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9168 - bpp: 0.4734 - mse: 2.1652e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9341 - bpp: 0.4770 - mse: 2.2320e-04\n",
      "Epoch 1007: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.9341 - bpp: 0.4770 - mse: 2.2320e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0484 - bpp: 0.5027 - mse: 2.6646e-04\n",
      "Epoch 1008: loss did not improve from 0.85714\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0484 - bpp: 0.5027 - mse: 2.6646e-04\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8519 - bpp: 0.4576 - mse: 1.9254e-04\n",
      "Epoch 1009: loss improved from 0.85714 to 0.85194, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 0.8519 - bpp: 0.4576 - mse: 1.9254e-04\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8679 - bpp: 0.4552 - mse: 2.0150e-04\n",
      "Epoch 1010: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.8679 - bpp: 0.4552 - mse: 2.0150e-04\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9742 - bpp: 0.4848 - mse: 2.3899e-04\n",
      "Epoch 1011: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.9742 - bpp: 0.4848 - mse: 2.3899e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9932 - bpp: 0.4815 - mse: 2.4981e-04\n",
      "Epoch 1012: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9932 - bpp: 0.4815 - mse: 2.4981e-04\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0277 - bpp: 0.4968 - mse: 2.5924e-04\n",
      "Epoch 1013: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.0277 - bpp: 0.4968 - mse: 2.5924e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9796 - bpp: 0.4842 - mse: 2.4187e-04\n",
      "Epoch 1014: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9796 - bpp: 0.4842 - mse: 2.4187e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9432 - bpp: 0.4701 - mse: 2.3100e-04\n",
      "Epoch 1015: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9432 - bpp: 0.4701 - mse: 2.3100e-04\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9562 - bpp: 0.4805 - mse: 2.3227e-04\n",
      "Epoch 1016: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9562 - bpp: 0.4805 - mse: 2.3227e-04\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9955 - bpp: 0.4858 - mse: 2.4885e-04\n",
      "Epoch 1017: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9955 - bpp: 0.4858 - mse: 2.4885e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9051 - bpp: 0.4641 - mse: 2.1534e-04\n",
      "Epoch 1018: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9051 - bpp: 0.4641 - mse: 2.1534e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0246 - bpp: 0.4868 - mse: 2.6258e-04\n",
      "Epoch 1019: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0246 - bpp: 0.4868 - mse: 2.6258e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8874 - bpp: 0.4593 - mse: 2.0903e-04\n",
      "Epoch 1020: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.8874 - bpp: 0.4593 - mse: 2.0903e-04\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0191 - bpp: 0.4810 - mse: 2.6274e-04\n",
      "Epoch 1021: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.0191 - bpp: 0.4810 - mse: 2.6274e-04\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0010 - bpp: 0.4868 - mse: 2.5109e-04\n",
      "Epoch 1022: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.0010 - bpp: 0.4868 - mse: 2.5109e-04\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0527 - bpp: 0.4966 - mse: 2.7156e-04\n",
      "Epoch 1023: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0527 - bpp: 0.4966 - mse: 2.7156e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9957 - bpp: 0.4928 - mse: 2.4559e-04\n",
      "Epoch 1024: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9957 - bpp: 0.4928 - mse: 2.4559e-04\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9875 - bpp: 0.4913 - mse: 2.4233e-04\n",
      "Epoch 1025: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9875 - bpp: 0.4913 - mse: 2.4233e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9557 - bpp: 0.4777 - mse: 2.3338e-04\n",
      "Epoch 1026: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9557 - bpp: 0.4777 - mse: 2.3338e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9921 - bpp: 0.4844 - mse: 2.4788e-04\n",
      "Epoch 1027: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9921 - bpp: 0.4844 - mse: 2.4788e-04\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9595 - bpp: 0.4777 - mse: 2.3525e-04\n",
      "Epoch 1028: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.9595 - bpp: 0.4777 - mse: 2.3525e-04\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9277 - bpp: 0.4690 - mse: 2.2396e-04\n",
      "Epoch 1029: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9277 - bpp: 0.4690 - mse: 2.2396e-04\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0356 - bpp: 0.4957 - mse: 2.6364e-04\n",
      "Epoch 1030: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0356 - bpp: 0.4957 - mse: 2.6364e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0160 - bpp: 0.4878 - mse: 2.5795e-04\n",
      "Epoch 1031: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0160 - bpp: 0.4878 - mse: 2.5795e-04\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0629 - bpp: 0.5006 - mse: 2.7454e-04\n",
      "Epoch 1032: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0629 - bpp: 0.5006 - mse: 2.7454e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9194 - bpp: 0.4659 - mse: 2.2146e-04\n",
      "Epoch 1033: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9194 - bpp: 0.4659 - mse: 2.2146e-04\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9643 - bpp: 0.4806 - mse: 2.3616e-04\n",
      "Epoch 1034: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9643 - bpp: 0.4806 - mse: 2.3616e-04\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0037 - bpp: 0.4859 - mse: 2.5284e-04\n",
      "Epoch 1035: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0037 - bpp: 0.4859 - mse: 2.5284e-04\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9193 - bpp: 0.4703 - mse: 2.1920e-04\n",
      "Epoch 1036: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9193 - bpp: 0.4703 - mse: 2.1920e-04\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9086 - bpp: 0.4650 - mse: 2.1656e-04\n",
      "Epoch 1037: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.9086 - bpp: 0.4650 - mse: 2.1656e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9126 - bpp: 0.4664 - mse: 2.1784e-04\n",
      "Epoch 1038: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9126 - bpp: 0.4664 - mse: 2.1784e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9081 - bpp: 0.4653 - mse: 2.1620e-04\n",
      "Epoch 1039: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9081 - bpp: 0.4653 - mse: 2.1620e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0792 - bpp: 0.5120 - mse: 2.7694e-04\n",
      "Epoch 1040: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0792 - bpp: 0.5120 - mse: 2.7694e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9602 - bpp: 0.4746 - mse: 2.3708e-04\n",
      "Epoch 1041: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9602 - bpp: 0.4746 - mse: 2.3708e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9239 - bpp: 0.4723 - mse: 2.2050e-04\n",
      "Epoch 1042: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9239 - bpp: 0.4723 - mse: 2.2050e-04\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9707 - bpp: 0.4796 - mse: 2.3981e-04\n",
      "Epoch 1043: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9707 - bpp: 0.4796 - mse: 2.3981e-04\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9891 - bpp: 0.4824 - mse: 2.4741e-04\n",
      "Epoch 1044: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9891 - bpp: 0.4824 - mse: 2.4741e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9539 - bpp: 0.4796 - mse: 2.3160e-04\n",
      "Epoch 1045: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9539 - bpp: 0.4796 - mse: 2.3160e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9399 - bpp: 0.4757 - mse: 2.2668e-04\n",
      "Epoch 1046: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9399 - bpp: 0.4757 - mse: 2.2668e-04\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9456 - bpp: 0.4756 - mse: 2.2951e-04\n",
      "Epoch 1047: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.9456 - bpp: 0.4756 - mse: 2.2951e-04\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9694 - bpp: 0.4807 - mse: 2.3859e-04\n",
      "Epoch 1048: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9694 - bpp: 0.4807 - mse: 2.3859e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9881 - bpp: 0.4925 - mse: 2.4202e-04\n",
      "Epoch 1049: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.9881 - bpp: 0.4925 - mse: 2.4202e-04\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9834 - bpp: 0.4872 - mse: 2.4232e-04\n",
      "Epoch 1050: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9834 - bpp: 0.4872 - mse: 2.4232e-04\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0228 - bpp: 0.4919 - mse: 2.5923e-04\n",
      "Epoch 1051: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.0228 - bpp: 0.4919 - mse: 2.5923e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0177 - bpp: 0.4897 - mse: 2.5782e-04\n",
      "Epoch 1052: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.0177 - bpp: 0.4897 - mse: 2.5782e-04\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9859 - bpp: 0.4880 - mse: 2.4312e-04\n",
      "Epoch 1053: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9859 - bpp: 0.4880 - mse: 2.4312e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8528 - bpp: 0.4530 - mse: 1.9524e-04\n",
      "Epoch 1054: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.8528 - bpp: 0.4530 - mse: 1.9524e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0298 - bpp: 0.4955 - mse: 2.6091e-04\n",
      "Epoch 1055: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0298 - bpp: 0.4955 - mse: 2.6091e-04\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9934 - bpp: 0.4837 - mse: 2.4888e-04\n",
      "Epoch 1056: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9934 - bpp: 0.4837 - mse: 2.4888e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9512 - bpp: 0.4807 - mse: 2.2972e-04\n",
      "Epoch 1057: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9512 - bpp: 0.4807 - mse: 2.2972e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9417 - bpp: 0.4729 - mse: 2.2889e-04\n",
      "Epoch 1058: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9417 - bpp: 0.4729 - mse: 2.2889e-04\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9633 - bpp: 0.4797 - mse: 2.3611e-04\n",
      "Epoch 1059: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 0.9633 - bpp: 0.4797 - mse: 2.3611e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.4923 - mse: 2.7347e-04\n",
      "Epoch 1060: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0524 - bpp: 0.4923 - mse: 2.7347e-04\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9941 - bpp: 0.4872 - mse: 2.4750e-04\n",
      "Epoch 1061: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9941 - bpp: 0.4872 - mse: 2.4750e-04\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9320 - bpp: 0.4744 - mse: 2.2346e-04\n",
      "Epoch 1062: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9320 - bpp: 0.4744 - mse: 2.2346e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9344 - bpp: 0.4759 - mse: 2.2385e-04\n",
      "Epoch 1063: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9344 - bpp: 0.4759 - mse: 2.2385e-04\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9501 - bpp: 0.4799 - mse: 2.2960e-04\n",
      "Epoch 1064: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9501 - bpp: 0.4799 - mse: 2.2960e-04\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9380 - bpp: 0.4744 - mse: 2.2635e-04\n",
      "Epoch 1065: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9380 - bpp: 0.4744 - mse: 2.2635e-04\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0213 - bpp: 0.4900 - mse: 2.5943e-04\n",
      "Epoch 1066: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0213 - bpp: 0.4900 - mse: 2.5943e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9516 - bpp: 0.4815 - mse: 2.2951e-04\n",
      "Epoch 1067: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9516 - bpp: 0.4815 - mse: 2.2951e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9852 - bpp: 0.4838 - mse: 2.4485e-04\n",
      "Epoch 1068: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9852 - bpp: 0.4838 - mse: 2.4485e-04\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9693 - bpp: 0.4804 - mse: 2.3876e-04\n",
      "Epoch 1069: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9693 - bpp: 0.4804 - mse: 2.3876e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0272 - bpp: 0.4916 - mse: 2.6151e-04\n",
      "Epoch 1070: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.0272 - bpp: 0.4916 - mse: 2.6151e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9860 - bpp: 0.4842 - mse: 2.4502e-04\n",
      "Epoch 1071: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9860 - bpp: 0.4842 - mse: 2.4502e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9318 - bpp: 0.4746 - mse: 2.2325e-04\n",
      "Epoch 1072: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9318 - bpp: 0.4746 - mse: 2.2325e-04\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0182 - bpp: 0.4887 - mse: 2.5851e-04\n",
      "Epoch 1073: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0182 - bpp: 0.4887 - mse: 2.5851e-04\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9629 - bpp: 0.4818 - mse: 2.3488e-04\n",
      "Epoch 1074: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9629 - bpp: 0.4818 - mse: 2.3488e-04\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9573 - bpp: 0.4756 - mse: 2.3522e-04\n",
      "Epoch 1075: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.9573 - bpp: 0.4756 - mse: 2.3522e-04\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0458 - bpp: 0.5014 - mse: 2.6583e-04\n",
      "Epoch 1076: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0458 - bpp: 0.5014 - mse: 2.6583e-04\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9841 - bpp: 0.4827 - mse: 2.4481e-04\n",
      "Epoch 1077: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9841 - bpp: 0.4827 - mse: 2.4481e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9250 - bpp: 0.4720 - mse: 2.2119e-04\n",
      "Epoch 1078: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9250 - bpp: 0.4720 - mse: 2.2119e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9756 - bpp: 0.4826 - mse: 2.4072e-04\n",
      "Epoch 1079: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9756 - bpp: 0.4826 - mse: 2.4072e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9576 - bpp: 0.4804 - mse: 2.3299e-04\n",
      "Epoch 1080: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9576 - bpp: 0.4804 - mse: 2.3299e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9882 - bpp: 0.4877 - mse: 2.4441e-04\n",
      "Epoch 1081: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9882 - bpp: 0.4877 - mse: 2.4441e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0810 - bpp: 0.5083 - mse: 2.7963e-04\n",
      "Epoch 1082: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0810 - bpp: 0.5083 - mse: 2.7963e-04\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9335 - bpp: 0.4690 - mse: 2.2678e-04\n",
      "Epoch 1083: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.9335 - bpp: 0.4690 - mse: 2.2678e-04\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9299 - bpp: 0.4702 - mse: 2.2447e-04\n",
      "Epoch 1084: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9299 - bpp: 0.4702 - mse: 2.2447e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9181 - bpp: 0.4670 - mse: 2.2027e-04\n",
      "Epoch 1085: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9181 - bpp: 0.4670 - mse: 2.2027e-04\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0245 - bpp: 0.4943 - mse: 2.5888e-04\n",
      "Epoch 1086: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0245 - bpp: 0.4943 - mse: 2.5888e-04\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9608 - bpp: 0.4855 - mse: 2.3210e-04\n",
      "Epoch 1087: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9608 - bpp: 0.4855 - mse: 2.3210e-04\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9480 - bpp: 0.4804 - mse: 2.2833e-04\n",
      "Epoch 1088: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 0.9480 - bpp: 0.4804 - mse: 2.2833e-04\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9780 - bpp: 0.4832 - mse: 2.4158e-04\n",
      "Epoch 1089: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9780 - bpp: 0.4832 - mse: 2.4158e-04\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9458 - bpp: 0.4803 - mse: 2.2730e-04\n",
      "Epoch 1090: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9458 - bpp: 0.4803 - mse: 2.2730e-04\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9362 - bpp: 0.4786 - mse: 2.2343e-04\n",
      "Epoch 1091: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.9362 - bpp: 0.4786 - mse: 2.2343e-04\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9787 - bpp: 0.4897 - mse: 2.3877e-04\n",
      "Epoch 1092: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9787 - bpp: 0.4897 - mse: 2.3877e-04\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0415 - bpp: 0.5096 - mse: 2.5969e-04\n",
      "Epoch 1093: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.0415 - bpp: 0.5096 - mse: 2.5969e-04\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0262 - bpp: 0.4999 - mse: 2.5698e-04\n",
      "Epoch 1094: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0262 - bpp: 0.4999 - mse: 2.5698e-04\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9261 - bpp: 0.4655 - mse: 2.2489e-04\n",
      "Epoch 1095: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9261 - bpp: 0.4655 - mse: 2.2489e-04\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9806 - bpp: 0.4764 - mse: 2.4619e-04\n",
      "Epoch 1096: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9806 - bpp: 0.4764 - mse: 2.4619e-04\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9175 - bpp: 0.4729 - mse: 2.1706e-04\n",
      "Epoch 1097: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9175 - bpp: 0.4729 - mse: 2.1706e-04\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9731 - bpp: 0.4893 - mse: 2.3626e-04\n",
      "Epoch 1098: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.9731 - bpp: 0.4893 - mse: 2.3626e-04\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9754 - bpp: 0.4801 - mse: 2.4186e-04\n",
      "Epoch 1099: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9754 - bpp: 0.4801 - mse: 2.4186e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9720 - bpp: 0.4834 - mse: 2.3854e-04\n",
      "Epoch 1100: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9720 - bpp: 0.4834 - mse: 2.3854e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9489 - bpp: 0.4822 - mse: 2.2790e-04\n",
      "Epoch 1101: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9489 - bpp: 0.4822 - mse: 2.2790e-04\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8807 - bpp: 0.4665 - mse: 2.0221e-04\n",
      "Epoch 1102: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.8807 - bpp: 0.4665 - mse: 2.0221e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0886 - bpp: 0.4926 - mse: 2.9101e-04\n",
      "Epoch 1103: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0886 - bpp: 0.4926 - mse: 2.9101e-04\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0220 - bpp: 0.4960 - mse: 2.5681e-04\n",
      "Epoch 1104: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 1.0220 - bpp: 0.4960 - mse: 2.5681e-04\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9337 - bpp: 0.4639 - mse: 2.2941e-04\n",
      "Epoch 1105: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9337 - bpp: 0.4639 - mse: 2.2941e-04\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0346 - bpp: 0.4914 - mse: 2.6523e-04\n",
      "Epoch 1106: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.0346 - bpp: 0.4914 - mse: 2.6523e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9777 - bpp: 0.4866 - mse: 2.3980e-04\n",
      "Epoch 1107: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9777 - bpp: 0.4866 - mse: 2.3980e-04\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9670 - bpp: 0.4859 - mse: 2.3491e-04\n",
      "Epoch 1108: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 0.9670 - bpp: 0.4859 - mse: 2.3491e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0358 - bpp: 0.4943 - mse: 2.6439e-04\n",
      "Epoch 1109: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0358 - bpp: 0.4943 - mse: 2.6439e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0033 - bpp: 0.4867 - mse: 2.5228e-04\n",
      "Epoch 1110: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0033 - bpp: 0.4867 - mse: 2.5228e-04\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9497 - bpp: 0.4738 - mse: 2.3236e-04\n",
      "Epoch 1111: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9497 - bpp: 0.4738 - mse: 2.3236e-04\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0379 - bpp: 0.5006 - mse: 2.6236e-04\n",
      "Epoch 1112: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.0379 - bpp: 0.5006 - mse: 2.6236e-04\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1021 - bpp: 0.5131 - mse: 2.8763e-04\n",
      "Epoch 1113: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.1021 - bpp: 0.5131 - mse: 2.8763e-04\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0022 - bpp: 0.4907 - mse: 2.4977e-04\n",
      "Epoch 1114: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.0022 - bpp: 0.4907 - mse: 2.4977e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0154 - bpp: 0.4991 - mse: 2.5212e-04\n",
      "Epoch 1115: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.0154 - bpp: 0.4991 - mse: 2.5212e-04\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9695 - bpp: 0.4898 - mse: 2.3419e-04\n",
      "Epoch 1116: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9695 - bpp: 0.4898 - mse: 2.3419e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0091 - bpp: 0.4900 - mse: 2.5347e-04\n",
      "Epoch 1117: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.0091 - bpp: 0.4900 - mse: 2.5347e-04\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0939 - bpp: 0.5138 - mse: 2.8325e-04\n",
      "Epoch 1118: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.0939 - bpp: 0.5138 - mse: 2.8325e-04\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9777 - bpp: 0.4837 - mse: 2.4119e-04\n",
      "Epoch 1119: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9777 - bpp: 0.4837 - mse: 2.4119e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9773 - bpp: 0.4879 - mse: 2.3896e-04\n",
      "Epoch 1120: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9773 - bpp: 0.4879 - mse: 2.3896e-04\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9603 - bpp: 0.4771 - mse: 2.3594e-04\n",
      "Epoch 1121: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 0.9603 - bpp: 0.4771 - mse: 2.3594e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0011 - bpp: 0.4799 - mse: 2.5449e-04\n",
      "Epoch 1122: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.0011 - bpp: 0.4799 - mse: 2.5449e-04\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9013 - bpp: 0.4633 - mse: 2.1390e-04\n",
      "Epoch 1123: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9013 - bpp: 0.4633 - mse: 2.1390e-04\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9357 - bpp: 0.4692 - mse: 2.2782e-04\n",
      "Epoch 1124: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9357 - bpp: 0.4692 - mse: 2.2782e-04\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0338 - bpp: 0.4967 - mse: 2.6227e-04\n",
      "Epoch 1125: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.0338 - bpp: 0.4967 - mse: 2.6227e-04\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9941 - bpp: 0.4856 - mse: 2.4830e-04\n",
      "Epoch 1126: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9941 - bpp: 0.4856 - mse: 2.4830e-04\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9560 - bpp: 0.4697 - mse: 2.3747e-04\n",
      "Epoch 1127: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.9560 - bpp: 0.4697 - mse: 2.3747e-04\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9616 - bpp: 0.4833 - mse: 2.3356e-04\n",
      "Epoch 1128: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9616 - bpp: 0.4833 - mse: 2.3356e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9949 - bpp: 0.4879 - mse: 2.4755e-04\n",
      "Epoch 1129: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 0.9949 - bpp: 0.4879 - mse: 2.4755e-04\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9177 - bpp: 0.4666 - mse: 2.2025e-04\n",
      "Epoch 1130: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9177 - bpp: 0.4666 - mse: 2.2025e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9349 - bpp: 0.4782 - mse: 2.2302e-04\n",
      "Epoch 1131: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9349 - bpp: 0.4782 - mse: 2.2302e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0077 - bpp: 0.4935 - mse: 2.5110e-04\n",
      "Epoch 1132: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.0077 - bpp: 0.4935 - mse: 2.5110e-04\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9953 - bpp: 0.4850 - mse: 2.4917e-04\n",
      "Epoch 1133: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9953 - bpp: 0.4850 - mse: 2.4917e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9523 - bpp: 0.4684 - mse: 2.3628e-04\n",
      "Epoch 1134: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9523 - bpp: 0.4684 - mse: 2.3628e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9512 - bpp: 0.4747 - mse: 2.3266e-04\n",
      "Epoch 1135: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9512 - bpp: 0.4747 - mse: 2.3266e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9601 - bpp: 0.4809 - mse: 2.3398e-04\n",
      "Epoch 1136: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9601 - bpp: 0.4809 - mse: 2.3398e-04\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9755 - bpp: 0.4874 - mse: 2.3835e-04\n",
      "Epoch 1137: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9755 - bpp: 0.4874 - mse: 2.3835e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0848 - bpp: 0.5093 - mse: 2.8099e-04\n",
      "Epoch 1138: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0848 - bpp: 0.5093 - mse: 2.8099e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5058 - mse: 2.7253e-04\n",
      "Epoch 1139: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0640 - bpp: 0.5058 - mse: 2.7253e-04\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0334 - bpp: 0.4931 - mse: 2.6382e-04\n",
      "Epoch 1140: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0334 - bpp: 0.4931 - mse: 2.6382e-04\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9797 - bpp: 0.4863 - mse: 2.4089e-04\n",
      "Epoch 1141: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9797 - bpp: 0.4863 - mse: 2.4089e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9549 - bpp: 0.4816 - mse: 2.3113e-04\n",
      "Epoch 1142: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.9549 - bpp: 0.4816 - mse: 2.3113e-04\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9169 - bpp: 0.4763 - mse: 2.1514e-04\n",
      "Epoch 1143: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9169 - bpp: 0.4763 - mse: 2.1514e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0210 - bpp: 0.4948 - mse: 2.5693e-04\n",
      "Epoch 1144: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0210 - bpp: 0.4948 - mse: 2.5693e-04\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9078 - bpp: 0.4688 - mse: 2.1431e-04\n",
      "Epoch 1145: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9078 - bpp: 0.4688 - mse: 2.1431e-04\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8981 - bpp: 0.4653 - mse: 2.1135e-04\n",
      "Epoch 1146: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.8981 - bpp: 0.4653 - mse: 2.1135e-04\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9778 - bpp: 0.4875 - mse: 2.3941e-04\n",
      "Epoch 1147: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.9778 - bpp: 0.4875 - mse: 2.3941e-04\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8799 - bpp: 0.4576 - mse: 2.0621e-04\n",
      "Epoch 1148: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.8799 - bpp: 0.4576 - mse: 2.0621e-04\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0072 - bpp: 0.4917 - mse: 2.5172e-04\n",
      "Epoch 1149: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0072 - bpp: 0.4917 - mse: 2.5172e-04\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0093 - bpp: 0.4930 - mse: 2.5208e-04\n",
      "Epoch 1150: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0093 - bpp: 0.4930 - mse: 2.5208e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9684 - bpp: 0.4816 - mse: 2.3770e-04\n",
      "Epoch 1151: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9684 - bpp: 0.4816 - mse: 2.3770e-04\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0128 - bpp: 0.4944 - mse: 2.5312e-04\n",
      "Epoch 1152: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0128 - bpp: 0.4944 - mse: 2.5312e-04\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9360 - bpp: 0.4780 - mse: 2.2362e-04\n",
      "Epoch 1153: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9360 - bpp: 0.4780 - mse: 2.2362e-04\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0521 - bpp: 0.5063 - mse: 2.6650e-04\n",
      "Epoch 1154: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.0521 - bpp: 0.5063 - mse: 2.6650e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9949 - bpp: 0.4839 - mse: 2.4952e-04\n",
      "Epoch 1155: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9949 - bpp: 0.4839 - mse: 2.4952e-04\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9621 - bpp: 0.4865 - mse: 2.3225e-04\n",
      "Epoch 1156: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 0.9621 - bpp: 0.4865 - mse: 2.3225e-04\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9907 - bpp: 0.4852 - mse: 2.4683e-04\n",
      "Epoch 1157: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9907 - bpp: 0.4852 - mse: 2.4683e-04\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9629 - bpp: 0.4826 - mse: 2.3452e-04\n",
      "Epoch 1158: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9629 - bpp: 0.4826 - mse: 2.3452e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0011 - bpp: 0.4906 - mse: 2.4924e-04\n",
      "Epoch 1159: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.0011 - bpp: 0.4906 - mse: 2.4924e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0352 - bpp: 0.4912 - mse: 2.6562e-04\n",
      "Epoch 1160: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0352 - bpp: 0.4912 - mse: 2.6562e-04\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9796 - bpp: 0.4906 - mse: 2.3874e-04\n",
      "Epoch 1161: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9796 - bpp: 0.4906 - mse: 2.3874e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9866 - bpp: 0.4871 - mse: 2.4386e-04\n",
      "Epoch 1162: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9866 - bpp: 0.4871 - mse: 2.4386e-04\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0322 - bpp: 0.4922 - mse: 2.6369e-04\n",
      "Epoch 1163: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.0322 - bpp: 0.4922 - mse: 2.6369e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5047 - mse: 2.6875e-04\n",
      "Epoch 1164: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0551 - bpp: 0.5047 - mse: 2.6875e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9907 - bpp: 0.4929 - mse: 2.4308e-04\n",
      "Epoch 1165: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9907 - bpp: 0.4929 - mse: 2.4308e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9666 - bpp: 0.4826 - mse: 2.3636e-04\n",
      "Epoch 1166: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.9666 - bpp: 0.4826 - mse: 2.3636e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0213 - bpp: 0.4967 - mse: 2.5615e-04\n",
      "Epoch 1167: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0213 - bpp: 0.4967 - mse: 2.5615e-04\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0740 - bpp: 0.5098 - mse: 2.7548e-04\n",
      "Epoch 1168: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0740 - bpp: 0.5098 - mse: 2.7548e-04\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0133 - bpp: 0.4894 - mse: 2.5581e-04\n",
      "Epoch 1169: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0133 - bpp: 0.4894 - mse: 2.5581e-04\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9294 - bpp: 0.4686 - mse: 2.2502e-04\n",
      "Epoch 1170: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9294 - bpp: 0.4686 - mse: 2.2502e-04\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9614 - bpp: 0.4764 - mse: 2.3683e-04\n",
      "Epoch 1171: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9614 - bpp: 0.4764 - mse: 2.3683e-04\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8824 - bpp: 0.4538 - mse: 2.0929e-04\n",
      "Epoch 1172: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.8824 - bpp: 0.4538 - mse: 2.0929e-04\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9022 - bpp: 0.4644 - mse: 2.1375e-04\n",
      "Epoch 1173: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9022 - bpp: 0.4644 - mse: 2.1375e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9989 - bpp: 0.4871 - mse: 2.4987e-04\n",
      "Epoch 1174: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9989 - bpp: 0.4871 - mse: 2.4987e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9785 - bpp: 0.4879 - mse: 2.3956e-04\n",
      "Epoch 1175: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9785 - bpp: 0.4879 - mse: 2.3956e-04\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9570 - bpp: 0.4863 - mse: 2.2986e-04\n",
      "Epoch 1176: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9570 - bpp: 0.4863 - mse: 2.2986e-04\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0327 - bpp: 0.5011 - mse: 2.5954e-04\n",
      "Epoch 1177: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0327 - bpp: 0.5011 - mse: 2.5954e-04\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9707 - bpp: 0.4807 - mse: 2.3922e-04\n",
      "Epoch 1178: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9707 - bpp: 0.4807 - mse: 2.3922e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0043 - bpp: 0.4698 - mse: 2.6100e-04\n",
      "Epoch 1179: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0043 - bpp: 0.4698 - mse: 2.6100e-04\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9974 - bpp: 0.4819 - mse: 2.5167e-04\n",
      "Epoch 1180: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9974 - bpp: 0.4819 - mse: 2.5167e-04\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9381 - bpp: 0.4716 - mse: 2.2777e-04\n",
      "Epoch 1181: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9381 - bpp: 0.4716 - mse: 2.2777e-04\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0056 - bpp: 0.4885 - mse: 2.5247e-04\n",
      "Epoch 1182: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0056 - bpp: 0.4885 - mse: 2.5247e-04\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0067 - bpp: 0.4848 - mse: 2.5484e-04\n",
      "Epoch 1183: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0067 - bpp: 0.4848 - mse: 2.5484e-04\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9540 - bpp: 0.4774 - mse: 2.3268e-04\n",
      "Epoch 1184: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9540 - bpp: 0.4774 - mse: 2.3268e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9642 - bpp: 0.4807 - mse: 2.3607e-04\n",
      "Epoch 1185: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9642 - bpp: 0.4807 - mse: 2.3607e-04\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9342 - bpp: 0.4775 - mse: 2.2299e-04\n",
      "Epoch 1186: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.9342 - bpp: 0.4775 - mse: 2.2299e-04\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9781 - bpp: 0.4805 - mse: 2.4295e-04\n",
      "Epoch 1187: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9781 - bpp: 0.4805 - mse: 2.4295e-04\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9061 - bpp: 0.4691 - mse: 2.1336e-04\n",
      "Epoch 1188: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9061 - bpp: 0.4691 - mse: 2.1336e-04\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0143 - bpp: 0.4952 - mse: 2.5343e-04\n",
      "Epoch 1189: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0143 - bpp: 0.4952 - mse: 2.5343e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9717 - bpp: 0.4767 - mse: 2.4169e-04\n",
      "Epoch 1190: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9717 - bpp: 0.4767 - mse: 2.4169e-04\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9398 - bpp: 0.4798 - mse: 2.2462e-04\n",
      "Epoch 1191: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9398 - bpp: 0.4798 - mse: 2.2462e-04\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9763 - bpp: 0.4773 - mse: 2.4366e-04\n",
      "Epoch 1192: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9763 - bpp: 0.4773 - mse: 2.4366e-04\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0296 - bpp: 0.4966 - mse: 2.6024e-04\n",
      "Epoch 1193: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0296 - bpp: 0.4966 - mse: 2.6024e-04\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9965 - bpp: 0.4852 - mse: 2.4966e-04\n",
      "Epoch 1194: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9965 - bpp: 0.4852 - mse: 2.4966e-04\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9040 - bpp: 0.4673 - mse: 2.1323e-04\n",
      "Epoch 1195: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9040 - bpp: 0.4673 - mse: 2.1323e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9919 - bpp: 0.4881 - mse: 2.4599e-04\n",
      "Epoch 1196: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.9919 - bpp: 0.4881 - mse: 2.4599e-04\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9351 - bpp: 0.4701 - mse: 2.2706e-04\n",
      "Epoch 1197: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9351 - bpp: 0.4701 - mse: 2.2706e-04\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9967 - bpp: 0.4909 - mse: 2.4696e-04\n",
      "Epoch 1198: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9967 - bpp: 0.4909 - mse: 2.4696e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0405 - bpp: 0.5051 - mse: 2.6141e-04\n",
      "Epoch 1199: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0405 - bpp: 0.5051 - mse: 2.6141e-04\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9643 - bpp: 0.4863 - mse: 2.3341e-04\n",
      "Epoch 1200: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9643 - bpp: 0.4863 - mse: 2.3341e-04\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9992 - bpp: 0.4960 - mse: 2.4568e-04\n",
      "Epoch 1201: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9992 - bpp: 0.4960 - mse: 2.4568e-04\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9540 - bpp: 0.4791 - mse: 2.3191e-04\n",
      "Epoch 1202: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 252ms/step - loss: 0.9540 - bpp: 0.4791 - mse: 2.3191e-04\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9960 - bpp: 0.4884 - mse: 2.4785e-04\n",
      "Epoch 1203: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9960 - bpp: 0.4884 - mse: 2.4785e-04\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9112 - bpp: 0.4693 - mse: 2.1575e-04\n",
      "Epoch 1204: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.9112 - bpp: 0.4693 - mse: 2.1575e-04\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0379 - bpp: 0.4920 - mse: 2.6655e-04\n",
      "Epoch 1205: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0379 - bpp: 0.4920 - mse: 2.6655e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9528 - bpp: 0.4779 - mse: 2.3189e-04\n",
      "Epoch 1206: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9528 - bpp: 0.4779 - mse: 2.3189e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8844 - bpp: 0.4618 - mse: 2.0635e-04\n",
      "Epoch 1207: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.8844 - bpp: 0.4618 - mse: 2.0635e-04\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0036 - bpp: 0.4887 - mse: 2.5139e-04\n",
      "Epoch 1208: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0036 - bpp: 0.4887 - mse: 2.5139e-04\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8597 - bpp: 0.4561 - mse: 1.9707e-04\n",
      "Epoch 1209: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.8597 - bpp: 0.4561 - mse: 1.9707e-04\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9806 - bpp: 0.4919 - mse: 2.3862e-04\n",
      "Epoch 1210: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 0.9806 - bpp: 0.4919 - mse: 2.3862e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9993 - bpp: 0.4918 - mse: 2.4783e-04\n",
      "Epoch 1211: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9993 - bpp: 0.4918 - mse: 2.4783e-04\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8858 - bpp: 0.4637 - mse: 2.0611e-04\n",
      "Epoch 1212: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.8858 - bpp: 0.4637 - mse: 2.0611e-04\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0223 - bpp: 0.4924 - mse: 2.5878e-04\n",
      "Epoch 1213: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0223 - bpp: 0.4924 - mse: 2.5878e-04\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9509 - bpp: 0.4834 - mse: 2.2832e-04\n",
      "Epoch 1214: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9509 - bpp: 0.4834 - mse: 2.2832e-04\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9716 - bpp: 0.4850 - mse: 2.3761e-04\n",
      "Epoch 1215: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9716 - bpp: 0.4850 - mse: 2.3761e-04\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9868 - bpp: 0.4898 - mse: 2.4264e-04\n",
      "Epoch 1216: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9868 - bpp: 0.4898 - mse: 2.4264e-04\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9977 - bpp: 0.4840 - mse: 2.5084e-04\n",
      "Epoch 1217: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9977 - bpp: 0.4840 - mse: 2.5084e-04\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9386 - bpp: 0.4765 - mse: 2.2566e-04\n",
      "Epoch 1218: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9386 - bpp: 0.4765 - mse: 2.2566e-04\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9177 - bpp: 0.4675 - mse: 2.1985e-04\n",
      "Epoch 1219: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9177 - bpp: 0.4675 - mse: 2.1985e-04\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9606 - bpp: 0.4829 - mse: 2.3327e-04\n",
      "Epoch 1220: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9606 - bpp: 0.4829 - mse: 2.3327e-04\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0616 - bpp: 0.4892 - mse: 2.7950e-04\n",
      "Epoch 1221: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0616 - bpp: 0.4892 - mse: 2.7950e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9014 - bpp: 0.4676 - mse: 2.1181e-04\n",
      "Epoch 1222: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9014 - bpp: 0.4676 - mse: 2.1181e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9147 - bpp: 0.4716 - mse: 2.1636e-04\n",
      "Epoch 1223: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9147 - bpp: 0.4716 - mse: 2.1636e-04\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9874 - bpp: 0.4879 - mse: 2.4389e-04\n",
      "Epoch 1224: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9874 - bpp: 0.4879 - mse: 2.4389e-04\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0093 - bpp: 0.4909 - mse: 2.5311e-04\n",
      "Epoch 1225: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0093 - bpp: 0.4909 - mse: 2.5311e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9024 - bpp: 0.4655 - mse: 2.1333e-04\n",
      "Epoch 1226: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9024 - bpp: 0.4655 - mse: 2.1333e-04\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9676 - bpp: 0.4768 - mse: 2.3968e-04\n",
      "Epoch 1227: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9676 - bpp: 0.4768 - mse: 2.3968e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8700 - bpp: 0.4544 - mse: 2.0295e-04\n",
      "Epoch 1228: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.8700 - bpp: 0.4544 - mse: 2.0295e-04\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0051 - bpp: 0.4871 - mse: 2.5292e-04\n",
      "Epoch 1229: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0051 - bpp: 0.4871 - mse: 2.5292e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9842 - bpp: 0.4890 - mse: 2.4177e-04\n",
      "Epoch 1230: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9842 - bpp: 0.4890 - mse: 2.4177e-04\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9912 - bpp: 0.4882 - mse: 2.4559e-04\n",
      "Epoch 1231: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9912 - bpp: 0.4882 - mse: 2.4559e-04\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0320 - bpp: 0.5026 - mse: 2.5847e-04\n",
      "Epoch 1232: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0320 - bpp: 0.5026 - mse: 2.5847e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9162 - bpp: 0.4679 - mse: 2.1893e-04\n",
      "Epoch 1233: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9162 - bpp: 0.4679 - mse: 2.1893e-04\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0124 - bpp: 0.4852 - mse: 2.5744e-04\n",
      "Epoch 1234: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0124 - bpp: 0.4852 - mse: 2.5744e-04\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0174 - bpp: 0.4879 - mse: 2.5853e-04\n",
      "Epoch 1235: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.0174 - bpp: 0.4879 - mse: 2.5853e-04\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9938 - bpp: 0.4886 - mse: 2.4666e-04\n",
      "Epoch 1236: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9938 - bpp: 0.4886 - mse: 2.4666e-04\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9959 - bpp: 0.4880 - mse: 2.4798e-04\n",
      "Epoch 1237: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9959 - bpp: 0.4880 - mse: 2.4798e-04\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9943 - bpp: 0.4881 - mse: 2.4718e-04\n",
      "Epoch 1238: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9943 - bpp: 0.4881 - mse: 2.4718e-04\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0025 - bpp: 0.4853 - mse: 2.5258e-04\n",
      "Epoch 1239: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0025 - bpp: 0.4853 - mse: 2.5258e-04\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9552 - bpp: 0.4798 - mse: 2.3211e-04\n",
      "Epoch 1240: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9552 - bpp: 0.4798 - mse: 2.3211e-04\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9645 - bpp: 0.4806 - mse: 2.3625e-04\n",
      "Epoch 1241: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9645 - bpp: 0.4806 - mse: 2.3625e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9251 - bpp: 0.4730 - mse: 2.2076e-04\n",
      "Epoch 1242: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9251 - bpp: 0.4730 - mse: 2.2076e-04\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9323 - bpp: 0.4685 - mse: 2.2644e-04\n",
      "Epoch 1243: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9323 - bpp: 0.4685 - mse: 2.2644e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0056 - bpp: 0.4966 - mse: 2.4858e-04\n",
      "Epoch 1244: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0056 - bpp: 0.4966 - mse: 2.4858e-04\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9880 - bpp: 0.4863 - mse: 2.4499e-04\n",
      "Epoch 1245: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 0.9880 - bpp: 0.4863 - mse: 2.4499e-04\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9461 - bpp: 0.4705 - mse: 2.3221e-04\n",
      "Epoch 1246: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9461 - bpp: 0.4705 - mse: 2.3221e-04\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0287 - bpp: 0.5017 - mse: 2.5730e-04\n",
      "Epoch 1247: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0287 - bpp: 0.5017 - mse: 2.5730e-04\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0289 - bpp: 0.5010 - mse: 2.5779e-04\n",
      "Epoch 1248: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0289 - bpp: 0.5010 - mse: 2.5779e-04\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0308 - bpp: 0.5025 - mse: 2.5796e-04\n",
      "Epoch 1249: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0308 - bpp: 0.5025 - mse: 2.5796e-04\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9680 - bpp: 0.4864 - mse: 2.3514e-04\n",
      "Epoch 1250: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9680 - bpp: 0.4864 - mse: 2.3514e-04\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9408 - bpp: 0.4779 - mse: 2.2599e-04\n",
      "Epoch 1251: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.9408 - bpp: 0.4779 - mse: 2.2599e-04\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0885 - bpp: 0.5092 - mse: 2.8285e-04\n",
      "Epoch 1252: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0885 - bpp: 0.5092 - mse: 2.8285e-04\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9353 - bpp: 0.4762 - mse: 2.2417e-04\n",
      "Epoch 1253: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9353 - bpp: 0.4762 - mse: 2.2417e-04\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0459 - bpp: 0.4898 - mse: 2.7151e-04\n",
      "Epoch 1254: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0459 - bpp: 0.4898 - mse: 2.7151e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9479 - bpp: 0.4765 - mse: 2.3014e-04\n",
      "Epoch 1255: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9479 - bpp: 0.4765 - mse: 2.3014e-04\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9222 - bpp: 0.4691 - mse: 2.2124e-04\n",
      "Epoch 1256: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9222 - bpp: 0.4691 - mse: 2.2124e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0437 - bpp: 0.5035 - mse: 2.6378e-04\n",
      "Epoch 1257: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0437 - bpp: 0.5035 - mse: 2.6378e-04\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9942 - bpp: 0.4878 - mse: 2.4728e-04\n",
      "Epoch 1258: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9942 - bpp: 0.4878 - mse: 2.4728e-04\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9230 - bpp: 0.4727 - mse: 2.1986e-04\n",
      "Epoch 1259: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9230 - bpp: 0.4727 - mse: 2.1986e-04\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9841 - bpp: 0.4884 - mse: 2.4202e-04\n",
      "Epoch 1260: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9841 - bpp: 0.4884 - mse: 2.4202e-04\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9133 - bpp: 0.4709 - mse: 2.1597e-04\n",
      "Epoch 1261: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9133 - bpp: 0.4709 - mse: 2.1597e-04\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9831 - bpp: 0.4851 - mse: 2.4317e-04\n",
      "Epoch 1262: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9831 - bpp: 0.4851 - mse: 2.4317e-04\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9478 - bpp: 0.4693 - mse: 2.3362e-04\n",
      "Epoch 1263: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9478 - bpp: 0.4693 - mse: 2.3362e-04\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9045 - bpp: 0.4667 - mse: 2.1379e-04\n",
      "Epoch 1264: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9045 - bpp: 0.4667 - mse: 2.1379e-04\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0555 - bpp: 0.5020 - mse: 2.7027e-04\n",
      "Epoch 1265: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.0555 - bpp: 0.5020 - mse: 2.7027e-04\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9991 - bpp: 0.4891 - mse: 2.4903e-04\n",
      "Epoch 1266: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.9991 - bpp: 0.4891 - mse: 2.4903e-04\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9691 - bpp: 0.4858 - mse: 2.3596e-04\n",
      "Epoch 1267: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9691 - bpp: 0.4858 - mse: 2.3596e-04\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8850 - bpp: 0.4585 - mse: 2.0826e-04\n",
      "Epoch 1268: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.8850 - bpp: 0.4585 - mse: 2.0826e-04\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9164 - bpp: 0.4689 - mse: 2.1852e-04\n",
      "Epoch 1269: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9164 - bpp: 0.4689 - mse: 2.1852e-04\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9665 - bpp: 0.4671 - mse: 2.4383e-04\n",
      "Epoch 1270: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9665 - bpp: 0.4671 - mse: 2.4383e-04\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9975 - bpp: 0.4927 - mse: 2.4646e-04\n",
      "Epoch 1271: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 0.9975 - bpp: 0.4927 - mse: 2.4646e-04\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9055 - bpp: 0.4612 - mse: 2.1698e-04\n",
      "Epoch 1272: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.9055 - bpp: 0.4612 - mse: 2.1698e-04\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9636 - bpp: 0.4846 - mse: 2.3385e-04\n",
      "Epoch 1273: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9636 - bpp: 0.4846 - mse: 2.3385e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8979 - bpp: 0.4663 - mse: 2.1077e-04\n",
      "Epoch 1274: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.8979 - bpp: 0.4663 - mse: 2.1077e-04\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.4916 - mse: 2.6155e-04\n",
      "Epoch 1275: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0273 - bpp: 0.4916 - mse: 2.6155e-04\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9588 - bpp: 0.4830 - mse: 2.3233e-04\n",
      "Epoch 1276: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9588 - bpp: 0.4830 - mse: 2.3233e-04\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9435 - bpp: 0.4705 - mse: 2.3092e-04\n",
      "Epoch 1277: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9435 - bpp: 0.4705 - mse: 2.3092e-04\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9962 - bpp: 0.4912 - mse: 2.4655e-04\n",
      "Epoch 1278: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9962 - bpp: 0.4912 - mse: 2.4655e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9748 - bpp: 0.4882 - mse: 2.3760e-04\n",
      "Epoch 1279: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.9748 - bpp: 0.4882 - mse: 2.3760e-04\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9525 - bpp: 0.4816 - mse: 2.2990e-04\n",
      "Epoch 1280: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9525 - bpp: 0.4816 - mse: 2.2990e-04\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9768 - bpp: 0.4830 - mse: 2.4111e-04\n",
      "Epoch 1281: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.9768 - bpp: 0.4830 - mse: 2.4111e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9527 - bpp: 0.4721 - mse: 2.3465e-04\n",
      "Epoch 1282: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9527 - bpp: 0.4721 - mse: 2.3465e-04\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9866 - bpp: 0.4790 - mse: 2.4788e-04\n",
      "Epoch 1283: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 0.9866 - bpp: 0.4790 - mse: 2.4788e-04\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9802 - bpp: 0.4818 - mse: 2.4335e-04\n",
      "Epoch 1284: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9802 - bpp: 0.4818 - mse: 2.4335e-04\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9299 - bpp: 0.4750 - mse: 2.2211e-04\n",
      "Epoch 1285: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9299 - bpp: 0.4750 - mse: 2.2211e-04\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9425 - bpp: 0.4774 - mse: 2.2710e-04\n",
      "Epoch 1286: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9425 - bpp: 0.4774 - mse: 2.2710e-04\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9884 - bpp: 0.4844 - mse: 2.4611e-04\n",
      "Epoch 1287: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9884 - bpp: 0.4844 - mse: 2.4611e-04\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9365 - bpp: 0.4720 - mse: 2.2680e-04\n",
      "Epoch 1288: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9365 - bpp: 0.4720 - mse: 2.2680e-04\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9628 - bpp: 0.4803 - mse: 2.3559e-04\n",
      "Epoch 1289: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9628 - bpp: 0.4803 - mse: 2.3559e-04\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8964 - bpp: 0.4670 - mse: 2.0963e-04\n",
      "Epoch 1290: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.8964 - bpp: 0.4670 - mse: 2.0963e-04\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9904 - bpp: 0.4855 - mse: 2.4653e-04\n",
      "Epoch 1291: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9904 - bpp: 0.4855 - mse: 2.4653e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9263 - bpp: 0.4730 - mse: 2.2135e-04\n",
      "Epoch 1292: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9263 - bpp: 0.4730 - mse: 2.2135e-04\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9950 - bpp: 0.4885 - mse: 2.4731e-04\n",
      "Epoch 1293: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9950 - bpp: 0.4885 - mse: 2.4731e-04\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8866 - bpp: 0.4554 - mse: 2.1055e-04\n",
      "Epoch 1294: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.8866 - bpp: 0.4554 - mse: 2.1055e-04\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9891 - bpp: 0.4918 - mse: 2.4282e-04\n",
      "Epoch 1295: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9891 - bpp: 0.4918 - mse: 2.4282e-04\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9223 - bpp: 0.4733 - mse: 2.1923e-04\n",
      "Epoch 1296: loss did not improve from 0.85194\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9223 - bpp: 0.4733 - mse: 2.1923e-04\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8505 - bpp: 0.4475 - mse: 1.9679e-04\n",
      "Epoch 1297: loss improved from 0.85194 to 0.85049, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.8505 - bpp: 0.4475 - mse: 1.9679e-04\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9191 - bpp: 0.4686 - mse: 2.1999e-04\n",
      "Epoch 1298: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 0.9191 - bpp: 0.4686 - mse: 2.1999e-04\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9281 - bpp: 0.4677 - mse: 2.2480e-04\n",
      "Epoch 1299: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.9281 - bpp: 0.4677 - mse: 2.2480e-04\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9489 - bpp: 0.4775 - mse: 2.3017e-04\n",
      "Epoch 1300: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9489 - bpp: 0.4775 - mse: 2.3017e-04\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9226 - bpp: 0.4679 - mse: 2.2203e-04\n",
      "Epoch 1301: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9226 - bpp: 0.4679 - mse: 2.2203e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9631 - bpp: 0.4837 - mse: 2.3406e-04\n",
      "Epoch 1302: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9631 - bpp: 0.4837 - mse: 2.3406e-04\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9320 - bpp: 0.4688 - mse: 2.2613e-04\n",
      "Epoch 1303: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 0.9320 - bpp: 0.4688 - mse: 2.2613e-04\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9484 - bpp: 0.4701 - mse: 2.3351e-04\n",
      "Epoch 1304: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9484 - bpp: 0.4701 - mse: 2.3351e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9021 - bpp: 0.4677 - mse: 2.1211e-04\n",
      "Epoch 1305: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 0.9021 - bpp: 0.4677 - mse: 2.1211e-04\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9577 - bpp: 0.4813 - mse: 2.3262e-04\n",
      "Epoch 1306: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9577 - bpp: 0.4813 - mse: 2.3262e-04\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9601 - bpp: 0.4714 - mse: 2.3859e-04\n",
      "Epoch 1307: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9601 - bpp: 0.4714 - mse: 2.3859e-04\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0295 - bpp: 0.4996 - mse: 2.5875e-04\n",
      "Epoch 1308: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0295 - bpp: 0.4996 - mse: 2.5875e-04\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9584 - bpp: 0.4864 - mse: 2.3047e-04\n",
      "Epoch 1309: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9584 - bpp: 0.4864 - mse: 2.3047e-04\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9882 - bpp: 0.4871 - mse: 2.4468e-04\n",
      "Epoch 1310: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9882 - bpp: 0.4871 - mse: 2.4468e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0302 - bpp: 0.4929 - mse: 2.6234e-04\n",
      "Epoch 1311: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.0302 - bpp: 0.4929 - mse: 2.6234e-04\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9883 - bpp: 0.4755 - mse: 2.5040e-04\n",
      "Epoch 1312: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9883 - bpp: 0.4755 - mse: 2.5040e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9511 - bpp: 0.4718 - mse: 2.3405e-04\n",
      "Epoch 1313: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 0.9511 - bpp: 0.4718 - mse: 2.3405e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9954 - bpp: 0.4883 - mse: 2.4760e-04\n",
      "Epoch 1314: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9954 - bpp: 0.4883 - mse: 2.4760e-04\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9408 - bpp: 0.4699 - mse: 2.2992e-04\n",
      "Epoch 1315: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 0.9408 - bpp: 0.4699 - mse: 2.2992e-04\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0760 - bpp: 0.5024 - mse: 2.8004e-04\n",
      "Epoch 1316: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0760 - bpp: 0.5024 - mse: 2.8004e-04\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9012 - bpp: 0.4666 - mse: 2.1219e-04\n",
      "Epoch 1317: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9012 - bpp: 0.4666 - mse: 2.1219e-04\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9243 - bpp: 0.4697 - mse: 2.2196e-04\n",
      "Epoch 1318: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9243 - bpp: 0.4697 - mse: 2.2196e-04\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9618 - bpp: 0.4741 - mse: 2.3816e-04\n",
      "Epoch 1319: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9618 - bpp: 0.4741 - mse: 2.3816e-04\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9104 - bpp: 0.4600 - mse: 2.1994e-04\n",
      "Epoch 1320: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 0.9104 - bpp: 0.4600 - mse: 2.1994e-04\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9885 - bpp: 0.4835 - mse: 2.4658e-04\n",
      "Epoch 1321: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 0.9885 - bpp: 0.4835 - mse: 2.4658e-04\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9612 - bpp: 0.4807 - mse: 2.3461e-04\n",
      "Epoch 1322: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9612 - bpp: 0.4807 - mse: 2.3461e-04\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9644 - bpp: 0.4774 - mse: 2.3781e-04\n",
      "Epoch 1323: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9644 - bpp: 0.4774 - mse: 2.3781e-04\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9683 - bpp: 0.4808 - mse: 2.3800e-04\n",
      "Epoch 1324: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9683 - bpp: 0.4808 - mse: 2.3800e-04\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9485 - bpp: 0.4731 - mse: 2.3210e-04\n",
      "Epoch 1325: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9485 - bpp: 0.4731 - mse: 2.3210e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9281 - bpp: 0.4671 - mse: 2.2511e-04\n",
      "Epoch 1326: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9281 - bpp: 0.4671 - mse: 2.2511e-04\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9685 - bpp: 0.4853 - mse: 2.3595e-04\n",
      "Epoch 1327: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9685 - bpp: 0.4853 - mse: 2.3595e-04\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9408 - bpp: 0.4760 - mse: 2.2698e-04\n",
      "Epoch 1328: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.9408 - bpp: 0.4760 - mse: 2.2698e-04\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9813 - bpp: 0.4839 - mse: 2.4285e-04\n",
      "Epoch 1329: loss did not improve from 0.85049\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9813 - bpp: 0.4839 - mse: 2.4285e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8452 - bpp: 0.4501 - mse: 1.9293e-04\n",
      "Epoch 1330: loss improved from 0.85049 to 0.84522, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.8452 - bpp: 0.4501 - mse: 1.9293e-04\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9648 - bpp: 0.4813 - mse: 2.3606e-04\n",
      "Epoch 1331: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9648 - bpp: 0.4813 - mse: 2.3606e-04\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9655 - bpp: 0.4814 - mse: 2.3637e-04\n",
      "Epoch 1332: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9655 - bpp: 0.4814 - mse: 2.3637e-04\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8615 - bpp: 0.4532 - mse: 1.9933e-04\n",
      "Epoch 1333: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.8615 - bpp: 0.4532 - mse: 1.9933e-04\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9707 - bpp: 0.4802 - mse: 2.3952e-04\n",
      "Epoch 1334: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9707 - bpp: 0.4802 - mse: 2.3952e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9206 - bpp: 0.4585 - mse: 2.2564e-04\n",
      "Epoch 1335: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9206 - bpp: 0.4585 - mse: 2.2564e-04\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0024 - bpp: 0.4865 - mse: 2.5193e-04\n",
      "Epoch 1336: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0024 - bpp: 0.4865 - mse: 2.5193e-04\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8937 - bpp: 0.4631 - mse: 2.1025e-04\n",
      "Epoch 1337: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.8937 - bpp: 0.4631 - mse: 2.1025e-04\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9325 - bpp: 0.4708 - mse: 2.2541e-04\n",
      "Epoch 1338: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9325 - bpp: 0.4708 - mse: 2.2541e-04\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0282 - bpp: 0.4904 - mse: 2.6261e-04\n",
      "Epoch 1339: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0282 - bpp: 0.4904 - mse: 2.6261e-04\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9416 - bpp: 0.4751 - mse: 2.2781e-04\n",
      "Epoch 1340: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9416 - bpp: 0.4751 - mse: 2.2781e-04\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9638 - bpp: 0.4694 - mse: 2.4141e-04\n",
      "Epoch 1341: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9638 - bpp: 0.4694 - mse: 2.4141e-04\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8975 - bpp: 0.4660 - mse: 2.1068e-04\n",
      "Epoch 1342: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.8975 - bpp: 0.4660 - mse: 2.1068e-04\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0232 - bpp: 0.4933 - mse: 2.5871e-04\n",
      "Epoch 1343: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0232 - bpp: 0.4933 - mse: 2.5871e-04\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9099 - bpp: 0.4697 - mse: 2.1494e-04\n",
      "Epoch 1344: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.9099 - bpp: 0.4697 - mse: 2.1494e-04\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0566 - bpp: 0.5001 - mse: 2.7175e-04\n",
      "Epoch 1345: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0566 - bpp: 0.5001 - mse: 2.7175e-04\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9799 - bpp: 0.4825 - mse: 2.4286e-04\n",
      "Epoch 1346: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9799 - bpp: 0.4825 - mse: 2.4286e-04\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0454 - bpp: 0.4956 - mse: 2.6846e-04\n",
      "Epoch 1347: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0454 - bpp: 0.4956 - mse: 2.6846e-04\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9860 - bpp: 0.4910 - mse: 2.4168e-04\n",
      "Epoch 1348: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9860 - bpp: 0.4910 - mse: 2.4168e-04\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9217 - bpp: 0.4564 - mse: 2.2720e-04\n",
      "Epoch 1349: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9217 - bpp: 0.4564 - mse: 2.2720e-04\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9430 - bpp: 0.4757 - mse: 2.2817e-04\n",
      "Epoch 1350: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.9430 - bpp: 0.4757 - mse: 2.2817e-04\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9899 - bpp: 0.4914 - mse: 2.4339e-04\n",
      "Epoch 1351: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9899 - bpp: 0.4914 - mse: 2.4339e-04\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9902 - bpp: 0.4868 - mse: 2.4581e-04\n",
      "Epoch 1352: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9902 - bpp: 0.4868 - mse: 2.4581e-04\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0188 - bpp: 0.4899 - mse: 2.5827e-04\n",
      "Epoch 1353: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0188 - bpp: 0.4899 - mse: 2.5827e-04\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9197 - bpp: 0.4649 - mse: 2.2209e-04\n",
      "Epoch 1354: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9197 - bpp: 0.4649 - mse: 2.2209e-04\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8678 - bpp: 0.4513 - mse: 2.0340e-04\n",
      "Epoch 1355: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 0.8678 - bpp: 0.4513 - mse: 2.0340e-04\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8791 - bpp: 0.4609 - mse: 2.0420e-04\n",
      "Epoch 1356: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.8791 - bpp: 0.4609 - mse: 2.0420e-04\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9601 - bpp: 0.4724 - mse: 2.3812e-04\n",
      "Epoch 1357: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9601 - bpp: 0.4724 - mse: 2.3812e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9266 - bpp: 0.4671 - mse: 2.2435e-04\n",
      "Epoch 1358: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9266 - bpp: 0.4671 - mse: 2.2435e-04\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9499 - bpp: 0.4783 - mse: 2.3025e-04\n",
      "Epoch 1359: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9499 - bpp: 0.4783 - mse: 2.3025e-04\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9317 - bpp: 0.4764 - mse: 2.2234e-04\n",
      "Epoch 1360: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.9317 - bpp: 0.4764 - mse: 2.2234e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8478 - bpp: 0.4519 - mse: 1.9330e-04\n",
      "Epoch 1361: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.8478 - bpp: 0.4519 - mse: 1.9330e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9112 - bpp: 0.4722 - mse: 2.1434e-04\n",
      "Epoch 1362: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9112 - bpp: 0.4722 - mse: 2.1434e-04\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9039 - bpp: 0.4633 - mse: 2.1514e-04\n",
      "Epoch 1363: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9039 - bpp: 0.4633 - mse: 2.1514e-04\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9098 - bpp: 0.4669 - mse: 2.1625e-04\n",
      "Epoch 1364: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9098 - bpp: 0.4669 - mse: 2.1625e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0134 - bpp: 0.4918 - mse: 2.5467e-04\n",
      "Epoch 1365: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0134 - bpp: 0.4918 - mse: 2.5467e-04\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9449 - bpp: 0.4721 - mse: 2.3085e-04\n",
      "Epoch 1366: loss did not improve from 0.84522\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9449 - bpp: 0.4721 - mse: 2.3085e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8288 - bpp: 0.4519 - mse: 1.8402e-04\n",
      "Epoch 1367: loss improved from 0.84522 to 0.82877, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.8288 - bpp: 0.4519 - mse: 1.8402e-04\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0539 - bpp: 0.5015 - mse: 2.6972e-04\n",
      "Epoch 1368: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0539 - bpp: 0.5015 - mse: 2.6972e-04\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9031 - bpp: 0.4622 - mse: 2.1530e-04\n",
      "Epoch 1369: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9031 - bpp: 0.4622 - mse: 2.1530e-04\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9475 - bpp: 0.4770 - mse: 2.2974e-04\n",
      "Epoch 1370: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9475 - bpp: 0.4770 - mse: 2.2974e-04\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0000 - bpp: 0.4836 - mse: 2.5215e-04\n",
      "Epoch 1371: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0000 - bpp: 0.4836 - mse: 2.5215e-04\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9737 - bpp: 0.4845 - mse: 2.3886e-04\n",
      "Epoch 1372: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9737 - bpp: 0.4845 - mse: 2.3886e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9231 - bpp: 0.4731 - mse: 2.1968e-04\n",
      "Epoch 1373: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9231 - bpp: 0.4731 - mse: 2.1968e-04\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9985 - bpp: 0.4893 - mse: 2.4862e-04\n",
      "Epoch 1374: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9985 - bpp: 0.4893 - mse: 2.4862e-04\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9387 - bpp: 0.4730 - mse: 2.2743e-04\n",
      "Epoch 1375: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9387 - bpp: 0.4730 - mse: 2.2743e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9574 - bpp: 0.4795 - mse: 2.3335e-04\n",
      "Epoch 1376: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9574 - bpp: 0.4795 - mse: 2.3335e-04\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0376 - bpp: 0.4946 - mse: 2.6511e-04\n",
      "Epoch 1377: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0376 - bpp: 0.4946 - mse: 2.6511e-04\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9861 - bpp: 0.4844 - mse: 2.4497e-04\n",
      "Epoch 1378: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 249ms/step - loss: 0.9861 - bpp: 0.4844 - mse: 2.4497e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9631 - bpp: 0.4814 - mse: 2.3521e-04\n",
      "Epoch 1379: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9631 - bpp: 0.4814 - mse: 2.3521e-04\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9336 - bpp: 0.4742 - mse: 2.2434e-04\n",
      "Epoch 1380: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9336 - bpp: 0.4742 - mse: 2.2434e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9188 - bpp: 0.4652 - mse: 2.2147e-04\n",
      "Epoch 1381: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9188 - bpp: 0.4652 - mse: 2.2147e-04\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0059 - bpp: 0.4884 - mse: 2.5270e-04\n",
      "Epoch 1382: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0059 - bpp: 0.4884 - mse: 2.5270e-04\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9802 - bpp: 0.4882 - mse: 2.4025e-04\n",
      "Epoch 1383: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9802 - bpp: 0.4882 - mse: 2.4025e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9320 - bpp: 0.4741 - mse: 2.2357e-04\n",
      "Epoch 1384: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9320 - bpp: 0.4741 - mse: 2.2357e-04\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9583 - bpp: 0.4777 - mse: 2.3464e-04\n",
      "Epoch 1385: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9583 - bpp: 0.4777 - mse: 2.3464e-04\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8853 - bpp: 0.4640 - mse: 2.0571e-04\n",
      "Epoch 1386: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.8853 - bpp: 0.4640 - mse: 2.0571e-04\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0186 - bpp: 0.4908 - mse: 2.5774e-04\n",
      "Epoch 1387: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0186 - bpp: 0.4908 - mse: 2.5774e-04\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9181 - bpp: 0.4722 - mse: 2.1773e-04\n",
      "Epoch 1388: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9181 - bpp: 0.4722 - mse: 2.1773e-04\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9054 - bpp: 0.4689 - mse: 2.1314e-04\n",
      "Epoch 1389: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9054 - bpp: 0.4689 - mse: 2.1314e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.4924 - mse: 2.5903e-04\n",
      "Epoch 1390: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0229 - bpp: 0.4924 - mse: 2.5903e-04\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9443 - bpp: 0.4789 - mse: 2.2726e-04\n",
      "Epoch 1391: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9443 - bpp: 0.4789 - mse: 2.2726e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9961 - bpp: 0.4860 - mse: 2.4907e-04\n",
      "Epoch 1392: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9961 - bpp: 0.4860 - mse: 2.4907e-04\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9665 - bpp: 0.4814 - mse: 2.3690e-04\n",
      "Epoch 1393: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9665 - bpp: 0.4814 - mse: 2.3690e-04\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9852 - bpp: 0.4926 - mse: 2.4055e-04\n",
      "Epoch 1394: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9852 - bpp: 0.4926 - mse: 2.4055e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0005 - bpp: 0.4892 - mse: 2.4964e-04\n",
      "Epoch 1395: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0005 - bpp: 0.4892 - mse: 2.4964e-04\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0062 - bpp: 0.4892 - mse: 2.5245e-04\n",
      "Epoch 1396: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0062 - bpp: 0.4892 - mse: 2.5245e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9842 - bpp: 0.4898 - mse: 2.4141e-04\n",
      "Epoch 1397: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9842 - bpp: 0.4898 - mse: 2.4141e-04\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9678 - bpp: 0.4805 - mse: 2.3790e-04\n",
      "Epoch 1398: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9678 - bpp: 0.4805 - mse: 2.3790e-04\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9814 - bpp: 0.4839 - mse: 2.4295e-04\n",
      "Epoch 1399: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9814 - bpp: 0.4839 - mse: 2.4295e-04\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9515 - bpp: 0.4763 - mse: 2.3204e-04\n",
      "Epoch 1400: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9515 - bpp: 0.4763 - mse: 2.3204e-04\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9862 - bpp: 0.4829 - mse: 2.4574e-04\n",
      "Epoch 1401: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.9862 - bpp: 0.4829 - mse: 2.4574e-04\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9234 - bpp: 0.4679 - mse: 2.2244e-04\n",
      "Epoch 1402: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.9234 - bpp: 0.4679 - mse: 2.2244e-04\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9437 - bpp: 0.4739 - mse: 2.2941e-04\n",
      "Epoch 1403: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9437 - bpp: 0.4739 - mse: 2.2941e-04\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0066 - bpp: 0.4899 - mse: 2.5231e-04\n",
      "Epoch 1404: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0066 - bpp: 0.4899 - mse: 2.5231e-04\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8960 - bpp: 0.4630 - mse: 2.1143e-04\n",
      "Epoch 1405: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.8960 - bpp: 0.4630 - mse: 2.1143e-04\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0261 - bpp: 0.4961 - mse: 2.5876e-04\n",
      "Epoch 1406: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0261 - bpp: 0.4961 - mse: 2.5876e-04\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9350 - bpp: 0.4741 - mse: 2.2505e-04\n",
      "Epoch 1407: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9350 - bpp: 0.4741 - mse: 2.2505e-04\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0378 - bpp: 0.4967 - mse: 2.6419e-04\n",
      "Epoch 1408: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0378 - bpp: 0.4967 - mse: 2.6419e-04\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9931 - bpp: 0.4856 - mse: 2.4781e-04\n",
      "Epoch 1409: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 0.9931 - bpp: 0.4856 - mse: 2.4781e-04\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9344 - bpp: 0.4728 - mse: 2.2540e-04\n",
      "Epoch 1410: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9344 - bpp: 0.4728 - mse: 2.2540e-04\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9143 - bpp: 0.4782 - mse: 2.1297e-04\n",
      "Epoch 1411: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9143 - bpp: 0.4782 - mse: 2.1297e-04\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8690 - bpp: 0.4555 - mse: 2.0190e-04\n",
      "Epoch 1412: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.8690 - bpp: 0.4555 - mse: 2.0190e-04\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9855 - bpp: 0.4915 - mse: 2.4124e-04\n",
      "Epoch 1413: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9855 - bpp: 0.4915 - mse: 2.4124e-04\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8803 - bpp: 0.4603 - mse: 2.0509e-04\n",
      "Epoch 1414: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.8803 - bpp: 0.4603 - mse: 2.0509e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8512 - bpp: 0.4554 - mse: 1.9324e-04\n",
      "Epoch 1415: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.8512 - bpp: 0.4554 - mse: 1.9324e-04\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9322 - bpp: 0.4736 - mse: 2.2395e-04\n",
      "Epoch 1416: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9322 - bpp: 0.4736 - mse: 2.2395e-04\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9798 - bpp: 0.4844 - mse: 2.4192e-04\n",
      "Epoch 1417: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9798 - bpp: 0.4844 - mse: 2.4192e-04\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0153 - bpp: 0.4908 - mse: 2.5610e-04\n",
      "Epoch 1418: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0153 - bpp: 0.4908 - mse: 2.5610e-04\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9926 - bpp: 0.4790 - mse: 2.5080e-04\n",
      "Epoch 1419: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9926 - bpp: 0.4790 - mse: 2.5080e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9806 - bpp: 0.4807 - mse: 2.4409e-04\n",
      "Epoch 1420: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9806 - bpp: 0.4807 - mse: 2.4409e-04\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9184 - bpp: 0.4738 - mse: 2.1707e-04\n",
      "Epoch 1421: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9184 - bpp: 0.4738 - mse: 2.1707e-04\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9083 - bpp: 0.4700 - mse: 2.1402e-04\n",
      "Epoch 1422: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9083 - bpp: 0.4700 - mse: 2.1402e-04\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.4944 - mse: 2.6050e-04\n",
      "Epoch 1423: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0279 - bpp: 0.4944 - mse: 2.6050e-04\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9635 - bpp: 0.4757 - mse: 2.3817e-04\n",
      "Epoch 1424: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9635 - bpp: 0.4757 - mse: 2.3817e-04\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9743 - bpp: 0.4825 - mse: 2.4014e-04\n",
      "Epoch 1425: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 0.9743 - bpp: 0.4825 - mse: 2.4014e-04\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9210 - bpp: 0.4675 - mse: 2.2143e-04\n",
      "Epoch 1426: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9210 - bpp: 0.4675 - mse: 2.2143e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9521 - bpp: 0.4747 - mse: 2.3314e-04\n",
      "Epoch 1427: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 0.9521 - bpp: 0.4747 - mse: 2.3314e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8699 - bpp: 0.4593 - mse: 2.0050e-04\n",
      "Epoch 1428: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.8699 - bpp: 0.4593 - mse: 2.0050e-04\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0302 - bpp: 0.4899 - mse: 2.6382e-04\n",
      "Epoch 1429: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0302 - bpp: 0.4899 - mse: 2.6382e-04\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0187 - bpp: 0.4938 - mse: 2.5627e-04\n",
      "Epoch 1430: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0187 - bpp: 0.4938 - mse: 2.5627e-04\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8451 - bpp: 0.4512 - mse: 1.9235e-04\n",
      "Epoch 1431: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.8451 - bpp: 0.4512 - mse: 1.9235e-04\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9188 - bpp: 0.4674 - mse: 2.2044e-04\n",
      "Epoch 1432: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9188 - bpp: 0.4674 - mse: 2.2044e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9519 - bpp: 0.4764 - mse: 2.3217e-04\n",
      "Epoch 1433: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9519 - bpp: 0.4764 - mse: 2.3217e-04\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9275 - bpp: 0.4671 - mse: 2.2480e-04\n",
      "Epoch 1434: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9275 - bpp: 0.4671 - mse: 2.2480e-04\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9247 - bpp: 0.4720 - mse: 2.2103e-04\n",
      "Epoch 1435: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9247 - bpp: 0.4720 - mse: 2.2103e-04\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9477 - bpp: 0.4785 - mse: 2.2908e-04\n",
      "Epoch 1436: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9477 - bpp: 0.4785 - mse: 2.2908e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8919 - bpp: 0.4691 - mse: 2.0643e-04\n",
      "Epoch 1437: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.8919 - bpp: 0.4691 - mse: 2.0643e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9284 - bpp: 0.4712 - mse: 2.2328e-04\n",
      "Epoch 1438: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9284 - bpp: 0.4712 - mse: 2.2328e-04\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9683 - bpp: 0.4888 - mse: 2.3411e-04\n",
      "Epoch 1439: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9683 - bpp: 0.4888 - mse: 2.3411e-04\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9625 - bpp: 0.4826 - mse: 2.3435e-04\n",
      "Epoch 1440: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 0.9625 - bpp: 0.4826 - mse: 2.3435e-04\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9447 - bpp: 0.4731 - mse: 2.3025e-04\n",
      "Epoch 1441: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9447 - bpp: 0.4731 - mse: 2.3025e-04\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9704 - bpp: 0.4734 - mse: 2.4264e-04\n",
      "Epoch 1442: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.9704 - bpp: 0.4734 - mse: 2.4264e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9741 - bpp: 0.4933 - mse: 2.3477e-04\n",
      "Epoch 1443: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9741 - bpp: 0.4933 - mse: 2.3477e-04\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9869 - bpp: 0.4885 - mse: 2.4337e-04\n",
      "Epoch 1444: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 0.9869 - bpp: 0.4885 - mse: 2.4337e-04\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9263 - bpp: 0.4632 - mse: 2.2609e-04\n",
      "Epoch 1445: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9263 - bpp: 0.4632 - mse: 2.2609e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8835 - bpp: 0.4639 - mse: 2.0489e-04\n",
      "Epoch 1446: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.8835 - bpp: 0.4639 - mse: 2.0489e-04\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0639 - bpp: 0.5079 - mse: 2.7150e-04\n",
      "Epoch 1447: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0639 - bpp: 0.5079 - mse: 2.7150e-04\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0161 - bpp: 0.4931 - mse: 2.5537e-04\n",
      "Epoch 1448: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0161 - bpp: 0.4931 - mse: 2.5537e-04\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9871 - bpp: 0.4893 - mse: 2.4307e-04\n",
      "Epoch 1449: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9871 - bpp: 0.4893 - mse: 2.4307e-04\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9474 - bpp: 0.4779 - mse: 2.2925e-04\n",
      "Epoch 1450: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9474 - bpp: 0.4779 - mse: 2.2925e-04\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9723 - bpp: 0.4741 - mse: 2.4324e-04\n",
      "Epoch 1451: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9723 - bpp: 0.4741 - mse: 2.4324e-04\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9617 - bpp: 0.4783 - mse: 2.3606e-04\n",
      "Epoch 1452: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.9617 - bpp: 0.4783 - mse: 2.3606e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9748 - bpp: 0.4948 - mse: 2.3437e-04\n",
      "Epoch 1453: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9748 - bpp: 0.4948 - mse: 2.3437e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9110 - bpp: 0.4684 - mse: 2.1610e-04\n",
      "Epoch 1454: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9110 - bpp: 0.4684 - mse: 2.1610e-04\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9186 - bpp: 0.4701 - mse: 2.1896e-04\n",
      "Epoch 1455: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9186 - bpp: 0.4701 - mse: 2.1896e-04\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9087 - bpp: 0.4655 - mse: 2.1639e-04\n",
      "Epoch 1456: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9087 - bpp: 0.4655 - mse: 2.1639e-04\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9668 - bpp: 0.4767 - mse: 2.3930e-04\n",
      "Epoch 1457: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9668 - bpp: 0.4767 - mse: 2.3930e-04\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8959 - bpp: 0.4569 - mse: 2.1436e-04\n",
      "Epoch 1458: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 0.8959 - bpp: 0.4569 - mse: 2.1436e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9786 - bpp: 0.4822 - mse: 2.4237e-04\n",
      "Epoch 1459: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9786 - bpp: 0.4822 - mse: 2.4237e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9363 - bpp: 0.4803 - mse: 2.2265e-04\n",
      "Epoch 1460: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9363 - bpp: 0.4803 - mse: 2.2265e-04\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9953 - bpp: 0.4925 - mse: 2.4550e-04\n",
      "Epoch 1461: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9953 - bpp: 0.4925 - mse: 2.4550e-04\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0122 - bpp: 0.4904 - mse: 2.5479e-04\n",
      "Epoch 1462: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0122 - bpp: 0.4904 - mse: 2.5479e-04\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9730 - bpp: 0.4845 - mse: 2.3853e-04\n",
      "Epoch 1463: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9730 - bpp: 0.4845 - mse: 2.3853e-04\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9876 - bpp: 0.4876 - mse: 2.4416e-04\n",
      "Epoch 1464: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.9876 - bpp: 0.4876 - mse: 2.4416e-04\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9507 - bpp: 0.4773 - mse: 2.3116e-04\n",
      "Epoch 1465: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 0.9507 - bpp: 0.4773 - mse: 2.3116e-04\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8922 - bpp: 0.4657 - mse: 2.0828e-04\n",
      "Epoch 1466: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 0.8922 - bpp: 0.4657 - mse: 2.0828e-04\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8879 - bpp: 0.4634 - mse: 2.0727e-04\n",
      "Epoch 1467: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.8879 - bpp: 0.4634 - mse: 2.0727e-04\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9160 - bpp: 0.4696 - mse: 2.1796e-04\n",
      "Epoch 1468: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 0.9160 - bpp: 0.4696 - mse: 2.1796e-04\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9135 - bpp: 0.4729 - mse: 2.1516e-04\n",
      "Epoch 1469: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9135 - bpp: 0.4729 - mse: 2.1516e-04\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8834 - bpp: 0.4621 - mse: 2.0576e-04\n",
      "Epoch 1470: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.8834 - bpp: 0.4621 - mse: 2.0576e-04\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9748 - bpp: 0.4835 - mse: 2.3990e-04\n",
      "Epoch 1471: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9748 - bpp: 0.4835 - mse: 2.3990e-04\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9271 - bpp: 0.4664 - mse: 2.2495e-04\n",
      "Epoch 1472: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 0.9271 - bpp: 0.4664 - mse: 2.2495e-04\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8754 - bpp: 0.4558 - mse: 2.0487e-04\n",
      "Epoch 1473: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.8754 - bpp: 0.4558 - mse: 2.0487e-04\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9985 - bpp: 0.4814 - mse: 2.5248e-04\n",
      "Epoch 1474: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9985 - bpp: 0.4814 - mse: 2.5248e-04\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9549 - bpp: 0.4743 - mse: 2.3468e-04\n",
      "Epoch 1475: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 0.9549 - bpp: 0.4743 - mse: 2.3468e-04\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9760 - bpp: 0.4863 - mse: 2.3911e-04\n",
      "Epoch 1476: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9760 - bpp: 0.4863 - mse: 2.3911e-04\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8904 - bpp: 0.4554 - mse: 2.1238e-04\n",
      "Epoch 1477: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 0.8904 - bpp: 0.4554 - mse: 2.1238e-04\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0058 - bpp: 0.4874 - mse: 2.5311e-04\n",
      "Epoch 1478: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0058 - bpp: 0.4874 - mse: 2.5311e-04\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0133 - bpp: 0.4950 - mse: 2.5307e-04\n",
      "Epoch 1479: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0133 - bpp: 0.4950 - mse: 2.5307e-04\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8807 - bpp: 0.4531 - mse: 2.0883e-04\n",
      "Epoch 1480: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.8807 - bpp: 0.4531 - mse: 2.0883e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9036 - bpp: 0.4624 - mse: 2.1544e-04\n",
      "Epoch 1481: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9036 - bpp: 0.4624 - mse: 2.1544e-04\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9653 - bpp: 0.4783 - mse: 2.3782e-04\n",
      "Epoch 1482: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9653 - bpp: 0.4783 - mse: 2.3782e-04\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9324 - bpp: 0.4793 - mse: 2.2120e-04\n",
      "Epoch 1483: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.9324 - bpp: 0.4793 - mse: 2.2120e-04\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9751 - bpp: 0.4861 - mse: 2.3877e-04\n",
      "Epoch 1484: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.9751 - bpp: 0.4861 - mse: 2.3877e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8802 - bpp: 0.4585 - mse: 2.0590e-04\n",
      "Epoch 1485: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.8802 - bpp: 0.4585 - mse: 2.0590e-04\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9874 - bpp: 0.4815 - mse: 2.4705e-04\n",
      "Epoch 1486: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9874 - bpp: 0.4815 - mse: 2.4705e-04\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9417 - bpp: 0.4804 - mse: 2.2520e-04\n",
      "Epoch 1487: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.9417 - bpp: 0.4804 - mse: 2.2520e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9689 - bpp: 0.4810 - mse: 2.3821e-04\n",
      "Epoch 1488: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.9689 - bpp: 0.4810 - mse: 2.3821e-04\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9701 - bpp: 0.4840 - mse: 2.3733e-04\n",
      "Epoch 1489: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 0.9701 - bpp: 0.4840 - mse: 2.3733e-04\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9110 - bpp: 0.4682 - mse: 2.1621e-04\n",
      "Epoch 1490: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9110 - bpp: 0.4682 - mse: 2.1621e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8893 - bpp: 0.4601 - mse: 2.0959e-04\n",
      "Epoch 1491: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.8893 - bpp: 0.4601 - mse: 2.0959e-04\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9140 - bpp: 0.4730 - mse: 2.1529e-04\n",
      "Epoch 1492: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.9140 - bpp: 0.4730 - mse: 2.1529e-04\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9271 - bpp: 0.4677 - mse: 2.2431e-04\n",
      "Epoch 1493: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.9271 - bpp: 0.4677 - mse: 2.2431e-04\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9440 - bpp: 0.4743 - mse: 2.2935e-04\n",
      "Epoch 1494: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 0.9440 - bpp: 0.4743 - mse: 2.2935e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9911 - bpp: 0.4829 - mse: 2.4815e-04\n",
      "Epoch 1495: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.9911 - bpp: 0.4829 - mse: 2.4815e-04\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9750 - bpp: 0.4754 - mse: 2.4394e-04\n",
      "Epoch 1496: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 0.9750 - bpp: 0.4754 - mse: 2.4394e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9340 - bpp: 0.4816 - mse: 2.2090e-04\n",
      "Epoch 1497: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.9340 - bpp: 0.4816 - mse: 2.2090e-04\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0147 - bpp: 0.4858 - mse: 2.5823e-04\n",
      "Epoch 1498: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0147 - bpp: 0.4858 - mse: 2.5823e-04\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9511 - bpp: 0.4698 - mse: 2.3499e-04\n",
      "Epoch 1499: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.9511 - bpp: 0.4698 - mse: 2.3499e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0341 - bpp: 0.4951 - mse: 2.6320e-04\n",
      "Epoch 1500: loss did not improve from 0.82877\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0341 - bpp: 0.4951 - mse: 2.6320e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220506-205303/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_11 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_11.compile()\n",
    "trainer_11.fit()\n",
    "trainer_11.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 68.6722 - bpp: 5.3060 - mse: 0.0155\n",
      "Epoch 1: loss improved from inf to 68.67219, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 72s 181ms/step - loss: 68.6722 - bpp: 5.3060 - mse: 0.0155\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4483 - bpp: 5.1678 - mse: 0.0028\n",
      "Epoch 2: loss improved from 68.67219 to 16.44827, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 16.4483 - bpp: 5.1678 - mse: 0.0028\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2616 - bpp: 5.0324 - mse: 0.0020\n",
      "Epoch 3: loss improved from 16.44827 to 13.26156, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 13.2616 - bpp: 5.0324 - mse: 0.0020\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.1388 - bpp: 4.8998 - mse: 0.0015\n",
      "Epoch 4: loss improved from 13.26156 to 11.13884, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 11.1388 - bpp: 4.8998 - mse: 0.0015\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8837 - bpp: 4.7697 - mse: 0.0015\n",
      "Epoch 5: loss improved from 11.13884 to 10.88369, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 10.8837 - bpp: 4.7697 - mse: 0.0015\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.8961 - bpp: 4.6425 - mse: 0.0018\n",
      "Epoch 6: loss did not improve from 10.88369\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 11.8961 - bpp: 4.6425 - mse: 0.0018\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3413 - bpp: 4.5195 - mse: 0.0012\n",
      "Epoch 7: loss improved from 10.88369 to 9.34128, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 9.3413 - bpp: 4.5195 - mse: 0.0012\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8791 - bpp: 4.3968 - mse: 0.0011\n",
      "Epoch 8: loss improved from 9.34128 to 8.87912, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 8.8791 - bpp: 4.3968 - mse: 0.0011\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0440 - bpp: 4.2754 - mse: 9.2007e-04\n",
      "Epoch 9: loss improved from 8.87912 to 8.04403, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 8.0440 - bpp: 4.2754 - mse: 9.2007e-04\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1708 - bpp: 4.1569 - mse: 7.3582e-04\n",
      "Epoch 10: loss improved from 8.04403 to 7.17080, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 7.1708 - bpp: 4.1569 - mse: 7.3582e-04\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6383 - bpp: 4.0401 - mse: 6.3432e-04\n",
      "Epoch 11: loss improved from 7.17080 to 6.63829, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 6.6383 - bpp: 4.0401 - mse: 6.3432e-04\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6571 - bpp: 3.9269 - mse: 6.6655e-04\n",
      "Epoch 12: loss did not improve from 6.63829\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 6.6571 - bpp: 3.9269 - mse: 6.6655e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2806 - bpp: 3.8154 - mse: 6.0185e-04\n",
      "Epoch 13: loss improved from 6.63829 to 6.28056, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 6.2806 - bpp: 3.8154 - mse: 6.0185e-04\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1429 - bpp: 3.7069 - mse: 5.9473e-04\n",
      "Epoch 14: loss improved from 6.28056 to 6.14291, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 6.1429 - bpp: 3.7069 - mse: 5.9473e-04\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7683 - bpp: 3.6018 - mse: 5.2893e-04\n",
      "Epoch 15: loss improved from 6.14291 to 5.76829, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 5.7683 - bpp: 3.6018 - mse: 5.2893e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3768 - bpp: 3.4964 - mse: 4.5908e-04\n",
      "Epoch 16: loss improved from 5.76829 to 5.37680, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 5.3768 - bpp: 3.4964 - mse: 4.5908e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0867 - bpp: 3.3929 - mse: 4.1351e-04\n",
      "Epoch 17: loss improved from 5.37680 to 5.08666, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 5.0867 - bpp: 3.3929 - mse: 4.1351e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2815 - bpp: 3.2973 - mse: 4.8443e-04\n",
      "Epoch 18: loss did not improve from 5.08666\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 5.2815 - bpp: 3.2973 - mse: 4.8443e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2253 - bpp: 3.2048 - mse: 4.9329e-04\n",
      "Epoch 19: loss did not improve from 5.08666\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 5.2253 - bpp: 3.2048 - mse: 4.9329e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9643 - bpp: 3.1093 - mse: 4.5289e-04\n",
      "Epoch 20: loss improved from 5.08666 to 4.96429, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 4.9643 - bpp: 3.1093 - mse: 4.5289e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7777 - bpp: 3.0132 - mse: 4.3080e-04\n",
      "Epoch 21: loss improved from 4.96429 to 4.77772, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 4.7777 - bpp: 3.0132 - mse: 4.3080e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2561 - bpp: 2.9193 - mse: 3.2638e-04\n",
      "Epoch 22: loss improved from 4.77772 to 4.25615, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 4.2561 - bpp: 2.9193 - mse: 3.2638e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3743 - bpp: 2.8367 - mse: 3.7539e-04\n",
      "Epoch 23: loss did not improve from 4.25615\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 4.3743 - bpp: 2.8367 - mse: 3.7539e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4358 - bpp: 2.7650 - mse: 4.0791e-04\n",
      "Epoch 24: loss did not improve from 4.25615\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 4.4358 - bpp: 2.7650 - mse: 4.0791e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1213 - bpp: 2.6740 - mse: 3.5334e-04\n",
      "Epoch 25: loss improved from 4.25615 to 4.12131, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 4.1213 - bpp: 2.6740 - mse: 3.5334e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.9064 - bpp: 2.6247 - mse: 0.0030\n",
      "Epoch 26: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 14.9064 - bpp: 2.6247 - mse: 0.0030\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3356 - bpp: 2.5724 - mse: 0.0019\n",
      "Epoch 27: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 10.3356 - bpp: 2.5724 - mse: 0.0019\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0001 - bpp: 2.4587 - mse: 6.2047e-04\n",
      "Epoch 28: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 5.0001 - bpp: 2.4587 - mse: 6.2047e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5003 - bpp: 2.3863 - mse: 5.1611e-04\n",
      "Epoch 29: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 4.5003 - bpp: 2.3863 - mse: 5.1611e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8097 - bpp: 2.2884 - mse: 3.7142e-04\n",
      "Epoch 30: loss improved from 4.12131 to 3.80973, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 3.8097 - bpp: 2.2884 - mse: 3.7142e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1226 - bpp: 2.2370 - mse: 4.6035e-04\n",
      "Epoch 31: loss did not improve from 3.80973\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 4.1226 - bpp: 2.2370 - mse: 4.6035e-04\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7824 - bpp: 2.1723 - mse: 3.9309e-04\n",
      "Epoch 32: loss improved from 3.80973 to 3.78237, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 3.7824 - bpp: 2.1723 - mse: 3.9309e-04\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6854 - bpp: 2.1054 - mse: 3.8576e-04\n",
      "Epoch 33: loss improved from 3.78237 to 3.68542, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 3.6854 - bpp: 2.1054 - mse: 3.8576e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7362 - bpp: 2.0504 - mse: 4.1156e-04\n",
      "Epoch 34: loss did not improve from 3.68542\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 3.7362 - bpp: 2.0504 - mse: 4.1156e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2624 - bpp: 1.9788 - mse: 3.1339e-04\n",
      "Epoch 35: loss improved from 3.68542 to 3.26242, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 3.2624 - bpp: 1.9788 - mse: 3.1339e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2211 - bpp: 1.9124 - mse: 3.1949e-04\n",
      "Epoch 36: loss improved from 3.26242 to 3.22107, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 3.2211 - bpp: 1.9124 - mse: 3.1949e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2101 - bpp: 1.8677 - mse: 3.2775e-04\n",
      "Epoch 37: loss improved from 3.22107 to 3.21012, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 3.2101 - bpp: 1.8677 - mse: 3.2775e-04\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0177 - bpp: 1.7997 - mse: 2.9735e-04\n",
      "Epoch 38: loss improved from 3.21012 to 3.01767, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.0177 - bpp: 1.7997 - mse: 2.9735e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8902 - bpp: 1.7485 - mse: 2.7872e-04\n",
      "Epoch 39: loss improved from 3.01767 to 2.89015, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.8902 - bpp: 1.7485 - mse: 2.7872e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8006 - bpp: 1.6941 - mse: 2.7014e-04\n",
      "Epoch 40: loss improved from 2.89015 to 2.80061, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 198ms/step - loss: 2.8006 - bpp: 1.6941 - mse: 2.7014e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8044 - bpp: 1.6470 - mse: 2.8257e-04\n",
      "Epoch 41: loss did not improve from 2.80061\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.8044 - bpp: 1.6470 - mse: 2.8257e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7494 - bpp: 1.6065 - mse: 2.7902e-04\n",
      "Epoch 42: loss improved from 2.80061 to 2.74939, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.7494 - bpp: 1.6065 - mse: 2.7902e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6235 - bpp: 1.5552 - mse: 2.6081e-04\n",
      "Epoch 43: loss improved from 2.74939 to 2.62347, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.6235 - bpp: 1.5552 - mse: 2.6081e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6555 - bpp: 1.5094 - mse: 2.7982e-04\n",
      "Epoch 44: loss did not improve from 2.62347\n",
      "200/200 [==============================] - 37s 180ms/step - loss: 2.6555 - bpp: 1.5094 - mse: 2.7982e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5936 - bpp: 1.4893 - mse: 2.6961e-04\n",
      "Epoch 45: loss improved from 2.62347 to 2.59363, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.5936 - bpp: 1.4893 - mse: 2.6961e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6515 - bpp: 1.4837 - mse: 2.8511e-04\n",
      "Epoch 46: loss did not improve from 2.59363\n",
      "200/200 [==============================] - 36s 175ms/step - loss: 2.6515 - bpp: 1.4837 - mse: 2.8511e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7061 - bpp: 1.4343 - mse: 3.1052e-04\n",
      "Epoch 47: loss did not improve from 2.59363\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 2.7061 - bpp: 1.4343 - mse: 3.1052e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7228 - bpp: 1.4258 - mse: 3.1666e-04\n",
      "Epoch 48: loss did not improve from 2.59363\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 2.7228 - bpp: 1.4258 - mse: 3.1666e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5242 - bpp: 1.3692 - mse: 2.8197e-04\n",
      "Epoch 49: loss improved from 2.59363 to 2.52417, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.5242 - bpp: 1.3692 - mse: 2.8197e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5347 - bpp: 1.3254 - mse: 2.9525e-04\n",
      "Epoch 50: loss did not improve from 2.52417\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 2.5347 - bpp: 1.3254 - mse: 2.9525e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2714 - bpp: 1.2779 - mse: 2.4256e-04\n",
      "Epoch 51: loss improved from 2.52417 to 2.27142, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.2714 - bpp: 1.2779 - mse: 2.4256e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5155 - bpp: 1.2930 - mse: 2.9848e-04\n",
      "Epoch 52: loss did not improve from 2.27142\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 2.5155 - bpp: 1.2930 - mse: 2.9848e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2514 - bpp: 1.2403 - mse: 2.4685e-04\n",
      "Epoch 53: loss improved from 2.27142 to 2.25144, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.2514 - bpp: 1.2403 - mse: 2.4685e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.2319 - bpp: 1.3859 - mse: 0.0034\n",
      "Epoch 54: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 15.2319 - bpp: 1.3859 - mse: 0.0034\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0597 - bpp: 1.2810 - mse: 0.0012\n",
      "Epoch 55: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 6.0597 - bpp: 1.2810 - mse: 0.0012\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1330 - bpp: 1.2588 - mse: 9.4584e-04\n",
      "Epoch 56: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 5.1330 - bpp: 1.2588 - mse: 9.4584e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6067 - bpp: 1.2128 - mse: 5.8444e-04\n",
      "Epoch 57: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 3.6067 - bpp: 1.2128 - mse: 5.8444e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3044 - bpp: 1.2028 - mse: 5.1308e-04\n",
      "Epoch 58: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.3044 - bpp: 1.2028 - mse: 5.1308e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8740 - bpp: 1.2544 - mse: 6.3953e-04\n",
      "Epoch 59: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 3.8740 - bpp: 1.2544 - mse: 6.3953e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0976 - bpp: 1.2171 - mse: 4.5912e-04\n",
      "Epoch 60: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 3.0976 - bpp: 1.2171 - mse: 4.5912e-04\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1099 - bpp: 1.2394 - mse: 4.5667e-04\n",
      "Epoch 61: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 3.1099 - bpp: 1.2394 - mse: 4.5667e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8433 - bpp: 1.2383 - mse: 3.9186e-04\n",
      "Epoch 62: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.8433 - bpp: 1.2383 - mse: 3.9186e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5307 - bpp: 1.1677 - mse: 3.3278e-04\n",
      "Epoch 63: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 2.5307 - bpp: 1.1677 - mse: 3.3278e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7920 - bpp: 1.2056 - mse: 3.8731e-04\n",
      "Epoch 64: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.7920 - bpp: 1.2056 - mse: 3.8731e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5687 - bpp: 1.1582 - mse: 3.4435e-04\n",
      "Epoch 65: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 2.5687 - bpp: 1.1582 - mse: 3.4435e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3711 - bpp: 1.2362 - mse: 5.2120e-04\n",
      "Epoch 66: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 3.3711 - bpp: 1.2362 - mse: 5.2120e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1415 - bpp: 1.2150 - mse: 4.7034e-04\n",
      "Epoch 67: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 3.1415 - bpp: 1.2150 - mse: 4.7034e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4854 - bpp: 1.1449 - mse: 3.2728e-04\n",
      "Epoch 68: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.4854 - bpp: 1.1449 - mse: 3.2728e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3487 - bpp: 1.1071 - mse: 3.0312e-04\n",
      "Epoch 69: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 2.3487 - bpp: 1.1071 - mse: 3.0312e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4232 - bpp: 1.1200 - mse: 3.1815e-04\n",
      "Epoch 70: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.4232 - bpp: 1.1200 - mse: 3.1815e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3601 - bpp: 1.0999 - mse: 3.0766e-04\n",
      "Epoch 71: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 2.3601 - bpp: 1.0999 - mse: 3.0766e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2558 - bpp: 1.0694 - mse: 2.8964e-04\n",
      "Epoch 72: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.2558 - bpp: 1.0694 - mse: 2.8964e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1711 - bpp: 1.0483 - mse: 2.7414e-04\n",
      "Epoch 73: loss improved from 2.25144 to 2.17115, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.1711 - bpp: 1.0483 - mse: 2.7414e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3286 - bpp: 1.0623 - mse: 3.0918e-04\n",
      "Epoch 74: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 2.3286 - bpp: 1.0623 - mse: 3.0918e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2320 - bpp: 1.0585 - mse: 2.8650e-04\n",
      "Epoch 75: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.2320 - bpp: 1.0585 - mse: 2.8650e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4526 - bpp: 1.0947 - mse: 3.3153e-04\n",
      "Epoch 76: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.4526 - bpp: 1.0947 - mse: 3.3153e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2476 - bpp: 1.0470 - mse: 2.9311e-04\n",
      "Epoch 77: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.2476 - bpp: 1.0470 - mse: 2.9311e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1400 - bpp: 1.0298 - mse: 2.7104e-04\n",
      "Epoch 78: loss improved from 2.17115 to 2.14001, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 2.1400 - bpp: 1.0298 - mse: 2.7104e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2091 - bpp: 1.0289 - mse: 2.8811e-04\n",
      "Epoch 79: loss did not improve from 2.14001\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.2091 - bpp: 1.0289 - mse: 2.8811e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2126 - bpp: 1.0278 - mse: 2.8925e-04\n",
      "Epoch 80: loss did not improve from 2.14001\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.2126 - bpp: 1.0278 - mse: 2.8925e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1991 - bpp: 1.0354 - mse: 2.8409e-04\n",
      "Epoch 81: loss did not improve from 2.14001\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1991 - bpp: 1.0354 - mse: 2.8409e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9984 - bpp: 0.9780 - mse: 2.4913e-04\n",
      "Epoch 82: loss improved from 2.14001 to 1.99840, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 187ms/step - loss: 1.9984 - bpp: 0.9780 - mse: 2.4913e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0850 - bpp: 0.9908 - mse: 2.6713e-04\n",
      "Epoch 83: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.0850 - bpp: 0.9908 - mse: 2.6713e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1867 - bpp: 1.0008 - mse: 2.8954e-04\n",
      "Epoch 84: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.1867 - bpp: 1.0008 - mse: 2.8954e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2498 - bpp: 0.9945 - mse: 3.0648e-04\n",
      "Epoch 85: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.2498 - bpp: 0.9945 - mse: 3.0648e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1085 - bpp: 0.9677 - mse: 2.7850e-04\n",
      "Epoch 86: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.1085 - bpp: 0.9677 - mse: 2.7850e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9382 - bpp: 0.9582 - mse: 2.3926e-04\n",
      "Epoch 87: loss improved from 1.99840 to 1.93824, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.9382 - bpp: 0.9582 - mse: 2.3926e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0673 - bpp: 0.9652 - mse: 2.6908e-04\n",
      "Epoch 88: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.0673 - bpp: 0.9652 - mse: 2.6908e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1659 - bpp: 0.9650 - mse: 2.9318e-04\n",
      "Epoch 89: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1659 - bpp: 0.9650 - mse: 2.9318e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0502 - bpp: 1.0982 - mse: 0.0022\n",
      "Epoch 90: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 10.0502 - bpp: 1.0982 - mse: 0.0022\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5108 - bpp: 1.0079 - mse: 0.0011\n",
      "Epoch 91: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 5.5108 - bpp: 1.0079 - mse: 0.0011\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5029 - bpp: 0.9581 - mse: 6.2131e-04\n",
      "Epoch 92: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 3.5029 - bpp: 0.9581 - mse: 6.2131e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5660 - bpp: 1.0184 - mse: 8.6613e-04\n",
      "Epoch 93: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 4.5660 - bpp: 1.0184 - mse: 8.6613e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0275 - bpp: 1.0147 - mse: 4.9140e-04\n",
      "Epoch 94: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 3.0275 - bpp: 1.0147 - mse: 4.9140e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7894 - bpp: 0.9939 - mse: 4.3835e-04\n",
      "Epoch 95: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.7894 - bpp: 0.9939 - mse: 4.3835e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8865 - bpp: 1.0357 - mse: 4.5187e-04\n",
      "Epoch 96: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.8865 - bpp: 1.0357 - mse: 4.5187e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0445 - bpp: 1.0745 - mse: 4.8097e-04\n",
      "Epoch 97: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.0445 - bpp: 1.0745 - mse: 4.8097e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6232 - bpp: 1.0484 - mse: 3.8447e-04\n",
      "Epoch 98: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.6232 - bpp: 1.0484 - mse: 3.8447e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6869 - bpp: 1.0728 - mse: 3.9406e-04\n",
      "Epoch 99: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 2.6869 - bpp: 1.0728 - mse: 3.9406e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5428 - bpp: 1.0527 - mse: 3.6379e-04\n",
      "Epoch 100: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.5428 - bpp: 1.0527 - mse: 3.6379e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2030 - bpp: 1.0015 - mse: 2.9332e-04\n",
      "Epoch 101: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 2.2030 - bpp: 1.0015 - mse: 2.9332e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4146 - bpp: 1.0243 - mse: 3.3942e-04\n",
      "Epoch 102: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.4146 - bpp: 1.0243 - mse: 3.3942e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3354 - bpp: 1.0194 - mse: 3.2130e-04\n",
      "Epoch 103: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.3354 - bpp: 1.0194 - mse: 3.2130e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3422 - bpp: 1.0038 - mse: 3.2677e-04\n",
      "Epoch 104: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.3422 - bpp: 1.0038 - mse: 3.2677e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6078 - bpp: 1.1442 - mse: 6.0147e-04\n",
      "Epoch 105: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.6078 - bpp: 1.1442 - mse: 6.0147e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3643 - bpp: 1.0622 - mse: 3.1788e-04\n",
      "Epoch 106: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.3643 - bpp: 1.0622 - mse: 3.1788e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1253 - bpp: 0.9789 - mse: 2.7989e-04\n",
      "Epoch 107: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 180ms/step - loss: 2.1253 - bpp: 0.9789 - mse: 2.7989e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2841 - bpp: 1.0210 - mse: 3.0835e-04\n",
      "Epoch 108: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.2841 - bpp: 1.0210 - mse: 3.0835e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9916 - bpp: 0.9750 - mse: 2.4821e-04\n",
      "Epoch 109: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9916 - bpp: 0.9750 - mse: 2.4821e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0982 - bpp: 0.9775 - mse: 2.7362e-04\n",
      "Epoch 110: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 2.0982 - bpp: 0.9775 - mse: 2.7362e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3236 - bpp: 1.0254 - mse: 3.1693e-04\n",
      "Epoch 111: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.3236 - bpp: 1.0254 - mse: 3.1693e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1281 - bpp: 0.9897 - mse: 2.7792e-04\n",
      "Epoch 112: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 2.1281 - bpp: 0.9897 - mse: 2.7792e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9717 - bpp: 0.9504 - mse: 2.4934e-04\n",
      "Epoch 113: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.9717 - bpp: 0.9504 - mse: 2.4934e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9645 - bpp: 0.9395 - mse: 2.5024e-04\n",
      "Epoch 114: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.9645 - bpp: 0.9395 - mse: 2.5024e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0751 - bpp: 0.9661 - mse: 2.7074e-04\n",
      "Epoch 115: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.0751 - bpp: 0.9661 - mse: 2.7074e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4195 - bpp: 1.0398 - mse: 3.3683e-04\n",
      "Epoch 116: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.4195 - bpp: 1.0398 - mse: 3.3683e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9853 - bpp: 0.9346 - mse: 2.5652e-04\n",
      "Epoch 117: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9853 - bpp: 0.9346 - mse: 2.5652e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9575 - bpp: 0.9385 - mse: 2.4878e-04\n",
      "Epoch 118: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.9575 - bpp: 0.9385 - mse: 2.4878e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9402 - bpp: 0.9177 - mse: 2.4964e-04\n",
      "Epoch 119: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.9402 - bpp: 0.9177 - mse: 2.4964e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1504 - bpp: 0.9773 - mse: 2.8638e-04\n",
      "Epoch 120: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.1504 - bpp: 0.9773 - mse: 2.8638e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9399 - bpp: 0.9175 - mse: 2.4959e-04\n",
      "Epoch 121: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9399 - bpp: 0.9175 - mse: 2.4959e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8710 - bpp: 0.8926 - mse: 2.3887e-04\n",
      "Epoch 122: loss improved from 1.93824 to 1.87103, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.8710 - bpp: 0.8926 - mse: 2.3887e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7935 - bpp: 0.9497 - mse: 4.5015e-04\n",
      "Epoch 123: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 2.7935 - bpp: 0.9497 - mse: 4.5015e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5414 - bpp: 1.0175 - mse: 3.7205e-04\n",
      "Epoch 124: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.5414 - bpp: 1.0175 - mse: 3.7205e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0257 - bpp: 0.9087 - mse: 2.7269e-04\n",
      "Epoch 125: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.0257 - bpp: 0.9087 - mse: 2.7269e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0594 - bpp: 0.9417 - mse: 2.7287e-04\n",
      "Epoch 126: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.0594 - bpp: 0.9417 - mse: 2.7287e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0739 - bpp: 0.9558 - mse: 2.7298e-04\n",
      "Epoch 127: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.0739 - bpp: 0.9558 - mse: 2.7298e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9917 - bpp: 0.9504 - mse: 2.5422e-04\n",
      "Epoch 128: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9917 - bpp: 0.9504 - mse: 2.5422e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0876 - bpp: 0.9379 - mse: 2.8069e-04\n",
      "Epoch 129: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.0876 - bpp: 0.9379 - mse: 2.8069e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6436 - bpp: 0.9551 - mse: 4.1224e-04\n",
      "Epoch 130: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 2.6436 - bpp: 0.9551 - mse: 4.1224e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2651 - bpp: 1.1503 - mse: 0.0022\n",
      "Epoch 131: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 10.2651 - bpp: 1.1503 - mse: 0.0022\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9908 - bpp: 0.9900 - mse: 4.8847e-04\n",
      "Epoch 132: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.9908 - bpp: 0.9900 - mse: 4.8847e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5696 - bpp: 0.9614 - mse: 3.9264e-04\n",
      "Epoch 133: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 2.5696 - bpp: 0.9614 - mse: 3.9264e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4512 - bpp: 0.9660 - mse: 3.6259e-04\n",
      "Epoch 134: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 2.4512 - bpp: 0.9660 - mse: 3.6259e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1531 - bpp: 0.9345 - mse: 2.9751e-04\n",
      "Epoch 135: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.1531 - bpp: 0.9345 - mse: 2.9751e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1323 - bpp: 0.9336 - mse: 2.9267e-04\n",
      "Epoch 136: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.1323 - bpp: 0.9336 - mse: 2.9267e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0774 - bpp: 0.9309 - mse: 2.7989e-04\n",
      "Epoch 137: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 2.0774 - bpp: 0.9309 - mse: 2.7989e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0143 - bpp: 0.9353 - mse: 2.6342e-04\n",
      "Epoch 138: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.0143 - bpp: 0.9353 - mse: 2.6342e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1236 - bpp: 0.9473 - mse: 2.8717e-04\n",
      "Epoch 139: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1236 - bpp: 0.9473 - mse: 2.8717e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9407 - bpp: 0.9121 - mse: 2.5111e-04\n",
      "Epoch 140: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.9407 - bpp: 0.9121 - mse: 2.5111e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9809 - bpp: 0.9237 - mse: 2.5810e-04\n",
      "Epoch 141: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.9809 - bpp: 0.9237 - mse: 2.5810e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9969 - bpp: 0.9187 - mse: 2.6322e-04\n",
      "Epoch 142: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.9969 - bpp: 0.9187 - mse: 2.6322e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9608 - bpp: 0.9167 - mse: 2.5491e-04\n",
      "Epoch 143: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.9608 - bpp: 0.9167 - mse: 2.5491e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8530 - bpp: 0.9015 - mse: 2.3231e-04\n",
      "Epoch 144: loss improved from 1.87103 to 1.85300, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.8530 - bpp: 0.9015 - mse: 2.3231e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7570 - bpp: 0.8719 - mse: 2.1607e-04\n",
      "Epoch 145: loss improved from 1.85300 to 1.75696, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.7570 - bpp: 0.8719 - mse: 2.1607e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9308 - bpp: 0.8948 - mse: 2.5293e-04\n",
      "Epoch 146: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.9308 - bpp: 0.8948 - mse: 2.5293e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9045 - bpp: 0.8705 - mse: 2.5246e-04\n",
      "Epoch 147: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.9045 - bpp: 0.8705 - mse: 2.5246e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8837 - bpp: 0.8864 - mse: 2.4347e-04\n",
      "Epoch 148: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.8837 - bpp: 0.8864 - mse: 2.4347e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8962 - bpp: 0.8842 - mse: 2.4706e-04\n",
      "Epoch 149: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.8962 - bpp: 0.8842 - mse: 2.4706e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8880 - bpp: 0.8767 - mse: 2.4690e-04\n",
      "Epoch 150: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.8880 - bpp: 0.8767 - mse: 2.4690e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8727 - bpp: 0.8642 - mse: 2.4619e-04\n",
      "Epoch 151: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.8727 - bpp: 0.8642 - mse: 2.4619e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8157 - bpp: 0.8650 - mse: 2.3211e-04\n",
      "Epoch 152: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.8157 - bpp: 0.8650 - mse: 2.3211e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7521 - bpp: 0.8496 - mse: 2.2033e-04\n",
      "Epoch 153: loss improved from 1.75696 to 1.75214, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.7521 - bpp: 0.8496 - mse: 2.2033e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9290 - bpp: 0.8707 - mse: 2.5836e-04\n",
      "Epoch 154: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.9290 - bpp: 0.8707 - mse: 2.5836e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8812 - bpp: 0.8739 - mse: 2.4591e-04\n",
      "Epoch 155: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.8812 - bpp: 0.8739 - mse: 2.4591e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1392 - bpp: 0.8783 - mse: 3.0782e-04\n",
      "Epoch 156: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1392 - bpp: 0.8783 - mse: 3.0782e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9495 - bpp: 0.8504 - mse: 2.6832e-04\n",
      "Epoch 157: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.9495 - bpp: 0.8504 - mse: 2.6832e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8340 - bpp: 0.8521 - mse: 2.3972e-04\n",
      "Epoch 158: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.8340 - bpp: 0.8521 - mse: 2.3972e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5501 - bpp: 0.9437 - mse: 3.9220e-04\n",
      "Epoch 159: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.5501 - bpp: 0.9437 - mse: 3.9220e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8861 - bpp: 0.8796 - mse: 2.4572e-04\n",
      "Epoch 160: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.8861 - bpp: 0.8796 - mse: 2.4572e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7760 - bpp: 0.8471 - mse: 2.2679e-04\n",
      "Epoch 161: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.7760 - bpp: 0.8471 - mse: 2.2679e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7231 - bpp: 0.8414 - mse: 2.1527e-04\n",
      "Epoch 162: loss improved from 1.75214 to 1.72314, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.7231 - bpp: 0.8414 - mse: 2.1527e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0422 - bpp: 0.8715 - mse: 2.8582e-04\n",
      "Epoch 163: loss did not improve from 1.72314\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.0422 - bpp: 0.8715 - mse: 2.8582e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8620 - bpp: 0.8520 - mse: 2.4658e-04\n",
      "Epoch 164: loss did not improve from 1.72314\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.8620 - bpp: 0.8520 - mse: 2.4658e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7063 - bpp: 0.8220 - mse: 2.1590e-04\n",
      "Epoch 165: loss improved from 1.72314 to 1.70632, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.7063 - bpp: 0.8220 - mse: 2.1590e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8160 - bpp: 0.8329 - mse: 2.4002e-04\n",
      "Epoch 166: loss did not improve from 1.70632\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.8160 - bpp: 0.8329 - mse: 2.4002e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8498 - bpp: 0.8322 - mse: 2.4843e-04\n",
      "Epoch 167: loss did not improve from 1.70632\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.8498 - bpp: 0.8322 - mse: 2.4843e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6539 - bpp: 0.7911 - mse: 2.1065e-04\n",
      "Epoch 168: loss improved from 1.70632 to 1.65394, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.6539 - bpp: 0.7911 - mse: 2.1065e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7616 - bpp: 0.8278 - mse: 2.2798e-04\n",
      "Epoch 169: loss did not improve from 1.65394\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 1.7616 - bpp: 0.8278 - mse: 2.2798e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6011 - bpp: 0.7882 - mse: 1.9848e-04\n",
      "Epoch 170: loss improved from 1.65394 to 1.60112, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6011 - bpp: 0.7882 - mse: 1.9848e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5699 - bpp: 0.7756 - mse: 1.9393e-04\n",
      "Epoch 171: loss improved from 1.60112 to 1.56994, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5699 - bpp: 0.7756 - mse: 1.9393e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9266 - bpp: 0.8338 - mse: 2.6679e-04\n",
      "Epoch 172: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.9266 - bpp: 0.8338 - mse: 2.6679e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0495 - bpp: 0.8307 - mse: 2.9756e-04\n",
      "Epoch 173: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 2.0495 - bpp: 0.8307 - mse: 2.9756e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0943 - bpp: 0.9057 - mse: 5.3431e-04\n",
      "Epoch 174: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 3.0943 - bpp: 0.9057 - mse: 5.3431e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9737 - bpp: 0.8571 - mse: 2.7259e-04\n",
      "Epoch 175: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.9737 - bpp: 0.8571 - mse: 2.7259e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8294 - bpp: 0.8232 - mse: 2.4564e-04\n",
      "Epoch 176: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.8294 - bpp: 0.8232 - mse: 2.4564e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5815 - bpp: 0.7756 - mse: 1.9673e-04\n",
      "Epoch 177: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5815 - bpp: 0.7756 - mse: 1.9673e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6970 - bpp: 0.7987 - mse: 2.1931e-04\n",
      "Epoch 178: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6970 - bpp: 0.7987 - mse: 2.1931e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6383 - bpp: 0.7793 - mse: 2.0971e-04\n",
      "Epoch 179: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.6383 - bpp: 0.7793 - mse: 2.0971e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4496 - bpp: 0.7411 - mse: 1.7297e-04\n",
      "Epoch 180: loss improved from 1.56994 to 1.44958, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4496 - bpp: 0.7411 - mse: 1.7297e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6624 - bpp: 0.7932 - mse: 2.1221e-04\n",
      "Epoch 181: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.6624 - bpp: 0.7932 - mse: 2.1221e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6404 - bpp: 0.7661 - mse: 2.1345e-04\n",
      "Epoch 182: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.6404 - bpp: 0.7661 - mse: 2.1345e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5330 - bpp: 0.7571 - mse: 1.8945e-04\n",
      "Epoch 183: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.5330 - bpp: 0.7571 - mse: 1.8945e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4907 - bpp: 0.7500 - mse: 1.8083e-04\n",
      "Epoch 184: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4907 - bpp: 0.7500 - mse: 1.8083e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5378 - bpp: 0.7638 - mse: 1.8896e-04\n",
      "Epoch 185: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5378 - bpp: 0.7638 - mse: 1.8896e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6785 - bpp: 0.7667 - mse: 2.2262e-04\n",
      "Epoch 186: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.6785 - bpp: 0.7667 - mse: 2.2262e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7221 - bpp: 0.7867 - mse: 2.2839e-04\n",
      "Epoch 187: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.7221 - bpp: 0.7867 - mse: 2.2839e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5191 - bpp: 0.7616 - mse: 1.8494e-04\n",
      "Epoch 188: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.5191 - bpp: 0.7616 - mse: 1.8494e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5811 - bpp: 0.7509 - mse: 2.0270e-04\n",
      "Epoch 189: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5811 - bpp: 0.7509 - mse: 2.0270e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6210 - bpp: 0.7701 - mse: 2.0773e-04\n",
      "Epoch 190: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6210 - bpp: 0.7701 - mse: 2.0773e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6036 - bpp: 0.8692 - mse: 4.2343e-04\n",
      "Epoch 191: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 2.6036 - bpp: 0.8692 - mse: 4.2343e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6007 - bpp: 0.7701 - mse: 2.0278e-04\n",
      "Epoch 192: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.6007 - bpp: 0.7701 - mse: 2.0278e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6130 - bpp: 0.7689 - mse: 2.0607e-04\n",
      "Epoch 193: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6130 - bpp: 0.7689 - mse: 2.0607e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6066 - bpp: 0.7629 - mse: 2.0597e-04\n",
      "Epoch 194: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.6066 - bpp: 0.7629 - mse: 2.0597e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5705 - bpp: 0.7512 - mse: 2.0003e-04\n",
      "Epoch 195: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5705 - bpp: 0.7512 - mse: 2.0003e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5607 - bpp: 0.7409 - mse: 2.0015e-04\n",
      "Epoch 196: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5607 - bpp: 0.7409 - mse: 2.0015e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5295 - bpp: 0.7387 - mse: 1.9306e-04\n",
      "Epoch 197: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 40s 193ms/step - loss: 1.5295 - bpp: 0.7387 - mse: 1.9306e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4352 - bpp: 0.7213 - mse: 1.7428e-04\n",
      "Epoch 198: loss improved from 1.44958 to 1.43518, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.4352 - bpp: 0.7213 - mse: 1.7428e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5043 - bpp: 0.7340 - mse: 1.8808e-04\n",
      "Epoch 199: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5043 - bpp: 0.7340 - mse: 1.8808e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5584 - bpp: 0.7440 - mse: 1.9882e-04\n",
      "Epoch 200: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.5584 - bpp: 0.7440 - mse: 1.9882e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6087 - bpp: 0.7446 - mse: 2.1095e-04\n",
      "Epoch 201: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6087 - bpp: 0.7446 - mse: 2.1095e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5568 - bpp: 0.7443 - mse: 1.9837e-04\n",
      "Epoch 202: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.5568 - bpp: 0.7443 - mse: 1.9837e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5330 - bpp: 0.7367 - mse: 1.9440e-04\n",
      "Epoch 203: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5330 - bpp: 0.7367 - mse: 1.9440e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4732 - bpp: 0.7049 - mse: 1.8755e-04\n",
      "Epoch 204: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4732 - bpp: 0.7049 - mse: 1.8755e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5934 - bpp: 0.7389 - mse: 2.0863e-04\n",
      "Epoch 205: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5934 - bpp: 0.7389 - mse: 2.0863e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6407 - bpp: 0.7559 - mse: 2.1603e-04\n",
      "Epoch 206: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.6407 - bpp: 0.7559 - mse: 2.1603e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4452 - bpp: 0.7076 - mse: 1.8007e-04\n",
      "Epoch 207: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4452 - bpp: 0.7076 - mse: 1.8007e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7409 - bpp: 0.7650 - mse: 2.3825e-04\n",
      "Epoch 208: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.7409 - bpp: 0.7650 - mse: 2.3825e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5283 - bpp: 0.7324 - mse: 1.9430e-04\n",
      "Epoch 209: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5283 - bpp: 0.7324 - mse: 1.9430e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5700 - bpp: 0.7353 - mse: 2.0377e-04\n",
      "Epoch 210: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5700 - bpp: 0.7353 - mse: 2.0377e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7577 - bpp: 0.8407 - mse: 4.6802e-04\n",
      "Epoch 211: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.7577 - bpp: 0.8407 - mse: 4.6802e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6510 - bpp: 0.7514 - mse: 2.1961e-04\n",
      "Epoch 212: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6510 - bpp: 0.7514 - mse: 2.1961e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5486 - bpp: 0.7248 - mse: 2.0112e-04\n",
      "Epoch 213: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5486 - bpp: 0.7248 - mse: 2.0112e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6316 - bpp: 0.7485 - mse: 2.1561e-04\n",
      "Epoch 214: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6316 - bpp: 0.7485 - mse: 2.1561e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5152 - bpp: 0.7176 - mse: 1.9473e-04\n",
      "Epoch 215: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5152 - bpp: 0.7176 - mse: 1.9473e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4720 - bpp: 0.7184 - mse: 1.8397e-04\n",
      "Epoch 216: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.4720 - bpp: 0.7184 - mse: 1.8397e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5907 - bpp: 0.7403 - mse: 2.0761e-04\n",
      "Epoch 217: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5907 - bpp: 0.7403 - mse: 2.0761e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5817 - bpp: 0.7382 - mse: 2.0592e-04\n",
      "Epoch 218: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.5817 - bpp: 0.7382 - mse: 2.0592e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5008 - bpp: 0.7156 - mse: 1.9170e-04\n",
      "Epoch 219: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5008 - bpp: 0.7156 - mse: 1.9170e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5008 - bpp: 0.7140 - mse: 1.9208e-04\n",
      "Epoch 220: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5008 - bpp: 0.7140 - mse: 1.9208e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5871 - bpp: 0.7397 - mse: 2.0689e-04\n",
      "Epoch 221: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5871 - bpp: 0.7397 - mse: 2.0689e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5141 - bpp: 0.7148 - mse: 1.9514e-04\n",
      "Epoch 222: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5141 - bpp: 0.7148 - mse: 1.9514e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5579 - bpp: 0.7224 - mse: 2.0396e-04\n",
      "Epoch 223: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5579 - bpp: 0.7224 - mse: 2.0396e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5111 - bpp: 0.7182 - mse: 1.9357e-04\n",
      "Epoch 224: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5111 - bpp: 0.7182 - mse: 1.9357e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4056 - bpp: 0.6974 - mse: 1.7290e-04\n",
      "Epoch 225: loss improved from 1.43518 to 1.40561, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4056 - bpp: 0.6974 - mse: 1.7290e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4761 - bpp: 0.7133 - mse: 1.8623e-04\n",
      "Epoch 226: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.4761 - bpp: 0.7133 - mse: 1.8623e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5237 - bpp: 0.7084 - mse: 1.9905e-04\n",
      "Epoch 227: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5237 - bpp: 0.7084 - mse: 1.9905e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4822 - bpp: 0.7180 - mse: 1.8656e-04\n",
      "Epoch 228: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.4822 - bpp: 0.7180 - mse: 1.8656e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4441 - bpp: 0.6981 - mse: 1.8214e-04\n",
      "Epoch 229: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4441 - bpp: 0.6981 - mse: 1.8214e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6126 - bpp: 0.7312 - mse: 2.1520e-04\n",
      "Epoch 230: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6126 - bpp: 0.7312 - mse: 2.1520e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4195 - bpp: 0.6943 - mse: 1.7704e-04\n",
      "Epoch 231: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.4195 - bpp: 0.6943 - mse: 1.7704e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5497 - bpp: 0.7005 - mse: 2.0732e-04\n",
      "Epoch 232: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.5497 - bpp: 0.7005 - mse: 2.0732e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5313 - bpp: 0.8122 - mse: 4.1970e-04\n",
      "Epoch 233: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.5313 - bpp: 0.8122 - mse: 4.1970e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6742 - bpp: 0.7630 - mse: 2.2244e-04\n",
      "Epoch 234: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6742 - bpp: 0.7630 - mse: 2.2244e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5710 - bpp: 0.7351 - mse: 2.0408e-04\n",
      "Epoch 235: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5710 - bpp: 0.7351 - mse: 2.0408e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5710 - bpp: 0.7227 - mse: 2.0709e-04\n",
      "Epoch 236: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5710 - bpp: 0.7227 - mse: 2.0709e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4817 - bpp: 0.7118 - mse: 1.8797e-04\n",
      "Epoch 237: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.4817 - bpp: 0.7118 - mse: 1.8797e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4904 - bpp: 0.6973 - mse: 1.9363e-04\n",
      "Epoch 238: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.4904 - bpp: 0.6973 - mse: 1.9363e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4939 - bpp: 0.7073 - mse: 1.9204e-04\n",
      "Epoch 239: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.4939 - bpp: 0.7073 - mse: 1.9204e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4018 - bpp: 0.6932 - mse: 1.7300e-04\n",
      "Epoch 240: loss improved from 1.40561 to 1.40185, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.4018 - bpp: 0.6932 - mse: 1.7300e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5485 - bpp: 0.7242 - mse: 2.0127e-04\n",
      "Epoch 241: loss did not improve from 1.40185\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.5485 - bpp: 0.7242 - mse: 2.0127e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5060 - bpp: 0.7022 - mse: 1.9625e-04\n",
      "Epoch 242: loss did not improve from 1.40185\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5060 - bpp: 0.7022 - mse: 1.9625e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4410 - bpp: 0.6895 - mse: 1.8346e-04\n",
      "Epoch 243: loss did not improve from 1.40185\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4410 - bpp: 0.6895 - mse: 1.8346e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3018 - bpp: 0.6688 - mse: 1.5452e-04\n",
      "Epoch 244: loss improved from 1.40185 to 1.30176, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3018 - bpp: 0.6688 - mse: 1.5452e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4586 - bpp: 0.6960 - mse: 1.8617e-04\n",
      "Epoch 245: loss did not improve from 1.30176\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.4586 - bpp: 0.6960 - mse: 1.8617e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4952 - bpp: 0.7153 - mse: 1.9042e-04\n",
      "Epoch 246: loss did not improve from 1.30176\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4952 - bpp: 0.7153 - mse: 1.9042e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4077 - bpp: 0.6849 - mse: 1.7648e-04\n",
      "Epoch 247: loss did not improve from 1.30176\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4077 - bpp: 0.6849 - mse: 1.7648e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2499 - bpp: 0.6539 - mse: 1.4551e-04\n",
      "Epoch 248: loss improved from 1.30176 to 1.24989, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2499 - bpp: 0.6539 - mse: 1.4551e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3409 - bpp: 0.6719 - mse: 1.6334e-04\n",
      "Epoch 249: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3409 - bpp: 0.6719 - mse: 1.6334e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4697 - bpp: 0.6949 - mse: 1.8915e-04\n",
      "Epoch 250: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4697 - bpp: 0.6949 - mse: 1.8915e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5648 - bpp: 0.7261 - mse: 2.0475e-04\n",
      "Epoch 251: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5648 - bpp: 0.7261 - mse: 2.0475e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6837 - bpp: 0.7295 - mse: 2.3297e-04\n",
      "Epoch 252: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.6837 - bpp: 0.7295 - mse: 2.3297e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6437 - bpp: 0.7393 - mse: 2.2080e-04\n",
      "Epoch 253: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.6437 - bpp: 0.7393 - mse: 2.2080e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5243 - bpp: 0.7170 - mse: 1.9710e-04\n",
      "Epoch 254: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5243 - bpp: 0.7170 - mse: 1.9710e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4146 - bpp: 0.6901 - mse: 1.7688e-04\n",
      "Epoch 255: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4146 - bpp: 0.6901 - mse: 1.7688e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9217 - bpp: 0.7275 - mse: 2.9156e-04\n",
      "Epoch 256: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.9217 - bpp: 0.7275 - mse: 2.9156e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6794 - bpp: 0.7608 - mse: 2.2425e-04\n",
      "Epoch 257: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6794 - bpp: 0.7608 - mse: 2.2425e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3917 - bpp: 0.6873 - mse: 1.7197e-04\n",
      "Epoch 258: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.3917 - bpp: 0.6873 - mse: 1.7197e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4579 - bpp: 0.7165 - mse: 1.8101e-04\n",
      "Epoch 259: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4579 - bpp: 0.7165 - mse: 1.8101e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4539 - bpp: 0.6784 - mse: 1.8933e-04\n",
      "Epoch 260: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4539 - bpp: 0.6784 - mse: 1.8933e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5487 - bpp: 0.7140 - mse: 2.0380e-04\n",
      "Epoch 261: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.5487 - bpp: 0.7140 - mse: 2.0380e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4084 - bpp: 0.6844 - mse: 1.7676e-04\n",
      "Epoch 262: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4084 - bpp: 0.6844 - mse: 1.7676e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5090 - bpp: 0.7016 - mse: 1.9711e-04\n",
      "Epoch 263: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5090 - bpp: 0.7016 - mse: 1.9711e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3626 - bpp: 0.6756 - mse: 1.6772e-04\n",
      "Epoch 264: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3626 - bpp: 0.6756 - mse: 1.6772e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4128 - bpp: 0.6842 - mse: 1.7787e-04\n",
      "Epoch 265: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.4128 - bpp: 0.6842 - mse: 1.7787e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4548 - bpp: 0.6898 - mse: 1.8677e-04\n",
      "Epoch 266: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4548 - bpp: 0.6898 - mse: 1.8677e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4253 - bpp: 0.6821 - mse: 1.8147e-04\n",
      "Epoch 267: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4253 - bpp: 0.6821 - mse: 1.8147e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3573 - bpp: 0.6666 - mse: 1.6863e-04\n",
      "Epoch 268: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3573 - bpp: 0.6666 - mse: 1.6863e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4367 - bpp: 0.6821 - mse: 1.8423e-04\n",
      "Epoch 269: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4367 - bpp: 0.6821 - mse: 1.8423e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4221 - bpp: 0.6921 - mse: 1.7821e-04\n",
      "Epoch 270: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4221 - bpp: 0.6921 - mse: 1.7821e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4001 - bpp: 0.6755 - mse: 1.7691e-04\n",
      "Epoch 271: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4001 - bpp: 0.6755 - mse: 1.7691e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3083 - bpp: 0.6600 - mse: 1.5828e-04\n",
      "Epoch 272: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.3083 - bpp: 0.6600 - mse: 1.5828e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4412 - bpp: 0.6785 - mse: 1.8620e-04\n",
      "Epoch 273: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4412 - bpp: 0.6785 - mse: 1.8620e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4552 - bpp: 0.6660 - mse: 1.9269e-04\n",
      "Epoch 274: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.4552 - bpp: 0.6660 - mse: 1.9269e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4125 - bpp: 0.6760 - mse: 1.7981e-04\n",
      "Epoch 275: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4125 - bpp: 0.6760 - mse: 1.7981e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3449 - bpp: 0.6576 - mse: 1.6780e-04\n",
      "Epoch 276: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3449 - bpp: 0.6576 - mse: 1.6780e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4074 - bpp: 0.6737 - mse: 1.7911e-04\n",
      "Epoch 277: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4074 - bpp: 0.6737 - mse: 1.7911e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3660 - bpp: 0.6656 - mse: 1.7101e-04\n",
      "Epoch 278: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3660 - bpp: 0.6656 - mse: 1.7101e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8550 - bpp: 0.8118 - mse: 4.9882e-04\n",
      "Epoch 279: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 189ms/step - loss: 2.8550 - bpp: 0.8118 - mse: 4.9882e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5119 - bpp: 0.7250 - mse: 1.9211e-04\n",
      "Epoch 280: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5119 - bpp: 0.7250 - mse: 1.9211e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4709 - bpp: 0.7047 - mse: 1.8706e-04\n",
      "Epoch 281: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.4709 - bpp: 0.7047 - mse: 1.8706e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5685 - bpp: 0.7311 - mse: 2.0444e-04\n",
      "Epoch 282: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5685 - bpp: 0.7311 - mse: 2.0444e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4181 - bpp: 0.6751 - mse: 1.8140e-04\n",
      "Epoch 283: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4181 - bpp: 0.6751 - mse: 1.8140e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3861 - bpp: 0.6739 - mse: 1.7387e-04\n",
      "Epoch 284: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3861 - bpp: 0.6739 - mse: 1.7387e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4483 - bpp: 0.6907 - mse: 1.8496e-04\n",
      "Epoch 285: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4483 - bpp: 0.6907 - mse: 1.8496e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.6440 - mse: 1.6111e-04\n",
      "Epoch 286: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.3039 - bpp: 0.6440 - mse: 1.6111e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4029 - bpp: 0.6743 - mse: 1.7787e-04\n",
      "Epoch 287: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4029 - bpp: 0.6743 - mse: 1.7787e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3355 - bpp: 0.6572 - mse: 1.6560e-04\n",
      "Epoch 288: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3355 - bpp: 0.6572 - mse: 1.6560e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5114 - bpp: 0.6916 - mse: 2.0014e-04\n",
      "Epoch 289: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.5114 - bpp: 0.6916 - mse: 2.0014e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4294 - bpp: 0.6728 - mse: 1.8473e-04\n",
      "Epoch 290: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4294 - bpp: 0.6728 - mse: 1.8473e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3844 - bpp: 0.6671 - mse: 1.7512e-04\n",
      "Epoch 291: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3844 - bpp: 0.6671 - mse: 1.7512e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4031 - bpp: 0.6780 - mse: 1.7703e-04\n",
      "Epoch 292: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.4031 - bpp: 0.6780 - mse: 1.7703e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2905 - bpp: 0.6403 - mse: 1.5874e-04\n",
      "Epoch 293: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2905 - bpp: 0.6403 - mse: 1.5874e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4675 - bpp: 0.6757 - mse: 1.9330e-04\n",
      "Epoch 294: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4675 - bpp: 0.6757 - mse: 1.9330e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4429 - bpp: 0.6936 - mse: 1.8294e-04\n",
      "Epoch 295: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4429 - bpp: 0.6936 - mse: 1.8294e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5073 - bpp: 0.6961 - mse: 1.9806e-04\n",
      "Epoch 296: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.5073 - bpp: 0.6961 - mse: 1.9806e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3494 - bpp: 0.6532 - mse: 1.6997e-04\n",
      "Epoch 297: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3494 - bpp: 0.6532 - mse: 1.6997e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4561 - bpp: 0.6639 - mse: 1.9342e-04\n",
      "Epoch 298: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4561 - bpp: 0.6639 - mse: 1.9342e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4474 - bpp: 0.6743 - mse: 1.8874e-04\n",
      "Epoch 299: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4474 - bpp: 0.6743 - mse: 1.8874e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4072 - bpp: 0.6685 - mse: 1.8035e-04\n",
      "Epoch 300: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4072 - bpp: 0.6685 - mse: 1.8035e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3225 - bpp: 0.6514 - mse: 1.6382e-04\n",
      "Epoch 301: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.3225 - bpp: 0.6514 - mse: 1.6382e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3782 - bpp: 0.6650 - mse: 1.7414e-04\n",
      "Epoch 302: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3782 - bpp: 0.6650 - mse: 1.7414e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4570 - bpp: 0.6916 - mse: 1.8686e-04\n",
      "Epoch 303: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4570 - bpp: 0.6916 - mse: 1.8686e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3744 - bpp: 0.6678 - mse: 1.7251e-04\n",
      "Epoch 304: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3744 - bpp: 0.6678 - mse: 1.7251e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2345 - bpp: 0.6261 - mse: 1.4855e-04\n",
      "Epoch 305: loss improved from 1.24989 to 1.23451, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2345 - bpp: 0.6261 - mse: 1.4855e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3956 - bpp: 0.6729 - mse: 1.7643e-04\n",
      "Epoch 306: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.3956 - bpp: 0.6729 - mse: 1.7643e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2938 - bpp: 0.6457 - mse: 1.5825e-04\n",
      "Epoch 307: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2938 - bpp: 0.6457 - mse: 1.5825e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5765 - bpp: 0.8515 - mse: 6.6526e-04\n",
      "Epoch 308: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 3.5765 - bpp: 0.8515 - mse: 6.6526e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5568 - bpp: 0.7564 - mse: 1.9541e-04\n",
      "Epoch 309: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5568 - bpp: 0.7564 - mse: 1.9541e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4708 - bpp: 0.7059 - mse: 1.8674e-04\n",
      "Epoch 310: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4708 - bpp: 0.7059 - mse: 1.8674e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3938 - bpp: 0.6920 - mse: 1.7134e-04\n",
      "Epoch 311: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3938 - bpp: 0.6920 - mse: 1.7134e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4383 - bpp: 0.6963 - mse: 1.8117e-04\n",
      "Epoch 312: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.4383 - bpp: 0.6963 - mse: 1.8117e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3722 - bpp: 0.6680 - mse: 1.7193e-04\n",
      "Epoch 313: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3722 - bpp: 0.6680 - mse: 1.7193e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4081 - bpp: 0.6691 - mse: 1.8042e-04\n",
      "Epoch 314: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4081 - bpp: 0.6691 - mse: 1.8042e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3239 - bpp: 0.6629 - mse: 1.6137e-04\n",
      "Epoch 315: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3239 - bpp: 0.6629 - mse: 1.6137e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3339 - bpp: 0.6535 - mse: 1.6611e-04\n",
      "Epoch 316: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3339 - bpp: 0.6535 - mse: 1.6611e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4300 - bpp: 0.6806 - mse: 1.8295e-04\n",
      "Epoch 317: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4300 - bpp: 0.6806 - mse: 1.8295e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2763 - bpp: 0.6430 - mse: 1.5463e-04\n",
      "Epoch 318: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2763 - bpp: 0.6430 - mse: 1.5463e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2980 - bpp: 0.6468 - mse: 1.5899e-04\n",
      "Epoch 319: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2980 - bpp: 0.6468 - mse: 1.5899e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3554 - bpp: 0.6638 - mse: 1.6884e-04\n",
      "Epoch 320: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3554 - bpp: 0.6638 - mse: 1.6884e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3303 - bpp: 0.6583 - mse: 1.6407e-04\n",
      "Epoch 321: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3303 - bpp: 0.6583 - mse: 1.6407e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2856 - bpp: 0.6340 - mse: 1.5908e-04\n",
      "Epoch 322: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2856 - bpp: 0.6340 - mse: 1.5908e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3621 - bpp: 0.6607 - mse: 1.7124e-04\n",
      "Epoch 323: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3621 - bpp: 0.6607 - mse: 1.7124e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3576 - bpp: 0.6605 - mse: 1.7020e-04\n",
      "Epoch 324: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.3576 - bpp: 0.6605 - mse: 1.7020e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4178 - bpp: 0.6692 - mse: 1.8277e-04\n",
      "Epoch 325: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.4178 - bpp: 0.6692 - mse: 1.8277e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3420 - bpp: 0.6557 - mse: 1.6757e-04\n",
      "Epoch 326: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3420 - bpp: 0.6557 - mse: 1.6757e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5164 - bpp: 0.6807 - mse: 2.0401e-04\n",
      "Epoch 327: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5164 - bpp: 0.6807 - mse: 2.0401e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3805 - bpp: 0.6744 - mse: 1.7237e-04\n",
      "Epoch 328: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.3805 - bpp: 0.6744 - mse: 1.7237e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2999 - bpp: 0.6399 - mse: 1.6113e-04\n",
      "Epoch 329: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2999 - bpp: 0.6399 - mse: 1.6113e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.6432 - mse: 1.6130e-04\n",
      "Epoch 330: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3039 - bpp: 0.6432 - mse: 1.6130e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3251 - bpp: 0.6461 - mse: 1.6577e-04\n",
      "Epoch 331: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3251 - bpp: 0.6461 - mse: 1.6577e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3332 - bpp: 0.6398 - mse: 1.6929e-04\n",
      "Epoch 332: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3332 - bpp: 0.6398 - mse: 1.6929e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3481 - bpp: 0.6594 - mse: 1.6814e-04\n",
      "Epoch 333: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.3481 - bpp: 0.6594 - mse: 1.6814e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2566 - bpp: 0.6287 - mse: 1.5329e-04\n",
      "Epoch 334: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2566 - bpp: 0.6287 - mse: 1.5329e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4299 - bpp: 0.6697 - mse: 1.8559e-04\n",
      "Epoch 335: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.4299 - bpp: 0.6697 - mse: 1.8559e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3480 - bpp: 0.6437 - mse: 1.7194e-04\n",
      "Epoch 336: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.3480 - bpp: 0.6437 - mse: 1.7194e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3441 - bpp: 0.6492 - mse: 1.6965e-04\n",
      "Epoch 337: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.3441 - bpp: 0.6492 - mse: 1.6965e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2868 - bpp: 0.6460 - mse: 1.5645e-04\n",
      "Epoch 338: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.2868 - bpp: 0.6460 - mse: 1.5645e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3988 - bpp: 0.6687 - mse: 1.7825e-04\n",
      "Epoch 339: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.3988 - bpp: 0.6687 - mse: 1.7825e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3641 - bpp: 0.6558 - mse: 1.7291e-04\n",
      "Epoch 340: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.3641 - bpp: 0.6558 - mse: 1.7291e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0496 - bpp: 0.7578 - mse: 3.1537e-04\n",
      "Epoch 341: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 2.0496 - bpp: 0.7578 - mse: 3.1537e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4757 - bpp: 0.7037 - mse: 1.8847e-04\n",
      "Epoch 342: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.4757 - bpp: 0.7037 - mse: 1.8847e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3437 - bpp: 0.6662 - mse: 1.6541e-04\n",
      "Epoch 343: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.3437 - bpp: 0.6662 - mse: 1.6541e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3997 - bpp: 0.6715 - mse: 1.7780e-04\n",
      "Epoch 344: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.3997 - bpp: 0.6715 - mse: 1.7780e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3729 - bpp: 0.6674 - mse: 1.7223e-04\n",
      "Epoch 345: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.3729 - bpp: 0.6674 - mse: 1.7223e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3187 - bpp: 0.6530 - mse: 1.6252e-04\n",
      "Epoch 346: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.3187 - bpp: 0.6530 - mse: 1.6252e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2860 - bpp: 0.6424 - mse: 1.5714e-04\n",
      "Epoch 347: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2860 - bpp: 0.6424 - mse: 1.5714e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3166 - bpp: 0.6510 - mse: 1.6250e-04\n",
      "Epoch 348: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.3166 - bpp: 0.6510 - mse: 1.6250e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2921 - bpp: 0.6405 - mse: 1.5907e-04\n",
      "Epoch 349: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2921 - bpp: 0.6405 - mse: 1.5907e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3681 - bpp: 0.6561 - mse: 1.7381e-04\n",
      "Epoch 350: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.3681 - bpp: 0.6561 - mse: 1.7381e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4059 - bpp: 0.6733 - mse: 1.7886e-04\n",
      "Epoch 351: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.4059 - bpp: 0.6733 - mse: 1.7886e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4182 - bpp: 0.6629 - mse: 1.8440e-04\n",
      "Epoch 352: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.4182 - bpp: 0.6629 - mse: 1.8440e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3355 - bpp: 0.6517 - mse: 1.6694e-04\n",
      "Epoch 353: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.3355 - bpp: 0.6517 - mse: 1.6694e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2906 - bpp: 0.6326 - mse: 1.6065e-04\n",
      "Epoch 354: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.2906 - bpp: 0.6326 - mse: 1.6065e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2640 - bpp: 0.6180 - mse: 1.5772e-04\n",
      "Epoch 355: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.2640 - bpp: 0.6180 - mse: 1.5772e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3859 - bpp: 0.6550 - mse: 1.7846e-04\n",
      "Epoch 356: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.3859 - bpp: 0.6550 - mse: 1.7846e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2515 - bpp: 0.6202 - mse: 1.5414e-04\n",
      "Epoch 357: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.2515 - bpp: 0.6202 - mse: 1.5414e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1979 - bpp: 0.6086 - mse: 1.4387e-04\n",
      "Epoch 358: loss improved from 1.23451 to 1.19793, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.1979 - bpp: 0.6086 - mse: 1.4387e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4254 - bpp: 0.6577 - mse: 1.8742e-04\n",
      "Epoch 359: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.4254 - bpp: 0.6577 - mse: 1.8742e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4449 - bpp: 0.6677 - mse: 1.8975e-04\n",
      "Epoch 360: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.4449 - bpp: 0.6677 - mse: 1.8975e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3486 - bpp: 0.6610 - mse: 1.6787e-04\n",
      "Epoch 361: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.3486 - bpp: 0.6610 - mse: 1.6787e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4440 - bpp: 0.6602 - mse: 1.9135e-04\n",
      "Epoch 362: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4440 - bpp: 0.6602 - mse: 1.9135e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2865 - bpp: 0.6337 - mse: 1.5937e-04\n",
      "Epoch 363: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2865 - bpp: 0.6337 - mse: 1.5937e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2997 - bpp: 0.6458 - mse: 1.5964e-04\n",
      "Epoch 364: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.2997 - bpp: 0.6458 - mse: 1.5964e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4322 - bpp: 0.6681 - mse: 1.8655e-04\n",
      "Epoch 365: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 32s 156ms/step - loss: 1.4322 - bpp: 0.6681 - mse: 1.8655e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3688 - bpp: 0.6607 - mse: 1.7286e-04\n",
      "Epoch 366: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.3688 - bpp: 0.6607 - mse: 1.7286e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3196 - bpp: 0.6503 - mse: 1.6341e-04\n",
      "Epoch 367: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.3196 - bpp: 0.6503 - mse: 1.6341e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2571 - bpp: 0.6252 - mse: 1.5428e-04\n",
      "Epoch 368: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.2571 - bpp: 0.6252 - mse: 1.5428e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3008 - bpp: 0.6308 - mse: 1.6359e-04\n",
      "Epoch 369: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.3008 - bpp: 0.6308 - mse: 1.6359e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1533 - bpp: 0.5978 - mse: 1.3562e-04\n",
      "Epoch 370: loss improved from 1.19793 to 1.15328, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.1533 - bpp: 0.5978 - mse: 1.3562e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4104 - bpp: 0.6723 - mse: 1.8019e-04\n",
      "Epoch 371: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 1.4104 - bpp: 0.6723 - mse: 1.8019e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2701 - bpp: 0.6219 - mse: 1.5825e-04\n",
      "Epoch 372: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 1.2701 - bpp: 0.6219 - mse: 1.5825e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3150 - bpp: 0.6330 - mse: 1.6651e-04\n",
      "Epoch 373: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 1.3150 - bpp: 0.6330 - mse: 1.6651e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2853 - bpp: 0.6361 - mse: 1.5850e-04\n",
      "Epoch 374: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.2853 - bpp: 0.6361 - mse: 1.5850e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3605 - bpp: 0.6534 - mse: 1.7265e-04\n",
      "Epoch 375: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 1.3605 - bpp: 0.6534 - mse: 1.7265e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4594 - bpp: 0.6751 - mse: 1.9149e-04\n",
      "Epoch 376: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4594 - bpp: 0.6751 - mse: 1.9149e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3530 - bpp: 0.6676 - mse: 1.6733e-04\n",
      "Epoch 377: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.3530 - bpp: 0.6676 - mse: 1.6733e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2657 - bpp: 0.6385 - mse: 1.5313e-04\n",
      "Epoch 378: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.2657 - bpp: 0.6385 - mse: 1.5313e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5708 - bpp: 0.6942 - mse: 2.1402e-04\n",
      "Epoch 379: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5708 - bpp: 0.6942 - mse: 2.1402e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3382 - bpp: 0.6474 - mse: 1.6866e-04\n",
      "Epoch 380: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3382 - bpp: 0.6474 - mse: 1.6866e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4337 - bpp: 0.6777 - mse: 1.8458e-04\n",
      "Epoch 381: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.4337 - bpp: 0.6777 - mse: 1.8458e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3497 - bpp: 0.6524 - mse: 1.7024e-04\n",
      "Epoch 382: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.3497 - bpp: 0.6524 - mse: 1.7024e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2814 - bpp: 0.6329 - mse: 1.5832e-04\n",
      "Epoch 383: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2814 - bpp: 0.6329 - mse: 1.5832e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2430 - bpp: 0.6207 - mse: 1.5194e-04\n",
      "Epoch 384: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2430 - bpp: 0.6207 - mse: 1.5194e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3226 - bpp: 0.6438 - mse: 1.6572e-04\n",
      "Epoch 385: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3226 - bpp: 0.6438 - mse: 1.6572e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2371 - bpp: 0.6235 - mse: 1.4979e-04\n",
      "Epoch 386: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2371 - bpp: 0.6235 - mse: 1.4979e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4281 - bpp: 0.6656 - mse: 1.8614e-04\n",
      "Epoch 387: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4281 - bpp: 0.6656 - mse: 1.8614e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2461 - bpp: 0.6218 - mse: 1.5240e-04\n",
      "Epoch 388: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2461 - bpp: 0.6218 - mse: 1.5240e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2053 - bpp: 0.6135 - mse: 1.4448e-04\n",
      "Epoch 389: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2053 - bpp: 0.6135 - mse: 1.4448e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5344 - bpp: 0.6848 - mse: 2.0741e-04\n",
      "Epoch 390: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5344 - bpp: 0.6848 - mse: 2.0741e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3485 - bpp: 0.6513 - mse: 1.7020e-04\n",
      "Epoch 391: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.3485 - bpp: 0.6513 - mse: 1.7020e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1691 - bpp: 0.5999 - mse: 1.3895e-04\n",
      "Epoch 392: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1691 - bpp: 0.5999 - mse: 1.3895e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1370 - bpp: 0.5980 - mse: 1.3158e-04\n",
      "Epoch 393: loss improved from 1.15328 to 1.13697, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1370 - bpp: 0.5980 - mse: 1.3158e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2778 - bpp: 0.6302 - mse: 1.5812e-04\n",
      "Epoch 394: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2778 - bpp: 0.6302 - mse: 1.5812e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1937 - bpp: 0.6121 - mse: 1.4199e-04\n",
      "Epoch 395: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1937 - bpp: 0.6121 - mse: 1.4199e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2668 - bpp: 0.6292 - mse: 1.5565e-04\n",
      "Epoch 396: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2668 - bpp: 0.6292 - mse: 1.5565e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3443 - bpp: 0.6542 - mse: 1.6848e-04\n",
      "Epoch 397: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.3443 - bpp: 0.6542 - mse: 1.6848e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2916 - bpp: 0.6365 - mse: 1.5993e-04\n",
      "Epoch 398: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2916 - bpp: 0.6365 - mse: 1.5993e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2366 - bpp: 0.6188 - mse: 1.5083e-04\n",
      "Epoch 399: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2366 - bpp: 0.6188 - mse: 1.5083e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4114 - bpp: 0.6622 - mse: 1.8290e-04\n",
      "Epoch 400: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.4114 - bpp: 0.6622 - mse: 1.8290e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2316 - bpp: 0.6140 - mse: 1.5079e-04\n",
      "Epoch 401: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2316 - bpp: 0.6140 - mse: 1.5079e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2771 - bpp: 0.6328 - mse: 1.5730e-04\n",
      "Epoch 402: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2771 - bpp: 0.6328 - mse: 1.5730e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3469 - bpp: 0.6485 - mse: 1.7052e-04\n",
      "Epoch 403: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3469 - bpp: 0.6485 - mse: 1.7052e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3237 - bpp: 0.6396 - mse: 1.6702e-04\n",
      "Epoch 404: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.3237 - bpp: 0.6396 - mse: 1.6702e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2849 - bpp: 0.6402 - mse: 1.5740e-04\n",
      "Epoch 405: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.2849 - bpp: 0.6402 - mse: 1.5740e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1640 - bpp: 0.6048 - mse: 1.3651e-04\n",
      "Epoch 406: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1640 - bpp: 0.6048 - mse: 1.3651e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3017 - bpp: 0.6360 - mse: 1.6251e-04\n",
      "Epoch 407: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3017 - bpp: 0.6360 - mse: 1.6251e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1531 - bpp: 0.5988 - mse: 1.3535e-04\n",
      "Epoch 408: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1531 - bpp: 0.5988 - mse: 1.3535e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2743 - bpp: 0.6219 - mse: 1.5929e-04\n",
      "Epoch 409: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2743 - bpp: 0.6219 - mse: 1.5929e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3964 - bpp: 0.6550 - mse: 1.8100e-04\n",
      "Epoch 410: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3964 - bpp: 0.6550 - mse: 1.8100e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2459 - bpp: 0.6281 - mse: 1.5084e-04\n",
      "Epoch 411: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2459 - bpp: 0.6281 - mse: 1.5084e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2414 - bpp: 0.6313 - mse: 1.4897e-04\n",
      "Epoch 412: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2414 - bpp: 0.6313 - mse: 1.4897e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3506 - bpp: 0.6482 - mse: 1.7150e-04\n",
      "Epoch 413: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3506 - bpp: 0.6482 - mse: 1.7150e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2764 - bpp: 0.6336 - mse: 1.5695e-04\n",
      "Epoch 414: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2764 - bpp: 0.6336 - mse: 1.5695e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3156 - bpp: 0.6357 - mse: 1.6598e-04\n",
      "Epoch 415: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3156 - bpp: 0.6357 - mse: 1.6598e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.6315 - mse: 1.6417e-04\n",
      "Epoch 416: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3039 - bpp: 0.6315 - mse: 1.6417e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2765 - bpp: 0.6242 - mse: 1.5923e-04\n",
      "Epoch 417: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2765 - bpp: 0.6242 - mse: 1.5923e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3644 - bpp: 0.6451 - mse: 1.7561e-04\n",
      "Epoch 418: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3644 - bpp: 0.6451 - mse: 1.7561e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2841 - bpp: 0.6306 - mse: 1.5954e-04\n",
      "Epoch 419: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2841 - bpp: 0.6306 - mse: 1.5954e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2072 - bpp: 0.6123 - mse: 1.4526e-04\n",
      "Epoch 420: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2072 - bpp: 0.6123 - mse: 1.4526e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2139 - bpp: 0.6153 - mse: 1.4614e-04\n",
      "Epoch 421: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.2139 - bpp: 0.6153 - mse: 1.4614e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2047 - bpp: 0.6074 - mse: 1.4583e-04\n",
      "Epoch 422: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2047 - bpp: 0.6074 - mse: 1.4583e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5920 - bpp: 0.6794 - mse: 2.2281e-04\n",
      "Epoch 423: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5920 - bpp: 0.6794 - mse: 2.2281e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2265 - bpp: 0.6101 - mse: 1.5049e-04\n",
      "Epoch 424: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2265 - bpp: 0.6101 - mse: 1.5049e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1886 - bpp: 0.6037 - mse: 1.4281e-04\n",
      "Epoch 425: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.1886 - bpp: 0.6037 - mse: 1.4281e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2002 - bpp: 0.6043 - mse: 1.4549e-04\n",
      "Epoch 426: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2002 - bpp: 0.6043 - mse: 1.4549e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2841 - bpp: 0.6281 - mse: 1.6016e-04\n",
      "Epoch 427: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2841 - bpp: 0.6281 - mse: 1.6016e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2482 - bpp: 0.6230 - mse: 1.5263e-04\n",
      "Epoch 428: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2482 - bpp: 0.6230 - mse: 1.5263e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3010 - bpp: 0.6309 - mse: 1.6358e-04\n",
      "Epoch 429: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.3010 - bpp: 0.6309 - mse: 1.6358e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2113 - bpp: 0.6074 - mse: 1.4744e-04\n",
      "Epoch 430: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2113 - bpp: 0.6074 - mse: 1.4744e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3507 - bpp: 0.6449 - mse: 1.7232e-04\n",
      "Epoch 431: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3507 - bpp: 0.6449 - mse: 1.7232e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2949 - bpp: 0.6353 - mse: 1.6106e-04\n",
      "Epoch 432: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2949 - bpp: 0.6353 - mse: 1.6106e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3391 - bpp: 0.6488 - mse: 1.6853e-04\n",
      "Epoch 433: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.3391 - bpp: 0.6488 - mse: 1.6853e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2042 - bpp: 0.6022 - mse: 1.4697e-04\n",
      "Epoch 434: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2042 - bpp: 0.6022 - mse: 1.4697e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1873 - bpp: 0.5921 - mse: 1.4532e-04\n",
      "Epoch 435: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1873 - bpp: 0.5921 - mse: 1.4532e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4227 - bpp: 0.6640 - mse: 1.8523e-04\n",
      "Epoch 436: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.4227 - bpp: 0.6640 - mse: 1.8523e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1850 - bpp: 0.6069 - mse: 1.4113e-04\n",
      "Epoch 437: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1850 - bpp: 0.6069 - mse: 1.4113e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3517 - bpp: 0.6247 - mse: 1.7749e-04\n",
      "Epoch 438: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.3517 - bpp: 0.6247 - mse: 1.7749e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3704 - bpp: 0.6487 - mse: 1.7619e-04\n",
      "Epoch 439: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.3704 - bpp: 0.6487 - mse: 1.7619e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2111 - bpp: 0.6047 - mse: 1.4804e-04\n",
      "Epoch 440: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2111 - bpp: 0.6047 - mse: 1.4804e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2808 - bpp: 0.6349 - mse: 1.5770e-04\n",
      "Epoch 441: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2808 - bpp: 0.6349 - mse: 1.5770e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2745 - bpp: 0.6305 - mse: 1.5724e-04\n",
      "Epoch 442: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2745 - bpp: 0.6305 - mse: 1.5724e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2770 - bpp: 0.6311 - mse: 1.5769e-04\n",
      "Epoch 443: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2770 - bpp: 0.6311 - mse: 1.5769e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2521 - bpp: 0.6301 - mse: 1.5185e-04\n",
      "Epoch 444: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2521 - bpp: 0.6301 - mse: 1.5185e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3418 - bpp: 0.6315 - mse: 1.7343e-04\n",
      "Epoch 445: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.3418 - bpp: 0.6315 - mse: 1.7343e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2620 - bpp: 0.6197 - mse: 1.5681e-04\n",
      "Epoch 446: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2620 - bpp: 0.6197 - mse: 1.5681e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2420 - bpp: 0.6159 - mse: 1.5286e-04\n",
      "Epoch 447: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2420 - bpp: 0.6159 - mse: 1.5286e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2308 - bpp: 0.6135 - mse: 1.5072e-04\n",
      "Epoch 448: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2308 - bpp: 0.6135 - mse: 1.5072e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2163 - bpp: 0.6107 - mse: 1.4785e-04\n",
      "Epoch 449: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2163 - bpp: 0.6107 - mse: 1.4785e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1531 - bpp: 0.5949 - mse: 1.3627e-04\n",
      "Epoch 450: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1531 - bpp: 0.5949 - mse: 1.3627e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3201 - bpp: 0.6345 - mse: 1.6739e-04\n",
      "Epoch 451: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.3201 - bpp: 0.6345 - mse: 1.6739e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2128 - bpp: 0.6127 - mse: 1.4651e-04\n",
      "Epoch 452: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2128 - bpp: 0.6127 - mse: 1.4651e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2939 - bpp: 0.6323 - mse: 1.6152e-04\n",
      "Epoch 453: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2939 - bpp: 0.6323 - mse: 1.6152e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5871 - mse: 1.3886e-04\n",
      "Epoch 454: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1559 - bpp: 0.5871 - mse: 1.3886e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2511 - bpp: 0.6214 - mse: 1.5373e-04\n",
      "Epoch 455: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2511 - bpp: 0.6214 - mse: 1.5373e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3020 - bpp: 0.6338 - mse: 1.6312e-04\n",
      "Epoch 456: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3020 - bpp: 0.6338 - mse: 1.6312e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2606 - bpp: 0.6203 - mse: 1.5634e-04\n",
      "Epoch 457: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2606 - bpp: 0.6203 - mse: 1.5634e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1804 - bpp: 0.6100 - mse: 1.3926e-04\n",
      "Epoch 458: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1804 - bpp: 0.6100 - mse: 1.3926e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2008 - bpp: 0.6095 - mse: 1.4436e-04\n",
      "Epoch 459: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2008 - bpp: 0.6095 - mse: 1.4436e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2528 - bpp: 0.6194 - mse: 1.5465e-04\n",
      "Epoch 460: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2528 - bpp: 0.6194 - mse: 1.5465e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3362 - bpp: 0.6360 - mse: 1.7095e-04\n",
      "Epoch 461: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3362 - bpp: 0.6360 - mse: 1.7095e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3488 - bpp: 0.6302 - mse: 1.7543e-04\n",
      "Epoch 462: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3488 - bpp: 0.6302 - mse: 1.7543e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5838 - bpp: 0.6692 - mse: 2.2329e-04\n",
      "Epoch 463: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5838 - bpp: 0.6692 - mse: 2.2329e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2209 - bpp: 0.6153 - mse: 1.4785e-04\n",
      "Epoch 464: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2209 - bpp: 0.6153 - mse: 1.4785e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2933 - bpp: 0.6299 - mse: 1.6197e-04\n",
      "Epoch 465: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2933 - bpp: 0.6299 - mse: 1.6197e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2501 - bpp: 0.6173 - mse: 1.5449e-04\n",
      "Epoch 466: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2501 - bpp: 0.6173 - mse: 1.5449e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2790 - bpp: 0.6317 - mse: 1.5804e-04\n",
      "Epoch 467: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2790 - bpp: 0.6317 - mse: 1.5804e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5949 - bpp: 0.6630 - mse: 2.2751e-04\n",
      "Epoch 468: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5949 - bpp: 0.6630 - mse: 2.2751e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1937 - bpp: 0.6166 - mse: 1.4089e-04\n",
      "Epoch 469: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1937 - bpp: 0.6166 - mse: 1.4089e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2189 - bpp: 0.6224 - mse: 1.4561e-04\n",
      "Epoch 470: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2189 - bpp: 0.6224 - mse: 1.4561e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2131 - bpp: 0.6024 - mse: 1.4910e-04\n",
      "Epoch 471: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2131 - bpp: 0.6024 - mse: 1.4910e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3507 - bpp: 0.6437 - mse: 1.7260e-04\n",
      "Epoch 472: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3507 - bpp: 0.6437 - mse: 1.7260e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2586 - bpp: 0.6198 - mse: 1.5595e-04\n",
      "Epoch 473: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2586 - bpp: 0.6198 - mse: 1.5595e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1732 - bpp: 0.5950 - mse: 1.4116e-04\n",
      "Epoch 474: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1732 - bpp: 0.5950 - mse: 1.4116e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2518 - bpp: 0.6188 - mse: 1.5455e-04\n",
      "Epoch 475: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.2518 - bpp: 0.6188 - mse: 1.5455e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2061 - bpp: 0.6159 - mse: 1.4408e-04\n",
      "Epoch 476: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2061 - bpp: 0.6159 - mse: 1.4408e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1391 - bpp: 0.5940 - mse: 1.3309e-04\n",
      "Epoch 477: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1391 - bpp: 0.5940 - mse: 1.3309e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2458 - bpp: 0.6211 - mse: 1.5254e-04\n",
      "Epoch 478: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2458 - bpp: 0.6211 - mse: 1.5254e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2282 - bpp: 0.6091 - mse: 1.5116e-04\n",
      "Epoch 479: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2282 - bpp: 0.6091 - mse: 1.5116e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1392 - bpp: 0.5880 - mse: 1.3457e-04\n",
      "Epoch 480: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1392 - bpp: 0.5880 - mse: 1.3457e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3318 - bpp: 0.6354 - mse: 1.7002e-04\n",
      "Epoch 481: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.3318 - bpp: 0.6354 - mse: 1.7002e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1410 - bpp: 0.5894 - mse: 1.3467e-04\n",
      "Epoch 482: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1410 - bpp: 0.5894 - mse: 1.3467e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2333 - bpp: 0.6080 - mse: 1.5267e-04\n",
      "Epoch 483: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.2333 - bpp: 0.6080 - mse: 1.5267e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2882 - bpp: 0.6176 - mse: 1.6374e-04\n",
      "Epoch 484: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2882 - bpp: 0.6176 - mse: 1.6374e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1881 - bpp: 0.5941 - mse: 1.4501e-04\n",
      "Epoch 485: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1881 - bpp: 0.5941 - mse: 1.4501e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2890 - bpp: 0.6283 - mse: 1.6130e-04\n",
      "Epoch 486: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2890 - bpp: 0.6283 - mse: 1.6130e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3140 - bpp: 0.6395 - mse: 1.6468e-04\n",
      "Epoch 487: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3140 - bpp: 0.6395 - mse: 1.6468e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1635 - bpp: 0.5922 - mse: 1.3948e-04\n",
      "Epoch 488: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1635 - bpp: 0.5922 - mse: 1.3948e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2562 - bpp: 0.6183 - mse: 1.5574e-04\n",
      "Epoch 489: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2562 - bpp: 0.6183 - mse: 1.5574e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1990 - bpp: 0.6007 - mse: 1.4608e-04\n",
      "Epoch 490: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1990 - bpp: 0.6007 - mse: 1.4608e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1103 - bpp: 0.5807 - mse: 1.2930e-04\n",
      "Epoch 491: loss improved from 1.13697 to 1.11033, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1103 - bpp: 0.5807 - mse: 1.2930e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2323 - bpp: 0.6075 - mse: 1.5254e-04\n",
      "Epoch 492: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2323 - bpp: 0.6075 - mse: 1.5254e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2126 - bpp: 0.5989 - mse: 1.4984e-04\n",
      "Epoch 493: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2126 - bpp: 0.5989 - mse: 1.4984e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1759 - bpp: 0.6043 - mse: 1.3956e-04\n",
      "Epoch 494: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1759 - bpp: 0.6043 - mse: 1.3956e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2895 - bpp: 0.6256 - mse: 1.6209e-04\n",
      "Epoch 495: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.2895 - bpp: 0.6256 - mse: 1.6209e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1799 - bpp: 0.5941 - mse: 1.4301e-04\n",
      "Epoch 496: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1799 - bpp: 0.5941 - mse: 1.4301e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4169 - bpp: 0.6212 - mse: 1.9425e-04\n",
      "Epoch 497: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4169 - bpp: 0.6212 - mse: 1.9425e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4162 - bpp: 0.6604 - mse: 1.8453e-04\n",
      "Epoch 498: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4162 - bpp: 0.6604 - mse: 1.8453e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2275 - bpp: 0.6069 - mse: 1.5150e-04\n",
      "Epoch 499: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2275 - bpp: 0.6069 - mse: 1.5150e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1735 - bpp: 0.5989 - mse: 1.4028e-04\n",
      "Epoch 500: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1735 - bpp: 0.5989 - mse: 1.4028e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3980 - bpp: 0.6570 - mse: 1.8091e-04\n",
      "Epoch 501: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.3980 - bpp: 0.6570 - mse: 1.8091e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2637 - bpp: 0.6247 - mse: 1.5601e-04\n",
      "Epoch 502: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2637 - bpp: 0.6247 - mse: 1.5601e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2007 - bpp: 0.5967 - mse: 1.4746e-04\n",
      "Epoch 503: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2007 - bpp: 0.5967 - mse: 1.4746e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2688 - bpp: 0.6215 - mse: 1.5804e-04\n",
      "Epoch 504: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2688 - bpp: 0.6215 - mse: 1.5804e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2750 - bpp: 0.6277 - mse: 1.5802e-04\n",
      "Epoch 505: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2750 - bpp: 0.6277 - mse: 1.5802e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2385 - bpp: 0.6011 - mse: 1.5563e-04\n",
      "Epoch 506: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2385 - bpp: 0.6011 - mse: 1.5563e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.5980 - mse: 1.4506e-04\n",
      "Epoch 507: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1922 - bpp: 0.5980 - mse: 1.4506e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2073 - bpp: 0.5922 - mse: 1.5018e-04\n",
      "Epoch 508: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2073 - bpp: 0.5922 - mse: 1.5018e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2343 - bpp: 0.6115 - mse: 1.5205e-04\n",
      "Epoch 509: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.2343 - bpp: 0.6115 - mse: 1.5205e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4195 - bpp: 0.6587 - mse: 1.8573e-04\n",
      "Epoch 510: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4195 - bpp: 0.6587 - mse: 1.8573e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2950 - bpp: 0.6279 - mse: 1.6288e-04\n",
      "Epoch 511: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2950 - bpp: 0.6279 - mse: 1.6288e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2213 - bpp: 0.6063 - mse: 1.5016e-04\n",
      "Epoch 512: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2213 - bpp: 0.6063 - mse: 1.5016e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3386 - bpp: 0.6270 - mse: 1.7373e-04\n",
      "Epoch 513: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3386 - bpp: 0.6270 - mse: 1.7373e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3374 - bpp: 0.6296 - mse: 1.7279e-04\n",
      "Epoch 514: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3374 - bpp: 0.6296 - mse: 1.7279e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2627 - bpp: 0.6220 - mse: 1.5642e-04\n",
      "Epoch 515: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2627 - bpp: 0.6220 - mse: 1.5642e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3189 - bpp: 0.6408 - mse: 1.6554e-04\n",
      "Epoch 516: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3189 - bpp: 0.6408 - mse: 1.6554e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3003 - bpp: 0.6362 - mse: 1.6214e-04\n",
      "Epoch 517: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.3003 - bpp: 0.6362 - mse: 1.6214e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2998 - bpp: 0.6318 - mse: 1.6307e-04\n",
      "Epoch 518: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2998 - bpp: 0.6318 - mse: 1.6307e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2402 - bpp: 0.6246 - mse: 1.5031e-04\n",
      "Epoch 519: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2402 - bpp: 0.6246 - mse: 1.5031e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1637 - bpp: 0.5961 - mse: 1.3859e-04\n",
      "Epoch 520: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1637 - bpp: 0.5961 - mse: 1.3859e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1940 - bpp: 0.5993 - mse: 1.4520e-04\n",
      "Epoch 521: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1940 - bpp: 0.5993 - mse: 1.4520e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2587 - bpp: 0.6209 - mse: 1.5571e-04\n",
      "Epoch 522: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2587 - bpp: 0.6209 - mse: 1.5571e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2540 - bpp: 0.6168 - mse: 1.5556e-04\n",
      "Epoch 523: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2540 - bpp: 0.6168 - mse: 1.5556e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3878 - bpp: 0.6581 - mse: 1.7813e-04\n",
      "Epoch 524: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3878 - bpp: 0.6581 - mse: 1.7813e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3554 - bpp: 0.6514 - mse: 1.7189e-04\n",
      "Epoch 525: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.3554 - bpp: 0.6514 - mse: 1.7189e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2948 - bpp: 0.6310 - mse: 1.6206e-04\n",
      "Epoch 526: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2948 - bpp: 0.6310 - mse: 1.6206e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2982 - bpp: 0.6383 - mse: 1.6110e-04\n",
      "Epoch 527: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2982 - bpp: 0.6383 - mse: 1.6110e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2335 - bpp: 0.6146 - mse: 1.5110e-04\n",
      "Epoch 528: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2335 - bpp: 0.6146 - mse: 1.5110e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2674 - bpp: 0.6289 - mse: 1.5587e-04\n",
      "Epoch 529: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2674 - bpp: 0.6289 - mse: 1.5587e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1985 - bpp: 0.6158 - mse: 1.4226e-04\n",
      "Epoch 530: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.1985 - bpp: 0.6158 - mse: 1.4226e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2103 - bpp: 0.6092 - mse: 1.4676e-04\n",
      "Epoch 531: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2103 - bpp: 0.6092 - mse: 1.4676e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2232 - bpp: 0.6061 - mse: 1.5065e-04\n",
      "Epoch 532: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2232 - bpp: 0.6061 - mse: 1.5065e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1244 - bpp: 0.5897 - mse: 1.3053e-04\n",
      "Epoch 533: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1244 - bpp: 0.5897 - mse: 1.3053e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2812 - bpp: 0.6324 - mse: 1.5841e-04\n",
      "Epoch 534: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.2812 - bpp: 0.6324 - mse: 1.5841e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2961 - bpp: 0.6229 - mse: 1.6435e-04\n",
      "Epoch 535: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2961 - bpp: 0.6229 - mse: 1.6435e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2901 - bpp: 0.6289 - mse: 1.6144e-04\n",
      "Epoch 536: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2901 - bpp: 0.6289 - mse: 1.6144e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3856 - bpp: 0.6354 - mse: 1.8315e-04\n",
      "Epoch 537: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.3856 - bpp: 0.6354 - mse: 1.8315e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1464 - bpp: 0.5888 - mse: 1.3614e-04\n",
      "Epoch 538: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1464 - bpp: 0.5888 - mse: 1.3614e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1542 - bpp: 0.5966 - mse: 1.3614e-04\n",
      "Epoch 539: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1542 - bpp: 0.5966 - mse: 1.3614e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1911 - bpp: 0.6015 - mse: 1.4394e-04\n",
      "Epoch 540: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1911 - bpp: 0.6015 - mse: 1.4394e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3285 - bpp: 0.6300 - mse: 1.7053e-04\n",
      "Epoch 541: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3285 - bpp: 0.6300 - mse: 1.7053e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1633 - bpp: 0.5937 - mse: 1.3907e-04\n",
      "Epoch 542: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1633 - bpp: 0.5937 - mse: 1.3907e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1224 - bpp: 0.5778 - mse: 1.3296e-04\n",
      "Epoch 543: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1224 - bpp: 0.5778 - mse: 1.3296e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1436 - bpp: 0.5828 - mse: 1.3692e-04\n",
      "Epoch 544: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1436 - bpp: 0.5828 - mse: 1.3692e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2136 - bpp: 0.6086 - mse: 1.4770e-04\n",
      "Epoch 545: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2136 - bpp: 0.6086 - mse: 1.4770e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2514 - bpp: 0.6134 - mse: 1.5576e-04\n",
      "Epoch 546: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2514 - bpp: 0.6134 - mse: 1.5576e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2139 - bpp: 0.6163 - mse: 1.4589e-04\n",
      "Epoch 547: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2139 - bpp: 0.6163 - mse: 1.4589e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2258 - bpp: 0.6058 - mse: 1.5136e-04\n",
      "Epoch 548: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2258 - bpp: 0.6058 - mse: 1.5136e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2447 - bpp: 0.6192 - mse: 1.5271e-04\n",
      "Epoch 549: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2447 - bpp: 0.6192 - mse: 1.5271e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1646 - bpp: 0.5956 - mse: 1.3890e-04\n",
      "Epoch 550: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1646 - bpp: 0.5956 - mse: 1.3890e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2392 - bpp: 0.6100 - mse: 1.5362e-04\n",
      "Epoch 551: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2392 - bpp: 0.6100 - mse: 1.5362e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2002 - bpp: 0.5949 - mse: 1.4777e-04\n",
      "Epoch 552: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2002 - bpp: 0.5949 - mse: 1.4777e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2717 - bpp: 0.6198 - mse: 1.5917e-04\n",
      "Epoch 553: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2717 - bpp: 0.6198 - mse: 1.5917e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2367 - bpp: 0.6096 - mse: 1.5310e-04\n",
      "Epoch 554: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2367 - bpp: 0.6096 - mse: 1.5310e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2069 - bpp: 0.6059 - mse: 1.4672e-04\n",
      "Epoch 555: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2069 - bpp: 0.6059 - mse: 1.4672e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1313 - bpp: 0.5818 - mse: 1.3415e-04\n",
      "Epoch 556: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1313 - bpp: 0.5818 - mse: 1.3415e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1438 - bpp: 0.5810 - mse: 1.3741e-04\n",
      "Epoch 557: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1438 - bpp: 0.5810 - mse: 1.3741e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2808 - bpp: 0.6190 - mse: 1.6157e-04\n",
      "Epoch 558: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2808 - bpp: 0.6190 - mse: 1.6157e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2264 - bpp: 0.6078 - mse: 1.5103e-04\n",
      "Epoch 559: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2264 - bpp: 0.6078 - mse: 1.5103e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4254 - bpp: 0.6589 - mse: 1.8713e-04\n",
      "Epoch 560: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.4254 - bpp: 0.6589 - mse: 1.8713e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1484 - bpp: 0.5850 - mse: 1.3754e-04\n",
      "Epoch 561: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1484 - bpp: 0.5850 - mse: 1.3754e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2087 - bpp: 0.5983 - mse: 1.4904e-04\n",
      "Epoch 562: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2087 - bpp: 0.5983 - mse: 1.4904e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2761 - bpp: 0.6144 - mse: 1.6154e-04\n",
      "Epoch 563: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2761 - bpp: 0.6144 - mse: 1.6154e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2241 - bpp: 0.6137 - mse: 1.4903e-04\n",
      "Epoch 564: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2241 - bpp: 0.6137 - mse: 1.4903e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3449 - bpp: 0.6221 - mse: 1.7648e-04\n",
      "Epoch 565: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3449 - bpp: 0.6221 - mse: 1.7648e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1918 - bpp: 0.5992 - mse: 1.4468e-04\n",
      "Epoch 566: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1918 - bpp: 0.5992 - mse: 1.4468e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0839 - bpp: 0.5587 - mse: 1.2823e-04\n",
      "Epoch 567: loss improved from 1.11033 to 1.08390, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0839 - bpp: 0.5587 - mse: 1.2823e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1789 - bpp: 0.6034 - mse: 1.4048e-04\n",
      "Epoch 568: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1789 - bpp: 0.6034 - mse: 1.4048e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1254 - bpp: 0.5873 - mse: 1.3138e-04\n",
      "Epoch 569: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1254 - bpp: 0.5873 - mse: 1.3138e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1708 - bpp: 0.5962 - mse: 1.4029e-04\n",
      "Epoch 570: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1708 - bpp: 0.5962 - mse: 1.4029e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2442 - bpp: 0.6159 - mse: 1.5340e-04\n",
      "Epoch 571: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2442 - bpp: 0.6159 - mse: 1.5340e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2213 - bpp: 0.6079 - mse: 1.4976e-04\n",
      "Epoch 572: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2213 - bpp: 0.6079 - mse: 1.4976e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2008 - bpp: 0.5987 - mse: 1.4701e-04\n",
      "Epoch 573: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2008 - bpp: 0.5987 - mse: 1.4701e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1549 - bpp: 0.5911 - mse: 1.3763e-04\n",
      "Epoch 574: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1549 - bpp: 0.5911 - mse: 1.3763e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1428 - bpp: 0.5944 - mse: 1.3388e-04\n",
      "Epoch 575: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1428 - bpp: 0.5944 - mse: 1.3388e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1835 - bpp: 0.5964 - mse: 1.4334e-04\n",
      "Epoch 576: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1835 - bpp: 0.5964 - mse: 1.4334e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1219 - bpp: 0.5704 - mse: 1.3463e-04\n",
      "Epoch 577: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1219 - bpp: 0.5704 - mse: 1.3463e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2743 - bpp: 0.6243 - mse: 1.5869e-04\n",
      "Epoch 578: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2743 - bpp: 0.6243 - mse: 1.5869e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1738 - bpp: 0.5908 - mse: 1.4232e-04\n",
      "Epoch 579: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1738 - bpp: 0.5908 - mse: 1.4232e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0988 - bpp: 0.5766 - mse: 1.2749e-04\n",
      "Epoch 580: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0988 - bpp: 0.5766 - mse: 1.2749e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2774 - bpp: 0.6248 - mse: 1.5932e-04\n",
      "Epoch 581: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2774 - bpp: 0.6248 - mse: 1.5932e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.6075 - mse: 1.4273e-04\n",
      "Epoch 582: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1922 - bpp: 0.6075 - mse: 1.4273e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1256 - bpp: 0.5769 - mse: 1.3396e-04\n",
      "Epoch 583: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1256 - bpp: 0.5769 - mse: 1.3396e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1463 - bpp: 0.5879 - mse: 1.3633e-04\n",
      "Epoch 584: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1463 - bpp: 0.5879 - mse: 1.3633e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2436 - bpp: 0.6126 - mse: 1.5405e-04\n",
      "Epoch 585: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2436 - bpp: 0.6126 - mse: 1.5405e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2545 - bpp: 0.6096 - mse: 1.5744e-04\n",
      "Epoch 586: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.2545 - bpp: 0.6096 - mse: 1.5744e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1982 - bpp: 0.5925 - mse: 1.4788e-04\n",
      "Epoch 587: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1982 - bpp: 0.5925 - mse: 1.4788e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2537 - bpp: 0.6097 - mse: 1.5724e-04\n",
      "Epoch 588: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2537 - bpp: 0.6097 - mse: 1.5724e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2621 - bpp: 0.6106 - mse: 1.5905e-04\n",
      "Epoch 589: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2621 - bpp: 0.6106 - mse: 1.5905e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2032 - bpp: 0.6057 - mse: 1.4587e-04\n",
      "Epoch 590: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2032 - bpp: 0.6057 - mse: 1.4587e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2909 - bpp: 0.6248 - mse: 1.6262e-04\n",
      "Epoch 591: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2909 - bpp: 0.6248 - mse: 1.6262e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2664 - bpp: 0.6152 - mse: 1.5898e-04\n",
      "Epoch 592: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2664 - bpp: 0.6152 - mse: 1.5898e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2354 - bpp: 0.6085 - mse: 1.5305e-04\n",
      "Epoch 593: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2354 - bpp: 0.6085 - mse: 1.5305e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1863 - bpp: 0.5832 - mse: 1.4724e-04\n",
      "Epoch 594: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1863 - bpp: 0.5832 - mse: 1.4724e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1176 - bpp: 0.5691 - mse: 1.3392e-04\n",
      "Epoch 595: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1176 - bpp: 0.5691 - mse: 1.3392e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2268 - bpp: 0.6131 - mse: 1.4984e-04\n",
      "Epoch 596: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2268 - bpp: 0.6131 - mse: 1.4984e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.6074 - mse: 1.4388e-04\n",
      "Epoch 597: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1967 - bpp: 0.6074 - mse: 1.4388e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1802 - bpp: 0.5890 - mse: 1.4434e-04\n",
      "Epoch 598: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1802 - bpp: 0.5890 - mse: 1.4434e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2010 - bpp: 0.6052 - mse: 1.4548e-04\n",
      "Epoch 599: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2010 - bpp: 0.6052 - mse: 1.4548e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3197 - bpp: 0.6318 - mse: 1.6794e-04\n",
      "Epoch 600: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.3197 - bpp: 0.6318 - mse: 1.6794e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1649 - bpp: 0.5940 - mse: 1.3938e-04\n",
      "Epoch 601: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1649 - bpp: 0.5940 - mse: 1.3938e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2021 - bpp: 0.5989 - mse: 1.4725e-04\n",
      "Epoch 602: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2021 - bpp: 0.5989 - mse: 1.4725e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1995 - bpp: 0.5981 - mse: 1.4683e-04\n",
      "Epoch 603: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1995 - bpp: 0.5981 - mse: 1.4683e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2604 - bpp: 0.6105 - mse: 1.5866e-04\n",
      "Epoch 604: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2604 - bpp: 0.6105 - mse: 1.5866e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2301 - bpp: 0.6075 - mse: 1.5201e-04\n",
      "Epoch 605: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2301 - bpp: 0.6075 - mse: 1.5201e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1813 - bpp: 0.5964 - mse: 1.4279e-04\n",
      "Epoch 606: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1813 - bpp: 0.5964 - mse: 1.4279e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2083 - bpp: 0.6061 - mse: 1.4700e-04\n",
      "Epoch 607: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2083 - bpp: 0.6061 - mse: 1.4700e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3116 - bpp: 0.6327 - mse: 1.6573e-04\n",
      "Epoch 608: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3116 - bpp: 0.6327 - mse: 1.6573e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2863 - bpp: 0.6114 - mse: 1.6477e-04\n",
      "Epoch 609: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.2863 - bpp: 0.6114 - mse: 1.6477e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1621 - bpp: 0.5885 - mse: 1.4003e-04\n",
      "Epoch 610: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1621 - bpp: 0.5885 - mse: 1.4003e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2812 - bpp: 0.6160 - mse: 1.6241e-04\n",
      "Epoch 611: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2812 - bpp: 0.6160 - mse: 1.6241e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1481 - bpp: 0.5798 - mse: 1.3874e-04\n",
      "Epoch 612: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1481 - bpp: 0.5798 - mse: 1.3874e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1830 - bpp: 0.5988 - mse: 1.4263e-04\n",
      "Epoch 613: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1830 - bpp: 0.5988 - mse: 1.4263e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2198 - bpp: 0.5982 - mse: 1.5177e-04\n",
      "Epoch 614: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2198 - bpp: 0.5982 - mse: 1.5177e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1651 - bpp: 0.5999 - mse: 1.3798e-04\n",
      "Epoch 615: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1651 - bpp: 0.5999 - mse: 1.3798e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1995 - bpp: 0.6054 - mse: 1.4502e-04\n",
      "Epoch 616: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1995 - bpp: 0.6054 - mse: 1.4502e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1397 - bpp: 0.5852 - mse: 1.3538e-04\n",
      "Epoch 617: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1397 - bpp: 0.5852 - mse: 1.3538e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2084 - bpp: 0.5971 - mse: 1.4925e-04\n",
      "Epoch 618: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2084 - bpp: 0.5971 - mse: 1.4925e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2958 - bpp: 0.6365 - mse: 1.6096e-04\n",
      "Epoch 619: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2958 - bpp: 0.6365 - mse: 1.6096e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2373 - bpp: 0.6129 - mse: 1.5245e-04\n",
      "Epoch 620: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2373 - bpp: 0.6129 - mse: 1.5245e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3706 - bpp: 0.6541 - mse: 1.7492e-04\n",
      "Epoch 621: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3706 - bpp: 0.6541 - mse: 1.7492e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1882 - bpp: 0.5936 - mse: 1.4517e-04\n",
      "Epoch 622: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1882 - bpp: 0.5936 - mse: 1.4517e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0377 - bpp: 0.5571 - mse: 1.1735e-04\n",
      "Epoch 623: loss improved from 1.08390 to 1.03774, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0377 - bpp: 0.5571 - mse: 1.1735e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1653 - bpp: 0.5796 - mse: 1.4299e-04\n",
      "Epoch 624: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.1653 - bpp: 0.5796 - mse: 1.4299e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2339 - bpp: 0.6056 - mse: 1.5337e-04\n",
      "Epoch 625: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.2339 - bpp: 0.6056 - mse: 1.5337e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0809 - bpp: 0.5635 - mse: 1.2631e-04\n",
      "Epoch 626: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0809 - bpp: 0.5635 - mse: 1.2631e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3189 - bpp: 0.6330 - mse: 1.6746e-04\n",
      "Epoch 627: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3189 - bpp: 0.6330 - mse: 1.6746e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0414 - bpp: 0.5605 - mse: 1.1740e-04\n",
      "Epoch 628: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0414 - bpp: 0.5605 - mse: 1.1740e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1388 - bpp: 0.5855 - mse: 1.3509e-04\n",
      "Epoch 629: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1388 - bpp: 0.5855 - mse: 1.3509e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1820 - bpp: 0.5979 - mse: 1.4259e-04\n",
      "Epoch 630: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1820 - bpp: 0.5979 - mse: 1.4259e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2085 - bpp: 0.6037 - mse: 1.4768e-04\n",
      "Epoch 631: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2085 - bpp: 0.6037 - mse: 1.4768e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1454 - bpp: 0.5833 - mse: 1.3725e-04\n",
      "Epoch 632: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1454 - bpp: 0.5833 - mse: 1.3725e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1980 - bpp: 0.6128 - mse: 1.4286e-04\n",
      "Epoch 633: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1980 - bpp: 0.6128 - mse: 1.4286e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2372 - bpp: 0.6205 - mse: 1.5058e-04\n",
      "Epoch 634: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2372 - bpp: 0.6205 - mse: 1.5058e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2442 - bpp: 0.6101 - mse: 1.5482e-04\n",
      "Epoch 635: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2442 - bpp: 0.6101 - mse: 1.5482e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1673 - bpp: 0.5972 - mse: 1.3919e-04\n",
      "Epoch 636: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1673 - bpp: 0.5972 - mse: 1.3919e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2038 - bpp: 0.6019 - mse: 1.4693e-04\n",
      "Epoch 637: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2038 - bpp: 0.6019 - mse: 1.4693e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1484 - bpp: 0.5841 - mse: 1.3775e-04\n",
      "Epoch 638: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1484 - bpp: 0.5841 - mse: 1.3775e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1752 - bpp: 0.5954 - mse: 1.4154e-04\n",
      "Epoch 639: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1752 - bpp: 0.5954 - mse: 1.4154e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3404 - bpp: 0.6482 - mse: 1.6899e-04\n",
      "Epoch 640: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3404 - bpp: 0.6482 - mse: 1.6899e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2046 - bpp: 0.5972 - mse: 1.4829e-04\n",
      "Epoch 641: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2046 - bpp: 0.5972 - mse: 1.4829e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0892 - bpp: 0.5650 - mse: 1.2799e-04\n",
      "Epoch 642: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0892 - bpp: 0.5650 - mse: 1.2799e-04\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1612 - bpp: 0.5874 - mse: 1.4008e-04\n",
      "Epoch 643: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1612 - bpp: 0.5874 - mse: 1.4008e-04\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2337 - bpp: 0.6046 - mse: 1.5359e-04\n",
      "Epoch 644: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2337 - bpp: 0.6046 - mse: 1.5359e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2964 - bpp: 0.6314 - mse: 1.6236e-04\n",
      "Epoch 645: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2964 - bpp: 0.6314 - mse: 1.6236e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1599 - bpp: 0.5853 - mse: 1.4029e-04\n",
      "Epoch 646: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1599 - bpp: 0.5853 - mse: 1.4029e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1986 - bpp: 0.5847 - mse: 1.4988e-04\n",
      "Epoch 647: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1986 - bpp: 0.5847 - mse: 1.4988e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1322 - bpp: 0.5661 - mse: 1.3820e-04\n",
      "Epoch 648: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1322 - bpp: 0.5661 - mse: 1.3820e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3143 - bpp: 0.6249 - mse: 1.6831e-04\n",
      "Epoch 649: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3143 - bpp: 0.6249 - mse: 1.6831e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1140 - bpp: 0.5713 - mse: 1.3250e-04\n",
      "Epoch 650: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1140 - bpp: 0.5713 - mse: 1.3250e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2747 - bpp: 0.6162 - mse: 1.6077e-04\n",
      "Epoch 651: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2747 - bpp: 0.6162 - mse: 1.6077e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1850 - bpp: 0.6032 - mse: 1.4203e-04\n",
      "Epoch 652: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1850 - bpp: 0.6032 - mse: 1.4203e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1800 - bpp: 0.5927 - mse: 1.4338e-04\n",
      "Epoch 653: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1800 - bpp: 0.5927 - mse: 1.4338e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2014 - bpp: 0.6052 - mse: 1.4557e-04\n",
      "Epoch 654: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2014 - bpp: 0.6052 - mse: 1.4557e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2417 - bpp: 0.6123 - mse: 1.5367e-04\n",
      "Epoch 655: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2417 - bpp: 0.6123 - mse: 1.5367e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0989 - bpp: 0.5666 - mse: 1.2997e-04\n",
      "Epoch 656: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0989 - bpp: 0.5666 - mse: 1.2997e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1637 - bpp: 0.5867 - mse: 1.4088e-04\n",
      "Epoch 657: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1637 - bpp: 0.5867 - mse: 1.4088e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0803 - bpp: 0.5717 - mse: 1.2416e-04\n",
      "Epoch 658: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0803 - bpp: 0.5717 - mse: 1.2416e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2094 - bpp: 0.6003 - mse: 1.4872e-04\n",
      "Epoch 659: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2094 - bpp: 0.6003 - mse: 1.4872e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1176 - bpp: 0.5671 - mse: 1.3440e-04\n",
      "Epoch 660: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1176 - bpp: 0.5671 - mse: 1.3440e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1459 - bpp: 0.5857 - mse: 1.3677e-04\n",
      "Epoch 661: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1459 - bpp: 0.5857 - mse: 1.3677e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0689 - bpp: 0.5568 - mse: 1.2501e-04\n",
      "Epoch 662: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0689 - bpp: 0.5568 - mse: 1.2501e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1092 - bpp: 0.5739 - mse: 1.3067e-04\n",
      "Epoch 663: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1092 - bpp: 0.5739 - mse: 1.3067e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2279 - bpp: 0.5978 - mse: 1.5383e-04\n",
      "Epoch 664: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2279 - bpp: 0.5978 - mse: 1.5383e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1915 - bpp: 0.5882 - mse: 1.4728e-04\n",
      "Epoch 665: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1915 - bpp: 0.5882 - mse: 1.4728e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0554 - bpp: 0.5498 - mse: 1.2343e-04\n",
      "Epoch 666: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0554 - bpp: 0.5498 - mse: 1.2343e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1763 - bpp: 0.5977 - mse: 1.4128e-04\n",
      "Epoch 667: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1763 - bpp: 0.5977 - mse: 1.4128e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1768 - bpp: 0.5889 - mse: 1.4353e-04\n",
      "Epoch 668: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1768 - bpp: 0.5889 - mse: 1.4353e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3337 - bpp: 0.6337 - mse: 1.7090e-04\n",
      "Epoch 669: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3337 - bpp: 0.6337 - mse: 1.7090e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1644 - bpp: 0.5848 - mse: 1.4150e-04\n",
      "Epoch 670: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1644 - bpp: 0.5848 - mse: 1.4150e-04\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1718 - bpp: 0.5859 - mse: 1.4306e-04\n",
      "Epoch 671: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1718 - bpp: 0.5859 - mse: 1.4306e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1107 - bpp: 0.5819 - mse: 1.2911e-04\n",
      "Epoch 672: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 1.1107 - bpp: 0.5819 - mse: 1.2911e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1051 - bpp: 0.5752 - mse: 1.2938e-04\n",
      "Epoch 673: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.1051 - bpp: 0.5752 - mse: 1.2938e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1133 - bpp: 0.5728 - mse: 1.3196e-04\n",
      "Epoch 674: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1133 - bpp: 0.5728 - mse: 1.3196e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2790 - bpp: 0.6206 - mse: 1.6073e-04\n",
      "Epoch 675: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 205ms/step - loss: 1.2790 - bpp: 0.6206 - mse: 1.6073e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0644 - bpp: 0.5587 - mse: 1.2346e-04\n",
      "Epoch 676: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0644 - bpp: 0.5587 - mse: 1.2346e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1936 - bpp: 0.5879 - mse: 1.4787e-04\n",
      "Epoch 677: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1936 - bpp: 0.5879 - mse: 1.4787e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0630 - bpp: 0.5592 - mse: 1.2301e-04\n",
      "Epoch 678: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0630 - bpp: 0.5592 - mse: 1.2301e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1297 - bpp: 0.5707 - mse: 1.3647e-04\n",
      "Epoch 679: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1297 - bpp: 0.5707 - mse: 1.3647e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1548 - bpp: 0.5820 - mse: 1.3983e-04\n",
      "Epoch 680: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1548 - bpp: 0.5820 - mse: 1.3983e-04\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2793 - bpp: 0.6031 - mse: 1.6510e-04\n",
      "Epoch 681: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.2793 - bpp: 0.6031 - mse: 1.6510e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2157 - bpp: 0.6106 - mse: 1.4772e-04\n",
      "Epoch 682: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.2157 - bpp: 0.6106 - mse: 1.4772e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.5537 - mse: 1.2666e-04\n",
      "Epoch 683: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0725 - bpp: 0.5537 - mse: 1.2666e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2486 - bpp: 0.6137 - mse: 1.5499e-04\n",
      "Epoch 684: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.2486 - bpp: 0.6137 - mse: 1.5499e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1259 - bpp: 0.5833 - mse: 1.3249e-04\n",
      "Epoch 685: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1259 - bpp: 0.5833 - mse: 1.3249e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1464 - bpp: 0.5821 - mse: 1.3776e-04\n",
      "Epoch 686: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1464 - bpp: 0.5821 - mse: 1.3776e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1776 - bpp: 0.5883 - mse: 1.4387e-04\n",
      "Epoch 687: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 204ms/step - loss: 1.1776 - bpp: 0.5883 - mse: 1.4387e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2244 - bpp: 0.6155 - mse: 1.4867e-04\n",
      "Epoch 688: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2244 - bpp: 0.6155 - mse: 1.4867e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1513 - bpp: 0.5839 - mse: 1.3853e-04\n",
      "Epoch 689: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1513 - bpp: 0.5839 - mse: 1.3853e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1822 - bpp: 0.6002 - mse: 1.4209e-04\n",
      "Epoch 690: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1822 - bpp: 0.6002 - mse: 1.4209e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2099 - bpp: 0.5940 - mse: 1.5037e-04\n",
      "Epoch 691: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.2099 - bpp: 0.5940 - mse: 1.5037e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1623 - bpp: 0.5918 - mse: 1.3930e-04\n",
      "Epoch 692: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1623 - bpp: 0.5918 - mse: 1.3930e-04\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2167 - bpp: 0.6004 - mse: 1.5046e-04\n",
      "Epoch 693: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.2167 - bpp: 0.6004 - mse: 1.5046e-04\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1824 - bpp: 0.5965 - mse: 1.4304e-04\n",
      "Epoch 694: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1824 - bpp: 0.5965 - mse: 1.4304e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1357 - bpp: 0.5757 - mse: 1.3672e-04\n",
      "Epoch 695: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1357 - bpp: 0.5757 - mse: 1.3672e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2198 - bpp: 0.6081 - mse: 1.4935e-04\n",
      "Epoch 696: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2198 - bpp: 0.6081 - mse: 1.4935e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1258 - bpp: 0.5799 - mse: 1.3330e-04\n",
      "Epoch 697: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1258 - bpp: 0.5799 - mse: 1.3330e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1605 - bpp: 0.5872 - mse: 1.3995e-04\n",
      "Epoch 698: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.1605 - bpp: 0.5872 - mse: 1.3995e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1639 - bpp: 0.5967 - mse: 1.3847e-04\n",
      "Epoch 699: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1639 - bpp: 0.5967 - mse: 1.3847e-04\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1443 - bpp: 0.5784 - mse: 1.3816e-04\n",
      "Epoch 700: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1443 - bpp: 0.5784 - mse: 1.3816e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0896 - bpp: 0.5697 - mse: 1.2691e-04\n",
      "Epoch 701: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0896 - bpp: 0.5697 - mse: 1.2691e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1481 - bpp: 0.5897 - mse: 1.3633e-04\n",
      "Epoch 702: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1481 - bpp: 0.5897 - mse: 1.3633e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1032 - bpp: 0.5624 - mse: 1.3201e-04\n",
      "Epoch 703: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.1032 - bpp: 0.5624 - mse: 1.3201e-04\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0818 - bpp: 0.5611 - mse: 1.2711e-04\n",
      "Epoch 704: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0818 - bpp: 0.5611 - mse: 1.2711e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2515 - bpp: 0.6173 - mse: 1.5484e-04\n",
      "Epoch 705: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2515 - bpp: 0.6173 - mse: 1.5484e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2216 - bpp: 0.6141 - mse: 1.4831e-04\n",
      "Epoch 706: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2216 - bpp: 0.6141 - mse: 1.4831e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1263 - bpp: 0.5857 - mse: 1.3198e-04\n",
      "Epoch 707: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1263 - bpp: 0.5857 - mse: 1.3198e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2009 - bpp: 0.6005 - mse: 1.4656e-04\n",
      "Epoch 708: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2009 - bpp: 0.6005 - mse: 1.4656e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2063 - bpp: 0.5877 - mse: 1.5103e-04\n",
      "Epoch 709: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2063 - bpp: 0.5877 - mse: 1.5103e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0760 - bpp: 0.5622 - mse: 1.2544e-04\n",
      "Epoch 710: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0760 - bpp: 0.5622 - mse: 1.2544e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0644 - bpp: 0.5617 - mse: 1.2274e-04\n",
      "Epoch 711: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0644 - bpp: 0.5617 - mse: 1.2274e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1919 - bpp: 0.5982 - mse: 1.4495e-04\n",
      "Epoch 712: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1919 - bpp: 0.5982 - mse: 1.4495e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1618 - bpp: 0.5887 - mse: 1.3993e-04\n",
      "Epoch 713: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1618 - bpp: 0.5887 - mse: 1.3993e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0627 - bpp: 0.5572 - mse: 1.2341e-04\n",
      "Epoch 714: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0627 - bpp: 0.5572 - mse: 1.2341e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1139 - bpp: 0.5634 - mse: 1.3441e-04\n",
      "Epoch 715: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1139 - bpp: 0.5634 - mse: 1.3441e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0848 - bpp: 0.5677 - mse: 1.2624e-04\n",
      "Epoch 716: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0848 - bpp: 0.5677 - mse: 1.2624e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1505 - bpp: 0.5785 - mse: 1.3964e-04\n",
      "Epoch 717: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1505 - bpp: 0.5785 - mse: 1.3964e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1470 - bpp: 0.5741 - mse: 1.3985e-04\n",
      "Epoch 718: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1470 - bpp: 0.5741 - mse: 1.3985e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2009 - bpp: 0.5953 - mse: 1.4783e-04\n",
      "Epoch 719: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2009 - bpp: 0.5953 - mse: 1.4783e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1302 - bpp: 0.5856 - mse: 1.3296e-04\n",
      "Epoch 720: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1302 - bpp: 0.5856 - mse: 1.3296e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1710 - bpp: 0.5914 - mse: 1.4151e-04\n",
      "Epoch 721: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1710 - bpp: 0.5914 - mse: 1.4151e-04\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1789 - bpp: 0.5908 - mse: 1.4359e-04\n",
      "Epoch 722: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1789 - bpp: 0.5908 - mse: 1.4359e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1306 - bpp: 0.5836 - mse: 1.3352e-04\n",
      "Epoch 723: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1306 - bpp: 0.5836 - mse: 1.3352e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2070 - bpp: 0.5983 - mse: 1.4861e-04\n",
      "Epoch 724: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2070 - bpp: 0.5983 - mse: 1.4861e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1970 - bpp: 0.6005 - mse: 1.4565e-04\n",
      "Epoch 725: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.1970 - bpp: 0.6005 - mse: 1.4565e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1533 - bpp: 0.5762 - mse: 1.4090e-04\n",
      "Epoch 726: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1533 - bpp: 0.5762 - mse: 1.4090e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1879 - bpp: 0.5748 - mse: 1.4967e-04\n",
      "Epoch 727: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1879 - bpp: 0.5748 - mse: 1.4967e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1933 - bpp: 0.5945 - mse: 1.4618e-04\n",
      "Epoch 728: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 1.1933 - bpp: 0.5945 - mse: 1.4618e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0884 - bpp: 0.5616 - mse: 1.2863e-04\n",
      "Epoch 729: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0884 - bpp: 0.5616 - mse: 1.2863e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1582 - bpp: 0.5864 - mse: 1.3961e-04\n",
      "Epoch 730: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 1.1582 - bpp: 0.5864 - mse: 1.3961e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1154 - bpp: 0.5689 - mse: 1.3341e-04\n",
      "Epoch 731: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1154 - bpp: 0.5689 - mse: 1.3341e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2420 - bpp: 0.6089 - mse: 1.5458e-04\n",
      "Epoch 732: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2420 - bpp: 0.6089 - mse: 1.5458e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2829 - bpp: 0.6259 - mse: 1.6040e-04\n",
      "Epoch 733: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.2829 - bpp: 0.6259 - mse: 1.6040e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1104 - bpp: 0.5698 - mse: 1.3197e-04\n",
      "Epoch 734: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1104 - bpp: 0.5698 - mse: 1.3197e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2490 - bpp: 0.6083 - mse: 1.5643e-04\n",
      "Epoch 735: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2490 - bpp: 0.6083 - mse: 1.5643e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1566 - bpp: 0.5927 - mse: 1.3768e-04\n",
      "Epoch 736: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1566 - bpp: 0.5927 - mse: 1.3768e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1468 - bpp: 0.5760 - mse: 1.3937e-04\n",
      "Epoch 737: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1468 - bpp: 0.5760 - mse: 1.3937e-04\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1225 - bpp: 0.5686 - mse: 1.3523e-04\n",
      "Epoch 738: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1225 - bpp: 0.5686 - mse: 1.3523e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1674 - bpp: 0.5860 - mse: 1.4195e-04\n",
      "Epoch 739: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1674 - bpp: 0.5860 - mse: 1.4195e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0353 - bpp: 0.5493 - mse: 1.1867e-04\n",
      "Epoch 740: loss improved from 1.03774 to 1.03535, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0353 - bpp: 0.5493 - mse: 1.1867e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1813 - bpp: 0.5917 - mse: 1.4394e-04\n",
      "Epoch 741: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1813 - bpp: 0.5917 - mse: 1.4394e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1750 - bpp: 0.5926 - mse: 1.4218e-04\n",
      "Epoch 742: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1750 - bpp: 0.5926 - mse: 1.4218e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1987 - bpp: 0.5885 - mse: 1.4898e-04\n",
      "Epoch 743: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1987 - bpp: 0.5885 - mse: 1.4898e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1503 - bpp: 0.5877 - mse: 1.3737e-04\n",
      "Epoch 744: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1503 - bpp: 0.5877 - mse: 1.3737e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1267 - bpp: 0.5718 - mse: 1.3546e-04\n",
      "Epoch 745: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1267 - bpp: 0.5718 - mse: 1.3546e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2029 - bpp: 0.6087 - mse: 1.4507e-04\n",
      "Epoch 746: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2029 - bpp: 0.6087 - mse: 1.4507e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1286 - bpp: 0.5740 - mse: 1.3538e-04\n",
      "Epoch 747: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1286 - bpp: 0.5740 - mse: 1.3538e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1387 - bpp: 0.5755 - mse: 1.3750e-04\n",
      "Epoch 748: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1387 - bpp: 0.5755 - mse: 1.3750e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1926 - bpp: 0.5924 - mse: 1.4652e-04\n",
      "Epoch 749: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1926 - bpp: 0.5924 - mse: 1.4652e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1947 - bpp: 0.5841 - mse: 1.4907e-04\n",
      "Epoch 750: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1947 - bpp: 0.5841 - mse: 1.4907e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1103 - bpp: 0.5717 - mse: 1.3150e-04\n",
      "Epoch 751: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1103 - bpp: 0.5717 - mse: 1.3150e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2344 - bpp: 0.6010 - mse: 1.5464e-04\n",
      "Epoch 752: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2344 - bpp: 0.6010 - mse: 1.5464e-04\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1373 - bpp: 0.5747 - mse: 1.3736e-04\n",
      "Epoch 753: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1373 - bpp: 0.5747 - mse: 1.3736e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0878 - bpp: 0.5650 - mse: 1.2763e-04\n",
      "Epoch 754: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0878 - bpp: 0.5650 - mse: 1.2763e-04\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1185 - bpp: 0.5699 - mse: 1.3393e-04\n",
      "Epoch 755: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.1185 - bpp: 0.5699 - mse: 1.3393e-04\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1122 - bpp: 0.5634 - mse: 1.3398e-04\n",
      "Epoch 756: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1122 - bpp: 0.5634 - mse: 1.3398e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1194 - bpp: 0.5649 - mse: 1.3539e-04\n",
      "Epoch 757: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.1194 - bpp: 0.5649 - mse: 1.3539e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1322 - bpp: 0.5780 - mse: 1.3531e-04\n",
      "Epoch 758: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1322 - bpp: 0.5780 - mse: 1.3531e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1984 - bpp: 0.5930 - mse: 1.4780e-04\n",
      "Epoch 759: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1984 - bpp: 0.5930 - mse: 1.4780e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1596 - bpp: 0.5845 - mse: 1.4042e-04\n",
      "Epoch 760: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1596 - bpp: 0.5845 - mse: 1.4042e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2218 - bpp: 0.6005 - mse: 1.5168e-04\n",
      "Epoch 761: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2218 - bpp: 0.6005 - mse: 1.5168e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0902 - bpp: 0.5605 - mse: 1.2932e-04\n",
      "Epoch 762: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0902 - bpp: 0.5605 - mse: 1.2932e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1777 - bpp: 0.5818 - mse: 1.4547e-04\n",
      "Epoch 763: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1777 - bpp: 0.5818 - mse: 1.4547e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2215 - bpp: 0.5995 - mse: 1.5187e-04\n",
      "Epoch 764: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2215 - bpp: 0.5995 - mse: 1.5187e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1115 - bpp: 0.5687 - mse: 1.3252e-04\n",
      "Epoch 765: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1115 - bpp: 0.5687 - mse: 1.3252e-04\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2005 - bpp: 0.5907 - mse: 1.4887e-04\n",
      "Epoch 766: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2005 - bpp: 0.5907 - mse: 1.4887e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0718 - bpp: 0.5585 - mse: 1.2531e-04\n",
      "Epoch 767: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0718 - bpp: 0.5585 - mse: 1.2531e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0685 - bpp: 0.5641 - mse: 1.2315e-04\n",
      "Epoch 768: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0685 - bpp: 0.5641 - mse: 1.2315e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1742 - bpp: 0.5941 - mse: 1.4161e-04\n",
      "Epoch 769: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1742 - bpp: 0.5941 - mse: 1.4161e-04\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1260 - bpp: 0.5724 - mse: 1.3515e-04\n",
      "Epoch 770: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1260 - bpp: 0.5724 - mse: 1.3515e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0976 - bpp: 0.5650 - mse: 1.3001e-04\n",
      "Epoch 771: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0976 - bpp: 0.5650 - mse: 1.3001e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.5974 - mse: 1.4630e-04\n",
      "Epoch 772: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1967 - bpp: 0.5974 - mse: 1.4630e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0660 - bpp: 0.5520 - mse: 1.2549e-04\n",
      "Epoch 773: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0660 - bpp: 0.5520 - mse: 1.2549e-04\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0500 - bpp: 0.5505 - mse: 1.2195e-04\n",
      "Epoch 774: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 210ms/step - loss: 1.0500 - bpp: 0.5505 - mse: 1.2195e-04\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1510 - bpp: 0.5814 - mse: 1.3905e-04\n",
      "Epoch 775: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1510 - bpp: 0.5814 - mse: 1.3905e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1209 - bpp: 0.5837 - mse: 1.3116e-04\n",
      "Epoch 776: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.1209 - bpp: 0.5837 - mse: 1.3116e-04\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1743 - bpp: 0.5924 - mse: 1.4206e-04\n",
      "Epoch 777: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1743 - bpp: 0.5924 - mse: 1.4206e-04\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1872 - bpp: 0.5862 - mse: 1.4672e-04\n",
      "Epoch 778: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1872 - bpp: 0.5862 - mse: 1.4672e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2393 - bpp: 0.6029 - mse: 1.5536e-04\n",
      "Epoch 779: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.2393 - bpp: 0.6029 - mse: 1.5536e-04\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0479 - bpp: 0.5518 - mse: 1.2111e-04\n",
      "Epoch 780: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0479 - bpp: 0.5518 - mse: 1.2111e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1560 - bpp: 0.5779 - mse: 1.4114e-04\n",
      "Epoch 781: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1560 - bpp: 0.5779 - mse: 1.4114e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1151 - bpp: 0.5718 - mse: 1.3265e-04\n",
      "Epoch 782: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1151 - bpp: 0.5718 - mse: 1.3265e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1350 - bpp: 0.5803 - mse: 1.3542e-04\n",
      "Epoch 783: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1350 - bpp: 0.5803 - mse: 1.3542e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1064 - bpp: 0.5824 - mse: 1.2791e-04\n",
      "Epoch 784: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1064 - bpp: 0.5824 - mse: 1.2791e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0719 - bpp: 0.5551 - mse: 1.2616e-04\n",
      "Epoch 785: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0719 - bpp: 0.5551 - mse: 1.2616e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.5778 - mse: 1.5001e-04\n",
      "Epoch 786: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1922 - bpp: 0.5778 - mse: 1.5001e-04\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2730 - bpp: 0.6090 - mse: 1.6209e-04\n",
      "Epoch 787: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2730 - bpp: 0.6090 - mse: 1.6209e-04\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5536 - mse: 1.2347e-04\n",
      "Epoch 788: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0594 - bpp: 0.5536 - mse: 1.2347e-04\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1416 - bpp: 0.5832 - mse: 1.3631e-04\n",
      "Epoch 789: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1416 - bpp: 0.5832 - mse: 1.3631e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0812 - bpp: 0.5565 - mse: 1.2809e-04\n",
      "Epoch 790: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0812 - bpp: 0.5565 - mse: 1.2809e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1253 - bpp: 0.5676 - mse: 1.3615e-04\n",
      "Epoch 791: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1253 - bpp: 0.5676 - mse: 1.3615e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1866 - bpp: 0.5904 - mse: 1.4558e-04\n",
      "Epoch 792: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1866 - bpp: 0.5904 - mse: 1.4558e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1736 - bpp: 0.5948 - mse: 1.4131e-04\n",
      "Epoch 793: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1736 - bpp: 0.5948 - mse: 1.4131e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1353 - bpp: 0.5785 - mse: 1.3595e-04\n",
      "Epoch 794: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1353 - bpp: 0.5785 - mse: 1.3595e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2884 - bpp: 0.6132 - mse: 1.6486e-04\n",
      "Epoch 795: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.2884 - bpp: 0.6132 - mse: 1.6486e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1156 - bpp: 0.5658 - mse: 1.3422e-04\n",
      "Epoch 796: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1156 - bpp: 0.5658 - mse: 1.3422e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1536 - bpp: 0.5838 - mse: 1.3910e-04\n",
      "Epoch 797: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1536 - bpp: 0.5838 - mse: 1.3910e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1189 - bpp: 0.5709 - mse: 1.3379e-04\n",
      "Epoch 798: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1189 - bpp: 0.5709 - mse: 1.3379e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1054 - bpp: 0.5711 - mse: 1.3044e-04\n",
      "Epoch 799: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1054 - bpp: 0.5711 - mse: 1.3044e-04\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0639 - bpp: 0.5568 - mse: 1.2382e-04\n",
      "Epoch 800: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0639 - bpp: 0.5568 - mse: 1.2382e-04\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1797 - bpp: 0.5936 - mse: 1.4311e-04\n",
      "Epoch 801: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1797 - bpp: 0.5936 - mse: 1.4311e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1523 - bpp: 0.5821 - mse: 1.3920e-04\n",
      "Epoch 802: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.1523 - bpp: 0.5821 - mse: 1.3920e-04\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.5620 - mse: 1.2698e-04\n",
      "Epoch 803: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0821 - bpp: 0.5620 - mse: 1.2698e-04\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1065 - bpp: 0.5659 - mse: 1.3197e-04\n",
      "Epoch 804: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1065 - bpp: 0.5659 - mse: 1.3197e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1852 - bpp: 0.5925 - mse: 1.4471e-04\n",
      "Epoch 805: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1852 - bpp: 0.5925 - mse: 1.4471e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1420 - bpp: 0.5841 - mse: 1.3621e-04\n",
      "Epoch 806: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1420 - bpp: 0.5841 - mse: 1.3621e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2272 - bpp: 0.6117 - mse: 1.5025e-04\n",
      "Epoch 807: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.2272 - bpp: 0.6117 - mse: 1.5025e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1443 - bpp: 0.5740 - mse: 1.3923e-04\n",
      "Epoch 808: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1443 - bpp: 0.5740 - mse: 1.3923e-04\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1876 - bpp: 0.5925 - mse: 1.4529e-04\n",
      "Epoch 809: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 1.1876 - bpp: 0.5925 - mse: 1.4529e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1441 - bpp: 0.5855 - mse: 1.3638e-04\n",
      "Epoch 810: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1441 - bpp: 0.5855 - mse: 1.3638e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2483 - bpp: 0.6204 - mse: 1.5331e-04\n",
      "Epoch 811: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.2483 - bpp: 0.6204 - mse: 1.5331e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1908 - bpp: 0.6005 - mse: 1.4412e-04\n",
      "Epoch 812: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1908 - bpp: 0.6005 - mse: 1.4412e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1427 - bpp: 0.5815 - mse: 1.3701e-04\n",
      "Epoch 813: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1427 - bpp: 0.5815 - mse: 1.3701e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0492 - bpp: 0.5550 - mse: 1.2065e-04\n",
      "Epoch 814: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0492 - bpp: 0.5550 - mse: 1.2065e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1565 - bpp: 0.5748 - mse: 1.4199e-04\n",
      "Epoch 815: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1565 - bpp: 0.5748 - mse: 1.4199e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1964 - bpp: 0.6079 - mse: 1.4368e-04\n",
      "Epoch 816: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1964 - bpp: 0.6079 - mse: 1.4368e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1690 - bpp: 0.5878 - mse: 1.4189e-04\n",
      "Epoch 817: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1690 - bpp: 0.5878 - mse: 1.4189e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1303 - bpp: 0.5701 - mse: 1.3676e-04\n",
      "Epoch 818: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1303 - bpp: 0.5701 - mse: 1.3676e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0832 - bpp: 0.5645 - mse: 1.2663e-04\n",
      "Epoch 819: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.0832 - bpp: 0.5645 - mse: 1.2663e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1376 - bpp: 0.5808 - mse: 1.3594e-04\n",
      "Epoch 820: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1376 - bpp: 0.5808 - mse: 1.3594e-04\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0429 - bpp: 0.5520 - mse: 1.1984e-04\n",
      "Epoch 821: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0429 - bpp: 0.5520 - mse: 1.1984e-04\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1941 - bpp: 0.5722 - mse: 1.5183e-04\n",
      "Epoch 822: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1941 - bpp: 0.5722 - mse: 1.5183e-04\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0922 - bpp: 0.5706 - mse: 1.2735e-04\n",
      "Epoch 823: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0922 - bpp: 0.5706 - mse: 1.2735e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1866 - bpp: 0.5952 - mse: 1.4437e-04\n",
      "Epoch 824: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.1866 - bpp: 0.5952 - mse: 1.4437e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0406 - bpp: 0.5331 - mse: 1.2389e-04\n",
      "Epoch 825: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0406 - bpp: 0.5331 - mse: 1.2389e-04\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1576 - bpp: 0.5878 - mse: 1.3911e-04\n",
      "Epoch 826: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1576 - bpp: 0.5878 - mse: 1.3911e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2366 - bpp: 0.5989 - mse: 1.5568e-04\n",
      "Epoch 827: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2366 - bpp: 0.5989 - mse: 1.5568e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1371 - bpp: 0.5802 - mse: 1.3596e-04\n",
      "Epoch 828: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1371 - bpp: 0.5802 - mse: 1.3596e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0587 - bpp: 0.5541 - mse: 1.2320e-04\n",
      "Epoch 829: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0587 - bpp: 0.5541 - mse: 1.2320e-04\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0694 - bpp: 0.5553 - mse: 1.2551e-04\n",
      "Epoch 830: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0694 - bpp: 0.5553 - mse: 1.2551e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0335 - bpp: 0.5472 - mse: 1.1872e-04\n",
      "Epoch 831: loss improved from 1.03535 to 1.03346, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0335 - bpp: 0.5472 - mse: 1.1872e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0272 - bpp: 0.5419 - mse: 1.1848e-04\n",
      "Epoch 832: loss improved from 1.03346 to 1.02722, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0272 - bpp: 0.5419 - mse: 1.1848e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1198 - bpp: 0.5729 - mse: 1.3352e-04\n",
      "Epoch 833: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1198 - bpp: 0.5729 - mse: 1.3352e-04\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1430 - bpp: 0.5871 - mse: 1.3573e-04\n",
      "Epoch 834: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1430 - bpp: 0.5871 - mse: 1.3573e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1977 - bpp: 0.5975 - mse: 1.4655e-04\n",
      "Epoch 835: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1977 - bpp: 0.5975 - mse: 1.4655e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1539 - bpp: 0.5874 - mse: 1.3831e-04\n",
      "Epoch 836: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.1539 - bpp: 0.5874 - mse: 1.3831e-04\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1834 - bpp: 0.5881 - mse: 1.4532e-04\n",
      "Epoch 837: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1834 - bpp: 0.5881 - mse: 1.4532e-04\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1586 - bpp: 0.5787 - mse: 1.4156e-04\n",
      "Epoch 838: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1586 - bpp: 0.5787 - mse: 1.4156e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1152 - bpp: 0.5605 - mse: 1.3543e-04\n",
      "Epoch 839: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1152 - bpp: 0.5605 - mse: 1.3543e-04\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1039 - bpp: 0.5709 - mse: 1.3012e-04\n",
      "Epoch 840: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1039 - bpp: 0.5709 - mse: 1.3012e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1080 - bpp: 0.5683 - mse: 1.3175e-04\n",
      "Epoch 841: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1080 - bpp: 0.5683 - mse: 1.3175e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1609 - bpp: 0.5797 - mse: 1.4190e-04\n",
      "Epoch 842: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1609 - bpp: 0.5797 - mse: 1.4190e-04\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1401 - bpp: 0.5750 - mse: 1.3795e-04\n",
      "Epoch 843: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.1401 - bpp: 0.5750 - mse: 1.3795e-04\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1230 - bpp: 0.5699 - mse: 1.3503e-04\n",
      "Epoch 844: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1230 - bpp: 0.5699 - mse: 1.3503e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1110 - bpp: 0.5691 - mse: 1.3230e-04\n",
      "Epoch 845: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1110 - bpp: 0.5691 - mse: 1.3230e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1361 - bpp: 0.5793 - mse: 1.3592e-04\n",
      "Epoch 846: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1361 - bpp: 0.5793 - mse: 1.3592e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1544 - bpp: 0.5775 - mse: 1.4085e-04\n",
      "Epoch 847: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1544 - bpp: 0.5775 - mse: 1.4085e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1203 - bpp: 0.5719 - mse: 1.3390e-04\n",
      "Epoch 848: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1203 - bpp: 0.5719 - mse: 1.3390e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0508 - bpp: 0.5393 - mse: 1.2486e-04\n",
      "Epoch 849: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0508 - bpp: 0.5393 - mse: 1.2486e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1625 - bpp: 0.5805 - mse: 1.4208e-04\n",
      "Epoch 850: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1625 - bpp: 0.5805 - mse: 1.4208e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0560 - bpp: 0.5512 - mse: 1.2324e-04\n",
      "Epoch 851: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0560 - bpp: 0.5512 - mse: 1.2324e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1385 - bpp: 0.5881 - mse: 1.3438e-04\n",
      "Epoch 852: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1385 - bpp: 0.5881 - mse: 1.3438e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1920 - bpp: 0.5880 - mse: 1.4746e-04\n",
      "Epoch 853: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1920 - bpp: 0.5880 - mse: 1.4746e-04\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1040 - bpp: 0.5639 - mse: 1.3187e-04\n",
      "Epoch 854: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1040 - bpp: 0.5639 - mse: 1.3187e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0771 - bpp: 0.5671 - mse: 1.2450e-04\n",
      "Epoch 855: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0771 - bpp: 0.5671 - mse: 1.2450e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2091 - bpp: 0.6034 - mse: 1.4786e-04\n",
      "Epoch 856: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2091 - bpp: 0.6034 - mse: 1.4786e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1880 - bpp: 0.5851 - mse: 1.4720e-04\n",
      "Epoch 857: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1880 - bpp: 0.5851 - mse: 1.4720e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1364 - bpp: 0.5770 - mse: 1.3657e-04\n",
      "Epoch 858: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1364 - bpp: 0.5770 - mse: 1.3657e-04\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1113 - bpp: 0.5665 - mse: 1.3301e-04\n",
      "Epoch 859: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1113 - bpp: 0.5665 - mse: 1.3301e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2661 - bpp: 0.6174 - mse: 1.5837e-04\n",
      "Epoch 860: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2661 - bpp: 0.6174 - mse: 1.5837e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1159 - bpp: 0.5628 - mse: 1.3505e-04\n",
      "Epoch 861: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1159 - bpp: 0.5628 - mse: 1.3505e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1366 - bpp: 0.5769 - mse: 1.3664e-04\n",
      "Epoch 862: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1366 - bpp: 0.5769 - mse: 1.3664e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1637 - bpp: 0.5922 - mse: 1.3952e-04\n",
      "Epoch 863: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1637 - bpp: 0.5922 - mse: 1.3952e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0754 - bpp: 0.5622 - mse: 1.2529e-04\n",
      "Epoch 864: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0754 - bpp: 0.5622 - mse: 1.2529e-04\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0651 - bpp: 0.5540 - mse: 1.2478e-04\n",
      "Epoch 865: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0651 - bpp: 0.5540 - mse: 1.2478e-04\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1614 - bpp: 0.5847 - mse: 1.4079e-04\n",
      "Epoch 866: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1614 - bpp: 0.5847 - mse: 1.4079e-04\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0982 - bpp: 0.5755 - mse: 1.2760e-04\n",
      "Epoch 867: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0982 - bpp: 0.5755 - mse: 1.2760e-04\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1307 - bpp: 0.5775 - mse: 1.3504e-04\n",
      "Epoch 868: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1307 - bpp: 0.5775 - mse: 1.3504e-04\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.5611 - mse: 1.2860e-04\n",
      "Epoch 869: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0879 - bpp: 0.5611 - mse: 1.2860e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1672 - bpp: 0.5794 - mse: 1.4351e-04\n",
      "Epoch 870: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1672 - bpp: 0.5794 - mse: 1.4351e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1357 - bpp: 0.5764 - mse: 1.3653e-04\n",
      "Epoch 871: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 1.1357 - bpp: 0.5764 - mse: 1.3653e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0810 - bpp: 0.5548 - mse: 1.2847e-04\n",
      "Epoch 872: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0810 - bpp: 0.5548 - mse: 1.2847e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1962 - bpp: 0.5924 - mse: 1.4740e-04\n",
      "Epoch 873: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1962 - bpp: 0.5924 - mse: 1.4740e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0613 - bpp: 0.5547 - mse: 1.2367e-04\n",
      "Epoch 874: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0613 - bpp: 0.5547 - mse: 1.2367e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1679 - bpp: 0.5937 - mse: 1.4016e-04\n",
      "Epoch 875: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1679 - bpp: 0.5937 - mse: 1.4016e-04\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5604 - mse: 1.2806e-04\n",
      "Epoch 876: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0850 - bpp: 0.5604 - mse: 1.2806e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2465 - bpp: 0.6047 - mse: 1.5669e-04\n",
      "Epoch 877: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2465 - bpp: 0.6047 - mse: 1.5669e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1149 - bpp: 0.5653 - mse: 1.3419e-04\n",
      "Epoch 878: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1149 - bpp: 0.5653 - mse: 1.3419e-04\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0843 - bpp: 0.5599 - mse: 1.2802e-04\n",
      "Epoch 879: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0843 - bpp: 0.5599 - mse: 1.2802e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1685 - bpp: 0.5850 - mse: 1.4245e-04\n",
      "Epoch 880: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1685 - bpp: 0.5850 - mse: 1.4245e-04\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0522 - bpp: 0.5532 - mse: 1.2181e-04\n",
      "Epoch 881: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0522 - bpp: 0.5532 - mse: 1.2181e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1196 - bpp: 0.5580 - mse: 1.3711e-04\n",
      "Epoch 882: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1196 - bpp: 0.5580 - mse: 1.3711e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1562 - bpp: 0.5864 - mse: 1.3911e-04\n",
      "Epoch 883: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1562 - bpp: 0.5864 - mse: 1.3911e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2418 - bpp: 0.5988 - mse: 1.5699e-04\n",
      "Epoch 884: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2418 - bpp: 0.5988 - mse: 1.5699e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1251 - bpp: 0.5726 - mse: 1.3487e-04\n",
      "Epoch 885: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1251 - bpp: 0.5726 - mse: 1.3487e-04\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1313 - bpp: 0.5846 - mse: 1.3346e-04\n",
      "Epoch 886: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1313 - bpp: 0.5846 - mse: 1.3346e-04\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0503 - bpp: 0.5548 - mse: 1.2097e-04\n",
      "Epoch 887: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0503 - bpp: 0.5548 - mse: 1.2097e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1483 - bpp: 0.5746 - mse: 1.4007e-04\n",
      "Epoch 888: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.1483 - bpp: 0.5746 - mse: 1.4007e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1059 - bpp: 0.5576 - mse: 1.3386e-04\n",
      "Epoch 889: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1059 - bpp: 0.5576 - mse: 1.3386e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1612 - bpp: 0.5989 - mse: 1.3727e-04\n",
      "Epoch 890: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 1.1612 - bpp: 0.5989 - mse: 1.3727e-04\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0398 - bpp: 0.5397 - mse: 1.2210e-04\n",
      "Epoch 891: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0398 - bpp: 0.5397 - mse: 1.2210e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0715 - bpp: 0.5661 - mse: 1.2338e-04\n",
      "Epoch 892: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0715 - bpp: 0.5661 - mse: 1.2338e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1422 - bpp: 0.5799 - mse: 1.3728e-04\n",
      "Epoch 893: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.1422 - bpp: 0.5799 - mse: 1.3728e-04\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0831 - bpp: 0.5614 - mse: 1.2737e-04\n",
      "Epoch 894: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.0831 - bpp: 0.5614 - mse: 1.2737e-04\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1321 - bpp: 0.5837 - mse: 1.3389e-04\n",
      "Epoch 895: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1321 - bpp: 0.5837 - mse: 1.3389e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5636 - mse: 1.3551e-04\n",
      "Epoch 896: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1186 - bpp: 0.5636 - mse: 1.3551e-04\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0668 - bpp: 0.5552 - mse: 1.2491e-04\n",
      "Epoch 897: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0668 - bpp: 0.5552 - mse: 1.2491e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0890 - bpp: 0.5612 - mse: 1.2884e-04\n",
      "Epoch 898: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0890 - bpp: 0.5612 - mse: 1.2884e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0786 - bpp: 0.5628 - mse: 1.2591e-04\n",
      "Epoch 899: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0786 - bpp: 0.5628 - mse: 1.2591e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1098 - bpp: 0.5729 - mse: 1.3109e-04\n",
      "Epoch 900: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1098 - bpp: 0.5729 - mse: 1.3109e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1593 - bpp: 0.5850 - mse: 1.4021e-04\n",
      "Epoch 901: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1593 - bpp: 0.5850 - mse: 1.4021e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2019 - bpp: 0.6028 - mse: 1.4626e-04\n",
      "Epoch 902: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2019 - bpp: 0.6028 - mse: 1.4626e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0363 - bpp: 0.5454 - mse: 1.1986e-04\n",
      "Epoch 903: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0363 - bpp: 0.5454 - mse: 1.1986e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1453 - bpp: 0.5828 - mse: 1.3731e-04\n",
      "Epoch 904: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.1453 - bpp: 0.5828 - mse: 1.3731e-04\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1398 - bpp: 0.5722 - mse: 1.3857e-04\n",
      "Epoch 905: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1398 - bpp: 0.5722 - mse: 1.3857e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1604 - bpp: 0.5786 - mse: 1.4203e-04\n",
      "Epoch 906: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 1.1604 - bpp: 0.5786 - mse: 1.4203e-04\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2260 - bpp: 0.6051 - mse: 1.5159e-04\n",
      "Epoch 907: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2260 - bpp: 0.6051 - mse: 1.5159e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0502 - bpp: 0.5568 - mse: 1.2045e-04\n",
      "Epoch 908: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0502 - bpp: 0.5568 - mse: 1.2045e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1285 - bpp: 0.5677 - mse: 1.3689e-04\n",
      "Epoch 909: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1285 - bpp: 0.5677 - mse: 1.3689e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1087 - bpp: 0.5626 - mse: 1.3333e-04\n",
      "Epoch 910: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1087 - bpp: 0.5626 - mse: 1.3333e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0467 - bpp: 0.5478 - mse: 1.2180e-04\n",
      "Epoch 911: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0467 - bpp: 0.5478 - mse: 1.2180e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1809 - bpp: 0.5931 - mse: 1.4351e-04\n",
      "Epoch 912: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1809 - bpp: 0.5931 - mse: 1.4351e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0350 - bpp: 0.5457 - mse: 1.1946e-04\n",
      "Epoch 913: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0350 - bpp: 0.5457 - mse: 1.1946e-04\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0988 - bpp: 0.5577 - mse: 1.3210e-04\n",
      "Epoch 914: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0988 - bpp: 0.5577 - mse: 1.3210e-04\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1914 - bpp: 0.5867 - mse: 1.4763e-04\n",
      "Epoch 915: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1914 - bpp: 0.5867 - mse: 1.4763e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0492 - bpp: 0.5476 - mse: 1.2245e-04\n",
      "Epoch 916: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0492 - bpp: 0.5476 - mse: 1.2245e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0760 - bpp: 0.5617 - mse: 1.2557e-04\n",
      "Epoch 917: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 1.0760 - bpp: 0.5617 - mse: 1.2557e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1335 - bpp: 0.5775 - mse: 1.3574e-04\n",
      "Epoch 918: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1335 - bpp: 0.5775 - mse: 1.3574e-04\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2619 - bpp: 0.6100 - mse: 1.5917e-04\n",
      "Epoch 919: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.2619 - bpp: 0.6100 - mse: 1.5917e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0802 - bpp: 0.5542 - mse: 1.2843e-04\n",
      "Epoch 920: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0802 - bpp: 0.5542 - mse: 1.2843e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0645 - bpp: 0.5428 - mse: 1.2736e-04\n",
      "Epoch 921: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0645 - bpp: 0.5428 - mse: 1.2736e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1360 - bpp: 0.5688 - mse: 1.3847e-04\n",
      "Epoch 922: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1360 - bpp: 0.5688 - mse: 1.3847e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1073 - bpp: 0.5636 - mse: 1.3274e-04\n",
      "Epoch 923: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.1073 - bpp: 0.5636 - mse: 1.3274e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1478 - bpp: 0.5779 - mse: 1.3913e-04\n",
      "Epoch 924: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1478 - bpp: 0.5779 - mse: 1.3913e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0836 - bpp: 0.5645 - mse: 1.2673e-04\n",
      "Epoch 925: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0836 - bpp: 0.5645 - mse: 1.2673e-04\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0374 - bpp: 0.5400 - mse: 1.2144e-04\n",
      "Epoch 926: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0374 - bpp: 0.5400 - mse: 1.2144e-04\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1206 - bpp: 0.5748 - mse: 1.3325e-04\n",
      "Epoch 927: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.1206 - bpp: 0.5748 - mse: 1.3325e-04\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9667 - bpp: 0.5144 - mse: 1.1043e-04\n",
      "Epoch 928: loss improved from 1.02722 to 0.96673, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.9667 - bpp: 0.5144 - mse: 1.1043e-04\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1061 - bpp: 0.5579 - mse: 1.3383e-04\n",
      "Epoch 929: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.1061 - bpp: 0.5579 - mse: 1.3383e-04\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0789 - bpp: 0.5508 - mse: 1.2893e-04\n",
      "Epoch 930: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0789 - bpp: 0.5508 - mse: 1.2893e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1064 - bpp: 0.5596 - mse: 1.3350e-04\n",
      "Epoch 931: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1064 - bpp: 0.5596 - mse: 1.3350e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1899 - bpp: 0.5875 - mse: 1.4708e-04\n",
      "Epoch 932: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.1899 - bpp: 0.5875 - mse: 1.4708e-04\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0818 - bpp: 0.5601 - mse: 1.2738e-04\n",
      "Epoch 933: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.0818 - bpp: 0.5601 - mse: 1.2738e-04\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1516 - bpp: 0.5710 - mse: 1.4173e-04\n",
      "Epoch 934: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1516 - bpp: 0.5710 - mse: 1.4173e-04\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0860 - bpp: 0.5519 - mse: 1.3041e-04\n",
      "Epoch 935: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 1.0860 - bpp: 0.5519 - mse: 1.3041e-04\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1752 - bpp: 0.5871 - mse: 1.4357e-04\n",
      "Epoch 936: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.1752 - bpp: 0.5871 - mse: 1.4357e-04\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1626 - bpp: 0.5686 - mse: 1.4500e-04\n",
      "Epoch 937: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1626 - bpp: 0.5686 - mse: 1.4500e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0724 - bpp: 0.5565 - mse: 1.2594e-04\n",
      "Epoch 938: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 1.0724 - bpp: 0.5565 - mse: 1.2594e-04\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.5381 - mse: 1.3045e-04\n",
      "Epoch 939: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.0725 - bpp: 0.5381 - mse: 1.3045e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0607 - bpp: 0.5546 - mse: 1.2356e-04\n",
      "Epoch 940: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.0607 - bpp: 0.5546 - mse: 1.2356e-04\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0755 - bpp: 0.5554 - mse: 1.2697e-04\n",
      "Epoch 941: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0755 - bpp: 0.5554 - mse: 1.2697e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1555 - bpp: 0.5775 - mse: 1.4112e-04\n",
      "Epoch 942: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.1555 - bpp: 0.5775 - mse: 1.4112e-04\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0868 - bpp: 0.5698 - mse: 1.2621e-04\n",
      "Epoch 943: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0868 - bpp: 0.5698 - mse: 1.2621e-04\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1461 - bpp: 0.5721 - mse: 1.4014e-04\n",
      "Epoch 944: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1461 - bpp: 0.5721 - mse: 1.4014e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1885 - bpp: 0.5797 - mse: 1.4863e-04\n",
      "Epoch 945: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1885 - bpp: 0.5797 - mse: 1.4863e-04\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1456 - bpp: 0.5755 - mse: 1.3918e-04\n",
      "Epoch 946: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1456 - bpp: 0.5755 - mse: 1.3918e-04\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1998 - bpp: 0.5924 - mse: 1.4830e-04\n",
      "Epoch 947: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1998 - bpp: 0.5924 - mse: 1.4830e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0332 - bpp: 0.5477 - mse: 1.1853e-04\n",
      "Epoch 948: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0332 - bpp: 0.5477 - mse: 1.1853e-04\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1138 - bpp: 0.5591 - mse: 1.3543e-04\n",
      "Epoch 949: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1138 - bpp: 0.5591 - mse: 1.3543e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1352 - bpp: 0.5717 - mse: 1.3757e-04\n",
      "Epoch 950: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1352 - bpp: 0.5717 - mse: 1.3757e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0849 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 951: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.0849 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0911 - bpp: 0.5677 - mse: 1.2777e-04\n",
      "Epoch 952: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.0911 - bpp: 0.5677 - mse: 1.2777e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0737 - bpp: 0.5383 - mse: 1.3073e-04\n",
      "Epoch 953: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0737 - bpp: 0.5383 - mse: 1.3073e-04\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0164 - bpp: 0.5348 - mse: 1.1758e-04\n",
      "Epoch 954: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 1.0164 - bpp: 0.5348 - mse: 1.1758e-04\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1123 - bpp: 0.5679 - mse: 1.3291e-04\n",
      "Epoch 955: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1123 - bpp: 0.5679 - mse: 1.3291e-04\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0045 - bpp: 0.5269 - mse: 1.1658e-04\n",
      "Epoch 956: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0045 - bpp: 0.5269 - mse: 1.1658e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0595 - bpp: 0.5436 - mse: 1.2594e-04\n",
      "Epoch 957: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0595 - bpp: 0.5436 - mse: 1.2594e-04\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0683 - bpp: 0.5534 - mse: 1.2571e-04\n",
      "Epoch 958: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0683 - bpp: 0.5534 - mse: 1.2571e-04\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1049 - bpp: 0.5625 - mse: 1.3242e-04\n",
      "Epoch 959: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1049 - bpp: 0.5625 - mse: 1.3242e-04\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1959 - bpp: 0.5885 - mse: 1.4831e-04\n",
      "Epoch 960: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.1959 - bpp: 0.5885 - mse: 1.4831e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0484 - bpp: 0.5522 - mse: 1.2116e-04\n",
      "Epoch 961: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0484 - bpp: 0.5522 - mse: 1.2116e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1695 - bpp: 0.5765 - mse: 1.4478e-04\n",
      "Epoch 962: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1695 - bpp: 0.5765 - mse: 1.4478e-04\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1691 - bpp: 0.5818 - mse: 1.4338e-04\n",
      "Epoch 963: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1691 - bpp: 0.5818 - mse: 1.4338e-04\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1145 - bpp: 0.5599 - mse: 1.3540e-04\n",
      "Epoch 964: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1145 - bpp: 0.5599 - mse: 1.3540e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1803 - bpp: 0.5852 - mse: 1.4529e-04\n",
      "Epoch 965: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1803 - bpp: 0.5852 - mse: 1.4529e-04\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0472 - bpp: 0.5500 - mse: 1.2139e-04\n",
      "Epoch 966: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0472 - bpp: 0.5500 - mse: 1.2139e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1370 - bpp: 0.5704 - mse: 1.3834e-04\n",
      "Epoch 967: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1370 - bpp: 0.5704 - mse: 1.3834e-04\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1205 - bpp: 0.5727 - mse: 1.3373e-04\n",
      "Epoch 968: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1205 - bpp: 0.5727 - mse: 1.3373e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0526 - bpp: 0.5490 - mse: 1.2296e-04\n",
      "Epoch 969: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0526 - bpp: 0.5490 - mse: 1.2296e-04\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1355 - bpp: 0.5815 - mse: 1.3524e-04\n",
      "Epoch 970: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1355 - bpp: 0.5815 - mse: 1.3524e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1321 - bpp: 0.5643 - mse: 1.3862e-04\n",
      "Epoch 971: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1321 - bpp: 0.5643 - mse: 1.3862e-04\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0167 - bpp: 0.5375 - mse: 1.1700e-04\n",
      "Epoch 972: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0167 - bpp: 0.5375 - mse: 1.1700e-04\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0478 - bpp: 0.5452 - mse: 1.2271e-04\n",
      "Epoch 973: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0478 - bpp: 0.5452 - mse: 1.2271e-04\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0835 - bpp: 0.5502 - mse: 1.3020e-04\n",
      "Epoch 974: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0835 - bpp: 0.5502 - mse: 1.3020e-04\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0493 - bpp: 0.5456 - mse: 1.2296e-04\n",
      "Epoch 975: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0493 - bpp: 0.5456 - mse: 1.2296e-04\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0910 - bpp: 0.5651 - mse: 1.2837e-04\n",
      "Epoch 976: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0910 - bpp: 0.5651 - mse: 1.2837e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0732 - bpp: 0.5415 - mse: 1.2979e-04\n",
      "Epoch 977: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0732 - bpp: 0.5415 - mse: 1.2979e-04\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0311 - bpp: 0.5228 - mse: 1.2408e-04\n",
      "Epoch 978: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0311 - bpp: 0.5228 - mse: 1.2408e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1193 - bpp: 0.5749 - mse: 1.3290e-04\n",
      "Epoch 979: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1193 - bpp: 0.5749 - mse: 1.3290e-04\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0247 - bpp: 0.5307 - mse: 1.2061e-04\n",
      "Epoch 980: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0247 - bpp: 0.5307 - mse: 1.2061e-04\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0048 - bpp: 0.5250 - mse: 1.1714e-04\n",
      "Epoch 981: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0048 - bpp: 0.5250 - mse: 1.1714e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0682 - bpp: 0.5493 - mse: 1.2670e-04\n",
      "Epoch 982: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0682 - bpp: 0.5493 - mse: 1.2670e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1706 - bpp: 0.5714 - mse: 1.4629e-04\n",
      "Epoch 983: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1706 - bpp: 0.5714 - mse: 1.4629e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1277 - bpp: 0.5699 - mse: 1.3617e-04\n",
      "Epoch 984: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1277 - bpp: 0.5699 - mse: 1.3617e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1027 - bpp: 0.5598 - mse: 1.3255e-04\n",
      "Epoch 985: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1027 - bpp: 0.5598 - mse: 1.3255e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1636 - bpp: 0.5865 - mse: 1.4089e-04\n",
      "Epoch 986: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1636 - bpp: 0.5865 - mse: 1.4089e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1363 - bpp: 0.5817 - mse: 1.3541e-04\n",
      "Epoch 987: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1363 - bpp: 0.5817 - mse: 1.3541e-04\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0919 - bpp: 0.5544 - mse: 1.3122e-04\n",
      "Epoch 988: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0919 - bpp: 0.5544 - mse: 1.3122e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0456 - bpp: 0.5445 - mse: 1.2234e-04\n",
      "Epoch 989: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0456 - bpp: 0.5445 - mse: 1.2234e-04\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2013 - bpp: 0.5986 - mse: 1.4714e-04\n",
      "Epoch 990: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.2013 - bpp: 0.5986 - mse: 1.4714e-04\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1116 - bpp: 0.5684 - mse: 1.3263e-04\n",
      "Epoch 991: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1116 - bpp: 0.5684 - mse: 1.3263e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0460 - bpp: 0.5485 - mse: 1.2147e-04\n",
      "Epoch 992: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0460 - bpp: 0.5485 - mse: 1.2147e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0762 - bpp: 0.5551 - mse: 1.2723e-04\n",
      "Epoch 993: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0762 - bpp: 0.5551 - mse: 1.2723e-04\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1547 - bpp: 0.5695 - mse: 1.4286e-04\n",
      "Epoch 994: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1547 - bpp: 0.5695 - mse: 1.4286e-04\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0724 - bpp: 0.5533 - mse: 1.2674e-04\n",
      "Epoch 995: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0724 - bpp: 0.5533 - mse: 1.2674e-04\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0974 - bpp: 0.5668 - mse: 1.2955e-04\n",
      "Epoch 996: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0974 - bpp: 0.5668 - mse: 1.2955e-04\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1315 - bpp: 0.5712 - mse: 1.3680e-04\n",
      "Epoch 997: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1315 - bpp: 0.5712 - mse: 1.3680e-04\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2006 - bpp: 0.5893 - mse: 1.4925e-04\n",
      "Epoch 998: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.2006 - bpp: 0.5893 - mse: 1.4925e-04\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1386 - bpp: 0.5685 - mse: 1.3918e-04\n",
      "Epoch 999: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1386 - bpp: 0.5685 - mse: 1.3918e-04\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0826 - bpp: 0.5608 - mse: 1.2740e-04\n",
      "Epoch 1000: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0826 - bpp: 0.5608 - mse: 1.2740e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1084 - bpp: 0.5555 - mse: 1.3499e-04\n",
      "Epoch 1001: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1084 - bpp: 0.5555 - mse: 1.3499e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1803 - bpp: 0.5960 - mse: 1.4265e-04\n",
      "Epoch 1002: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 243ms/step - loss: 1.1803 - bpp: 0.5960 - mse: 1.4265e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1015 - bpp: 0.5669 - mse: 1.3051e-04\n",
      "Epoch 1003: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1015 - bpp: 0.5669 - mse: 1.3051e-04\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1097 - bpp: 0.5687 - mse: 1.3207e-04\n",
      "Epoch 1004: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1097 - bpp: 0.5687 - mse: 1.3207e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0751 - bpp: 0.5478 - mse: 1.2874e-04\n",
      "Epoch 1005: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0751 - bpp: 0.5478 - mse: 1.2874e-04\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0757 - bpp: 0.5569 - mse: 1.2666e-04\n",
      "Epoch 1006: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0757 - bpp: 0.5569 - mse: 1.2666e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0922 - bpp: 0.5539 - mse: 1.3141e-04\n",
      "Epoch 1007: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0922 - bpp: 0.5539 - mse: 1.3141e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.5477 - mse: 1.2814e-04\n",
      "Epoch 1008: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0725 - bpp: 0.5477 - mse: 1.2814e-04\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1042 - bpp: 0.5568 - mse: 1.3364e-04\n",
      "Epoch 1009: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1042 - bpp: 0.5568 - mse: 1.3364e-04\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0207 - bpp: 0.5352 - mse: 1.1853e-04\n",
      "Epoch 1010: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0207 - bpp: 0.5352 - mse: 1.1853e-04\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1818 - bpp: 0.5826 - mse: 1.4630e-04\n",
      "Epoch 1011: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1818 - bpp: 0.5826 - mse: 1.4630e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1217 - bpp: 0.5650 - mse: 1.3592e-04\n",
      "Epoch 1012: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1217 - bpp: 0.5650 - mse: 1.3592e-04\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0389 - bpp: 0.5445 - mse: 1.2070e-04\n",
      "Epoch 1013: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0389 - bpp: 0.5445 - mse: 1.2070e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1095 - bpp: 0.5632 - mse: 1.3338e-04\n",
      "Epoch 1014: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1095 - bpp: 0.5632 - mse: 1.3338e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0163 - bpp: 0.5362 - mse: 1.1721e-04\n",
      "Epoch 1015: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0163 - bpp: 0.5362 - mse: 1.1721e-04\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0357 - bpp: 0.5397 - mse: 1.2111e-04\n",
      "Epoch 1016: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0357 - bpp: 0.5397 - mse: 1.2111e-04\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0830 - bpp: 0.5638 - mse: 1.2675e-04\n",
      "Epoch 1017: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0830 - bpp: 0.5638 - mse: 1.2675e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9844 - bpp: 0.5249 - mse: 1.1218e-04\n",
      "Epoch 1018: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9844 - bpp: 0.5249 - mse: 1.1218e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0417 - bpp: 0.5406 - mse: 1.2234e-04\n",
      "Epoch 1019: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0417 - bpp: 0.5406 - mse: 1.2234e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0370 - bpp: 0.5366 - mse: 1.2215e-04\n",
      "Epoch 1020: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0370 - bpp: 0.5366 - mse: 1.2215e-04\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0625 - bpp: 0.5453 - mse: 1.2626e-04\n",
      "Epoch 1021: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 1.0625 - bpp: 0.5453 - mse: 1.2626e-04\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1256 - bpp: 0.5695 - mse: 1.3578e-04\n",
      "Epoch 1022: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1256 - bpp: 0.5695 - mse: 1.3578e-04\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0918 - bpp: 0.5571 - mse: 1.3054e-04\n",
      "Epoch 1023: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0918 - bpp: 0.5571 - mse: 1.3054e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9974 - bpp: 0.5153 - mse: 1.1768e-04\n",
      "Epoch 1024: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.9974 - bpp: 0.5153 - mse: 1.1768e-04\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.5544 - mse: 1.3024e-04\n",
      "Epoch 1025: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0879 - bpp: 0.5544 - mse: 1.3024e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0783 - bpp: 0.5523 - mse: 1.2841e-04\n",
      "Epoch 1026: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0783 - bpp: 0.5523 - mse: 1.2841e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0939 - bpp: 0.5581 - mse: 1.3082e-04\n",
      "Epoch 1027: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0939 - bpp: 0.5581 - mse: 1.3082e-04\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0871 - bpp: 0.5449 - mse: 1.3239e-04\n",
      "Epoch 1028: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0871 - bpp: 0.5449 - mse: 1.3239e-04\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5895 - mse: 1.3827e-04\n",
      "Epoch 1029: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1559 - bpp: 0.5895 - mse: 1.3827e-04\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1599 - bpp: 0.5873 - mse: 1.3977e-04\n",
      "Epoch 1030: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1599 - bpp: 0.5873 - mse: 1.3977e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1891 - bpp: 0.5823 - mse: 1.4813e-04\n",
      "Epoch 1031: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1891 - bpp: 0.5823 - mse: 1.4813e-04\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1093 - bpp: 0.5605 - mse: 1.3397e-04\n",
      "Epoch 1032: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1093 - bpp: 0.5605 - mse: 1.3397e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0631 - bpp: 0.5491 - mse: 1.2551e-04\n",
      "Epoch 1033: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0631 - bpp: 0.5491 - mse: 1.2551e-04\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0814 - bpp: 0.5533 - mse: 1.2892e-04\n",
      "Epoch 1034: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0814 - bpp: 0.5533 - mse: 1.2892e-04\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0668 - bpp: 0.5520 - mse: 1.2568e-04\n",
      "Epoch 1035: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0668 - bpp: 0.5520 - mse: 1.2568e-04\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1526 - bpp: 0.5780 - mse: 1.4028e-04\n",
      "Epoch 1036: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1526 - bpp: 0.5780 - mse: 1.4028e-04\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1485 - bpp: 0.5688 - mse: 1.4155e-04\n",
      "Epoch 1037: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1485 - bpp: 0.5688 - mse: 1.4155e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0660 - bpp: 0.5491 - mse: 1.2620e-04\n",
      "Epoch 1038: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0660 - bpp: 0.5491 - mse: 1.2620e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0825 - bpp: 0.5623 - mse: 1.2700e-04\n",
      "Epoch 1039: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0825 - bpp: 0.5623 - mse: 1.2700e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0909 - bpp: 0.5734 - mse: 1.2634e-04\n",
      "Epoch 1040: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0909 - bpp: 0.5734 - mse: 1.2634e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0697 - bpp: 0.5547 - mse: 1.2574e-04\n",
      "Epoch 1041: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0697 - bpp: 0.5547 - mse: 1.2574e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0299 - bpp: 0.5316 - mse: 1.2165e-04\n",
      "Epoch 1042: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 1.0299 - bpp: 0.5316 - mse: 1.2165e-04\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1506 - bpp: 0.5728 - mse: 1.4106e-04\n",
      "Epoch 1043: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1506 - bpp: 0.5728 - mse: 1.4106e-04\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5663 - mse: 1.3484e-04\n",
      "Epoch 1044: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1186 - bpp: 0.5663 - mse: 1.3484e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0144 - bpp: 0.5310 - mse: 1.1802e-04\n",
      "Epoch 1045: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0144 - bpp: 0.5310 - mse: 1.1802e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0450 - bpp: 0.5389 - mse: 1.2356e-04\n",
      "Epoch 1046: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0450 - bpp: 0.5389 - mse: 1.2356e-04\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0530 - bpp: 0.5556 - mse: 1.2144e-04\n",
      "Epoch 1047: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0530 - bpp: 0.5556 - mse: 1.2144e-04\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1589 - bpp: 0.5726 - mse: 1.4314e-04\n",
      "Epoch 1048: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1589 - bpp: 0.5726 - mse: 1.4314e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0473 - bpp: 0.5404 - mse: 1.2375e-04\n",
      "Epoch 1049: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0473 - bpp: 0.5404 - mse: 1.2375e-04\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0763 - bpp: 0.5468 - mse: 1.2928e-04\n",
      "Epoch 1050: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0763 - bpp: 0.5468 - mse: 1.2928e-04\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0823 - bpp: 0.5557 - mse: 1.2856e-04\n",
      "Epoch 1051: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0823 - bpp: 0.5557 - mse: 1.2856e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1575 - bpp: 0.5740 - mse: 1.4245e-04\n",
      "Epoch 1052: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1575 - bpp: 0.5740 - mse: 1.4245e-04\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0989 - bpp: 0.5636 - mse: 1.3071e-04\n",
      "Epoch 1053: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0989 - bpp: 0.5636 - mse: 1.3071e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0805 - bpp: 0.5561 - mse: 1.2802e-04\n",
      "Epoch 1054: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0805 - bpp: 0.5561 - mse: 1.2802e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0448 - bpp: 0.5458 - mse: 1.2182e-04\n",
      "Epoch 1055: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0448 - bpp: 0.5458 - mse: 1.2182e-04\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0616 - bpp: 0.5499 - mse: 1.2493e-04\n",
      "Epoch 1056: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0616 - bpp: 0.5499 - mse: 1.2493e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1149 - bpp: 0.5655 - mse: 1.3413e-04\n",
      "Epoch 1057: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.1149 - bpp: 0.5655 - mse: 1.3413e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0843 - bpp: 0.5566 - mse: 1.2883e-04\n",
      "Epoch 1058: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0843 - bpp: 0.5566 - mse: 1.2883e-04\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0518 - bpp: 0.5476 - mse: 1.2309e-04\n",
      "Epoch 1059: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0518 - bpp: 0.5476 - mse: 1.2309e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1236 - bpp: 0.5661 - mse: 1.3612e-04\n",
      "Epoch 1060: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1236 - bpp: 0.5661 - mse: 1.3612e-04\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0216 - bpp: 0.5324 - mse: 1.1942e-04\n",
      "Epoch 1061: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0216 - bpp: 0.5324 - mse: 1.1942e-04\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0617 - bpp: 0.5516 - mse: 1.2455e-04\n",
      "Epoch 1062: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0617 - bpp: 0.5516 - mse: 1.2455e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2306 - bpp: 0.6090 - mse: 1.5178e-04\n",
      "Epoch 1063: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2306 - bpp: 0.6090 - mse: 1.5178e-04\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9383 - bpp: 0.5129 - mse: 1.0387e-04\n",
      "Epoch 1064: loss improved from 0.96673 to 0.93830, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9383 - bpp: 0.5129 - mse: 1.0387e-04\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2698 - bpp: 0.6054 - mse: 1.6221e-04\n",
      "Epoch 1065: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2698 - bpp: 0.6054 - mse: 1.6221e-04\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0570 - bpp: 0.5450 - mse: 1.2501e-04\n",
      "Epoch 1066: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0570 - bpp: 0.5450 - mse: 1.2501e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5545 - mse: 1.2951e-04\n",
      "Epoch 1067: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0850 - bpp: 0.5545 - mse: 1.2951e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0788 - bpp: 0.5528 - mse: 1.2840e-04\n",
      "Epoch 1068: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0788 - bpp: 0.5528 - mse: 1.2840e-04\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0269 - bpp: 0.5394 - mse: 1.1902e-04\n",
      "Epoch 1069: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0269 - bpp: 0.5394 - mse: 1.1902e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9732 - bpp: 0.5179 - mse: 1.1114e-04\n",
      "Epoch 1070: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9732 - bpp: 0.5179 - mse: 1.1114e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0225 - bpp: 0.5408 - mse: 1.1762e-04\n",
      "Epoch 1071: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0225 - bpp: 0.5408 - mse: 1.1762e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1265 - bpp: 0.5709 - mse: 1.3565e-04\n",
      "Epoch 1072: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1265 - bpp: 0.5709 - mse: 1.3565e-04\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0993 - bpp: 0.5502 - mse: 1.3406e-04\n",
      "Epoch 1073: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0993 - bpp: 0.5502 - mse: 1.3406e-04\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0221 - bpp: 0.5356 - mse: 1.1878e-04\n",
      "Epoch 1074: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0221 - bpp: 0.5356 - mse: 1.1878e-04\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5317 - mse: 1.2883e-04\n",
      "Epoch 1075: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0594 - bpp: 0.5317 - mse: 1.2883e-04\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1163 - bpp: 0.5758 - mse: 1.3195e-04\n",
      "Epoch 1076: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1163 - bpp: 0.5758 - mse: 1.3195e-04\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1230 - bpp: 0.5597 - mse: 1.3753e-04\n",
      "Epoch 1077: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.1230 - bpp: 0.5597 - mse: 1.3753e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0876 - bpp: 0.5519 - mse: 1.3079e-04\n",
      "Epoch 1078: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0876 - bpp: 0.5519 - mse: 1.3079e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0583 - bpp: 0.5514 - mse: 1.2376e-04\n",
      "Epoch 1079: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0583 - bpp: 0.5514 - mse: 1.2376e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0688 - bpp: 0.5445 - mse: 1.2800e-04\n",
      "Epoch 1080: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0688 - bpp: 0.5445 - mse: 1.2800e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0255 - bpp: 0.5319 - mse: 1.2050e-04\n",
      "Epoch 1081: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0255 - bpp: 0.5319 - mse: 1.2050e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5523 - mse: 1.3005e-04\n",
      "Epoch 1082: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.0850 - bpp: 0.5523 - mse: 1.3005e-04\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0237 - bpp: 0.5364 - mse: 1.1898e-04\n",
      "Epoch 1083: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0237 - bpp: 0.5364 - mse: 1.1898e-04\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1270 - bpp: 0.5672 - mse: 1.3665e-04\n",
      "Epoch 1084: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1270 - bpp: 0.5672 - mse: 1.3665e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1386 - bpp: 0.5648 - mse: 1.4007e-04\n",
      "Epoch 1085: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1386 - bpp: 0.5648 - mse: 1.4007e-04\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1141 - bpp: 0.5626 - mse: 1.3463e-04\n",
      "Epoch 1086: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1141 - bpp: 0.5626 - mse: 1.3463e-04\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1071 - bpp: 0.5704 - mse: 1.3102e-04\n",
      "Epoch 1087: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1071 - bpp: 0.5704 - mse: 1.3102e-04\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1524 - bpp: 0.5773 - mse: 1.4040e-04\n",
      "Epoch 1088: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1524 - bpp: 0.5773 - mse: 1.4040e-04\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9791 - bpp: 0.5282 - mse: 1.1010e-04\n",
      "Epoch 1089: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9791 - bpp: 0.5282 - mse: 1.1010e-04\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1168 - bpp: 0.5659 - mse: 1.3449e-04\n",
      "Epoch 1090: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.1168 - bpp: 0.5659 - mse: 1.3449e-04\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0693 - bpp: 0.5550 - mse: 1.2557e-04\n",
      "Epoch 1091: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0693 - bpp: 0.5550 - mse: 1.2557e-04\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0948 - bpp: 0.5497 - mse: 1.3309e-04\n",
      "Epoch 1092: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0948 - bpp: 0.5497 - mse: 1.3309e-04\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0631 - bpp: 0.5458 - mse: 1.2632e-04\n",
      "Epoch 1093: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0631 - bpp: 0.5458 - mse: 1.2632e-04\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0787 - bpp: 0.5519 - mse: 1.2862e-04\n",
      "Epoch 1094: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0787 - bpp: 0.5519 - mse: 1.2862e-04\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0952 - bpp: 0.5572 - mse: 1.3134e-04\n",
      "Epoch 1095: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0952 - bpp: 0.5572 - mse: 1.3134e-04\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0276 - bpp: 0.5364 - mse: 1.1994e-04\n",
      "Epoch 1096: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0276 - bpp: 0.5364 - mse: 1.1994e-04\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0984 - bpp: 0.5616 - mse: 1.3106e-04\n",
      "Epoch 1097: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0984 - bpp: 0.5616 - mse: 1.3106e-04\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9999 - bpp: 0.5317 - mse: 1.1431e-04\n",
      "Epoch 1098: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9999 - bpp: 0.5317 - mse: 1.1431e-04\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0759 - bpp: 0.5567 - mse: 1.2676e-04\n",
      "Epoch 1099: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0759 - bpp: 0.5567 - mse: 1.2676e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5586 - mse: 1.2976e-04\n",
      "Epoch 1100: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0901 - bpp: 0.5586 - mse: 1.2976e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0864 - bpp: 0.5556 - mse: 1.2959e-04\n",
      "Epoch 1101: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0864 - bpp: 0.5556 - mse: 1.2959e-04\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0208 - bpp: 0.5351 - mse: 1.1858e-04\n",
      "Epoch 1102: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0208 - bpp: 0.5351 - mse: 1.1858e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5568 - mse: 1.3019e-04\n",
      "Epoch 1103: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0901 - bpp: 0.5568 - mse: 1.3019e-04\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1614 - bpp: 0.5725 - mse: 1.4378e-04\n",
      "Epoch 1104: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1614 - bpp: 0.5725 - mse: 1.4378e-04\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1105 - bpp: 0.5593 - mse: 1.3457e-04\n",
      "Epoch 1105: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1105 - bpp: 0.5593 - mse: 1.3457e-04\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5605 - mse: 1.3627e-04\n",
      "Epoch 1106: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1186 - bpp: 0.5605 - mse: 1.3627e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0091 - bpp: 0.5327 - mse: 1.1632e-04\n",
      "Epoch 1107: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0091 - bpp: 0.5327 - mse: 1.1632e-04\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0845 - bpp: 0.5514 - mse: 1.3015e-04\n",
      "Epoch 1108: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0845 - bpp: 0.5514 - mse: 1.3015e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0717 - bpp: 0.5505 - mse: 1.2726e-04\n",
      "Epoch 1109: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0717 - bpp: 0.5505 - mse: 1.2726e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1208 - bpp: 0.5650 - mse: 1.3570e-04\n",
      "Epoch 1110: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1208 - bpp: 0.5650 - mse: 1.3570e-04\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0746 - bpp: 0.5472 - mse: 1.2876e-04\n",
      "Epoch 1111: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0746 - bpp: 0.5472 - mse: 1.2876e-04\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0918 - bpp: 0.5558 - mse: 1.3086e-04\n",
      "Epoch 1112: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0918 - bpp: 0.5558 - mse: 1.3086e-04\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0123 - bpp: 0.5375 - mse: 1.1592e-04\n",
      "Epoch 1113: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0123 - bpp: 0.5375 - mse: 1.1592e-04\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1608 - bpp: 0.5861 - mse: 1.4029e-04\n",
      "Epoch 1114: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1608 - bpp: 0.5861 - mse: 1.4029e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0583 - bpp: 0.5435 - mse: 1.2568e-04\n",
      "Epoch 1115: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0583 - bpp: 0.5435 - mse: 1.2568e-04\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0120 - bpp: 0.5314 - mse: 1.1734e-04\n",
      "Epoch 1116: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 1.0120 - bpp: 0.5314 - mse: 1.1734e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1689 - bpp: 0.5761 - mse: 1.4474e-04\n",
      "Epoch 1117: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1689 - bpp: 0.5761 - mse: 1.4474e-04\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5839 - mse: 1.3965e-04\n",
      "Epoch 1118: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1559 - bpp: 0.5839 - mse: 1.3965e-04\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0703 - bpp: 0.5556 - mse: 1.2565e-04\n",
      "Epoch 1119: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0703 - bpp: 0.5556 - mse: 1.2565e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1652 - bpp: 0.5781 - mse: 1.4332e-04\n",
      "Epoch 1120: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1652 - bpp: 0.5781 - mse: 1.4332e-04\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0788 - bpp: 0.5521 - mse: 1.2859e-04\n",
      "Epoch 1121: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0788 - bpp: 0.5521 - mse: 1.2859e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0513 - bpp: 0.5453 - mse: 1.2353e-04\n",
      "Epoch 1122: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0513 - bpp: 0.5453 - mse: 1.2353e-04\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5523 - mse: 1.2380e-04\n",
      "Epoch 1123: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0594 - bpp: 0.5523 - mse: 1.2380e-04\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1062 - bpp: 0.5557 - mse: 1.3440e-04\n",
      "Epoch 1124: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1062 - bpp: 0.5557 - mse: 1.3440e-04\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1078 - bpp: 0.5567 - mse: 1.3456e-04\n",
      "Epoch 1125: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.1078 - bpp: 0.5567 - mse: 1.3456e-04\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0847 - bpp: 0.5507 - mse: 1.3036e-04\n",
      "Epoch 1126: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0847 - bpp: 0.5507 - mse: 1.3036e-04\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0964 - bpp: 0.5709 - mse: 1.2831e-04\n",
      "Epoch 1127: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0964 - bpp: 0.5709 - mse: 1.2831e-04\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1428 - bpp: 0.5766 - mse: 1.3823e-04\n",
      "Epoch 1128: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1428 - bpp: 0.5766 - mse: 1.3823e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0097 - bpp: 0.5315 - mse: 1.1674e-04\n",
      "Epoch 1129: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0097 - bpp: 0.5315 - mse: 1.1674e-04\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0187 - bpp: 0.5258 - mse: 1.2034e-04\n",
      "Epoch 1130: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0187 - bpp: 0.5258 - mse: 1.2034e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0081 - bpp: 0.5274 - mse: 1.1735e-04\n",
      "Epoch 1131: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0081 - bpp: 0.5274 - mse: 1.1735e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0479 - bpp: 0.5517 - mse: 1.2114e-04\n",
      "Epoch 1132: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0479 - bpp: 0.5517 - mse: 1.2114e-04\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0623 - bpp: 0.5444 - mse: 1.2646e-04\n",
      "Epoch 1133: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0623 - bpp: 0.5444 - mse: 1.2646e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9951 - bpp: 0.5267 - mse: 1.1435e-04\n",
      "Epoch 1134: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.9951 - bpp: 0.5267 - mse: 1.1435e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0397 - bpp: 0.5500 - mse: 1.1955e-04\n",
      "Epoch 1135: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0397 - bpp: 0.5500 - mse: 1.1955e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1621 - bpp: 0.5730 - mse: 1.4381e-04\n",
      "Epoch 1136: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1621 - bpp: 0.5730 - mse: 1.4381e-04\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0488 - bpp: 0.5486 - mse: 1.2214e-04\n",
      "Epoch 1137: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0488 - bpp: 0.5486 - mse: 1.2214e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1274 - bpp: 0.5642 - mse: 1.3752e-04\n",
      "Epoch 1138: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.1274 - bpp: 0.5642 - mse: 1.3752e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0882 - bpp: 0.5489 - mse: 1.3167e-04\n",
      "Epoch 1139: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0882 - bpp: 0.5489 - mse: 1.3167e-04\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0286 - bpp: 0.5467 - mse: 1.1766e-04\n",
      "Epoch 1140: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0286 - bpp: 0.5467 - mse: 1.1766e-04\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9926 - bpp: 0.5227 - mse: 1.1472e-04\n",
      "Epoch 1141: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.9926 - bpp: 0.5227 - mse: 1.1472e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9918 - bpp: 0.5281 - mse: 1.1322e-04\n",
      "Epoch 1142: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9918 - bpp: 0.5281 - mse: 1.1322e-04\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0149 - bpp: 0.5400 - mse: 1.1595e-04\n",
      "Epoch 1143: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0149 - bpp: 0.5400 - mse: 1.1595e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0556 - bpp: 0.5451 - mse: 1.2465e-04\n",
      "Epoch 1144: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0556 - bpp: 0.5451 - mse: 1.2465e-04\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1390 - bpp: 0.5771 - mse: 1.3717e-04\n",
      "Epoch 1145: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.1390 - bpp: 0.5771 - mse: 1.3717e-04\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0219 - bpp: 0.5322 - mse: 1.1956e-04\n",
      "Epoch 1146: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0219 - bpp: 0.5322 - mse: 1.1956e-04\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0729 - bpp: 0.5501 - mse: 1.2764e-04\n",
      "Epoch 1147: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0729 - bpp: 0.5501 - mse: 1.2764e-04\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0852 - bpp: 0.5526 - mse: 1.3002e-04\n",
      "Epoch 1148: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0852 - bpp: 0.5526 - mse: 1.3002e-04\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1090 - bpp: 0.5615 - mse: 1.3367e-04\n",
      "Epoch 1149: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1090 - bpp: 0.5615 - mse: 1.3367e-04\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9954 - bpp: 0.5330 - mse: 1.1290e-04\n",
      "Epoch 1150: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 0.9954 - bpp: 0.5330 - mse: 1.1290e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1226 - bpp: 0.5573 - mse: 1.3801e-04\n",
      "Epoch 1151: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1226 - bpp: 0.5573 - mse: 1.3801e-04\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1089 - bpp: 0.5636 - mse: 1.3314e-04\n",
      "Epoch 1152: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1089 - bpp: 0.5636 - mse: 1.3314e-04\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0993 - bpp: 0.5558 - mse: 1.3270e-04\n",
      "Epoch 1153: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0993 - bpp: 0.5558 - mse: 1.3270e-04\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0634 - bpp: 0.5538 - mse: 1.2441e-04\n",
      "Epoch 1154: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0634 - bpp: 0.5538 - mse: 1.2441e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0932 - bpp: 0.5547 - mse: 1.3145e-04\n",
      "Epoch 1155: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.0932 - bpp: 0.5547 - mse: 1.3145e-04\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0013 - bpp: 0.5205 - mse: 1.1737e-04\n",
      "Epoch 1156: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0013 - bpp: 0.5205 - mse: 1.1737e-04\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0255 - bpp: 0.5295 - mse: 1.2109e-04\n",
      "Epoch 1157: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0255 - bpp: 0.5295 - mse: 1.2109e-04\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9989 - bpp: 0.5315 - mse: 1.1409e-04\n",
      "Epoch 1158: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 0.9989 - bpp: 0.5315 - mse: 1.1409e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9767 - bpp: 0.5200 - mse: 1.1150e-04\n",
      "Epoch 1159: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 0.9767 - bpp: 0.5200 - mse: 1.1150e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0665 - bpp: 0.5514 - mse: 1.2576e-04\n",
      "Epoch 1160: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0665 - bpp: 0.5514 - mse: 1.2576e-04\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1139 - bpp: 0.5550 - mse: 1.3646e-04\n",
      "Epoch 1161: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1139 - bpp: 0.5550 - mse: 1.3646e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0692 - bpp: 0.5483 - mse: 1.2717e-04\n",
      "Epoch 1162: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0692 - bpp: 0.5483 - mse: 1.2717e-04\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0223 - bpp: 0.5370 - mse: 1.1849e-04\n",
      "Epoch 1163: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0223 - bpp: 0.5370 - mse: 1.1849e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0101 - bpp: 0.5275 - mse: 1.1782e-04\n",
      "Epoch 1164: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0101 - bpp: 0.5275 - mse: 1.1782e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1017 - bpp: 0.5611 - mse: 1.3196e-04\n",
      "Epoch 1165: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1017 - bpp: 0.5611 - mse: 1.3196e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1053 - bpp: 0.5572 - mse: 1.3380e-04\n",
      "Epoch 1166: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1053 - bpp: 0.5572 - mse: 1.3380e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1014 - bpp: 0.5565 - mse: 1.3303e-04\n",
      "Epoch 1167: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1014 - bpp: 0.5565 - mse: 1.3303e-04\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9972 - bpp: 0.5284 - mse: 1.1445e-04\n",
      "Epoch 1168: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 0.9972 - bpp: 0.5284 - mse: 1.1445e-04\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0403 - bpp: 0.5386 - mse: 1.2249e-04\n",
      "Epoch 1169: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.0403 - bpp: 0.5386 - mse: 1.2249e-04\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0509 - bpp: 0.5335 - mse: 1.2632e-04\n",
      "Epoch 1170: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0509 - bpp: 0.5335 - mse: 1.2632e-04\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0965 - bpp: 0.5571 - mse: 1.3169e-04\n",
      "Epoch 1171: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.0965 - bpp: 0.5571 - mse: 1.3169e-04\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0014 - bpp: 0.5179 - mse: 1.1806e-04\n",
      "Epoch 1172: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0014 - bpp: 0.5179 - mse: 1.1806e-04\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1331 - bpp: 0.5748 - mse: 1.3631e-04\n",
      "Epoch 1173: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1331 - bpp: 0.5748 - mse: 1.3631e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1194 - bpp: 0.5620 - mse: 1.3610e-04\n",
      "Epoch 1174: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 1.1194 - bpp: 0.5620 - mse: 1.3610e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0949 - bpp: 0.5540 - mse: 1.3205e-04\n",
      "Epoch 1175: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0949 - bpp: 0.5540 - mse: 1.3205e-04\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0335 - bpp: 0.5336 - mse: 1.2206e-04\n",
      "Epoch 1176: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0335 - bpp: 0.5336 - mse: 1.2206e-04\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1612 - bpp: 0.5732 - mse: 1.4353e-04\n",
      "Epoch 1177: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1612 - bpp: 0.5732 - mse: 1.4353e-04\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0284 - bpp: 0.5324 - mse: 1.2108e-04\n",
      "Epoch 1178: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 1.0284 - bpp: 0.5324 - mse: 1.2108e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0293 - bpp: 0.5328 - mse: 1.2121e-04\n",
      "Epoch 1179: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0293 - bpp: 0.5328 - mse: 1.2121e-04\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0726 - bpp: 0.5452 - mse: 1.2876e-04\n",
      "Epoch 1180: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.0726 - bpp: 0.5452 - mse: 1.2876e-04\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.5397 - mse: 1.1903e-04\n",
      "Epoch 1181: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0273 - bpp: 0.5397 - mse: 1.1903e-04\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0055 - bpp: 0.5240 - mse: 1.1756e-04\n",
      "Epoch 1182: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0055 - bpp: 0.5240 - mse: 1.1756e-04\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0936 - bpp: 0.5486 - mse: 1.3304e-04\n",
      "Epoch 1183: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0936 - bpp: 0.5486 - mse: 1.3304e-04\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0146 - bpp: 0.5338 - mse: 1.1737e-04\n",
      "Epoch 1184: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.0146 - bpp: 0.5338 - mse: 1.1737e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1038 - bpp: 0.5647 - mse: 1.3162e-04\n",
      "Epoch 1185: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1038 - bpp: 0.5647 - mse: 1.3162e-04\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1178 - bpp: 0.5633 - mse: 1.3539e-04\n",
      "Epoch 1186: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.1178 - bpp: 0.5633 - mse: 1.3539e-04\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0226 - bpp: 0.5392 - mse: 1.1801e-04\n",
      "Epoch 1187: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0226 - bpp: 0.5392 - mse: 1.1801e-04\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1098 - bpp: 0.5629 - mse: 1.3352e-04\n",
      "Epoch 1188: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1098 - bpp: 0.5629 - mse: 1.3352e-04\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0111 - bpp: 0.5256 - mse: 1.1855e-04\n",
      "Epoch 1189: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0111 - bpp: 0.5256 - mse: 1.1855e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0421 - bpp: 0.5345 - mse: 1.2391e-04\n",
      "Epoch 1190: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0421 - bpp: 0.5345 - mse: 1.2391e-04\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1314 - bpp: 0.5681 - mse: 1.3754e-04\n",
      "Epoch 1191: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1314 - bpp: 0.5681 - mse: 1.3754e-04\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9875 - bpp: 0.5253 - mse: 1.1286e-04\n",
      "Epoch 1192: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9875 - bpp: 0.5253 - mse: 1.1286e-04\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0238 - bpp: 0.5371 - mse: 1.1881e-04\n",
      "Epoch 1193: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0238 - bpp: 0.5371 - mse: 1.1881e-04\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0574 - bpp: 0.5400 - mse: 1.2630e-04\n",
      "Epoch 1194: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0574 - bpp: 0.5400 - mse: 1.2630e-04\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.5390 - mse: 1.1949e-04\n",
      "Epoch 1195: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0285 - bpp: 0.5390 - mse: 1.1949e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0569 - bpp: 0.5385 - mse: 1.2656e-04\n",
      "Epoch 1196: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0569 - bpp: 0.5385 - mse: 1.2656e-04\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1320 - bpp: 0.5590 - mse: 1.3991e-04\n",
      "Epoch 1197: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1320 - bpp: 0.5590 - mse: 1.3991e-04\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9949 - bpp: 0.5198 - mse: 1.1599e-04\n",
      "Epoch 1198: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.9949 - bpp: 0.5198 - mse: 1.1599e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1302 - bpp: 0.5752 - mse: 1.3549e-04\n",
      "Epoch 1199: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1302 - bpp: 0.5752 - mse: 1.3549e-04\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1308 - bpp: 0.5707 - mse: 1.3675e-04\n",
      "Epoch 1200: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1308 - bpp: 0.5707 - mse: 1.3675e-04\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0923 - bpp: 0.5642 - mse: 1.2893e-04\n",
      "Epoch 1201: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0923 - bpp: 0.5642 - mse: 1.2893e-04\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0588 - bpp: 0.5450 - mse: 1.2545e-04\n",
      "Epoch 1202: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0588 - bpp: 0.5450 - mse: 1.2545e-04\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0727 - bpp: 0.5438 - mse: 1.2911e-04\n",
      "Epoch 1203: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0727 - bpp: 0.5438 - mse: 1.2911e-04\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0423 - bpp: 0.5330 - mse: 1.2435e-04\n",
      "Epoch 1204: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0423 - bpp: 0.5330 - mse: 1.2435e-04\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.5333 - mse: 1.1952e-04\n",
      "Epoch 1205: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0229 - bpp: 0.5333 - mse: 1.1952e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1581 - bpp: 0.5723 - mse: 1.4302e-04\n",
      "Epoch 1206: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1581 - bpp: 0.5723 - mse: 1.4302e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0353 - bpp: 0.5363 - mse: 1.2184e-04\n",
      "Epoch 1207: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0353 - bpp: 0.5363 - mse: 1.2184e-04\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0277 - bpp: 0.5495 - mse: 1.1674e-04\n",
      "Epoch 1208: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0277 - bpp: 0.5495 - mse: 1.1674e-04\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0753 - bpp: 0.5585 - mse: 1.2619e-04\n",
      "Epoch 1209: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0753 - bpp: 0.5585 - mse: 1.2619e-04\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0827 - bpp: 0.5547 - mse: 1.2892e-04\n",
      "Epoch 1210: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0827 - bpp: 0.5547 - mse: 1.2892e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0065 - bpp: 0.5285 - mse: 1.1671e-04\n",
      "Epoch 1211: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0065 - bpp: 0.5285 - mse: 1.1671e-04\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9512 - bpp: 0.5087 - mse: 1.0805e-04\n",
      "Epoch 1212: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9512 - bpp: 0.5087 - mse: 1.0805e-04\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1368 - bpp: 0.5765 - mse: 1.3678e-04\n",
      "Epoch 1213: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1368 - bpp: 0.5765 - mse: 1.3678e-04\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1284 - bpp: 0.5649 - mse: 1.3758e-04\n",
      "Epoch 1214: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.1284 - bpp: 0.5649 - mse: 1.3758e-04\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1059 - bpp: 0.5633 - mse: 1.3247e-04\n",
      "Epoch 1215: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1059 - bpp: 0.5633 - mse: 1.3247e-04\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1226 - bpp: 0.5591 - mse: 1.3758e-04\n",
      "Epoch 1216: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1226 - bpp: 0.5591 - mse: 1.3758e-04\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0978 - bpp: 0.5613 - mse: 1.3098e-04\n",
      "Epoch 1217: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0978 - bpp: 0.5613 - mse: 1.3098e-04\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0593 - bpp: 0.5505 - mse: 1.2423e-04\n",
      "Epoch 1218: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0593 - bpp: 0.5505 - mse: 1.2423e-04\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0312 - bpp: 0.5397 - mse: 1.2001e-04\n",
      "Epoch 1219: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0312 - bpp: 0.5397 - mse: 1.2001e-04\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0525 - bpp: 0.5503 - mse: 1.2259e-04\n",
      "Epoch 1220: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0525 - bpp: 0.5503 - mse: 1.2259e-04\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1050 - bpp: 0.5500 - mse: 1.3551e-04\n",
      "Epoch 1221: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1050 - bpp: 0.5500 - mse: 1.3551e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0722 - bpp: 0.5532 - mse: 1.2672e-04\n",
      "Epoch 1222: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0722 - bpp: 0.5532 - mse: 1.2672e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0297 - bpp: 0.5333 - mse: 1.2118e-04\n",
      "Epoch 1223: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0297 - bpp: 0.5333 - mse: 1.2118e-04\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1224 - bpp: 0.5677 - mse: 1.3544e-04\n",
      "Epoch 1224: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1224 - bpp: 0.5677 - mse: 1.3544e-04\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1220 - bpp: 0.5702 - mse: 1.3473e-04\n",
      "Epoch 1225: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1220 - bpp: 0.5702 - mse: 1.3473e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0593 - bpp: 0.5414 - mse: 1.2646e-04\n",
      "Epoch 1226: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0593 - bpp: 0.5414 - mse: 1.2646e-04\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1026 - bpp: 0.5580 - mse: 1.3296e-04\n",
      "Epoch 1227: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1026 - bpp: 0.5580 - mse: 1.3296e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0087 - bpp: 0.5263 - mse: 1.1778e-04\n",
      "Epoch 1228: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0087 - bpp: 0.5263 - mse: 1.1778e-04\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1235 - bpp: 0.5700 - mse: 1.3515e-04\n",
      "Epoch 1229: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1235 - bpp: 0.5700 - mse: 1.3515e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0315 - bpp: 0.5365 - mse: 1.2086e-04\n",
      "Epoch 1230: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0315 - bpp: 0.5365 - mse: 1.2086e-04\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0104 - bpp: 0.5349 - mse: 1.1608e-04\n",
      "Epoch 1231: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0104 - bpp: 0.5349 - mse: 1.1608e-04\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0549 - bpp: 0.5466 - mse: 1.2411e-04\n",
      "Epoch 1232: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0549 - bpp: 0.5466 - mse: 1.2411e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1158 - bpp: 0.5636 - mse: 1.3481e-04\n",
      "Epoch 1233: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1158 - bpp: 0.5636 - mse: 1.3481e-04\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0308 - bpp: 0.5250 - mse: 1.2349e-04\n",
      "Epoch 1234: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0308 - bpp: 0.5250 - mse: 1.2349e-04\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1828 - bpp: 0.5864 - mse: 1.4562e-04\n",
      "Epoch 1235: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1828 - bpp: 0.5864 - mse: 1.4562e-04\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0356 - bpp: 0.5415 - mse: 1.2062e-04\n",
      "Epoch 1236: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0356 - bpp: 0.5415 - mse: 1.2062e-04\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0887 - bpp: 0.5588 - mse: 1.2938e-04\n",
      "Epoch 1237: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0887 - bpp: 0.5588 - mse: 1.2938e-04\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1164 - bpp: 0.5633 - mse: 1.3505e-04\n",
      "Epoch 1238: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1164 - bpp: 0.5633 - mse: 1.3505e-04\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0345 - bpp: 0.5381 - mse: 1.2118e-04\n",
      "Epoch 1239: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0345 - bpp: 0.5381 - mse: 1.2118e-04\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1876 - bpp: 0.5877 - mse: 1.4647e-04\n",
      "Epoch 1240: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1876 - bpp: 0.5877 - mse: 1.4647e-04\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0264 - bpp: 0.5345 - mse: 1.2008e-04\n",
      "Epoch 1241: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0264 - bpp: 0.5345 - mse: 1.2008e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1572 - bpp: 0.5753 - mse: 1.4206e-04\n",
      "Epoch 1242: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1572 - bpp: 0.5753 - mse: 1.4206e-04\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9660 - bpp: 0.5037 - mse: 1.1285e-04\n",
      "Epoch 1243: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9660 - bpp: 0.5037 - mse: 1.1285e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0588 - bpp: 0.5444 - mse: 1.2559e-04\n",
      "Epoch 1244: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0588 - bpp: 0.5444 - mse: 1.2559e-04\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0277 - bpp: 0.5354 - mse: 1.2020e-04\n",
      "Epoch 1245: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0277 - bpp: 0.5354 - mse: 1.2020e-04\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0622 - bpp: 0.5550 - mse: 1.2384e-04\n",
      "Epoch 1246: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0622 - bpp: 0.5550 - mse: 1.2384e-04\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0762 - bpp: 0.5499 - mse: 1.2848e-04\n",
      "Epoch 1247: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0762 - bpp: 0.5499 - mse: 1.2848e-04\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1063 - bpp: 0.5548 - mse: 1.3466e-04\n",
      "Epoch 1248: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1063 - bpp: 0.5548 - mse: 1.3466e-04\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0933 - bpp: 0.5593 - mse: 1.3038e-04\n",
      "Epoch 1249: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0933 - bpp: 0.5593 - mse: 1.3038e-04\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0413 - bpp: 0.5335 - mse: 1.2396e-04\n",
      "Epoch 1250: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0413 - bpp: 0.5335 - mse: 1.2396e-04\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1450 - bpp: 0.5704 - mse: 1.4030e-04\n",
      "Epoch 1251: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1450 - bpp: 0.5704 - mse: 1.4030e-04\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0143 - bpp: 0.5306 - mse: 1.1809e-04\n",
      "Epoch 1252: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0143 - bpp: 0.5306 - mse: 1.1809e-04\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1147 - bpp: 0.5627 - mse: 1.3476e-04\n",
      "Epoch 1253: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1147 - bpp: 0.5627 - mse: 1.3476e-04\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0883 - bpp: 0.5624 - mse: 1.2839e-04\n",
      "Epoch 1254: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0883 - bpp: 0.5624 - mse: 1.2839e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5452 - mse: 1.2665e-04\n",
      "Epoch 1255: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0640 - bpp: 0.5452 - mse: 1.2665e-04\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0875 - bpp: 0.5605 - mse: 1.2865e-04\n",
      "Epoch 1256: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0875 - bpp: 0.5605 - mse: 1.2865e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1012 - bpp: 0.5563 - mse: 1.3303e-04\n",
      "Epoch 1257: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1012 - bpp: 0.5563 - mse: 1.3303e-04\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9942 - bpp: 0.5199 - mse: 1.1578e-04\n",
      "Epoch 1258: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 0.9942 - bpp: 0.5199 - mse: 1.1578e-04\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0486 - bpp: 0.5450 - mse: 1.2294e-04\n",
      "Epoch 1259: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0486 - bpp: 0.5450 - mse: 1.2294e-04\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0270 - bpp: 0.5250 - mse: 1.2256e-04\n",
      "Epoch 1260: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0270 - bpp: 0.5250 - mse: 1.2256e-04\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9514 - bpp: 0.5077 - mse: 1.0833e-04\n",
      "Epoch 1261: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 0.9514 - bpp: 0.5077 - mse: 1.0833e-04\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2654 - bpp: 0.6133 - mse: 1.5920e-04\n",
      "Epoch 1262: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2654 - bpp: 0.6133 - mse: 1.5920e-04\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0366 - bpp: 0.5461 - mse: 1.1974e-04\n",
      "Epoch 1263: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.0366 - bpp: 0.5461 - mse: 1.1974e-04\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0796 - bpp: 0.5637 - mse: 1.2595e-04\n",
      "Epoch 1264: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0796 - bpp: 0.5637 - mse: 1.2595e-04\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0599 - bpp: 0.5395 - mse: 1.2704e-04\n",
      "Epoch 1265: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0599 - bpp: 0.5395 - mse: 1.2704e-04\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1457 - bpp: 0.5718 - mse: 1.4010e-04\n",
      "Epoch 1266: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.1457 - bpp: 0.5718 - mse: 1.4010e-04\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0968 - bpp: 0.5575 - mse: 1.3165e-04\n",
      "Epoch 1267: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0968 - bpp: 0.5575 - mse: 1.3165e-04\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0699 - bpp: 0.5473 - mse: 1.2759e-04\n",
      "Epoch 1268: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0699 - bpp: 0.5473 - mse: 1.2759e-04\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1163 - bpp: 0.5680 - mse: 1.3388e-04\n",
      "Epoch 1269: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.1163 - bpp: 0.5680 - mse: 1.3388e-04\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0642 - bpp: 0.5462 - mse: 1.2646e-04\n",
      "Epoch 1270: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0642 - bpp: 0.5462 - mse: 1.2646e-04\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0474 - bpp: 0.5456 - mse: 1.2253e-04\n",
      "Epoch 1271: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0474 - bpp: 0.5456 - mse: 1.2253e-04\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9946 - bpp: 0.5214 - mse: 1.1553e-04\n",
      "Epoch 1272: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9946 - bpp: 0.5214 - mse: 1.1553e-04\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0836 - bpp: 0.5509 - mse: 1.3005e-04\n",
      "Epoch 1273: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0836 - bpp: 0.5509 - mse: 1.3005e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0427 - bpp: 0.5370 - mse: 1.2347e-04\n",
      "Epoch 1274: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0427 - bpp: 0.5370 - mse: 1.2347e-04\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0704 - bpp: 0.5444 - mse: 1.2842e-04\n",
      "Epoch 1275: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0704 - bpp: 0.5444 - mse: 1.2842e-04\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.5277 - mse: 1.2196e-04\n",
      "Epoch 1276: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0273 - bpp: 0.5277 - mse: 1.2196e-04\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0028 - bpp: 0.5310 - mse: 1.1519e-04\n",
      "Epoch 1277: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0028 - bpp: 0.5310 - mse: 1.1519e-04\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9985 - bpp: 0.5287 - mse: 1.1469e-04\n",
      "Epoch 1278: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9985 - bpp: 0.5287 - mse: 1.1469e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5529 - mse: 1.2991e-04\n",
      "Epoch 1279: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0850 - bpp: 0.5529 - mse: 1.2991e-04\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1271 - bpp: 0.5735 - mse: 1.3516e-04\n",
      "Epoch 1280: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1271 - bpp: 0.5735 - mse: 1.3516e-04\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9969 - bpp: 0.5243 - mse: 1.1539e-04\n",
      "Epoch 1281: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.9969 - bpp: 0.5243 - mse: 1.1539e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0395 - bpp: 0.5339 - mse: 1.2343e-04\n",
      "Epoch 1282: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0395 - bpp: 0.5339 - mse: 1.2343e-04\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2177 - bpp: 0.5954 - mse: 1.5193e-04\n",
      "Epoch 1283: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2177 - bpp: 0.5954 - mse: 1.5193e-04\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0632 - bpp: 0.5480 - mse: 1.2577e-04\n",
      "Epoch 1284: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0632 - bpp: 0.5480 - mse: 1.2577e-04\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0785 - bpp: 0.5434 - mse: 1.3064e-04\n",
      "Epoch 1285: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0785 - bpp: 0.5434 - mse: 1.3064e-04\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1375 - bpp: 0.5647 - mse: 1.3985e-04\n",
      "Epoch 1286: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1375 - bpp: 0.5647 - mse: 1.3985e-04\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1003 - bpp: 0.5613 - mse: 1.3159e-04\n",
      "Epoch 1287: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1003 - bpp: 0.5613 - mse: 1.3159e-04\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0603 - bpp: 0.5469 - mse: 1.2535e-04\n",
      "Epoch 1288: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0603 - bpp: 0.5469 - mse: 1.2535e-04\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9964 - bpp: 0.5323 - mse: 1.1329e-04\n",
      "Epoch 1289: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9964 - bpp: 0.5323 - mse: 1.1329e-04\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0328 - bpp: 0.5382 - mse: 1.2073e-04\n",
      "Epoch 1290: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0328 - bpp: 0.5382 - mse: 1.2073e-04\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1539 - bpp: 0.5683 - mse: 1.4296e-04\n",
      "Epoch 1291: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1539 - bpp: 0.5683 - mse: 1.4296e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0559 - bpp: 0.5400 - mse: 1.2597e-04\n",
      "Epoch 1292: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0559 - bpp: 0.5400 - mse: 1.2597e-04\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1394 - bpp: 0.5627 - mse: 1.4080e-04\n",
      "Epoch 1293: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1394 - bpp: 0.5627 - mse: 1.4080e-04\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9975 - bpp: 0.5313 - mse: 1.1381e-04\n",
      "Epoch 1294: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.9975 - bpp: 0.5313 - mse: 1.1381e-04\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0644 - bpp: 0.5499 - mse: 1.2562e-04\n",
      "Epoch 1295: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0644 - bpp: 0.5499 - mse: 1.2562e-04\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1154 - bpp: 0.5634 - mse: 1.3476e-04\n",
      "Epoch 1296: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1154 - bpp: 0.5634 - mse: 1.3476e-04\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0657 - bpp: 0.5477 - mse: 1.2647e-04\n",
      "Epoch 1297: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0657 - bpp: 0.5477 - mse: 1.2647e-04\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1192 - bpp: 0.5537 - mse: 1.3806e-04\n",
      "Epoch 1298: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1192 - bpp: 0.5537 - mse: 1.3806e-04\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5494 - mse: 1.3201e-04\n",
      "Epoch 1299: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0901 - bpp: 0.5494 - mse: 1.3201e-04\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0090 - bpp: 0.5272 - mse: 1.1761e-04\n",
      "Epoch 1300: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0090 - bpp: 0.5272 - mse: 1.1761e-04\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1769 - bpp: 0.5834 - mse: 1.4489e-04\n",
      "Epoch 1301: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1769 - bpp: 0.5834 - mse: 1.4489e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0364 - bpp: 0.5320 - mse: 1.2312e-04\n",
      "Epoch 1302: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0364 - bpp: 0.5320 - mse: 1.2312e-04\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.5281 - mse: 1.2216e-04\n",
      "Epoch 1303: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0285 - bpp: 0.5281 - mse: 1.2216e-04\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1028 - bpp: 0.5581 - mse: 1.3299e-04\n",
      "Epoch 1304: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1028 - bpp: 0.5581 - mse: 1.3299e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0698 - bpp: 0.5498 - mse: 1.2694e-04\n",
      "Epoch 1305: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0698 - bpp: 0.5498 - mse: 1.2694e-04\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0830 - bpp: 0.5614 - mse: 1.2734e-04\n",
      "Epoch 1306: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0830 - bpp: 0.5614 - mse: 1.2734e-04\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0832 - bpp: 0.5626 - mse: 1.2709e-04\n",
      "Epoch 1307: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0832 - bpp: 0.5626 - mse: 1.2709e-04\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0141 - bpp: 0.5355 - mse: 1.1686e-04\n",
      "Epoch 1308: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0141 - bpp: 0.5355 - mse: 1.1686e-04\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0645 - bpp: 0.5473 - mse: 1.2626e-04\n",
      "Epoch 1309: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0645 - bpp: 0.5473 - mse: 1.2626e-04\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0381 - bpp: 0.5401 - mse: 1.2158e-04\n",
      "Epoch 1310: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0381 - bpp: 0.5401 - mse: 1.2158e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0183 - bpp: 0.5398 - mse: 1.1683e-04\n",
      "Epoch 1311: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0183 - bpp: 0.5398 - mse: 1.1683e-04\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0466 - bpp: 0.5353 - mse: 1.2483e-04\n",
      "Epoch 1312: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0466 - bpp: 0.5353 - mse: 1.2483e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9934 - bpp: 0.5199 - mse: 1.1560e-04\n",
      "Epoch 1313: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9934 - bpp: 0.5199 - mse: 1.1560e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0238 - bpp: 0.5359 - mse: 1.1913e-04\n",
      "Epoch 1314: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0238 - bpp: 0.5359 - mse: 1.1913e-04\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0469 - bpp: 0.5339 - mse: 1.2523e-04\n",
      "Epoch 1315: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0469 - bpp: 0.5339 - mse: 1.2523e-04\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0357 - bpp: 0.5437 - mse: 1.2012e-04\n",
      "Epoch 1316: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0357 - bpp: 0.5437 - mse: 1.2012e-04\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9680 - bpp: 0.5219 - mse: 1.0891e-04\n",
      "Epoch 1317: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9680 - bpp: 0.5219 - mse: 1.0891e-04\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0931 - bpp: 0.5564 - mse: 1.3103e-04\n",
      "Epoch 1318: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0931 - bpp: 0.5564 - mse: 1.3103e-04\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0602 - bpp: 0.5510 - mse: 1.2433e-04\n",
      "Epoch 1319: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0602 - bpp: 0.5510 - mse: 1.2433e-04\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0425 - bpp: 0.5414 - mse: 1.2233e-04\n",
      "Epoch 1320: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0425 - bpp: 0.5414 - mse: 1.2233e-04\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0098 - bpp: 0.5348 - mse: 1.1595e-04\n",
      "Epoch 1321: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0098 - bpp: 0.5348 - mse: 1.1595e-04\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0118 - bpp: 0.5252 - mse: 1.1878e-04\n",
      "Epoch 1322: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0118 - bpp: 0.5252 - mse: 1.1878e-04\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.5547 - mse: 1.2877e-04\n",
      "Epoch 1323: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0821 - bpp: 0.5547 - mse: 1.2877e-04\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0740 - bpp: 0.5517 - mse: 1.2753e-04\n",
      "Epoch 1324: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0740 - bpp: 0.5517 - mse: 1.2753e-04\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0380 - bpp: 0.5382 - mse: 1.2202e-04\n",
      "Epoch 1325: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0380 - bpp: 0.5382 - mse: 1.2202e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1197 - bpp: 0.5692 - mse: 1.3440e-04\n",
      "Epoch 1326: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1197 - bpp: 0.5692 - mse: 1.3440e-04\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0213 - bpp: 0.5282 - mse: 1.2039e-04\n",
      "Epoch 1327: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0213 - bpp: 0.5282 - mse: 1.2039e-04\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0449 - bpp: 0.5465 - mse: 1.2168e-04\n",
      "Epoch 1328: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.0449 - bpp: 0.5465 - mse: 1.2168e-04\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9865 - bpp: 0.5170 - mse: 1.1461e-04\n",
      "Epoch 1329: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9865 - bpp: 0.5170 - mse: 1.1461e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0276 - bpp: 0.5361 - mse: 1.2000e-04\n",
      "Epoch 1330: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0276 - bpp: 0.5361 - mse: 1.2000e-04\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0953 - bpp: 0.5501 - mse: 1.3312e-04\n",
      "Epoch 1331: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0953 - bpp: 0.5501 - mse: 1.3312e-04\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1080 - bpp: 0.5539 - mse: 1.3529e-04\n",
      "Epoch 1332: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1080 - bpp: 0.5539 - mse: 1.3529e-04\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1114 - bpp: 0.5601 - mse: 1.3460e-04\n",
      "Epoch 1333: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1114 - bpp: 0.5601 - mse: 1.3460e-04\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1442 - bpp: 0.5798 - mse: 1.3781e-04\n",
      "Epoch 1334: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1442 - bpp: 0.5798 - mse: 1.3781e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0695 - bpp: 0.5475 - mse: 1.2745e-04\n",
      "Epoch 1335: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0695 - bpp: 0.5475 - mse: 1.2745e-04\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0599 - bpp: 0.5504 - mse: 1.2441e-04\n",
      "Epoch 1336: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0599 - bpp: 0.5504 - mse: 1.2441e-04\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0021 - bpp: 0.5289 - mse: 1.1552e-04\n",
      "Epoch 1337: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0021 - bpp: 0.5289 - mse: 1.1552e-04\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9453 - bpp: 0.5083 - mse: 1.0669e-04\n",
      "Epoch 1338: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9453 - bpp: 0.5083 - mse: 1.0669e-04\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9723 - bpp: 0.5206 - mse: 1.1027e-04\n",
      "Epoch 1339: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9723 - bpp: 0.5206 - mse: 1.1027e-04\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9998 - bpp: 0.5332 - mse: 1.1393e-04\n",
      "Epoch 1340: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9998 - bpp: 0.5332 - mse: 1.1393e-04\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0574 - bpp: 0.5421 - mse: 1.2580e-04\n",
      "Epoch 1341: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0574 - bpp: 0.5421 - mse: 1.2580e-04\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0342 - bpp: 0.5369 - mse: 1.2140e-04\n",
      "Epoch 1342: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0342 - bpp: 0.5369 - mse: 1.2140e-04\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9922 - bpp: 0.5186 - mse: 1.1562e-04\n",
      "Epoch 1343: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9922 - bpp: 0.5186 - mse: 1.1562e-04\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9652 - bpp: 0.5129 - mse: 1.1043e-04\n",
      "Epoch 1344: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9652 - bpp: 0.5129 - mse: 1.1043e-04\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0874 - bpp: 0.5519 - mse: 1.3074e-04\n",
      "Epoch 1345: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0874 - bpp: 0.5519 - mse: 1.3074e-04\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9907 - bpp: 0.5339 - mse: 1.1154e-04\n",
      "Epoch 1346: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9907 - bpp: 0.5339 - mse: 1.1154e-04\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5475 - mse: 1.2609e-04\n",
      "Epoch 1347: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0640 - bpp: 0.5475 - mse: 1.2609e-04\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0393 - bpp: 0.5417 - mse: 1.2149e-04\n",
      "Epoch 1348: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0393 - bpp: 0.5417 - mse: 1.2149e-04\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9897 - bpp: 0.5198 - mse: 1.1471e-04\n",
      "Epoch 1349: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9897 - bpp: 0.5198 - mse: 1.1471e-04\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0673 - bpp: 0.5523 - mse: 1.2572e-04\n",
      "Epoch 1350: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0673 - bpp: 0.5523 - mse: 1.2572e-04\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9678 - bpp: 0.5248 - mse: 1.0815e-04\n",
      "Epoch 1351: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9678 - bpp: 0.5248 - mse: 1.0815e-04\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0217 - bpp: 0.5374 - mse: 1.1825e-04\n",
      "Epoch 1352: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0217 - bpp: 0.5374 - mse: 1.1825e-04\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1187 - bpp: 0.5739 - mse: 1.3302e-04\n",
      "Epoch 1353: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1187 - bpp: 0.5739 - mse: 1.3302e-04\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0802 - bpp: 0.5559 - mse: 1.2799e-04\n",
      "Epoch 1354: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0802 - bpp: 0.5559 - mse: 1.2799e-04\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9722 - bpp: 0.5215 - mse: 1.1003e-04\n",
      "Epoch 1355: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9722 - bpp: 0.5215 - mse: 1.1003e-04\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0079 - bpp: 0.5247 - mse: 1.1796e-04\n",
      "Epoch 1356: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0079 - bpp: 0.5247 - mse: 1.1796e-04\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0242 - bpp: 0.5258 - mse: 1.2167e-04\n",
      "Epoch 1357: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0242 - bpp: 0.5258 - mse: 1.2167e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0253 - bpp: 0.5246 - mse: 1.2224e-04\n",
      "Epoch 1358: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0253 - bpp: 0.5246 - mse: 1.2224e-04\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0745 - bpp: 0.5521 - mse: 1.2753e-04\n",
      "Epoch 1359: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0745 - bpp: 0.5521 - mse: 1.2753e-04\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5365 - mse: 1.2224e-04\n",
      "Epoch 1360: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0372 - bpp: 0.5365 - mse: 1.2224e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1441 - bpp: 0.5695 - mse: 1.4028e-04\n",
      "Epoch 1361: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1441 - bpp: 0.5695 - mse: 1.4028e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5389 - mse: 1.2165e-04\n",
      "Epoch 1362: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0372 - bpp: 0.5389 - mse: 1.2165e-04\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0542 - bpp: 0.5447 - mse: 1.2438e-04\n",
      "Epoch 1363: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0542 - bpp: 0.5447 - mse: 1.2438e-04\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1555 - bpp: 0.5864 - mse: 1.3893e-04\n",
      "Epoch 1364: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1555 - bpp: 0.5864 - mse: 1.3893e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.5473 - mse: 1.2707e-04\n",
      "Epoch 1365: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.0678 - bpp: 0.5473 - mse: 1.2707e-04\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0605 - bpp: 0.5470 - mse: 1.2536e-04\n",
      "Epoch 1366: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0605 - bpp: 0.5470 - mse: 1.2536e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0356 - bpp: 0.5426 - mse: 1.2037e-04\n",
      "Epoch 1367: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0356 - bpp: 0.5426 - mse: 1.2037e-04\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0276 - bpp: 0.5251 - mse: 1.2268e-04\n",
      "Epoch 1368: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0276 - bpp: 0.5251 - mse: 1.2268e-04\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0379 - bpp: 0.5454 - mse: 1.2025e-04\n",
      "Epoch 1369: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0379 - bpp: 0.5454 - mse: 1.2025e-04\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1008 - bpp: 0.5582 - mse: 1.3248e-04\n",
      "Epoch 1370: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1008 - bpp: 0.5582 - mse: 1.3248e-04\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1538 - bpp: 0.5882 - mse: 1.3807e-04\n",
      "Epoch 1371: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1538 - bpp: 0.5882 - mse: 1.3807e-04\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0305 - bpp: 0.5336 - mse: 1.2133e-04\n",
      "Epoch 1372: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0305 - bpp: 0.5336 - mse: 1.2133e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0749 - bpp: 0.5501 - mse: 1.2813e-04\n",
      "Epoch 1373: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0749 - bpp: 0.5501 - mse: 1.2813e-04\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0061 - bpp: 0.5312 - mse: 1.1596e-04\n",
      "Epoch 1374: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0061 - bpp: 0.5312 - mse: 1.1596e-04\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0395 - bpp: 0.5324 - mse: 1.2382e-04\n",
      "Epoch 1375: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0395 - bpp: 0.5324 - mse: 1.2382e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5385 - mse: 1.2613e-04\n",
      "Epoch 1376: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0551 - bpp: 0.5385 - mse: 1.2613e-04\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1421 - bpp: 0.5672 - mse: 1.4036e-04\n",
      "Epoch 1377: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1421 - bpp: 0.5672 - mse: 1.4036e-04\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0000 - bpp: 0.5219 - mse: 1.1671e-04\n",
      "Epoch 1378: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.0000 - bpp: 0.5219 - mse: 1.1671e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0975 - bpp: 0.5450 - mse: 1.3488e-04\n",
      "Epoch 1379: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0975 - bpp: 0.5450 - mse: 1.3488e-04\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0011 - bpp: 0.5237 - mse: 1.1655e-04\n",
      "Epoch 1380: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0011 - bpp: 0.5237 - mse: 1.1655e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0250 - bpp: 0.5242 - mse: 1.2226e-04\n",
      "Epoch 1381: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0250 - bpp: 0.5242 - mse: 1.2226e-04\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0269 - bpp: 0.5288 - mse: 1.2160e-04\n",
      "Epoch 1382: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0269 - bpp: 0.5288 - mse: 1.2160e-04\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1267 - bpp: 0.5649 - mse: 1.3714e-04\n",
      "Epoch 1383: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1267 - bpp: 0.5649 - mse: 1.3714e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9924 - bpp: 0.5182 - mse: 1.1577e-04\n",
      "Epoch 1384: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9924 - bpp: 0.5182 - mse: 1.1577e-04\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2248 - bpp: 0.5976 - mse: 1.5311e-04\n",
      "Epoch 1385: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.2248 - bpp: 0.5976 - mse: 1.5311e-04\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0126 - bpp: 0.5287 - mse: 1.1815e-04\n",
      "Epoch 1386: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0126 - bpp: 0.5287 - mse: 1.1815e-04\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9995 - bpp: 0.5170 - mse: 1.1780e-04\n",
      "Epoch 1387: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9995 - bpp: 0.5170 - mse: 1.1780e-04\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0183 - bpp: 0.5306 - mse: 1.1907e-04\n",
      "Epoch 1388: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0183 - bpp: 0.5306 - mse: 1.1907e-04\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0690 - bpp: 0.5482 - mse: 1.2716e-04\n",
      "Epoch 1389: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0690 - bpp: 0.5482 - mse: 1.2716e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0507 - bpp: 0.5440 - mse: 1.2370e-04\n",
      "Epoch 1390: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0507 - bpp: 0.5440 - mse: 1.2370e-04\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9800 - bpp: 0.5246 - mse: 1.1118e-04\n",
      "Epoch 1391: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9800 - bpp: 0.5246 - mse: 1.1118e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1235 - bpp: 0.5626 - mse: 1.3695e-04\n",
      "Epoch 1392: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1235 - bpp: 0.5626 - mse: 1.3695e-04\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0262 - bpp: 0.5389 - mse: 1.1896e-04\n",
      "Epoch 1393: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0262 - bpp: 0.5389 - mse: 1.1896e-04\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9961 - bpp: 0.5305 - mse: 1.1365e-04\n",
      "Epoch 1394: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9961 - bpp: 0.5305 - mse: 1.1365e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0880 - bpp: 0.5605 - mse: 1.2877e-04\n",
      "Epoch 1395: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0880 - bpp: 0.5605 - mse: 1.2877e-04\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5410 - mse: 1.2770e-04\n",
      "Epoch 1396: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0640 - bpp: 0.5410 - mse: 1.2770e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0519 - bpp: 0.5346 - mse: 1.2629e-04\n",
      "Epoch 1397: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0519 - bpp: 0.5346 - mse: 1.2629e-04\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0666 - bpp: 0.5382 - mse: 1.2900e-04\n",
      "Epoch 1398: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0666 - bpp: 0.5382 - mse: 1.2900e-04\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0079 - bpp: 0.5305 - mse: 1.1655e-04\n",
      "Epoch 1399: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0079 - bpp: 0.5305 - mse: 1.1655e-04\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0420 - bpp: 0.5386 - mse: 1.2291e-04\n",
      "Epoch 1400: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0420 - bpp: 0.5386 - mse: 1.2291e-04\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0549 - bpp: 0.5377 - mse: 1.2626e-04\n",
      "Epoch 1401: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0549 - bpp: 0.5377 - mse: 1.2626e-04\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1285 - bpp: 0.5591 - mse: 1.3901e-04\n",
      "Epoch 1402: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1285 - bpp: 0.5591 - mse: 1.3901e-04\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5518 - mse: 1.2288e-04\n",
      "Epoch 1403: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0551 - bpp: 0.5518 - mse: 1.2288e-04\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0587 - bpp: 0.5415 - mse: 1.2627e-04\n",
      "Epoch 1404: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0587 - bpp: 0.5415 - mse: 1.2627e-04\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9874 - bpp: 0.5252 - mse: 1.1283e-04\n",
      "Epoch 1405: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9874 - bpp: 0.5252 - mse: 1.1283e-04\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0081 - bpp: 0.5325 - mse: 1.1612e-04\n",
      "Epoch 1406: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0081 - bpp: 0.5325 - mse: 1.1612e-04\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0852 - bpp: 0.5461 - mse: 1.3162e-04\n",
      "Epoch 1407: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0852 - bpp: 0.5461 - mse: 1.3162e-04\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0692 - bpp: 0.5451 - mse: 1.2798e-04\n",
      "Epoch 1408: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0692 - bpp: 0.5451 - mse: 1.2798e-04\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0015 - bpp: 0.5183 - mse: 1.1798e-04\n",
      "Epoch 1409: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0015 - bpp: 0.5183 - mse: 1.1798e-04\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1005 - bpp: 0.5519 - mse: 1.3392e-04\n",
      "Epoch 1410: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1005 - bpp: 0.5519 - mse: 1.3392e-04\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0566 - bpp: 0.5387 - mse: 1.2645e-04\n",
      "Epoch 1411: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0566 - bpp: 0.5387 - mse: 1.2645e-04\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0142 - bpp: 0.5297 - mse: 1.1828e-04\n",
      "Epoch 1412: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0142 - bpp: 0.5297 - mse: 1.1828e-04\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0320 - bpp: 0.5364 - mse: 1.2100e-04\n",
      "Epoch 1413: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0320 - bpp: 0.5364 - mse: 1.2100e-04\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0858 - bpp: 0.5461 - mse: 1.3178e-04\n",
      "Epoch 1414: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0858 - bpp: 0.5461 - mse: 1.3178e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0286 - bpp: 0.5283 - mse: 1.2213e-04\n",
      "Epoch 1415: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0286 - bpp: 0.5283 - mse: 1.2213e-04\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0282 - bpp: 0.5349 - mse: 1.2044e-04\n",
      "Epoch 1416: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0282 - bpp: 0.5349 - mse: 1.2044e-04\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9958 - bpp: 0.5294 - mse: 1.1387e-04\n",
      "Epoch 1417: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9958 - bpp: 0.5294 - mse: 1.1387e-04\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0537 - bpp: 0.5537 - mse: 1.2209e-04\n",
      "Epoch 1418: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0537 - bpp: 0.5537 - mse: 1.2209e-04\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9957 - bpp: 0.5286 - mse: 1.1404e-04\n",
      "Epoch 1419: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.9957 - bpp: 0.5286 - mse: 1.1404e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0597 - bpp: 0.5418 - mse: 1.2645e-04\n",
      "Epoch 1420: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0597 - bpp: 0.5418 - mse: 1.2645e-04\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0568 - bpp: 0.5443 - mse: 1.2511e-04\n",
      "Epoch 1421: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.0568 - bpp: 0.5443 - mse: 1.2511e-04\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0362 - bpp: 0.5405 - mse: 1.2100e-04\n",
      "Epoch 1422: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0362 - bpp: 0.5405 - mse: 1.2100e-04\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0793 - bpp: 0.5488 - mse: 1.2952e-04\n",
      "Epoch 1423: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0793 - bpp: 0.5488 - mse: 1.2952e-04\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0872 - bpp: 0.5523 - mse: 1.3059e-04\n",
      "Epoch 1424: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0872 - bpp: 0.5523 - mse: 1.3059e-04\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1016 - bpp: 0.5713 - mse: 1.2948e-04\n",
      "Epoch 1425: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1016 - bpp: 0.5713 - mse: 1.2948e-04\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1187 - bpp: 0.5676 - mse: 1.3454e-04\n",
      "Epoch 1426: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1187 - bpp: 0.5676 - mse: 1.3454e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0246 - bpp: 0.5358 - mse: 1.1933e-04\n",
      "Epoch 1427: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0246 - bpp: 0.5358 - mse: 1.1933e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0856 - bpp: 0.5481 - mse: 1.3123e-04\n",
      "Epoch 1428: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0856 - bpp: 0.5481 - mse: 1.3123e-04\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1153 - bpp: 0.5637 - mse: 1.3465e-04\n",
      "Epoch 1429: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1153 - bpp: 0.5637 - mse: 1.3465e-04\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1113 - bpp: 0.5478 - mse: 1.3756e-04\n",
      "Epoch 1430: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1113 - bpp: 0.5478 - mse: 1.3756e-04\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5425 - mse: 1.2515e-04\n",
      "Epoch 1431: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0551 - bpp: 0.5425 - mse: 1.2515e-04\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9979 - bpp: 0.5287 - mse: 1.1455e-04\n",
      "Epoch 1432: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 0.9979 - bpp: 0.5287 - mse: 1.1455e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0525 - bpp: 0.5447 - mse: 1.2396e-04\n",
      "Epoch 1433: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0525 - bpp: 0.5447 - mse: 1.2396e-04\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0517 - bpp: 0.5394 - mse: 1.2508e-04\n",
      "Epoch 1434: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0517 - bpp: 0.5394 - mse: 1.2508e-04\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9803 - bpp: 0.5212 - mse: 1.1207e-04\n",
      "Epoch 1435: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9803 - bpp: 0.5212 - mse: 1.1207e-04\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1060 - bpp: 0.5640 - mse: 1.3233e-04\n",
      "Epoch 1436: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1060 - bpp: 0.5640 - mse: 1.3233e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0565 - bpp: 0.5463 - mse: 1.2456e-04\n",
      "Epoch 1437: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0565 - bpp: 0.5463 - mse: 1.2456e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1101 - bpp: 0.5635 - mse: 1.3343e-04\n",
      "Epoch 1438: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1101 - bpp: 0.5635 - mse: 1.3343e-04\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0150 - bpp: 0.5299 - mse: 1.1842e-04\n",
      "Epoch 1439: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0150 - bpp: 0.5299 - mse: 1.1842e-04\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0486 - bpp: 0.5404 - mse: 1.2409e-04\n",
      "Epoch 1440: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 1.0486 - bpp: 0.5404 - mse: 1.2409e-04\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1529 - bpp: 0.5684 - mse: 1.4270e-04\n",
      "Epoch 1441: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1529 - bpp: 0.5684 - mse: 1.4270e-04\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0614 - bpp: 0.5523 - mse: 1.2428e-04\n",
      "Epoch 1442: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0614 - bpp: 0.5523 - mse: 1.2428e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1083 - bpp: 0.5622 - mse: 1.3333e-04\n",
      "Epoch 1443: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1083 - bpp: 0.5622 - mse: 1.3333e-04\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5508 - mse: 1.2417e-04\n",
      "Epoch 1444: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0594 - bpp: 0.5508 - mse: 1.2417e-04\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0885 - bpp: 0.5621 - mse: 1.2851e-04\n",
      "Epoch 1445: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0885 - bpp: 0.5621 - mse: 1.2851e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5403 - mse: 1.2132e-04\n",
      "Epoch 1446: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0372 - bpp: 0.5403 - mse: 1.2132e-04\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1216 - bpp: 0.5695 - mse: 1.3478e-04\n",
      "Epoch 1447: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1216 - bpp: 0.5695 - mse: 1.3478e-04\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0511 - bpp: 0.5439 - mse: 1.2381e-04\n",
      "Epoch 1448: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0511 - bpp: 0.5439 - mse: 1.2381e-04\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1133 - bpp: 0.5678 - mse: 1.3319e-04\n",
      "Epoch 1449: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1133 - bpp: 0.5678 - mse: 1.3319e-04\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0598 - bpp: 0.5444 - mse: 1.2585e-04\n",
      "Epoch 1450: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0598 - bpp: 0.5444 - mse: 1.2585e-04\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0621 - bpp: 0.5332 - mse: 1.2913e-04\n",
      "Epoch 1451: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0621 - bpp: 0.5332 - mse: 1.2913e-04\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0299 - bpp: 0.5265 - mse: 1.2292e-04\n",
      "Epoch 1452: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0299 - bpp: 0.5265 - mse: 1.2292e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0031 - bpp: 0.5258 - mse: 1.1654e-04\n",
      "Epoch 1453: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0031 - bpp: 0.5258 - mse: 1.1654e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0745 - bpp: 0.5524 - mse: 1.2745e-04\n",
      "Epoch 1454: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0745 - bpp: 0.5524 - mse: 1.2745e-04\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0519 - bpp: 0.5468 - mse: 1.2332e-04\n",
      "Epoch 1455: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0519 - bpp: 0.5468 - mse: 1.2332e-04\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0238 - bpp: 0.5361 - mse: 1.1906e-04\n",
      "Epoch 1456: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0238 - bpp: 0.5361 - mse: 1.1906e-04\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9971 - bpp: 0.5233 - mse: 1.1566e-04\n",
      "Epoch 1457: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9971 - bpp: 0.5233 - mse: 1.1566e-04\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9688 - bpp: 0.5186 - mse: 1.0991e-04\n",
      "Epoch 1458: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9688 - bpp: 0.5186 - mse: 1.0991e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0029 - bpp: 0.5263 - mse: 1.1635e-04\n",
      "Epoch 1459: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0029 - bpp: 0.5263 - mse: 1.1635e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9750 - bpp: 0.5181 - mse: 1.1156e-04\n",
      "Epoch 1460: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9750 - bpp: 0.5181 - mse: 1.1156e-04\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0472 - bpp: 0.5400 - mse: 1.2382e-04\n",
      "Epoch 1461: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0472 - bpp: 0.5400 - mse: 1.2382e-04\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0443 - bpp: 0.5454 - mse: 1.2179e-04\n",
      "Epoch 1462: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0443 - bpp: 0.5454 - mse: 1.2179e-04\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1158 - bpp: 0.5610 - mse: 1.3545e-04\n",
      "Epoch 1463: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1158 - bpp: 0.5610 - mse: 1.3545e-04\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0858 - bpp: 0.5537 - mse: 1.2991e-04\n",
      "Epoch 1464: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0858 - bpp: 0.5537 - mse: 1.2991e-04\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0923 - bpp: 0.5469 - mse: 1.3315e-04\n",
      "Epoch 1465: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0923 - bpp: 0.5469 - mse: 1.3315e-04\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1303 - bpp: 0.5529 - mse: 1.4098e-04\n",
      "Epoch 1466: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1303 - bpp: 0.5529 - mse: 1.4098e-04\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0455 - bpp: 0.5475 - mse: 1.2158e-04\n",
      "Epoch 1467: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0455 - bpp: 0.5475 - mse: 1.2158e-04\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2077 - bpp: 0.5964 - mse: 1.4926e-04\n",
      "Epoch 1468: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.2077 - bpp: 0.5964 - mse: 1.4926e-04\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0888 - bpp: 0.5537 - mse: 1.3066e-04\n",
      "Epoch 1469: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.0888 - bpp: 0.5537 - mse: 1.3066e-04\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9935 - bpp: 0.5252 - mse: 1.1432e-04\n",
      "Epoch 1470: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9935 - bpp: 0.5252 - mse: 1.1432e-04\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 1471: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0850 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8819 - bpp: 0.4831 - mse: 9.7368e-05\n",
      "Epoch 1472: loss improved from 0.93830 to 0.88193, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.8819 - bpp: 0.4831 - mse: 9.7368e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0647 - bpp: 0.5496 - mse: 1.2574e-04\n",
      "Epoch 1473: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0647 - bpp: 0.5496 - mse: 1.2574e-04\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0259 - bpp: 0.5340 - mse: 1.2009e-04\n",
      "Epoch 1474: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0259 - bpp: 0.5340 - mse: 1.2009e-04\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1516 - bpp: 0.5838 - mse: 1.3861e-04\n",
      "Epoch 1475: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1516 - bpp: 0.5838 - mse: 1.3861e-04\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0723 - bpp: 0.5531 - mse: 1.2676e-04\n",
      "Epoch 1476: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0723 - bpp: 0.5531 - mse: 1.2676e-04\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1928 - bpp: 0.5741 - mse: 1.5105e-04\n",
      "Epoch 1477: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1928 - bpp: 0.5741 - mse: 1.5105e-04\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.5522 - mse: 1.3078e-04\n",
      "Epoch 1478: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0879 - bpp: 0.5522 - mse: 1.3078e-04\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.5501 - mse: 1.2639e-04\n",
      "Epoch 1479: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0678 - bpp: 0.5501 - mse: 1.2639e-04\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0493 - bpp: 0.5343 - mse: 1.2572e-04\n",
      "Epoch 1480: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0493 - bpp: 0.5343 - mse: 1.2572e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0838 - bpp: 0.5606 - mse: 1.2774e-04\n",
      "Epoch 1481: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0838 - bpp: 0.5606 - mse: 1.2774e-04\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.5381 - mse: 1.1958e-04\n",
      "Epoch 1482: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0279 - bpp: 0.5381 - mse: 1.1958e-04\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0721 - bpp: 0.5520 - mse: 1.2698e-04\n",
      "Epoch 1483: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0721 - bpp: 0.5520 - mse: 1.2698e-04\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9779 - bpp: 0.5289 - mse: 1.0962e-04\n",
      "Epoch 1484: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 0.9779 - bpp: 0.5289 - mse: 1.0962e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0624 - bpp: 0.5544 - mse: 1.2402e-04\n",
      "Epoch 1485: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0624 - bpp: 0.5544 - mse: 1.2402e-04\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0521 - bpp: 0.5345 - mse: 1.2638e-04\n",
      "Epoch 1486: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 1.0521 - bpp: 0.5345 - mse: 1.2638e-04\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9658 - bpp: 0.5068 - mse: 1.1206e-04\n",
      "Epoch 1487: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9658 - bpp: 0.5068 - mse: 1.1206e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0805 - bpp: 0.5432 - mse: 1.3117e-04\n",
      "Epoch 1488: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0805 - bpp: 0.5432 - mse: 1.3117e-04\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1300 - bpp: 0.5684 - mse: 1.3711e-04\n",
      "Epoch 1489: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.1300 - bpp: 0.5684 - mse: 1.3711e-04\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.5359 - mse: 1.2611e-04\n",
      "Epoch 1490: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0524 - bpp: 0.5359 - mse: 1.2611e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0967 - bpp: 0.5593 - mse: 1.3118e-04\n",
      "Epoch 1491: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0967 - bpp: 0.5593 - mse: 1.3118e-04\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0153 - bpp: 0.5286 - mse: 1.1883e-04\n",
      "Epoch 1492: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0153 - bpp: 0.5286 - mse: 1.1883e-04\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0625 - bpp: 0.5425 - mse: 1.2694e-04\n",
      "Epoch 1493: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0625 - bpp: 0.5425 - mse: 1.2694e-04\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1807 - bpp: 0.5861 - mse: 1.4516e-04\n",
      "Epoch 1494: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1807 - bpp: 0.5861 - mse: 1.4516e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2027 - bpp: 0.6005 - mse: 1.4702e-04\n",
      "Epoch 1495: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.2027 - bpp: 0.6005 - mse: 1.4702e-04\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9574 - bpp: 0.5118 - mse: 1.0880e-04\n",
      "Epoch 1496: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9574 - bpp: 0.5118 - mse: 1.0880e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1282 - bpp: 0.5674 - mse: 1.3692e-04\n",
      "Epoch 1497: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1282 - bpp: 0.5674 - mse: 1.3692e-04\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0491 - bpp: 0.5355 - mse: 1.2538e-04\n",
      "Epoch 1498: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0491 - bpp: 0.5355 - mse: 1.2538e-04\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0694 - bpp: 0.5559 - mse: 1.2535e-04\n",
      "Epoch 1499: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.0694 - bpp: 0.5559 - mse: 1.2535e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9917 - bpp: 0.5232 - mse: 1.1440e-04\n",
      "Epoch 1500: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 0.9917 - bpp: 0.5232 - mse: 1.1440e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_1_layer_call_fn, optical_flow_loss_1_layer_call_and_return_conditional_losses, dwt_1_layer_call_fn, dwt_1_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_12 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_12.compile()\n",
    "trainer_12.fit()\n",
    "trainer_12.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 85.1674 - bpp: 5.3091 - mse: 0.0097\n",
      "Epoch 1: loss improved from inf to 85.16737, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 72s 183ms/step - loss: 85.1674 - bpp: 5.3091 - mse: 0.0097\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.8944 - bpp: 5.1707 - mse: 0.0027\n",
      "Epoch 2: loss improved from 85.16737 to 26.89436, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 26.8944 - bpp: 5.1707 - mse: 0.0027\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.4823 - bpp: 5.0353 - mse: 0.0016\n",
      "Epoch 3: loss improved from 26.89436 to 18.48234, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 18.4823 - bpp: 5.0353 - mse: 0.0016\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.6875 - bpp: 4.9029 - mse: 0.0018\n",
      "Epoch 4: loss did not improve from 18.48234\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 19.6875 - bpp: 4.9029 - mse: 0.0018\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.1279 - bpp: 4.7726 - mse: 0.0014\n",
      "Epoch 5: loss improved from 18.48234 to 16.12789, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 16.1279 - bpp: 4.7726 - mse: 0.0014\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.1944 - bpp: 4.6446 - mse: 0.0012\n",
      "Epoch 6: loss improved from 16.12789 to 14.19441, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 14.1944 - bpp: 4.6446 - mse: 0.0012\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.2647 - bpp: 4.5190 - mse: 0.0013\n",
      "Epoch 7: loss did not improve from 14.19441\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 15.2647 - bpp: 4.5190 - mse: 0.0013\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.7385 - bpp: 4.3958 - mse: 0.0013\n",
      "Epoch 8: loss did not improve from 14.19441\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 14.7385 - bpp: 4.3958 - mse: 0.0013\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.4750 - bpp: 4.2753 - mse: 0.0014\n",
      "Epoch 9: loss did not improve from 14.19441\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 15.4750 - bpp: 4.2753 - mse: 0.0014\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1904 - bpp: 4.1555 - mse: 9.8082e-04\n",
      "Epoch 10: loss improved from 14.19441 to 12.19039, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 12.1904 - bpp: 4.1555 - mse: 9.8082e-04\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.0311 - bpp: 4.0397 - mse: 0.0013\n",
      "Epoch 11: loss did not improve from 12.19039\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 15.0311 - bpp: 4.0397 - mse: 0.0013\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2684 - bpp: 3.9265 - mse: 0.0010\n",
      "Epoch 12: loss did not improve from 12.19039\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 12.2684 - bpp: 3.9265 - mse: 0.0010\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6372 - bpp: 3.8123 - mse: 8.3312e-04\n",
      "Epoch 13: loss improved from 12.19039 to 10.63724, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 10.6372 - bpp: 3.8123 - mse: 8.3312e-04\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6028 - bpp: 3.7043 - mse: 8.4209e-04\n",
      "Epoch 14: loss improved from 10.63724 to 10.60276, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 10.6028 - bpp: 3.7043 - mse: 8.4209e-04\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4313 - bpp: 3.5993 - mse: 9.5606e-04\n",
      "Epoch 15: loss did not improve from 10.60276\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 11.4313 - bpp: 3.5993 - mse: 9.5606e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2169 - bpp: 3.4949 - mse: 8.2055e-04\n",
      "Epoch 16: loss improved from 10.60276 to 10.21692, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 10.2169 - bpp: 3.4949 - mse: 8.2055e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8477 - bpp: 3.3916 - mse: 7.8809e-04\n",
      "Epoch 17: loss improved from 10.21692 to 9.84767, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 9.8477 - bpp: 3.3916 - mse: 7.8809e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3938 - bpp: 3.2943 - mse: 8.6664e-04\n",
      "Epoch 18: loss did not improve from 9.84767\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 10.3938 - bpp: 3.2943 - mse: 8.6664e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1991 - bpp: 3.1951 - mse: 7.3292e-04\n",
      "Epoch 19: loss improved from 9.84767 to 9.19915, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 9.1991 - bpp: 3.1951 - mse: 7.3292e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9130 - bpp: 3.1032 - mse: 8.3127e-04\n",
      "Epoch 20: loss did not improve from 9.19915\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 9.9130 - bpp: 3.1032 - mse: 8.3127e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0619 - bpp: 3.0052 - mse: 6.1728e-04\n",
      "Epoch 21: loss improved from 9.19915 to 8.06191, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 8.0619 - bpp: 3.0052 - mse: 6.1728e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.3990 - bpp: 2.9244 - mse: 0.0010  \n",
      "Epoch 22: loss did not improve from 8.06191\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 11.3990 - bpp: 2.9244 - mse: 0.0010\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3033 - bpp: 2.8468 - mse: 0.0012\n",
      "Epoch 23: loss did not improve from 8.06191\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 12.3033 - bpp: 2.8468 - mse: 0.0012\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6094 - bpp: 2.7403 - mse: 4.7231e-04\n",
      "Epoch 24: loss improved from 8.06191 to 6.60939, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 6.6094 - bpp: 2.7403 - mse: 4.7231e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2264 - bpp: 2.6672 - mse: 5.5654e-04\n",
      "Epoch 25: loss did not improve from 6.60939\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 7.2264 - bpp: 2.6672 - mse: 5.5654e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0370 - bpp: 2.5831 - mse: 5.4369e-04\n",
      "Epoch 26: loss did not improve from 6.60939\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 7.0370 - bpp: 2.5831 - mse: 5.4369e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3726 - bpp: 2.5072 - mse: 4.7186e-04\n",
      "Epoch 27: loss improved from 6.60939 to 6.37262, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 6.3726 - bpp: 2.5072 - mse: 4.7186e-04\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2348 - bpp: 2.4414 - mse: 5.8513e-04\n",
      "Epoch 28: loss did not improve from 6.37262\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 7.2348 - bpp: 2.4414 - mse: 5.8513e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1280 - bpp: 2.3669 - mse: 4.5912e-04\n",
      "Epoch 29: loss improved from 6.37262 to 6.12796, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 6.1280 - bpp: 2.3669 - mse: 4.5912e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5599 - bpp: 2.3101 - mse: 5.1877e-04\n",
      "Epoch 30: loss did not improve from 6.12796\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 6.5599 - bpp: 2.3101 - mse: 5.1877e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9899 - bpp: 2.2430 - mse: 4.5738e-04\n",
      "Epoch 31: loss improved from 6.12796 to 5.98988, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 5.9899 - bpp: 2.2430 - mse: 4.5738e-04\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 141.3153 - bpp: 2.3097 - mse: 0.0170\n",
      "Epoch 32: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 141.3153 - bpp: 2.3097 - mse: 0.0170\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 49.2769 - bpp: 2.3677 - mse: 0.0057\n",
      "Epoch 33: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 49.2769 - bpp: 2.3677 - mse: 0.0057\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.2063 - bpp: 2.2122 - mse: 0.0021\n",
      "Epoch 34: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 19.2063 - bpp: 2.2122 - mse: 0.0021\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.6738 - bpp: 2.1296 - mse: 0.0017\n",
      "Epoch 35: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 15.6738 - bpp: 2.1296 - mse: 0.0017\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.0605 - bpp: 2.0634 - mse: 0.0013\n",
      "Epoch 36: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 13.0605 - bpp: 2.0634 - mse: 0.0013\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.1294 - bpp: 2.0075 - mse: 0.0011\n",
      "Epoch 37: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 11.1294 - bpp: 2.0075 - mse: 0.0011\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3753 - bpp: 1.9577 - mse: 0.0010\n",
      "Epoch 38: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 10.3753 - bpp: 1.9577 - mse: 0.0010\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.0660 - bpp: 1.9464 - mse: 0.0014\n",
      "Epoch 39: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 13.0660 - bpp: 1.9464 - mse: 0.0014\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8389 - bpp: 1.8727 - mse: 8.5037e-04\n",
      "Epoch 40: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 8.8389 - bpp: 1.8727 - mse: 8.5037e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0593 - bpp: 1.8352 - mse: 8.8185e-04\n",
      "Epoch 41: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 9.0593 - bpp: 1.8352 - mse: 8.8185e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4139 - bpp: 1.7890 - mse: 0.0011\n",
      "Epoch 42: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 10.4139 - bpp: 1.7890 - mse: 0.0011\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8999 - bpp: 1.7545 - mse: 7.5016e-04\n",
      "Epoch 43: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 7.8999 - bpp: 1.7545 - mse: 7.5016e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9830 - bpp: 1.7492 - mse: 8.8303e-04\n",
      "Epoch 44: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 8.9830 - bpp: 1.7492 - mse: 8.8303e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4181 - bpp: 1.7031 - mse: 6.9763e-04\n",
      "Epoch 45: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 7.4181 - bpp: 1.7031 - mse: 6.9763e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8157 - bpp: 1.6383 - mse: 6.3201e-04\n",
      "Epoch 46: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 6.8157 - bpp: 1.6383 - mse: 6.3201e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5863 - bpp: 1.5638 - mse: 6.1309e-04\n",
      "Epoch 47: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 6.5863 - bpp: 1.5638 - mse: 6.1309e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0790 - bpp: 1.5926 - mse: 6.6973e-04\n",
      "Epoch 48: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 7.0790 - bpp: 1.5926 - mse: 6.6973e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2816 - bpp: 1.5283 - mse: 5.8024e-04\n",
      "Epoch 49: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 6.2816 - bpp: 1.5283 - mse: 5.8024e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8258 - bpp: 1.4860 - mse: 5.2975e-04\n",
      "Epoch 50: loss improved from 5.98988 to 5.82578, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 5.8258 - bpp: 1.4860 - mse: 5.2975e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9466 - bpp: 1.4741 - mse: 5.4596e-04\n",
      "Epoch 51: loss did not improve from 5.82578\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 5.9466 - bpp: 1.4741 - mse: 5.4596e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6225 - bpp: 1.4452 - mse: 5.0992e-04\n",
      "Epoch 52: loss improved from 5.82578 to 5.62245, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 5.6225 - bpp: 1.4452 - mse: 5.0992e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3137 - bpp: 1.4095 - mse: 4.7659e-04\n",
      "Epoch 53: loss improved from 5.62245 to 5.31374, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 5.3137 - bpp: 1.4095 - mse: 4.7659e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5027 - bpp: 1.4024 - mse: 5.0052e-04\n",
      "Epoch 54: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 5.5027 - bpp: 1.4024 - mse: 5.0052e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3460 - bpp: 1.3901 - mse: 4.8290e-04\n",
      "Epoch 55: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 5.3460 - bpp: 1.3901 - mse: 4.8290e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7867 - bpp: 1.4352 - mse: 5.3120e-04\n",
      "Epoch 56: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.7867 - bpp: 1.4352 - mse: 5.3120e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3418 - bpp: 1.3735 - mse: 4.8441e-04\n",
      "Epoch 57: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 5.3418 - bpp: 1.3735 - mse: 4.8441e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4842 - bpp: 1.3701 - mse: 5.0221e-04\n",
      "Epoch 58: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.4842 - bpp: 1.3701 - mse: 5.0221e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4727 - bpp: 1.3600 - mse: 5.0204e-04\n",
      "Epoch 59: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.4727 - bpp: 1.3600 - mse: 5.0204e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4524 - bpp: 1.2880 - mse: 3.8629e-04\n",
      "Epoch 60: loss improved from 5.31374 to 4.45244, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.4524 - bpp: 1.2880 - mse: 3.8629e-04\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8403 - bpp: 1.3208 - mse: 4.2962e-04\n",
      "Epoch 61: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.8403 - bpp: 1.3208 - mse: 4.2962e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9502 - bpp: 1.3146 - mse: 4.4380e-04\n",
      "Epoch 62: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 4.9502 - bpp: 1.3146 - mse: 4.4380e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7700 - bpp: 1.3051 - mse: 4.2296e-04\n",
      "Epoch 63: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.7700 - bpp: 1.3051 - mse: 4.2296e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8391 - bpp: 1.3114 - mse: 4.3063e-04\n",
      "Epoch 64: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 4.8391 - bpp: 1.3114 - mse: 4.3063e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3976 - bpp: 1.2567 - mse: 3.8341e-04\n",
      "Epoch 65: loss improved from 4.45244 to 4.39755, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.3976 - bpp: 1.2567 - mse: 3.8341e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9703 - bpp: 1.3104 - mse: 4.4677e-04\n",
      "Epoch 66: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.9703 - bpp: 1.3104 - mse: 4.4677e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9047 - bpp: 1.2493 - mse: 4.4621e-04\n",
      "Epoch 67: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.9047 - bpp: 1.2493 - mse: 4.4621e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6667 - bpp: 1.2796 - mse: 4.1347e-04\n",
      "Epoch 68: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.6667 - bpp: 1.2796 - mse: 4.1347e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6131 - bpp: 1.2596 - mse: 4.0936e-04\n",
      "Epoch 69: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.6131 - bpp: 1.2596 - mse: 4.0936e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5435 - bpp: 1.2366 - mse: 4.0367e-04\n",
      "Epoch 70: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.5435 - bpp: 1.2366 - mse: 4.0367e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1378 - bpp: 1.2202 - mse: 3.5615e-04\n",
      "Epoch 71: loss improved from 4.39755 to 4.13780, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.1378 - bpp: 1.2202 - mse: 3.5615e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1006 - bpp: 1.2201 - mse: 3.5162e-04\n",
      "Epoch 72: loss improved from 4.13780 to 4.10061, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 4.1006 - bpp: 1.2201 - mse: 3.5162e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2948 - bpp: 1.2363 - mse: 3.7336e-04\n",
      "Epoch 73: loss did not improve from 4.10061\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.2948 - bpp: 1.2363 - mse: 3.7336e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9568 - bpp: 1.2009 - mse: 3.3641e-04\n",
      "Epoch 74: loss improved from 4.10061 to 3.95679, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 242ms/step - loss: 3.9568 - bpp: 1.2009 - mse: 3.3641e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1626 - bpp: 1.2484 - mse: 3.5574e-04\n",
      "Epoch 75: loss did not improve from 3.95679\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.1626 - bpp: 1.2484 - mse: 3.5574e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1499 - bpp: 1.2015 - mse: 3.5991e-04\n",
      "Epoch 76: loss did not improve from 3.95679\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.1499 - bpp: 1.2015 - mse: 3.5991e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6699 - bpp: 1.1857 - mse: 3.0325e-04\n",
      "Epoch 77: loss improved from 3.95679 to 3.66990, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.6699 - bpp: 1.1857 - mse: 3.0325e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9643 - bpp: 1.2138 - mse: 3.3575e-04\n",
      "Epoch 78: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.9643 - bpp: 1.2138 - mse: 3.3575e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8808 - bpp: 1.1992 - mse: 3.2734e-04\n",
      "Epoch 79: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.8808 - bpp: 1.1992 - mse: 3.2734e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9813 - bpp: 1.2004 - mse: 3.3946e-04\n",
      "Epoch 80: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 3.9813 - bpp: 1.2004 - mse: 3.3946e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9985 - bpp: 1.2050 - mse: 3.4100e-04\n",
      "Epoch 81: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.9985 - bpp: 1.2050 - mse: 3.4100e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0266 - bpp: 1.2023 - mse: 3.4476e-04\n",
      "Epoch 82: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 4.0266 - bpp: 1.2023 - mse: 3.4476e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5693 - bpp: 1.1768 - mse: 2.9205e-04\n",
      "Epoch 83: loss improved from 3.66990 to 3.56931, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5693 - bpp: 1.1768 - mse: 2.9205e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0489 - bpp: 1.2030 - mse: 3.4739e-04\n",
      "Epoch 84: loss did not improve from 3.56931\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.0489 - bpp: 1.2030 - mse: 3.4739e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4248 - bpp: 1.1517 - mse: 2.7748e-04\n",
      "Epoch 85: loss improved from 3.56931 to 3.42485, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4248 - bpp: 1.1517 - mse: 2.7748e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4257 - bpp: 1.1687 - mse: 2.7552e-04\n",
      "Epoch 86: loss did not improve from 3.42485\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.4257 - bpp: 1.1687 - mse: 2.7552e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7657 - bpp: 1.1777 - mse: 3.1592e-04\n",
      "Epoch 87: loss did not improve from 3.42485\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7657 - bpp: 1.1777 - mse: 3.1592e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2940 - bpp: 1.1548 - mse: 2.6112e-04\n",
      "Epoch 88: loss improved from 3.42485 to 3.29395, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.2940 - bpp: 1.1548 - mse: 2.6112e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4713 - bpp: 1.1541 - mse: 2.8287e-04\n",
      "Epoch 89: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.4713 - bpp: 1.1541 - mse: 2.8287e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9899 - bpp: 1.3895 - mse: 9.2777e-04\n",
      "Epoch 90: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 8.9899 - bpp: 1.3895 - mse: 9.2777e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1444 - bpp: 1.2205 - mse: 3.5693e-04\n",
      "Epoch 91: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.1444 - bpp: 1.2205 - mse: 3.5693e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8057 - bpp: 1.1939 - mse: 3.1882e-04\n",
      "Epoch 92: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.8057 - bpp: 1.1939 - mse: 3.1882e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4397 - bpp: 1.1527 - mse: 2.7917e-04\n",
      "Epoch 93: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4397 - bpp: 1.1527 - mse: 2.7917e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3314 - bpp: 1.1116 - mse: 2.7097e-04\n",
      "Epoch 94: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3314 - bpp: 1.1116 - mse: 2.7097e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2551 - bpp: 1.1257 - mse: 2.5994e-04\n",
      "Epoch 95: loss improved from 3.29395 to 3.25510, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2551 - bpp: 1.1257 - mse: 2.5994e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2429 - bpp: 1.1605 - mse: 2.5419e-04\n",
      "Epoch 96: loss improved from 3.25510 to 3.24288, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2429 - bpp: 1.1605 - mse: 2.5419e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4665 - bpp: 1.1661 - mse: 2.8081e-04\n",
      "Epoch 97: loss did not improve from 3.24288\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.4665 - bpp: 1.1661 - mse: 2.8081e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1847 - bpp: 1.1212 - mse: 2.5189e-04\n",
      "Epoch 98: loss improved from 3.24288 to 3.18472, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.1847 - bpp: 1.1212 - mse: 2.5189e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3540 - bpp: 1.1488 - mse: 2.6919e-04\n",
      "Epoch 99: loss did not improve from 3.18472\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3540 - bpp: 1.1488 - mse: 2.6919e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1016 - bpp: 1.1248 - mse: 2.4131e-04\n",
      "Epoch 100: loss improved from 3.18472 to 3.10164, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1016 - bpp: 1.1248 - mse: 2.4131e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3583 - bpp: 1.1389 - mse: 2.7092e-04\n",
      "Epoch 101: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3583 - bpp: 1.1389 - mse: 2.7092e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2388 - bpp: 1.1570 - mse: 2.5412e-04\n",
      "Epoch 102: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2388 - bpp: 1.1570 - mse: 2.5412e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.8232 - bpp: 1.4129 - mse: 0.0014\n",
      "Epoch 103: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 12.8232 - bpp: 1.4129 - mse: 0.0014\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0910 - bpp: 1.2558 - mse: 3.4610e-04\n",
      "Epoch 104: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.0910 - bpp: 1.2558 - mse: 3.4610e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9235 - bpp: 1.2335 - mse: 3.2837e-04\n",
      "Epoch 105: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.9235 - bpp: 1.2335 - mse: 3.2837e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3616 - bpp: 1.1778 - mse: 2.6658e-04\n",
      "Epoch 106: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3616 - bpp: 1.1778 - mse: 2.6658e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0366 - bpp: 1.1045 - mse: 2.3585e-04\n",
      "Epoch 107: loss improved from 3.10164 to 3.03663, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0366 - bpp: 1.1045 - mse: 2.3585e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0509 - bpp: 1.1143 - mse: 2.3640e-04\n",
      "Epoch 108: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.0509 - bpp: 1.1143 - mse: 2.3640e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1314 - bpp: 1.1143 - mse: 2.4622e-04\n",
      "Epoch 109: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1314 - bpp: 1.1143 - mse: 2.4622e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1605 - bpp: 1.1263 - mse: 2.4832e-04\n",
      "Epoch 110: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1605 - bpp: 1.1263 - mse: 2.4832e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0724 - bpp: 1.1259 - mse: 2.3761e-04\n",
      "Epoch 111: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.0724 - bpp: 1.1259 - mse: 2.3761e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2807 - bpp: 1.1547 - mse: 2.5953e-04\n",
      "Epoch 112: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2807 - bpp: 1.1547 - mse: 2.5953e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1538 - bpp: 1.1258 - mse: 2.4756e-04\n",
      "Epoch 113: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 233ms/step - loss: 3.1538 - bpp: 1.1258 - mse: 2.4756e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2315 - bpp: 1.1359 - mse: 2.5581e-04\n",
      "Epoch 114: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2315 - bpp: 1.1359 - mse: 2.5581e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1119 - bpp: 1.0916 - mse: 2.4662e-04\n",
      "Epoch 115: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.1119 - bpp: 1.0916 - mse: 2.4662e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0637 - bpp: 1.1332 - mse: 2.3566e-04\n",
      "Epoch 116: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.0637 - bpp: 1.1332 - mse: 2.3566e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3637 - bpp: 1.1457 - mse: 2.7075e-04\n",
      "Epoch 117: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3637 - bpp: 1.1457 - mse: 2.7075e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1365 - bpp: 1.1100 - mse: 2.4738e-04\n",
      "Epoch 118: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1365 - bpp: 1.1100 - mse: 2.4738e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8306 - bpp: 1.0696 - mse: 2.1497e-04\n",
      "Epoch 119: loss improved from 3.03663 to 2.83058, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.8306 - bpp: 1.0696 - mse: 2.1497e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0569 - bpp: 1.1220 - mse: 2.3619e-04\n",
      "Epoch 120: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0569 - bpp: 1.1220 - mse: 2.3619e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9025 - bpp: 1.0800 - mse: 2.2247e-04\n",
      "Epoch 121: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 2.9025 - bpp: 1.0800 - mse: 2.2247e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1629 - bpp: 1.1150 - mse: 2.4998e-04\n",
      "Epoch 122: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1629 - bpp: 1.1150 - mse: 2.4998e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0464 - bpp: 1.1200 - mse: 2.3515e-04\n",
      "Epoch 123: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0464 - bpp: 1.1200 - mse: 2.3515e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9641 - bpp: 1.0973 - mse: 2.2789e-04\n",
      "Epoch 124: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9641 - bpp: 1.0973 - mse: 2.2789e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1519 - bpp: 1.1279 - mse: 2.4706e-04\n",
      "Epoch 125: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1519 - bpp: 1.1279 - mse: 2.4706e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0040 - bpp: 1.2930 - mse: 9.4128e-04\n",
      "Epoch 126: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 9.0040 - bpp: 1.2930 - mse: 9.4128e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7551 - bpp: 1.1740 - mse: 3.1507e-04\n",
      "Epoch 127: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.7551 - bpp: 1.1740 - mse: 3.1507e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1946 - bpp: 1.1457 - mse: 2.5012e-04\n",
      "Epoch 128: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1946 - bpp: 1.1457 - mse: 2.5012e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2436 - bpp: 1.1535 - mse: 2.5513e-04\n",
      "Epoch 129: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.2436 - bpp: 1.1535 - mse: 2.5513e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4344 - bpp: 1.1578 - mse: 2.7791e-04\n",
      "Epoch 130: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.4344 - bpp: 1.1578 - mse: 2.7791e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9728 - bpp: 1.1180 - mse: 2.2641e-04\n",
      "Epoch 131: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9728 - bpp: 1.1180 - mse: 2.2641e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2360 - bpp: 1.1125 - mse: 2.5921e-04\n",
      "Epoch 132: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2360 - bpp: 1.1125 - mse: 2.5921e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9380 - bpp: 1.1092 - mse: 2.2325e-04\n",
      "Epoch 133: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9380 - bpp: 1.1092 - mse: 2.2325e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9654 - bpp: 1.0877 - mse: 2.2921e-04\n",
      "Epoch 134: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9654 - bpp: 1.0877 - mse: 2.2921e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9479 - bpp: 1.0832 - mse: 2.2763e-04\n",
      "Epoch 135: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9479 - bpp: 1.0832 - mse: 2.2763e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0716 - bpp: 1.1374 - mse: 2.3612e-04\n",
      "Epoch 136: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0716 - bpp: 1.1374 - mse: 2.3612e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9645 - bpp: 1.0938 - mse: 2.2836e-04\n",
      "Epoch 137: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.9645 - bpp: 1.0938 - mse: 2.2836e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6036 - bpp: 1.0508 - mse: 1.8955e-04\n",
      "Epoch 138: loss improved from 2.83058 to 2.60360, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.6036 - bpp: 1.0508 - mse: 1.8955e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5070 - bpp: 1.0409 - mse: 1.7896e-04\n",
      "Epoch 139: loss improved from 2.60360 to 2.50696, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.5070 - bpp: 1.0409 - mse: 1.7896e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8283 - bpp: 1.0880 - mse: 2.1243e-04\n",
      "Epoch 140: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8283 - bpp: 1.0880 - mse: 2.1243e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1821 - bpp: 1.1020 - mse: 2.5393e-04\n",
      "Epoch 141: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1821 - bpp: 1.1020 - mse: 2.5393e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8671 - bpp: 1.0795 - mse: 2.1822e-04\n",
      "Epoch 142: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.8671 - bpp: 1.0795 - mse: 2.1822e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6372 - bpp: 1.0311 - mse: 1.9606e-04\n",
      "Epoch 143: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.6372 - bpp: 1.0311 - mse: 1.9606e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1040 - bpp: 1.1392 - mse: 4.8398e-04\n",
      "Epoch 144: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 5.1040 - bpp: 1.1392 - mse: 4.8398e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8648 - bpp: 1.3523 - mse: 0.0012\n",
      "Epoch 145: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 10.8648 - bpp: 1.3523 - mse: 0.0012\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2063 - bpp: 1.1128 - mse: 2.5556e-04\n",
      "Epoch 146: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2063 - bpp: 1.1128 - mse: 2.5556e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9226 - bpp: 1.0941 - mse: 2.2321e-04\n",
      "Epoch 147: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.9226 - bpp: 1.0941 - mse: 2.2321e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1129 - bpp: 1.1365 - mse: 2.4127e-04\n",
      "Epoch 148: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1129 - bpp: 1.1365 - mse: 2.4127e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8764 - bpp: 1.1137 - mse: 2.1517e-04\n",
      "Epoch 149: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.8764 - bpp: 1.1137 - mse: 2.1517e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5430 - bpp: 1.0469 - mse: 1.8263e-04\n",
      "Epoch 150: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.5430 - bpp: 1.0469 - mse: 1.8263e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2949 - bpp: 1.1579 - mse: 2.6086e-04\n",
      "Epoch 151: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.2949 - bpp: 1.1579 - mse: 2.6086e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7348 - bpp: 1.0713 - mse: 2.0306e-04\n",
      "Epoch 152: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7348 - bpp: 1.0713 - mse: 2.0306e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9855 - bpp: 1.0929 - mse: 2.3104e-04\n",
      "Epoch 153: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.9855 - bpp: 1.0929 - mse: 2.3104e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5444 - bpp: 1.0579 - mse: 1.8146e-04\n",
      "Epoch 154: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.5444 - bpp: 1.0579 - mse: 1.8146e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6564 - bpp: 1.0566 - mse: 1.9528e-04\n",
      "Epoch 155: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.6564 - bpp: 1.0566 - mse: 1.9528e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7921 - bpp: 1.0688 - mse: 2.1037e-04\n",
      "Epoch 156: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.7921 - bpp: 1.0688 - mse: 2.1037e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7771 - bpp: 1.0976 - mse: 2.0502e-04\n",
      "Epoch 157: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.7771 - bpp: 1.0976 - mse: 2.0502e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3733 - bpp: 1.0245 - mse: 1.6465e-04\n",
      "Epoch 158: loss improved from 2.50696 to 2.37328, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.3733 - bpp: 1.0245 - mse: 1.6465e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7222 - bpp: 1.0685 - mse: 2.0188e-04\n",
      "Epoch 159: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7222 - bpp: 1.0685 - mse: 2.0188e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7108 - bpp: 1.0727 - mse: 1.9996e-04\n",
      "Epoch 160: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7108 - bpp: 1.0727 - mse: 1.9996e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8494 - bpp: 1.0714 - mse: 2.1704e-04\n",
      "Epoch 161: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.8494 - bpp: 1.0714 - mse: 2.1704e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6968 - bpp: 1.0278 - mse: 2.0374e-04\n",
      "Epoch 162: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.6968 - bpp: 1.0278 - mse: 2.0374e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5536 - bpp: 1.0369 - mse: 1.8515e-04\n",
      "Epoch 163: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.5536 - bpp: 1.0369 - mse: 1.8515e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5715 - bpp: 1.0471 - mse: 1.8608e-04\n",
      "Epoch 164: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.5715 - bpp: 1.0471 - mse: 1.8608e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5346 - bpp: 1.0529 - mse: 1.8087e-04\n",
      "Epoch 165: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.5346 - bpp: 1.0529 - mse: 1.8087e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4985 - bpp: 1.0286 - mse: 1.7943e-04\n",
      "Epoch 166: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.4985 - bpp: 1.0286 - mse: 1.7943e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9327 - bpp: 1.0797 - mse: 2.2620e-04\n",
      "Epoch 167: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.9327 - bpp: 1.0797 - mse: 2.2620e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5135 - bpp: 1.0215 - mse: 1.8212e-04\n",
      "Epoch 168: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.5135 - bpp: 1.0215 - mse: 1.8212e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0687 - bpp: 1.1644 - mse: 4.7660e-04\n",
      "Epoch 169: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 5.0687 - bpp: 1.1644 - mse: 4.7660e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9457 - bpp: 1.0833 - mse: 2.2735e-04\n",
      "Epoch 170: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9457 - bpp: 1.0833 - mse: 2.2735e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6619 - bpp: 1.0295 - mse: 1.9926e-04\n",
      "Epoch 171: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.6619 - bpp: 1.0295 - mse: 1.9926e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7935 - bpp: 1.0552 - mse: 2.1220e-04\n",
      "Epoch 172: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.7935 - bpp: 1.0552 - mse: 2.1220e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6965 - bpp: 1.0215 - mse: 2.0446e-04\n",
      "Epoch 173: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.6965 - bpp: 1.0215 - mse: 2.0446e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4958 - bpp: 1.0081 - mse: 1.8161e-04\n",
      "Epoch 174: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.4958 - bpp: 1.0081 - mse: 1.8161e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5883 - bpp: 1.0285 - mse: 1.9040e-04\n",
      "Epoch 175: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.5883 - bpp: 1.0285 - mse: 1.9040e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5803 - bpp: 1.0005 - mse: 1.9284e-04\n",
      "Epoch 176: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.5803 - bpp: 1.0005 - mse: 1.9284e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4880 - bpp: 1.0330 - mse: 1.7761e-04\n",
      "Epoch 177: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.4880 - bpp: 1.0330 - mse: 1.7761e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4309 - bpp: 1.0102 - mse: 1.7342e-04\n",
      "Epoch 178: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.4309 - bpp: 1.0102 - mse: 1.7342e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4985 - bpp: 0.9952 - mse: 1.8351e-04\n",
      "Epoch 179: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.4985 - bpp: 0.9952 - mse: 1.8351e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5311 - bpp: 0.9907 - mse: 1.8804e-04\n",
      "Epoch 180: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.5311 - bpp: 0.9907 - mse: 1.8804e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2493 - bpp: 0.9852 - mse: 1.5431e-04\n",
      "Epoch 181: loss improved from 2.37328 to 2.24927, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2493 - bpp: 0.9852 - mse: 1.5431e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5610 - bpp: 1.0200 - mse: 1.8811e-04\n",
      "Epoch 182: loss did not improve from 2.24927\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.5610 - bpp: 1.0200 - mse: 1.8811e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4470 - bpp: 0.9784 - mse: 1.7927e-04\n",
      "Epoch 183: loss did not improve from 2.24927\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.4470 - bpp: 0.9784 - mse: 1.7927e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2235 - bpp: 0.9590 - mse: 1.5436e-04\n",
      "Epoch 184: loss improved from 2.24927 to 2.22350, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.2235 - bpp: 0.9590 - mse: 1.5436e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4175 - bpp: 0.9700 - mse: 1.7670e-04\n",
      "Epoch 185: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 2.4175 - bpp: 0.9700 - mse: 1.7670e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.3372 - bpp: 1.2615 - mse: 0.0018\n",
      "Epoch 186: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 16.3372 - bpp: 1.2615 - mse: 0.0018\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6925 - bpp: 1.2071 - mse: 4.2547e-04\n",
      "Epoch 187: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.6925 - bpp: 1.2071 - mse: 4.2547e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2964 - bpp: 1.0952 - mse: 2.6870e-04\n",
      "Epoch 188: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2964 - bpp: 1.0952 - mse: 2.6870e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9347 - bpp: 1.0724 - mse: 2.2733e-04\n",
      "Epoch 189: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9347 - bpp: 1.0724 - mse: 2.2733e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9774 - bpp: 1.0837 - mse: 2.3116e-04\n",
      "Epoch 190: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.9774 - bpp: 1.0837 - mse: 2.3116e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7241 - bpp: 1.0560 - mse: 2.0363e-04\n",
      "Epoch 191: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.7241 - bpp: 1.0560 - mse: 2.0363e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9318 - bpp: 1.0883 - mse: 2.2505e-04\n",
      "Epoch 192: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.9318 - bpp: 1.0883 - mse: 2.2505e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3393 - bpp: 1.0088 - mse: 1.6242e-04\n",
      "Epoch 193: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.3393 - bpp: 1.0088 - mse: 1.6242e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5808 - bpp: 1.0476 - mse: 1.8716e-04\n",
      "Epoch 194: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.5808 - bpp: 1.0476 - mse: 1.8716e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9886 - bpp: 1.0806 - mse: 2.3291e-04\n",
      "Epoch 195: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9886 - bpp: 1.0806 - mse: 2.3291e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4693 - bpp: 1.0064 - mse: 1.7858e-04\n",
      "Epoch 196: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.4693 - bpp: 1.0064 - mse: 1.7858e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4938 - bpp: 1.0105 - mse: 1.8107e-04\n",
      "Epoch 197: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.4938 - bpp: 1.0105 - mse: 1.8107e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4982 - bpp: 1.0230 - mse: 1.8007e-04\n",
      "Epoch 198: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.4982 - bpp: 1.0230 - mse: 1.8007e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5712 - bpp: 1.0247 - mse: 1.8878e-04\n",
      "Epoch 199: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.5712 - bpp: 1.0247 - mse: 1.8878e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4700 - bpp: 1.0265 - mse: 1.7620e-04\n",
      "Epoch 200: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.4700 - bpp: 1.0265 - mse: 1.7620e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6182 - bpp: 1.0165 - mse: 1.9552e-04\n",
      "Epoch 201: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.6182 - bpp: 1.0165 - mse: 1.9552e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6143 - bpp: 1.0347 - mse: 1.9282e-04\n",
      "Epoch 202: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.6143 - bpp: 1.0347 - mse: 1.9282e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3972 - bpp: 0.9877 - mse: 1.7206e-04\n",
      "Epoch 203: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.3972 - bpp: 0.9877 - mse: 1.7206e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4176 - bpp: 1.0015 - mse: 1.7286e-04\n",
      "Epoch 204: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.4176 - bpp: 1.0015 - mse: 1.7286e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4182 - bpp: 0.9823 - mse: 1.7527e-04\n",
      "Epoch 205: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4182 - bpp: 0.9823 - mse: 1.7527e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4194 - bpp: 1.0019 - mse: 1.7303e-04\n",
      "Epoch 206: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.4194 - bpp: 1.0019 - mse: 1.7303e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2601 - bpp: 1.0009 - mse: 1.5371e-04\n",
      "Epoch 207: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.2601 - bpp: 1.0009 - mse: 1.5371e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2534 - bpp: 0.9682 - mse: 1.5688e-04\n",
      "Epoch 208: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.2534 - bpp: 0.9682 - mse: 1.5688e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8160 - bpp: 1.0176 - mse: 2.1953e-04\n",
      "Epoch 209: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.8160 - bpp: 1.0176 - mse: 2.1953e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2709 - bpp: 0.9569 - mse: 1.6040e-04\n",
      "Epoch 210: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.2709 - bpp: 0.9569 - mse: 1.6040e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4853 - bpp: 1.0018 - mse: 1.8109e-04\n",
      "Epoch 211: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.4853 - bpp: 1.0018 - mse: 1.8109e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1670 - bpp: 0.9750 - mse: 1.4550e-04\n",
      "Epoch 212: loss improved from 2.22350 to 2.16699, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.1670 - bpp: 0.9750 - mse: 1.4550e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1683 - bpp: 0.9538 - mse: 1.4825e-04\n",
      "Epoch 213: loss did not improve from 2.16699\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.1683 - bpp: 0.9538 - mse: 1.4825e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5860 - bpp: 1.0122 - mse: 1.9211e-04\n",
      "Epoch 214: loss did not improve from 2.16699\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.5860 - bpp: 1.0122 - mse: 1.9211e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1515 - bpp: 0.9547 - mse: 1.4609e-04\n",
      "Epoch 215: loss improved from 2.16699 to 2.15146, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.1515 - bpp: 0.9547 - mse: 1.4609e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3605 - bpp: 0.9636 - mse: 1.7051e-04\n",
      "Epoch 216: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.3605 - bpp: 0.9636 - mse: 1.7051e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3337 - bpp: 0.9689 - mse: 1.6660e-04\n",
      "Epoch 217: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 2.3337 - bpp: 0.9689 - mse: 1.6660e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0340 - bpp: 1.1783 - mse: 0.0012\n",
      "Epoch 218: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 11.0340 - bpp: 1.1783 - mse: 0.0012\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1823 - bpp: 1.1191 - mse: 3.7392e-04\n",
      "Epoch 219: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.1823 - bpp: 1.1191 - mse: 3.7392e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9653 - bpp: 1.0676 - mse: 2.3165e-04\n",
      "Epoch 220: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9653 - bpp: 1.0676 - mse: 2.3165e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4091 - bpp: 1.0055 - mse: 1.7133e-04\n",
      "Epoch 221: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.4091 - bpp: 1.0055 - mse: 1.7133e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8078 - bpp: 1.0356 - mse: 2.1633e-04\n",
      "Epoch 222: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.8078 - bpp: 1.0356 - mse: 2.1633e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5411 - bpp: 1.0253 - mse: 1.8503e-04\n",
      "Epoch 223: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.5411 - bpp: 1.0253 - mse: 1.8503e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3528 - bpp: 0.9928 - mse: 1.6601e-04\n",
      "Epoch 224: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.3528 - bpp: 0.9928 - mse: 1.6601e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6545 - bpp: 1.0172 - mse: 1.9987e-04\n",
      "Epoch 225: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.6545 - bpp: 1.0172 - mse: 1.9987e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5495 - bpp: 1.0192 - mse: 1.8681e-04\n",
      "Epoch 226: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.5495 - bpp: 1.0192 - mse: 1.8681e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3041 - bpp: 0.9702 - mse: 1.6283e-04\n",
      "Epoch 227: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.3041 - bpp: 0.9702 - mse: 1.6283e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1726 - bpp: 0.9555 - mse: 1.4857e-04\n",
      "Epoch 228: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.1726 - bpp: 0.9555 - mse: 1.4857e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4155 - bpp: 0.9897 - mse: 1.7405e-04\n",
      "Epoch 229: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.4155 - bpp: 0.9897 - mse: 1.7405e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4559 - bpp: 0.9849 - mse: 1.7956e-04\n",
      "Epoch 230: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4559 - bpp: 0.9849 - mse: 1.7956e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2939 - bpp: 0.9648 - mse: 1.6224e-04\n",
      "Epoch 231: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.2939 - bpp: 0.9648 - mse: 1.6224e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2614 - bpp: 0.9578 - mse: 1.5914e-04\n",
      "Epoch 232: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.2614 - bpp: 0.9578 - mse: 1.5914e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5034 - bpp: 1.0012 - mse: 1.8337e-04\n",
      "Epoch 233: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.5034 - bpp: 1.0012 - mse: 1.8337e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4732 - bpp: 0.9926 - mse: 1.8074e-04\n",
      "Epoch 234: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.4732 - bpp: 0.9926 - mse: 1.8074e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1460 - bpp: 0.9560 - mse: 1.4526e-04\n",
      "Epoch 235: loss improved from 2.15146 to 2.14602, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.1460 - bpp: 0.9560 - mse: 1.4526e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3257 - bpp: 0.9883 - mse: 1.6325e-04\n",
      "Epoch 236: loss did not improve from 2.14602\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.3257 - bpp: 0.9883 - mse: 1.6325e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3909 - bpp: 0.9718 - mse: 1.7323e-04\n",
      "Epoch 237: loss did not improve from 2.14602\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.3909 - bpp: 0.9718 - mse: 1.7323e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1110 - bpp: 0.9262 - mse: 1.4463e-04\n",
      "Epoch 238: loss improved from 2.14602 to 2.11102, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.1110 - bpp: 0.9262 - mse: 1.4463e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5405 - bpp: 0.9887 - mse: 1.8943e-04\n",
      "Epoch 239: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.5405 - bpp: 0.9887 - mse: 1.8943e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2313 - bpp: 0.9634 - mse: 1.5478e-04\n",
      "Epoch 240: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.2313 - bpp: 0.9634 - mse: 1.5478e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1215 - bpp: 0.9340 - mse: 1.4496e-04\n",
      "Epoch 241: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.1215 - bpp: 0.9340 - mse: 1.4496e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6718 - bpp: 0.9915 - mse: 2.0511e-04\n",
      "Epoch 242: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.6718 - bpp: 0.9915 - mse: 2.0511e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3841 - bpp: 0.9789 - mse: 1.7153e-04\n",
      "Epoch 243: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.3841 - bpp: 0.9789 - mse: 1.7153e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4195 - bpp: 0.9880 - mse: 1.7474e-04\n",
      "Epoch 244: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.4195 - bpp: 0.9880 - mse: 1.7474e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5552 - bpp: 1.0014 - mse: 1.8967e-04\n",
      "Epoch 245: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.5552 - bpp: 1.0014 - mse: 1.8967e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3200 - bpp: 0.9708 - mse: 1.6470e-04\n",
      "Epoch 246: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.3200 - bpp: 0.9708 - mse: 1.6470e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4898 - bpp: 0.9826 - mse: 1.8398e-04\n",
      "Epoch 247: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.4898 - bpp: 0.9826 - mse: 1.8398e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4112 - bpp: 0.9558 - mse: 1.7766e-04\n",
      "Epoch 248: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.4112 - bpp: 0.9558 - mse: 1.7766e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3066 - bpp: 0.9530 - mse: 1.6523e-04\n",
      "Epoch 249: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.3066 - bpp: 0.9530 - mse: 1.6523e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0686 - bpp: 1.1099 - mse: 6.0531e-04\n",
      "Epoch 250: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 6.0686 - bpp: 1.1099 - mse: 6.0531e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6529 - bpp: 1.0279 - mse: 1.9836e-04\n",
      "Epoch 251: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.6529 - bpp: 1.0279 - mse: 1.9836e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3644 - bpp: 0.9701 - mse: 1.7020e-04\n",
      "Epoch 252: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.3644 - bpp: 0.9701 - mse: 1.7020e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4828 - bpp: 0.9915 - mse: 1.8205e-04\n",
      "Epoch 253: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.4828 - bpp: 0.9915 - mse: 1.8205e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1166 - bpp: 0.9287 - mse: 1.4501e-04\n",
      "Epoch 254: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.1166 - bpp: 0.9287 - mse: 1.4501e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3941 - bpp: 0.9872 - mse: 1.7174e-04\n",
      "Epoch 255: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.3941 - bpp: 0.9872 - mse: 1.7174e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2175 - bpp: 0.9669 - mse: 1.5266e-04\n",
      "Epoch 256: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.2175 - bpp: 0.9669 - mse: 1.5266e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4059 - bpp: 0.9645 - mse: 1.7596e-04\n",
      "Epoch 257: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.4059 - bpp: 0.9645 - mse: 1.7596e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2869 - bpp: 0.9345 - mse: 1.6509e-04\n",
      "Epoch 258: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.2869 - bpp: 0.9345 - mse: 1.6509e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3839 - bpp: 0.9810 - mse: 1.7125e-04\n",
      "Epoch 259: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.3839 - bpp: 0.9810 - mse: 1.7125e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3388 - bpp: 0.9493 - mse: 1.6961e-04\n",
      "Epoch 260: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.3388 - bpp: 0.9493 - mse: 1.6961e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9001 - bpp: 1.0464 - mse: 2.2628e-04\n",
      "Epoch 261: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.9001 - bpp: 1.0464 - mse: 2.2628e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2607 - bpp: 0.9558 - mse: 1.5929e-04\n",
      "Epoch 262: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.2607 - bpp: 0.9558 - mse: 1.5929e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2115 - bpp: 0.9505 - mse: 1.5393e-04\n",
      "Epoch 263: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.2115 - bpp: 0.9505 - mse: 1.5393e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6698 - bpp: 0.9747 - mse: 2.0692e-04\n",
      "Epoch 264: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.6698 - bpp: 0.9747 - mse: 2.0692e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2918 - bpp: 0.9692 - mse: 1.6145e-04\n",
      "Epoch 265: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.2918 - bpp: 0.9692 - mse: 1.6145e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2581 - bpp: 0.9560 - mse: 1.5894e-04\n",
      "Epoch 266: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.2581 - bpp: 0.9560 - mse: 1.5894e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4573 - bpp: 0.9619 - mse: 1.8255e-04\n",
      "Epoch 267: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.4573 - bpp: 0.9619 - mse: 1.8255e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2390 - bpp: 0.9536 - mse: 1.5691e-04\n",
      "Epoch 268: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.2390 - bpp: 0.9536 - mse: 1.5691e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9945 - bpp: 0.8980 - mse: 1.3384e-04\n",
      "Epoch 269: loss improved from 2.11102 to 1.99448, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9945 - bpp: 0.8980 - mse: 1.3384e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1999 - bpp: 0.9236 - mse: 1.5581e-04\n",
      "Epoch 270: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.1999 - bpp: 0.9236 - mse: 1.5581e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2726 - bpp: 0.9401 - mse: 1.6265e-04\n",
      "Epoch 271: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.2726 - bpp: 0.9401 - mse: 1.6265e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3300 - bpp: 0.9662 - mse: 1.6648e-04\n",
      "Epoch 272: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.3300 - bpp: 0.9662 - mse: 1.6648e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1596 - bpp: 0.9389 - mse: 1.4901e-04\n",
      "Epoch 273: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.1596 - bpp: 0.9389 - mse: 1.4901e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4322 - bpp: 0.9569 - mse: 1.8009e-04\n",
      "Epoch 274: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4322 - bpp: 0.9569 - mse: 1.8009e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2390 - bpp: 0.9343 - mse: 1.5927e-04\n",
      "Epoch 275: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.2390 - bpp: 0.9343 - mse: 1.5927e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1836 - bpp: 0.9277 - mse: 1.5331e-04\n",
      "Epoch 276: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.1836 - bpp: 0.9277 - mse: 1.5331e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2004 - bpp: 0.9479 - mse: 1.5290e-04\n",
      "Epoch 277: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2004 - bpp: 0.9479 - mse: 1.5290e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4123 - bpp: 0.9632 - mse: 1.7689e-04\n",
      "Epoch 278: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.4123 - bpp: 0.9632 - mse: 1.7689e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0725 - bpp: 0.9236 - mse: 1.4025e-04\n",
      "Epoch 279: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.0725 - bpp: 0.9236 - mse: 1.4025e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3116 - bpp: 0.9443 - mse: 1.6691e-04\n",
      "Epoch 280: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.3116 - bpp: 0.9443 - mse: 1.6691e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2148 - bpp: 0.9531 - mse: 1.5402e-04\n",
      "Epoch 281: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2148 - bpp: 0.9531 - mse: 1.5402e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1710 - bpp: 0.9183 - mse: 1.5292e-04\n",
      "Epoch 282: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.1710 - bpp: 0.9183 - mse: 1.5292e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9805 - bpp: 0.9016 - mse: 1.3171e-04\n",
      "Epoch 283: loss improved from 1.99448 to 1.98050, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9805 - bpp: 0.9016 - mse: 1.3171e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1600 - bpp: 0.9415 - mse: 1.4875e-04\n",
      "Epoch 284: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.1600 - bpp: 0.9415 - mse: 1.4875e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1796 - bpp: 0.9332 - mse: 1.5215e-04\n",
      "Epoch 285: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.1796 - bpp: 0.9332 - mse: 1.5215e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2425 - bpp: 0.9522 - mse: 1.5751e-04\n",
      "Epoch 286: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.2425 - bpp: 0.9522 - mse: 1.5751e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4722 - bpp: 0.9639 - mse: 1.8411e-04\n",
      "Epoch 287: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4722 - bpp: 0.9639 - mse: 1.8411e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5605 - bpp: 0.9900 - mse: 4.3585e-04\n",
      "Epoch 288: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 4.5605 - bpp: 0.9900 - mse: 4.3585e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5685 - bpp: 1.0609 - mse: 3.0610e-04\n",
      "Epoch 289: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5685 - bpp: 1.0609 - mse: 3.0610e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2674 - bpp: 0.9631 - mse: 1.5921e-04\n",
      "Epoch 290: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.2674 - bpp: 0.9631 - mse: 1.5921e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1110 - bpp: 0.9241 - mse: 1.4488e-04\n",
      "Epoch 291: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.1110 - bpp: 0.9241 - mse: 1.4488e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2711 - bpp: 0.9505 - mse: 1.6121e-04\n",
      "Epoch 292: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.2711 - bpp: 0.9505 - mse: 1.6121e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1065 - bpp: 0.8992 - mse: 1.4738e-04\n",
      "Epoch 293: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.1065 - bpp: 0.8992 - mse: 1.4738e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0127 - bpp: 0.9219 - mse: 1.3316e-04\n",
      "Epoch 294: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0127 - bpp: 0.9219 - mse: 1.3316e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0739 - bpp: 0.9079 - mse: 1.4233e-04\n",
      "Epoch 295: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0739 - bpp: 0.9079 - mse: 1.4233e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1098 - bpp: 0.9422 - mse: 1.4253e-04\n",
      "Epoch 296: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 2.1098 - bpp: 0.9422 - mse: 1.4253e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1949 - bpp: 0.9162 - mse: 1.5609e-04\n",
      "Epoch 297: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.1949 - bpp: 0.9162 - mse: 1.5609e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1761 - bpp: 0.9272 - mse: 1.5245e-04\n",
      "Epoch 298: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.1761 - bpp: 0.9272 - mse: 1.5245e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2397 - bpp: 0.9412 - mse: 1.5850e-04\n",
      "Epoch 299: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.2397 - bpp: 0.9412 - mse: 1.5850e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2186 - bpp: 0.9252 - mse: 1.5789e-04\n",
      "Epoch 300: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.2186 - bpp: 0.9252 - mse: 1.5789e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1385 - bpp: 0.9041 - mse: 1.5069e-04\n",
      "Epoch 301: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.1385 - bpp: 0.9041 - mse: 1.5069e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1028 - bpp: 0.9190 - mse: 1.4451e-04\n",
      "Epoch 302: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.1028 - bpp: 0.9190 - mse: 1.4451e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1601 - bpp: 0.9212 - mse: 1.5123e-04\n",
      "Epoch 303: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.1601 - bpp: 0.9212 - mse: 1.5123e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1752 - bpp: 0.9295 - mse: 1.5206e-04\n",
      "Epoch 304: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.1752 - bpp: 0.9295 - mse: 1.5206e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1535 - bpp: 0.9209 - mse: 1.5047e-04\n",
      "Epoch 305: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.1535 - bpp: 0.9209 - mse: 1.5047e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9712 - bpp: 0.8813 - mse: 1.3305e-04\n",
      "Epoch 306: loss improved from 1.98050 to 1.97118, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9712 - bpp: 0.8813 - mse: 1.3305e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0700 - bpp: 0.9051 - mse: 1.4219e-04\n",
      "Epoch 307: loss did not improve from 1.97118\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.0700 - bpp: 0.9051 - mse: 1.4219e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7946 - bpp: 0.8579 - mse: 1.1435e-04\n",
      "Epoch 308: loss improved from 1.97118 to 1.79462, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7946 - bpp: 0.8579 - mse: 1.1435e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3312 - bpp: 0.9336 - mse: 1.7061e-04\n",
      "Epoch 309: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.3312 - bpp: 0.9336 - mse: 1.7061e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3012 - bpp: 0.9099 - mse: 1.6983e-04\n",
      "Epoch 310: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.3012 - bpp: 0.9099 - mse: 1.6983e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1443 - bpp: 0.8974 - mse: 1.5221e-04\n",
      "Epoch 311: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 2.1443 - bpp: 0.8974 - mse: 1.5221e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9796 - bpp: 0.8837 - mse: 1.3378e-04\n",
      "Epoch 312: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.9796 - bpp: 0.8837 - mse: 1.3378e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0538 - bpp: 0.8945 - mse: 1.4152e-04\n",
      "Epoch 313: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.0538 - bpp: 0.8945 - mse: 1.4152e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0139 - bpp: 1.1049 - mse: 5.9925e-04\n",
      "Epoch 314: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 6.0139 - bpp: 1.1049 - mse: 5.9925e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7281 - bpp: 1.0402 - mse: 2.0605e-04\n",
      "Epoch 315: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.7281 - bpp: 1.0402 - mse: 2.0605e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4004 - bpp: 0.9905 - mse: 1.7211e-04\n",
      "Epoch 316: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.4004 - bpp: 0.9905 - mse: 1.7211e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3021 - bpp: 0.9751 - mse: 1.6199e-04\n",
      "Epoch 317: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.3021 - bpp: 0.9751 - mse: 1.6199e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0994 - bpp: 0.9332 - mse: 1.4235e-04\n",
      "Epoch 318: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0994 - bpp: 0.9332 - mse: 1.4235e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0921 - bpp: 0.9419 - mse: 1.4040e-04\n",
      "Epoch 319: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.0921 - bpp: 0.9419 - mse: 1.4040e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1506 - bpp: 0.9284 - mse: 1.4920e-04\n",
      "Epoch 320: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.1506 - bpp: 0.9284 - mse: 1.4920e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9266 - bpp: 0.8825 - mse: 1.2746e-04\n",
      "Epoch 321: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.9266 - bpp: 0.8825 - mse: 1.2746e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9617 - bpp: 0.9025 - mse: 1.2930e-04\n",
      "Epoch 322: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.9617 - bpp: 0.9025 - mse: 1.2930e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0873 - bpp: 0.9267 - mse: 1.4168e-04\n",
      "Epoch 323: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 2.0873 - bpp: 0.9267 - mse: 1.4168e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0137 - bpp: 0.8774 - mse: 1.3872e-04\n",
      "Epoch 324: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.0137 - bpp: 0.8774 - mse: 1.3872e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9748 - bpp: 0.9068 - mse: 1.3037e-04\n",
      "Epoch 325: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.9748 - bpp: 0.9068 - mse: 1.3037e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9838 - bpp: 0.8862 - mse: 1.3400e-04\n",
      "Epoch 326: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.9838 - bpp: 0.8862 - mse: 1.3400e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9048 - bpp: 0.8794 - mse: 1.2518e-04\n",
      "Epoch 327: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9048 - bpp: 0.8794 - mse: 1.2518e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0688 - bpp: 0.8872 - mse: 1.4423e-04\n",
      "Epoch 328: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.0688 - bpp: 0.8872 - mse: 1.4423e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4473 - bpp: 1.0772 - mse: 5.3346e-04\n",
      "Epoch 329: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 5.4473 - bpp: 1.0772 - mse: 5.3346e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4584 - bpp: 0.9734 - mse: 1.8127e-04\n",
      "Epoch 330: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 2.4584 - bpp: 0.9734 - mse: 1.8127e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0166 - bpp: 0.9078 - mse: 1.3534e-04\n",
      "Epoch 331: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.0166 - bpp: 0.9078 - mse: 1.3534e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1178 - bpp: 0.9375 - mse: 1.4408e-04\n",
      "Epoch 332: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 2.1178 - bpp: 0.9375 - mse: 1.4408e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2346 - bpp: 0.9439 - mse: 1.5755e-04\n",
      "Epoch 333: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 2.2346 - bpp: 0.9439 - mse: 1.5755e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9595 - bpp: 0.8885 - mse: 1.3074e-04\n",
      "Epoch 334: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.9595 - bpp: 0.8885 - mse: 1.3074e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2022 - bpp: 0.9204 - mse: 1.5648e-04\n",
      "Epoch 335: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.2022 - bpp: 0.9204 - mse: 1.5648e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1326 - bpp: 0.9188 - mse: 1.4818e-04\n",
      "Epoch 336: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.1326 - bpp: 0.9188 - mse: 1.4818e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1815 - bpp: 0.9417 - mse: 1.5135e-04\n",
      "Epoch 337: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 2.1815 - bpp: 0.9417 - mse: 1.5135e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4647 - bpp: 0.9499 - mse: 1.8492e-04\n",
      "Epoch 338: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 2.4647 - bpp: 0.9499 - mse: 1.8492e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3335 - bpp: 0.9481 - mse: 1.6911e-04\n",
      "Epoch 339: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.3335 - bpp: 0.9481 - mse: 1.6911e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9527 - bpp: 0.8951 - mse: 1.2910e-04\n",
      "Epoch 340: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.9527 - bpp: 0.8951 - mse: 1.2910e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9463 - bpp: 0.8860 - mse: 1.2943e-04\n",
      "Epoch 341: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.9463 - bpp: 0.8860 - mse: 1.2943e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0421 - bpp: 0.9024 - mse: 1.3913e-04\n",
      "Epoch 342: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 2.0421 - bpp: 0.9024 - mse: 1.3913e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0147 - bpp: 0.8916 - mse: 1.3710e-04\n",
      "Epoch 343: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 2.0147 - bpp: 0.8916 - mse: 1.3710e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9611 - bpp: 0.8792 - mse: 1.3207e-04\n",
      "Epoch 344: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.9611 - bpp: 0.8792 - mse: 1.3207e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1355 - bpp: 0.9294 - mse: 1.4723e-04\n",
      "Epoch 345: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.1355 - bpp: 0.9294 - mse: 1.4723e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1479 - bpp: 0.9007 - mse: 1.5224e-04\n",
      "Epoch 346: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 2.1479 - bpp: 0.9007 - mse: 1.5224e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9770 - bpp: 0.8762 - mse: 1.3438e-04\n",
      "Epoch 347: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.9770 - bpp: 0.8762 - mse: 1.3438e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0174 - bpp: 0.8944 - mse: 1.3709e-04\n",
      "Epoch 348: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 2.0174 - bpp: 0.8944 - mse: 1.3709e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2066 - bpp: 0.9183 - mse: 1.5726e-04\n",
      "Epoch 349: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 2.2066 - bpp: 0.9183 - mse: 1.5726e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9043 - bpp: 0.8703 - mse: 1.2623e-04\n",
      "Epoch 350: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.9043 - bpp: 0.8703 - mse: 1.2623e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1697 - bpp: 0.9023 - mse: 1.5471e-04\n",
      "Epoch 351: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 2.1697 - bpp: 0.9023 - mse: 1.5471e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0354 - bpp: 0.9059 - mse: 1.3788e-04\n",
      "Epoch 352: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 2.0354 - bpp: 0.9059 - mse: 1.3788e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1213 - bpp: 0.9085 - mse: 1.4806e-04\n",
      "Epoch 353: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 2.1213 - bpp: 0.9085 - mse: 1.4806e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0828 - bpp: 0.8867 - mse: 1.4600e-04\n",
      "Epoch 354: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 2.0828 - bpp: 0.8867 - mse: 1.4600e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2082 - bpp: 0.9039 - mse: 1.5922e-04\n",
      "Epoch 355: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 2.2082 - bpp: 0.9039 - mse: 1.5922e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0283 - bpp: 0.8818 - mse: 1.3994e-04\n",
      "Epoch 356: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.0283 - bpp: 0.8818 - mse: 1.3994e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3359 - bpp: 0.9152 - mse: 1.7342e-04\n",
      "Epoch 357: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 2.3359 - bpp: 0.9152 - mse: 1.7342e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9338 - bpp: 0.8847 - mse: 1.2807e-04\n",
      "Epoch 358: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.9338 - bpp: 0.8847 - mse: 1.2807e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0365 - bpp: 0.9006 - mse: 1.3866e-04\n",
      "Epoch 359: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 2.0365 - bpp: 0.9006 - mse: 1.3866e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0810 - bpp: 0.8818 - mse: 1.4639e-04\n",
      "Epoch 360: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 2.0810 - bpp: 0.8818 - mse: 1.4639e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0679 - bpp: 0.9006 - mse: 1.4250e-04\n",
      "Epoch 361: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 2.0679 - bpp: 0.9006 - mse: 1.4250e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7381 - bpp: 0.9798 - mse: 2.1464e-04\n",
      "Epoch 362: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 2.7381 - bpp: 0.9798 - mse: 2.1464e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1330 - bpp: 0.9155 - mse: 1.4862e-04\n",
      "Epoch 363: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 2.1330 - bpp: 0.9155 - mse: 1.4862e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1882 - bpp: 0.9070 - mse: 1.5639e-04\n",
      "Epoch 364: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 2.1882 - bpp: 0.9070 - mse: 1.5639e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1004 - bpp: 0.9025 - mse: 1.4623e-04\n",
      "Epoch 365: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.1004 - bpp: 0.9025 - mse: 1.4623e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0123 - bpp: 0.8622 - mse: 1.4040e-04\n",
      "Epoch 366: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0123 - bpp: 0.8622 - mse: 1.4040e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0612 - bpp: 0.8783 - mse: 1.4439e-04\n",
      "Epoch 367: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0612 - bpp: 0.8783 - mse: 1.4439e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9386 - bpp: 0.8724 - mse: 1.3015e-04\n",
      "Epoch 368: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.9386 - bpp: 0.8724 - mse: 1.3015e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1838 - bpp: 0.9038 - mse: 1.5624e-04\n",
      "Epoch 369: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.1838 - bpp: 0.9038 - mse: 1.5624e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0647 - bpp: 0.8855 - mse: 1.4393e-04\n",
      "Epoch 370: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.0647 - bpp: 0.8855 - mse: 1.4393e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7697 - bpp: 1.0492 - mse: 4.5416e-04\n",
      "Epoch 371: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 4.7697 - bpp: 1.0492 - mse: 4.5416e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4408 - bpp: 0.9890 - mse: 1.7722e-04\n",
      "Epoch 372: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.4408 - bpp: 0.9890 - mse: 1.7722e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0412 - bpp: 0.8934 - mse: 1.4011e-04\n",
      "Epoch 373: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.0412 - bpp: 0.8934 - mse: 1.4011e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9123 - bpp: 0.8747 - mse: 1.2666e-04\n",
      "Epoch 374: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.9123 - bpp: 0.8747 - mse: 1.2666e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9335 - bpp: 0.8980 - mse: 1.2641e-04\n",
      "Epoch 375: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.9335 - bpp: 0.8980 - mse: 1.2641e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2818 - bpp: 0.9298 - mse: 1.6504e-04\n",
      "Epoch 376: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.2818 - bpp: 0.9298 - mse: 1.6504e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0859 - bpp: 0.9264 - mse: 1.4154e-04\n",
      "Epoch 377: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.0859 - bpp: 0.9264 - mse: 1.4154e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9150 - bpp: 0.8891 - mse: 1.2524e-04\n",
      "Epoch 378: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.9150 - bpp: 0.8891 - mse: 1.2524e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0722 - bpp: 0.9114 - mse: 1.4170e-04\n",
      "Epoch 379: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.0722 - bpp: 0.9114 - mse: 1.4170e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0534 - bpp: 0.8911 - mse: 1.4189e-04\n",
      "Epoch 380: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0534 - bpp: 0.8911 - mse: 1.4189e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9856 - bpp: 0.8989 - mse: 1.3265e-04\n",
      "Epoch 381: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.9856 - bpp: 0.8989 - mse: 1.3265e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1648 - bpp: 0.9266 - mse: 1.5115e-04\n",
      "Epoch 382: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.1648 - bpp: 0.9266 - mse: 1.5115e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0190 - bpp: 0.8996 - mse: 1.3664e-04\n",
      "Epoch 383: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.0190 - bpp: 0.8996 - mse: 1.3664e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9537 - bpp: 0.8839 - mse: 1.3059e-04\n",
      "Epoch 384: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.9537 - bpp: 0.8839 - mse: 1.3059e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1916 - bpp: 0.9318 - mse: 1.5378e-04\n",
      "Epoch 385: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.1916 - bpp: 0.9318 - mse: 1.5378e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9496 - bpp: 0.8704 - mse: 1.3174e-04\n",
      "Epoch 386: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9496 - bpp: 0.8704 - mse: 1.3174e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9383 - bpp: 0.8850 - mse: 1.2858e-04\n",
      "Epoch 387: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9383 - bpp: 0.8850 - mse: 1.2858e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7907 - bpp: 0.8508 - mse: 1.1474e-04\n",
      "Epoch 388: loss improved from 1.79462 to 1.79071, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7907 - bpp: 0.8508 - mse: 1.1474e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9184 - bpp: 0.8595 - mse: 1.2926e-04\n",
      "Epoch 389: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9184 - bpp: 0.8595 - mse: 1.2926e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9891 - bpp: 0.8687 - mse: 1.3676e-04\n",
      "Epoch 390: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9891 - bpp: 0.8687 - mse: 1.3676e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8733 - bpp: 1.0271 - mse: 3.4744e-04\n",
      "Epoch 391: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.8733 - bpp: 1.0271 - mse: 3.4744e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3169 - bpp: 0.9531 - mse: 1.6648e-04\n",
      "Epoch 392: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 2.3169 - bpp: 0.9531 - mse: 1.6648e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0664 - bpp: 0.8997 - mse: 1.4242e-04\n",
      "Epoch 393: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.0664 - bpp: 0.8997 - mse: 1.4242e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9257 - bpp: 0.8901 - mse: 1.2642e-04\n",
      "Epoch 394: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 243ms/step - loss: 1.9257 - bpp: 0.8901 - mse: 1.2642e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9351 - bpp: 0.8923 - mse: 1.2729e-04\n",
      "Epoch 395: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.9351 - bpp: 0.8923 - mse: 1.2729e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0101 - bpp: 0.8926 - mse: 1.3642e-04\n",
      "Epoch 396: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0101 - bpp: 0.8926 - mse: 1.3642e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9399 - bpp: 0.8847 - mse: 1.2881e-04\n",
      "Epoch 397: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.9399 - bpp: 0.8847 - mse: 1.2881e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9228 - bpp: 0.8743 - mse: 1.2799e-04\n",
      "Epoch 398: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9228 - bpp: 0.8743 - mse: 1.2799e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0761 - bpp: 0.9082 - mse: 1.4256e-04\n",
      "Epoch 399: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0761 - bpp: 0.9082 - mse: 1.4256e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8067 - bpp: 0.8410 - mse: 1.1788e-04\n",
      "Epoch 400: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.8067 - bpp: 0.8410 - mse: 1.1788e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1377 - bpp: 0.8985 - mse: 1.5127e-04\n",
      "Epoch 401: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 2.1377 - bpp: 0.8985 - mse: 1.5127e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8472 - bpp: 0.8429 - mse: 1.2260e-04\n",
      "Epoch 402: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8472 - bpp: 0.8429 - mse: 1.2260e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5300 - bpp: 0.9258 - mse: 1.9583e-04\n",
      "Epoch 403: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.5300 - bpp: 0.9258 - mse: 1.9583e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0873 - bpp: 0.9008 - mse: 1.4484e-04\n",
      "Epoch 404: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.0873 - bpp: 0.9008 - mse: 1.4484e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0279 - bpp: 0.8874 - mse: 1.3921e-04\n",
      "Epoch 405: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.0279 - bpp: 0.8874 - mse: 1.3921e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0057 - bpp: 0.8776 - mse: 1.3770e-04\n",
      "Epoch 406: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0057 - bpp: 0.8776 - mse: 1.3770e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9838 - bpp: 0.8868 - mse: 1.3391e-04\n",
      "Epoch 407: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9838 - bpp: 0.8868 - mse: 1.3391e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9720 - bpp: 0.8796 - mse: 1.3335e-04\n",
      "Epoch 408: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.9720 - bpp: 0.8796 - mse: 1.3335e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8975 - bpp: 0.8626 - mse: 1.2633e-04\n",
      "Epoch 409: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8975 - bpp: 0.8626 - mse: 1.2633e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0047 - bpp: 0.8666 - mse: 1.3893e-04\n",
      "Epoch 410: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.0047 - bpp: 0.8666 - mse: 1.3893e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0216 - bpp: 0.8920 - mse: 1.3790e-04\n",
      "Epoch 411: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.0216 - bpp: 0.8920 - mse: 1.3790e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0267 - bpp: 0.8665 - mse: 1.4163e-04\n",
      "Epoch 412: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0267 - bpp: 0.8665 - mse: 1.4163e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8239 - bpp: 0.8428 - mse: 1.1976e-04\n",
      "Epoch 413: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8239 - bpp: 0.8428 - mse: 1.1976e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0813 - bpp: 0.8869 - mse: 1.4579e-04\n",
      "Epoch 414: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.0813 - bpp: 0.8869 - mse: 1.4579e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8537 - bpp: 0.8620 - mse: 1.2106e-04\n",
      "Epoch 415: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8537 - bpp: 0.8620 - mse: 1.2106e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0149 - bpp: 0.9397 - mse: 2.5332e-04\n",
      "Epoch 416: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0149 - bpp: 0.9397 - mse: 2.5332e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1929 - bpp: 0.9205 - mse: 1.5533e-04\n",
      "Epoch 417: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.1929 - bpp: 0.9205 - mse: 1.5533e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0097 - bpp: 0.8906 - mse: 1.3661e-04\n",
      "Epoch 418: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.0097 - bpp: 0.8906 - mse: 1.3661e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9929 - bpp: 0.8874 - mse: 1.3495e-04\n",
      "Epoch 419: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.9929 - bpp: 0.8874 - mse: 1.3495e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0030 - bpp: 0.8737 - mse: 1.3785e-04\n",
      "Epoch 420: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.0030 - bpp: 0.8737 - mse: 1.3785e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0033 - bpp: 0.8825 - mse: 1.3681e-04\n",
      "Epoch 421: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.0033 - bpp: 0.8825 - mse: 1.3681e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9271 - bpp: 0.8493 - mse: 1.3157e-04\n",
      "Epoch 422: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.9271 - bpp: 0.8493 - mse: 1.3157e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9752 - bpp: 0.8648 - mse: 1.3554e-04\n",
      "Epoch 423: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.9752 - bpp: 0.8648 - mse: 1.3554e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7329 - bpp: 0.8338 - mse: 1.0975e-04\n",
      "Epoch 424: loss improved from 1.79071 to 1.73288, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7329 - bpp: 0.8338 - mse: 1.0975e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8970 - bpp: 0.8627 - mse: 1.2626e-04\n",
      "Epoch 425: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8970 - bpp: 0.8627 - mse: 1.2626e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2275 - bpp: 0.8929 - mse: 1.6292e-04\n",
      "Epoch 426: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2275 - bpp: 0.8929 - mse: 1.6292e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3685 - bpp: 0.9383 - mse: 1.7458e-04\n",
      "Epoch 427: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.3685 - bpp: 0.9383 - mse: 1.7458e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0598 - bpp: 0.9014 - mse: 1.4141e-04\n",
      "Epoch 428: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.0598 - bpp: 0.9014 - mse: 1.4141e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0876 - bpp: 0.8992 - mse: 1.4506e-04\n",
      "Epoch 429: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.0876 - bpp: 0.8992 - mse: 1.4506e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0740 - bpp: 0.8928 - mse: 1.4419e-04\n",
      "Epoch 430: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.0740 - bpp: 0.8928 - mse: 1.4419e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0234 - bpp: 0.8880 - mse: 1.3859e-04\n",
      "Epoch 431: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0234 - bpp: 0.8880 - mse: 1.3859e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8757 - bpp: 0.8471 - mse: 1.2557e-04\n",
      "Epoch 432: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8757 - bpp: 0.8471 - mse: 1.2557e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8912 - bpp: 0.8633 - mse: 1.2548e-04\n",
      "Epoch 433: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.8912 - bpp: 0.8633 - mse: 1.2548e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9277 - bpp: 0.8553 - mse: 1.3091e-04\n",
      "Epoch 434: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9277 - bpp: 0.8553 - mse: 1.3091e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8280 - bpp: 0.8532 - mse: 1.1899e-04\n",
      "Epoch 435: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8280 - bpp: 0.8532 - mse: 1.1899e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9933 - bpp: 0.8851 - mse: 1.3528e-04\n",
      "Epoch 436: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.9933 - bpp: 0.8851 - mse: 1.3528e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1284 - bpp: 0.8870 - mse: 1.5153e-04\n",
      "Epoch 437: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.1284 - bpp: 0.8870 - mse: 1.5153e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8701 - bpp: 0.8489 - mse: 1.2466e-04\n",
      "Epoch 438: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8701 - bpp: 0.8489 - mse: 1.2466e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0276 - bpp: 0.8850 - mse: 1.3948e-04\n",
      "Epoch 439: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0276 - bpp: 0.8850 - mse: 1.3948e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0921 - bpp: 0.8902 - mse: 1.4672e-04\n",
      "Epoch 440: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.0921 - bpp: 0.8902 - mse: 1.4672e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2591 - bpp: 0.9010 - mse: 1.6578e-04\n",
      "Epoch 441: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.2591 - bpp: 0.9010 - mse: 1.6578e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8563 - bpp: 0.8427 - mse: 1.2374e-04\n",
      "Epoch 442: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.8563 - bpp: 0.8427 - mse: 1.2374e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7492 - bpp: 0.8160 - mse: 1.1392e-04\n",
      "Epoch 443: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.7492 - bpp: 0.8160 - mse: 1.1392e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7939 - bpp: 0.8390 - mse: 1.1656e-04\n",
      "Epoch 444: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7939 - bpp: 0.8390 - mse: 1.1656e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9165 - bpp: 0.8686 - mse: 1.2792e-04\n",
      "Epoch 445: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9165 - bpp: 0.8686 - mse: 1.2792e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8889 - bpp: 0.8434 - mse: 1.2762e-04\n",
      "Epoch 446: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8889 - bpp: 0.8434 - mse: 1.2762e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9923 - bpp: 0.8471 - mse: 1.3979e-04\n",
      "Epoch 447: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9923 - bpp: 0.8471 - mse: 1.3979e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0131 - bpp: 0.8713 - mse: 1.3938e-04\n",
      "Epoch 448: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.0131 - bpp: 0.8713 - mse: 1.3938e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0769 - bpp: 0.9081 - mse: 1.4268e-04\n",
      "Epoch 449: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0769 - bpp: 0.9081 - mse: 1.4268e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8279 - bpp: 0.8472 - mse: 1.1972e-04\n",
      "Epoch 450: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8279 - bpp: 0.8472 - mse: 1.1972e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2948 - bpp: 0.8872 - mse: 1.7182e-04\n",
      "Epoch 451: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2948 - bpp: 0.8872 - mse: 1.7182e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1339 - bpp: 0.9087 - mse: 1.4956e-04\n",
      "Epoch 452: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.1339 - bpp: 0.9087 - mse: 1.4956e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8676 - bpp: 0.8383 - mse: 1.2565e-04\n",
      "Epoch 453: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.8676 - bpp: 0.8383 - mse: 1.2565e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8218 - bpp: 0.8469 - mse: 1.1901e-04\n",
      "Epoch 454: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.8218 - bpp: 0.8469 - mse: 1.1901e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9812 - bpp: 0.8652 - mse: 1.3623e-04\n",
      "Epoch 455: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.9812 - bpp: 0.8652 - mse: 1.3623e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9109 - bpp: 0.8681 - mse: 1.2729e-04\n",
      "Epoch 456: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.9109 - bpp: 0.8681 - mse: 1.2729e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9351 - bpp: 0.8542 - mse: 1.3195e-04\n",
      "Epoch 457: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.9351 - bpp: 0.8542 - mse: 1.3195e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0906 - bpp: 0.8752 - mse: 1.4837e-04\n",
      "Epoch 458: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.0906 - bpp: 0.8752 - mse: 1.4837e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9046 - bpp: 0.8593 - mse: 1.2761e-04\n",
      "Epoch 459: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9046 - bpp: 0.8593 - mse: 1.2761e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8952 - bpp: 0.8410 - mse: 1.2868e-04\n",
      "Epoch 460: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8952 - bpp: 0.8410 - mse: 1.2868e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9045 - bpp: 0.8646 - mse: 1.2695e-04\n",
      "Epoch 461: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.9045 - bpp: 0.8646 - mse: 1.2695e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9250 - bpp: 0.8644 - mse: 1.2948e-04\n",
      "Epoch 462: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9250 - bpp: 0.8644 - mse: 1.2948e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7636 - bpp: 0.8290 - mse: 1.1410e-04\n",
      "Epoch 463: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7636 - bpp: 0.8290 - mse: 1.1410e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9585 - bpp: 0.8548 - mse: 1.3473e-04\n",
      "Epoch 464: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.9585 - bpp: 0.8548 - mse: 1.3473e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7312 - bpp: 0.8363 - mse: 1.0924e-04\n",
      "Epoch 465: loss improved from 1.73288 to 1.73117, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 1.7312 - bpp: 0.8363 - mse: 1.0924e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0049 - bpp: 0.8711 - mse: 1.3840e-04\n",
      "Epoch 466: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.0049 - bpp: 0.8711 - mse: 1.3840e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7656 - bpp: 0.8341 - mse: 1.1371e-04\n",
      "Epoch 467: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7656 - bpp: 0.8341 - mse: 1.1371e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9036 - bpp: 0.8557 - mse: 1.2791e-04\n",
      "Epoch 468: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9036 - bpp: 0.8557 - mse: 1.2791e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9604 - bpp: 0.8523 - mse: 1.3526e-04\n",
      "Epoch 469: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9604 - bpp: 0.8523 - mse: 1.3526e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9310 - bpp: 0.8644 - mse: 1.3019e-04\n",
      "Epoch 470: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9310 - bpp: 0.8644 - mse: 1.3019e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9968 - bpp: 0.8553 - mse: 1.3935e-04\n",
      "Epoch 471: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.9968 - bpp: 0.8553 - mse: 1.3935e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9333 - bpp: 0.8514 - mse: 1.3207e-04\n",
      "Epoch 472: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9333 - bpp: 0.8514 - mse: 1.3207e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9775 - bpp: 0.8641 - mse: 1.3591e-04\n",
      "Epoch 473: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.9775 - bpp: 0.8641 - mse: 1.3591e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8514 - bpp: 0.8425 - mse: 1.2316e-04\n",
      "Epoch 474: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.8514 - bpp: 0.8425 - mse: 1.2316e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1588 - bpp: 0.8929 - mse: 1.5452e-04\n",
      "Epoch 475: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.1588 - bpp: 0.8929 - mse: 1.5452e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0496 - bpp: 0.8726 - mse: 1.4368e-04\n",
      "Epoch 476: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.0496 - bpp: 0.8726 - mse: 1.4368e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0233 - bpp: 0.8896 - mse: 1.3839e-04\n",
      "Epoch 477: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.0233 - bpp: 0.8896 - mse: 1.3839e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7676 - bpp: 0.8326 - mse: 1.1414e-04\n",
      "Epoch 478: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.7676 - bpp: 0.8326 - mse: 1.1414e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6953 - bpp: 0.8079 - mse: 1.0834e-04\n",
      "Epoch 479: loss improved from 1.73117 to 1.69535, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6953 - bpp: 0.8079 - mse: 1.0834e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8330 - bpp: 0.8453 - mse: 1.2056e-04\n",
      "Epoch 480: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8330 - bpp: 0.8453 - mse: 1.2056e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8121 - bpp: 0.8337 - mse: 1.1944e-04\n",
      "Epoch 481: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 1.8121 - bpp: 0.8337 - mse: 1.1944e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8759 - bpp: 0.8573 - mse: 1.2434e-04\n",
      "Epoch 482: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.8759 - bpp: 0.8573 - mse: 1.2434e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8761 - bpp: 0.8530 - mse: 1.2488e-04\n",
      "Epoch 483: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.8761 - bpp: 0.8530 - mse: 1.2488e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0882 - bpp: 0.8743 - mse: 1.4819e-04\n",
      "Epoch 484: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.0882 - bpp: 0.8743 - mse: 1.4819e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0396 - bpp: 0.8775 - mse: 1.4186e-04\n",
      "Epoch 485: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0396 - bpp: 0.8775 - mse: 1.4186e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7653 - bpp: 0.8273 - mse: 1.1450e-04\n",
      "Epoch 486: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.7653 - bpp: 0.8273 - mse: 1.1450e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1014 - bpp: 0.8876 - mse: 1.4817e-04\n",
      "Epoch 487: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.1014 - bpp: 0.8876 - mse: 1.4817e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8436 - bpp: 0.8257 - mse: 1.2426e-04\n",
      "Epoch 488: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.8436 - bpp: 0.8257 - mse: 1.2426e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9209 - bpp: 0.8699 - mse: 1.2830e-04\n",
      "Epoch 489: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.9209 - bpp: 0.8699 - mse: 1.2830e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9229 - bpp: 0.8580 - mse: 1.2999e-04\n",
      "Epoch 490: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.9229 - bpp: 0.8580 - mse: 1.2999e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7956 - bpp: 0.8400 - mse: 1.1665e-04\n",
      "Epoch 491: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7956 - bpp: 0.8400 - mse: 1.1665e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8339 - bpp: 0.8474 - mse: 1.2042e-04\n",
      "Epoch 492: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.8339 - bpp: 0.8474 - mse: 1.2042e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6622 - bpp: 0.8137 - mse: 1.0357e-04\n",
      "Epoch 493: loss improved from 1.69535 to 1.66221, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6622 - bpp: 0.8137 - mse: 1.0357e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0472 - bpp: 0.8807 - mse: 1.4239e-04\n",
      "Epoch 494: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.0472 - bpp: 0.8807 - mse: 1.4239e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3381 - bpp: 0.8977 - mse: 1.7583e-04\n",
      "Epoch 495: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.3381 - bpp: 0.8977 - mse: 1.7583e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9216 - bpp: 0.8720 - mse: 1.2813e-04\n",
      "Epoch 496: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.9216 - bpp: 0.8720 - mse: 1.2813e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9738 - bpp: 0.8598 - mse: 1.3599e-04\n",
      "Epoch 497: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9738 - bpp: 0.8598 - mse: 1.3599e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9484 - bpp: 0.8610 - mse: 1.3273e-04\n",
      "Epoch 498: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9484 - bpp: 0.8610 - mse: 1.3273e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7929 - bpp: 0.8313 - mse: 1.1738e-04\n",
      "Epoch 499: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7929 - bpp: 0.8313 - mse: 1.1738e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8476 - bpp: 0.8322 - mse: 1.2395e-04\n",
      "Epoch 500: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8476 - bpp: 0.8322 - mse: 1.2395e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7852 - bpp: 0.8298 - mse: 1.1662e-04\n",
      "Epoch 501: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.7852 - bpp: 0.8298 - mse: 1.1662e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9620 - bpp: 0.8674 - mse: 1.3362e-04\n",
      "Epoch 502: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9620 - bpp: 0.8674 - mse: 1.3362e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7889 - bpp: 0.8415 - mse: 1.1565e-04\n",
      "Epoch 503: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.7889 - bpp: 0.8415 - mse: 1.1565e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8481 - bpp: 0.8547 - mse: 1.2126e-04\n",
      "Epoch 504: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8481 - bpp: 0.8547 - mse: 1.2126e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8542 - bpp: 0.8542 - mse: 1.2207e-04\n",
      "Epoch 505: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8542 - bpp: 0.8542 - mse: 1.2207e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1465 - bpp: 0.8885 - mse: 1.5357e-04\n",
      "Epoch 506: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.1465 - bpp: 0.8885 - mse: 1.5357e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9441 - bpp: 0.8631 - mse: 1.3195e-04\n",
      "Epoch 507: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9441 - bpp: 0.8631 - mse: 1.3195e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7004 - bpp: 0.8103 - mse: 1.0866e-04\n",
      "Epoch 508: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7004 - bpp: 0.8103 - mse: 1.0866e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9092 - bpp: 0.8468 - mse: 1.2969e-04\n",
      "Epoch 509: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9092 - bpp: 0.8468 - mse: 1.2969e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8633 - bpp: 0.8525 - mse: 1.2339e-04\n",
      "Epoch 510: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8633 - bpp: 0.8525 - mse: 1.2339e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9488 - bpp: 0.8698 - mse: 1.3171e-04\n",
      "Epoch 511: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9488 - bpp: 0.8698 - mse: 1.3171e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7564 - bpp: 0.8209 - mse: 1.1419e-04\n",
      "Epoch 512: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7564 - bpp: 0.8209 - mse: 1.1419e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7875 - bpp: 0.8407 - mse: 1.1557e-04\n",
      "Epoch 513: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7875 - bpp: 0.8407 - mse: 1.1557e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8997 - bpp: 0.8562 - mse: 1.2739e-04\n",
      "Epoch 514: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8997 - bpp: 0.8562 - mse: 1.2739e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7801 - bpp: 0.8412 - mse: 1.1462e-04\n",
      "Epoch 515: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7801 - bpp: 0.8412 - mse: 1.1462e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9034 - bpp: 0.8454 - mse: 1.2915e-04\n",
      "Epoch 516: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9034 - bpp: 0.8454 - mse: 1.2915e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8816 - bpp: 0.8490 - mse: 1.2605e-04\n",
      "Epoch 517: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8816 - bpp: 0.8490 - mse: 1.2605e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7119 - bpp: 0.8102 - mse: 1.1007e-04\n",
      "Epoch 518: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7119 - bpp: 0.8102 - mse: 1.1007e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7951 - bpp: 0.8265 - mse: 1.1823e-04\n",
      "Epoch 519: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7951 - bpp: 0.8265 - mse: 1.1823e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8193 - bpp: 0.8540 - mse: 1.1783e-04\n",
      "Epoch 520: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8193 - bpp: 0.8540 - mse: 1.1783e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7749 - bpp: 0.8261 - mse: 1.1581e-04\n",
      "Epoch 521: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7749 - bpp: 0.8261 - mse: 1.1581e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7133 - bpp: 0.8257 - mse: 1.0836e-04\n",
      "Epoch 522: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7133 - bpp: 0.8257 - mse: 1.0836e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8225 - bpp: 0.8343 - mse: 1.2063e-04\n",
      "Epoch 523: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8225 - bpp: 0.8343 - mse: 1.2063e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7522 - bpp: 0.8136 - mse: 1.1458e-04\n",
      "Epoch 524: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7522 - bpp: 0.8136 - mse: 1.1458e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8234 - bpp: 0.8401 - mse: 1.2004e-04\n",
      "Epoch 525: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8234 - bpp: 0.8401 - mse: 1.2004e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9344 - bpp: 0.8685 - mse: 1.3011e-04\n",
      "Epoch 526: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 1.9344 - bpp: 0.8685 - mse: 1.3011e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0198 - bpp: 0.8580 - mse: 1.4182e-04\n",
      "Epoch 527: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.0198 - bpp: 0.8580 - mse: 1.4182e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8701 - bpp: 0.8581 - mse: 1.2354e-04\n",
      "Epoch 528: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.8701 - bpp: 0.8581 - mse: 1.2354e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9742 - bpp: 0.8754 - mse: 1.3413e-04\n",
      "Epoch 529: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.9742 - bpp: 0.8754 - mse: 1.3413e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9403 - bpp: 0.8608 - mse: 1.3178e-04\n",
      "Epoch 530: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9403 - bpp: 0.8608 - mse: 1.3178e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9423 - bpp: 0.8674 - mse: 1.3121e-04\n",
      "Epoch 531: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9423 - bpp: 0.8674 - mse: 1.3121e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7848 - bpp: 0.8253 - mse: 1.1713e-04\n",
      "Epoch 532: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7848 - bpp: 0.8253 - mse: 1.1713e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8094 - bpp: 0.8373 - mse: 1.1866e-04\n",
      "Epoch 533: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8094 - bpp: 0.8373 - mse: 1.1866e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0200 - bpp: 0.8793 - mse: 1.3924e-04\n",
      "Epoch 534: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 2.0200 - bpp: 0.8793 - mse: 1.3924e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8630 - bpp: 0.8456 - mse: 1.2420e-04\n",
      "Epoch 535: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8630 - bpp: 0.8456 - mse: 1.2420e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7853 - bpp: 0.8211 - mse: 1.1769e-04\n",
      "Epoch 536: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.7853 - bpp: 0.8211 - mse: 1.1769e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8910 - bpp: 0.8593 - mse: 1.2594e-04\n",
      "Epoch 537: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8910 - bpp: 0.8593 - mse: 1.2594e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6875 - bpp: 0.8095 - mse: 1.0717e-04\n",
      "Epoch 538: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6875 - bpp: 0.8095 - mse: 1.0717e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8391 - bpp: 0.8483 - mse: 1.2096e-04\n",
      "Epoch 539: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8391 - bpp: 0.8483 - mse: 1.2096e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3046 - bpp: 0.9096 - mse: 1.7029e-04\n",
      "Epoch 540: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.3046 - bpp: 0.9096 - mse: 1.7029e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9607 - bpp: 0.8610 - mse: 1.3424e-04\n",
      "Epoch 541: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.9607 - bpp: 0.8610 - mse: 1.3424e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1394 - bpp: 0.9186 - mse: 1.4903e-04\n",
      "Epoch 542: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.1394 - bpp: 0.9186 - mse: 1.4903e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0475 - bpp: 0.8811 - mse: 1.4238e-04\n",
      "Epoch 543: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.0475 - bpp: 0.8811 - mse: 1.4238e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8414 - bpp: 0.8333 - mse: 1.2306e-04\n",
      "Epoch 544: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8414 - bpp: 0.8333 - mse: 1.2306e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7446 - bpp: 0.8290 - mse: 1.1177e-04\n",
      "Epoch 545: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7446 - bpp: 0.8290 - mse: 1.1177e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7189 - bpp: 0.8391 - mse: 1.0740e-04\n",
      "Epoch 546: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.7189 - bpp: 0.8391 - mse: 1.0740e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8601 - bpp: 0.8508 - mse: 1.2320e-04\n",
      "Epoch 547: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8601 - bpp: 0.8508 - mse: 1.2320e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7743 - bpp: 0.8329 - mse: 1.1492e-04\n",
      "Epoch 548: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7743 - bpp: 0.8329 - mse: 1.1492e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8082 - bpp: 0.8516 - mse: 1.1678e-04\n",
      "Epoch 549: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8082 - bpp: 0.8516 - mse: 1.1678e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8885 - bpp: 0.8587 - mse: 1.2570e-04\n",
      "Epoch 550: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8885 - bpp: 0.8587 - mse: 1.2570e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8663 - bpp: 0.8588 - mse: 1.2298e-04\n",
      "Epoch 551: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8663 - bpp: 0.8588 - mse: 1.2298e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0249 - bpp: 0.8662 - mse: 1.4144e-04\n",
      "Epoch 552: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.0249 - bpp: 0.8662 - mse: 1.4144e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8897 - bpp: 0.8508 - mse: 1.2682e-04\n",
      "Epoch 553: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8897 - bpp: 0.8508 - mse: 1.2682e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9000 - bpp: 0.8536 - mse: 1.2773e-04\n",
      "Epoch 554: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9000 - bpp: 0.8536 - mse: 1.2773e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8979 - bpp: 0.8511 - mse: 1.2778e-04\n",
      "Epoch 555: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8979 - bpp: 0.8511 - mse: 1.2778e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9176 - bpp: 0.8506 - mse: 1.3025e-04\n",
      "Epoch 556: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.9176 - bpp: 0.8506 - mse: 1.3025e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8037 - bpp: 0.8435 - mse: 1.1721e-04\n",
      "Epoch 557: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.8037 - bpp: 0.8435 - mse: 1.1721e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8895 - bpp: 0.8646 - mse: 1.2511e-04\n",
      "Epoch 558: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.8895 - bpp: 0.8646 - mse: 1.2511e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7310 - bpp: 0.8214 - mse: 1.1104e-04\n",
      "Epoch 559: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7310 - bpp: 0.8214 - mse: 1.1104e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0337 - bpp: 0.8928 - mse: 1.3928e-04\n",
      "Epoch 560: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.0337 - bpp: 0.8928 - mse: 1.3928e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7565 - bpp: 0.8366 - mse: 1.1230e-04\n",
      "Epoch 561: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.7565 - bpp: 0.8366 - mse: 1.1230e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7000 - bpp: 0.8252 - mse: 1.0679e-04\n",
      "Epoch 562: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.7000 - bpp: 0.8252 - mse: 1.0679e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7491 - bpp: 0.8361 - mse: 1.1144e-04\n",
      "Epoch 563: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7491 - bpp: 0.8361 - mse: 1.1144e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7375 - bpp: 0.8370 - mse: 1.0992e-04\n",
      "Epoch 564: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7375 - bpp: 0.8370 - mse: 1.0992e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7397 - bpp: 0.8178 - mse: 1.1253e-04\n",
      "Epoch 565: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.7397 - bpp: 0.8178 - mse: 1.1253e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9573 - bpp: 0.8781 - mse: 1.3173e-04\n",
      "Epoch 566: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9573 - bpp: 0.8781 - mse: 1.3173e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6455 - bpp: 0.8024 - mse: 1.0291e-04\n",
      "Epoch 567: loss improved from 1.66221 to 1.64552, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6455 - bpp: 0.8024 - mse: 1.0291e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8468 - bpp: 0.8429 - mse: 1.2255e-04\n",
      "Epoch 568: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.8468 - bpp: 0.8429 - mse: 1.2255e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6682 - bpp: 0.8038 - mse: 1.0551e-04\n",
      "Epoch 569: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6682 - bpp: 0.8038 - mse: 1.0551e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7865 - bpp: 0.8285 - mse: 1.1694e-04\n",
      "Epoch 570: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7865 - bpp: 0.8285 - mse: 1.1694e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0149 - bpp: 0.8785 - mse: 1.3871e-04\n",
      "Epoch 571: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.0149 - bpp: 0.8785 - mse: 1.3871e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8640 - bpp: 0.8414 - mse: 1.2483e-04\n",
      "Epoch 572: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.8640 - bpp: 0.8414 - mse: 1.2483e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9018 - bpp: 0.8668 - mse: 1.2635e-04\n",
      "Epoch 573: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9018 - bpp: 0.8668 - mse: 1.2635e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8692 - bpp: 0.8639 - mse: 1.2271e-04\n",
      "Epoch 574: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8692 - bpp: 0.8639 - mse: 1.2271e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8338 - bpp: 0.8310 - mse: 1.2242e-04\n",
      "Epoch 575: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.8338 - bpp: 0.8310 - mse: 1.2242e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8082 - bpp: 0.8469 - mse: 1.1734e-04\n",
      "Epoch 576: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8082 - bpp: 0.8469 - mse: 1.1734e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7548 - bpp: 0.8189 - mse: 1.1425e-04\n",
      "Epoch 577: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7548 - bpp: 0.8189 - mse: 1.1425e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9535 - bpp: 0.8838 - mse: 1.3058e-04\n",
      "Epoch 578: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.9535 - bpp: 0.8838 - mse: 1.3058e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7871 - bpp: 0.8353 - mse: 1.1619e-04\n",
      "Epoch 579: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.7871 - bpp: 0.8353 - mse: 1.1619e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7471 - bpp: 0.8281 - mse: 1.1219e-04\n",
      "Epoch 580: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7471 - bpp: 0.8281 - mse: 1.1219e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8680 - bpp: 0.8619 - mse: 1.2282e-04\n",
      "Epoch 581: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.8680 - bpp: 0.8619 - mse: 1.2282e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8892 - bpp: 0.8523 - mse: 1.2657e-04\n",
      "Epoch 582: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8892 - bpp: 0.8523 - mse: 1.2657e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7322 - bpp: 0.8248 - mse: 1.1077e-04\n",
      "Epoch 583: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.7322 - bpp: 0.8248 - mse: 1.1077e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7100 - bpp: 0.8228 - mse: 1.0830e-04\n",
      "Epoch 584: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7100 - bpp: 0.8228 - mse: 1.0830e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0067 - bpp: 0.8891 - mse: 1.3643e-04\n",
      "Epoch 585: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.0067 - bpp: 0.8891 - mse: 1.3643e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8229 - bpp: 0.8587 - mse: 1.1771e-04\n",
      "Epoch 586: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.8229 - bpp: 0.8587 - mse: 1.1771e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8861 - bpp: 0.8522 - mse: 1.2621e-04\n",
      "Epoch 587: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.8861 - bpp: 0.8522 - mse: 1.2621e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7199 - bpp: 0.8265 - mse: 1.0905e-04\n",
      "Epoch 588: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7199 - bpp: 0.8265 - mse: 1.0905e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9062 - bpp: 0.8730 - mse: 1.2612e-04\n",
      "Epoch 589: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.9062 - bpp: 0.8730 - mse: 1.2612e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7609 - bpp: 0.8373 - mse: 1.1274e-04\n",
      "Epoch 590: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7609 - bpp: 0.8373 - mse: 1.1274e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6523 - bpp: 0.8075 - mse: 1.0313e-04\n",
      "Epoch 591: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6523 - bpp: 0.8075 - mse: 1.0313e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7583 - bpp: 0.8414 - mse: 1.1192e-04\n",
      "Epoch 592: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7583 - bpp: 0.8414 - mse: 1.1192e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8378 - bpp: 0.8419 - mse: 1.2157e-04\n",
      "Epoch 593: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8378 - bpp: 0.8419 - mse: 1.2157e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8975 - bpp: 0.8643 - mse: 1.2613e-04\n",
      "Epoch 594: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8975 - bpp: 0.8643 - mse: 1.2613e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8643 - bpp: 0.8424 - mse: 1.2475e-04\n",
      "Epoch 595: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.8643 - bpp: 0.8424 - mse: 1.2475e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8832 - bpp: 0.8129 - mse: 1.3065e-04\n",
      "Epoch 596: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.8832 - bpp: 0.8129 - mse: 1.3065e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7478 - bpp: 0.8473 - mse: 1.0993e-04\n",
      "Epoch 597: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7478 - bpp: 0.8473 - mse: 1.0993e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7827 - bpp: 0.8288 - mse: 1.1645e-04\n",
      "Epoch 598: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.7827 - bpp: 0.8288 - mse: 1.1645e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6209 - bpp: 0.7920 - mse: 1.0119e-04\n",
      "Epoch 599: loss improved from 1.64552 to 1.62089, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6209 - bpp: 0.7920 - mse: 1.0119e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7219 - bpp: 0.8058 - mse: 1.1182e-04\n",
      "Epoch 600: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.7219 - bpp: 0.8058 - mse: 1.1182e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7824 - bpp: 0.8375 - mse: 1.1534e-04\n",
      "Epoch 601: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7824 - bpp: 0.8375 - mse: 1.1534e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8420 - bpp: 0.8574 - mse: 1.2019e-04\n",
      "Epoch 602: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 1.8420 - bpp: 0.8574 - mse: 1.2019e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3050 - bpp: 0.9122 - mse: 1.7002e-04\n",
      "Epoch 603: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.3050 - bpp: 0.9122 - mse: 1.7002e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7260 - bpp: 0.8193 - mse: 1.1067e-04\n",
      "Epoch 604: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.7260 - bpp: 0.8193 - mse: 1.1067e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6864 - bpp: 0.8178 - mse: 1.0603e-04\n",
      "Epoch 605: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6864 - bpp: 0.8178 - mse: 1.0603e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0582 - bpp: 0.8766 - mse: 1.4424e-04\n",
      "Epoch 606: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.0582 - bpp: 0.8766 - mse: 1.4424e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8038 - bpp: 0.8386 - mse: 1.1782e-04\n",
      "Epoch 607: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8038 - bpp: 0.8386 - mse: 1.1782e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7383 - bpp: 0.8249 - mse: 1.1149e-04\n",
      "Epoch 608: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7383 - bpp: 0.8249 - mse: 1.1149e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8041 - bpp: 0.8238 - mse: 1.1967e-04\n",
      "Epoch 609: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.8041 - bpp: 0.8238 - mse: 1.1967e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8011 - bpp: 0.8271 - mse: 1.1890e-04\n",
      "Epoch 610: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.8011 - bpp: 0.8271 - mse: 1.1890e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7549 - bpp: 0.8308 - mse: 1.1280e-04\n",
      "Epoch 611: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7549 - bpp: 0.8308 - mse: 1.1280e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7213 - bpp: 0.8188 - mse: 1.1016e-04\n",
      "Epoch 612: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7213 - bpp: 0.8188 - mse: 1.1016e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6669 - bpp: 0.8120 - mse: 1.0436e-04\n",
      "Epoch 613: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6669 - bpp: 0.8120 - mse: 1.0436e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8238 - bpp: 0.8520 - mse: 1.1863e-04\n",
      "Epoch 614: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.8238 - bpp: 0.8520 - mse: 1.1863e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6936 - bpp: 0.8177 - mse: 1.0692e-04\n",
      "Epoch 615: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.6936 - bpp: 0.8177 - mse: 1.0692e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7787 - bpp: 0.8355 - mse: 1.1513e-04\n",
      "Epoch 616: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7787 - bpp: 0.8355 - mse: 1.1513e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9111 - bpp: 0.8671 - mse: 1.2744e-04\n",
      "Epoch 617: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.9111 - bpp: 0.8671 - mse: 1.2744e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7585 - bpp: 0.8244 - mse: 1.1403e-04\n",
      "Epoch 618: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7585 - bpp: 0.8244 - mse: 1.1403e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9183 - bpp: 0.8589 - mse: 1.2931e-04\n",
      "Epoch 619: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.9183 - bpp: 0.8589 - mse: 1.2931e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8115 - bpp: 0.8501 - mse: 1.1736e-04\n",
      "Epoch 620: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8115 - bpp: 0.8501 - mse: 1.1736e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7381 - bpp: 0.8394 - mse: 1.0970e-04\n",
      "Epoch 621: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7381 - bpp: 0.8394 - mse: 1.0970e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7058 - bpp: 0.8171 - mse: 1.0849e-04\n",
      "Epoch 622: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7058 - bpp: 0.8171 - mse: 1.0849e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8941 - bpp: 0.8344 - mse: 1.2936e-04\n",
      "Epoch 623: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.8941 - bpp: 0.8344 - mse: 1.2936e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7854 - bpp: 0.8370 - mse: 1.1577e-04\n",
      "Epoch 624: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7854 - bpp: 0.8370 - mse: 1.1577e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7546 - bpp: 0.8238 - mse: 1.1362e-04\n",
      "Epoch 625: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7546 - bpp: 0.8238 - mse: 1.1362e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7819 - bpp: 0.8325 - mse: 1.1590e-04\n",
      "Epoch 626: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7819 - bpp: 0.8325 - mse: 1.1590e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6531 - bpp: 0.7961 - mse: 1.0463e-04\n",
      "Epoch 627: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6531 - bpp: 0.7961 - mse: 1.0463e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7578 - bpp: 0.8318 - mse: 1.1303e-04\n",
      "Epoch 628: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.7578 - bpp: 0.8318 - mse: 1.1303e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7314 - bpp: 0.8223 - mse: 1.1097e-04\n",
      "Epoch 629: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7314 - bpp: 0.8223 - mse: 1.1097e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8097 - bpp: 0.8298 - mse: 1.1962e-04\n",
      "Epoch 630: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8097 - bpp: 0.8298 - mse: 1.1962e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6308 - bpp: 0.8036 - mse: 1.0098e-04\n",
      "Epoch 631: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.6308 - bpp: 0.8036 - mse: 1.0098e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7861 - bpp: 0.8262 - mse: 1.1718e-04\n",
      "Epoch 632: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7861 - bpp: 0.8262 - mse: 1.1718e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8035 - bpp: 0.8345 - mse: 1.1828e-04\n",
      "Epoch 633: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.8035 - bpp: 0.8345 - mse: 1.1828e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6586 - bpp: 0.8019 - mse: 1.0458e-04\n",
      "Epoch 634: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6586 - bpp: 0.8019 - mse: 1.0458e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6793 - bpp: 0.8081 - mse: 1.0635e-04\n",
      "Epoch 635: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6793 - bpp: 0.8081 - mse: 1.0635e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6865 - bpp: 0.8061 - mse: 1.0746e-04\n",
      "Epoch 636: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.6865 - bpp: 0.8061 - mse: 1.0746e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8016 - bpp: 0.8476 - mse: 1.1645e-04\n",
      "Epoch 637: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.8016 - bpp: 0.8476 - mse: 1.1645e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9616 - bpp: 0.8648 - mse: 1.3388e-04\n",
      "Epoch 638: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.9616 - bpp: 0.8648 - mse: 1.3388e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8151 - bpp: 0.8497 - mse: 1.1785e-04\n",
      "Epoch 639: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8151 - bpp: 0.8497 - mse: 1.1785e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0415 - bpp: 0.9003 - mse: 1.3931e-04\n",
      "Epoch 640: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 2.0415 - bpp: 0.9003 - mse: 1.3931e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7008 - bpp: 0.8170 - mse: 1.0788e-04\n",
      "Epoch 641: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.7008 - bpp: 0.8170 - mse: 1.0788e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6296 - bpp: 0.8116 - mse: 9.9849e-05\n",
      "Epoch 642: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.6296 - bpp: 0.8116 - mse: 9.9849e-05\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5668 - bpp: 0.7847 - mse: 9.5468e-05\n",
      "Epoch 643: loss improved from 1.62089 to 1.56675, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.5668 - bpp: 0.7847 - mse: 9.5468e-05\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7599 - bpp: 0.8243 - mse: 1.1420e-04\n",
      "Epoch 644: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7599 - bpp: 0.8243 - mse: 1.1420e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8326 - bpp: 0.8437 - mse: 1.2071e-04\n",
      "Epoch 645: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8326 - bpp: 0.8437 - mse: 1.2071e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6510 - bpp: 0.8098 - mse: 1.0268e-04\n",
      "Epoch 646: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6510 - bpp: 0.8098 - mse: 1.0268e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8060 - bpp: 0.8458 - mse: 1.1721e-04\n",
      "Epoch 647: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8060 - bpp: 0.8458 - mse: 1.1721e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7777 - bpp: 0.8197 - mse: 1.1694e-04\n",
      "Epoch 648: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.7777 - bpp: 0.8197 - mse: 1.1694e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6489 - bpp: 0.8004 - mse: 1.0358e-04\n",
      "Epoch 649: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6489 - bpp: 0.8004 - mse: 1.0358e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8344 - bpp: 0.8379 - mse: 1.2164e-04\n",
      "Epoch 650: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8344 - bpp: 0.8379 - mse: 1.2164e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8055 - bpp: 0.8388 - mse: 1.1800e-04\n",
      "Epoch 651: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8055 - bpp: 0.8388 - mse: 1.1800e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7193 - bpp: 0.8085 - mse: 1.1119e-04\n",
      "Epoch 652: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7193 - bpp: 0.8085 - mse: 1.1119e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7754 - bpp: 0.8255 - mse: 1.1595e-04\n",
      "Epoch 653: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7754 - bpp: 0.8255 - mse: 1.1595e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7933 - bpp: 0.8348 - mse: 1.1701e-04\n",
      "Epoch 654: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7933 - bpp: 0.8348 - mse: 1.1701e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6870 - bpp: 0.8186 - mse: 1.0602e-04\n",
      "Epoch 655: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6870 - bpp: 0.8186 - mse: 1.0602e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7176 - bpp: 0.8257 - mse: 1.0887e-04\n",
      "Epoch 656: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7176 - bpp: 0.8257 - mse: 1.0887e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7936 - bpp: 0.8351 - mse: 1.1701e-04\n",
      "Epoch 657: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7936 - bpp: 0.8351 - mse: 1.1701e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6746 - bpp: 0.7976 - mse: 1.0706e-04\n",
      "Epoch 658: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6746 - bpp: 0.7976 - mse: 1.0706e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6650 - bpp: 0.8033 - mse: 1.0519e-04\n",
      "Epoch 659: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6650 - bpp: 0.8033 - mse: 1.0519e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8376 - bpp: 0.8601 - mse: 1.1931e-04\n",
      "Epoch 660: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.8376 - bpp: 0.8601 - mse: 1.1931e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8280 - bpp: 0.8444 - mse: 1.2007e-04\n",
      "Epoch 661: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8280 - bpp: 0.8444 - mse: 1.2007e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7318 - bpp: 0.8163 - mse: 1.1176e-04\n",
      "Epoch 662: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7318 - bpp: 0.8163 - mse: 1.1176e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7735 - bpp: 0.8252 - mse: 1.1576e-04\n",
      "Epoch 663: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7735 - bpp: 0.8252 - mse: 1.1576e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6773 - bpp: 0.8136 - mse: 1.0543e-04\n",
      "Epoch 664: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6773 - bpp: 0.8136 - mse: 1.0543e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6347 - bpp: 0.7896 - mse: 1.0315e-04\n",
      "Epoch 665: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.6347 - bpp: 0.7896 - mse: 1.0315e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8484 - bpp: 0.8331 - mse: 1.2394e-04\n",
      "Epoch 666: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.8484 - bpp: 0.8331 - mse: 1.2394e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8106 - bpp: 0.8253 - mse: 1.2028e-04\n",
      "Epoch 667: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8106 - bpp: 0.8253 - mse: 1.2028e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9454 - bpp: 0.8547 - mse: 1.3315e-04\n",
      "Epoch 668: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9454 - bpp: 0.8547 - mse: 1.3315e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6210 - bpp: 0.8014 - mse: 1.0005e-04\n",
      "Epoch 669: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.6210 - bpp: 0.8014 - mse: 1.0005e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6046 - bpp: 0.7871 - mse: 9.9787e-05\n",
      "Epoch 670: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6046 - bpp: 0.7871 - mse: 9.9787e-05\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6331 - bpp: 0.7984 - mse: 1.0189e-04\n",
      "Epoch 671: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6331 - bpp: 0.7984 - mse: 1.0189e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7080 - bpp: 0.8240 - mse: 1.0791e-04\n",
      "Epoch 672: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.7080 - bpp: 0.8240 - mse: 1.0791e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7781 - bpp: 0.8223 - mse: 1.1667e-04\n",
      "Epoch 673: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7781 - bpp: 0.8223 - mse: 1.1667e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7343 - bpp: 0.8150 - mse: 1.1221e-04\n",
      "Epoch 674: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7343 - bpp: 0.8150 - mse: 1.1221e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7443 - bpp: 0.8200 - mse: 1.1283e-04\n",
      "Epoch 675: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7443 - bpp: 0.8200 - mse: 1.1283e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8025 - bpp: 0.8411 - mse: 1.1736e-04\n",
      "Epoch 676: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.8025 - bpp: 0.8411 - mse: 1.1736e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7373 - bpp: 0.8234 - mse: 1.1156e-04\n",
      "Epoch 677: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7373 - bpp: 0.8234 - mse: 1.1156e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6485 - bpp: 0.7937 - mse: 1.0434e-04\n",
      "Epoch 678: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 1.6485 - bpp: 0.7937 - mse: 1.0434e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9275 - bpp: 0.8646 - mse: 1.2974e-04\n",
      "Epoch 679: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.9275 - bpp: 0.8646 - mse: 1.2974e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5490 - bpp: 0.7872 - mse: 9.2989e-05\n",
      "Epoch 680: loss improved from 1.56675 to 1.54897, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5490 - bpp: 0.7872 - mse: 9.2989e-05\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8086 - bpp: 0.8391 - mse: 1.1834e-04\n",
      "Epoch 681: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8086 - bpp: 0.8391 - mse: 1.1834e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8200 - bpp: 0.8286 - mse: 1.2102e-04\n",
      "Epoch 682: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8200 - bpp: 0.8286 - mse: 1.2102e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9570 - bpp: 0.8426 - mse: 1.3603e-04\n",
      "Epoch 683: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9570 - bpp: 0.8426 - mse: 1.3603e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7380 - bpp: 0.8281 - mse: 1.1107e-04\n",
      "Epoch 684: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7380 - bpp: 0.8281 - mse: 1.1107e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6308 - bpp: 0.8065 - mse: 1.0062e-04\n",
      "Epoch 685: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.6308 - bpp: 0.8065 - mse: 1.0062e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6787 - bpp: 0.8008 - mse: 1.0716e-04\n",
      "Epoch 686: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.6787 - bpp: 0.8008 - mse: 1.0716e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7128 - bpp: 0.8172 - mse: 1.0932e-04\n",
      "Epoch 687: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7128 - bpp: 0.8172 - mse: 1.0932e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.7956 - mse: 1.0823e-04\n",
      "Epoch 688: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6823 - bpp: 0.7956 - mse: 1.0823e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7804 - bpp: 0.8143 - mse: 1.1793e-04\n",
      "Epoch 689: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7804 - bpp: 0.8143 - mse: 1.1793e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7159 - bpp: 0.8133 - mse: 1.1018e-04\n",
      "Epoch 690: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.7159 - bpp: 0.8133 - mse: 1.1018e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7582 - bpp: 0.8360 - mse: 1.1258e-04\n",
      "Epoch 691: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7582 - bpp: 0.8360 - mse: 1.1258e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5617 - bpp: 0.7890 - mse: 9.4324e-05\n",
      "Epoch 692: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5617 - bpp: 0.7890 - mse: 9.4324e-05\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6099 - bpp: 0.7957 - mse: 9.9392e-05\n",
      "Epoch 693: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6099 - bpp: 0.7957 - mse: 9.9392e-05\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7603 - bpp: 0.8188 - mse: 1.1493e-04\n",
      "Epoch 694: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7603 - bpp: 0.8188 - mse: 1.1493e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8309 - bpp: 0.8563 - mse: 1.1897e-04\n",
      "Epoch 695: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8309 - bpp: 0.8563 - mse: 1.1897e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7529 - bpp: 0.8228 - mse: 1.1353e-04\n",
      "Epoch 696: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7529 - bpp: 0.8228 - mse: 1.1353e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7226 - bpp: 0.8256 - mse: 1.0950e-04\n",
      "Epoch 697: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7226 - bpp: 0.8256 - mse: 1.0950e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7152 - bpp: 0.8002 - mse: 1.1169e-04\n",
      "Epoch 698: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7152 - bpp: 0.8002 - mse: 1.1169e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4933 - bpp: 0.7537 - mse: 9.0279e-05\n",
      "Epoch 699: loss improved from 1.54897 to 1.49329, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4933 - bpp: 0.7537 - mse: 9.0279e-05\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6573 - bpp: 0.8024 - mse: 1.0435e-04\n",
      "Epoch 700: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6573 - bpp: 0.8024 - mse: 1.0435e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7616 - bpp: 0.8236 - mse: 1.1451e-04\n",
      "Epoch 701: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7616 - bpp: 0.8236 - mse: 1.1451e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8429 - bpp: 0.8252 - mse: 1.2422e-04\n",
      "Epoch 702: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8429 - bpp: 0.8252 - mse: 1.2422e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5686 - bpp: 0.7746 - mse: 9.6928e-05\n",
      "Epoch 703: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5686 - bpp: 0.7746 - mse: 9.6928e-05\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6992 - bpp: 0.8080 - mse: 1.0878e-04\n",
      "Epoch 704: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6992 - bpp: 0.8080 - mse: 1.0878e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7485 - bpp: 0.8261 - mse: 1.1259e-04\n",
      "Epoch 705: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7485 - bpp: 0.8261 - mse: 1.1259e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7090 - bpp: 0.8211 - mse: 1.0838e-04\n",
      "Epoch 706: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7090 - bpp: 0.8211 - mse: 1.0838e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9688 - bpp: 0.8679 - mse: 1.3439e-04\n",
      "Epoch 707: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.9688 - bpp: 0.8679 - mse: 1.3439e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7918 - bpp: 0.8284 - mse: 1.1760e-04\n",
      "Epoch 708: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7918 - bpp: 0.8284 - mse: 1.1760e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6438 - bpp: 0.8163 - mse: 1.0100e-04\n",
      "Epoch 709: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6438 - bpp: 0.8163 - mse: 1.0100e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6232 - bpp: 0.7907 - mse: 1.0162e-04\n",
      "Epoch 710: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6232 - bpp: 0.7907 - mse: 1.0162e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7725 - bpp: 0.8346 - mse: 1.1450e-04\n",
      "Epoch 711: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.7725 - bpp: 0.8346 - mse: 1.1450e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0929 - bpp: 0.8702 - mse: 1.4925e-04\n",
      "Epoch 712: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.0929 - bpp: 0.8702 - mse: 1.4925e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8332 - bpp: 0.8420 - mse: 1.2100e-04\n",
      "Epoch 713: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8332 - bpp: 0.8420 - mse: 1.2100e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7302 - bpp: 0.8139 - mse: 1.1186e-04\n",
      "Epoch 714: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7302 - bpp: 0.8139 - mse: 1.1186e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7226 - bpp: 0.8305 - mse: 1.0890e-04\n",
      "Epoch 715: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7226 - bpp: 0.8305 - mse: 1.0890e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7787 - bpp: 0.8256 - mse: 1.1635e-04\n",
      "Epoch 716: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7787 - bpp: 0.8256 - mse: 1.1635e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6468 - bpp: 0.8135 - mse: 1.0172e-04\n",
      "Epoch 717: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6468 - bpp: 0.8135 - mse: 1.0172e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6954 - bpp: 0.8178 - mse: 1.0713e-04\n",
      "Epoch 718: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6954 - bpp: 0.8178 - mse: 1.0713e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7149 - bpp: 0.8332 - mse: 1.0763e-04\n",
      "Epoch 719: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7149 - bpp: 0.8332 - mse: 1.0763e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9360 - bpp: 0.8673 - mse: 1.3046e-04\n",
      "Epoch 720: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.9360 - bpp: 0.8673 - mse: 1.3046e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5860 - bpp: 0.7724 - mse: 9.9315e-05\n",
      "Epoch 721: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.5860 - bpp: 0.7724 - mse: 9.9315e-05\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8238 - bpp: 0.8338 - mse: 1.2084e-04\n",
      "Epoch 722: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.8238 - bpp: 0.8338 - mse: 1.2084e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7080 - bpp: 0.8186 - mse: 1.0857e-04\n",
      "Epoch 723: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7080 - bpp: 0.8186 - mse: 1.0857e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8334 - bpp: 0.8564 - mse: 1.1926e-04\n",
      "Epoch 724: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.8334 - bpp: 0.8564 - mse: 1.1926e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8344 - bpp: 0.8561 - mse: 1.1941e-04\n",
      "Epoch 725: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 1.8344 - bpp: 0.8561 - mse: 1.1941e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6617 - bpp: 0.7981 - mse: 1.0542e-04\n",
      "Epoch 726: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6617 - bpp: 0.7981 - mse: 1.0542e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6557 - bpp: 0.8078 - mse: 1.0350e-04\n",
      "Epoch 727: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6557 - bpp: 0.8078 - mse: 1.0350e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6489 - bpp: 0.8129 - mse: 1.0205e-04\n",
      "Epoch 728: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6489 - bpp: 0.8129 - mse: 1.0205e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8090 - bpp: 0.8319 - mse: 1.1928e-04\n",
      "Epoch 729: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8090 - bpp: 0.8319 - mse: 1.1928e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6193 - bpp: 0.7994 - mse: 1.0009e-04\n",
      "Epoch 730: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.6193 - bpp: 0.7994 - mse: 1.0009e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7805 - bpp: 0.8412 - mse: 1.1466e-04\n",
      "Epoch 731: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7805 - bpp: 0.8412 - mse: 1.1466e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7656 - bpp: 0.8353 - mse: 1.1355e-04\n",
      "Epoch 732: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7656 - bpp: 0.8353 - mse: 1.1355e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6366 - bpp: 0.8019 - mse: 1.0190e-04\n",
      "Epoch 733: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6366 - bpp: 0.8019 - mse: 1.0190e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8594 - bpp: 0.8481 - mse: 1.2345e-04\n",
      "Epoch 734: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.8594 - bpp: 0.8481 - mse: 1.2345e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7004 - bpp: 0.8322 - mse: 1.0599e-04\n",
      "Epoch 735: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7004 - bpp: 0.8322 - mse: 1.0599e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7057 - bpp: 0.8187 - mse: 1.0827e-04\n",
      "Epoch 736: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 1.7057 - bpp: 0.8187 - mse: 1.0827e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5724 - bpp: 0.7822 - mse: 9.6464e-05\n",
      "Epoch 737: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5724 - bpp: 0.7822 - mse: 9.6464e-05\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7230 - bpp: 0.8137 - mse: 1.1099e-04\n",
      "Epoch 738: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7230 - bpp: 0.8137 - mse: 1.1099e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7606 - bpp: 0.8187 - mse: 1.1497e-04\n",
      "Epoch 739: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 56s 274ms/step - loss: 1.7606 - bpp: 0.8187 - mse: 1.1497e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7695 - bpp: 0.8321 - mse: 1.1443e-04\n",
      "Epoch 740: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.7695 - bpp: 0.8321 - mse: 1.1443e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7696 - bpp: 0.8372 - mse: 1.1382e-04\n",
      "Epoch 741: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7696 - bpp: 0.8372 - mse: 1.1382e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6303 - bpp: 0.8015 - mse: 1.0116e-04\n",
      "Epoch 742: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6303 - bpp: 0.8015 - mse: 1.0116e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6627 - bpp: 0.8075 - mse: 1.0440e-04\n",
      "Epoch 743: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6627 - bpp: 0.8075 - mse: 1.0440e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6639 - bpp: 0.8189 - mse: 1.0315e-04\n",
      "Epoch 744: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6639 - bpp: 0.8189 - mse: 1.0315e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7407 - bpp: 0.8361 - mse: 1.1042e-04\n",
      "Epoch 745: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7407 - bpp: 0.8361 - mse: 1.1042e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7898 - bpp: 0.8353 - mse: 1.1652e-04\n",
      "Epoch 746: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7898 - bpp: 0.8353 - mse: 1.1652e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8017 - bpp: 0.8527 - mse: 1.1584e-04\n",
      "Epoch 747: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.8017 - bpp: 0.8527 - mse: 1.1584e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6878 - bpp: 0.8227 - mse: 1.0560e-04\n",
      "Epoch 748: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6878 - bpp: 0.8227 - mse: 1.0560e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8319 - bpp: 0.8430 - mse: 1.2072e-04\n",
      "Epoch 749: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.8319 - bpp: 0.8430 - mse: 1.2072e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7045 - bpp: 0.8129 - mse: 1.0884e-04\n",
      "Epoch 750: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.7045 - bpp: 0.8129 - mse: 1.0884e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6611 - bpp: 0.8140 - mse: 1.0341e-04\n",
      "Epoch 751: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6611 - bpp: 0.8140 - mse: 1.0341e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6196 - bpp: 0.8065 - mse: 9.9256e-05\n",
      "Epoch 752: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.6196 - bpp: 0.8065 - mse: 9.9256e-05\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6400 - bpp: 0.7914 - mse: 1.0359e-04\n",
      "Epoch 753: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6400 - bpp: 0.7914 - mse: 1.0359e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5576 - bpp: 0.7855 - mse: 9.4252e-05\n",
      "Epoch 754: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.5576 - bpp: 0.7855 - mse: 9.4252e-05\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6249 - bpp: 0.8073 - mse: 9.9798e-05\n",
      "Epoch 755: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6249 - bpp: 0.8073 - mse: 9.9798e-05\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7102 - bpp: 0.8257 - mse: 1.0797e-04\n",
      "Epoch 756: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7102 - bpp: 0.8257 - mse: 1.0797e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7016 - bpp: 0.8082 - mse: 1.0907e-04\n",
      "Epoch 757: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7016 - bpp: 0.8082 - mse: 1.0907e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6792 - bpp: 0.8073 - mse: 1.0644e-04\n",
      "Epoch 758: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6792 - bpp: 0.8073 - mse: 1.0644e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7369 - bpp: 0.8112 - mse: 1.1299e-04\n",
      "Epoch 759: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7369 - bpp: 0.8112 - mse: 1.1299e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7333 - bpp: 0.8319 - mse: 1.1004e-04\n",
      "Epoch 760: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7333 - bpp: 0.8319 - mse: 1.1004e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8025 - bpp: 0.8503 - mse: 1.1623e-04\n",
      "Epoch 761: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.8025 - bpp: 0.8503 - mse: 1.1623e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7699 - bpp: 0.8223 - mse: 1.1568e-04\n",
      "Epoch 762: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7699 - bpp: 0.8223 - mse: 1.1568e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6378 - bpp: 0.8069 - mse: 1.0142e-04\n",
      "Epoch 763: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6378 - bpp: 0.8069 - mse: 1.0142e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6661 - bpp: 0.8145 - mse: 1.0395e-04\n",
      "Epoch 764: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6661 - bpp: 0.8145 - mse: 1.0395e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5805 - bpp: 0.7843 - mse: 9.7192e-05\n",
      "Epoch 765: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.5805 - bpp: 0.7843 - mse: 9.7192e-05\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9806 - bpp: 0.8641 - mse: 1.3628e-04\n",
      "Epoch 766: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.9806 - bpp: 0.8641 - mse: 1.3628e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6879 - bpp: 0.8023 - mse: 1.0810e-04\n",
      "Epoch 767: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 264ms/step - loss: 1.6879 - bpp: 0.8023 - mse: 1.0810e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7917 - bpp: 0.8389 - mse: 1.1632e-04\n",
      "Epoch 768: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7917 - bpp: 0.8389 - mse: 1.1632e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7766 - bpp: 0.8323 - mse: 1.1528e-04\n",
      "Epoch 769: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7766 - bpp: 0.8323 - mse: 1.1528e-04\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7718 - bpp: 0.8251 - mse: 1.1557e-04\n",
      "Epoch 770: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7718 - bpp: 0.8251 - mse: 1.1557e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8115 - bpp: 0.8384 - mse: 1.1879e-04\n",
      "Epoch 771: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.8115 - bpp: 0.8384 - mse: 1.1879e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7391 - bpp: 0.8179 - mse: 1.1246e-04\n",
      "Epoch 772: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.7391 - bpp: 0.8179 - mse: 1.1246e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5849 - bpp: 0.7822 - mse: 9.7983e-05\n",
      "Epoch 773: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.5849 - bpp: 0.7822 - mse: 9.7983e-05\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6204 - bpp: 0.8084 - mse: 9.9118e-05\n",
      "Epoch 774: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.6204 - bpp: 0.8084 - mse: 9.9118e-05\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8440 - bpp: 0.8254 - mse: 1.2434e-04\n",
      "Epoch 775: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.8440 - bpp: 0.8254 - mse: 1.2434e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5179 - bpp: 0.7806 - mse: 8.9998e-05\n",
      "Epoch 776: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5179 - bpp: 0.7806 - mse: 8.9998e-05\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6022 - bpp: 0.7947 - mse: 9.8570e-05\n",
      "Epoch 777: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 264ms/step - loss: 1.6022 - bpp: 0.7947 - mse: 9.8570e-05\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6472 - bpp: 0.7950 - mse: 1.0403e-04\n",
      "Epoch 778: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6472 - bpp: 0.7950 - mse: 1.0403e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5936 - bpp: 0.8015 - mse: 9.6699e-05\n",
      "Epoch 779: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5936 - bpp: 0.8015 - mse: 9.6699e-05\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6623 - bpp: 0.8082 - mse: 1.0427e-04\n",
      "Epoch 780: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6623 - bpp: 0.8082 - mse: 1.0427e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6605 - bpp: 0.7972 - mse: 1.0539e-04\n",
      "Epoch 781: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.6605 - bpp: 0.7972 - mse: 1.0539e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7263 - bpp: 0.8223 - mse: 1.1035e-04\n",
      "Epoch 782: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7263 - bpp: 0.8223 - mse: 1.1035e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6537 - bpp: 0.8049 - mse: 1.0361e-04\n",
      "Epoch 783: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6537 - bpp: 0.8049 - mse: 1.0361e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7247 - bpp: 0.8120 - mse: 1.1141e-04\n",
      "Epoch 784: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.7247 - bpp: 0.8120 - mse: 1.1141e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8454 - bpp: 0.8518 - mse: 1.2129e-04\n",
      "Epoch 785: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.8454 - bpp: 0.8518 - mse: 1.2129e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5307 - bpp: 0.7675 - mse: 9.3170e-05\n",
      "Epoch 786: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5307 - bpp: 0.7675 - mse: 9.3170e-05\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4932 - bpp: 0.7783 - mse: 8.7260e-05\n",
      "Epoch 787: loss improved from 1.49329 to 1.49317, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.4932 - bpp: 0.7783 - mse: 8.7260e-05\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5985 - bpp: 0.8027 - mse: 9.7143e-05\n",
      "Epoch 788: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5985 - bpp: 0.8027 - mse: 9.7143e-05\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7440 - bpp: 0.8276 - mse: 1.1186e-04\n",
      "Epoch 789: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.7440 - bpp: 0.8276 - mse: 1.1186e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6764 - bpp: 0.8049 - mse: 1.0638e-04\n",
      "Epoch 790: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6764 - bpp: 0.8049 - mse: 1.0638e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9668 - bpp: 0.8834 - mse: 1.3225e-04\n",
      "Epoch 791: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.9668 - bpp: 0.8834 - mse: 1.3225e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7328 - bpp: 0.8281 - mse: 1.1043e-04\n",
      "Epoch 792: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.7328 - bpp: 0.8281 - mse: 1.1043e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6834 - bpp: 0.7992 - mse: 1.0793e-04\n",
      "Epoch 793: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6834 - bpp: 0.7992 - mse: 1.0793e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6627 - bpp: 0.7969 - mse: 1.0568e-04\n",
      "Epoch 794: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6627 - bpp: 0.7969 - mse: 1.0568e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9563 - bpp: 0.8557 - mse: 1.3436e-04\n",
      "Epoch 795: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.9563 - bpp: 0.8557 - mse: 1.3436e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6556 - bpp: 0.8100 - mse: 1.0323e-04\n",
      "Epoch 796: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6556 - bpp: 0.8100 - mse: 1.0323e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8284 - bpp: 0.8284 - mse: 1.2207e-04\n",
      "Epoch 797: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8284 - bpp: 0.8284 - mse: 1.2207e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6713 - bpp: 0.8027 - mse: 1.0602e-04\n",
      "Epoch 798: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6713 - bpp: 0.8027 - mse: 1.0602e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5671 - bpp: 0.7909 - mse: 9.4745e-05\n",
      "Epoch 799: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5671 - bpp: 0.7909 - mse: 9.4745e-05\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4848 - bpp: 0.7556 - mse: 8.9019e-05\n",
      "Epoch 800: loss improved from 1.49317 to 1.48480, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.4848 - bpp: 0.7556 - mse: 8.9019e-05\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6188 - bpp: 0.7967 - mse: 1.0036e-04\n",
      "Epoch 801: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6188 - bpp: 0.7967 - mse: 1.0036e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6030 - bpp: 0.7866 - mse: 9.9658e-05\n",
      "Epoch 802: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6030 - bpp: 0.7866 - mse: 9.9658e-05\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6184 - bpp: 0.8059 - mse: 9.9180e-05\n",
      "Epoch 803: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6184 - bpp: 0.8059 - mse: 9.9180e-05\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6892 - bpp: 0.8097 - mse: 1.0736e-04\n",
      "Epoch 804: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6892 - bpp: 0.8097 - mse: 1.0736e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6764 - bpp: 0.7982 - mse: 1.0720e-04\n",
      "Epoch 805: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.6764 - bpp: 0.7982 - mse: 1.0720e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6965 - bpp: 0.8197 - mse: 1.0703e-04\n",
      "Epoch 806: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6965 - bpp: 0.8197 - mse: 1.0703e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6543 - bpp: 0.7903 - mse: 1.0546e-04\n",
      "Epoch 807: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6543 - bpp: 0.7903 - mse: 1.0546e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6892 - bpp: 0.8128 - mse: 1.0697e-04\n",
      "Epoch 808: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6892 - bpp: 0.8128 - mse: 1.0697e-04\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6796 - bpp: 0.8093 - mse: 1.0625e-04\n",
      "Epoch 809: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6796 - bpp: 0.8093 - mse: 1.0625e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7756 - bpp: 0.8363 - mse: 1.1466e-04\n",
      "Epoch 810: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7756 - bpp: 0.8363 - mse: 1.1466e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8004 - bpp: 0.8490 - mse: 1.1613e-04\n",
      "Epoch 811: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8004 - bpp: 0.8490 - mse: 1.1613e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7125 - bpp: 0.8294 - mse: 1.0780e-04\n",
      "Epoch 812: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7125 - bpp: 0.8294 - mse: 1.0780e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7121 - bpp: 0.8144 - mse: 1.0958e-04\n",
      "Epoch 813: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 254ms/step - loss: 1.7121 - bpp: 0.8144 - mse: 1.0958e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7269 - bpp: 0.8177 - mse: 1.1099e-04\n",
      "Epoch 814: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7269 - bpp: 0.8177 - mse: 1.1099e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7800 - bpp: 0.8411 - mse: 1.1461e-04\n",
      "Epoch 815: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7800 - bpp: 0.8411 - mse: 1.1461e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6376 - bpp: 0.8011 - mse: 1.0211e-04\n",
      "Epoch 816: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6376 - bpp: 0.8011 - mse: 1.0211e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6616 - bpp: 0.8141 - mse: 1.0345e-04\n",
      "Epoch 817: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6616 - bpp: 0.8141 - mse: 1.0345e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7552 - bpp: 0.8067 - mse: 1.1578e-04\n",
      "Epoch 818: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7552 - bpp: 0.8067 - mse: 1.1578e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6753 - bpp: 0.7944 - mse: 1.0753e-04\n",
      "Epoch 819: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.6753 - bpp: 0.7944 - mse: 1.0753e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6023 - bpp: 0.7849 - mse: 9.9782e-05\n",
      "Epoch 820: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6023 - bpp: 0.7849 - mse: 9.9782e-05\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5777 - bpp: 0.7840 - mse: 9.6892e-05\n",
      "Epoch 821: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.5777 - bpp: 0.7840 - mse: 9.6892e-05\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6009 - bpp: 0.7847 - mse: 9.9633e-05\n",
      "Epoch 822: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6009 - bpp: 0.7847 - mse: 9.9633e-05\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6111 - bpp: 0.7889 - mse: 1.0037e-04\n",
      "Epoch 823: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6111 - bpp: 0.7889 - mse: 1.0037e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6565 - bpp: 0.7999 - mse: 1.0457e-04\n",
      "Epoch 824: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.6565 - bpp: 0.7999 - mse: 1.0457e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5365 - bpp: 0.7604 - mse: 9.4741e-05\n",
      "Epoch 825: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5365 - bpp: 0.7604 - mse: 9.4741e-05\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6935 - bpp: 0.8053 - mse: 1.0843e-04\n",
      "Epoch 826: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6935 - bpp: 0.8053 - mse: 1.0843e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6202 - bpp: 0.7849 - mse: 1.0197e-04\n",
      "Epoch 827: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6202 - bpp: 0.7849 - mse: 1.0197e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6473 - bpp: 0.7976 - mse: 1.0373e-04\n",
      "Epoch 828: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6473 - bpp: 0.7976 - mse: 1.0373e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5463 - bpp: 0.7731 - mse: 9.4387e-05\n",
      "Epoch 829: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5463 - bpp: 0.7731 - mse: 9.4387e-05\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6174 - bpp: 0.7883 - mse: 1.0122e-04\n",
      "Epoch 830: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6174 - bpp: 0.7883 - mse: 1.0122e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7594 - bpp: 0.8222 - mse: 1.1440e-04\n",
      "Epoch 831: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7594 - bpp: 0.8222 - mse: 1.1440e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6297 - bpp: 0.7861 - mse: 1.0299e-04\n",
      "Epoch 832: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6297 - bpp: 0.7861 - mse: 1.0299e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5290 - bpp: 0.7769 - mse: 9.1803e-05\n",
      "Epoch 833: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.5290 - bpp: 0.7769 - mse: 9.1803e-05\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6179 - bpp: 0.7873 - mse: 1.0139e-04\n",
      "Epoch 834: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.6179 - bpp: 0.7873 - mse: 1.0139e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8271 - bpp: 0.8353 - mse: 1.2107e-04\n",
      "Epoch 835: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8271 - bpp: 0.8353 - mse: 1.2107e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5181 - bpp: 0.7636 - mse: 9.2109e-05\n",
      "Epoch 836: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.5181 - bpp: 0.7636 - mse: 9.2109e-05\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5381 - bpp: 0.7807 - mse: 9.2455e-05\n",
      "Epoch 837: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5381 - bpp: 0.7807 - mse: 9.2455e-05\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8408 - bpp: 0.8457 - mse: 1.2147e-04\n",
      "Epoch 838: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.8408 - bpp: 0.8457 - mse: 1.2147e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5539 - bpp: 0.7635 - mse: 9.6481e-05\n",
      "Epoch 839: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5539 - bpp: 0.7635 - mse: 9.6481e-05\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6797 - bpp: 0.7940 - mse: 1.0812e-04\n",
      "Epoch 840: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.6797 - bpp: 0.7940 - mse: 1.0812e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6319 - bpp: 0.7964 - mse: 1.0199e-04\n",
      "Epoch 841: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6319 - bpp: 0.7964 - mse: 1.0199e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5196 - bpp: 0.7645 - mse: 9.2184e-05\n",
      "Epoch 842: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5196 - bpp: 0.7645 - mse: 9.2184e-05\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6060 - bpp: 0.7973 - mse: 9.8715e-05\n",
      "Epoch 843: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6060 - bpp: 0.7973 - mse: 9.8715e-05\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8111 - bpp: 0.8380 - mse: 1.1878e-04\n",
      "Epoch 844: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8111 - bpp: 0.8380 - mse: 1.1878e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6826 - bpp: 0.8084 - mse: 1.0672e-04\n",
      "Epoch 845: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6826 - bpp: 0.8084 - mse: 1.0672e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6582 - bpp: 0.8046 - mse: 1.0420e-04\n",
      "Epoch 846: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.6582 - bpp: 0.8046 - mse: 1.0420e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6088 - bpp: 0.7870 - mse: 1.0032e-04\n",
      "Epoch 847: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6088 - bpp: 0.7870 - mse: 1.0032e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6729 - bpp: 0.8093 - mse: 1.0542e-04\n",
      "Epoch 848: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6729 - bpp: 0.8093 - mse: 1.0542e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6487 - bpp: 0.7961 - mse: 1.0407e-04\n",
      "Epoch 849: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6487 - bpp: 0.7961 - mse: 1.0407e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6792 - bpp: 0.8155 - mse: 1.0543e-04\n",
      "Epoch 850: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6792 - bpp: 0.8155 - mse: 1.0543e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6390 - bpp: 0.7935 - mse: 1.0321e-04\n",
      "Epoch 851: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6390 - bpp: 0.7935 - mse: 1.0321e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6778 - bpp: 0.7975 - mse: 1.0746e-04\n",
      "Epoch 852: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6778 - bpp: 0.7975 - mse: 1.0746e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5753 - bpp: 0.7862 - mse: 9.6326e-05\n",
      "Epoch 853: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5753 - bpp: 0.7862 - mse: 9.6326e-05\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7238 - bpp: 0.8071 - mse: 1.1190e-04\n",
      "Epoch 854: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.7238 - bpp: 0.8071 - mse: 1.1190e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7252 - bpp: 0.8073 - mse: 1.1205e-04\n",
      "Epoch 855: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7252 - bpp: 0.8073 - mse: 1.1205e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6112 - bpp: 0.7846 - mse: 1.0090e-04\n",
      "Epoch 856: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6112 - bpp: 0.7846 - mse: 1.0090e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6629 - bpp: 0.8142 - mse: 1.0360e-04\n",
      "Epoch 857: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.6629 - bpp: 0.8142 - mse: 1.0360e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5696 - bpp: 0.7641 - mse: 9.8326e-05\n",
      "Epoch 858: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5696 - bpp: 0.7641 - mse: 9.8326e-05\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7477 - bpp: 0.8323 - mse: 1.1174e-04\n",
      "Epoch 859: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7477 - bpp: 0.8323 - mse: 1.1174e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6336 - bpp: 0.7995 - mse: 1.0182e-04\n",
      "Epoch 860: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6336 - bpp: 0.7995 - mse: 1.0182e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7726 - bpp: 0.8166 - mse: 1.1670e-04\n",
      "Epoch 861: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7726 - bpp: 0.8166 - mse: 1.1670e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7172 - bpp: 0.8099 - mse: 1.1076e-04\n",
      "Epoch 862: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.7172 - bpp: 0.8099 - mse: 1.1076e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6568 - bpp: 0.8008 - mse: 1.0449e-04\n",
      "Epoch 863: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6568 - bpp: 0.8008 - mse: 1.0449e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4165 - bpp: 0.7477 - mse: 8.1635e-05\n",
      "Epoch 864: loss improved from 1.48480 to 1.41648, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.4165 - bpp: 0.7477 - mse: 8.1635e-05\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6524 - bpp: 0.8004 - mse: 1.0401e-04\n",
      "Epoch 865: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6524 - bpp: 0.8004 - mse: 1.0401e-04\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5800 - bpp: 0.7900 - mse: 9.6440e-05\n",
      "Epoch 866: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5800 - bpp: 0.7900 - mse: 9.6440e-05\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5060 - bpp: 0.7645 - mse: 9.0512e-05\n",
      "Epoch 867: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5060 - bpp: 0.7645 - mse: 9.0512e-05\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5158 - bpp: 0.7643 - mse: 9.1743e-05\n",
      "Epoch 868: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5158 - bpp: 0.7643 - mse: 9.1743e-05\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6094 - bpp: 0.7810 - mse: 1.0112e-04\n",
      "Epoch 869: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6094 - bpp: 0.7810 - mse: 1.0112e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6643 - bpp: 0.7867 - mse: 1.0714e-04\n",
      "Epoch 870: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6643 - bpp: 0.7867 - mse: 1.0714e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6848 - bpp: 0.7967 - mse: 1.0842e-04\n",
      "Epoch 871: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6848 - bpp: 0.7967 - mse: 1.0842e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6117 - bpp: 0.7764 - mse: 1.0197e-04\n",
      "Epoch 872: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6117 - bpp: 0.7764 - mse: 1.0197e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6570 - bpp: 0.8042 - mse: 1.0410e-04\n",
      "Epoch 873: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6570 - bpp: 0.8042 - mse: 1.0410e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7337 - bpp: 0.8202 - mse: 1.1150e-04\n",
      "Epoch 874: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7337 - bpp: 0.8202 - mse: 1.1150e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4918 - bpp: 0.7433 - mse: 9.1377e-05\n",
      "Epoch 875: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.4918 - bpp: 0.7433 - mse: 9.1377e-05\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6826 - bpp: 0.8031 - mse: 1.0736e-04\n",
      "Epoch 876: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6826 - bpp: 0.8031 - mse: 1.0736e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7318 - bpp: 0.8092 - mse: 1.1262e-04\n",
      "Epoch 877: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7318 - bpp: 0.8092 - mse: 1.1262e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5942 - bpp: 0.7902 - mse: 9.8155e-05\n",
      "Epoch 878: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.5942 - bpp: 0.7902 - mse: 9.8155e-05\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6710 - bpp: 0.8040 - mse: 1.0583e-04\n",
      "Epoch 879: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6710 - bpp: 0.8040 - mse: 1.0583e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5714 - bpp: 0.7895 - mse: 9.5443e-05\n",
      "Epoch 880: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.5714 - bpp: 0.7895 - mse: 9.5443e-05\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6327 - bpp: 0.7972 - mse: 1.0198e-04\n",
      "Epoch 881: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 257ms/step - loss: 1.6327 - bpp: 0.7972 - mse: 1.0198e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7876 - bpp: 0.8367 - mse: 1.1608e-04\n",
      "Epoch 882: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7876 - bpp: 0.8367 - mse: 1.1608e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6090 - bpp: 0.7841 - mse: 1.0069e-04\n",
      "Epoch 883: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6090 - bpp: 0.7841 - mse: 1.0069e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6287 - bpp: 0.7785 - mse: 1.0378e-04\n",
      "Epoch 884: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6287 - bpp: 0.7785 - mse: 1.0378e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5718 - bpp: 0.7626 - mse: 9.8774e-05\n",
      "Epoch 885: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5718 - bpp: 0.7626 - mse: 9.8774e-05\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5599 - bpp: 0.7728 - mse: 9.6077e-05\n",
      "Epoch 886: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5599 - bpp: 0.7728 - mse: 9.6077e-05\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6209 - bpp: 0.7916 - mse: 1.0123e-04\n",
      "Epoch 887: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.6209 - bpp: 0.7916 - mse: 1.0123e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6381 - bpp: 0.7937 - mse: 1.0307e-04\n",
      "Epoch 888: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6381 - bpp: 0.7937 - mse: 1.0307e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7695 - bpp: 0.8161 - mse: 1.1639e-04\n",
      "Epoch 889: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7695 - bpp: 0.8161 - mse: 1.1639e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5803 - bpp: 0.7836 - mse: 9.7254e-05\n",
      "Epoch 890: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.5803 - bpp: 0.7836 - mse: 9.7254e-05\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7671 - bpp: 0.8122 - mse: 1.1657e-04\n",
      "Epoch 891: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.7671 - bpp: 0.8122 - mse: 1.1657e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7942 - bpp: 0.8462 - mse: 1.1572e-04\n",
      "Epoch 892: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7942 - bpp: 0.8462 - mse: 1.1572e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5235 - bpp: 0.7656 - mse: 9.2523e-05\n",
      "Epoch 893: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.5235 - bpp: 0.7656 - mse: 9.2523e-05\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5626 - bpp: 0.7752 - mse: 9.6116e-05\n",
      "Epoch 894: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.5626 - bpp: 0.7752 - mse: 9.6116e-05\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6669 - bpp: 0.7896 - mse: 1.0709e-04\n",
      "Epoch 895: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6669 - bpp: 0.7896 - mse: 1.0709e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5879 - bpp: 0.7900 - mse: 9.7399e-05\n",
      "Epoch 896: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5879 - bpp: 0.7900 - mse: 9.7399e-05\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6289 - bpp: 0.7829 - mse: 1.0327e-04\n",
      "Epoch 897: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6289 - bpp: 0.7829 - mse: 1.0327e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6959 - bpp: 0.7837 - mse: 1.1135e-04\n",
      "Epoch 898: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6959 - bpp: 0.7837 - mse: 1.1135e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8348 - bpp: 0.8532 - mse: 1.1983e-04\n",
      "Epoch 899: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8348 - bpp: 0.8532 - mse: 1.1983e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7141 - bpp: 0.8067 - mse: 1.1077e-04\n",
      "Epoch 900: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7141 - bpp: 0.8067 - mse: 1.1077e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6959 - bpp: 0.8020 - mse: 1.0912e-04\n",
      "Epoch 901: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6959 - bpp: 0.8020 - mse: 1.0912e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8338 - bpp: 0.8279 - mse: 1.2279e-04\n",
      "Epoch 902: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8338 - bpp: 0.8279 - mse: 1.2279e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6355 - bpp: 0.7959 - mse: 1.0249e-04\n",
      "Epoch 903: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6355 - bpp: 0.7959 - mse: 1.0249e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5663 - bpp: 0.7859 - mse: 9.5266e-05\n",
      "Epoch 904: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.5663 - bpp: 0.7859 - mse: 9.5266e-05\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6073 - bpp: 0.7861 - mse: 1.0026e-04\n",
      "Epoch 905: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6073 - bpp: 0.7861 - mse: 1.0026e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5828 - bpp: 0.7867 - mse: 9.7179e-05\n",
      "Epoch 906: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.5828 - bpp: 0.7867 - mse: 9.7179e-05\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7189 - bpp: 0.8105 - mse: 1.1089e-04\n",
      "Epoch 907: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.7189 - bpp: 0.8105 - mse: 1.1089e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8013 - bpp: 0.8263 - mse: 1.1901e-04\n",
      "Epoch 908: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.8013 - bpp: 0.8263 - mse: 1.1901e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6210 - bpp: 0.7918 - mse: 1.0121e-04\n",
      "Epoch 909: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.6210 - bpp: 0.7918 - mse: 1.0121e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6760 - bpp: 0.8014 - mse: 1.0677e-04\n",
      "Epoch 910: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6760 - bpp: 0.8014 - mse: 1.0677e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6786 - bpp: 0.7870 - mse: 1.0884e-04\n",
      "Epoch 911: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6786 - bpp: 0.7870 - mse: 1.0884e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6476 - bpp: 0.7886 - mse: 1.0486e-04\n",
      "Epoch 912: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.6476 - bpp: 0.7886 - mse: 1.0486e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5880 - bpp: 0.7773 - mse: 9.8957e-05\n",
      "Epoch 913: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 1.5880 - bpp: 0.7773 - mse: 9.8957e-05\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5836 - bpp: 0.7899 - mse: 9.6888e-05\n",
      "Epoch 914: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5836 - bpp: 0.7899 - mse: 9.6888e-05\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7353 - bpp: 0.8050 - mse: 1.1355e-04\n",
      "Epoch 915: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7353 - bpp: 0.8050 - mse: 1.1355e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6424 - bpp: 0.7958 - mse: 1.0335e-04\n",
      "Epoch 916: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6424 - bpp: 0.7958 - mse: 1.0335e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7918 - bpp: 0.8363 - mse: 1.1664e-04\n",
      "Epoch 917: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.7918 - bpp: 0.8363 - mse: 1.1664e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5629 - bpp: 0.7861 - mse: 9.4824e-05\n",
      "Epoch 918: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.5629 - bpp: 0.7861 - mse: 9.4824e-05\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6192 - bpp: 0.7871 - mse: 1.0158e-04\n",
      "Epoch 919: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6192 - bpp: 0.7871 - mse: 1.0158e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6883 - bpp: 0.8201 - mse: 1.0598e-04\n",
      "Epoch 920: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6883 - bpp: 0.8201 - mse: 1.0598e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6497 - bpp: 0.8040 - mse: 1.0323e-04\n",
      "Epoch 921: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.6497 - bpp: 0.8040 - mse: 1.0323e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6756 - bpp: 0.8079 - mse: 1.0592e-04\n",
      "Epoch 922: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6756 - bpp: 0.8079 - mse: 1.0592e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7254 - bpp: 0.8330 - mse: 1.0894e-04\n",
      "Epoch 923: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.7254 - bpp: 0.8330 - mse: 1.0894e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6999 - bpp: 0.8089 - mse: 1.0876e-04\n",
      "Epoch 924: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.6999 - bpp: 0.8089 - mse: 1.0876e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4887 - bpp: 0.7353 - mse: 9.1966e-05\n",
      "Epoch 925: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.4887 - bpp: 0.7353 - mse: 9.1966e-05\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4981 - bpp: 0.7715 - mse: 8.8703e-05\n",
      "Epoch 926: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.4981 - bpp: 0.7715 - mse: 8.8703e-05\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5859 - bpp: 0.7936 - mse: 9.6716e-05\n",
      "Epoch 927: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 1.5859 - bpp: 0.7936 - mse: 9.6716e-05\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5496 - bpp: 0.7699 - mse: 9.5168e-05\n",
      "Epoch 928: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.5496 - bpp: 0.7699 - mse: 9.5168e-05\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4879 - bpp: 0.7474 - mse: 9.0397e-05\n",
      "Epoch 929: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.4879 - bpp: 0.7474 - mse: 9.0397e-05\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7717 - bpp: 0.8025 - mse: 1.1830e-04\n",
      "Epoch 930: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.7717 - bpp: 0.8025 - mse: 1.1830e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8580 - bpp: 0.8578 - mse: 1.2210e-04\n",
      "Epoch 931: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.8580 - bpp: 0.8578 - mse: 1.2210e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5484 - bpp: 0.7786 - mse: 9.3966e-05\n",
      "Epoch 932: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5484 - bpp: 0.7786 - mse: 9.3966e-05\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5208 - bpp: 0.7747 - mse: 9.1085e-05\n",
      "Epoch 933: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.5208 - bpp: 0.7747 - mse: 9.1085e-05\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5988 - bpp: 0.7868 - mse: 9.9129e-05\n",
      "Epoch 934: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5988 - bpp: 0.7868 - mse: 9.9129e-05\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5615 - bpp: 0.7762 - mse: 9.5859e-05\n",
      "Epoch 935: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.5615 - bpp: 0.7762 - mse: 9.5859e-05\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5882 - bpp: 0.7863 - mse: 9.7892e-05\n",
      "Epoch 936: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5882 - bpp: 0.7863 - mse: 9.7892e-05\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6697 - bpp: 0.8130 - mse: 1.0458e-04\n",
      "Epoch 937: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6697 - bpp: 0.8130 - mse: 1.0458e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5539 - bpp: 0.7727 - mse: 9.5372e-05\n",
      "Epoch 938: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5539 - bpp: 0.7727 - mse: 9.5372e-05\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7521 - bpp: 0.8149 - mse: 1.1440e-04\n",
      "Epoch 939: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.7521 - bpp: 0.8149 - mse: 1.1440e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5553 - bpp: 0.7709 - mse: 9.5758e-05\n",
      "Epoch 940: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5553 - bpp: 0.7709 - mse: 9.5758e-05\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6294 - bpp: 0.7915 - mse: 1.0229e-04\n",
      "Epoch 941: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 1.6294 - bpp: 0.7915 - mse: 1.0229e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5827 - bpp: 0.7977 - mse: 9.5825e-05\n",
      "Epoch 942: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 281ms/step - loss: 1.5827 - bpp: 0.7977 - mse: 9.5825e-05\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5658 - bpp: 0.7797 - mse: 9.5965e-05\n",
      "Epoch 943: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.5658 - bpp: 0.7797 - mse: 9.5965e-05\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6667 - bpp: 0.8067 - mse: 1.0498e-04\n",
      "Epoch 944: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6667 - bpp: 0.8067 - mse: 1.0498e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5870 - bpp: 0.7809 - mse: 9.8393e-05\n",
      "Epoch 945: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5870 - bpp: 0.7809 - mse: 9.8393e-05\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5242 - bpp: 0.7584 - mse: 9.3482e-05\n",
      "Epoch 946: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 1.5242 - bpp: 0.7584 - mse: 9.3482e-05\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6903 - bpp: 0.8159 - mse: 1.0674e-04\n",
      "Epoch 947: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6903 - bpp: 0.8159 - mse: 1.0674e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5098 - bpp: 0.7638 - mse: 9.1072e-05\n",
      "Epoch 948: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5098 - bpp: 0.7638 - mse: 9.1072e-05\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7092 - bpp: 0.8243 - mse: 1.0803e-04\n",
      "Epoch 949: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.7092 - bpp: 0.8243 - mse: 1.0803e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5991 - bpp: 0.7720 - mse: 1.0096e-04\n",
      "Epoch 950: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5991 - bpp: 0.7720 - mse: 1.0096e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5530 - bpp: 0.7808 - mse: 9.4264e-05\n",
      "Epoch 951: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5530 - bpp: 0.7808 - mse: 9.4264e-05\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6930 - bpp: 0.8093 - mse: 1.0786e-04\n",
      "Epoch 952: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.6930 - bpp: 0.8093 - mse: 1.0786e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5956 - bpp: 0.7823 - mse: 9.9285e-05\n",
      "Epoch 953: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5956 - bpp: 0.7823 - mse: 9.9285e-05\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5200 - bpp: 0.7757 - mse: 9.0865e-05\n",
      "Epoch 954: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.5200 - bpp: 0.7757 - mse: 9.0865e-05\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4948 - bpp: 0.7468 - mse: 9.1306e-05\n",
      "Epoch 955: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.4948 - bpp: 0.7468 - mse: 9.1306e-05\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6195 - bpp: 0.7880 - mse: 1.0150e-04\n",
      "Epoch 956: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6195 - bpp: 0.7880 - mse: 1.0150e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5787 - bpp: 0.7726 - mse: 9.8412e-05\n",
      "Epoch 957: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5787 - bpp: 0.7726 - mse: 9.8412e-05\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5608 - bpp: 0.7674 - mse: 9.6853e-05\n",
      "Epoch 958: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5608 - bpp: 0.7674 - mse: 9.6853e-05\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5345 - bpp: 0.7728 - mse: 9.2985e-05\n",
      "Epoch 959: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 1.5345 - bpp: 0.7728 - mse: 9.2985e-05\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6048 - bpp: 0.7820 - mse: 1.0043e-04\n",
      "Epoch 960: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6048 - bpp: 0.7820 - mse: 1.0043e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6768 - bpp: 0.8023 - mse: 1.0675e-04\n",
      "Epoch 961: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.6768 - bpp: 0.8023 - mse: 1.0675e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5993 - bpp: 0.7893 - mse: 9.8871e-05\n",
      "Epoch 962: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.5993 - bpp: 0.7893 - mse: 9.8871e-05\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5679 - bpp: 0.7880 - mse: 9.5211e-05\n",
      "Epoch 963: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 1.5679 - bpp: 0.7880 - mse: 9.5211e-05\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6711 - bpp: 0.8038 - mse: 1.0586e-04\n",
      "Epoch 964: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6711 - bpp: 0.8038 - mse: 1.0586e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5425 - bpp: 0.7805 - mse: 9.3015e-05\n",
      "Epoch 965: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.5425 - bpp: 0.7805 - mse: 9.3015e-05\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8371 - bpp: 0.8238 - mse: 1.2369e-04\n",
      "Epoch 966: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.8371 - bpp: 0.8238 - mse: 1.2369e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5773 - bpp: 0.7849 - mse: 9.6741e-05\n",
      "Epoch 967: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5773 - bpp: 0.7849 - mse: 9.6741e-05\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7249 - bpp: 0.8326 - mse: 1.0892e-04\n",
      "Epoch 968: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 1.7249 - bpp: 0.8326 - mse: 1.0892e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4989 - bpp: 0.7603 - mse: 9.0163e-05\n",
      "Epoch 969: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.4989 - bpp: 0.7603 - mse: 9.0163e-05\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6233 - bpp: 0.8014 - mse: 1.0034e-04\n",
      "Epoch 970: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6233 - bpp: 0.8014 - mse: 1.0034e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6036 - bpp: 0.7861 - mse: 9.9791e-05\n",
      "Epoch 971: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6036 - bpp: 0.7861 - mse: 9.9791e-05\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4257 - bpp: 0.7395 - mse: 8.3755e-05\n",
      "Epoch 972: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.4257 - bpp: 0.7395 - mse: 8.3755e-05\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5723 - bpp: 0.7825 - mse: 9.6413e-05\n",
      "Epoch 973: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5723 - bpp: 0.7825 - mse: 9.6413e-05\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5292 - bpp: 0.7673 - mse: 9.3007e-05\n",
      "Epoch 974: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 1.5292 - bpp: 0.7673 - mse: 9.3007e-05\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5832 - bpp: 0.7801 - mse: 9.8033e-05\n",
      "Epoch 975: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5832 - bpp: 0.7801 - mse: 9.8033e-05\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6159 - bpp: 0.7784 - mse: 1.0224e-04\n",
      "Epoch 976: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6159 - bpp: 0.7784 - mse: 1.0224e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5280 - bpp: 0.7770 - mse: 9.1674e-05\n",
      "Epoch 977: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.5280 - bpp: 0.7770 - mse: 9.1674e-05\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6054 - bpp: 0.7764 - mse: 1.0120e-04\n",
      "Epoch 978: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.6054 - bpp: 0.7764 - mse: 1.0120e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5880 - bpp: 0.7885 - mse: 9.7595e-05\n",
      "Epoch 979: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.5880 - bpp: 0.7885 - mse: 9.7595e-05\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5950 - bpp: 0.7864 - mse: 9.8705e-05\n",
      "Epoch 980: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5950 - bpp: 0.7864 - mse: 9.8705e-05\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7229 - bpp: 0.8033 - mse: 1.1226e-04\n",
      "Epoch 981: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.7229 - bpp: 0.8033 - mse: 1.1226e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6991 - bpp: 0.8235 - mse: 1.0688e-04\n",
      "Epoch 982: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.6991 - bpp: 0.8235 - mse: 1.0688e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7072 - bpp: 0.8046 - mse: 1.1017e-04\n",
      "Epoch 983: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.7072 - bpp: 0.8046 - mse: 1.1017e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7550 - bpp: 0.8207 - mse: 1.1405e-04\n",
      "Epoch 984: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.7550 - bpp: 0.8207 - mse: 1.1405e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6693 - bpp: 0.8150 - mse: 1.0429e-04\n",
      "Epoch 985: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.6693 - bpp: 0.8150 - mse: 1.0429e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6326 - bpp: 0.8087 - mse: 1.0057e-04\n",
      "Epoch 986: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.6326 - bpp: 0.8087 - mse: 1.0057e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5949 - bpp: 0.7836 - mse: 9.9033e-05\n",
      "Epoch 987: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.5949 - bpp: 0.7836 - mse: 9.9033e-05\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7701 - bpp: 0.8140 - mse: 1.1671e-04\n",
      "Epoch 988: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.7701 - bpp: 0.8140 - mse: 1.1671e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4639 - bpp: 0.7627 - mse: 8.5597e-05\n",
      "Epoch 989: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.4639 - bpp: 0.7627 - mse: 8.5597e-05\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5229 - bpp: 0.7679 - mse: 9.2161e-05\n",
      "Epoch 990: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5229 - bpp: 0.7679 - mse: 9.2161e-05\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6871 - bpp: 0.8165 - mse: 1.0627e-04\n",
      "Epoch 991: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6871 - bpp: 0.8165 - mse: 1.0627e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6804 - bpp: 0.8003 - mse: 1.0743e-04\n",
      "Epoch 992: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.6804 - bpp: 0.8003 - mse: 1.0743e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5191 - bpp: 0.7572 - mse: 9.3013e-05\n",
      "Epoch 993: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.5191 - bpp: 0.7572 - mse: 9.3013e-05\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5484 - bpp: 0.7678 - mse: 9.5288e-05\n",
      "Epoch 994: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5484 - bpp: 0.7678 - mse: 9.5288e-05\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4524 - bpp: 0.7407 - mse: 8.6885e-05\n",
      "Epoch 995: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4524 - bpp: 0.7407 - mse: 8.6885e-05\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5627 - bpp: 0.7762 - mse: 9.6004e-05\n",
      "Epoch 996: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.5627 - bpp: 0.7762 - mse: 9.6004e-05\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5812 - bpp: 0.7831 - mse: 9.7424e-05\n",
      "Epoch 997: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5812 - bpp: 0.7831 - mse: 9.7424e-05\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5402 - bpp: 0.7594 - mse: 9.5321e-05\n",
      "Epoch 998: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5402 - bpp: 0.7594 - mse: 9.5321e-05\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5721 - bpp: 0.7738 - mse: 9.7449e-05\n",
      "Epoch 999: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.5721 - bpp: 0.7738 - mse: 9.7449e-05\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6320 - bpp: 0.7781 - mse: 1.0423e-04\n",
      "Epoch 1000: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6320 - bpp: 0.7781 - mse: 1.0423e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7672 - bpp: 0.8312 - mse: 1.1426e-04\n",
      "Epoch 1001: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7672 - bpp: 0.8312 - mse: 1.1426e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8340 - bpp: 0.8304 - mse: 1.2251e-04\n",
      "Epoch 1002: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 1.8340 - bpp: 0.8304 - mse: 1.2251e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5253 - bpp: 0.7728 - mse: 9.1855e-05\n",
      "Epoch 1003: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.5253 - bpp: 0.7728 - mse: 9.1855e-05\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6717 - bpp: 0.8028 - mse: 1.0607e-04\n",
      "Epoch 1004: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6717 - bpp: 0.8028 - mse: 1.0607e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4756 - bpp: 0.7562 - mse: 8.7825e-05\n",
      "Epoch 1005: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.4756 - bpp: 0.7562 - mse: 8.7825e-05\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6221 - bpp: 0.7918 - mse: 1.0136e-04\n",
      "Epoch 1006: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 1.6221 - bpp: 0.7918 - mse: 1.0136e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6159 - bpp: 0.7903 - mse: 1.0079e-04\n",
      "Epoch 1007: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.6159 - bpp: 0.7903 - mse: 1.0079e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7707 - bpp: 0.8159 - mse: 1.1656e-04\n",
      "Epoch 1008: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.7707 - bpp: 0.8159 - mse: 1.1656e-04\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5372 - bpp: 0.7466 - mse: 9.6515e-05\n",
      "Epoch 1009: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5372 - bpp: 0.7466 - mse: 9.6515e-05\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5320 - bpp: 0.7691 - mse: 9.3127e-05\n",
      "Epoch 1010: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5320 - bpp: 0.7691 - mse: 9.3127e-05\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7301 - bpp: 0.8415 - mse: 1.0848e-04\n",
      "Epoch 1011: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.7301 - bpp: 0.8415 - mse: 1.0848e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4651 - bpp: 0.7467 - mse: 8.7691e-05\n",
      "Epoch 1012: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.4651 - bpp: 0.7467 - mse: 8.7691e-05\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6189 - bpp: 0.7912 - mse: 1.0104e-04\n",
      "Epoch 1013: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6189 - bpp: 0.7912 - mse: 1.0104e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8187 - bpp: 0.8167 - mse: 1.2232e-04\n",
      "Epoch 1014: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.8187 - bpp: 0.8167 - mse: 1.2232e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5465 - bpp: 0.7776 - mse: 9.3860e-05\n",
      "Epoch 1015: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.5465 - bpp: 0.7776 - mse: 9.3860e-05\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5286 - bpp: 0.7500 - mse: 9.5049e-05\n",
      "Epoch 1016: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5286 - bpp: 0.7500 - mse: 9.5049e-05\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7513 - bpp: 0.8159 - mse: 1.1418e-04\n",
      "Epoch 1017: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.7513 - bpp: 0.8159 - mse: 1.1418e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7417 - bpp: 0.8247 - mse: 1.1194e-04\n",
      "Epoch 1018: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7417 - bpp: 0.8247 - mse: 1.1194e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7317 - bpp: 0.8175 - mse: 1.1159e-04\n",
      "Epoch 1019: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.7317 - bpp: 0.8175 - mse: 1.1159e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5929 - bpp: 0.7940 - mse: 9.7527e-05\n",
      "Epoch 1020: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.5929 - bpp: 0.7940 - mse: 9.7527e-05\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4967 - bpp: 0.7576 - mse: 9.0227e-05\n",
      "Epoch 1021: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4967 - bpp: 0.7576 - mse: 9.0227e-05\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5907 - bpp: 0.7861 - mse: 9.8218e-05\n",
      "Epoch 1022: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5907 - bpp: 0.7861 - mse: 9.8218e-05\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6222 - bpp: 0.7878 - mse: 1.0186e-04\n",
      "Epoch 1023: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.6222 - bpp: 0.7878 - mse: 1.0186e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5744 - bpp: 0.7803 - mse: 9.6937e-05\n",
      "Epoch 1024: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5744 - bpp: 0.7803 - mse: 9.6937e-05\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6719 - bpp: 0.8123 - mse: 1.0494e-04\n",
      "Epoch 1025: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 1.6719 - bpp: 0.8123 - mse: 1.0494e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7273 - bpp: 0.8385 - mse: 1.0850e-04\n",
      "Epoch 1026: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.7273 - bpp: 0.8385 - mse: 1.0850e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5546 - bpp: 0.7783 - mse: 9.4760e-05\n",
      "Epoch 1027: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.5546 - bpp: 0.7783 - mse: 9.4760e-05\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4882 - bpp: 0.7501 - mse: 9.0093e-05\n",
      "Epoch 1028: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.4882 - bpp: 0.7501 - mse: 9.0093e-05\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6194 - bpp: 0.7895 - mse: 1.0131e-04\n",
      "Epoch 1029: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6194 - bpp: 0.7895 - mse: 1.0131e-04\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6693 - bpp: 0.8086 - mse: 1.0506e-04\n",
      "Epoch 1030: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.6693 - bpp: 0.8086 - mse: 1.0506e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5771 - bpp: 0.7663 - mse: 9.8971e-05\n",
      "Epoch 1031: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.5771 - bpp: 0.7663 - mse: 9.8971e-05\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7880 - bpp: 0.8314 - mse: 1.1678e-04\n",
      "Epoch 1032: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.7880 - bpp: 0.8314 - mse: 1.1678e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4914 - bpp: 0.7604 - mse: 8.9231e-05\n",
      "Epoch 1033: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.4914 - bpp: 0.7604 - mse: 8.9231e-05\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5518 - bpp: 0.7593 - mse: 9.6742e-05\n",
      "Epoch 1034: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.5518 - bpp: 0.7593 - mse: 9.6742e-05\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5264 - bpp: 0.7627 - mse: 9.3227e-05\n",
      "Epoch 1035: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5264 - bpp: 0.7627 - mse: 9.3227e-05\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5844 - bpp: 0.7667 - mse: 9.9823e-05\n",
      "Epoch 1036: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5844 - bpp: 0.7667 - mse: 9.9823e-05\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7439 - bpp: 0.7940 - mse: 1.1596e-04\n",
      "Epoch 1037: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.7439 - bpp: 0.7940 - mse: 1.1596e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7306 - bpp: 0.8202 - mse: 1.1114e-04\n",
      "Epoch 1038: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.7306 - bpp: 0.8202 - mse: 1.1114e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6350 - bpp: 0.7932 - mse: 1.0277e-04\n",
      "Epoch 1039: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6350 - bpp: 0.7932 - mse: 1.0277e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6608 - bpp: 0.8021 - mse: 1.0482e-04\n",
      "Epoch 1040: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.6608 - bpp: 0.8021 - mse: 1.0482e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6523 - bpp: 0.8038 - mse: 1.0358e-04\n",
      "Epoch 1041: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.6523 - bpp: 0.8038 - mse: 1.0358e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6071 - bpp: 0.8016 - mse: 9.8331e-05\n",
      "Epoch 1042: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6071 - bpp: 0.8016 - mse: 9.8331e-05\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6333 - bpp: 0.7905 - mse: 1.0288e-04\n",
      "Epoch 1043: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 59s 291ms/step - loss: 1.6333 - bpp: 0.7905 - mse: 1.0288e-04\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6590 - bpp: 0.8091 - mse: 1.0375e-04\n",
      "Epoch 1044: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.6590 - bpp: 0.8091 - mse: 1.0375e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8191 - bpp: 0.8258 - mse: 1.2126e-04\n",
      "Epoch 1045: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.8191 - bpp: 0.8258 - mse: 1.2126e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5447 - bpp: 0.7778 - mse: 9.3622e-05\n",
      "Epoch 1046: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5447 - bpp: 0.7778 - mse: 9.3622e-05\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5442 - bpp: 0.7738 - mse: 9.4035e-05\n",
      "Epoch 1047: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5442 - bpp: 0.7738 - mse: 9.4035e-05\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6127 - bpp: 0.7845 - mse: 1.0110e-04\n",
      "Epoch 1048: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.6127 - bpp: 0.7845 - mse: 1.0110e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5814 - bpp: 0.7686 - mse: 9.9213e-05\n",
      "Epoch 1049: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5814 - bpp: 0.7686 - mse: 9.9213e-05\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4606 - bpp: 0.7514 - mse: 8.6579e-05\n",
      "Epoch 1050: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4606 - bpp: 0.7514 - mse: 8.6579e-05\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6232 - bpp: 0.7944 - mse: 1.0117e-04\n",
      "Epoch 1051: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.6232 - bpp: 0.7944 - mse: 1.0117e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5834 - bpp: 0.7793 - mse: 9.8152e-05\n",
      "Epoch 1052: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5834 - bpp: 0.7793 - mse: 9.8152e-05\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6217 - bpp: 0.7857 - mse: 1.0204e-04\n",
      "Epoch 1053: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6217 - bpp: 0.7857 - mse: 1.0204e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7229 - bpp: 0.8142 - mse: 1.1092e-04\n",
      "Epoch 1054: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7229 - bpp: 0.8142 - mse: 1.1092e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4915 - bpp: 0.7590 - mse: 8.9417e-05\n",
      "Epoch 1055: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.4915 - bpp: 0.7590 - mse: 8.9417e-05\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6774 - bpp: 0.7703 - mse: 1.1073e-04\n",
      "Epoch 1056: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6774 - bpp: 0.7703 - mse: 1.1073e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7190 - bpp: 0.7984 - mse: 1.1238e-04\n",
      "Epoch 1057: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7190 - bpp: 0.7984 - mse: 1.1238e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4586 - bpp: 0.7459 - mse: 8.6994e-05\n",
      "Epoch 1058: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.4586 - bpp: 0.7459 - mse: 8.6994e-05\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7530 - bpp: 0.8132 - mse: 1.1472e-04\n",
      "Epoch 1059: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7530 - bpp: 0.8132 - mse: 1.1472e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5127 - bpp: 0.7567 - mse: 9.2284e-05\n",
      "Epoch 1060: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.5127 - bpp: 0.7567 - mse: 9.2284e-05\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5037 - bpp: 0.7651 - mse: 9.0159e-05\n",
      "Epoch 1061: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5037 - bpp: 0.7651 - mse: 9.0159e-05\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6913 - bpp: 0.7945 - mse: 1.0947e-04\n",
      "Epoch 1062: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.6913 - bpp: 0.7945 - mse: 1.0947e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5711 - bpp: 0.7862 - mse: 9.5813e-05\n",
      "Epoch 1063: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5711 - bpp: 0.7862 - mse: 9.5813e-05\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5812 - bpp: 0.7854 - mse: 9.7138e-05\n",
      "Epoch 1064: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.5812 - bpp: 0.7854 - mse: 9.7138e-05\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5063 - bpp: 0.7609 - mse: 9.0987e-05\n",
      "Epoch 1065: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5063 - bpp: 0.7609 - mse: 9.0987e-05\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.8003 - mse: 1.0767e-04\n",
      "Epoch 1066: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6823 - bpp: 0.8003 - mse: 1.0767e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6505 - bpp: 0.8040 - mse: 1.0333e-04\n",
      "Epoch 1067: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.6505 - bpp: 0.8040 - mse: 1.0333e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6029 - bpp: 0.7851 - mse: 9.9828e-05\n",
      "Epoch 1068: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.6029 - bpp: 0.7851 - mse: 9.9828e-05\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6728 - bpp: 0.8029 - mse: 1.0618e-04\n",
      "Epoch 1069: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.6728 - bpp: 0.8029 - mse: 1.0618e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.8129 - mse: 1.0613e-04\n",
      "Epoch 1070: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6823 - bpp: 0.8129 - mse: 1.0613e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7167 - bpp: 0.8106 - mse: 1.1060e-04\n",
      "Epoch 1071: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.7167 - bpp: 0.8106 - mse: 1.1060e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5808 - bpp: 0.7873 - mse: 9.6862e-05\n",
      "Epoch 1072: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 1.5808 - bpp: 0.7873 - mse: 9.6862e-05\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5507 - bpp: 0.7721 - mse: 9.5033e-05\n",
      "Epoch 1073: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5507 - bpp: 0.7721 - mse: 9.5033e-05\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5055 - bpp: 0.7532 - mse: 9.1828e-05\n",
      "Epoch 1074: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5055 - bpp: 0.7532 - mse: 9.1828e-05\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6127 - bpp: 0.7954 - mse: 9.9769e-05\n",
      "Epoch 1075: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6127 - bpp: 0.7954 - mse: 9.9769e-05\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5411 - bpp: 0.7764 - mse: 9.3340e-05\n",
      "Epoch 1076: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5411 - bpp: 0.7764 - mse: 9.3340e-05\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6045 - bpp: 0.7714 - mse: 1.0170e-04\n",
      "Epoch 1077: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.6045 - bpp: 0.7714 - mse: 1.0170e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7436 - bpp: 0.8133 - mse: 1.1356e-04\n",
      "Epoch 1078: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.7436 - bpp: 0.8133 - mse: 1.1356e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7068 - bpp: 0.8081 - mse: 1.0970e-04\n",
      "Epoch 1079: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7068 - bpp: 0.8081 - mse: 1.0970e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7068 - bpp: 0.8136 - mse: 1.0903e-04\n",
      "Epoch 1080: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7068 - bpp: 0.8136 - mse: 1.0903e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6112 - bpp: 0.7771 - mse: 1.0182e-04\n",
      "Epoch 1081: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.6112 - bpp: 0.7771 - mse: 1.0182e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4489 - bpp: 0.7444 - mse: 8.5996e-05\n",
      "Epoch 1082: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.4489 - bpp: 0.7444 - mse: 8.5996e-05\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5508 - bpp: 0.7666 - mse: 9.5723e-05\n",
      "Epoch 1083: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.5508 - bpp: 0.7666 - mse: 9.5723e-05\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8006 - bpp: 0.8380 - mse: 1.1750e-04\n",
      "Epoch 1084: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.8006 - bpp: 0.8380 - mse: 1.1750e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4171 - bpp: 0.7406 - mse: 8.2587e-05\n",
      "Epoch 1085: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.4171 - bpp: 0.7406 - mse: 8.2587e-05\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5529 - bpp: 0.7627 - mse: 9.6454e-05\n",
      "Epoch 1086: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.5529 - bpp: 0.7627 - mse: 9.6454e-05\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5787 - bpp: 0.7802 - mse: 9.7484e-05\n",
      "Epoch 1087: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 1.5787 - bpp: 0.7802 - mse: 9.7484e-05\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5596 - bpp: 0.7658 - mse: 9.6909e-05\n",
      "Epoch 1088: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5596 - bpp: 0.7658 - mse: 9.6909e-05\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5794 - bpp: 0.8010 - mse: 9.5012e-05\n",
      "Epoch 1089: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.5794 - bpp: 0.8010 - mse: 9.5012e-05\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5550 - bpp: 0.7753 - mse: 9.5188e-05\n",
      "Epoch 1090: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5550 - bpp: 0.7753 - mse: 9.5188e-05\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5774 - bpp: 0.7948 - mse: 9.5539e-05\n",
      "Epoch 1091: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.5774 - bpp: 0.7948 - mse: 9.5539e-05\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5406 - bpp: 0.7637 - mse: 9.4827e-05\n",
      "Epoch 1092: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5406 - bpp: 0.7637 - mse: 9.4827e-05\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4977 - bpp: 0.7540 - mse: 9.0789e-05\n",
      "Epoch 1093: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.4977 - bpp: 0.7540 - mse: 9.0789e-05\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4974 - bpp: 0.7584 - mse: 9.0203e-05\n",
      "Epoch 1094: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.4974 - bpp: 0.7584 - mse: 9.0203e-05\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4959 - bpp: 0.7685 - mse: 8.8783e-05\n",
      "Epoch 1095: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.4959 - bpp: 0.7685 - mse: 8.8783e-05\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4862 - bpp: 0.7553 - mse: 8.9217e-05\n",
      "Epoch 1096: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.4862 - bpp: 0.7553 - mse: 8.9217e-05\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4552 - bpp: 0.7471 - mse: 8.6436e-05\n",
      "Epoch 1097: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.4552 - bpp: 0.7471 - mse: 8.6436e-05\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5780 - bpp: 0.7695 - mse: 9.8684e-05\n",
      "Epoch 1098: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5780 - bpp: 0.7695 - mse: 9.8684e-05\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6618 - bpp: 0.7891 - mse: 1.0653e-04\n",
      "Epoch 1099: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6618 - bpp: 0.7891 - mse: 1.0653e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6525 - bpp: 0.8046 - mse: 1.0350e-04\n",
      "Epoch 1100: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6525 - bpp: 0.8046 - mse: 1.0350e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5488 - bpp: 0.7835 - mse: 9.3418e-05\n",
      "Epoch 1101: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.5488 - bpp: 0.7835 - mse: 9.3418e-05\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6794 - bpp: 0.8129 - mse: 1.0578e-04\n",
      "Epoch 1102: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6794 - bpp: 0.8129 - mse: 1.0578e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5497 - bpp: 0.7625 - mse: 9.6093e-05\n",
      "Epoch 1103: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.5497 - bpp: 0.7625 - mse: 9.6093e-05\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5645 - bpp: 0.7750 - mse: 9.6384e-05\n",
      "Epoch 1104: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.5645 - bpp: 0.7750 - mse: 9.6384e-05\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6056 - bpp: 0.7971 - mse: 9.8697e-05\n",
      "Epoch 1105: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6056 - bpp: 0.7971 - mse: 9.8697e-05\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7118 - bpp: 0.8099 - mse: 1.1010e-04\n",
      "Epoch 1106: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 1.7118 - bpp: 0.8099 - mse: 1.1010e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5189 - bpp: 0.7699 - mse: 9.1421e-05\n",
      "Epoch 1107: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.5189 - bpp: 0.7699 - mse: 9.1421e-05\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6408 - bpp: 0.7865 - mse: 1.0429e-04\n",
      "Epoch 1108: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6408 - bpp: 0.7865 - mse: 1.0429e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6685 - bpp: 0.7913 - mse: 1.0708e-04\n",
      "Epoch 1109: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6685 - bpp: 0.7913 - mse: 1.0708e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5208 - bpp: 0.7517 - mse: 9.3881e-05\n",
      "Epoch 1110: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 1.5208 - bpp: 0.7517 - mse: 9.3881e-05\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4496 - bpp: 0.7490 - mse: 8.5529e-05\n",
      "Epoch 1111: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.4496 - bpp: 0.7490 - mse: 8.5529e-05\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5633 - bpp: 0.7775 - mse: 9.5925e-05\n",
      "Epoch 1112: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5633 - bpp: 0.7775 - mse: 9.5925e-05\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5841 - bpp: 0.7936 - mse: 9.6494e-05\n",
      "Epoch 1113: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.5841 - bpp: 0.7936 - mse: 9.6494e-05\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6221 - bpp: 0.7840 - mse: 1.0230e-04\n",
      "Epoch 1114: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6221 - bpp: 0.7840 - mse: 1.0230e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5863 - bpp: 0.7727 - mse: 9.9323e-05\n",
      "Epoch 1115: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.5863 - bpp: 0.7727 - mse: 9.9323e-05\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6181 - bpp: 0.7829 - mse: 1.0196e-04\n",
      "Epoch 1116: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 1.6181 - bpp: 0.7829 - mse: 1.0196e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5589 - bpp: 0.7611 - mse: 9.7382e-05\n",
      "Epoch 1117: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5589 - bpp: 0.7611 - mse: 9.7382e-05\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5940 - bpp: 0.7763 - mse: 9.9811e-05\n",
      "Epoch 1118: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.5940 - bpp: 0.7763 - mse: 9.9811e-05\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6634 - bpp: 0.7996 - mse: 1.0544e-04\n",
      "Epoch 1119: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.6634 - bpp: 0.7996 - mse: 1.0544e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5999 - bpp: 0.7981 - mse: 9.7868e-05\n",
      "Epoch 1120: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5999 - bpp: 0.7981 - mse: 9.7868e-05\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6527 - bpp: 0.7856 - mse: 1.0585e-04\n",
      "Epoch 1121: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6527 - bpp: 0.7856 - mse: 1.0585e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5227 - bpp: 0.7597 - mse: 9.3134e-05\n",
      "Epoch 1122: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5227 - bpp: 0.7597 - mse: 9.3134e-05\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4999 - bpp: 0.7625 - mse: 9.0013e-05\n",
      "Epoch 1123: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.4999 - bpp: 0.7625 - mse: 9.0013e-05\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5518 - bpp: 0.7594 - mse: 9.6731e-05\n",
      "Epoch 1124: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5518 - bpp: 0.7594 - mse: 9.6731e-05\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5001 - bpp: 0.7598 - mse: 9.0364e-05\n",
      "Epoch 1125: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5001 - bpp: 0.7598 - mse: 9.0364e-05\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4575 - bpp: 0.7412 - mse: 8.7438e-05\n",
      "Epoch 1126: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4575 - bpp: 0.7412 - mse: 8.7438e-05\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6058 - bpp: 0.7883 - mse: 9.9801e-05\n",
      "Epoch 1127: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.6058 - bpp: 0.7883 - mse: 9.9801e-05\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6068 - bpp: 0.7744 - mse: 1.0161e-04\n",
      "Epoch 1128: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6068 - bpp: 0.7744 - mse: 1.0161e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5052 - bpp: 0.7651 - mse: 9.0342e-05\n",
      "Epoch 1129: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.5052 - bpp: 0.7651 - mse: 9.0342e-05\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6937 - bpp: 0.8147 - mse: 1.0730e-04\n",
      "Epoch 1130: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.6937 - bpp: 0.8147 - mse: 1.0730e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7221 - bpp: 0.8140 - mse: 1.1085e-04\n",
      "Epoch 1131: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.7221 - bpp: 0.8140 - mse: 1.1085e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5934 - bpp: 0.7860 - mse: 9.8560e-05\n",
      "Epoch 1132: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.5934 - bpp: 0.7860 - mse: 9.8560e-05\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6106 - bpp: 0.7862 - mse: 1.0064e-04\n",
      "Epoch 1133: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6106 - bpp: 0.7862 - mse: 1.0064e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6337 - bpp: 0.7998 - mse: 1.0180e-04\n",
      "Epoch 1134: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.6337 - bpp: 0.7998 - mse: 1.0180e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6802 - bpp: 0.8079 - mse: 1.0648e-04\n",
      "Epoch 1135: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6802 - bpp: 0.8079 - mse: 1.0648e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5220 - bpp: 0.7795 - mse: 9.0637e-05\n",
      "Epoch 1136: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5220 - bpp: 0.7795 - mse: 9.0637e-05\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6025 - bpp: 0.7827 - mse: 1.0007e-04\n",
      "Epoch 1137: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.6025 - bpp: 0.7827 - mse: 1.0007e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6672 - bpp: 0.7985 - mse: 1.0605e-04\n",
      "Epoch 1138: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.6672 - bpp: 0.7985 - mse: 1.0605e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5949 - bpp: 0.7863 - mse: 9.8716e-05\n",
      "Epoch 1139: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.5949 - bpp: 0.7863 - mse: 9.8716e-05\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5320 - bpp: 0.7633 - mse: 9.3830e-05\n",
      "Epoch 1140: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5320 - bpp: 0.7633 - mse: 9.3830e-05\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6100 - bpp: 0.7861 - mse: 1.0057e-04\n",
      "Epoch 1141: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.6100 - bpp: 0.7861 - mse: 1.0057e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5871 - bpp: 0.7746 - mse: 9.9185e-05\n",
      "Epoch 1142: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.5871 - bpp: 0.7746 - mse: 9.9185e-05\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7204 - bpp: 0.8032 - mse: 1.1196e-04\n",
      "Epoch 1143: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.7204 - bpp: 0.8032 - mse: 1.1196e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5107 - bpp: 0.7595 - mse: 9.1693e-05\n",
      "Epoch 1144: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5107 - bpp: 0.7595 - mse: 9.1693e-05\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5744 - bpp: 0.7733 - mse: 9.7796e-05\n",
      "Epoch 1145: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5744 - bpp: 0.7733 - mse: 9.7796e-05\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4894 - bpp: 0.7583 - mse: 8.9250e-05\n",
      "Epoch 1146: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4894 - bpp: 0.7583 - mse: 8.9250e-05\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4983 - bpp: 0.7437 - mse: 9.2123e-05\n",
      "Epoch 1147: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4983 - bpp: 0.7437 - mse: 9.2123e-05\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5931 - bpp: 0.7768 - mse: 9.9652e-05\n",
      "Epoch 1148: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5931 - bpp: 0.7768 - mse: 9.9652e-05\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5483 - bpp: 0.7776 - mse: 9.4078e-05\n",
      "Epoch 1149: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5483 - bpp: 0.7776 - mse: 9.4078e-05\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6213 - bpp: 0.7857 - mse: 1.0200e-04\n",
      "Epoch 1150: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.6213 - bpp: 0.7857 - mse: 1.0200e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5009 - bpp: 0.7560 - mse: 9.0923e-05\n",
      "Epoch 1151: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5009 - bpp: 0.7560 - mse: 9.0923e-05\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5650 - bpp: 0.7748 - mse: 9.6456e-05\n",
      "Epoch 1152: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5650 - bpp: 0.7748 - mse: 9.6456e-05\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5426 - bpp: 0.7834 - mse: 9.2674e-05\n",
      "Epoch 1153: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5426 - bpp: 0.7834 - mse: 9.2674e-05\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5959 - bpp: 0.7705 - mse: 1.0075e-04\n",
      "Epoch 1154: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.5959 - bpp: 0.7705 - mse: 1.0075e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5012 - bpp: 0.7448 - mse: 9.2327e-05\n",
      "Epoch 1155: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.5012 - bpp: 0.7448 - mse: 9.2327e-05\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4771 - bpp: 0.7586 - mse: 8.7716e-05\n",
      "Epoch 1156: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4771 - bpp: 0.7586 - mse: 8.7716e-05\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5441 - bpp: 0.7656 - mse: 9.5032e-05\n",
      "Epoch 1157: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5441 - bpp: 0.7656 - mse: 9.5032e-05\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6409 - bpp: 0.7900 - mse: 1.0387e-04\n",
      "Epoch 1158: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6409 - bpp: 0.7900 - mse: 1.0387e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7055 - bpp: 0.8041 - mse: 1.1003e-04\n",
      "Epoch 1159: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 179ms/step - loss: 1.7055 - bpp: 0.8041 - mse: 1.1003e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5291 - bpp: 0.7556 - mse: 9.4414e-05\n",
      "Epoch 1160: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.5291 - bpp: 0.7556 - mse: 9.4414e-05\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6874 - bpp: 0.8001 - mse: 1.0832e-04\n",
      "Epoch 1161: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.6874 - bpp: 0.8001 - mse: 1.0832e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4619 - bpp: 0.7502 - mse: 8.6876e-05\n",
      "Epoch 1162: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.4619 - bpp: 0.7502 - mse: 8.6876e-05\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6202 - bpp: 0.7845 - mse: 1.0201e-04\n",
      "Epoch 1163: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 183ms/step - loss: 1.6202 - bpp: 0.7845 - mse: 1.0201e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6286 - bpp: 0.7767 - mse: 1.0399e-04\n",
      "Epoch 1164: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 164ms/step - loss: 1.6286 - bpp: 0.7767 - mse: 1.0399e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6759 - bpp: 0.7936 - mse: 1.0771e-04\n",
      "Epoch 1165: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6759 - bpp: 0.7936 - mse: 1.0771e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6205 - bpp: 0.7917 - mse: 1.0118e-04\n",
      "Epoch 1166: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.6205 - bpp: 0.7917 - mse: 1.0118e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5140 - bpp: 0.7562 - mse: 9.2515e-05\n",
      "Epoch 1167: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.5140 - bpp: 0.7562 - mse: 9.2515e-05\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5115 - bpp: 0.7630 - mse: 9.1367e-05\n",
      "Epoch 1168: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.5115 - bpp: 0.7630 - mse: 9.1367e-05\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5015 - bpp: 0.7497 - mse: 9.1782e-05\n",
      "Epoch 1169: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.5015 - bpp: 0.7497 - mse: 9.1782e-05\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4863 - bpp: 0.7518 - mse: 8.9663e-05\n",
      "Epoch 1170: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 1.4863 - bpp: 0.7518 - mse: 8.9663e-05\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5831 - bpp: 0.7719 - mse: 9.9026e-05\n",
      "Epoch 1171: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.5831 - bpp: 0.7719 - mse: 9.9026e-05\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5935 - bpp: 0.7856 - mse: 9.8618e-05\n",
      "Epoch 1172: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.5935 - bpp: 0.7856 - mse: 9.8618e-05\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6138 - bpp: 0.7859 - mse: 1.0107e-04\n",
      "Epoch 1173: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.6138 - bpp: 0.7859 - mse: 1.0107e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6640 - bpp: 0.8026 - mse: 1.0516e-04\n",
      "Epoch 1174: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.6640 - bpp: 0.8026 - mse: 1.0516e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4572 - bpp: 0.7411 - mse: 8.7423e-05\n",
      "Epoch 1175: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4572 - bpp: 0.7411 - mse: 8.7423e-05\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5781 - bpp: 0.7775 - mse: 9.7727e-05\n",
      "Epoch 1176: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.5781 - bpp: 0.7775 - mse: 9.7727e-05\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5765 - bpp: 0.7738 - mse: 9.7988e-05\n",
      "Epoch 1177: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5765 - bpp: 0.7738 - mse: 9.7988e-05\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6783 - bpp: 0.8019 - mse: 1.0698e-04\n",
      "Epoch 1178: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.6783 - bpp: 0.8019 - mse: 1.0698e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4723 - bpp: 0.7589 - mse: 8.7083e-05\n",
      "Epoch 1179: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4723 - bpp: 0.7589 - mse: 8.7083e-05\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5493 - bpp: 0.7754 - mse: 9.4472e-05\n",
      "Epoch 1180: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.5493 - bpp: 0.7754 - mse: 9.4472e-05\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5216 - bpp: 0.7634 - mse: 9.2559e-05\n",
      "Epoch 1181: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 161ms/step - loss: 1.5216 - bpp: 0.7634 - mse: 9.2559e-05\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4375 - bpp: 0.7406 - mse: 8.5079e-05\n",
      "Epoch 1182: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4375 - bpp: 0.7406 - mse: 8.5079e-05\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5640 - bpp: 0.7686 - mse: 9.7098e-05\n",
      "Epoch 1183: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.5640 - bpp: 0.7686 - mse: 9.7098e-05\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6651 - bpp: 0.8150 - mse: 1.0377e-04\n",
      "Epoch 1184: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.6651 - bpp: 0.8150 - mse: 1.0377e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5667 - bpp: 0.7701 - mse: 9.7232e-05\n",
      "Epoch 1185: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5667 - bpp: 0.7701 - mse: 9.7232e-05\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4597 - bpp: 0.7396 - mse: 8.7901e-05\n",
      "Epoch 1186: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.4597 - bpp: 0.7396 - mse: 8.7901e-05\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5041 - bpp: 0.7571 - mse: 9.1182e-05\n",
      "Epoch 1187: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 1.5041 - bpp: 0.7571 - mse: 9.1182e-05\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5556 - bpp: 0.7783 - mse: 9.4874e-05\n",
      "Epoch 1188: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.5556 - bpp: 0.7783 - mse: 9.4874e-05\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7065 - bpp: 0.7904 - mse: 1.1182e-04\n",
      "Epoch 1189: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 165ms/step - loss: 1.7065 - bpp: 0.7904 - mse: 1.1182e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5333 - bpp: 0.7661 - mse: 9.3649e-05\n",
      "Epoch 1190: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.5333 - bpp: 0.7661 - mse: 9.3649e-05\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4409 - bpp: 0.7354 - mse: 8.6127e-05\n",
      "Epoch 1191: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4409 - bpp: 0.7354 - mse: 8.6127e-05\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4671 - bpp: 0.7457 - mse: 8.8053e-05\n",
      "Epoch 1192: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4671 - bpp: 0.7457 - mse: 8.8053e-05\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3182 - bpp: 0.7062 - mse: 7.4712e-05\n",
      "Epoch 1193: loss improved from 1.41648 to 1.31820, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3182 - bpp: 0.7062 - mse: 7.4712e-05\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5480 - bpp: 0.7527 - mse: 9.7083e-05\n",
      "Epoch 1194: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5480 - bpp: 0.7527 - mse: 9.7083e-05\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7172 - bpp: 0.8094 - mse: 1.1081e-04\n",
      "Epoch 1195: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.7172 - bpp: 0.8094 - mse: 1.1081e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5890 - bpp: 0.7750 - mse: 9.9364e-05\n",
      "Epoch 1196: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.5890 - bpp: 0.7750 - mse: 9.9364e-05\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5783 - bpp: 0.7738 - mse: 9.8212e-05\n",
      "Epoch 1197: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5783 - bpp: 0.7738 - mse: 9.8212e-05\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6498 - bpp: 0.8011 - mse: 1.0359e-04\n",
      "Epoch 1198: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.6498 - bpp: 0.8011 - mse: 1.0359e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4810 - bpp: 0.7548 - mse: 8.8654e-05\n",
      "Epoch 1199: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.4810 - bpp: 0.7548 - mse: 8.8654e-05\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4244 - bpp: 0.7427 - mse: 8.3212e-05\n",
      "Epoch 1200: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4244 - bpp: 0.7427 - mse: 8.3212e-05\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5617 - bpp: 0.7620 - mse: 9.7613e-05\n",
      "Epoch 1201: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.5617 - bpp: 0.7620 - mse: 9.7613e-05\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5564 - bpp: 0.7544 - mse: 9.7904e-05\n",
      "Epoch 1202: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.5564 - bpp: 0.7544 - mse: 9.7904e-05\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5543 - bpp: 0.7681 - mse: 9.5976e-05\n",
      "Epoch 1203: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.5543 - bpp: 0.7681 - mse: 9.5976e-05\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5437 - bpp: 0.7840 - mse: 9.2737e-05\n",
      "Epoch 1204: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5437 - bpp: 0.7840 - mse: 9.2737e-05\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6873 - bpp: 0.8052 - mse: 1.0768e-04\n",
      "Epoch 1205: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.6873 - bpp: 0.8052 - mse: 1.0768e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6569 - bpp: 0.7983 - mse: 1.0480e-04\n",
      "Epoch 1206: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6569 - bpp: 0.7983 - mse: 1.0480e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5473 - bpp: 0.7650 - mse: 9.5498e-05\n",
      "Epoch 1207: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.5473 - bpp: 0.7650 - mse: 9.5498e-05\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5542 - bpp: 0.7587 - mse: 9.7102e-05\n",
      "Epoch 1208: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5542 - bpp: 0.7587 - mse: 9.7102e-05\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6491 - bpp: 0.7918 - mse: 1.0465e-04\n",
      "Epoch 1209: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.6491 - bpp: 0.7918 - mse: 1.0465e-04\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6375 - bpp: 0.7906 - mse: 1.0337e-04\n",
      "Epoch 1210: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.6375 - bpp: 0.7906 - mse: 1.0337e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5143 - bpp: 0.7713 - mse: 9.0697e-05\n",
      "Epoch 1211: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5143 - bpp: 0.7713 - mse: 9.0697e-05\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5530 - bpp: 0.7759 - mse: 9.4868e-05\n",
      "Epoch 1212: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.5530 - bpp: 0.7759 - mse: 9.4868e-05\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4289 - bpp: 0.7367 - mse: 8.4507e-05\n",
      "Epoch 1213: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4289 - bpp: 0.7367 - mse: 8.4507e-05\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4251 - bpp: 0.7238 - mse: 8.5601e-05\n",
      "Epoch 1214: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.4251 - bpp: 0.7238 - mse: 8.5601e-05\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5117 - bpp: 0.7576 - mse: 9.2053e-05\n",
      "Epoch 1215: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.5117 - bpp: 0.7576 - mse: 9.2053e-05\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4954 - bpp: 0.7450 - mse: 9.1601e-05\n",
      "Epoch 1216: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4954 - bpp: 0.7450 - mse: 9.1601e-05\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5724 - bpp: 0.7764 - mse: 9.7178e-05\n",
      "Epoch 1217: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.5724 - bpp: 0.7764 - mse: 9.7178e-05\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5300 - bpp: 0.7558 - mse: 9.4515e-05\n",
      "Epoch 1218: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.5300 - bpp: 0.7558 - mse: 9.4515e-05\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6559 - bpp: 0.7891 - mse: 1.0581e-04\n",
      "Epoch 1219: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 1.6559 - bpp: 0.7891 - mse: 1.0581e-04\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4822 - bpp: 0.7545 - mse: 8.8840e-05\n",
      "Epoch 1220: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.4822 - bpp: 0.7545 - mse: 8.8840e-05\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6809 - bpp: 0.7898 - mse: 1.0877e-04\n",
      "Epoch 1221: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6809 - bpp: 0.7898 - mse: 1.0877e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6393 - bpp: 0.8044 - mse: 1.0192e-04\n",
      "Epoch 1222: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6393 - bpp: 0.8044 - mse: 1.0192e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4360 - bpp: 0.7422 - mse: 8.4695e-05\n",
      "Epoch 1223: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4360 - bpp: 0.7422 - mse: 8.4695e-05\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6009 - bpp: 0.7873 - mse: 9.9316e-05\n",
      "Epoch 1224: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 1.6009 - bpp: 0.7873 - mse: 9.9316e-05\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7412 - bpp: 0.8249 - mse: 1.1185e-04\n",
      "Epoch 1225: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7412 - bpp: 0.8249 - mse: 1.1185e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4695 - bpp: 0.7573 - mse: 8.6936e-05\n",
      "Epoch 1226: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.4695 - bpp: 0.7573 - mse: 8.6936e-05\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6241 - bpp: 0.7769 - mse: 1.0342e-04\n",
      "Epoch 1227: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6241 - bpp: 0.7769 - mse: 1.0342e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4589 - bpp: 0.7323 - mse: 8.8699e-05\n",
      "Epoch 1228: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.4589 - bpp: 0.7323 - mse: 8.8699e-05\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6798 - bpp: 0.8274 - mse: 1.0405e-04\n",
      "Epoch 1229: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.6798 - bpp: 0.8274 - mse: 1.0405e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5601 - bpp: 0.7656 - mse: 9.6991e-05\n",
      "Epoch 1230: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.5601 - bpp: 0.7656 - mse: 9.6991e-05\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4658 - bpp: 0.7372 - mse: 8.8939e-05\n",
      "Epoch 1231: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.4658 - bpp: 0.7372 - mse: 8.8939e-05\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6975 - bpp: 0.7973 - mse: 1.0989e-04\n",
      "Epoch 1232: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6975 - bpp: 0.7973 - mse: 1.0989e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5572 - bpp: 0.7590 - mse: 9.7441e-05\n",
      "Epoch 1233: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5572 - bpp: 0.7590 - mse: 9.7441e-05\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3930 - bpp: 0.7302 - mse: 8.0908e-05\n",
      "Epoch 1234: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.3930 - bpp: 0.7302 - mse: 8.0908e-05\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5191 - bpp: 0.7609 - mse: 9.2561e-05\n",
      "Epoch 1235: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5191 - bpp: 0.7609 - mse: 9.2561e-05\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4592 - bpp: 0.7411 - mse: 8.7665e-05\n",
      "Epoch 1236: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.4592 - bpp: 0.7411 - mse: 8.7665e-05\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5248 - bpp: 0.7629 - mse: 9.3012e-05\n",
      "Epoch 1237: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.5248 - bpp: 0.7629 - mse: 9.3012e-05\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5007 - bpp: 0.7496 - mse: 9.1685e-05\n",
      "Epoch 1238: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5007 - bpp: 0.7496 - mse: 9.1685e-05\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5080 - bpp: 0.7585 - mse: 9.1486e-05\n",
      "Epoch 1239: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.5080 - bpp: 0.7585 - mse: 9.1486e-05\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5372 - bpp: 0.7758 - mse: 9.2954e-05\n",
      "Epoch 1240: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.5372 - bpp: 0.7758 - mse: 9.2954e-05\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5959 - bpp: 0.7693 - mse: 1.0091e-04\n",
      "Epoch 1241: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5959 - bpp: 0.7693 - mse: 1.0091e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3976 - bpp: 0.7274 - mse: 8.1823e-05\n",
      "Epoch 1242: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.3976 - bpp: 0.7274 - mse: 8.1823e-05\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6098 - bpp: 0.7836 - mse: 1.0085e-04\n",
      "Epoch 1243: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6098 - bpp: 0.7836 - mse: 1.0085e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5204 - bpp: 0.7730 - mse: 9.1237e-05\n",
      "Epoch 1244: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5204 - bpp: 0.7730 - mse: 9.1237e-05\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4129 - bpp: 0.7369 - mse: 8.2520e-05\n",
      "Epoch 1245: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.4129 - bpp: 0.7369 - mse: 8.2520e-05\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4231 - bpp: 0.7330 - mse: 8.4238e-05\n",
      "Epoch 1246: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.4231 - bpp: 0.7330 - mse: 8.4238e-05\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6170 - bpp: 0.7808 - mse: 1.0208e-04\n",
      "Epoch 1247: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.6170 - bpp: 0.7808 - mse: 1.0208e-04\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6383 - bpp: 0.7924 - mse: 1.0326e-04\n",
      "Epoch 1248: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6383 - bpp: 0.7924 - mse: 1.0326e-04\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4760 - bpp: 0.7442 - mse: 8.9329e-05\n",
      "Epoch 1249: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.4760 - bpp: 0.7442 - mse: 8.9329e-05\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4920 - bpp: 0.7568 - mse: 8.9742e-05\n",
      "Epoch 1250: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.4920 - bpp: 0.7568 - mse: 8.9742e-05\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5705 - bpp: 0.7798 - mse: 9.6520e-05\n",
      "Epoch 1251: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.5705 - bpp: 0.7798 - mse: 9.6520e-05\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5553 - bpp: 0.7738 - mse: 9.5396e-05\n",
      "Epoch 1252: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.5553 - bpp: 0.7738 - mse: 9.5396e-05\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5815 - bpp: 0.7783 - mse: 9.8052e-05\n",
      "Epoch 1253: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5815 - bpp: 0.7783 - mse: 9.8052e-05\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6299 - bpp: 0.7724 - mse: 1.0468e-04\n",
      "Epoch 1254: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6299 - bpp: 0.7724 - mse: 1.0468e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4457 - bpp: 0.7434 - mse: 8.5729e-05\n",
      "Epoch 1255: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4457 - bpp: 0.7434 - mse: 8.5729e-05\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6217 - bpp: 0.7815 - mse: 1.0256e-04\n",
      "Epoch 1256: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6217 - bpp: 0.7815 - mse: 1.0256e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6183 - bpp: 0.7728 - mse: 1.0321e-04\n",
      "Epoch 1257: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.6183 - bpp: 0.7728 - mse: 1.0321e-04\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5485 - bpp: 0.7610 - mse: 9.6136e-05\n",
      "Epoch 1258: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.5485 - bpp: 0.7610 - mse: 9.6136e-05\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5487 - bpp: 0.7557 - mse: 9.6799e-05\n",
      "Epoch 1259: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5487 - bpp: 0.7557 - mse: 9.6799e-05\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6116 - bpp: 0.7939 - mse: 9.9818e-05\n",
      "Epoch 1260: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6116 - bpp: 0.7939 - mse: 9.9818e-05\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5059 - bpp: 0.7562 - mse: 9.1511e-05\n",
      "Epoch 1261: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.5059 - bpp: 0.7562 - mse: 9.1511e-05\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5272 - bpp: 0.7628 - mse: 9.3312e-05\n",
      "Epoch 1262: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.5272 - bpp: 0.7628 - mse: 9.3312e-05\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5596 - bpp: 0.7657 - mse: 9.6913e-05\n",
      "Epoch 1263: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.5596 - bpp: 0.7657 - mse: 9.6913e-05\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5878 - bpp: 0.7848 - mse: 9.8024e-05\n",
      "Epoch 1264: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.5878 - bpp: 0.7848 - mse: 9.8024e-05\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5932 - bpp: 0.7772 - mse: 9.9610e-05\n",
      "Epoch 1265: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.5932 - bpp: 0.7772 - mse: 9.9610e-05\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5323 - bpp: 0.7465 - mse: 9.5915e-05\n",
      "Epoch 1266: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.5323 - bpp: 0.7465 - mse: 9.5915e-05\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5302 - bpp: 0.7521 - mse: 9.4986e-05\n",
      "Epoch 1267: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.5302 - bpp: 0.7521 - mse: 9.4986e-05\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5827 - bpp: 0.7828 - mse: 9.7634e-05\n",
      "Epoch 1268: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5827 - bpp: 0.7828 - mse: 9.7634e-05\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4926 - bpp: 0.7414 - mse: 9.1705e-05\n",
      "Epoch 1269: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.4926 - bpp: 0.7414 - mse: 9.1705e-05\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5405 - bpp: 0.7744 - mse: 9.3516e-05\n",
      "Epoch 1270: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5405 - bpp: 0.7744 - mse: 9.3516e-05\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6480 - bpp: 0.7794 - mse: 1.0604e-04\n",
      "Epoch 1271: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.6480 - bpp: 0.7794 - mse: 1.0604e-04\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5458 - bpp: 0.7746 - mse: 9.4142e-05\n",
      "Epoch 1272: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.5458 - bpp: 0.7746 - mse: 9.4142e-05\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6060 - bpp: 0.7659 - mse: 1.0255e-04\n",
      "Epoch 1273: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.6060 - bpp: 0.7659 - mse: 1.0255e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4441 - bpp: 0.7449 - mse: 8.5351e-05\n",
      "Epoch 1274: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.4441 - bpp: 0.7449 - mse: 8.5351e-05\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5456 - bpp: 0.7590 - mse: 9.6027e-05\n",
      "Epoch 1275: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5456 - bpp: 0.7590 - mse: 9.6027e-05\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7018 - bpp: 0.7997 - mse: 1.1012e-04\n",
      "Epoch 1276: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7018 - bpp: 0.7997 - mse: 1.1012e-04\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5311 - bpp: 0.7663 - mse: 9.3358e-05\n",
      "Epoch 1277: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.5311 - bpp: 0.7663 - mse: 9.3358e-05\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6339 - bpp: 0.7840 - mse: 1.0375e-04\n",
      "Epoch 1278: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6339 - bpp: 0.7840 - mse: 1.0375e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4822 - bpp: 0.7390 - mse: 9.0718e-05\n",
      "Epoch 1279: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.4822 - bpp: 0.7390 - mse: 9.0718e-05\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5977 - bpp: 0.7809 - mse: 9.9698e-05\n",
      "Epoch 1280: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.5977 - bpp: 0.7809 - mse: 9.9698e-05\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5974 - bpp: 0.7775 - mse: 1.0009e-04\n",
      "Epoch 1281: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5974 - bpp: 0.7775 - mse: 1.0009e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5701 - bpp: 0.7790 - mse: 9.6575e-05\n",
      "Epoch 1282: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5701 - bpp: 0.7790 - mse: 9.6575e-05\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4974 - bpp: 0.7525 - mse: 9.0941e-05\n",
      "Epoch 1283: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4974 - bpp: 0.7525 - mse: 9.0941e-05\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5482 - bpp: 0.7629 - mse: 9.5859e-05\n",
      "Epoch 1284: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5482 - bpp: 0.7629 - mse: 9.5859e-05\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5848 - bpp: 0.7837 - mse: 9.7789e-05\n",
      "Epoch 1285: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5848 - bpp: 0.7837 - mse: 9.7789e-05\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5018 - bpp: 0.7424 - mse: 9.2700e-05\n",
      "Epoch 1286: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5018 - bpp: 0.7424 - mse: 9.2700e-05\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4483 - bpp: 0.7481 - mse: 8.5465e-05\n",
      "Epoch 1287: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4483 - bpp: 0.7481 - mse: 8.5465e-05\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5584 - bpp: 0.7765 - mse: 9.5456e-05\n",
      "Epoch 1288: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5584 - bpp: 0.7765 - mse: 9.5456e-05\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6247 - bpp: 0.7796 - mse: 1.0317e-04\n",
      "Epoch 1289: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.6247 - bpp: 0.7796 - mse: 1.0317e-04\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5873 - bpp: 0.7804 - mse: 9.8507e-05\n",
      "Epoch 1290: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5873 - bpp: 0.7804 - mse: 9.8507e-05\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6187 - bpp: 0.7905 - mse: 1.0111e-04\n",
      "Epoch 1291: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 194ms/step - loss: 1.6187 - bpp: 0.7905 - mse: 1.0111e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5698 - bpp: 0.7694 - mse: 9.7704e-05\n",
      "Epoch 1292: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5698 - bpp: 0.7694 - mse: 9.7704e-05\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4818 - bpp: 0.7229 - mse: 9.2634e-05\n",
      "Epoch 1293: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4818 - bpp: 0.7229 - mse: 9.2634e-05\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4640 - bpp: 0.7388 - mse: 8.8523e-05\n",
      "Epoch 1294: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4640 - bpp: 0.7388 - mse: 8.8523e-05\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5523 - bpp: 0.7742 - mse: 9.4986e-05\n",
      "Epoch 1295: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5523 - bpp: 0.7742 - mse: 9.4986e-05\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5010 - bpp: 0.7408 - mse: 9.2797e-05\n",
      "Epoch 1296: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5010 - bpp: 0.7408 - mse: 9.2797e-05\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5481 - bpp: 0.7524 - mse: 9.7135e-05\n",
      "Epoch 1297: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5481 - bpp: 0.7524 - mse: 9.7135e-05\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5898 - bpp: 0.7799 - mse: 9.8868e-05\n",
      "Epoch 1298: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5898 - bpp: 0.7799 - mse: 9.8868e-05\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5917 - bpp: 0.7747 - mse: 9.9733e-05\n",
      "Epoch 1299: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5917 - bpp: 0.7747 - mse: 9.9733e-05\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5315 - bpp: 0.7532 - mse: 9.5015e-05\n",
      "Epoch 1300: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5315 - bpp: 0.7532 - mse: 9.5015e-05\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7548 - bpp: 0.8342 - mse: 1.1238e-04\n",
      "Epoch 1301: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.7548 - bpp: 0.8342 - mse: 1.1238e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4473 - bpp: 0.7343 - mse: 8.7038e-05\n",
      "Epoch 1302: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4473 - bpp: 0.7343 - mse: 8.7038e-05\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4982 - bpp: 0.7408 - mse: 9.2463e-05\n",
      "Epoch 1303: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.4982 - bpp: 0.7408 - mse: 9.2463e-05\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7476 - bpp: 0.8389 - mse: 1.1091e-04\n",
      "Epoch 1304: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.7476 - bpp: 0.8389 - mse: 1.1091e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4690 - bpp: 0.7429 - mse: 8.8636e-05\n",
      "Epoch 1305: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.4690 - bpp: 0.7429 - mse: 8.8636e-05\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5762 - bpp: 0.7637 - mse: 9.9177e-05\n",
      "Epoch 1306: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5762 - bpp: 0.7637 - mse: 9.9177e-05\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4946 - bpp: 0.7646 - mse: 8.9112e-05\n",
      "Epoch 1307: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4946 - bpp: 0.7646 - mse: 8.9112e-05\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5752 - bpp: 0.7731 - mse: 9.7907e-05\n",
      "Epoch 1308: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.5752 - bpp: 0.7731 - mse: 9.7907e-05\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5450 - bpp: 0.7682 - mse: 9.4826e-05\n",
      "Epoch 1309: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5450 - bpp: 0.7682 - mse: 9.4826e-05\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7115 - bpp: 0.8048 - mse: 1.1068e-04\n",
      "Epoch 1310: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 178ms/step - loss: 1.7115 - bpp: 0.8048 - mse: 1.1068e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5787 - bpp: 0.7770 - mse: 9.7864e-05\n",
      "Epoch 1311: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5787 - bpp: 0.7770 - mse: 9.7864e-05\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6736 - bpp: 0.7790 - mse: 1.0921e-04\n",
      "Epoch 1312: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6736 - bpp: 0.7790 - mse: 1.0921e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6242 - bpp: 0.7995 - mse: 1.0067e-04\n",
      "Epoch 1313: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 1.6242 - bpp: 0.7995 - mse: 1.0067e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5354 - bpp: 0.7597 - mse: 9.4690e-05\n",
      "Epoch 1314: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5354 - bpp: 0.7597 - mse: 9.4690e-05\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5038 - bpp: 0.7562 - mse: 9.1259e-05\n",
      "Epoch 1315: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5038 - bpp: 0.7562 - mse: 9.1259e-05\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5539 - bpp: 0.7662 - mse: 9.6155e-05\n",
      "Epoch 1316: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5539 - bpp: 0.7662 - mse: 9.6155e-05\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4966 - bpp: 0.7538 - mse: 9.0676e-05\n",
      "Epoch 1317: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4966 - bpp: 0.7538 - mse: 9.0676e-05\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4534 - bpp: 0.7458 - mse: 8.6373e-05\n",
      "Epoch 1318: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4534 - bpp: 0.7458 - mse: 8.6373e-05\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4918 - bpp: 0.7667 - mse: 8.8501e-05\n",
      "Epoch 1319: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4918 - bpp: 0.7667 - mse: 8.8501e-05\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6877 - bpp: 0.8088 - mse: 1.0730e-04\n",
      "Epoch 1320: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.6877 - bpp: 0.8088 - mse: 1.0730e-04\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4766 - bpp: 0.7512 - mse: 8.8552e-05\n",
      "Epoch 1321: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4766 - bpp: 0.7512 - mse: 8.8552e-05\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4619 - bpp: 0.7372 - mse: 8.8470e-05\n",
      "Epoch 1322: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4619 - bpp: 0.7372 - mse: 8.8470e-05\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5028 - bpp: 0.7662 - mse: 8.9927e-05\n",
      "Epoch 1323: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5028 - bpp: 0.7662 - mse: 8.9927e-05\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5603 - bpp: 0.7725 - mse: 9.6168e-05\n",
      "Epoch 1324: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5603 - bpp: 0.7725 - mse: 9.6168e-05\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6262 - bpp: 0.7916 - mse: 1.0188e-04\n",
      "Epoch 1325: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6262 - bpp: 0.7916 - mse: 1.0188e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5487 - bpp: 0.7649 - mse: 9.5684e-05\n",
      "Epoch 1326: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5487 - bpp: 0.7649 - mse: 9.5684e-05\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4345 - bpp: 0.7457 - mse: 8.4082e-05\n",
      "Epoch 1327: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4345 - bpp: 0.7457 - mse: 8.4082e-05\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5764 - bpp: 0.7815 - mse: 9.7031e-05\n",
      "Epoch 1328: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5764 - bpp: 0.7815 - mse: 9.7031e-05\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6378 - bpp: 0.7994 - mse: 1.0235e-04\n",
      "Epoch 1329: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.6378 - bpp: 0.7994 - mse: 1.0235e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4526 - bpp: 0.7401 - mse: 8.6977e-05\n",
      "Epoch 1330: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4526 - bpp: 0.7401 - mse: 8.6977e-05\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5096 - bpp: 0.7527 - mse: 9.2389e-05\n",
      "Epoch 1331: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 1.5096 - bpp: 0.7527 - mse: 9.2389e-05\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5828 - bpp: 0.7805 - mse: 9.7940e-05\n",
      "Epoch 1332: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5828 - bpp: 0.7805 - mse: 9.7940e-05\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5580 - bpp: 0.7813 - mse: 9.4815e-05\n",
      "Epoch 1333: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5580 - bpp: 0.7813 - mse: 9.4815e-05\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6286 - bpp: 0.7834 - mse: 1.0317e-04\n",
      "Epoch 1334: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.6286 - bpp: 0.7834 - mse: 1.0317e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5785 - bpp: 0.7846 - mse: 9.6915e-05\n",
      "Epoch 1335: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5785 - bpp: 0.7846 - mse: 9.6915e-05\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5192 - bpp: 0.7676 - mse: 9.1752e-05\n",
      "Epoch 1336: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5192 - bpp: 0.7676 - mse: 9.1752e-05\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5721 - bpp: 0.7722 - mse: 9.7637e-05\n",
      "Epoch 1337: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5721 - bpp: 0.7722 - mse: 9.7637e-05\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5873 - bpp: 0.7696 - mse: 9.9825e-05\n",
      "Epoch 1338: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5873 - bpp: 0.7696 - mse: 9.9825e-05\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5308 - bpp: 0.7613 - mse: 9.3933e-05\n",
      "Epoch 1339: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5308 - bpp: 0.7613 - mse: 9.3933e-05\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5638 - bpp: 0.7818 - mse: 9.5460e-05\n",
      "Epoch 1340: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5638 - bpp: 0.7818 - mse: 9.5460e-05\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4625 - bpp: 0.7508 - mse: 8.6872e-05\n",
      "Epoch 1341: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4625 - bpp: 0.7508 - mse: 8.6872e-05\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5681 - bpp: 0.7804 - mse: 9.6162e-05\n",
      "Epoch 1342: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5681 - bpp: 0.7804 - mse: 9.6162e-05\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5112 - bpp: 0.7602 - mse: 9.1680e-05\n",
      "Epoch 1343: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5112 - bpp: 0.7602 - mse: 9.1680e-05\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5354 - bpp: 0.7652 - mse: 9.4029e-05\n",
      "Epoch 1344: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.5354 - bpp: 0.7652 - mse: 9.4029e-05\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5158 - bpp: 0.7643 - mse: 9.1730e-05\n",
      "Epoch 1345: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5158 - bpp: 0.7643 - mse: 9.1730e-05\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6164 - bpp: 0.7854 - mse: 1.0144e-04\n",
      "Epoch 1346: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6164 - bpp: 0.7854 - mse: 1.0144e-04\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5081 - bpp: 0.7617 - mse: 9.1112e-05\n",
      "Epoch 1347: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.5081 - bpp: 0.7617 - mse: 9.1112e-05\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4429 - bpp: 0.7258 - mse: 8.7536e-05\n",
      "Epoch 1348: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4429 - bpp: 0.7258 - mse: 8.7536e-05\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6157 - bpp: 0.8050 - mse: 9.8956e-05\n",
      "Epoch 1349: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.6157 - bpp: 0.8050 - mse: 9.8956e-05\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5295 - bpp: 0.7615 - mse: 9.3751e-05\n",
      "Epoch 1350: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5295 - bpp: 0.7615 - mse: 9.3751e-05\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5349 - bpp: 0.7546 - mse: 9.5246e-05\n",
      "Epoch 1351: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5349 - bpp: 0.7546 - mse: 9.5246e-05\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5045 - bpp: 0.7512 - mse: 9.1957e-05\n",
      "Epoch 1352: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.5045 - bpp: 0.7512 - mse: 9.1957e-05\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3540 - bpp: 0.7073 - mse: 7.8953e-05\n",
      "Epoch 1353: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3540 - bpp: 0.7073 - mse: 7.8953e-05\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4578 - bpp: 0.7427 - mse: 8.7288e-05\n",
      "Epoch 1354: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.4578 - bpp: 0.7427 - mse: 8.7288e-05\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5380 - bpp: 0.7665 - mse: 9.4175e-05\n",
      "Epoch 1355: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5380 - bpp: 0.7665 - mse: 9.4175e-05\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4355 - bpp: 0.7430 - mse: 8.4527e-05\n",
      "Epoch 1356: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4355 - bpp: 0.7430 - mse: 8.4527e-05\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6274 - bpp: 0.7942 - mse: 1.0171e-04\n",
      "Epoch 1357: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.6274 - bpp: 0.7942 - mse: 1.0171e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5137 - bpp: 0.7570 - mse: 9.2379e-05\n",
      "Epoch 1358: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5137 - bpp: 0.7570 - mse: 9.2379e-05\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4532 - bpp: 0.7356 - mse: 8.7592e-05\n",
      "Epoch 1359: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4532 - bpp: 0.7356 - mse: 8.7592e-05\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6351 - bpp: 0.7987 - mse: 1.0211e-04\n",
      "Epoch 1360: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.6351 - bpp: 0.7987 - mse: 1.0211e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6193 - bpp: 0.7747 - mse: 1.0309e-04\n",
      "Epoch 1361: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.6193 - bpp: 0.7747 - mse: 1.0309e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5565 - bpp: 0.7670 - mse: 9.6385e-05\n",
      "Epoch 1362: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.5565 - bpp: 0.7670 - mse: 9.6385e-05\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5773 - bpp: 0.7692 - mse: 9.8643e-05\n",
      "Epoch 1363: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5773 - bpp: 0.7692 - mse: 9.8643e-05\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6882 - bpp: 0.7961 - mse: 1.0889e-04\n",
      "Epoch 1364: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.6882 - bpp: 0.7961 - mse: 1.0889e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4058 - bpp: 0.7326 - mse: 8.2175e-05\n",
      "Epoch 1365: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4058 - bpp: 0.7326 - mse: 8.2175e-05\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7504 - bpp: 0.8180 - mse: 1.1381e-04\n",
      "Epoch 1366: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.7504 - bpp: 0.8180 - mse: 1.1381e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4764 - bpp: 0.7517 - mse: 8.8474e-05\n",
      "Epoch 1367: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4764 - bpp: 0.7517 - mse: 8.8474e-05\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5726 - bpp: 0.7589 - mse: 9.9331e-05\n",
      "Epoch 1368: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.5726 - bpp: 0.7589 - mse: 9.9331e-05\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5681 - bpp: 0.7689 - mse: 9.7561e-05\n",
      "Epoch 1369: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5681 - bpp: 0.7689 - mse: 9.7561e-05\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5175 - bpp: 0.7687 - mse: 9.1406e-05\n",
      "Epoch 1370: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5175 - bpp: 0.7687 - mse: 9.1406e-05\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5634 - bpp: 0.7572 - mse: 9.8421e-05\n",
      "Epoch 1371: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5634 - bpp: 0.7572 - mse: 9.8421e-05\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6680 - bpp: 0.8098 - mse: 1.0476e-04\n",
      "Epoch 1372: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.6680 - bpp: 0.8098 - mse: 1.0476e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5683 - bpp: 0.7913 - mse: 9.4855e-05\n",
      "Epoch 1373: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5683 - bpp: 0.7913 - mse: 9.4855e-05\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4727 - bpp: 0.7395 - mse: 8.9499e-05\n",
      "Epoch 1374: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.4727 - bpp: 0.7395 - mse: 8.9499e-05\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6814 - bpp: 0.7997 - mse: 1.0763e-04\n",
      "Epoch 1375: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.6814 - bpp: 0.7997 - mse: 1.0763e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5542 - bpp: 0.7773 - mse: 9.4833e-05\n",
      "Epoch 1376: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5542 - bpp: 0.7773 - mse: 9.4833e-05\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5264 - bpp: 0.7650 - mse: 9.2944e-05\n",
      "Epoch 1377: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5264 - bpp: 0.7650 - mse: 9.2944e-05\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6533 - bpp: 0.7985 - mse: 1.0433e-04\n",
      "Epoch 1378: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6533 - bpp: 0.7985 - mse: 1.0433e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4974 - bpp: 0.7564 - mse: 9.0456e-05\n",
      "Epoch 1379: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4974 - bpp: 0.7564 - mse: 9.0456e-05\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8215 - bpp: 0.8463 - mse: 1.1905e-04\n",
      "Epoch 1380: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.8215 - bpp: 0.8463 - mse: 1.1905e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5974 - bpp: 0.7869 - mse: 9.8939e-05\n",
      "Epoch 1381: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5974 - bpp: 0.7869 - mse: 9.8939e-05\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5335 - bpp: 0.7788 - mse: 9.2119e-05\n",
      "Epoch 1382: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.5335 - bpp: 0.7788 - mse: 9.2119e-05\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6000 - bpp: 0.7763 - mse: 1.0056e-04\n",
      "Epoch 1383: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.6000 - bpp: 0.7763 - mse: 1.0056e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4557 - bpp: 0.7465 - mse: 8.6565e-05\n",
      "Epoch 1384: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.4557 - bpp: 0.7465 - mse: 8.6565e-05\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5327 - bpp: 0.7651 - mse: 9.3708e-05\n",
      "Epoch 1385: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5327 - bpp: 0.7651 - mse: 9.3708e-05\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5145 - bpp: 0.7651 - mse: 9.1488e-05\n",
      "Epoch 1386: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5145 - bpp: 0.7651 - mse: 9.1488e-05\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4781 - bpp: 0.7396 - mse: 9.0150e-05\n",
      "Epoch 1387: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4781 - bpp: 0.7396 - mse: 9.0150e-05\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6125 - bpp: 0.7722 - mse: 1.0258e-04\n",
      "Epoch 1388: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6125 - bpp: 0.7722 - mse: 1.0258e-04\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6864 - bpp: 0.7852 - mse: 1.1000e-04\n",
      "Epoch 1389: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.6864 - bpp: 0.7852 - mse: 1.1000e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4282 - bpp: 0.7427 - mse: 8.3679e-05\n",
      "Epoch 1390: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.4282 - bpp: 0.7427 - mse: 8.3679e-05\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6170 - bpp: 0.7862 - mse: 1.0142e-04\n",
      "Epoch 1391: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.6170 - bpp: 0.7862 - mse: 1.0142e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5562 - bpp: 0.7678 - mse: 9.6242e-05\n",
      "Epoch 1392: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.5562 - bpp: 0.7678 - mse: 9.6242e-05\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5500 - bpp: 0.7773 - mse: 9.4319e-05\n",
      "Epoch 1393: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5500 - bpp: 0.7773 - mse: 9.4319e-05\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6483 - bpp: 0.7869 - mse: 1.0515e-04\n",
      "Epoch 1394: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.6483 - bpp: 0.7869 - mse: 1.0515e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5432 - bpp: 0.7746 - mse: 9.3823e-05\n",
      "Epoch 1395: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5432 - bpp: 0.7746 - mse: 9.3823e-05\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7046 - bpp: 0.8001 - mse: 1.1040e-04\n",
      "Epoch 1396: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.7046 - bpp: 0.8001 - mse: 1.1040e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5800 - bpp: 0.7849 - mse: 9.7059e-05\n",
      "Epoch 1397: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.5800 - bpp: 0.7849 - mse: 9.7059e-05\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5876 - bpp: 0.7670 - mse: 1.0017e-04\n",
      "Epoch 1398: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.5876 - bpp: 0.7670 - mse: 1.0017e-04\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5535 - bpp: 0.7605 - mse: 9.6800e-05\n",
      "Epoch 1399: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5535 - bpp: 0.7605 - mse: 9.6800e-05\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5312 - bpp: 0.7829 - mse: 9.1346e-05\n",
      "Epoch 1400: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5312 - bpp: 0.7829 - mse: 9.1346e-05\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5836 - bpp: 0.7679 - mse: 9.9567e-05\n",
      "Epoch 1401: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5836 - bpp: 0.7679 - mse: 9.9567e-05\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5289 - bpp: 0.7551 - mse: 9.4448e-05\n",
      "Epoch 1402: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5289 - bpp: 0.7551 - mse: 9.4448e-05\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6132 - bpp: 0.7972 - mse: 9.9608e-05\n",
      "Epoch 1403: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.6132 - bpp: 0.7972 - mse: 9.9608e-05\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5607 - bpp: 0.7845 - mse: 9.4752e-05\n",
      "Epoch 1404: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5607 - bpp: 0.7845 - mse: 9.4752e-05\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4851 - bpp: 0.7464 - mse: 9.0174e-05\n",
      "Epoch 1405: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4851 - bpp: 0.7464 - mse: 9.0174e-05\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6029 - bpp: 0.7865 - mse: 9.9655e-05\n",
      "Epoch 1406: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.6029 - bpp: 0.7865 - mse: 9.9655e-05\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5651 - bpp: 0.7521 - mse: 9.9244e-05\n",
      "Epoch 1407: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.5651 - bpp: 0.7521 - mse: 9.9244e-05\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4263 - bpp: 0.7179 - mse: 8.6469e-05\n",
      "Epoch 1408: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.4263 - bpp: 0.7179 - mse: 8.6469e-05\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4757 - bpp: 0.7410 - mse: 8.9687e-05\n",
      "Epoch 1409: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4757 - bpp: 0.7410 - mse: 8.9687e-05\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4922 - bpp: 0.7594 - mse: 8.9457e-05\n",
      "Epoch 1410: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.4922 - bpp: 0.7594 - mse: 8.9457e-05\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5883 - bpp: 0.7736 - mse: 9.9444e-05\n",
      "Epoch 1411: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.5883 - bpp: 0.7736 - mse: 9.9444e-05\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4459 - bpp: 0.7502 - mse: 8.4923e-05\n",
      "Epoch 1412: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4459 - bpp: 0.7502 - mse: 8.4923e-05\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4981 - bpp: 0.7491 - mse: 9.1427e-05\n",
      "Epoch 1413: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.4981 - bpp: 0.7491 - mse: 9.1427e-05\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6971 - bpp: 0.7820 - mse: 1.1170e-04\n",
      "Epoch 1414: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.6971 - bpp: 0.7820 - mse: 1.1170e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5073 - bpp: 0.7476 - mse: 9.2736e-05\n",
      "Epoch 1415: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.5073 - bpp: 0.7476 - mse: 9.2736e-05\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5766 - bpp: 0.7632 - mse: 9.9294e-05\n",
      "Epoch 1416: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5766 - bpp: 0.7632 - mse: 9.9294e-05\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4458 - bpp: 0.7483 - mse: 8.5151e-05\n",
      "Epoch 1417: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.4458 - bpp: 0.7483 - mse: 8.5151e-05\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4130 - bpp: 0.7399 - mse: 8.2171e-05\n",
      "Epoch 1418: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4130 - bpp: 0.7399 - mse: 8.2171e-05\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6120 - bpp: 0.7777 - mse: 1.0184e-04\n",
      "Epoch 1419: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6120 - bpp: 0.7777 - mse: 1.0184e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5373 - bpp: 0.7607 - mse: 9.4801e-05\n",
      "Epoch 1420: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5373 - bpp: 0.7607 - mse: 9.4801e-05\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5597 - bpp: 0.7771 - mse: 9.5534e-05\n",
      "Epoch 1421: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5597 - bpp: 0.7771 - mse: 9.5534e-05\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5256 - bpp: 0.7643 - mse: 9.2932e-05\n",
      "Epoch 1422: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 178ms/step - loss: 1.5256 - bpp: 0.7643 - mse: 9.2932e-05\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5026 - bpp: 0.7597 - mse: 9.0692e-05\n",
      "Epoch 1423: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 1.5026 - bpp: 0.7597 - mse: 9.0692e-05\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5251 - bpp: 0.7727 - mse: 9.1844e-05\n",
      "Epoch 1424: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 1.5251 - bpp: 0.7727 - mse: 9.1844e-05\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5798 - bpp: 0.7779 - mse: 9.7893e-05\n",
      "Epoch 1425: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.5798 - bpp: 0.7779 - mse: 9.7893e-05\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6544 - bpp: 0.7869 - mse: 1.0589e-04\n",
      "Epoch 1426: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6544 - bpp: 0.7869 - mse: 1.0589e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6419 - bpp: 0.7859 - mse: 1.0450e-04\n",
      "Epoch 1427: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6419 - bpp: 0.7859 - mse: 1.0450e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5841 - bpp: 0.7829 - mse: 9.7806e-05\n",
      "Epoch 1428: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.5841 - bpp: 0.7829 - mse: 9.7806e-05\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5301 - bpp: 0.7584 - mse: 9.4203e-05\n",
      "Epoch 1429: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.5301 - bpp: 0.7584 - mse: 9.4203e-05\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4937 - bpp: 0.7491 - mse: 9.0888e-05\n",
      "Epoch 1430: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.4937 - bpp: 0.7491 - mse: 9.0888e-05\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4708 - bpp: 0.7430 - mse: 8.8842e-05\n",
      "Epoch 1431: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.4708 - bpp: 0.7430 - mse: 8.8842e-05\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6408 - bpp: 0.8016 - mse: 1.0244e-04\n",
      "Epoch 1432: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6408 - bpp: 0.8016 - mse: 1.0244e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4593 - bpp: 0.7341 - mse: 8.8535e-05\n",
      "Epoch 1433: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.4593 - bpp: 0.7341 - mse: 8.8535e-05\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5759 - bpp: 0.7468 - mse: 1.0122e-04\n",
      "Epoch 1434: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5759 - bpp: 0.7468 - mse: 1.0122e-04\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5289 - bpp: 0.7555 - mse: 9.4409e-05\n",
      "Epoch 1435: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.5289 - bpp: 0.7555 - mse: 9.4409e-05\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6662 - bpp: 0.7998 - mse: 1.0576e-04\n",
      "Epoch 1436: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6662 - bpp: 0.7998 - mse: 1.0576e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6189 - bpp: 0.7760 - mse: 1.0289e-04\n",
      "Epoch 1437: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6189 - bpp: 0.7760 - mse: 1.0289e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5694 - bpp: 0.7783 - mse: 9.6571e-05\n",
      "Epoch 1438: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5694 - bpp: 0.7783 - mse: 9.6571e-05\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5495 - bpp: 0.7570 - mse: 9.6743e-05\n",
      "Epoch 1439: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.5495 - bpp: 0.7570 - mse: 9.6743e-05\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5109 - bpp: 0.7659 - mse: 9.0938e-05\n",
      "Epoch 1440: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5109 - bpp: 0.7659 - mse: 9.0938e-05\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5422 - bpp: 0.7655 - mse: 9.4808e-05\n",
      "Epoch 1441: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5422 - bpp: 0.7655 - mse: 9.4808e-05\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6393 - bpp: 0.7939 - mse: 1.0320e-04\n",
      "Epoch 1442: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6393 - bpp: 0.7939 - mse: 1.0320e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4517 - bpp: 0.7450 - mse: 8.6272e-05\n",
      "Epoch 1443: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.4517 - bpp: 0.7450 - mse: 8.6272e-05\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5137 - bpp: 0.7601 - mse: 9.1991e-05\n",
      "Epoch 1444: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5137 - bpp: 0.7601 - mse: 9.1991e-05\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7508 - bpp: 0.8224 - mse: 1.1333e-04\n",
      "Epoch 1445: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.7508 - bpp: 0.8224 - mse: 1.1333e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4857 - bpp: 0.7569 - mse: 8.8966e-05\n",
      "Epoch 1446: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4857 - bpp: 0.7569 - mse: 8.8966e-05\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4919 - bpp: 0.7476 - mse: 9.0855e-05\n",
      "Epoch 1447: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4919 - bpp: 0.7476 - mse: 9.0855e-05\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5648 - bpp: 0.7798 - mse: 9.5826e-05\n",
      "Epoch 1448: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5648 - bpp: 0.7798 - mse: 9.5826e-05\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5102 - bpp: 0.7563 - mse: 9.2039e-05\n",
      "Epoch 1449: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5102 - bpp: 0.7563 - mse: 9.2039e-05\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5777 - bpp: 0.7784 - mse: 9.7576e-05\n",
      "Epoch 1450: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5777 - bpp: 0.7784 - mse: 9.7576e-05\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4875 - bpp: 0.7373 - mse: 9.1582e-05\n",
      "Epoch 1451: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4875 - bpp: 0.7373 - mse: 9.1582e-05\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6473 - bpp: 0.7866 - mse: 1.0506e-04\n",
      "Epoch 1452: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.6473 - bpp: 0.7866 - mse: 1.0506e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6194 - bpp: 0.7772 - mse: 1.0281e-04\n",
      "Epoch 1453: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.6194 - bpp: 0.7772 - mse: 1.0281e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5009 - bpp: 0.7573 - mse: 9.0768e-05\n",
      "Epoch 1454: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5009 - bpp: 0.7573 - mse: 9.0768e-05\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5095 - bpp: 0.7605 - mse: 9.1429e-05\n",
      "Epoch 1455: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5095 - bpp: 0.7605 - mse: 9.1429e-05\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4335 - bpp: 0.7386 - mse: 8.4827e-05\n",
      "Epoch 1456: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.4335 - bpp: 0.7386 - mse: 8.4827e-05\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5479 - bpp: 0.7680 - mse: 9.5203e-05\n",
      "Epoch 1457: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5479 - bpp: 0.7680 - mse: 9.5203e-05\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6501 - bpp: 0.8081 - mse: 1.0278e-04\n",
      "Epoch 1458: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.6501 - bpp: 0.8081 - mse: 1.0278e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6470 - bpp: 0.7918 - mse: 1.0440e-04\n",
      "Epoch 1459: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6470 - bpp: 0.7918 - mse: 1.0440e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5831 - bpp: 0.7773 - mse: 9.8369e-05\n",
      "Epoch 1460: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5831 - bpp: 0.7773 - mse: 9.8369e-05\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5220 - bpp: 0.7494 - mse: 9.4317e-05\n",
      "Epoch 1461: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5220 - bpp: 0.7494 - mse: 9.4317e-05\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4753 - bpp: 0.7535 - mse: 8.8108e-05\n",
      "Epoch 1462: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4753 - bpp: 0.7535 - mse: 8.8108e-05\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5642 - bpp: 0.7838 - mse: 9.5265e-05\n",
      "Epoch 1463: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5642 - bpp: 0.7838 - mse: 9.5265e-05\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4942 - bpp: 0.7352 - mse: 9.2654e-05\n",
      "Epoch 1464: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4942 - bpp: 0.7352 - mse: 9.2654e-05\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5552 - bpp: 0.7762 - mse: 9.5087e-05\n",
      "Epoch 1465: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5552 - bpp: 0.7762 - mse: 9.5087e-05\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5355 - bpp: 0.7573 - mse: 9.4984e-05\n",
      "Epoch 1466: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5355 - bpp: 0.7573 - mse: 9.4984e-05\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5393 - bpp: 0.7561 - mse: 9.5597e-05\n",
      "Epoch 1467: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5393 - bpp: 0.7561 - mse: 9.5597e-05\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5332 - bpp: 0.7719 - mse: 9.2934e-05\n",
      "Epoch 1468: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5332 - bpp: 0.7719 - mse: 9.2934e-05\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5440 - bpp: 0.7478 - mse: 9.7199e-05\n",
      "Epoch 1469: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5440 - bpp: 0.7478 - mse: 9.7199e-05\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5654 - bpp: 0.7639 - mse: 9.7846e-05\n",
      "Epoch 1470: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5654 - bpp: 0.7639 - mse: 9.7846e-05\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5130 - bpp: 0.7607 - mse: 9.1827e-05\n",
      "Epoch 1471: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5130 - bpp: 0.7607 - mse: 9.1827e-05\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4826 - bpp: 0.7540 - mse: 8.8937e-05\n",
      "Epoch 1472: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.4826 - bpp: 0.7540 - mse: 8.8937e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4681 - bpp: 0.7304 - mse: 9.0054e-05\n",
      "Epoch 1473: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4681 - bpp: 0.7304 - mse: 9.0054e-05\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4474 - bpp: 0.7524 - mse: 8.4832e-05\n",
      "Epoch 1474: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4474 - bpp: 0.7524 - mse: 8.4832e-05\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5234 - bpp: 0.7601 - mse: 9.3175e-05\n",
      "Epoch 1475: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5234 - bpp: 0.7601 - mse: 9.3175e-05\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4679 - bpp: 0.7452 - mse: 8.8226e-05\n",
      "Epoch 1476: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.4679 - bpp: 0.7452 - mse: 8.8226e-05\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4912 - bpp: 0.7410 - mse: 9.1574e-05\n",
      "Epoch 1477: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.4912 - bpp: 0.7410 - mse: 9.1574e-05\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4520 - bpp: 0.7477 - mse: 8.5979e-05\n",
      "Epoch 1478: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 43s 208ms/step - loss: 1.4520 - bpp: 0.7477 - mse: 8.5979e-05\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5659 - bpp: 0.7797 - mse: 9.5970e-05\n",
      "Epoch 1479: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5659 - bpp: 0.7797 - mse: 9.5970e-05\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7596 - bpp: 0.8332 - mse: 1.1308e-04\n",
      "Epoch 1480: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.7596 - bpp: 0.8332 - mse: 1.1308e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5797 - bpp: 0.7792 - mse: 9.7723e-05\n",
      "Epoch 1481: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5797 - bpp: 0.7792 - mse: 9.7723e-05\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5577 - bpp: 0.7766 - mse: 9.5356e-05\n",
      "Epoch 1482: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5577 - bpp: 0.7766 - mse: 9.5356e-05\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5778 - bpp: 0.7689 - mse: 9.8743e-05\n",
      "Epoch 1483: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5778 - bpp: 0.7689 - mse: 9.8743e-05\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6188 - bpp: 0.7807 - mse: 1.0230e-04\n",
      "Epoch 1484: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.6188 - bpp: 0.7807 - mse: 1.0230e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5652 - bpp: 0.7825 - mse: 9.5553e-05\n",
      "Epoch 1485: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5652 - bpp: 0.7825 - mse: 9.5553e-05\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3742 - bpp: 0.7293 - mse: 7.8719e-05\n",
      "Epoch 1486: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.3742 - bpp: 0.7293 - mse: 7.8719e-05\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5971 - bpp: 0.7713 - mse: 1.0080e-04\n",
      "Epoch 1487: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5971 - bpp: 0.7713 - mse: 1.0080e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5820 - bpp: 0.7779 - mse: 9.8155e-05\n",
      "Epoch 1488: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5820 - bpp: 0.7779 - mse: 9.8155e-05\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4969 - bpp: 0.7488 - mse: 9.1322e-05\n",
      "Epoch 1489: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4969 - bpp: 0.7488 - mse: 9.1322e-05\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6050 - bpp: 0.7655 - mse: 1.0248e-04\n",
      "Epoch 1490: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6050 - bpp: 0.7655 - mse: 1.0248e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4984 - bpp: 0.7542 - mse: 9.0846e-05\n",
      "Epoch 1491: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4984 - bpp: 0.7542 - mse: 9.0846e-05\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5308 - bpp: 0.7594 - mse: 9.4162e-05\n",
      "Epoch 1492: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.5308 - bpp: 0.7594 - mse: 9.4162e-05\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5249 - bpp: 0.7614 - mse: 9.3191e-05\n",
      "Epoch 1493: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5249 - bpp: 0.7614 - mse: 9.3191e-05\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6067 - bpp: 0.7859 - mse: 1.0019e-04\n",
      "Epoch 1494: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6067 - bpp: 0.7859 - mse: 1.0019e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5482 - bpp: 0.7596 - mse: 9.6260e-05\n",
      "Epoch 1495: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5482 - bpp: 0.7596 - mse: 9.6260e-05\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6511 - bpp: 0.8004 - mse: 1.0385e-04\n",
      "Epoch 1496: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6511 - bpp: 0.8004 - mse: 1.0385e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5750 - bpp: 0.7780 - mse: 9.7298e-05\n",
      "Epoch 1497: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5750 - bpp: 0.7780 - mse: 9.7298e-05\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5676 - bpp: 0.7661 - mse: 9.7839e-05\n",
      "Epoch 1498: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5676 - bpp: 0.7661 - mse: 9.7839e-05\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6048 - bpp: 0.7729 - mse: 1.0155e-04\n",
      "Epoch 1499: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.6048 - bpp: 0.7729 - mse: 1.0155e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5940 - bpp: 0.7633 - mse: 1.0140e-04\n",
      "Epoch 1500: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5940 - bpp: 0.7633 - mse: 1.0140e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_2_layer_call_fn, optical_flow_loss_2_layer_call_and_return_conditional_losses, dwt_2_layer_call_fn, dwt_2_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_13 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_13.compile()\n",
    "trainer_13.fit()\n",
    "trainer_13.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 298.8000 - bpp: 5.3021 - mse: 0.0179\n",
      "Epoch 1: loss improved from inf to 298.79999, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 57s 146ms/step - loss: 298.8000 - bpp: 5.3021 - mse: 0.0179\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 56.5984 - bpp: 5.1646 - mse: 0.0031\n",
      "Epoch 2: loss improved from 298.79999 to 56.59837, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 56.5984 - bpp: 5.1646 - mse: 0.0031\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 47.4225 - bpp: 5.0300 - mse: 0.0026\n",
      "Epoch 3: loss improved from 56.59837 to 47.42254, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 47.4225 - bpp: 5.0300 - mse: 0.0026\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.0005 - bpp: 4.8977 - mse: 0.0017\n",
      "Epoch 4: loss improved from 47.42254 to 32.00049, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 32.0005 - bpp: 4.8977 - mse: 0.0017\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 34.2923 - bpp: 4.7682 - mse: 0.0018\n",
      "Epoch 5: loss did not improve from 32.00049\n",
      "200/200 [==============================] - 30s 147ms/step - loss: 34.2923 - bpp: 4.7682 - mse: 0.0018\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.5312 - bpp: 4.6408 - mse: 0.0017\n",
      "Epoch 6: loss did not improve from 32.00049\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 32.5312 - bpp: 4.6408 - mse: 0.0017\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.8706 - bpp: 4.5150 - mse: 0.0013\n",
      "Epoch 7: loss improved from 32.00049 to 25.87061, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 25.8706 - bpp: 4.5150 - mse: 0.0013\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 34.3133 - bpp: 4.3924 - mse: 0.0018\n",
      "Epoch 8: loss did not improve from 25.87061\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 34.3133 - bpp: 4.3924 - mse: 0.0018\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.9948 - bpp: 4.2712 - mse: 0.0011\n",
      "Epoch 9: loss improved from 25.87061 to 22.99475, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 22.9948 - bpp: 4.2712 - mse: 0.0011\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.7383 - bpp: 4.1524 - mse: 0.0012\n",
      "Epoch 10: loss did not improve from 22.99475\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 23.7383 - bpp: 4.1524 - mse: 0.0012\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.0457 - bpp: 4.0350 - mse: 0.0011\n",
      "Epoch 11: loss improved from 22.99475 to 22.04570, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 22.0457 - bpp: 4.0350 - mse: 0.0011\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.1082 - bpp: 3.9208 - mse: 9.2697e-04\n",
      "Epoch 12: loss improved from 22.04570 to 19.10817, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 19.1082 - bpp: 3.9208 - mse: 9.2697e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.2205 - bpp: 3.8097 - mse: 0.0011\n",
      "Epoch 13: loss did not improve from 19.10817\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 21.2205 - bpp: 3.8097 - mse: 0.0011\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.5870 - bpp: 3.6979 - mse: 0.0011\n",
      "Epoch 14: loss did not improve from 19.10817\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 21.5870 - bpp: 3.6979 - mse: 0.0011\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.8665 - bpp: 3.5916 - mse: 9.3230e-04\n",
      "Epoch 15: loss improved from 19.10817 to 18.86647, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 18.8665 - bpp: 3.5916 - mse: 9.3230e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.6269 - bpp: 3.4869 - mse: 9.8511e-04\n",
      "Epoch 16: loss did not improve from 18.86647\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 19.6269 - bpp: 3.4869 - mse: 9.8511e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.0836 - bpp: 3.3801 - mse: 8.3639e-04\n",
      "Epoch 17: loss improved from 18.86647 to 17.08357, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 17.0836 - bpp: 3.3801 - mse: 8.3639e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.9392 - bpp: 3.2816 - mse: 7.7256e-04\n",
      "Epoch 18: loss improved from 17.08357 to 15.93919, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 15.9392 - bpp: 3.2816 - mse: 7.7256e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.5858 - bpp: 3.1818 - mse: 7.5707e-04\n",
      "Epoch 19: loss improved from 15.93919 to 15.58576, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 15.5858 - bpp: 3.1818 - mse: 7.5707e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.0717 - bpp: 3.0896 - mse: 7.3133e-04\n",
      "Epoch 20: loss improved from 15.58576 to 15.07166, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 15.0717 - bpp: 3.0896 - mse: 7.3133e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.0567 - bpp: 2.9999 - mse: 8.5796e-04\n",
      "Epoch 21: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 17.0567 - bpp: 2.9999 - mse: 8.5796e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3912 - bpp: 2.9118 - mse: 7.6168e-04\n",
      "Epoch 22: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 15.3912 - bpp: 2.9118 - mse: 7.6168e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.3593 - bpp: 2.8269 - mse: 9.4802e-04\n",
      "Epoch 23: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 18.3593 - bpp: 2.8269 - mse: 9.4802e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.1031 - bpp: 2.7388 - mse: 8.7672e-04\n",
      "Epoch 24: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 31s 149ms/step - loss: 17.1031 - bpp: 2.7388 - mse: 8.7672e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 31.0728 - bpp: 2.6749 - mse: 0.0017\n",
      "Epoch 25: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 31.0728 - bpp: 2.6749 - mse: 0.0017\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2502 - bpp: 2.5746 - mse: 6.5159e-04\n",
      "Epoch 26: loss improved from 15.07166 to 13.25023, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 13.2502 - bpp: 2.5746 - mse: 6.5159e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.5089 - bpp: 2.5122 - mse: 9.1533e-04\n",
      "Epoch 27: loss did not improve from 13.25023\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 17.5089 - bpp: 2.5122 - mse: 9.1533e-04\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.9588 - bpp: 2.4304 - mse: 6.4260e-04\n",
      "Epoch 28: loss improved from 13.25023 to 12.95880, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 12.9588 - bpp: 2.4304 - mse: 6.4260e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.4475 - bpp: 2.3638 - mse: 7.3753e-04\n",
      "Epoch 29: loss did not improve from 12.95880\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 14.4475 - bpp: 2.3638 - mse: 7.3753e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2627 - bpp: 2.2989 - mse: 6.0814e-04\n",
      "Epoch 30: loss improved from 12.95880 to 12.26272, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 12.2627 - bpp: 2.2989 - mse: 6.0814e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 42.3166 - bpp: 2.2475 - mse: 0.0024\n",
      "Epoch 31: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 42.3166 - bpp: 2.2475 - mse: 0.0024\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3937 - bpp: 2.1682 - mse: 6.8515e-04\n",
      "Epoch 32: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 13.3937 - bpp: 2.1682 - mse: 6.8515e-04\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.8518 - bpp: 2.1185 - mse: 7.1614e-04\n",
      "Epoch 33: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 13.8518 - bpp: 2.1185 - mse: 7.1614e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3212 - bpp: 2.0518 - mse: 6.2680e-04\n",
      "Epoch 34: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 12.3212 - bpp: 2.0518 - mse: 6.2680e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.6762 - bpp: 1.9985 - mse: 6.5171e-04\n",
      "Epoch 35: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 12.6762 - bpp: 1.9985 - mse: 6.5171e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.8425 - bpp: 1.9782 - mse: 8.4621e-04\n",
      "Epoch 36: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 15.8425 - bpp: 1.9782 - mse: 8.4621e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.6302 - bpp: 1.9382 - mse: 6.5259e-04\n",
      "Epoch 37: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 12.6302 - bpp: 1.9382 - mse: 6.5259e-04\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.8354 - bpp: 1.8834 - mse: 6.6846e-04\n",
      "Epoch 38: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 12.8354 - bpp: 1.8834 - mse: 6.6846e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7066 - bpp: 1.8298 - mse: 5.4180e-04\n",
      "Epoch 39: loss improved from 12.26272 to 10.70657, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 10.7066 - bpp: 1.8298 - mse: 5.4180e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.5923 - bpp: 1.8010 - mse: 7.1968e-04\n",
      "Epoch 40: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 13.5923 - bpp: 1.8010 - mse: 7.1968e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.9613 - bpp: 1.7893 - mse: 7.4292e-04\n",
      "Epoch 41: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 13.9613 - bpp: 1.7893 - mse: 7.4292e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3515 - bpp: 1.7618 - mse: 8.2945e-04\n",
      "Epoch 42: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 15.3515 - bpp: 1.7618 - mse: 8.2945e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.5030 - bpp: 1.6902 - mse: 6.5996e-04\n",
      "Epoch 43: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 12.5030 - bpp: 1.6902 - mse: 6.5996e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3343 - bpp: 1.6836 - mse: 5.2799e-04\n",
      "Epoch 44: loss improved from 10.70657 to 10.33428, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 10.3343 - bpp: 1.6836 - mse: 5.2799e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2964 - bpp: 1.6731 - mse: 6.4840e-04\n",
      "Epoch 45: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 12.2964 - bpp: 1.6731 - mse: 6.4840e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.9567 - bpp: 1.6123 - mse: 5.7034e-04\n",
      "Epoch 46: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 10.9567 - bpp: 1.6123 - mse: 5.7034e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4450 - bpp: 1.6003 - mse: 9.0605e-04\n",
      "Epoch 47: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 31s 151ms/step - loss: 16.4450 - bpp: 1.6003 - mse: 9.0605e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3603 - bpp: 1.6374 - mse: 8.3758e-04\n",
      "Epoch 48: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 15.3603 - bpp: 1.6374 - mse: 8.3758e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9760 - bpp: 1.5765 - mse: 5.1266e-04\n",
      "Epoch 49: loss improved from 10.33428 to 9.97601, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 9.9760 - bpp: 1.5765 - mse: 5.1266e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6397 - bpp: 1.5326 - mse: 4.9482e-04\n",
      "Epoch 50: loss improved from 9.97601 to 9.63970, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 9.6397 - bpp: 1.5326 - mse: 4.9482e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3640 - bpp: 1.5514 - mse: 7.2098e-04\n",
      "Epoch 51: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 13.3640 - bpp: 1.5514 - mse: 7.2098e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3117 - bpp: 1.5097 - mse: 6.5930e-04\n",
      "Epoch 52: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 12.3117 - bpp: 1.5097 - mse: 6.5930e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4420 - bpp: 1.5154 - mse: 6.0587e-04\n",
      "Epoch 53: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 11.4420 - bpp: 1.5154 - mse: 6.0587e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6059 - bpp: 1.4582 - mse: 6.1937e-04\n",
      "Epoch 54: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 11.6059 - bpp: 1.4582 - mse: 6.1937e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0021 - bpp: 1.4748 - mse: 5.2047e-04\n",
      "Epoch 55: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 10.0021 - bpp: 1.4748 - mse: 5.2047e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7092 - bpp: 1.4354 - mse: 5.6603e-04\n",
      "Epoch 56: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 10.7092 - bpp: 1.4354 - mse: 5.6603e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1235 - bpp: 1.4302 - mse: 5.3060e-04\n",
      "Epoch 57: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 10.1235 - bpp: 1.4302 - mse: 5.3060e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0069 - bpp: 1.4534 - mse: 5.2206e-04\n",
      "Epoch 58: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 10.0069 - bpp: 1.4534 - mse: 5.2206e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1179 - bpp: 1.4233 - mse: 4.6964e-04\n",
      "Epoch 59: loss improved from 9.63970 to 9.11791, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 9.1179 - bpp: 1.4233 - mse: 4.6964e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.6766 - bpp: 1.4514 - mse: 0.0011\n",
      "Epoch 60: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 19.6766 - bpp: 1.4514 - mse: 0.0011\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.6092 - bpp: 1.4557 - mse: 7.4179e-04\n",
      "Epoch 61: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 13.6092 - bpp: 1.4557 - mse: 7.4179e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.7828 - bpp: 1.4384 - mse: 5.0930e-04\n",
      "Epoch 62: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 9.7828 - bpp: 1.4384 - mse: 5.0930e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1081 - bpp: 1.4284 - mse: 5.2977e-04\n",
      "Epoch 63: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 10.1081 - bpp: 1.4284 - mse: 5.2977e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2671 - bpp: 1.3838 - mse: 4.8116e-04\n",
      "Epoch 64: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 9.2671 - bpp: 1.3838 - mse: 4.8116e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3308 - bpp: 1.3735 - mse: 4.2464e-04\n",
      "Epoch 65: loss improved from 9.11791 to 8.33084, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 8.3308 - bpp: 1.3735 - mse: 4.2464e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2371 - bpp: 1.3570 - mse: 4.8097e-04\n",
      "Epoch 66: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 9.2371 - bpp: 1.3570 - mse: 4.8097e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3156 - bpp: 1.3925 - mse: 5.4462e-04\n",
      "Epoch 67: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 10.3156 - bpp: 1.3925 - mse: 5.4462e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6896 - bpp: 1.3475 - mse: 5.0916e-04\n",
      "Epoch 68: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 9.6896 - bpp: 1.3475 - mse: 5.0916e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2969 - bpp: 1.3417 - mse: 4.8555e-04\n",
      "Epoch 69: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 9.2969 - bpp: 1.3417 - mse: 4.8555e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.8020 - bpp: 1.3705 - mse: 9.4186e-04\n",
      "Epoch 70: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 16.8020 - bpp: 1.3705 - mse: 9.4186e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8698 - bpp: 1.3510 - mse: 5.1994e-04\n",
      "Epoch 71: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.8698 - bpp: 1.3510 - mse: 5.1994e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5230 - bpp: 1.3437 - mse: 4.9922e-04\n",
      "Epoch 72: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.5230 - bpp: 1.3437 - mse: 4.9922e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1263 - bpp: 1.3387 - mse: 4.7531e-04\n",
      "Epoch 73: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.1263 - bpp: 1.3387 - mse: 4.7531e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7896 - bpp: 1.3341 - mse: 4.5505e-04\n",
      "Epoch 74: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 8.7896 - bpp: 1.3341 - mse: 4.5505e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.2474 - bpp: 1.4133 - mse: 0.0013\n",
      "Epoch 75: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 22.2474 - bpp: 1.4133 - mse: 0.0013\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2921 - bpp: 1.3237 - mse: 4.8635e-04\n",
      "Epoch 76: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 9.2921 - bpp: 1.3237 - mse: 4.8635e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5032 - bpp: 1.2960 - mse: 4.3989e-04\n",
      "Epoch 77: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 8.5032 - bpp: 1.2960 - mse: 4.3989e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9211 - bpp: 1.2922 - mse: 4.0460e-04\n",
      "Epoch 78: loss improved from 8.33084 to 7.92108, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 7.9211 - bpp: 1.2922 - mse: 4.0460e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5743 - bpp: 1.2988 - mse: 4.4406e-04\n",
      "Epoch 79: loss did not improve from 7.92108\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 8.5743 - bpp: 1.2988 - mse: 4.4406e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3290 - bpp: 1.3071 - mse: 4.2858e-04\n",
      "Epoch 80: loss did not improve from 7.92108\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 8.3290 - bpp: 1.3071 - mse: 4.2858e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3206 - bpp: 1.2879 - mse: 3.6821e-04\n",
      "Epoch 81: loss improved from 7.92108 to 7.32060, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 7.3206 - bpp: 1.2879 - mse: 3.6821e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2155 - bpp: 1.3063 - mse: 4.2170e-04\n",
      "Epoch 82: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 8.2155 - bpp: 1.3063 - mse: 4.2170e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5041 - bpp: 1.3152 - mse: 4.9981e-04\n",
      "Epoch 83: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 9.5041 - bpp: 1.3152 - mse: 4.9981e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3220 - bpp: 1.2936 - mse: 4.2898e-04\n",
      "Epoch 84: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 8.3220 - bpp: 1.2936 - mse: 4.2898e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0100 - bpp: 1.2825 - mse: 4.1061e-04\n",
      "Epoch 85: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 8.0100 - bpp: 1.2825 - mse: 4.1061e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1152 - bpp: 1.2720 - mse: 3.5664e-04\n",
      "Epoch 86: loss improved from 7.32060 to 7.11517, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 7.1152 - bpp: 1.2720 - mse: 3.5664e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0676 - bpp: 1.2803 - mse: 4.7530e-04\n",
      "Epoch 87: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 9.0676 - bpp: 1.2803 - mse: 4.7530e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2917 - bpp: 1.2733 - mse: 3.6734e-04\n",
      "Epoch 88: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 7.2917 - bpp: 1.2733 - mse: 3.6734e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2083 - bpp: 1.3004 - mse: 5.4370e-04\n",
      "Epoch 89: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 10.2083 - bpp: 1.3004 - mse: 5.4370e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7020 - bpp: 1.2954 - mse: 4.5206e-04\n",
      "Epoch 90: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 8.7020 - bpp: 1.2954 - mse: 4.5206e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3745 - bpp: 1.2889 - mse: 4.3247e-04\n",
      "Epoch 91: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 8.3745 - bpp: 1.2889 - mse: 4.3247e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2160 - bpp: 1.2722 - mse: 3.6278e-04\n",
      "Epoch 92: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 7.2160 - bpp: 1.2722 - mse: 3.6278e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0656 - bpp: 1.2534 - mse: 3.5475e-04\n",
      "Epoch 93: loss improved from 7.11517 to 7.06557, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 7.0656 - bpp: 1.2534 - mse: 3.5475e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1996 - bpp: 1.2983 - mse: 4.2122e-04\n",
      "Epoch 94: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 8.1996 - bpp: 1.2983 - mse: 4.2122e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8694 - bpp: 1.2794 - mse: 4.0222e-04\n",
      "Epoch 95: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 7.8694 - bpp: 1.2794 - mse: 4.0222e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.8365 - bpp: 1.3394 - mse: 8.2380e-04\n",
      "Epoch 96: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 14.8365 - bpp: 1.3394 - mse: 8.2380e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1146 - bpp: 1.3165 - mse: 5.3699e-04\n",
      "Epoch 97: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 10.1146 - bpp: 1.3165 - mse: 5.3699e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9683 - bpp: 1.2568 - mse: 3.4860e-04\n",
      "Epoch 98: loss improved from 7.06557 to 6.96834, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 6.9683 - bpp: 1.2568 - mse: 3.4860e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4917 - bpp: 1.2896 - mse: 5.6166e-04\n",
      "Epoch 99: loss did not improve from 6.96834\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 10.4917 - bpp: 1.2896 - mse: 5.6166e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5552 - bpp: 1.2417 - mse: 3.2431e-04\n",
      "Epoch 100: loss improved from 6.96834 to 6.55519, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.5552 - bpp: 1.2417 - mse: 3.2431e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4396 - bpp: 1.2346 - mse: 3.1768e-04\n",
      "Epoch 101: loss improved from 6.55519 to 6.43955, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 6.4396 - bpp: 1.2346 - mse: 3.1768e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5057 - bpp: 1.2550 - mse: 3.8151e-04\n",
      "Epoch 102: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 7.5057 - bpp: 1.2550 - mse: 3.8151e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6776 - bpp: 1.2441 - mse: 3.3163e-04\n",
      "Epoch 103: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 6.6776 - bpp: 1.2441 - mse: 3.3163e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5047 - bpp: 1.2807 - mse: 3.7988e-04\n",
      "Epoch 104: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 7.5047 - bpp: 1.2807 - mse: 3.7988e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5081 - bpp: 1.2736 - mse: 3.1949e-04\n",
      "Epoch 105: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 6.5081 - bpp: 1.2736 - mse: 3.1949e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0799 - bpp: 1.2501 - mse: 2.9479e-04\n",
      "Epoch 106: loss improved from 6.43955 to 6.07990, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 6.0799 - bpp: 1.2501 - mse: 2.9479e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1279 - bpp: 1.3209 - mse: 4.7650e-04\n",
      "Epoch 107: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.1279 - bpp: 1.3209 - mse: 4.7650e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5623 - bpp: 1.2262 - mse: 3.2569e-04\n",
      "Epoch 108: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 6.5623 - bpp: 1.2262 - mse: 3.2569e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7810 - bpp: 1.2650 - mse: 3.3667e-04\n",
      "Epoch 109: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.7810 - bpp: 1.2650 - mse: 3.3667e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.9841 - bpp: 1.2821 - mse: 6.5320e-04\n",
      "Epoch 110: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 11.9841 - bpp: 1.2821 - mse: 6.5320e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5159 - bpp: 1.3007 - mse: 5.0142e-04\n",
      "Epoch 111: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 9.5159 - bpp: 1.3007 - mse: 5.0142e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1518 - bpp: 1.3014 - mse: 4.1812e-04\n",
      "Epoch 112: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 8.1518 - bpp: 1.3014 - mse: 4.1812e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3129 - bpp: 1.2443 - mse: 3.0936e-04\n",
      "Epoch 113: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 6.3129 - bpp: 1.2443 - mse: 3.0936e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1841 - bpp: 1.2434 - mse: 3.0156e-04\n",
      "Epoch 114: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 6.1841 - bpp: 1.2434 - mse: 3.0156e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9505 - bpp: 1.2472 - mse: 3.4810e-04\n",
      "Epoch 115: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.9505 - bpp: 1.2472 - mse: 3.4810e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0009 - bpp: 1.2593 - mse: 3.5044e-04\n",
      "Epoch 116: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 7.0009 - bpp: 1.2593 - mse: 3.5044e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3643 - bpp: 1.2333 - mse: 3.1317e-04\n",
      "Epoch 117: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.3643 - bpp: 1.2333 - mse: 3.1317e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6779 - bpp: 1.2327 - mse: 3.3235e-04\n",
      "Epoch 118: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 6.6779 - bpp: 1.2327 - mse: 3.3235e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5964 - bpp: 1.2396 - mse: 3.2695e-04\n",
      "Epoch 119: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 6.5964 - bpp: 1.2396 - mse: 3.2695e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8674 - bpp: 1.2526 - mse: 3.4270e-04\n",
      "Epoch 120: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 6.8674 - bpp: 1.2526 - mse: 3.4270e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1530 - bpp: 1.2734 - mse: 3.5886e-04\n",
      "Epoch 121: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 7.1530 - bpp: 1.2734 - mse: 3.5886e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8529 - bpp: 1.3429 - mse: 5.8044e-04\n",
      "Epoch 122: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 10.8529 - bpp: 1.3429 - mse: 5.8044e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8497 - bpp: 1.2358 - mse: 3.4265e-04\n",
      "Epoch 123: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 6.8497 - bpp: 1.2358 - mse: 3.4265e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9486 - bpp: 1.2745 - mse: 3.4632e-04\n",
      "Epoch 124: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 6.9486 - bpp: 1.2745 - mse: 3.4632e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2869 - bpp: 1.2451 - mse: 3.0773e-04\n",
      "Epoch 125: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.2869 - bpp: 1.2451 - mse: 3.0773e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8728 - bpp: 1.2268 - mse: 2.8357e-04\n",
      "Epoch 126: loss improved from 6.07990 to 5.87285, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 5.8728 - bpp: 1.2268 - mse: 2.8357e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2976 - bpp: 1.2917 - mse: 4.2760e-04\n",
      "Epoch 127: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 8.2976 - bpp: 1.2917 - mse: 4.2760e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1279 - bpp: 1.2813 - mse: 3.5685e-04\n",
      "Epoch 128: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 7.1279 - bpp: 1.2813 - mse: 3.5685e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8211 - bpp: 1.2659 - mse: 3.3906e-04\n",
      "Epoch 129: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 6.8211 - bpp: 1.2659 - mse: 3.3906e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8123 - bpp: 1.2750 - mse: 3.3797e-04\n",
      "Epoch 130: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 6.8123 - bpp: 1.2750 - mse: 3.3797e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7383 - bpp: 1.2667 - mse: 3.3396e-04\n",
      "Epoch 131: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 6.7383 - bpp: 1.2667 - mse: 3.3396e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3323 - bpp: 1.2503 - mse: 3.1018e-04\n",
      "Epoch 132: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 6.3323 - bpp: 1.2503 - mse: 3.1018e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0552 - bpp: 1.2612 - mse: 3.5364e-04\n",
      "Epoch 133: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 7.0552 - bpp: 1.2612 - mse: 3.5364e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.6789 - bpp: 1.3512 - mse: 0.0011\n",
      "Epoch 134: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 18.6789 - bpp: 1.3512 - mse: 0.0011\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1613 - bpp: 1.2704 - mse: 2.9852e-04\n",
      "Epoch 135: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 6.1613 - bpp: 1.2704 - mse: 2.9852e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1465 - bpp: 1.2743 - mse: 2.9738e-04\n",
      "Epoch 136: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 6.1465 - bpp: 1.2743 - mse: 2.9738e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0766 - bpp: 1.2718 - mse: 2.9326e-04\n",
      "Epoch 137: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 6.0766 - bpp: 1.2718 - mse: 2.9326e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0066 - bpp: 1.2626 - mse: 2.8955e-04\n",
      "Epoch 138: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 6.0066 - bpp: 1.2626 - mse: 2.8955e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4748 - bpp: 1.2419 - mse: 2.5836e-04\n",
      "Epoch 139: loss improved from 5.87285 to 5.47482, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.4748 - bpp: 1.2419 - mse: 2.5836e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3211 - bpp: 1.2657 - mse: 3.6960e-04\n",
      "Epoch 140: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 7.3211 - bpp: 1.2657 - mse: 3.6960e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1288 - bpp: 1.2415 - mse: 2.9830e-04\n",
      "Epoch 141: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.1288 - bpp: 1.2415 - mse: 2.9830e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9911 - bpp: 1.2903 - mse: 4.0899e-04\n",
      "Epoch 142: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 7.9911 - bpp: 1.2903 - mse: 4.0899e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7156 - bpp: 1.2798 - mse: 3.9281e-04\n",
      "Epoch 143: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 7.7156 - bpp: 1.2798 - mse: 3.9281e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7233 - bpp: 1.2815 - mse: 3.9317e-04\n",
      "Epoch 144: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 7.7233 - bpp: 1.2815 - mse: 3.9317e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4537 - bpp: 1.2623 - mse: 3.1686e-04\n",
      "Epoch 145: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 6.4537 - bpp: 1.2623 - mse: 3.1686e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5840 - bpp: 1.2526 - mse: 2.6437e-04\n",
      "Epoch 146: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 5.5840 - bpp: 1.2526 - mse: 2.6437e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1298 - bpp: 1.2618 - mse: 2.9712e-04\n",
      "Epoch 147: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 6.1298 - bpp: 1.2618 - mse: 2.9712e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6887 - bpp: 1.2652 - mse: 3.3102e-04\n",
      "Epoch 148: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.6887 - bpp: 1.2652 - mse: 3.3102e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9456 - bpp: 1.2565 - mse: 2.8620e-04\n",
      "Epoch 149: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.9456 - bpp: 1.2565 - mse: 2.8620e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1410 - bpp: 1.2345 - mse: 2.3843e-04\n",
      "Epoch 150: loss improved from 5.47482 to 5.14096, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 5.1410 - bpp: 1.2345 - mse: 2.3843e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6990 - bpp: 1.2577 - mse: 2.7107e-04\n",
      "Epoch 151: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 5.6990 - bpp: 1.2577 - mse: 2.7107e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3772 - bpp: 1.2683 - mse: 3.1182e-04\n",
      "Epoch 152: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 6.3772 - bpp: 1.2683 - mse: 3.1182e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5931 - bpp: 1.2621 - mse: 2.6434e-04\n",
      "Epoch 153: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.5931 - bpp: 1.2621 - mse: 2.6434e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9334 - bpp: 1.2875 - mse: 4.0564e-04\n",
      "Epoch 154: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 7.9334 - bpp: 1.2875 - mse: 4.0564e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0860 - bpp: 1.2701 - mse: 4.1601e-04\n",
      "Epoch 155: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 8.0860 - bpp: 1.2701 - mse: 4.1601e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7972 - bpp: 1.2942 - mse: 3.3588e-04\n",
      "Epoch 156: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 6.7972 - bpp: 1.2942 - mse: 3.3588e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9906 - bpp: 1.2558 - mse: 2.8899e-04\n",
      "Epoch 157: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 5.9906 - bpp: 1.2558 - mse: 2.8899e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6385 - bpp: 1.2470 - mse: 2.6804e-04\n",
      "Epoch 158: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.6385 - bpp: 1.2470 - mse: 2.6804e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5769 - bpp: 1.2683 - mse: 2.6298e-04\n",
      "Epoch 159: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 43s 208ms/step - loss: 5.5769 - bpp: 1.2683 - mse: 2.6298e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6298 - bpp: 1.2730 - mse: 2.6592e-04\n",
      "Epoch 160: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 5.6298 - bpp: 1.2730 - mse: 2.6592e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0332 - bpp: 1.2738 - mse: 2.9049e-04\n",
      "Epoch 161: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 6.0332 - bpp: 1.2738 - mse: 2.9049e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4067 - bpp: 1.2988 - mse: 3.1176e-04\n",
      "Epoch 162: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 6.4067 - bpp: 1.2988 - mse: 3.1176e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1349 - bpp: 1.2714 - mse: 6.6306e-04\n",
      "Epoch 163: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 12.1349 - bpp: 1.2714 - mse: 6.6306e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6732 - bpp: 1.2712 - mse: 2.6868e-04\n",
      "Epoch 164: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.6732 - bpp: 1.2712 - mse: 2.6868e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3819 - bpp: 1.2959 - mse: 3.1042e-04\n",
      "Epoch 165: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.3819 - bpp: 1.2959 - mse: 3.1042e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2156 - bpp: 1.2850 - mse: 3.0094e-04\n",
      "Epoch 166: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 6.2156 - bpp: 1.2850 - mse: 3.0094e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7307 - bpp: 1.2268 - mse: 2.1386e-04\n",
      "Epoch 167: loss improved from 5.14096 to 4.73069, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.7307 - bpp: 1.2268 - mse: 2.1386e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5823 - bpp: 1.2514 - mse: 3.2537e-04\n",
      "Epoch 168: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 6.5823 - bpp: 1.2514 - mse: 3.2537e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4602 - bpp: 1.2468 - mse: 3.1820e-04\n",
      "Epoch 169: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 6.4602 - bpp: 1.2468 - mse: 3.1820e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6897 - bpp: 1.2698 - mse: 2.6977e-04\n",
      "Epoch 170: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 5.6897 - bpp: 1.2698 - mse: 2.6977e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3022 - bpp: 1.2809 - mse: 3.0647e-04\n",
      "Epoch 171: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 6.3022 - bpp: 1.2809 - mse: 3.0647e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9726 - bpp: 1.2824 - mse: 4.6938e-04\n",
      "Epoch 172: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 8.9726 - bpp: 1.2824 - mse: 4.6938e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2654 - bpp: 1.2862 - mse: 3.0391e-04\n",
      "Epoch 173: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 6.2654 - bpp: 1.2862 - mse: 3.0391e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5823 - bpp: 1.2617 - mse: 2.6371e-04\n",
      "Epoch 174: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.5823 - bpp: 1.2617 - mse: 2.6371e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9267 - bpp: 1.3078 - mse: 2.8192e-04\n",
      "Epoch 175: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 5.9267 - bpp: 1.3078 - mse: 2.8192e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8354 - bpp: 1.2858 - mse: 3.3872e-04\n",
      "Epoch 176: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 6.8354 - bpp: 1.2858 - mse: 3.3872e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2580 - bpp: 1.2867 - mse: 4.2549e-04\n",
      "Epoch 177: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 8.2580 - bpp: 1.2867 - mse: 4.2549e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1646 - bpp: 1.2479 - mse: 2.3906e-04\n",
      "Epoch 178: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.1646 - bpp: 1.2479 - mse: 2.3906e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1451 - bpp: 1.2508 - mse: 2.3769e-04\n",
      "Epoch 179: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.1451 - bpp: 1.2508 - mse: 2.3769e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4580 - bpp: 1.3077 - mse: 3.1435e-04\n",
      "Epoch 180: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 6.4580 - bpp: 1.3077 - mse: 3.1435e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3057 - bpp: 1.3032 - mse: 3.0533e-04\n",
      "Epoch 181: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 6.3057 - bpp: 1.3032 - mse: 3.0533e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2790 - bpp: 1.2615 - mse: 2.4521e-04\n",
      "Epoch 182: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.2790 - bpp: 1.2615 - mse: 2.4521e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4486 - bpp: 1.2721 - mse: 2.5491e-04\n",
      "Epoch 183: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.4486 - bpp: 1.2721 - mse: 2.5491e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3004 - bpp: 1.2901 - mse: 2.4477e-04\n",
      "Epoch 184: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 5.3004 - bpp: 1.2901 - mse: 2.4477e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9692 - bpp: 1.2816 - mse: 2.8611e-04\n",
      "Epoch 185: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.9692 - bpp: 1.2816 - mse: 2.8611e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2095 - bpp: 1.2443 - mse: 2.4202e-04\n",
      "Epoch 186: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.2095 - bpp: 1.2443 - mse: 2.4202e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2081 - bpp: 1.3000 - mse: 2.9957e-04\n",
      "Epoch 187: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.2081 - bpp: 1.3000 - mse: 2.9957e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0101 - bpp: 1.2498 - mse: 2.2951e-04\n",
      "Epoch 188: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.0101 - bpp: 1.2498 - mse: 2.2951e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4854 - bpp: 1.2749 - mse: 3.1803e-04\n",
      "Epoch 189: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 6.4854 - bpp: 1.2749 - mse: 3.1803e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1946 - bpp: 1.3202 - mse: 4.1958e-04\n",
      "Epoch 190: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 8.1946 - bpp: 1.3202 - mse: 4.1958e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3831 - bpp: 1.2886 - mse: 2.4990e-04\n",
      "Epoch 191: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.3831 - bpp: 1.2886 - mse: 2.4990e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5927 - bpp: 1.2695 - mse: 2.6387e-04\n",
      "Epoch 192: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 5.5927 - bpp: 1.2695 - mse: 2.6387e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2126 - bpp: 1.2840 - mse: 3.0082e-04\n",
      "Epoch 193: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 6.2126 - bpp: 1.2840 - mse: 3.0082e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4492 - bpp: 1.2675 - mse: 2.5523e-04\n",
      "Epoch 194: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.4492 - bpp: 1.2675 - mse: 2.5523e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5631 - bpp: 1.2831 - mse: 2.6123e-04\n",
      "Epoch 195: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.5631 - bpp: 1.2831 - mse: 2.6123e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8739 - bpp: 1.3124 - mse: 4.6151e-04\n",
      "Epoch 196: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 8.8739 - bpp: 1.3124 - mse: 4.6151e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6007 - bpp: 1.2827 - mse: 2.6355e-04\n",
      "Epoch 197: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.6007 - bpp: 1.2827 - mse: 2.6355e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1865 - bpp: 1.2712 - mse: 2.3897e-04\n",
      "Epoch 198: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.1865 - bpp: 1.2712 - mse: 2.3897e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7893 - bpp: 1.2729 - mse: 2.1462e-04\n",
      "Epoch 199: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.7893 - bpp: 1.2729 - mse: 2.1462e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8233 - bpp: 1.2394 - mse: 2.1875e-04\n",
      "Epoch 200: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 4.8233 - bpp: 1.2394 - mse: 2.1875e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4854 - bpp: 1.2653 - mse: 2.5757e-04\n",
      "Epoch 201: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.4854 - bpp: 1.2653 - mse: 2.5757e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6424 - bpp: 1.2798 - mse: 2.6627e-04\n",
      "Epoch 202: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.6424 - bpp: 1.2798 - mse: 2.6627e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5648 - bpp: 1.2596 - mse: 2.0173e-04\n",
      "Epoch 203: loss improved from 4.73069 to 4.56479, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.5648 - bpp: 1.2596 - mse: 2.0173e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0663 - bpp: 1.2784 - mse: 2.3120e-04\n",
      "Epoch 204: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 5.0663 - bpp: 1.2784 - mse: 2.3120e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8007 - bpp: 1.2684 - mse: 2.1559e-04\n",
      "Epoch 205: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 4.8007 - bpp: 1.2684 - mse: 2.1559e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9475 - bpp: 1.2803 - mse: 2.8486e-04\n",
      "Epoch 206: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.9475 - bpp: 1.2803 - mse: 2.8486e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9825 - bpp: 1.2776 - mse: 2.2613e-04\n",
      "Epoch 207: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.9825 - bpp: 1.2776 - mse: 2.2613e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9930 - bpp: 1.2566 - mse: 2.8909e-04\n",
      "Epoch 208: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.9930 - bpp: 1.2566 - mse: 2.8909e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3370 - bpp: 1.2830 - mse: 2.4744e-04\n",
      "Epoch 209: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 5.3370 - bpp: 1.2830 - mse: 2.4744e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0187 - bpp: 1.2621 - mse: 2.2928e-04\n",
      "Epoch 210: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.0187 - bpp: 1.2621 - mse: 2.2928e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6665 - bpp: 1.2984 - mse: 2.6660e-04\n",
      "Epoch 211: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.6665 - bpp: 1.2984 - mse: 2.6660e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2795 - bpp: 1.2766 - mse: 2.4432e-04\n",
      "Epoch 212: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 5.2795 - bpp: 1.2766 - mse: 2.4432e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4122 - bpp: 1.2844 - mse: 2.5194e-04\n",
      "Epoch 213: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.4122 - bpp: 1.2844 - mse: 2.5194e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3706 - bpp: 1.2823 - mse: 2.4953e-04\n",
      "Epoch 214: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 5.3706 - bpp: 1.2823 - mse: 2.4953e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6038 - bpp: 1.3153 - mse: 2.6175e-04\n",
      "Epoch 215: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 5.6038 - bpp: 1.3153 - mse: 2.6175e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2646 - bpp: 1.2929 - mse: 2.4241e-04\n",
      "Epoch 216: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.2646 - bpp: 1.2929 - mse: 2.4241e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6351 - bpp: 1.2909 - mse: 2.0411e-04\n",
      "Epoch 217: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.6351 - bpp: 1.2909 - mse: 2.0411e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0033 - bpp: 1.3117 - mse: 4.0842e-04\n",
      "Epoch 218: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 8.0033 - bpp: 1.3117 - mse: 4.0842e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0164 - bpp: 1.2719 - mse: 2.2854e-04\n",
      "Epoch 219: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.0164 - bpp: 1.2719 - mse: 2.2854e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0344 - bpp: 1.2621 - mse: 2.3024e-04\n",
      "Epoch 220: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.0344 - bpp: 1.2621 - mse: 2.3024e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0045 - bpp: 1.2747 - mse: 2.2765e-04\n",
      "Epoch 221: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.0045 - bpp: 1.2747 - mse: 2.2765e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8009 - bpp: 1.2712 - mse: 2.1543e-04\n",
      "Epoch 222: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 4.8009 - bpp: 1.2712 - mse: 2.1543e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8193 - bpp: 1.3056 - mse: 2.7549e-04\n",
      "Epoch 223: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 5.8193 - bpp: 1.3056 - mse: 2.7549e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5416 - bpp: 1.3255 - mse: 4.4043e-04\n",
      "Epoch 224: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 8.5416 - bpp: 1.3255 - mse: 4.4043e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9567 - bpp: 1.3291 - mse: 2.8245e-04\n",
      "Epoch 225: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.9567 - bpp: 1.3291 - mse: 2.8245e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5432 - bpp: 1.2512 - mse: 2.0093e-04\n",
      "Epoch 226: loss improved from 4.56479 to 4.54320, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.5432 - bpp: 1.2512 - mse: 2.0093e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1638 - bpp: 1.3100 - mse: 2.9626e-04\n",
      "Epoch 227: loss did not improve from 4.54320\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 6.1638 - bpp: 1.3100 - mse: 2.9626e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2851 - bpp: 1.2384 - mse: 1.8596e-04\n",
      "Epoch 228: loss improved from 4.54320 to 4.28514, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.2851 - bpp: 1.2384 - mse: 1.8596e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8081 - bpp: 1.2920 - mse: 2.1461e-04\n",
      "Epoch 229: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.8081 - bpp: 1.2920 - mse: 2.1461e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4963 - bpp: 1.2757 - mse: 1.9658e-04\n",
      "Epoch 230: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 4.4963 - bpp: 1.2757 - mse: 1.9658e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7283 - bpp: 1.3095 - mse: 2.6970e-04\n",
      "Epoch 231: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.7283 - bpp: 1.3095 - mse: 2.6970e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4212 - bpp: 1.2471 - mse: 1.9374e-04\n",
      "Epoch 232: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 4.4212 - bpp: 1.2471 - mse: 1.9374e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1983 - bpp: 1.2990 - mse: 2.3799e-04\n",
      "Epoch 233: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.1983 - bpp: 1.2990 - mse: 2.3799e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2817 - bpp: 1.2546 - mse: 1.8476e-04\n",
      "Epoch 234: loss improved from 4.28514 to 4.28169, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.2817 - bpp: 1.2546 - mse: 1.8476e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5852 - bpp: 1.2751 - mse: 2.0203e-04\n",
      "Epoch 235: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.5852 - bpp: 1.2751 - mse: 2.0203e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6952 - bpp: 1.2807 - mse: 2.0840e-04\n",
      "Epoch 236: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.6952 - bpp: 1.2807 - mse: 2.0840e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8196 - bpp: 1.2854 - mse: 2.1571e-04\n",
      "Epoch 237: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.8196 - bpp: 1.2854 - mse: 2.1571e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2499 - bpp: 1.3337 - mse: 6.6627e-04\n",
      "Epoch 238: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 12.2499 - bpp: 1.3337 - mse: 6.6627e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2139 - bpp: 1.2888 - mse: 2.3957e-04\n",
      "Epoch 239: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 5.2139 - bpp: 1.2888 - mse: 2.3957e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0730 - bpp: 1.2691 - mse: 2.3217e-04\n",
      "Epoch 240: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.0730 - bpp: 1.2691 - mse: 2.3217e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2200 - bpp: 1.3020 - mse: 2.3914e-04\n",
      "Epoch 241: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 5.2200 - bpp: 1.3020 - mse: 2.3914e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1103 - bpp: 1.2366 - mse: 1.7540e-04\n",
      "Epoch 242: loss improved from 4.28169 to 4.11032, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.1103 - bpp: 1.2366 - mse: 1.7540e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2037 - bpp: 1.3097 - mse: 2.3767e-04\n",
      "Epoch 243: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 5.2037 - bpp: 1.3097 - mse: 2.3767e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6133 - bpp: 1.2637 - mse: 2.0444e-04\n",
      "Epoch 244: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.6133 - bpp: 1.2637 - mse: 2.0444e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6021 - bpp: 1.3078 - mse: 2.6210e-04\n",
      "Epoch 245: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.6021 - bpp: 1.3078 - mse: 2.6210e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5740 - bpp: 1.2826 - mse: 2.0089e-04\n",
      "Epoch 246: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.5740 - bpp: 1.2826 - mse: 2.0089e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6628 - bpp: 1.2703 - mse: 2.0706e-04\n",
      "Epoch 247: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 4.6628 - bpp: 1.2703 - mse: 2.0706e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1338 - bpp: 1.2672 - mse: 1.7497e-04\n",
      "Epoch 248: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.1338 - bpp: 1.2672 - mse: 1.7497e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9974 - bpp: 1.3235 - mse: 2.2424e-04\n",
      "Epoch 249: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 210ms/step - loss: 4.9974 - bpp: 1.3235 - mse: 2.2424e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3784 - bpp: 1.2986 - mse: 2.4901e-04\n",
      "Epoch 250: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.3784 - bpp: 1.2986 - mse: 2.4901e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0157 - bpp: 1.2788 - mse: 2.2809e-04\n",
      "Epoch 251: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.0157 - bpp: 1.2788 - mse: 2.2809e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5616 - bpp: 1.2635 - mse: 2.0130e-04\n",
      "Epoch 252: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.5616 - bpp: 1.2635 - mse: 2.0130e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9558 - bpp: 1.2888 - mse: 2.2381e-04\n",
      "Epoch 253: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.9558 - bpp: 1.2888 - mse: 2.2381e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7272 - bpp: 1.2975 - mse: 2.0933e-04\n",
      "Epoch 254: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.7272 - bpp: 1.2975 - mse: 2.0933e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0474 - bpp: 1.3069 - mse: 3.5038e-04\n",
      "Epoch 255: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 7.0474 - bpp: 1.3069 - mse: 3.5038e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9354 - bpp: 1.2829 - mse: 2.2293e-04\n",
      "Epoch 256: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.9354 - bpp: 1.2829 - mse: 2.2293e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3366 - bpp: 1.2704 - mse: 1.8714e-04\n",
      "Epoch 257: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.3366 - bpp: 1.2704 - mse: 1.8714e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9725 - bpp: 1.2875 - mse: 2.2491e-04\n",
      "Epoch 258: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.9725 - bpp: 1.2875 - mse: 2.2491e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9805 - bpp: 1.3322 - mse: 2.8371e-04\n",
      "Epoch 259: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.9805 - bpp: 1.3322 - mse: 2.8371e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4821 - bpp: 1.2937 - mse: 1.9460e-04\n",
      "Epoch 260: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.4821 - bpp: 1.2937 - mse: 1.9460e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2279 - bpp: 1.3058 - mse: 2.3939e-04\n",
      "Epoch 261: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.2279 - bpp: 1.3058 - mse: 2.3939e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5706 - bpp: 1.2913 - mse: 2.0015e-04\n",
      "Epoch 262: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5706 - bpp: 1.2913 - mse: 2.0015e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7048 - bpp: 1.2864 - mse: 2.0864e-04\n",
      "Epoch 263: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.7048 - bpp: 1.2864 - mse: 2.0864e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3197 - bpp: 1.2756 - mse: 1.8579e-04\n",
      "Epoch 264: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.3197 - bpp: 1.2756 - mse: 1.8579e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4982 - bpp: 1.2799 - mse: 1.9643e-04\n",
      "Epoch 265: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.4982 - bpp: 1.2799 - mse: 1.9643e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5301 - bpp: 1.2888 - mse: 2.5887e-04\n",
      "Epoch 266: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.5301 - bpp: 1.2888 - mse: 2.5887e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5012 - bpp: 1.3018 - mse: 2.5631e-04\n",
      "Epoch 267: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 5.5012 - bpp: 1.3018 - mse: 2.5631e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9661 - bpp: 1.2952 - mse: 2.2406e-04\n",
      "Epoch 268: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.9661 - bpp: 1.2952 - mse: 2.2406e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5216 - bpp: 1.2103 - mse: 1.4107e-04\n",
      "Epoch 269: loss improved from 4.11032 to 3.52158, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 3.5216 - bpp: 1.2103 - mse: 1.4107e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5962 - bpp: 1.2817 - mse: 2.0230e-04\n",
      "Epoch 270: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.5962 - bpp: 1.2817 - mse: 2.0230e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1720 - bpp: 1.2904 - mse: 2.3692e-04\n",
      "Epoch 271: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.1720 - bpp: 1.2904 - mse: 2.3692e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7162 - bpp: 1.2748 - mse: 2.1004e-04\n",
      "Epoch 272: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.7162 - bpp: 1.2748 - mse: 2.1004e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4632 - bpp: 1.3208 - mse: 3.7490e-04\n",
      "Epoch 273: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 7.4632 - bpp: 1.3208 - mse: 3.7490e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1700 - bpp: 1.3070 - mse: 2.3578e-04\n",
      "Epoch 274: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 5.1700 - bpp: 1.3070 - mse: 2.3578e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2666 - bpp: 1.2489 - mse: 1.8419e-04\n",
      "Epoch 275: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 4.2666 - bpp: 1.2489 - mse: 1.8419e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7855 - bpp: 1.2441 - mse: 1.5512e-04\n",
      "Epoch 276: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 3.7855 - bpp: 1.2441 - mse: 1.5512e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0223 - bpp: 1.2534 - mse: 1.6900e-04\n",
      "Epoch 277: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 4.0223 - bpp: 1.2534 - mse: 1.6900e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3738 - bpp: 1.2718 - mse: 1.8933e-04\n",
      "Epoch 278: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.3738 - bpp: 1.2718 - mse: 1.8933e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8045 - bpp: 1.3139 - mse: 2.1305e-04\n",
      "Epoch 279: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.8045 - bpp: 1.3139 - mse: 2.1305e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5487 - bpp: 1.2822 - mse: 1.9937e-04\n",
      "Epoch 280: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5487 - bpp: 1.2822 - mse: 1.9937e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5183 - bpp: 1.3098 - mse: 2.5686e-04\n",
      "Epoch 281: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.5183 - bpp: 1.3098 - mse: 2.5686e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9602 - bpp: 1.2784 - mse: 2.2472e-04\n",
      "Epoch 282: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.9602 - bpp: 1.2784 - mse: 2.2472e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1095 - bpp: 1.2629 - mse: 1.7374e-04\n",
      "Epoch 283: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.1095 - bpp: 1.2629 - mse: 1.7374e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9309 - bpp: 1.3002 - mse: 2.2160e-04\n",
      "Epoch 284: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.9309 - bpp: 1.3002 - mse: 2.2160e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6615 - bpp: 1.3127 - mse: 2.6543e-04\n",
      "Epoch 285: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 5.6615 - bpp: 1.3127 - mse: 2.6543e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4732 - bpp: 1.2689 - mse: 2.5661e-04\n",
      "Epoch 286: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.4732 - bpp: 1.2689 - mse: 2.5661e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5994 - bpp: 1.2673 - mse: 2.0338e-04\n",
      "Epoch 287: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.5994 - bpp: 1.2673 - mse: 2.0338e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8190 - bpp: 1.3035 - mse: 2.1456e-04\n",
      "Epoch 288: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.8190 - bpp: 1.3035 - mse: 2.1456e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2417 - bpp: 1.2852 - mse: 1.8045e-04\n",
      "Epoch 289: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.2417 - bpp: 1.2852 - mse: 1.8045e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9544 - bpp: 1.2771 - mse: 2.8548e-04\n",
      "Epoch 290: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 5.9544 - bpp: 1.2771 - mse: 2.8548e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3640 - bpp: 1.2722 - mse: 1.8871e-04\n",
      "Epoch 291: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 4.3640 - bpp: 1.2722 - mse: 1.8871e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8480 - bpp: 1.3018 - mse: 2.1644e-04\n",
      "Epoch 292: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 4.8480 - bpp: 1.3018 - mse: 2.1644e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5904 - bpp: 1.2620 - mse: 2.0315e-04\n",
      "Epoch 293: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.5904 - bpp: 1.2620 - mse: 2.0315e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1973 - bpp: 1.2683 - mse: 1.7877e-04\n",
      "Epoch 294: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.1973 - bpp: 1.2683 - mse: 1.7877e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0386 - bpp: 1.3106 - mse: 2.2754e-04\n",
      "Epoch 295: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.0386 - bpp: 1.3106 - mse: 2.2754e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2660 - bpp: 1.2742 - mse: 1.8261e-04\n",
      "Epoch 296: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 4.2660 - bpp: 1.2742 - mse: 1.8261e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2989 - bpp: 1.2650 - mse: 1.8517e-04\n",
      "Epoch 297: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.2989 - bpp: 1.2650 - mse: 1.8517e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1986 - bpp: 1.3184 - mse: 2.3683e-04\n",
      "Epoch 298: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.1986 - bpp: 1.3184 - mse: 2.3683e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3504 - bpp: 1.2572 - mse: 1.8879e-04\n",
      "Epoch 299: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.3504 - bpp: 1.2572 - mse: 1.8879e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4288 - bpp: 1.3026 - mse: 1.9081e-04\n",
      "Epoch 300: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.4288 - bpp: 1.3026 - mse: 1.9081e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6450 - bpp: 1.3059 - mse: 3.8691e-04\n",
      "Epoch 301: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 7.6450 - bpp: 1.3059 - mse: 3.8691e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6991 - bpp: 1.3067 - mse: 2.6809e-04\n",
      "Epoch 302: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.6991 - bpp: 1.3067 - mse: 2.6809e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1075 - bpp: 1.2736 - mse: 1.7297e-04\n",
      "Epoch 303: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.1075 - bpp: 1.2736 - mse: 1.7297e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4643 - bpp: 1.2881 - mse: 1.9386e-04\n",
      "Epoch 304: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.4643 - bpp: 1.2881 - mse: 1.9386e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5877 - bpp: 1.2826 - mse: 2.0173e-04\n",
      "Epoch 305: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.5877 - bpp: 1.2826 - mse: 2.0173e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3473 - bpp: 1.2920 - mse: 1.8648e-04\n",
      "Epoch 306: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.3473 - bpp: 1.2920 - mse: 1.8648e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0541 - bpp: 1.2815 - mse: 1.6922e-04\n",
      "Epoch 307: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.0541 - bpp: 1.2815 - mse: 1.6922e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3493 - bpp: 1.2811 - mse: 1.8727e-04\n",
      "Epoch 308: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.3493 - bpp: 1.2811 - mse: 1.8727e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6823 - bpp: 1.2870 - mse: 2.0723e-04\n",
      "Epoch 309: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.6823 - bpp: 1.2870 - mse: 2.0723e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1604 - bpp: 1.2589 - mse: 1.7710e-04\n",
      "Epoch 310: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.1604 - bpp: 1.2589 - mse: 1.7710e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0295 - bpp: 1.2795 - mse: 1.6785e-04\n",
      "Epoch 311: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.0295 - bpp: 1.2795 - mse: 1.6785e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5867 - bpp: 1.2603 - mse: 2.0303e-04\n",
      "Epoch 312: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 4.5867 - bpp: 1.2603 - mse: 2.0303e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3620 - bpp: 1.2815 - mse: 2.4905e-04\n",
      "Epoch 313: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.3620 - bpp: 1.2815 - mse: 2.4905e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3172 - bpp: 1.2645 - mse: 1.8632e-04\n",
      "Epoch 314: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.3172 - bpp: 1.2645 - mse: 1.8632e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6586 - bpp: 1.2672 - mse: 2.0699e-04\n",
      "Epoch 315: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.6586 - bpp: 1.2672 - mse: 2.0699e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3135 - bpp: 1.2978 - mse: 1.8406e-04\n",
      "Epoch 316: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.3135 - bpp: 1.2978 - mse: 1.8406e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0686 - bpp: 1.2692 - mse: 1.7087e-04\n",
      "Epoch 317: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.0686 - bpp: 1.2692 - mse: 1.7087e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5010 - bpp: 1.2928 - mse: 1.9581e-04\n",
      "Epoch 318: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5010 - bpp: 1.2928 - mse: 1.9581e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5093 - bpp: 1.2835 - mse: 1.9689e-04\n",
      "Epoch 319: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5093 - bpp: 1.2835 - mse: 1.9689e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9879 - bpp: 1.2856 - mse: 2.2597e-04\n",
      "Epoch 320: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.9879 - bpp: 1.2856 - mse: 2.2597e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3496 - bpp: 1.2785 - mse: 1.8745e-04\n",
      "Epoch 321: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.3496 - bpp: 1.2785 - mse: 1.8745e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9262 - bpp: 1.2666 - mse: 1.6233e-04\n",
      "Epoch 322: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 3.9262 - bpp: 1.2666 - mse: 1.6233e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8275 - bpp: 1.2528 - mse: 1.5715e-04\n",
      "Epoch 323: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 3.8275 - bpp: 1.2528 - mse: 1.5715e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9210 - bpp: 1.3188 - mse: 2.1986e-04\n",
      "Epoch 324: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.9210 - bpp: 1.3188 - mse: 2.1986e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3194 - bpp: 1.2931 - mse: 2.4575e-04\n",
      "Epoch 325: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.3194 - bpp: 1.2931 - mse: 2.4575e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2320 - bpp: 1.2696 - mse: 1.8081e-04\n",
      "Epoch 326: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.2320 - bpp: 1.2696 - mse: 1.8081e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9755 - bpp: 1.2702 - mse: 2.2616e-04\n",
      "Epoch 327: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.9755 - bpp: 1.2702 - mse: 2.2616e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4886 - bpp: 1.2524 - mse: 1.9752e-04\n",
      "Epoch 328: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.4886 - bpp: 1.2524 - mse: 1.9752e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1794 - bpp: 1.2880 - mse: 2.3751e-04\n",
      "Epoch 329: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.1794 - bpp: 1.2880 - mse: 2.3751e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4605 - bpp: 1.2755 - mse: 1.9440e-04\n",
      "Epoch 330: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.4605 - bpp: 1.2755 - mse: 1.9440e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0590 - bpp: 1.2659 - mse: 1.7048e-04\n",
      "Epoch 331: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.0590 - bpp: 1.2659 - mse: 1.7048e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9001 - bpp: 1.2385 - mse: 1.6245e-04\n",
      "Epoch 332: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.9001 - bpp: 1.2385 - mse: 1.6245e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9418 - bpp: 1.2765 - mse: 1.6268e-04\n",
      "Epoch 333: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.9418 - bpp: 1.2765 - mse: 1.6268e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5571 - bpp: 1.3024 - mse: 1.9865e-04\n",
      "Epoch 334: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.5571 - bpp: 1.3024 - mse: 1.9865e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2754 - bpp: 1.2789 - mse: 1.8289e-04\n",
      "Epoch 335: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.2754 - bpp: 1.2789 - mse: 1.8289e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1751 - bpp: 1.3090 - mse: 2.3597e-04\n",
      "Epoch 336: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.1751 - bpp: 1.3090 - mse: 2.3597e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0014 - bpp: 1.2511 - mse: 1.6787e-04\n",
      "Epoch 337: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.0014 - bpp: 1.2511 - mse: 1.6787e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5248 - bpp: 1.2865 - mse: 2.5869e-04\n",
      "Epoch 338: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 5.5248 - bpp: 1.2865 - mse: 2.5869e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7290 - bpp: 1.2892 - mse: 2.0995e-04\n",
      "Epoch 339: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 4.7290 - bpp: 1.2892 - mse: 2.0995e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3667 - bpp: 1.2854 - mse: 1.8807e-04\n",
      "Epoch 340: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.3667 - bpp: 1.2854 - mse: 1.8807e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5110 - bpp: 1.2979 - mse: 1.9612e-04\n",
      "Epoch 341: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.5110 - bpp: 1.2979 - mse: 1.9612e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9170 - bpp: 1.2466 - mse: 1.6299e-04\n",
      "Epoch 342: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.9170 - bpp: 1.2466 - mse: 1.6299e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1411 - bpp: 1.2616 - mse: 1.7575e-04\n",
      "Epoch 343: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.1411 - bpp: 1.2616 - mse: 1.7575e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9374 - bpp: 1.2625 - mse: 1.6327e-04\n",
      "Epoch 344: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.9374 - bpp: 1.2625 - mse: 1.6327e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1627 - bpp: 1.2534 - mse: 2.3860e-04\n",
      "Epoch 345: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.1627 - bpp: 1.2534 - mse: 2.3860e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3646 - bpp: 1.2737 - mse: 1.8866e-04\n",
      "Epoch 346: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.3646 - bpp: 1.2737 - mse: 1.8866e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6630 - bpp: 1.2522 - mse: 1.4715e-04\n",
      "Epoch 347: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.6630 - bpp: 1.2522 - mse: 1.4715e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6810 - bpp: 1.2355 - mse: 1.4926e-04\n",
      "Epoch 348: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.6810 - bpp: 1.2355 - mse: 1.4926e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9207 - bpp: 1.2931 - mse: 2.8245e-04\n",
      "Epoch 349: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.9207 - bpp: 1.2931 - mse: 2.8245e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1288 - bpp: 1.2543 - mse: 1.7545e-04\n",
      "Epoch 350: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.1288 - bpp: 1.2543 - mse: 1.7545e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1819 - bpp: 1.2736 - mse: 1.7751e-04\n",
      "Epoch 351: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.1819 - bpp: 1.2736 - mse: 1.7751e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9739 - bpp: 1.2352 - mse: 1.6716e-04\n",
      "Epoch 352: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9739 - bpp: 1.2352 - mse: 1.6716e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3282 - bpp: 1.2443 - mse: 1.8823e-04\n",
      "Epoch 353: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.3282 - bpp: 1.2443 - mse: 1.8823e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6763 - bpp: 1.2377 - mse: 1.4884e-04\n",
      "Epoch 354: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6763 - bpp: 1.2377 - mse: 1.4884e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0972 - bpp: 1.2593 - mse: 1.7321e-04\n",
      "Epoch 355: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.0972 - bpp: 1.2593 - mse: 1.7321e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0091 - bpp: 1.2313 - mse: 1.6954e-04\n",
      "Epoch 356: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.0091 - bpp: 1.2313 - mse: 1.6954e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5494 - bpp: 1.3004 - mse: 1.9830e-04\n",
      "Epoch 357: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.5494 - bpp: 1.3004 - mse: 1.9830e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8444 - bpp: 1.2412 - mse: 1.5889e-04\n",
      "Epoch 358: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8444 - bpp: 1.2412 - mse: 1.5889e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0478 - bpp: 1.2581 - mse: 1.7027e-04\n",
      "Epoch 359: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.0478 - bpp: 1.2581 - mse: 1.7027e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4804 - bpp: 1.2629 - mse: 1.9638e-04\n",
      "Epoch 360: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.4804 - bpp: 1.2629 - mse: 1.9638e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8747 - bpp: 1.2430 - mse: 1.6063e-04\n",
      "Epoch 361: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.8747 - bpp: 1.2430 - mse: 1.6063e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9383 - bpp: 1.3015 - mse: 2.2197e-04\n",
      "Epoch 362: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.9383 - bpp: 1.3015 - mse: 2.2197e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6485 - bpp: 1.2803 - mse: 2.0558e-04\n",
      "Epoch 363: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.6485 - bpp: 1.2803 - mse: 2.0558e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7721 - bpp: 1.2417 - mse: 1.5445e-04\n",
      "Epoch 364: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.7721 - bpp: 1.2417 - mse: 1.5445e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3273 - bpp: 1.2695 - mse: 1.8663e-04\n",
      "Epoch 365: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.3273 - bpp: 1.2695 - mse: 1.8663e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6678 - bpp: 1.2775 - mse: 2.0693e-04\n",
      "Epoch 366: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.6678 - bpp: 1.2775 - mse: 2.0693e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9992 - bpp: 1.2636 - mse: 1.6696e-04\n",
      "Epoch 367: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 224ms/step - loss: 3.9992 - bpp: 1.2636 - mse: 1.6696e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6779 - bpp: 1.2882 - mse: 2.0689e-04\n",
      "Epoch 368: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.6779 - bpp: 1.2882 - mse: 2.0689e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1758 - bpp: 1.2674 - mse: 1.7751e-04\n",
      "Epoch 369: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.1758 - bpp: 1.2674 - mse: 1.7751e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0733 - bpp: 1.2621 - mse: 1.7158e-04\n",
      "Epoch 370: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0733 - bpp: 1.2621 - mse: 1.7158e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0413 - bpp: 1.2513 - mse: 1.7029e-04\n",
      "Epoch 371: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.0413 - bpp: 1.2513 - mse: 1.7029e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9750 - bpp: 1.2637 - mse: 1.6548e-04\n",
      "Epoch 372: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.9750 - bpp: 1.2637 - mse: 1.6548e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2081 - bpp: 1.2939 - mse: 2.3891e-04\n",
      "Epoch 373: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.2081 - bpp: 1.2939 - mse: 2.3891e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8951 - bpp: 1.2868 - mse: 2.2023e-04\n",
      "Epoch 374: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.8951 - bpp: 1.2868 - mse: 2.2023e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4465 - bpp: 1.2757 - mse: 1.9353e-04\n",
      "Epoch 375: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.4465 - bpp: 1.2757 - mse: 1.9353e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8527 - bpp: 1.2546 - mse: 1.5858e-04\n",
      "Epoch 376: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.8527 - bpp: 1.2546 - mse: 1.5858e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1388 - bpp: 1.2764 - mse: 1.7471e-04\n",
      "Epoch 377: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.1388 - bpp: 1.2764 - mse: 1.7471e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8026 - bpp: 1.2438 - mse: 1.5617e-04\n",
      "Epoch 378: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.8026 - bpp: 1.2438 - mse: 1.5617e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9873 - bpp: 1.2519 - mse: 1.6695e-04\n",
      "Epoch 379: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.9873 - bpp: 1.2519 - mse: 1.6695e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5798 - bpp: 1.2771 - mse: 2.0158e-04\n",
      "Epoch 380: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.5798 - bpp: 1.2771 - mse: 2.0158e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7104 - bpp: 1.2306 - mse: 1.5135e-04\n",
      "Epoch 381: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.7104 - bpp: 1.2306 - mse: 1.5135e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6534 - bpp: 1.2359 - mse: 1.4755e-04\n",
      "Epoch 382: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6534 - bpp: 1.2359 - mse: 1.4755e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0900 - bpp: 1.2622 - mse: 1.7260e-04\n",
      "Epoch 383: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0900 - bpp: 1.2622 - mse: 1.7260e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2472 - bpp: 1.2816 - mse: 1.8101e-04\n",
      "Epoch 384: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.2472 - bpp: 1.2816 - mse: 1.8101e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5868 - bpp: 1.2626 - mse: 2.0289e-04\n",
      "Epoch 385: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 4.5868 - bpp: 1.2626 - mse: 2.0289e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3596 - bpp: 1.2850 - mse: 1.8766e-04\n",
      "Epoch 386: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 4.3596 - bpp: 1.2850 - mse: 1.8766e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3675 - bpp: 1.2380 - mse: 1.9101e-04\n",
      "Epoch 387: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 4.3675 - bpp: 1.2380 - mse: 1.9101e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7202 - bpp: 1.2385 - mse: 1.5147e-04\n",
      "Epoch 388: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.7202 - bpp: 1.2385 - mse: 1.5147e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7250 - bpp: 1.2372 - mse: 1.5184e-04\n",
      "Epoch 389: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.7250 - bpp: 1.2372 - mse: 1.5184e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2329 - bpp: 1.2673 - mse: 1.8100e-04\n",
      "Epoch 390: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.2329 - bpp: 1.2673 - mse: 1.8100e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1477 - bpp: 1.2620 - mse: 1.7613e-04\n",
      "Epoch 391: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 4.1477 - bpp: 1.2620 - mse: 1.7613e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8442 - bpp: 1.2575 - mse: 1.5788e-04\n",
      "Epoch 392: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8442 - bpp: 1.2575 - mse: 1.5788e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1041 - bpp: 1.2739 - mse: 1.7274e-04\n",
      "Epoch 393: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 4.1041 - bpp: 1.2739 - mse: 1.7274e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6648 - bpp: 1.2432 - mse: 1.4780e-04\n",
      "Epoch 394: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6648 - bpp: 1.2432 - mse: 1.4780e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9709 - bpp: 1.2556 - mse: 1.6573e-04\n",
      "Epoch 395: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.9709 - bpp: 1.2556 - mse: 1.6573e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8065 - bpp: 1.2545 - mse: 1.5576e-04\n",
      "Epoch 396: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.8065 - bpp: 1.2545 - mse: 1.5576e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4626 - bpp: 1.2571 - mse: 1.9565e-04\n",
      "Epoch 397: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.4626 - bpp: 1.2571 - mse: 1.9565e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7970 - bpp: 1.2508 - mse: 2.1645e-04\n",
      "Epoch 398: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.7970 - bpp: 1.2508 - mse: 2.1645e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7741 - bpp: 1.2705 - mse: 2.1384e-04\n",
      "Epoch 399: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.7741 - bpp: 1.2705 - mse: 2.1384e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5886 - bpp: 1.2806 - mse: 2.0191e-04\n",
      "Epoch 400: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.5886 - bpp: 1.2806 - mse: 2.0191e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4629 - bpp: 1.2183 - mse: 1.3700e-04\n",
      "Epoch 401: loss improved from 3.52158 to 3.46289, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.4629 - bpp: 1.2183 - mse: 1.3700e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3099 - bpp: 1.2852 - mse: 1.8461e-04\n",
      "Epoch 402: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.3099 - bpp: 1.2852 - mse: 1.8461e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6659 - bpp: 1.2454 - mse: 1.4774e-04\n",
      "Epoch 403: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 224ms/step - loss: 3.6659 - bpp: 1.2454 - mse: 1.4774e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1661 - bpp: 1.2621 - mse: 1.7725e-04\n",
      "Epoch 404: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.1661 - bpp: 1.2621 - mse: 1.7725e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6445 - bpp: 1.2581 - mse: 1.4565e-04\n",
      "Epoch 405: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6445 - bpp: 1.2581 - mse: 1.4565e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6375 - bpp: 1.2634 - mse: 2.0594e-04\n",
      "Epoch 406: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.6375 - bpp: 1.2634 - mse: 2.0594e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1646 - bpp: 1.2670 - mse: 1.7686e-04\n",
      "Epoch 407: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 4.1646 - bpp: 1.2670 - mse: 1.7686e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2200 - bpp: 1.2559 - mse: 1.8092e-04\n",
      "Epoch 408: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.2200 - bpp: 1.2559 - mse: 1.8092e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6132 - bpp: 1.2240 - mse: 1.4582e-04\n",
      "Epoch 409: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6132 - bpp: 1.2240 - mse: 1.4582e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5430 - bpp: 1.2450 - mse: 1.4026e-04\n",
      "Epoch 410: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5430 - bpp: 1.2450 - mse: 1.4026e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8415 - bpp: 1.2630 - mse: 1.5738e-04\n",
      "Epoch 411: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.8415 - bpp: 1.2630 - mse: 1.5738e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7443 - bpp: 1.2383 - mse: 1.5295e-04\n",
      "Epoch 412: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7443 - bpp: 1.2383 - mse: 1.5295e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1317 - bpp: 1.3018 - mse: 1.7273e-04\n",
      "Epoch 413: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.1317 - bpp: 1.3018 - mse: 1.7273e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9987 - bpp: 1.2640 - mse: 1.6691e-04\n",
      "Epoch 414: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.9987 - bpp: 1.2640 - mse: 1.6691e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3192 - bpp: 1.2698 - mse: 1.8612e-04\n",
      "Epoch 415: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.3192 - bpp: 1.2698 - mse: 1.8612e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4629 - bpp: 1.2245 - mse: 1.3662e-04\n",
      "Epoch 416: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4629 - bpp: 1.2245 - mse: 1.3662e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9252 - bpp: 1.2456 - mse: 1.6355e-04\n",
      "Epoch 417: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9252 - bpp: 1.2456 - mse: 1.6355e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3846 - bpp: 1.2263 - mse: 1.9276e-04\n",
      "Epoch 418: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.3846 - bpp: 1.2263 - mse: 1.9276e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9239 - bpp: 1.2494 - mse: 1.6324e-04\n",
      "Epoch 419: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.9239 - bpp: 1.2494 - mse: 1.6324e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9575 - bpp: 1.2545 - mse: 1.6498e-04\n",
      "Epoch 420: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.9575 - bpp: 1.2545 - mse: 1.6498e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2566 - bpp: 1.2604 - mse: 1.8288e-04\n",
      "Epoch 421: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.2566 - bpp: 1.2604 - mse: 1.8288e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2953 - bpp: 1.2539 - mse: 1.8563e-04\n",
      "Epoch 422: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.2953 - bpp: 1.2539 - mse: 1.8563e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6072 - bpp: 1.2205 - mse: 1.4567e-04\n",
      "Epoch 423: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6072 - bpp: 1.2205 - mse: 1.4567e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6233 - bpp: 1.2438 - mse: 1.4524e-04\n",
      "Epoch 424: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6233 - bpp: 1.2438 - mse: 1.4524e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5347 - bpp: 1.2568 - mse: 2.0007e-04\n",
      "Epoch 425: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.5347 - bpp: 1.2568 - mse: 2.0007e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9212 - bpp: 1.2330 - mse: 1.6408e-04\n",
      "Epoch 426: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.9212 - bpp: 1.2330 - mse: 1.6408e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8445 - bpp: 1.2424 - mse: 1.5882e-04\n",
      "Epoch 427: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.8445 - bpp: 1.2424 - mse: 1.5882e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6749 - bpp: 1.2303 - mse: 1.4920e-04\n",
      "Epoch 428: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6749 - bpp: 1.2303 - mse: 1.4920e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9995 - bpp: 1.2573 - mse: 1.6737e-04\n",
      "Epoch 429: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9995 - bpp: 1.2573 - mse: 1.6737e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0117 - bpp: 1.2634 - mse: 1.6774e-04\n",
      "Epoch 430: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.0117 - bpp: 1.2634 - mse: 1.6774e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5636 - bpp: 1.2150 - mse: 1.4335e-04\n",
      "Epoch 431: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5636 - bpp: 1.2150 - mse: 1.4335e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9978 - bpp: 1.2420 - mse: 1.6820e-04\n",
      "Epoch 432: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.9978 - bpp: 1.2420 - mse: 1.6820e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9257 - bpp: 1.2150 - mse: 1.6544e-04\n",
      "Epoch 433: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.9257 - bpp: 1.2150 - mse: 1.6544e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0126 - bpp: 1.2198 - mse: 1.7046e-04\n",
      "Epoch 434: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.0126 - bpp: 1.2198 - mse: 1.7046e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5561 - bpp: 1.2670 - mse: 2.0075e-04\n",
      "Epoch 435: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.5561 - bpp: 1.2670 - mse: 2.0075e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7052 - bpp: 1.2343 - mse: 1.5081e-04\n",
      "Epoch 436: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.7052 - bpp: 1.2343 - mse: 1.5081e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9511 - bpp: 1.2715 - mse: 1.6355e-04\n",
      "Epoch 437: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.9511 - bpp: 1.2715 - mse: 1.6355e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8666 - bpp: 1.2264 - mse: 1.6114e-04\n",
      "Epoch 438: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8666 - bpp: 1.2264 - mse: 1.6114e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9315 - bpp: 1.2381 - mse: 1.6440e-04\n",
      "Epoch 439: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.9315 - bpp: 1.2381 - mse: 1.6440e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5276 - bpp: 1.2110 - mse: 1.4139e-04\n",
      "Epoch 440: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.5276 - bpp: 1.2110 - mse: 1.4139e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6939 - bpp: 1.2086 - mse: 1.5169e-04\n",
      "Epoch 441: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.6939 - bpp: 1.2086 - mse: 1.5169e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7074 - bpp: 1.2454 - mse: 1.5027e-04\n",
      "Epoch 442: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.7074 - bpp: 1.2454 - mse: 1.5027e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9760 - bpp: 1.2271 - mse: 1.6778e-04\n",
      "Epoch 443: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.9760 - bpp: 1.2271 - mse: 1.6778e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7636 - bpp: 1.2294 - mse: 1.5467e-04\n",
      "Epoch 444: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.7636 - bpp: 1.2294 - mse: 1.5467e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7872 - bpp: 1.2247 - mse: 1.5640e-04\n",
      "Epoch 445: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7872 - bpp: 1.2247 - mse: 1.5640e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8584 - bpp: 1.2318 - mse: 1.6032e-04\n",
      "Epoch 446: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.8584 - bpp: 1.2318 - mse: 1.6032e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6694 - bpp: 1.2514 - mse: 1.4758e-04\n",
      "Epoch 447: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6694 - bpp: 1.2514 - mse: 1.4758e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1509 - bpp: 1.2553 - mse: 1.7673e-04\n",
      "Epoch 448: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.1509 - bpp: 1.2553 - mse: 1.7673e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6846 - bpp: 1.2397 - mse: 1.4923e-04\n",
      "Epoch 449: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.6846 - bpp: 1.2397 - mse: 1.4923e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0078 - bpp: 1.2498 - mse: 1.6834e-04\n",
      "Epoch 450: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0078 - bpp: 1.2498 - mse: 1.6834e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8853 - bpp: 1.2492 - mse: 1.6089e-04\n",
      "Epoch 451: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.8853 - bpp: 1.2492 - mse: 1.6089e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1989 - bpp: 1.2071 - mse: 1.2157e-04\n",
      "Epoch 452: loss improved from 3.46289 to 3.19885, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.1989 - bpp: 1.2071 - mse: 1.2157e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9404 - bpp: 1.2564 - mse: 1.6382e-04\n",
      "Epoch 453: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.9404 - bpp: 1.2564 - mse: 1.6382e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6425 - bpp: 1.2247 - mse: 1.4757e-04\n",
      "Epoch 454: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.6425 - bpp: 1.2247 - mse: 1.4757e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7624 - bpp: 1.2096 - mse: 1.5581e-04\n",
      "Epoch 455: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.7624 - bpp: 1.2096 - mse: 1.5581e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0969 - bpp: 1.2228 - mse: 1.7542e-04\n",
      "Epoch 456: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0969 - bpp: 1.2228 - mse: 1.7542e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2800 - bpp: 1.2251 - mse: 1.8646e-04\n",
      "Epoch 457: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 4.2800 - bpp: 1.2251 - mse: 1.8646e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5481 - bpp: 1.2278 - mse: 1.4162e-04\n",
      "Epoch 458: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.5481 - bpp: 1.2278 - mse: 1.4162e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5108 - bpp: 1.2272 - mse: 1.3938e-04\n",
      "Epoch 459: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.5108 - bpp: 1.2272 - mse: 1.3938e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7842 - bpp: 1.2553 - mse: 1.5435e-04\n",
      "Epoch 460: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.7842 - bpp: 1.2553 - mse: 1.5435e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1923 - bpp: 1.2717 - mse: 1.7826e-04\n",
      "Epoch 461: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 4.1923 - bpp: 1.2717 - mse: 1.7826e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5968 - bpp: 1.2333 - mse: 1.4426e-04\n",
      "Epoch 462: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5968 - bpp: 1.2333 - mse: 1.4426e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0071 - bpp: 1.2345 - mse: 1.6923e-04\n",
      "Epoch 463: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.0071 - bpp: 1.2345 - mse: 1.6923e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9655 - bpp: 1.2375 - mse: 1.6651e-04\n",
      "Epoch 464: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9655 - bpp: 1.2375 - mse: 1.6651e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1979 - bpp: 1.2429 - mse: 1.8036e-04\n",
      "Epoch 465: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 4.1979 - bpp: 1.2429 - mse: 1.8036e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4025 - bpp: 1.2129 - mse: 1.3364e-04\n",
      "Epoch 466: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.4025 - bpp: 1.2129 - mse: 1.3364e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7096 - bpp: 1.2225 - mse: 1.5180e-04\n",
      "Epoch 467: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7096 - bpp: 1.2225 - mse: 1.5180e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5357 - bpp: 1.2181 - mse: 1.4145e-04\n",
      "Epoch 468: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5357 - bpp: 1.2181 - mse: 1.4145e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7136 - bpp: 1.2271 - mse: 1.5177e-04\n",
      "Epoch 469: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7136 - bpp: 1.2271 - mse: 1.5177e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6530 - bpp: 1.2058 - mse: 1.4937e-04\n",
      "Epoch 470: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6530 - bpp: 1.2058 - mse: 1.4937e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7444 - bpp: 1.2161 - mse: 1.5432e-04\n",
      "Epoch 471: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7444 - bpp: 1.2161 - mse: 1.5432e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8537 - bpp: 1.2541 - mse: 2.1970e-04\n",
      "Epoch 472: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.8537 - bpp: 1.2541 - mse: 2.1970e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7746 - bpp: 1.2326 - mse: 1.5515e-04\n",
      "Epoch 473: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.7746 - bpp: 1.2326 - mse: 1.5515e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7019 - bpp: 1.2179 - mse: 1.5161e-04\n",
      "Epoch 474: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.7019 - bpp: 1.2179 - mse: 1.5161e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3812 - bpp: 1.1997 - mse: 1.3315e-04\n",
      "Epoch 475: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.3812 - bpp: 1.1997 - mse: 1.3315e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4456 - bpp: 1.2009 - mse: 1.3700e-04\n",
      "Epoch 476: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4456 - bpp: 1.2009 - mse: 1.3700e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4119 - bpp: 1.1994 - mse: 1.3504e-04\n",
      "Epoch 477: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.4119 - bpp: 1.1994 - mse: 1.3504e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4412 - bpp: 1.2207 - mse: 1.3552e-04\n",
      "Epoch 478: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4412 - bpp: 1.2207 - mse: 1.3552e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8900 - bpp: 1.2390 - mse: 2.2284e-04\n",
      "Epoch 479: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.8900 - bpp: 1.2390 - mse: 2.2284e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6689 - bpp: 1.2339 - mse: 1.4862e-04\n",
      "Epoch 480: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.6689 - bpp: 1.2339 - mse: 1.4862e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4680 - bpp: 1.2199 - mse: 1.3722e-04\n",
      "Epoch 481: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4680 - bpp: 1.2199 - mse: 1.3722e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4850 - bpp: 1.2017 - mse: 1.3937e-04\n",
      "Epoch 482: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.4850 - bpp: 1.2017 - mse: 1.3937e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7957 - bpp: 1.2365 - mse: 1.5620e-04\n",
      "Epoch 483: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7957 - bpp: 1.2365 - mse: 1.5620e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8392 - bpp: 1.2353 - mse: 1.5893e-04\n",
      "Epoch 484: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.8392 - bpp: 1.2353 - mse: 1.5893e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3876 - bpp: 1.1905 - mse: 1.3411e-04\n",
      "Epoch 485: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.3876 - bpp: 1.1905 - mse: 1.3411e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8407 - bpp: 1.2192 - mse: 1.6001e-04\n",
      "Epoch 486: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.8407 - bpp: 1.2192 - mse: 1.6001e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6593 - bpp: 1.2174 - mse: 1.4904e-04\n",
      "Epoch 487: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.6593 - bpp: 1.2174 - mse: 1.4904e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7031 - bpp: 1.2129 - mse: 1.5199e-04\n",
      "Epoch 488: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7031 - bpp: 1.2129 - mse: 1.5199e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6442 - bpp: 1.2258 - mse: 1.4760e-04\n",
      "Epoch 489: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.6442 - bpp: 1.2258 - mse: 1.4760e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6427 - bpp: 1.2228 - mse: 1.4770e-04\n",
      "Epoch 490: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.6427 - bpp: 1.2228 - mse: 1.4770e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4497 - bpp: 1.2029 - mse: 1.3713e-04\n",
      "Epoch 491: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4497 - bpp: 1.2029 - mse: 1.3713e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8457 - bpp: 1.2382 - mse: 1.5915e-04\n",
      "Epoch 492: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.8457 - bpp: 1.2382 - mse: 1.5915e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0335 - bpp: 1.2356 - mse: 1.7077e-04\n",
      "Epoch 493: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.0335 - bpp: 1.2356 - mse: 1.7077e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2708 - bpp: 1.2640 - mse: 1.8352e-04\n",
      "Epoch 494: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.2708 - bpp: 1.2640 - mse: 1.8352e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8695 - bpp: 1.2294 - mse: 1.6114e-04\n",
      "Epoch 495: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.8695 - bpp: 1.2294 - mse: 1.6114e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9419 - bpp: 1.2198 - mse: 1.6615e-04\n",
      "Epoch 496: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9419 - bpp: 1.2198 - mse: 1.6615e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2764 - bpp: 1.1915 - mse: 1.2725e-04\n",
      "Epoch 497: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2764 - bpp: 1.1915 - mse: 1.2725e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3026 - bpp: 1.1825 - mse: 1.2940e-04\n",
      "Epoch 498: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3026 - bpp: 1.1825 - mse: 1.2940e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1532 - bpp: 1.1865 - mse: 1.2004e-04\n",
      "Epoch 499: loss improved from 3.19885 to 3.15324, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.1532 - bpp: 1.1865 - mse: 1.2004e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7635 - bpp: 1.2262 - mse: 1.5486e-04\n",
      "Epoch 500: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7635 - bpp: 1.2262 - mse: 1.5486e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9530 - bpp: 1.2389 - mse: 2.2669e-04\n",
      "Epoch 501: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.9530 - bpp: 1.2389 - mse: 2.2669e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9979 - bpp: 1.2381 - mse: 1.6844e-04\n",
      "Epoch 502: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.9979 - bpp: 1.2381 - mse: 1.6844e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8595 - bpp: 1.2452 - mse: 1.5956e-04\n",
      "Epoch 503: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8595 - bpp: 1.2452 - mse: 1.5956e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5148 - bpp: 1.2021 - mse: 1.4115e-04\n",
      "Epoch 504: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5148 - bpp: 1.2021 - mse: 1.4115e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4259 - bpp: 1.1892 - mse: 1.3652e-04\n",
      "Epoch 505: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4259 - bpp: 1.1892 - mse: 1.3652e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4511 - bpp: 1.1943 - mse: 1.3774e-04\n",
      "Epoch 506: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4511 - bpp: 1.1943 - mse: 1.3774e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3001 - bpp: 1.1916 - mse: 1.2869e-04\n",
      "Epoch 507: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3001 - bpp: 1.1916 - mse: 1.2869e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5504 - bpp: 1.2135 - mse: 1.4263e-04\n",
      "Epoch 508: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.5504 - bpp: 1.2135 - mse: 1.4263e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5778 - bpp: 1.1949 - mse: 1.4544e-04\n",
      "Epoch 509: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5778 - bpp: 1.1949 - mse: 1.4544e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8558 - bpp: 1.2487 - mse: 1.5912e-04\n",
      "Epoch 510: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.8558 - bpp: 1.2487 - mse: 1.5912e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6731 - bpp: 1.1866 - mse: 1.5176e-04\n",
      "Epoch 511: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.6731 - bpp: 1.1866 - mse: 1.5176e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3443 - bpp: 1.1937 - mse: 1.3126e-04\n",
      "Epoch 512: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3443 - bpp: 1.1937 - mse: 1.3126e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6680 - bpp: 1.1954 - mse: 1.5092e-04\n",
      "Epoch 513: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.6680 - bpp: 1.1954 - mse: 1.5092e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1692 - bpp: 1.1762 - mse: 1.2165e-04\n",
      "Epoch 514: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.1692 - bpp: 1.1762 - mse: 1.2165e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0451 - bpp: 1.2183 - mse: 1.7254e-04\n",
      "Epoch 515: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.0451 - bpp: 1.2183 - mse: 1.7254e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6335 - bpp: 1.2326 - mse: 1.4654e-04\n",
      "Epoch 516: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.6335 - bpp: 1.2326 - mse: 1.4654e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5704 - bpp: 1.2150 - mse: 1.4376e-04\n",
      "Epoch 517: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5704 - bpp: 1.2150 - mse: 1.4376e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5643 - bpp: 1.1867 - mse: 1.4512e-04\n",
      "Epoch 518: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5643 - bpp: 1.1867 - mse: 1.4512e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7121 - bpp: 1.2159 - mse: 1.5236e-04\n",
      "Epoch 519: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7121 - bpp: 1.2159 - mse: 1.5236e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4970 - bpp: 1.2033 - mse: 1.4000e-04\n",
      "Epoch 520: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.4970 - bpp: 1.2033 - mse: 1.4000e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6592 - bpp: 1.1848 - mse: 1.5102e-04\n",
      "Epoch 521: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6592 - bpp: 1.1848 - mse: 1.5102e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1684 - bpp: 1.2289 - mse: 2.4045e-04\n",
      "Epoch 522: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.1684 - bpp: 1.2289 - mse: 2.4045e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1745 - bpp: 1.1851 - mse: 1.2142e-04\n",
      "Epoch 523: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.1745 - bpp: 1.1851 - mse: 1.2142e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5585 - bpp: 1.2046 - mse: 1.4367e-04\n",
      "Epoch 524: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5585 - bpp: 1.2046 - mse: 1.4367e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5660 - bpp: 1.2084 - mse: 1.4390e-04\n",
      "Epoch 525: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5660 - bpp: 1.2084 - mse: 1.4390e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4727 - bpp: 1.2014 - mse: 1.3863e-04\n",
      "Epoch 526: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4727 - bpp: 1.2014 - mse: 1.3863e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5086 - bpp: 1.2155 - mse: 1.3996e-04\n",
      "Epoch 527: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5086 - bpp: 1.2155 - mse: 1.3996e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4303 - bpp: 1.2345 - mse: 1.9505e-04\n",
      "Epoch 528: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.4303 - bpp: 1.2345 - mse: 1.9505e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5985 - bpp: 1.2066 - mse: 1.4599e-04\n",
      "Epoch 529: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5985 - bpp: 1.2066 - mse: 1.4599e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7819 - bpp: 1.2021 - mse: 1.5746e-04\n",
      "Epoch 530: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.7819 - bpp: 1.2021 - mse: 1.5746e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4584 - bpp: 1.1931 - mse: 1.3826e-04\n",
      "Epoch 531: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4584 - bpp: 1.1931 - mse: 1.3826e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1628 - bpp: 1.1518 - mse: 1.2275e-04\n",
      "Epoch 532: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1628 - bpp: 1.1518 - mse: 1.2275e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2742 - bpp: 1.1764 - mse: 1.2804e-04\n",
      "Epoch 533: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.2742 - bpp: 1.1764 - mse: 1.2804e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4845 - bpp: 1.2076 - mse: 2.0001e-04\n",
      "Epoch 534: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.4845 - bpp: 1.2076 - mse: 2.0001e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1660 - bpp: 1.1727 - mse: 1.2166e-04\n",
      "Epoch 535: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.1660 - bpp: 1.1727 - mse: 1.2166e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6783 - bpp: 1.2032 - mse: 1.5107e-04\n",
      "Epoch 536: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.6783 - bpp: 1.2032 - mse: 1.5107e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7672 - bpp: 1.2079 - mse: 1.5621e-04\n",
      "Epoch 537: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.7672 - bpp: 1.2079 - mse: 1.5621e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4558 - bpp: 1.2016 - mse: 1.3758e-04\n",
      "Epoch 538: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.4558 - bpp: 1.2016 - mse: 1.3758e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6754 - bpp: 1.2340 - mse: 1.4901e-04\n",
      "Epoch 539: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 228ms/step - loss: 3.6754 - bpp: 1.2340 - mse: 1.4901e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6673 - bpp: 1.2005 - mse: 1.5056e-04\n",
      "Epoch 540: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6673 - bpp: 1.2005 - mse: 1.5056e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2985 - bpp: 1.1920 - mse: 1.2857e-04\n",
      "Epoch 541: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.2985 - bpp: 1.1920 - mse: 1.2857e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7001 - bpp: 1.2008 - mse: 1.5255e-04\n",
      "Epoch 542: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7001 - bpp: 1.2008 - mse: 1.5255e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6576 - bpp: 1.2045 - mse: 1.4972e-04\n",
      "Epoch 543: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 3.6576 - bpp: 1.2045 - mse: 1.4972e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3994 - bpp: 1.1768 - mse: 1.3566e-04\n",
      "Epoch 544: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.3994 - bpp: 1.1768 - mse: 1.3566e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3621 - bpp: 1.1960 - mse: 1.3221e-04\n",
      "Epoch 545: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.3621 - bpp: 1.1960 - mse: 1.3221e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9297 - bpp: 1.2447 - mse: 1.6388e-04\n",
      "Epoch 546: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.9297 - bpp: 1.2447 - mse: 1.6388e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1883 - bpp: 1.1653 - mse: 1.2347e-04\n",
      "Epoch 547: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 3.1883 - bpp: 1.1653 - mse: 1.2347e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7427 - bpp: 1.2161 - mse: 1.5421e-04\n",
      "Epoch 548: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7427 - bpp: 1.2161 - mse: 1.5421e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8069 - bpp: 1.2214 - mse: 1.5781e-04\n",
      "Epoch 549: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8069 - bpp: 1.2214 - mse: 1.5781e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4749 - bpp: 1.1866 - mse: 1.3966e-04\n",
      "Epoch 550: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.4749 - bpp: 1.1866 - mse: 1.3966e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7247 - bpp: 1.2049 - mse: 1.5379e-04\n",
      "Epoch 551: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 3.7247 - bpp: 1.2049 - mse: 1.5379e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4451 - bpp: 1.1898 - mse: 1.3765e-04\n",
      "Epoch 552: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4451 - bpp: 1.1898 - mse: 1.3765e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6880 - bpp: 1.1841 - mse: 1.5283e-04\n",
      "Epoch 553: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 3.6880 - bpp: 1.1841 - mse: 1.5283e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6836 - bpp: 1.2023 - mse: 1.5145e-04\n",
      "Epoch 554: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 3.6836 - bpp: 1.2023 - mse: 1.5145e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8683 - bpp: 1.2182 - mse: 1.6175e-04\n",
      "Epoch 555: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8683 - bpp: 1.2182 - mse: 1.6175e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9683 - bpp: 1.2071 - mse: 1.6853e-04\n",
      "Epoch 556: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.9683 - bpp: 1.2071 - mse: 1.6853e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3910 - bpp: 1.1709 - mse: 1.3550e-04\n",
      "Epoch 557: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3910 - bpp: 1.1709 - mse: 1.3550e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2801 - bpp: 1.1824 - mse: 1.2803e-04\n",
      "Epoch 558: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.2801 - bpp: 1.1824 - mse: 1.2803e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4884 - bpp: 1.1812 - mse: 1.4082e-04\n",
      "Epoch 559: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4884 - bpp: 1.1812 - mse: 1.4082e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7537 - bpp: 1.1985 - mse: 1.5596e-04\n",
      "Epoch 560: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7537 - bpp: 1.1985 - mse: 1.5596e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7012 - bpp: 1.1879 - mse: 1.5340e-04\n",
      "Epoch 561: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.7012 - bpp: 1.1879 - mse: 1.5340e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6113 - bpp: 1.2018 - mse: 1.4707e-04\n",
      "Epoch 562: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.6113 - bpp: 1.2018 - mse: 1.4707e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6008 - bpp: 1.2066 - mse: 1.4613e-04\n",
      "Epoch 563: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6008 - bpp: 1.2066 - mse: 1.4613e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7269 - bpp: 1.2066 - mse: 1.5382e-04\n",
      "Epoch 564: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.7269 - bpp: 1.2066 - mse: 1.5382e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5306 - bpp: 1.1810 - mse: 1.4341e-04\n",
      "Epoch 565: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.5306 - bpp: 1.1810 - mse: 1.4341e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3713 - bpp: 1.2102 - mse: 1.9294e-04\n",
      "Epoch 566: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.3713 - bpp: 1.2102 - mse: 1.9294e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6963 - bpp: 1.2145 - mse: 1.5147e-04\n",
      "Epoch 567: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6963 - bpp: 1.2145 - mse: 1.5147e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2981 - bpp: 1.1771 - mse: 1.2946e-04\n",
      "Epoch 568: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.2981 - bpp: 1.1771 - mse: 1.2946e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6134 - bpp: 1.2017 - mse: 1.4720e-04\n",
      "Epoch 569: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6134 - bpp: 1.2017 - mse: 1.4720e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9052 - bpp: 1.2197 - mse: 1.6391e-04\n",
      "Epoch 570: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.9052 - bpp: 1.2197 - mse: 1.6391e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1485 - bpp: 1.1704 - mse: 1.2073e-04\n",
      "Epoch 571: loss improved from 3.15324 to 3.14846, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.1485 - bpp: 1.1704 - mse: 1.2073e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3908 - bpp: 1.1838 - mse: 1.3471e-04\n",
      "Epoch 572: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3908 - bpp: 1.1838 - mse: 1.3471e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8286 - bpp: 1.1940 - mse: 1.6080e-04\n",
      "Epoch 573: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.8286 - bpp: 1.1940 - mse: 1.6080e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8898 - bpp: 1.2331 - mse: 1.6215e-04\n",
      "Epoch 574: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.8898 - bpp: 1.2331 - mse: 1.6215e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3498 - bpp: 1.1999 - mse: 1.9226e-04\n",
      "Epoch 575: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.3498 - bpp: 1.1999 - mse: 1.9226e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1490 - bpp: 1.1677 - mse: 1.2093e-04\n",
      "Epoch 576: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.1490 - bpp: 1.1677 - mse: 1.2093e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2850 - bpp: 1.1614 - mse: 1.2962e-04\n",
      "Epoch 577: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2850 - bpp: 1.1614 - mse: 1.2962e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5949 - bpp: 1.2170 - mse: 1.4514e-04\n",
      "Epoch 578: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5949 - bpp: 1.2170 - mse: 1.4514e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5586 - bpp: 1.1876 - mse: 1.4471e-04\n",
      "Epoch 579: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.5586 - bpp: 1.1876 - mse: 1.4471e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6840 - bpp: 1.2265 - mse: 1.4999e-04\n",
      "Epoch 580: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6840 - bpp: 1.2265 - mse: 1.4999e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9407 - bpp: 1.1639 - mse: 1.0845e-04\n",
      "Epoch 581: loss improved from 3.14846 to 2.94070, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9407 - bpp: 1.1639 - mse: 1.0845e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0006 - bpp: 1.1503 - mse: 1.1294e-04\n",
      "Epoch 582: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.0006 - bpp: 1.1503 - mse: 1.1294e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1211 - bpp: 1.1661 - mse: 1.1932e-04\n",
      "Epoch 583: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1211 - bpp: 1.1661 - mse: 1.1932e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4167 - bpp: 1.2095 - mse: 1.3472e-04\n",
      "Epoch 584: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.4167 - bpp: 1.2095 - mse: 1.3472e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2801 - bpp: 1.1744 - mse: 1.2852e-04\n",
      "Epoch 585: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.2801 - bpp: 1.1744 - mse: 1.2852e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3443 - bpp: 1.1775 - mse: 1.3225e-04\n",
      "Epoch 586: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3443 - bpp: 1.1775 - mse: 1.3225e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9986 - bpp: 1.2187 - mse: 1.6967e-04\n",
      "Epoch 587: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.9986 - bpp: 1.2187 - mse: 1.6967e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7386 - bpp: 1.2006 - mse: 1.5491e-04\n",
      "Epoch 588: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.7386 - bpp: 1.2006 - mse: 1.5491e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7106 - bpp: 1.1858 - mse: 1.5410e-04\n",
      "Epoch 589: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 234ms/step - loss: 3.7106 - bpp: 1.1858 - mse: 1.5410e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3819 - bpp: 1.2091 - mse: 1.3262e-04\n",
      "Epoch 590: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.3819 - bpp: 1.2091 - mse: 1.3262e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8905 - bpp: 1.2287 - mse: 1.6247e-04\n",
      "Epoch 591: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.8905 - bpp: 1.2287 - mse: 1.6247e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9720 - bpp: 1.1951 - mse: 1.6949e-04\n",
      "Epoch 592: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.9720 - bpp: 1.1951 - mse: 1.6949e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1775 - bpp: 1.1944 - mse: 1.8207e-04\n",
      "Epoch 593: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.1775 - bpp: 1.1944 - mse: 1.8207e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4386 - bpp: 1.1992 - mse: 1.3668e-04\n",
      "Epoch 594: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.4386 - bpp: 1.1992 - mse: 1.3668e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8266 - bpp: 1.1983 - mse: 1.6042e-04\n",
      "Epoch 595: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.8266 - bpp: 1.1983 - mse: 1.6042e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6637 - bpp: 1.1875 - mse: 1.5113e-04\n",
      "Epoch 596: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.6637 - bpp: 1.1875 - mse: 1.5113e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7383 - bpp: 1.1804 - mse: 1.5612e-04\n",
      "Epoch 597: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.7383 - bpp: 1.1804 - mse: 1.5612e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3425 - bpp: 1.1647 - mse: 1.3292e-04\n",
      "Epoch 598: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.3425 - bpp: 1.1647 - mse: 1.3292e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7245 - bpp: 1.2047 - mse: 1.5379e-04\n",
      "Epoch 599: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.7245 - bpp: 1.2047 - mse: 1.5379e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3627 - bpp: 1.1767 - mse: 1.3342e-04\n",
      "Epoch 600: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.3627 - bpp: 1.1767 - mse: 1.3342e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2335 - bpp: 1.1633 - mse: 1.2636e-04\n",
      "Epoch 601: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.2335 - bpp: 1.1633 - mse: 1.2636e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8914 - bpp: 1.2056 - mse: 1.6393e-04\n",
      "Epoch 602: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.8914 - bpp: 1.2056 - mse: 1.6393e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5778 - bpp: 1.1980 - mse: 1.4525e-04\n",
      "Epoch 603: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.5778 - bpp: 1.1980 - mse: 1.4525e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0348 - bpp: 1.1996 - mse: 1.7305e-04\n",
      "Epoch 604: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.0348 - bpp: 1.1996 - mse: 1.7305e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3615 - bpp: 1.1682 - mse: 1.3387e-04\n",
      "Epoch 605: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3615 - bpp: 1.1682 - mse: 1.3387e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2424 - bpp: 1.1613 - mse: 1.2702e-04\n",
      "Epoch 606: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.2424 - bpp: 1.1613 - mse: 1.2702e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6449 - bpp: 1.2018 - mse: 1.4912e-04\n",
      "Epoch 607: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6449 - bpp: 1.2018 - mse: 1.4912e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8773 - bpp: 1.2146 - mse: 1.6251e-04\n",
      "Epoch 608: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.8773 - bpp: 1.2146 - mse: 1.6251e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5834 - bpp: 1.1981 - mse: 1.4559e-04\n",
      "Epoch 609: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5834 - bpp: 1.1981 - mse: 1.4559e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4810 - bpp: 1.1949 - mse: 1.3953e-04\n",
      "Epoch 610: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.4810 - bpp: 1.1949 - mse: 1.3953e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4241 - bpp: 1.2008 - mse: 1.3570e-04\n",
      "Epoch 611: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.4241 - bpp: 1.2008 - mse: 1.3570e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5022 - bpp: 1.1843 - mse: 1.4148e-04\n",
      "Epoch 612: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.5022 - bpp: 1.1843 - mse: 1.4148e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9421 - bpp: 1.1770 - mse: 1.6877e-04\n",
      "Epoch 613: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.9421 - bpp: 1.1770 - mse: 1.6877e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3529 - bpp: 1.1822 - mse: 1.3249e-04\n",
      "Epoch 614: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3529 - bpp: 1.1822 - mse: 1.3249e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6441 - bpp: 1.1853 - mse: 1.5007e-04\n",
      "Epoch 615: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6441 - bpp: 1.1853 - mse: 1.5007e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1485 - bpp: 1.1406 - mse: 1.2255e-04\n",
      "Epoch 616: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1485 - bpp: 1.1406 - mse: 1.2255e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4354 - bpp: 1.1798 - mse: 1.3767e-04\n",
      "Epoch 617: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4354 - bpp: 1.1798 - mse: 1.3767e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3130 - bpp: 1.1728 - mse: 1.3063e-04\n",
      "Epoch 618: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3.3130 - bpp: 1.1728 - mse: 1.3063e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6503 - bpp: 1.1869 - mse: 1.5036e-04\n",
      "Epoch 619: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6503 - bpp: 1.1869 - mse: 1.5036e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5203 - bpp: 1.2003 - mse: 1.4160e-04\n",
      "Epoch 620: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5203 - bpp: 1.2003 - mse: 1.4160e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8519 - bpp: 1.2137 - mse: 1.6102e-04\n",
      "Epoch 621: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.8519 - bpp: 1.2137 - mse: 1.6102e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4872 - bpp: 1.1740 - mse: 1.4119e-04\n",
      "Epoch 622: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.4872 - bpp: 1.1740 - mse: 1.4119e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1091 - bpp: 1.1541 - mse: 1.1932e-04\n",
      "Epoch 623: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1091 - bpp: 1.1541 - mse: 1.1932e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2489 - bpp: 1.1709 - mse: 1.2683e-04\n",
      "Epoch 624: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2489 - bpp: 1.1709 - mse: 1.2683e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9458 - bpp: 1.2019 - mse: 1.6748e-04\n",
      "Epoch 625: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9458 - bpp: 1.2019 - mse: 1.6748e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0789 - bpp: 1.1401 - mse: 1.1834e-04\n",
      "Epoch 626: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0789 - bpp: 1.1401 - mse: 1.1834e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8376 - bpp: 1.2051 - mse: 1.6068e-04\n",
      "Epoch 627: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.8376 - bpp: 1.2051 - mse: 1.6068e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7753 - bpp: 1.2103 - mse: 1.5655e-04\n",
      "Epoch 628: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7753 - bpp: 1.2103 - mse: 1.5655e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1436 - bpp: 1.1491 - mse: 1.2174e-04\n",
      "Epoch 629: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.1436 - bpp: 1.1491 - mse: 1.2174e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7667 - bpp: 1.1818 - mse: 1.5777e-04\n",
      "Epoch 630: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.7667 - bpp: 1.1818 - mse: 1.5777e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9040 - bpp: 1.1384 - mse: 1.0776e-04\n",
      "Epoch 631: loss improved from 2.94070 to 2.90399, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9040 - bpp: 1.1384 - mse: 1.0776e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0621 - bpp: 1.1460 - mse: 1.1695e-04\n",
      "Epoch 632: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.0621 - bpp: 1.1460 - mse: 1.1695e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3461 - bpp: 1.1746 - mse: 1.3253e-04\n",
      "Epoch 633: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.3461 - bpp: 1.1746 - mse: 1.3253e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7881 - bpp: 1.1987 - mse: 1.5804e-04\n",
      "Epoch 634: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7881 - bpp: 1.1987 - mse: 1.5804e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4186 - bpp: 1.1913 - mse: 1.3594e-04\n",
      "Epoch 635: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.4186 - bpp: 1.1913 - mse: 1.3594e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3452 - bpp: 1.1758 - mse: 1.3241e-04\n",
      "Epoch 636: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.3452 - bpp: 1.1758 - mse: 1.3241e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2390 - bpp: 1.1506 - mse: 1.2747e-04\n",
      "Epoch 637: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.2390 - bpp: 1.1506 - mse: 1.2747e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3393 - bpp: 1.1783 - mse: 1.3190e-04\n",
      "Epoch 638: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.3393 - bpp: 1.1783 - mse: 1.3190e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4675 - bpp: 1.1658 - mse: 1.4049e-04\n",
      "Epoch 639: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4675 - bpp: 1.1658 - mse: 1.4049e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6208 - bpp: 1.2021 - mse: 1.4763e-04\n",
      "Epoch 640: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.6208 - bpp: 1.2021 - mse: 1.4763e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3804 - bpp: 1.1822 - mse: 1.9520e-04\n",
      "Epoch 641: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.3804 - bpp: 1.1822 - mse: 1.9520e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4874 - bpp: 1.1739 - mse: 1.4120e-04\n",
      "Epoch 642: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.4874 - bpp: 1.1739 - mse: 1.4120e-04\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0801 - bpp: 1.1522 - mse: 1.1767e-04\n",
      "Epoch 643: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.0801 - bpp: 1.1522 - mse: 1.1767e-04\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1770 - bpp: 1.1585 - mse: 1.2320e-04\n",
      "Epoch 644: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.1770 - bpp: 1.1585 - mse: 1.2320e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6446 - bpp: 1.1676 - mse: 1.5119e-04\n",
      "Epoch 645: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.6446 - bpp: 1.1676 - mse: 1.5119e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4827 - bpp: 1.1995 - mse: 1.3936e-04\n",
      "Epoch 646: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.4827 - bpp: 1.1995 - mse: 1.3936e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4625 - bpp: 1.1727 - mse: 1.3976e-04\n",
      "Epoch 647: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4625 - bpp: 1.1727 - mse: 1.3976e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3355 - bpp: 1.1744 - mse: 1.3190e-04\n",
      "Epoch 648: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3355 - bpp: 1.1744 - mse: 1.3190e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1858 - bpp: 1.1564 - mse: 1.2387e-04\n",
      "Epoch 649: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.1858 - bpp: 1.1564 - mse: 1.2387e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4132 - bpp: 1.2115 - mse: 1.9542e-04\n",
      "Epoch 650: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 4.4132 - bpp: 1.2115 - mse: 1.9542e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9818 - bpp: 1.2083 - mse: 1.6928e-04\n",
      "Epoch 651: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.9818 - bpp: 1.2083 - mse: 1.6928e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6966 - bpp: 1.1983 - mse: 1.5248e-04\n",
      "Epoch 652: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.6966 - bpp: 1.1983 - mse: 1.5248e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6421 - bpp: 1.1928 - mse: 1.4950e-04\n",
      "Epoch 653: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.6421 - bpp: 1.1928 - mse: 1.4950e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5632 - bpp: 1.2075 - mse: 1.4378e-04\n",
      "Epoch 654: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.5632 - bpp: 1.2075 - mse: 1.4378e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2218 - bpp: 1.1595 - mse: 1.2587e-04\n",
      "Epoch 655: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2218 - bpp: 1.1595 - mse: 1.2587e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3107 - bpp: 1.1840 - mse: 1.2980e-04\n",
      "Epoch 656: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3107 - bpp: 1.1840 - mse: 1.2980e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2422 - bpp: 1.1575 - mse: 1.2724e-04\n",
      "Epoch 657: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.2422 - bpp: 1.1575 - mse: 1.2724e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0392 - bpp: 1.1494 - mse: 1.1535e-04\n",
      "Epoch 658: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.0392 - bpp: 1.1494 - mse: 1.1535e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1552 - bpp: 1.1496 - mse: 1.2241e-04\n",
      "Epoch 659: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.1552 - bpp: 1.1496 - mse: 1.2241e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2692 - bpp: 1.1698 - mse: 1.2814e-04\n",
      "Epoch 660: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2692 - bpp: 1.1698 - mse: 1.2814e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4150 - bpp: 1.1878 - mse: 1.3593e-04\n",
      "Epoch 661: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.4150 - bpp: 1.1878 - mse: 1.3593e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3176 - bpp: 1.1900 - mse: 1.2986e-04\n",
      "Epoch 662: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3176 - bpp: 1.1900 - mse: 1.2986e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3438 - bpp: 1.1778 - mse: 1.3220e-04\n",
      "Epoch 663: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.3438 - bpp: 1.1778 - mse: 1.3220e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2699 - bpp: 1.1693 - mse: 1.2821e-04\n",
      "Epoch 664: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.2699 - bpp: 1.1693 - mse: 1.2821e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7279 - bpp: 1.2049 - mse: 1.5399e-04\n",
      "Epoch 665: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7279 - bpp: 1.2049 - mse: 1.5399e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4107 - bpp: 1.1838 - mse: 1.3592e-04\n",
      "Epoch 666: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4107 - bpp: 1.1838 - mse: 1.3592e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5820 - bpp: 1.1739 - mse: 1.4698e-04\n",
      "Epoch 667: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 3.5820 - bpp: 1.1739 - mse: 1.4698e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6609 - bpp: 1.2024 - mse: 1.5006e-04\n",
      "Epoch 668: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.6609 - bpp: 1.2024 - mse: 1.5006e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3265 - bpp: 1.1590 - mse: 1.3229e-04\n",
      "Epoch 669: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.3265 - bpp: 1.1590 - mse: 1.3229e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3828 - bpp: 1.1792 - mse: 1.3449e-04\n",
      "Epoch 670: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3828 - bpp: 1.1792 - mse: 1.3449e-04\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2269 - bpp: 1.1558 - mse: 1.2641e-04\n",
      "Epoch 671: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.2269 - bpp: 1.1558 - mse: 1.2641e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3177 - bpp: 1.1557 - mse: 1.3196e-04\n",
      "Epoch 672: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3177 - bpp: 1.1557 - mse: 1.3196e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2980 - bpp: 1.1549 - mse: 1.3081e-04\n",
      "Epoch 673: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.2980 - bpp: 1.1549 - mse: 1.3081e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3075 - bpp: 1.1873 - mse: 1.2941e-04\n",
      "Epoch 674: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.3075 - bpp: 1.1873 - mse: 1.2941e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5112 - bpp: 1.1877 - mse: 1.4182e-04\n",
      "Epoch 675: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.5112 - bpp: 1.1877 - mse: 1.4182e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0118 - bpp: 1.1701 - mse: 1.1241e-04\n",
      "Epoch 676: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0118 - bpp: 1.1701 - mse: 1.1241e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3127 - bpp: 1.1543 - mse: 1.3174e-04\n",
      "Epoch 677: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3127 - bpp: 1.1543 - mse: 1.3174e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3345 - bpp: 1.1865 - mse: 1.3110e-04\n",
      "Epoch 678: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.3345 - bpp: 1.1865 - mse: 1.3110e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3931 - bpp: 1.1688 - mse: 1.3576e-04\n",
      "Epoch 679: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.3931 - bpp: 1.1688 - mse: 1.3576e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4547 - bpp: 1.1781 - mse: 1.3895e-04\n",
      "Epoch 680: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4547 - bpp: 1.1781 - mse: 1.3895e-04\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4301 - bpp: 1.1570 - mse: 1.3874e-04\n",
      "Epoch 681: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.4301 - bpp: 1.1570 - mse: 1.3874e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0069 - bpp: 1.2107 - mse: 1.7067e-04\n",
      "Epoch 682: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.0069 - bpp: 1.2107 - mse: 1.7067e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0726 - bpp: 1.1425 - mse: 1.1780e-04\n",
      "Epoch 683: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0726 - bpp: 1.1425 - mse: 1.1780e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4655 - bpp: 1.1766 - mse: 1.3971e-04\n",
      "Epoch 684: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.4655 - bpp: 1.1766 - mse: 1.3971e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3519 - bpp: 1.1776 - mse: 1.3271e-04\n",
      "Epoch 685: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.3519 - bpp: 1.1776 - mse: 1.3271e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1417 - bpp: 1.1624 - mse: 1.2081e-04\n",
      "Epoch 686: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.1417 - bpp: 1.1624 - mse: 1.2081e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0055 - bpp: 1.1383 - mse: 1.1396e-04\n",
      "Epoch 687: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0055 - bpp: 1.1383 - mse: 1.1396e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1467 - bpp: 1.1329 - mse: 1.2291e-04\n",
      "Epoch 688: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1467 - bpp: 1.1329 - mse: 1.2291e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3641 - bpp: 1.1776 - mse: 1.3345e-04\n",
      "Epoch 689: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.3641 - bpp: 1.1776 - mse: 1.3345e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5125 - bpp: 1.1637 - mse: 1.4336e-04\n",
      "Epoch 690: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.5125 - bpp: 1.1637 - mse: 1.4336e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2832 - bpp: 1.1655 - mse: 1.2925e-04\n",
      "Epoch 691: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.2832 - bpp: 1.1655 - mse: 1.2925e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3771 - bpp: 1.1549 - mse: 1.3564e-04\n",
      "Epoch 692: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.3771 - bpp: 1.1549 - mse: 1.3564e-04\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2361 - bpp: 1.1417 - mse: 1.2783e-04\n",
      "Epoch 693: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2361 - bpp: 1.1417 - mse: 1.2783e-04\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5756 - bpp: 1.1829 - mse: 1.4604e-04\n",
      "Epoch 694: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.5756 - bpp: 1.1829 - mse: 1.4604e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5709 - bpp: 1.1744 - mse: 1.4627e-04\n",
      "Epoch 695: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5709 - bpp: 1.1744 - mse: 1.4627e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5135 - bpp: 1.1885 - mse: 1.4191e-04\n",
      "Epoch 696: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5135 - bpp: 1.1885 - mse: 1.4191e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1428 - bpp: 1.1553 - mse: 1.2131e-04\n",
      "Epoch 697: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.1428 - bpp: 1.1553 - mse: 1.2131e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3410 - bpp: 1.1735 - mse: 1.3229e-04\n",
      "Epoch 698: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3410 - bpp: 1.1735 - mse: 1.3229e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4040 - bpp: 1.1526 - mse: 1.3742e-04\n",
      "Epoch 699: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.4040 - bpp: 1.1526 - mse: 1.3742e-04\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3479 - bpp: 1.1761 - mse: 1.3255e-04\n",
      "Epoch 700: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3479 - bpp: 1.1761 - mse: 1.3255e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2763 - bpp: 1.1516 - mse: 1.2969e-04\n",
      "Epoch 701: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2763 - bpp: 1.1516 - mse: 1.2969e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3890 - bpp: 1.1675 - mse: 1.3559e-04\n",
      "Epoch 702: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3890 - bpp: 1.1675 - mse: 1.3559e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2786 - bpp: 1.1695 - mse: 1.2872e-04\n",
      "Epoch 703: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.2786 - bpp: 1.1695 - mse: 1.2872e-04\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2001 - bpp: 1.1645 - mse: 1.2425e-04\n",
      "Epoch 704: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 243ms/step - loss: 3.2001 - bpp: 1.1645 - mse: 1.2425e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2548 - bpp: 1.1715 - mse: 1.2715e-04\n",
      "Epoch 705: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.2548 - bpp: 1.1715 - mse: 1.2715e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3522 - bpp: 1.1765 - mse: 1.3279e-04\n",
      "Epoch 706: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.3522 - bpp: 1.1765 - mse: 1.3279e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3218 - bpp: 1.1678 - mse: 1.3147e-04\n",
      "Epoch 707: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.3218 - bpp: 1.1678 - mse: 1.3147e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4951 - bpp: 1.1581 - mse: 1.4264e-04\n",
      "Epoch 708: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.4951 - bpp: 1.1581 - mse: 1.4264e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3957 - bpp: 1.1703 - mse: 1.3582e-04\n",
      "Epoch 709: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.3957 - bpp: 1.1703 - mse: 1.3582e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3088 - bpp: 1.1714 - mse: 1.3046e-04\n",
      "Epoch 710: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3088 - bpp: 1.1714 - mse: 1.3046e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8041 - bpp: 1.1521 - mse: 1.6186e-04\n",
      "Epoch 711: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.8041 - bpp: 1.1521 - mse: 1.6186e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1698 - bpp: 1.1577 - mse: 1.2281e-04\n",
      "Epoch 712: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1698 - bpp: 1.1577 - mse: 1.2281e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0428 - bpp: 1.1232 - mse: 1.1717e-04\n",
      "Epoch 713: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0428 - bpp: 1.1232 - mse: 1.1717e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3472 - bpp: 1.1924 - mse: 1.3152e-04\n",
      "Epoch 714: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3472 - bpp: 1.1924 - mse: 1.3152e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1614 - bpp: 1.1285 - mse: 1.2408e-04\n",
      "Epoch 715: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.1614 - bpp: 1.1285 - mse: 1.2408e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1755 - bpp: 1.1488 - mse: 1.2370e-04\n",
      "Epoch 716: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.1755 - bpp: 1.1488 - mse: 1.2370e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8025 - bpp: 1.1336 - mse: 1.0186e-04\n",
      "Epoch 717: loss improved from 2.90399 to 2.80251, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.8025 - bpp: 1.1336 - mse: 1.0186e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3264 - bpp: 1.1709 - mse: 1.3156e-04\n",
      "Epoch 718: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3264 - bpp: 1.1709 - mse: 1.3156e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3709 - bpp: 1.1714 - mse: 1.3425e-04\n",
      "Epoch 719: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3709 - bpp: 1.1714 - mse: 1.3425e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5359 - bpp: 1.1993 - mse: 1.4261e-04\n",
      "Epoch 720: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5359 - bpp: 1.1993 - mse: 1.4261e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2543 - bpp: 1.1545 - mse: 1.2817e-04\n",
      "Epoch 721: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2543 - bpp: 1.1545 - mse: 1.2817e-04\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9124 - bpp: 1.1294 - mse: 1.0882e-04\n",
      "Epoch 722: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9124 - bpp: 1.1294 - mse: 1.0882e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4108 - bpp: 1.1707 - mse: 1.3672e-04\n",
      "Epoch 723: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.4108 - bpp: 1.1707 - mse: 1.3672e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1332 - bpp: 1.1369 - mse: 1.2184e-04\n",
      "Epoch 724: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1332 - bpp: 1.1369 - mse: 1.2184e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2840 - bpp: 1.1512 - mse: 1.3018e-04\n",
      "Epoch 725: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.2840 - bpp: 1.1512 - mse: 1.3018e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0665 - bpp: 1.1348 - mse: 1.1790e-04\n",
      "Epoch 726: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0665 - bpp: 1.1348 - mse: 1.1790e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4323 - bpp: 1.1678 - mse: 1.3821e-04\n",
      "Epoch 727: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4323 - bpp: 1.1678 - mse: 1.3821e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1255 - bpp: 1.1395 - mse: 1.2122e-04\n",
      "Epoch 728: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1255 - bpp: 1.1395 - mse: 1.2122e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5386 - bpp: 1.1537 - mse: 1.4556e-04\n",
      "Epoch 729: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.5386 - bpp: 1.1537 - mse: 1.4556e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2062 - bpp: 1.1601 - mse: 1.2488e-04\n",
      "Epoch 730: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2062 - bpp: 1.1601 - mse: 1.2488e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2391 - bpp: 1.1463 - mse: 1.2774e-04\n",
      "Epoch 731: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2391 - bpp: 1.1463 - mse: 1.2774e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8994 - bpp: 1.1306 - mse: 1.0796e-04\n",
      "Epoch 732: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8994 - bpp: 1.1306 - mse: 1.0796e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4550 - bpp: 1.1845 - mse: 1.3858e-04\n",
      "Epoch 733: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.4550 - bpp: 1.1845 - mse: 1.3858e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2954 - bpp: 1.1673 - mse: 1.2989e-04\n",
      "Epoch 734: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2954 - bpp: 1.1673 - mse: 1.2989e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1940 - bpp: 1.1454 - mse: 1.2504e-04\n",
      "Epoch 735: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1940 - bpp: 1.1454 - mse: 1.2504e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3683 - bpp: 1.1647 - mse: 1.3450e-04\n",
      "Epoch 736: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3683 - bpp: 1.1647 - mse: 1.3450e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4314 - bpp: 1.1550 - mse: 1.3894e-04\n",
      "Epoch 737: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4314 - bpp: 1.1550 - mse: 1.3894e-04\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6426 - bpp: 1.1935 - mse: 1.4948e-04\n",
      "Epoch 738: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.6426 - bpp: 1.1935 - mse: 1.4948e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0736 - bpp: 1.1430 - mse: 1.1783e-04\n",
      "Epoch 739: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.0736 - bpp: 1.1430 - mse: 1.1783e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0538 - bpp: 1.1363 - mse: 1.1704e-04\n",
      "Epoch 740: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.0538 - bpp: 1.1363 - mse: 1.1704e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9608 - bpp: 1.1497 - mse: 1.1054e-04\n",
      "Epoch 741: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9608 - bpp: 1.1497 - mse: 1.1054e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4636 - bpp: 1.1464 - mse: 1.4144e-04\n",
      "Epoch 742: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4636 - bpp: 1.1464 - mse: 1.4144e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5061 - bpp: 1.1478 - mse: 1.4394e-04\n",
      "Epoch 743: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.5061 - bpp: 1.1478 - mse: 1.4394e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3482 - bpp: 1.1535 - mse: 1.3395e-04\n",
      "Epoch 744: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.3482 - bpp: 1.1535 - mse: 1.3395e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5808 - bpp: 1.1626 - mse: 1.4760e-04\n",
      "Epoch 745: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.5808 - bpp: 1.1626 - mse: 1.4760e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3962 - bpp: 1.1495 - mse: 1.3713e-04\n",
      "Epoch 746: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3962 - bpp: 1.1495 - mse: 1.3713e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0740 - bpp: 1.1527 - mse: 1.1727e-04\n",
      "Epoch 747: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0740 - bpp: 1.1527 - mse: 1.1727e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1558 - bpp: 1.1511 - mse: 1.2236e-04\n",
      "Epoch 748: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1558 - bpp: 1.1511 - mse: 1.2236e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2976 - bpp: 1.1643 - mse: 1.3021e-04\n",
      "Epoch 749: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2976 - bpp: 1.1643 - mse: 1.3021e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2699 - bpp: 1.1588 - mse: 1.2886e-04\n",
      "Epoch 750: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2699 - bpp: 1.1588 - mse: 1.2886e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3329 - bpp: 1.1472 - mse: 1.3340e-04\n",
      "Epoch 751: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3329 - bpp: 1.1472 - mse: 1.3340e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1337 - bpp: 1.1567 - mse: 1.2067e-04\n",
      "Epoch 752: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1337 - bpp: 1.1567 - mse: 1.2067e-04\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1398 - bpp: 1.1270 - mse: 1.2285e-04\n",
      "Epoch 753: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1398 - bpp: 1.1270 - mse: 1.2285e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1450 - bpp: 1.1354 - mse: 1.2266e-04\n",
      "Epoch 754: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1450 - bpp: 1.1354 - mse: 1.2266e-04\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3236 - bpp: 1.1763 - mse: 1.3106e-04\n",
      "Epoch 755: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3236 - bpp: 1.1763 - mse: 1.3106e-04\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1770 - bpp: 1.1754 - mse: 1.2217e-04\n",
      "Epoch 756: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1770 - bpp: 1.1754 - mse: 1.2217e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4219 - bpp: 1.1894 - mse: 1.3626e-04\n",
      "Epoch 757: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.4219 - bpp: 1.1894 - mse: 1.3626e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0675 - bpp: 1.1485 - mse: 1.1713e-04\n",
      "Epoch 758: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0675 - bpp: 1.1485 - mse: 1.1713e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5298 - bpp: 1.1780 - mse: 1.4355e-04\n",
      "Epoch 759: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5298 - bpp: 1.1780 - mse: 1.4355e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5151 - bpp: 1.1449 - mse: 1.4467e-04\n",
      "Epoch 760: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5151 - bpp: 1.1449 - mse: 1.4467e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3590 - bpp: 1.1586 - mse: 1.3430e-04\n",
      "Epoch 761: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3590 - bpp: 1.1586 - mse: 1.3430e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1580 - bpp: 1.1285 - mse: 1.2387e-04\n",
      "Epoch 762: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1580 - bpp: 1.1285 - mse: 1.2387e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1312 - bpp: 1.1422 - mse: 1.2140e-04\n",
      "Epoch 763: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1312 - bpp: 1.1422 - mse: 1.2140e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4697 - bpp: 1.1703 - mse: 1.4034e-04\n",
      "Epoch 764: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4697 - bpp: 1.1703 - mse: 1.4034e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2565 - bpp: 1.1427 - mse: 1.2902e-04\n",
      "Epoch 765: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2565 - bpp: 1.1427 - mse: 1.2902e-04\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7993 - bpp: 1.1941 - mse: 1.5901e-04\n",
      "Epoch 766: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.7993 - bpp: 1.1941 - mse: 1.5901e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4892 - bpp: 1.1663 - mse: 1.4178e-04\n",
      "Epoch 767: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.4892 - bpp: 1.1663 - mse: 1.4178e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2506 - bpp: 1.1345 - mse: 1.2916e-04\n",
      "Epoch 768: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2506 - bpp: 1.1345 - mse: 1.2916e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7067 - bpp: 1.1034 - mse: 9.7854e-05\n",
      "Epoch 769: loss improved from 2.80251 to 2.70666, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7067 - bpp: 1.1034 - mse: 9.7854e-05\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0144 - bpp: 1.1275 - mse: 1.1517e-04\n",
      "Epoch 770: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0144 - bpp: 1.1275 - mse: 1.1517e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0526 - bpp: 1.1303 - mse: 1.1733e-04\n",
      "Epoch 771: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0526 - bpp: 1.1303 - mse: 1.1733e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2361 - bpp: 1.1487 - mse: 1.2741e-04\n",
      "Epoch 772: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2361 - bpp: 1.1487 - mse: 1.2741e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3337 - bpp: 1.1610 - mse: 1.3261e-04\n",
      "Epoch 773: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3337 - bpp: 1.1610 - mse: 1.3261e-04\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1062 - bpp: 1.1500 - mse: 1.1939e-04\n",
      "Epoch 774: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1062 - bpp: 1.1500 - mse: 1.1939e-04\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4511 - bpp: 1.1603 - mse: 1.3982e-04\n",
      "Epoch 775: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.4511 - bpp: 1.1603 - mse: 1.3982e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1847 - bpp: 1.1506 - mse: 1.2415e-04\n",
      "Epoch 776: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1847 - bpp: 1.1506 - mse: 1.2415e-04\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3104 - bpp: 1.1626 - mse: 1.3109e-04\n",
      "Epoch 777: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3104 - bpp: 1.1626 - mse: 1.3109e-04\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2210 - bpp: 1.1481 - mse: 1.2652e-04\n",
      "Epoch 778: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.2210 - bpp: 1.1481 - mse: 1.2652e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3922 - bpp: 1.1655 - mse: 1.3590e-04\n",
      "Epoch 779: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3922 - bpp: 1.1655 - mse: 1.3590e-04\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9076 - bpp: 1.1424 - mse: 1.0774e-04\n",
      "Epoch 780: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9076 - bpp: 1.1424 - mse: 1.0774e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0927 - bpp: 1.1325 - mse: 1.1964e-04\n",
      "Epoch 781: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0927 - bpp: 1.1325 - mse: 1.1964e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4505 - bpp: 1.1805 - mse: 1.3855e-04\n",
      "Epoch 782: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4505 - bpp: 1.1805 - mse: 1.3855e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2085 - bpp: 1.1226 - mse: 1.2731e-04\n",
      "Epoch 783: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2085 - bpp: 1.1226 - mse: 1.2731e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3181 - bpp: 1.1699 - mse: 1.3112e-04\n",
      "Epoch 784: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.3181 - bpp: 1.1699 - mse: 1.3112e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0878 - bpp: 1.1358 - mse: 1.1914e-04\n",
      "Epoch 785: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0878 - bpp: 1.1358 - mse: 1.1914e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3705 - bpp: 1.1635 - mse: 1.3470e-04\n",
      "Epoch 786: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3705 - bpp: 1.1635 - mse: 1.3470e-04\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6872 - bpp: 1.1719 - mse: 1.5352e-04\n",
      "Epoch 787: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6872 - bpp: 1.1719 - mse: 1.5352e-04\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1348 - bpp: 1.1461 - mse: 1.2138e-04\n",
      "Epoch 788: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1348 - bpp: 1.1461 - mse: 1.2138e-04\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7005 - bpp: 1.1556 - mse: 1.5533e-04\n",
      "Epoch 789: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 3.7005 - bpp: 1.1556 - mse: 1.5533e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2267 - bpp: 1.1589 - mse: 1.2621e-04\n",
      "Epoch 790: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2267 - bpp: 1.1589 - mse: 1.2621e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0579 - bpp: 1.1262 - mse: 1.1790e-04\n",
      "Epoch 791: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0579 - bpp: 1.1262 - mse: 1.1790e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5271 - bpp: 1.1713 - mse: 1.4379e-04\n",
      "Epoch 792: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5271 - bpp: 1.1713 - mse: 1.4379e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0185 - bpp: 1.1392 - mse: 1.1471e-04\n",
      "Epoch 793: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0185 - bpp: 1.1392 - mse: 1.1471e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2123 - bpp: 1.1581 - mse: 1.2538e-04\n",
      "Epoch 794: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2123 - bpp: 1.1581 - mse: 1.2538e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1486 - bpp: 1.1488 - mse: 1.2206e-04\n",
      "Epoch 795: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1486 - bpp: 1.1488 - mse: 1.2206e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3458 - bpp: 1.1614 - mse: 1.3333e-04\n",
      "Epoch 796: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3458 - bpp: 1.1614 - mse: 1.3333e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2835 - bpp: 1.1464 - mse: 1.3044e-04\n",
      "Epoch 797: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2835 - bpp: 1.1464 - mse: 1.3044e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4589 - bpp: 1.1575 - mse: 1.4047e-04\n",
      "Epoch 798: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.4589 - bpp: 1.1575 - mse: 1.4047e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2851 - bpp: 1.1412 - mse: 1.3086e-04\n",
      "Epoch 799: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2851 - bpp: 1.1412 - mse: 1.3086e-04\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9337 - bpp: 1.1152 - mse: 1.1099e-04\n",
      "Epoch 800: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9337 - bpp: 1.1152 - mse: 1.1099e-04\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3558 - bpp: 1.1519 - mse: 1.3452e-04\n",
      "Epoch 801: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3558 - bpp: 1.1519 - mse: 1.3452e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6610 - bpp: 1.1753 - mse: 1.5171e-04\n",
      "Epoch 802: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.6610 - bpp: 1.1753 - mse: 1.5171e-04\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1307 - bpp: 1.1625 - mse: 1.2013e-04\n",
      "Epoch 803: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1307 - bpp: 1.1625 - mse: 1.2013e-04\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2456 - bpp: 1.1543 - mse: 1.2764e-04\n",
      "Epoch 804: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2456 - bpp: 1.1543 - mse: 1.2764e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3200 - bpp: 1.1740 - mse: 1.3098e-04\n",
      "Epoch 805: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3200 - bpp: 1.1740 - mse: 1.3098e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2260 - bpp: 1.1468 - mse: 1.2690e-04\n",
      "Epoch 806: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2260 - bpp: 1.1468 - mse: 1.2690e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2111 - bpp: 1.1432 - mse: 1.2621e-04\n",
      "Epoch 807: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.2111 - bpp: 1.1432 - mse: 1.2621e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5826 - bpp: 1.0918 - mse: 9.0990e-05\n",
      "Epoch 808: loss improved from 2.70666 to 2.58260, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.5826 - bpp: 1.0918 - mse: 9.0990e-05\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8151 - bpp: 1.1230 - mse: 1.0328e-04\n",
      "Epoch 809: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8151 - bpp: 1.1230 - mse: 1.0328e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1256 - bpp: 1.1634 - mse: 1.1976e-04\n",
      "Epoch 810: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1256 - bpp: 1.1634 - mse: 1.1976e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7811 - bpp: 1.1821 - mse: 1.5863e-04\n",
      "Epoch 811: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.7811 - bpp: 1.1821 - mse: 1.5863e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3730 - bpp: 1.1612 - mse: 1.3500e-04\n",
      "Epoch 812: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3730 - bpp: 1.1612 - mse: 1.3500e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2907 - bpp: 1.1504 - mse: 1.3063e-04\n",
      "Epoch 813: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.2907 - bpp: 1.1504 - mse: 1.3063e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1492 - bpp: 1.1548 - mse: 1.2173e-04\n",
      "Epoch 814: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1492 - bpp: 1.1548 - mse: 1.2173e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2809 - bpp: 1.1450 - mse: 1.3037e-04\n",
      "Epoch 815: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2809 - bpp: 1.1450 - mse: 1.3037e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9947 - bpp: 1.1324 - mse: 1.1367e-04\n",
      "Epoch 816: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9947 - bpp: 1.1324 - mse: 1.1367e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1713 - bpp: 1.1443 - mse: 1.2372e-04\n",
      "Epoch 817: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1713 - bpp: 1.1443 - mse: 1.2372e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1409 - bpp: 1.1515 - mse: 1.2142e-04\n",
      "Epoch 818: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1409 - bpp: 1.1515 - mse: 1.2142e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2183 - bpp: 1.1551 - mse: 1.2593e-04\n",
      "Epoch 819: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.2183 - bpp: 1.1551 - mse: 1.2593e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3586 - bpp: 1.1612 - mse: 1.3412e-04\n",
      "Epoch 820: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3586 - bpp: 1.1612 - mse: 1.3412e-04\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2388 - bpp: 1.1584 - mse: 1.2698e-04\n",
      "Epoch 821: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2388 - bpp: 1.1584 - mse: 1.2698e-04\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2142 - bpp: 1.1435 - mse: 1.2639e-04\n",
      "Epoch 822: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2142 - bpp: 1.1435 - mse: 1.2639e-04\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6279 - bpp: 1.1978 - mse: 1.4832e-04\n",
      "Epoch 823: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.6279 - bpp: 1.1978 - mse: 1.4832e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3496 - bpp: 1.1466 - mse: 1.3446e-04\n",
      "Epoch 824: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3496 - bpp: 1.1466 - mse: 1.3446e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2250 - bpp: 1.1428 - mse: 1.2709e-04\n",
      "Epoch 825: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2250 - bpp: 1.1428 - mse: 1.2709e-04\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2447 - bpp: 1.1453 - mse: 1.2814e-04\n",
      "Epoch 826: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.2447 - bpp: 1.1453 - mse: 1.2814e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0297 - bpp: 1.1459 - mse: 1.1498e-04\n",
      "Epoch 827: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0297 - bpp: 1.1459 - mse: 1.1498e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1515 - bpp: 1.1557 - mse: 1.2182e-04\n",
      "Epoch 828: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1515 - bpp: 1.1557 - mse: 1.2182e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3002 - bpp: 1.1364 - mse: 1.3207e-04\n",
      "Epoch 829: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3002 - bpp: 1.1364 - mse: 1.3207e-04\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4073 - bpp: 1.1580 - mse: 1.3729e-04\n",
      "Epoch 830: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.4073 - bpp: 1.1580 - mse: 1.3729e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3513 - bpp: 1.1650 - mse: 1.3344e-04\n",
      "Epoch 831: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3513 - bpp: 1.1650 - mse: 1.3344e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0425 - bpp: 1.1378 - mse: 1.1625e-04\n",
      "Epoch 832: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0425 - bpp: 1.1378 - mse: 1.1625e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3272 - bpp: 1.1541 - mse: 1.3264e-04\n",
      "Epoch 833: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3272 - bpp: 1.1541 - mse: 1.3264e-04\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1998 - bpp: 1.1516 - mse: 1.2501e-04\n",
      "Epoch 834: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1998 - bpp: 1.1516 - mse: 1.2501e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4939 - bpp: 1.1857 - mse: 1.4088e-04\n",
      "Epoch 835: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4939 - bpp: 1.1857 - mse: 1.4088e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3605 - bpp: 1.1792 - mse: 1.3314e-04\n",
      "Epoch 836: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3605 - bpp: 1.1792 - mse: 1.3314e-04\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7169 - bpp: 1.1032 - mse: 9.8493e-05\n",
      "Epoch 837: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.7169 - bpp: 1.1032 - mse: 9.8493e-05\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9103 - bpp: 1.1209 - mse: 1.0921e-04\n",
      "Epoch 838: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.9103 - bpp: 1.1209 - mse: 1.0921e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8584 - bpp: 1.1135 - mse: 1.0650e-04\n",
      "Epoch 839: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.8584 - bpp: 1.1135 - mse: 1.0650e-04\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1324 - bpp: 1.1324 - mse: 1.2207e-04\n",
      "Epoch 840: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1324 - bpp: 1.1324 - mse: 1.2207e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6085 - bpp: 1.1530 - mse: 1.4987e-04\n",
      "Epoch 841: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.6085 - bpp: 1.1530 - mse: 1.4987e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1513 - bpp: 1.1368 - mse: 1.2295e-04\n",
      "Epoch 842: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1513 - bpp: 1.1368 - mse: 1.2295e-04\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7827 - bpp: 1.1827 - mse: 1.5869e-04\n",
      "Epoch 843: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.7827 - bpp: 1.1827 - mse: 1.5869e-04\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7670 - bpp: 1.0864 - mse: 1.0258e-04\n",
      "Epoch 844: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7670 - bpp: 1.0864 - mse: 1.0258e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9951 - bpp: 1.1434 - mse: 1.1301e-04\n",
      "Epoch 845: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9951 - bpp: 1.1434 - mse: 1.1301e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2674 - bpp: 1.1352 - mse: 1.3014e-04\n",
      "Epoch 846: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2674 - bpp: 1.1352 - mse: 1.3014e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9228 - bpp: 1.1348 - mse: 1.0913e-04\n",
      "Epoch 847: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9228 - bpp: 1.1348 - mse: 1.0913e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2629 - bpp: 1.1568 - mse: 1.2855e-04\n",
      "Epoch 848: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2629 - bpp: 1.1568 - mse: 1.2855e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0799 - bpp: 1.1243 - mse: 1.1936e-04\n",
      "Epoch 849: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0799 - bpp: 1.1243 - mse: 1.1936e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1447 - bpp: 1.1490 - mse: 1.2181e-04\n",
      "Epoch 850: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1447 - bpp: 1.1490 - mse: 1.2181e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8150 - bpp: 1.1260 - mse: 1.0309e-04\n",
      "Epoch 851: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.8150 - bpp: 1.1260 - mse: 1.0309e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1429 - bpp: 1.1380 - mse: 1.2237e-04\n",
      "Epoch 852: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.1429 - bpp: 1.1380 - mse: 1.2237e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7897 - bpp: 1.1077 - mse: 1.0266e-04\n",
      "Epoch 853: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.7897 - bpp: 1.1077 - mse: 1.0266e-04\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4096 - bpp: 1.1474 - mse: 1.3807e-04\n",
      "Epoch 854: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4096 - bpp: 1.1474 - mse: 1.3807e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8719 - bpp: 1.1268 - mse: 1.0651e-04\n",
      "Epoch 855: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.8719 - bpp: 1.1268 - mse: 1.0651e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0076 - bpp: 1.1404 - mse: 1.1397e-04\n",
      "Epoch 856: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0076 - bpp: 1.1404 - mse: 1.1397e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1409 - bpp: 1.1511 - mse: 1.2145e-04\n",
      "Epoch 857: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1409 - bpp: 1.1511 - mse: 1.2145e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1726 - bpp: 1.1571 - mse: 1.2302e-04\n",
      "Epoch 858: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.1726 - bpp: 1.1571 - mse: 1.2302e-04\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3941 - bpp: 1.1557 - mse: 1.3663e-04\n",
      "Epoch 859: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3941 - bpp: 1.1557 - mse: 1.3663e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1126 - bpp: 1.1220 - mse: 1.2149e-04\n",
      "Epoch 860: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1126 - bpp: 1.1220 - mse: 1.2149e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1239 - bpp: 1.1472 - mse: 1.2065e-04\n",
      "Epoch 861: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1239 - bpp: 1.1472 - mse: 1.2065e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8363 - bpp: 1.1093 - mse: 1.0540e-04\n",
      "Epoch 862: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8363 - bpp: 1.1093 - mse: 1.0540e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9431 - bpp: 1.1340 - mse: 1.1041e-04\n",
      "Epoch 863: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9431 - bpp: 1.1340 - mse: 1.1041e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0590 - bpp: 1.1506 - mse: 1.1648e-04\n",
      "Epoch 864: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0590 - bpp: 1.1506 - mse: 1.1648e-04\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7422 - bpp: 1.1137 - mse: 9.9395e-05\n",
      "Epoch 865: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7422 - bpp: 1.1137 - mse: 9.9395e-05\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1755 - bpp: 1.1435 - mse: 1.2402e-04\n",
      "Epoch 866: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1755 - bpp: 1.1435 - mse: 1.2402e-04\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1321 - bpp: 1.1324 - mse: 1.2205e-04\n",
      "Epoch 867: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1321 - bpp: 1.1324 - mse: 1.2205e-04\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3075 - bpp: 1.1623 - mse: 1.3093e-04\n",
      "Epoch 868: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3075 - bpp: 1.1623 - mse: 1.3093e-04\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0991 - bpp: 1.1017 - mse: 1.2191e-04\n",
      "Epoch 869: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0991 - bpp: 1.1017 - mse: 1.2191e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3511 - bpp: 1.1640 - mse: 1.3349e-04\n",
      "Epoch 870: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3511 - bpp: 1.1640 - mse: 1.3349e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3506 - bpp: 1.1356 - mse: 1.3519e-04\n",
      "Epoch 871: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3506 - bpp: 1.1356 - mse: 1.3519e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6118 - bpp: 1.1539 - mse: 1.5002e-04\n",
      "Epoch 872: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6118 - bpp: 1.1539 - mse: 1.5002e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1511 - bpp: 1.1288 - mse: 1.2344e-04\n",
      "Epoch 873: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1511 - bpp: 1.1288 - mse: 1.2344e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6175 - bpp: 1.1822 - mse: 1.4864e-04\n",
      "Epoch 874: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 3.6175 - bpp: 1.1822 - mse: 1.4864e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3390 - bpp: 1.1840 - mse: 1.3153e-04\n",
      "Epoch 875: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3390 - bpp: 1.1840 - mse: 1.3153e-04\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8857 - bpp: 1.1181 - mse: 1.0789e-04\n",
      "Epoch 876: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.8857 - bpp: 1.1181 - mse: 1.0789e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3759 - bpp: 1.1612 - mse: 1.3517e-04\n",
      "Epoch 877: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3759 - bpp: 1.1612 - mse: 1.3517e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6134 - bpp: 1.1906 - mse: 1.4788e-04\n",
      "Epoch 878: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.6134 - bpp: 1.1906 - mse: 1.4788e-04\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0345 - bpp: 1.1385 - mse: 1.1572e-04\n",
      "Epoch 879: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0345 - bpp: 1.1385 - mse: 1.1572e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2075 - bpp: 1.1303 - mse: 1.2678e-04\n",
      "Epoch 880: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2075 - bpp: 1.1303 - mse: 1.2678e-04\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2599 - bpp: 1.1470 - mse: 1.2896e-04\n",
      "Epoch 881: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2599 - bpp: 1.1470 - mse: 1.2896e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9571 - bpp: 1.1303 - mse: 1.1150e-04\n",
      "Epoch 882: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9571 - bpp: 1.1303 - mse: 1.1150e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3299 - bpp: 1.1628 - mse: 1.3227e-04\n",
      "Epoch 883: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.3299 - bpp: 1.1628 - mse: 1.3227e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9575 - bpp: 1.1366 - mse: 1.1114e-04\n",
      "Epoch 884: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9575 - bpp: 1.1366 - mse: 1.1114e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0319 - bpp: 1.1445 - mse: 1.1520e-04\n",
      "Epoch 885: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0319 - bpp: 1.1445 - mse: 1.1520e-04\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1338 - bpp: 1.1612 - mse: 1.2040e-04\n",
      "Epoch 886: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1338 - bpp: 1.1612 - mse: 1.2040e-04\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2429 - bpp: 1.1534 - mse: 1.2754e-04\n",
      "Epoch 887: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.2429 - bpp: 1.1534 - mse: 1.2754e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1485 - bpp: 1.1321 - mse: 1.2307e-04\n",
      "Epoch 888: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1485 - bpp: 1.1321 - mse: 1.2307e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0493 - bpp: 1.1368 - mse: 1.1673e-04\n",
      "Epoch 889: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0493 - bpp: 1.1368 - mse: 1.1673e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1468 - bpp: 1.1490 - mse: 1.2194e-04\n",
      "Epoch 890: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1468 - bpp: 1.1490 - mse: 1.2194e-04\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1379 - bpp: 1.1491 - mse: 1.2138e-04\n",
      "Epoch 891: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1379 - bpp: 1.1491 - mse: 1.2138e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0967 - bpp: 1.1420 - mse: 1.1930e-04\n",
      "Epoch 892: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0967 - bpp: 1.1420 - mse: 1.1930e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8800 - bpp: 1.1148 - mse: 1.0774e-04\n",
      "Epoch 893: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.8800 - bpp: 1.1148 - mse: 1.0774e-04\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2338 - bpp: 1.1372 - mse: 1.2797e-04\n",
      "Epoch 894: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2338 - bpp: 1.1372 - mse: 1.2797e-04\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9854 - bpp: 1.1174 - mse: 1.1402e-04\n",
      "Epoch 895: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.9854 - bpp: 1.1174 - mse: 1.1402e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0810 - bpp: 1.1527 - mse: 1.1770e-04\n",
      "Epoch 896: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.0810 - bpp: 1.1527 - mse: 1.1770e-04\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1480 - bpp: 1.1052 - mse: 1.2469e-04\n",
      "Epoch 897: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1480 - bpp: 1.1052 - mse: 1.2469e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0872 - bpp: 1.1277 - mse: 1.1960e-04\n",
      "Epoch 898: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.0872 - bpp: 1.1277 - mse: 1.1960e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2962 - bpp: 1.1319 - mse: 1.3209e-04\n",
      "Epoch 899: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.2962 - bpp: 1.1319 - mse: 1.3209e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9436 - bpp: 1.1246 - mse: 1.1102e-04\n",
      "Epoch 900: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9436 - bpp: 1.1246 - mse: 1.1102e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2530 - bpp: 1.1421 - mse: 1.2884e-04\n",
      "Epoch 901: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2530 - bpp: 1.1421 - mse: 1.2884e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3578 - bpp: 1.1680 - mse: 1.3366e-04\n",
      "Epoch 902: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.3578 - bpp: 1.1680 - mse: 1.3366e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0013 - bpp: 1.1170 - mse: 1.1501e-04\n",
      "Epoch 903: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0013 - bpp: 1.1170 - mse: 1.1501e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9118 - bpp: 1.1326 - mse: 1.0859e-04\n",
      "Epoch 904: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9118 - bpp: 1.1326 - mse: 1.0859e-04\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0352 - bpp: 1.1253 - mse: 1.1657e-04\n",
      "Epoch 905: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0352 - bpp: 1.1253 - mse: 1.1657e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0205 - bpp: 1.1090 - mse: 1.1667e-04\n",
      "Epoch 906: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0205 - bpp: 1.1090 - mse: 1.1667e-04\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3889 - bpp: 1.1755 - mse: 1.3510e-04\n",
      "Epoch 907: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.3889 - bpp: 1.1755 - mse: 1.3510e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1935 - bpp: 1.1317 - mse: 1.2584e-04\n",
      "Epoch 908: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1935 - bpp: 1.1317 - mse: 1.2584e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0151 - bpp: 1.1457 - mse: 1.1410e-04\n",
      "Epoch 909: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0151 - bpp: 1.1457 - mse: 1.1410e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9652 - bpp: 1.1175 - mse: 1.1277e-04\n",
      "Epoch 910: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9652 - bpp: 1.1175 - mse: 1.1277e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8941 - bpp: 1.1255 - mse: 1.0795e-04\n",
      "Epoch 911: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.8941 - bpp: 1.1255 - mse: 1.0795e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0495 - bpp: 1.1300 - mse: 1.1716e-04\n",
      "Epoch 912: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0495 - bpp: 1.1300 - mse: 1.1716e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9374 - bpp: 1.1306 - mse: 1.1028e-04\n",
      "Epoch 913: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9374 - bpp: 1.1306 - mse: 1.1028e-04\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8906 - bpp: 1.1004 - mse: 1.0926e-04\n",
      "Epoch 914: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8906 - bpp: 1.1004 - mse: 1.0926e-04\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2662 - bpp: 1.1345 - mse: 1.3011e-04\n",
      "Epoch 915: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2662 - bpp: 1.1345 - mse: 1.3011e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3044 - bpp: 1.1552 - mse: 1.3118e-04\n",
      "Epoch 916: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3044 - bpp: 1.1552 - mse: 1.3118e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8380 - bpp: 1.1179 - mse: 1.0499e-04\n",
      "Epoch 917: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8380 - bpp: 1.1179 - mse: 1.0499e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3055 - bpp: 1.1488 - mse: 1.3164e-04\n",
      "Epoch 918: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3055 - bpp: 1.1488 - mse: 1.3164e-04\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0591 - bpp: 1.1402 - mse: 1.1712e-04\n",
      "Epoch 919: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0591 - bpp: 1.1402 - mse: 1.1712e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3491 - bpp: 1.1704 - mse: 1.3298e-04\n",
      "Epoch 920: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.3491 - bpp: 1.1704 - mse: 1.3298e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0947 - bpp: 1.1450 - mse: 1.1900e-04\n",
      "Epoch 921: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0947 - bpp: 1.1450 - mse: 1.1900e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0999 - bpp: 1.1372 - mse: 1.1979e-04\n",
      "Epoch 922: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0999 - bpp: 1.1372 - mse: 1.1979e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8626 - bpp: 1.0956 - mse: 1.0785e-04\n",
      "Epoch 923: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8626 - bpp: 1.0956 - mse: 1.0785e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1029 - bpp: 1.1465 - mse: 1.1941e-04\n",
      "Epoch 924: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1029 - bpp: 1.1465 - mse: 1.1941e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0278 - bpp: 1.1345 - mse: 1.1556e-04\n",
      "Epoch 925: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0278 - bpp: 1.1345 - mse: 1.1556e-04\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9909 - bpp: 1.1454 - mse: 1.1264e-04\n",
      "Epoch 926: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9909 - bpp: 1.1454 - mse: 1.1264e-04\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9828 - bpp: 1.1249 - mse: 1.1340e-04\n",
      "Epoch 927: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9828 - bpp: 1.1249 - mse: 1.1340e-04\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1985 - bpp: 1.1623 - mse: 1.2428e-04\n",
      "Epoch 928: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1985 - bpp: 1.1623 - mse: 1.2428e-04\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9753 - bpp: 1.1298 - mse: 1.1264e-04\n",
      "Epoch 929: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9753 - bpp: 1.1298 - mse: 1.1264e-04\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3782 - bpp: 1.1770 - mse: 1.3435e-04\n",
      "Epoch 930: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.3782 - bpp: 1.1770 - mse: 1.3435e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8938 - bpp: 1.1191 - mse: 1.0832e-04\n",
      "Epoch 931: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8938 - bpp: 1.1191 - mse: 1.0832e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9948 - bpp: 1.1162 - mse: 1.1466e-04\n",
      "Epoch 932: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9948 - bpp: 1.1162 - mse: 1.1466e-04\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9210 - bpp: 1.1075 - mse: 1.1069e-04\n",
      "Epoch 933: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.9210 - bpp: 1.1075 - mse: 1.1069e-04\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8783 - bpp: 1.1295 - mse: 1.0674e-04\n",
      "Epoch 934: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.8783 - bpp: 1.1295 - mse: 1.0674e-04\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0872 - bpp: 1.1310 - mse: 1.1940e-04\n",
      "Epoch 935: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0872 - bpp: 1.1310 - mse: 1.1940e-04\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0518 - bpp: 1.1456 - mse: 1.1634e-04\n",
      "Epoch 936: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0518 - bpp: 1.1456 - mse: 1.1634e-04\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0526 - bpp: 1.1237 - mse: 1.1773e-04\n",
      "Epoch 937: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0526 - bpp: 1.1237 - mse: 1.1773e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0497 - bpp: 1.1269 - mse: 1.1736e-04\n",
      "Epoch 938: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0497 - bpp: 1.1269 - mse: 1.1736e-04\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1896 - bpp: 1.1441 - mse: 1.2485e-04\n",
      "Epoch 939: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1896 - bpp: 1.1441 - mse: 1.2485e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8269 - bpp: 1.1119 - mse: 1.0468e-04\n",
      "Epoch 940: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8269 - bpp: 1.1119 - mse: 1.0468e-04\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2221 - bpp: 1.1234 - mse: 1.2810e-04\n",
      "Epoch 941: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.2221 - bpp: 1.1234 - mse: 1.2810e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2403 - bpp: 1.1550 - mse: 1.2728e-04\n",
      "Epoch 942: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.2403 - bpp: 1.1550 - mse: 1.2728e-04\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8975 - bpp: 1.1200 - mse: 1.0849e-04\n",
      "Epoch 943: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8975 - bpp: 1.1200 - mse: 1.0849e-04\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7712 - bpp: 1.0950 - mse: 1.0231e-04\n",
      "Epoch 944: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7712 - bpp: 1.0950 - mse: 1.0231e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1351 - bpp: 1.1384 - mse: 1.2187e-04\n",
      "Epoch 945: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1351 - bpp: 1.1384 - mse: 1.2187e-04\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0054 - bpp: 1.1269 - mse: 1.1466e-04\n",
      "Epoch 946: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0054 - bpp: 1.1269 - mse: 1.1466e-04\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1915 - bpp: 1.1275 - mse: 1.2597e-04\n",
      "Epoch 947: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 3.1915 - bpp: 1.1275 - mse: 1.2597e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1280 - bpp: 1.1312 - mse: 1.2187e-04\n",
      "Epoch 948: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1280 - bpp: 1.1312 - mse: 1.2187e-04\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1726 - bpp: 1.1504 - mse: 1.2343e-04\n",
      "Epoch 949: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 3.1726 - bpp: 1.1504 - mse: 1.2343e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8567 - bpp: 1.1197 - mse: 1.0602e-04\n",
      "Epoch 950: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.8567 - bpp: 1.1197 - mse: 1.0602e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9836 - bpp: 1.1319 - mse: 1.1302e-04\n",
      "Epoch 951: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9836 - bpp: 1.1319 - mse: 1.1302e-04\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1798 - bpp: 1.1433 - mse: 1.2430e-04\n",
      "Epoch 952: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1798 - bpp: 1.1433 - mse: 1.2430e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4571 - bpp: 1.1771 - mse: 1.3916e-04\n",
      "Epoch 953: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.4571 - bpp: 1.1771 - mse: 1.3916e-04\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1130 - bpp: 1.1182 - mse: 1.2175e-04\n",
      "Epoch 954: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1130 - bpp: 1.1182 - mse: 1.2175e-04\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3635 - bpp: 1.1459 - mse: 1.3536e-04\n",
      "Epoch 955: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.3635 - bpp: 1.1459 - mse: 1.3536e-04\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1627 - bpp: 1.1363 - mse: 1.2368e-04\n",
      "Epoch 956: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1627 - bpp: 1.1363 - mse: 1.2368e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8166 - bpp: 1.1247 - mse: 1.0326e-04\n",
      "Epoch 957: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8166 - bpp: 1.1247 - mse: 1.0326e-04\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9824 - bpp: 1.1263 - mse: 1.1329e-04\n",
      "Epoch 958: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9824 - bpp: 1.1263 - mse: 1.1329e-04\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9960 - bpp: 1.1168 - mse: 1.1470e-04\n",
      "Epoch 959: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.9960 - bpp: 1.1168 - mse: 1.1470e-04\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9309 - bpp: 1.1220 - mse: 1.1041e-04\n",
      "Epoch 960: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9309 - bpp: 1.1220 - mse: 1.1041e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1617 - bpp: 1.1306 - mse: 1.2397e-04\n",
      "Epoch 961: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1617 - bpp: 1.1306 - mse: 1.2397e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0643 - bpp: 1.1281 - mse: 1.1818e-04\n",
      "Epoch 962: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0643 - bpp: 1.1281 - mse: 1.1818e-04\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0631 - bpp: 1.1311 - mse: 1.1792e-04\n",
      "Epoch 963: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0631 - bpp: 1.1311 - mse: 1.1792e-04\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2986 - bpp: 1.1520 - mse: 1.3101e-04\n",
      "Epoch 964: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2986 - bpp: 1.1520 - mse: 1.3101e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2854 - bpp: 1.1462 - mse: 1.3056e-04\n",
      "Epoch 965: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2854 - bpp: 1.1462 - mse: 1.3056e-04\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0112 - bpp: 1.1354 - mse: 1.1449e-04\n",
      "Epoch 966: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0112 - bpp: 1.1354 - mse: 1.1449e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9854 - bpp: 1.1309 - mse: 1.1319e-04\n",
      "Epoch 967: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9854 - bpp: 1.1309 - mse: 1.1319e-04\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0096 - bpp: 1.1163 - mse: 1.1556e-04\n",
      "Epoch 968: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0096 - bpp: 1.1163 - mse: 1.1556e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3137 - bpp: 1.1549 - mse: 1.3177e-04\n",
      "Epoch 969: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3137 - bpp: 1.1549 - mse: 1.3177e-04\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9301 - bpp: 1.1274 - mse: 1.1003e-04\n",
      "Epoch 970: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9301 - bpp: 1.1274 - mse: 1.1003e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2784 - bpp: 1.1645 - mse: 1.2902e-04\n",
      "Epoch 971: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2784 - bpp: 1.1645 - mse: 1.2902e-04\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9432 - bpp: 1.0992 - mse: 1.1255e-04\n",
      "Epoch 972: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.9432 - bpp: 1.0992 - mse: 1.1255e-04\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9017 - bpp: 1.1269 - mse: 1.0832e-04\n",
      "Epoch 973: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9017 - bpp: 1.1269 - mse: 1.0832e-04\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4054 - bpp: 1.1601 - mse: 1.3704e-04\n",
      "Epoch 974: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.4054 - bpp: 1.1601 - mse: 1.3704e-04\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2268 - bpp: 1.1352 - mse: 1.2766e-04\n",
      "Epoch 975: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2268 - bpp: 1.1352 - mse: 1.2766e-04\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1149 - bpp: 1.1422 - mse: 1.2040e-04\n",
      "Epoch 976: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.1149 - bpp: 1.1422 - mse: 1.2040e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7985 - bpp: 1.1320 - mse: 1.0171e-04\n",
      "Epoch 977: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.7985 - bpp: 1.1320 - mse: 1.0171e-04\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9696 - bpp: 1.1223 - mse: 1.1275e-04\n",
      "Epoch 978: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9696 - bpp: 1.1223 - mse: 1.1275e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9878 - bpp: 1.1486 - mse: 1.1226e-04\n",
      "Epoch 979: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9878 - bpp: 1.1486 - mse: 1.1226e-04\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3316 - bpp: 1.1465 - mse: 1.3337e-04\n",
      "Epoch 980: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3316 - bpp: 1.1465 - mse: 1.3337e-04\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9416 - bpp: 1.1335 - mse: 1.1035e-04\n",
      "Epoch 981: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9416 - bpp: 1.1335 - mse: 1.1035e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4449 - bpp: 1.1689 - mse: 1.3892e-04\n",
      "Epoch 982: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.4449 - bpp: 1.1689 - mse: 1.3892e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9915 - bpp: 1.1335 - mse: 1.1340e-04\n",
      "Epoch 983: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 254ms/step - loss: 2.9915 - bpp: 1.1335 - mse: 1.1340e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1806 - bpp: 1.1323 - mse: 1.2502e-04\n",
      "Epoch 984: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 3.1806 - bpp: 1.1323 - mse: 1.2502e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0085 - bpp: 1.1147 - mse: 1.1559e-04\n",
      "Epoch 985: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.0085 - bpp: 1.1147 - mse: 1.1559e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0874 - bpp: 1.1315 - mse: 1.1938e-04\n",
      "Epoch 986: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0874 - bpp: 1.1315 - mse: 1.1938e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2416 - bpp: 1.1314 - mse: 1.2879e-04\n",
      "Epoch 987: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.2416 - bpp: 1.1314 - mse: 1.2879e-04\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2231 - bpp: 1.1654 - mse: 1.2559e-04\n",
      "Epoch 988: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.2231 - bpp: 1.1654 - mse: 1.2559e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1266 - bpp: 1.1166 - mse: 1.2268e-04\n",
      "Epoch 989: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.1266 - bpp: 1.1166 - mse: 1.2268e-04\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0225 - bpp: 1.1105 - mse: 1.1670e-04\n",
      "Epoch 990: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0225 - bpp: 1.1105 - mse: 1.1670e-04\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9575 - bpp: 1.0984 - mse: 1.1347e-04\n",
      "Epoch 991: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9575 - bpp: 1.0984 - mse: 1.1347e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0339 - bpp: 1.1564 - mse: 1.1460e-04\n",
      "Epoch 992: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.0339 - bpp: 1.1564 - mse: 1.1460e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3526 - bpp: 1.1470 - mse: 1.3462e-04\n",
      "Epoch 993: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.3526 - bpp: 1.1470 - mse: 1.3462e-04\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1383 - bpp: 1.1285 - mse: 1.2267e-04\n",
      "Epoch 994: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1383 - bpp: 1.1285 - mse: 1.2267e-04\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0994 - bpp: 1.1482 - mse: 1.1909e-04\n",
      "Epoch 995: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0994 - bpp: 1.1482 - mse: 1.1909e-04\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0706 - bpp: 1.1385 - mse: 1.1793e-04\n",
      "Epoch 996: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 3.0706 - bpp: 1.1385 - mse: 1.1793e-04\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0981 - bpp: 1.1279 - mse: 1.2025e-04\n",
      "Epoch 997: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0981 - bpp: 1.1279 - mse: 1.2025e-04\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1382 - bpp: 1.1403 - mse: 1.2194e-04\n",
      "Epoch 998: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1382 - bpp: 1.1403 - mse: 1.2194e-04\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5735 - bpp: 1.0786 - mse: 9.1236e-05\n",
      "Epoch 999: loss improved from 2.58260 to 2.57346, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.5735 - bpp: 1.0786 - mse: 9.1236e-05\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4496 - bpp: 1.1573 - mse: 1.3992e-04\n",
      "Epoch 1000: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.4496 - bpp: 1.1573 - mse: 1.3992e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2975 - bpp: 1.1517 - mse: 1.3096e-04\n",
      "Epoch 1001: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2975 - bpp: 1.1517 - mse: 1.3096e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4403 - bpp: 1.1591 - mse: 1.3923e-04\n",
      "Epoch 1002: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.4403 - bpp: 1.1591 - mse: 1.3923e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2958 - bpp: 1.1378 - mse: 1.3171e-04\n",
      "Epoch 1003: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2958 - bpp: 1.1378 - mse: 1.3171e-04\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9480 - bpp: 1.1147 - mse: 1.1190e-04\n",
      "Epoch 1004: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9480 - bpp: 1.1147 - mse: 1.1190e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8094 - bpp: 1.1067 - mse: 1.0393e-04\n",
      "Epoch 1005: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8094 - bpp: 1.1067 - mse: 1.0393e-04\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8773 - bpp: 1.1214 - mse: 1.0717e-04\n",
      "Epoch 1006: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8773 - bpp: 1.1214 - mse: 1.0717e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8673 - bpp: 1.1347 - mse: 1.0575e-04\n",
      "Epoch 1007: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8673 - bpp: 1.1347 - mse: 1.0575e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7291 - bpp: 1.0984 - mse: 9.9530e-05\n",
      "Epoch 1008: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.7291 - bpp: 1.0984 - mse: 9.9530e-05\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1827 - bpp: 1.1352 - mse: 1.2497e-04\n",
      "Epoch 1009: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1827 - bpp: 1.1352 - mse: 1.2497e-04\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8658 - bpp: 1.1281 - mse: 1.0606e-04\n",
      "Epoch 1010: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8658 - bpp: 1.1281 - mse: 1.0606e-04\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0463 - bpp: 1.1228 - mse: 1.1740e-04\n",
      "Epoch 1011: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0463 - bpp: 1.1228 - mse: 1.1740e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0914 - bpp: 1.1188 - mse: 1.2040e-04\n",
      "Epoch 1012: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 3.0914 - bpp: 1.1188 - mse: 1.2040e-04\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2739 - bpp: 1.1375 - mse: 1.3039e-04\n",
      "Epoch 1013: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2739 - bpp: 1.1375 - mse: 1.3039e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0721 - bpp: 1.1412 - mse: 1.1785e-04\n",
      "Epoch 1014: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0721 - bpp: 1.1412 - mse: 1.1785e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1621 - bpp: 1.1521 - mse: 1.2268e-04\n",
      "Epoch 1015: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1621 - bpp: 1.1521 - mse: 1.2268e-04\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3861 - bpp: 1.1531 - mse: 1.3629e-04\n",
      "Epoch 1016: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3861 - bpp: 1.1531 - mse: 1.3629e-04\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8597 - bpp: 1.1381 - mse: 1.0508e-04\n",
      "Epoch 1017: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8597 - bpp: 1.1381 - mse: 1.0508e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7729 - bpp: 1.0990 - mse: 1.0217e-04\n",
      "Epoch 1018: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.7729 - bpp: 1.0990 - mse: 1.0217e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3645 - bpp: 1.1598 - mse: 1.3456e-04\n",
      "Epoch 1019: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.3645 - bpp: 1.1598 - mse: 1.3456e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3872 - bpp: 1.1418 - mse: 1.3705e-04\n",
      "Epoch 1020: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.3872 - bpp: 1.1418 - mse: 1.3705e-04\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1444 - bpp: 1.1382 - mse: 1.2245e-04\n",
      "Epoch 1021: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1444 - bpp: 1.1382 - mse: 1.2245e-04\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9641 - bpp: 1.1283 - mse: 1.1205e-04\n",
      "Epoch 1022: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9641 - bpp: 1.1283 - mse: 1.1205e-04\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0309 - bpp: 1.1324 - mse: 1.1588e-04\n",
      "Epoch 1023: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0309 - bpp: 1.1324 - mse: 1.1588e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4856 - bpp: 1.1530 - mse: 1.4237e-04\n",
      "Epoch 1024: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.4856 - bpp: 1.1530 - mse: 1.4237e-04\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1343 - bpp: 1.1243 - mse: 1.2268e-04\n",
      "Epoch 1025: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1343 - bpp: 1.1243 - mse: 1.2268e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9956 - bpp: 1.1426 - mse: 1.1310e-04\n",
      "Epoch 1026: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9956 - bpp: 1.1426 - mse: 1.1310e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3525 - bpp: 1.1505 - mse: 1.3440e-04\n",
      "Epoch 1027: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3525 - bpp: 1.1505 - mse: 1.3440e-04\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1146 - bpp: 1.1508 - mse: 1.1986e-04\n",
      "Epoch 1028: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.1146 - bpp: 1.1508 - mse: 1.1986e-04\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7093 - bpp: 1.0963 - mse: 9.8451e-05\n",
      "Epoch 1029: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.7093 - bpp: 1.0963 - mse: 9.8451e-05\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8096 - bpp: 1.1112 - mse: 1.0366e-04\n",
      "Epoch 1030: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8096 - bpp: 1.1112 - mse: 1.0366e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4004 - bpp: 1.1600 - mse: 1.3675e-04\n",
      "Epoch 1031: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.4004 - bpp: 1.1600 - mse: 1.3675e-04\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0078 - bpp: 1.1332 - mse: 1.1441e-04\n",
      "Epoch 1032: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0078 - bpp: 1.1332 - mse: 1.1441e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1567 - bpp: 1.1348 - mse: 1.2341e-04\n",
      "Epoch 1033: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1567 - bpp: 1.1348 - mse: 1.2341e-04\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0061 - bpp: 1.1199 - mse: 1.1513e-04\n",
      "Epoch 1034: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0061 - bpp: 1.1199 - mse: 1.1513e-04\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1556 - bpp: 1.1367 - mse: 1.2323e-04\n",
      "Epoch 1035: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1556 - bpp: 1.1367 - mse: 1.2323e-04\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1806 - bpp: 1.1498 - mse: 1.2395e-04\n",
      "Epoch 1036: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1806 - bpp: 1.1498 - mse: 1.2395e-04\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4810 - bpp: 1.1735 - mse: 1.4084e-04\n",
      "Epoch 1037: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.4810 - bpp: 1.1735 - mse: 1.4084e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1228 - bpp: 1.1302 - mse: 1.2161e-04\n",
      "Epoch 1038: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1228 - bpp: 1.1302 - mse: 1.2161e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2705 - bpp: 1.1503 - mse: 1.2941e-04\n",
      "Epoch 1039: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.2705 - bpp: 1.1503 - mse: 1.2941e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8585 - bpp: 1.1057 - mse: 1.0698e-04\n",
      "Epoch 1040: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8585 - bpp: 1.1057 - mse: 1.0698e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1970 - bpp: 1.1464 - mse: 1.2516e-04\n",
      "Epoch 1041: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1970 - bpp: 1.1464 - mse: 1.2516e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8574 - bpp: 1.1149 - mse: 1.0636e-04\n",
      "Epoch 1042: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.8574 - bpp: 1.1149 - mse: 1.0636e-04\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6952 - bpp: 1.1100 - mse: 9.6750e-05\n",
      "Epoch 1043: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 2.6952 - bpp: 1.1100 - mse: 9.6750e-05\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9939 - bpp: 1.1356 - mse: 1.1342e-04\n",
      "Epoch 1044: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9939 - bpp: 1.1356 - mse: 1.1342e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2296 - bpp: 1.1447 - mse: 1.2725e-04\n",
      "Epoch 1045: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.2296 - bpp: 1.1447 - mse: 1.2725e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0667 - bpp: 1.1283 - mse: 1.1831e-04\n",
      "Epoch 1046: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0667 - bpp: 1.1283 - mse: 1.1831e-04\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7261 - bpp: 1.1025 - mse: 9.9094e-05\n",
      "Epoch 1047: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7261 - bpp: 1.1025 - mse: 9.9094e-05\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8441 - bpp: 1.1037 - mse: 1.0623e-04\n",
      "Epoch 1048: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8441 - bpp: 1.1037 - mse: 1.0623e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0137 - bpp: 1.1342 - mse: 1.1471e-04\n",
      "Epoch 1049: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0137 - bpp: 1.1342 - mse: 1.1471e-04\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1385 - bpp: 1.1415 - mse: 1.2189e-04\n",
      "Epoch 1050: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1385 - bpp: 1.1415 - mse: 1.2189e-04\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9095 - bpp: 1.1140 - mse: 1.0959e-04\n",
      "Epoch 1051: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9095 - bpp: 1.1140 - mse: 1.0959e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3867 - bpp: 1.1739 - mse: 1.3506e-04\n",
      "Epoch 1052: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.3867 - bpp: 1.1739 - mse: 1.3506e-04\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0835 - bpp: 1.1389 - mse: 1.1869e-04\n",
      "Epoch 1053: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0835 - bpp: 1.1389 - mse: 1.1869e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8310 - bpp: 1.1281 - mse: 1.0394e-04\n",
      "Epoch 1054: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 2.8310 - bpp: 1.1281 - mse: 1.0394e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0424 - bpp: 1.1127 - mse: 1.1778e-04\n",
      "Epoch 1055: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0424 - bpp: 1.1127 - mse: 1.1778e-04\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2029 - bpp: 1.1463 - mse: 1.2553e-04\n",
      "Epoch 1056: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2029 - bpp: 1.1463 - mse: 1.2553e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8779 - bpp: 1.1372 - mse: 1.0624e-04\n",
      "Epoch 1057: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8779 - bpp: 1.1372 - mse: 1.0624e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0612 - bpp: 1.1144 - mse: 1.1882e-04\n",
      "Epoch 1058: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0612 - bpp: 1.1144 - mse: 1.1882e-04\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9650 - bpp: 1.1147 - mse: 1.1294e-04\n",
      "Epoch 1059: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9650 - bpp: 1.1147 - mse: 1.1294e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0264 - bpp: 1.1381 - mse: 1.1525e-04\n",
      "Epoch 1060: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0264 - bpp: 1.1381 - mse: 1.1525e-04\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8525 - bpp: 1.1190 - mse: 1.0580e-04\n",
      "Epoch 1061: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8525 - bpp: 1.1190 - mse: 1.0580e-04\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9804 - bpp: 1.1183 - mse: 1.1365e-04\n",
      "Epoch 1062: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9804 - bpp: 1.1183 - mse: 1.1365e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0161 - bpp: 1.1157 - mse: 1.1599e-04\n",
      "Epoch 1063: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0161 - bpp: 1.1157 - mse: 1.1599e-04\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2708 - bpp: 1.1293 - mse: 1.3071e-04\n",
      "Epoch 1064: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.2708 - bpp: 1.1293 - mse: 1.3071e-04\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2303 - bpp: 1.1598 - mse: 1.2638e-04\n",
      "Epoch 1065: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2303 - bpp: 1.1598 - mse: 1.2638e-04\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8536 - bpp: 1.1154 - mse: 1.0609e-04\n",
      "Epoch 1066: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8536 - bpp: 1.1154 - mse: 1.0609e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0677 - bpp: 1.1211 - mse: 1.1881e-04\n",
      "Epoch 1067: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0677 - bpp: 1.1211 - mse: 1.1881e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9206 - bpp: 1.1040 - mse: 1.1087e-04\n",
      "Epoch 1068: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9206 - bpp: 1.1040 - mse: 1.1087e-04\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9785 - bpp: 1.1249 - mse: 1.1313e-04\n",
      "Epoch 1069: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9785 - bpp: 1.1249 - mse: 1.1313e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1420 - bpp: 1.1530 - mse: 1.2140e-04\n",
      "Epoch 1070: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1420 - bpp: 1.1530 - mse: 1.2140e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2470 - bpp: 1.1499 - mse: 1.2800e-04\n",
      "Epoch 1071: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 258ms/step - loss: 3.2470 - bpp: 1.1499 - mse: 1.2800e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0051 - bpp: 1.1208 - mse: 1.1501e-04\n",
      "Epoch 1072: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0051 - bpp: 1.1208 - mse: 1.1501e-04\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1364 - bpp: 1.1234 - mse: 1.2287e-04\n",
      "Epoch 1073: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1364 - bpp: 1.1234 - mse: 1.2287e-04\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7526 - bpp: 1.0998 - mse: 1.0087e-04\n",
      "Epoch 1074: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.7526 - bpp: 1.0998 - mse: 1.0087e-04\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1430 - bpp: 1.1437 - mse: 1.2203e-04\n",
      "Epoch 1075: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1430 - bpp: 1.1437 - mse: 1.2203e-04\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8139 - bpp: 1.1041 - mse: 1.0436e-04\n",
      "Epoch 1076: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8139 - bpp: 1.1041 - mse: 1.0436e-04\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1847 - bpp: 1.1482 - mse: 1.2430e-04\n",
      "Epoch 1077: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1847 - bpp: 1.1482 - mse: 1.2430e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0918 - bpp: 1.1438 - mse: 1.1890e-04\n",
      "Epoch 1078: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0918 - bpp: 1.1438 - mse: 1.1890e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0982 - bpp: 1.1341 - mse: 1.1988e-04\n",
      "Epoch 1079: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0982 - bpp: 1.1341 - mse: 1.1988e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8560 - bpp: 1.1024 - mse: 1.0703e-04\n",
      "Epoch 1080: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8560 - bpp: 1.1024 - mse: 1.0703e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0680 - bpp: 1.1227 - mse: 1.1873e-04\n",
      "Epoch 1081: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0680 - bpp: 1.1227 - mse: 1.1873e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2332 - bpp: 1.1425 - mse: 1.2761e-04\n",
      "Epoch 1082: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.2332 - bpp: 1.1425 - mse: 1.2761e-04\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2355 - bpp: 1.1131 - mse: 1.2954e-04\n",
      "Epoch 1083: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 259ms/step - loss: 3.2355 - bpp: 1.1131 - mse: 1.2954e-04\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8476 - bpp: 1.1292 - mse: 1.0488e-04\n",
      "Epoch 1084: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8476 - bpp: 1.1292 - mse: 1.0488e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9388 - bpp: 1.1133 - mse: 1.1142e-04\n",
      "Epoch 1085: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9388 - bpp: 1.1133 - mse: 1.1142e-04\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7898 - bpp: 1.0877 - mse: 1.0388e-04\n",
      "Epoch 1086: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.7898 - bpp: 1.0877 - mse: 1.0388e-04\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1680 - bpp: 1.1424 - mse: 1.2363e-04\n",
      "Epoch 1087: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1680 - bpp: 1.1424 - mse: 1.2363e-04\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8733 - bpp: 1.1219 - mse: 1.0690e-04\n",
      "Epoch 1088: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.8733 - bpp: 1.1219 - mse: 1.0690e-04\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1707 - bpp: 1.1485 - mse: 1.2342e-04\n",
      "Epoch 1089: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1707 - bpp: 1.1485 - mse: 1.2342e-04\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2327 - bpp: 1.1415 - mse: 1.2763e-04\n",
      "Epoch 1090: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2327 - bpp: 1.1415 - mse: 1.2763e-04\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0806 - bpp: 1.1291 - mse: 1.1911e-04\n",
      "Epoch 1091: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0806 - bpp: 1.1291 - mse: 1.1911e-04\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0161 - bpp: 1.1248 - mse: 1.1544e-04\n",
      "Epoch 1092: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.0161 - bpp: 1.1248 - mse: 1.1544e-04\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8429 - bpp: 1.1157 - mse: 1.0542e-04\n",
      "Epoch 1093: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8429 - bpp: 1.1157 - mse: 1.0542e-04\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7568 - bpp: 1.0981 - mse: 1.0124e-04\n",
      "Epoch 1094: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7568 - bpp: 1.0981 - mse: 1.0124e-04\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7802 - bpp: 1.1102 - mse: 1.0193e-04\n",
      "Epoch 1095: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7802 - bpp: 1.1102 - mse: 1.0193e-04\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1179 - bpp: 1.1390 - mse: 1.2078e-04\n",
      "Epoch 1096: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1179 - bpp: 1.1390 - mse: 1.2078e-04\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8980 - bpp: 1.1096 - mse: 1.0916e-04\n",
      "Epoch 1097: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8980 - bpp: 1.1096 - mse: 1.0916e-04\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1298 - bpp: 1.1343 - mse: 1.2180e-04\n",
      "Epoch 1098: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1298 - bpp: 1.1343 - mse: 1.2180e-04\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9975 - bpp: 1.1024 - mse: 1.1566e-04\n",
      "Epoch 1099: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9975 - bpp: 1.1024 - mse: 1.1566e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9159 - bpp: 1.1067 - mse: 1.1043e-04\n",
      "Epoch 1100: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9159 - bpp: 1.1067 - mse: 1.1043e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8330 - bpp: 1.1126 - mse: 1.0500e-04\n",
      "Epoch 1101: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.8330 - bpp: 1.1126 - mse: 1.0500e-04\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2860 - bpp: 1.1567 - mse: 1.2996e-04\n",
      "Epoch 1102: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.2860 - bpp: 1.1567 - mse: 1.2996e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0162 - bpp: 1.1479 - mse: 1.1404e-04\n",
      "Epoch 1103: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0162 - bpp: 1.1479 - mse: 1.1404e-04\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3944 - bpp: 1.1494 - mse: 1.3702e-04\n",
      "Epoch 1104: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.3944 - bpp: 1.1494 - mse: 1.3702e-04\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1495 - bpp: 1.1461 - mse: 1.2227e-04\n",
      "Epoch 1105: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1495 - bpp: 1.1461 - mse: 1.2227e-04\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0851 - bpp: 1.1316 - mse: 1.1923e-04\n",
      "Epoch 1106: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0851 - bpp: 1.1316 - mse: 1.1923e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0015 - bpp: 1.1252 - mse: 1.1453e-04\n",
      "Epoch 1107: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.0015 - bpp: 1.1252 - mse: 1.1453e-04\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1003 - bpp: 1.1358 - mse: 1.1990e-04\n",
      "Epoch 1108: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1003 - bpp: 1.1358 - mse: 1.1990e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9060 - bpp: 1.1242 - mse: 1.0875e-04\n",
      "Epoch 1109: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9060 - bpp: 1.1242 - mse: 1.0875e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1213 - bpp: 1.1269 - mse: 1.2173e-04\n",
      "Epoch 1110: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1213 - bpp: 1.1269 - mse: 1.2173e-04\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9810 - bpp: 1.1373 - mse: 1.1253e-04\n",
      "Epoch 1111: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9810 - bpp: 1.1373 - mse: 1.1253e-04\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0942 - bpp: 1.1475 - mse: 1.1882e-04\n",
      "Epoch 1112: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0942 - bpp: 1.1475 - mse: 1.1882e-04\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0496 - bpp: 1.1397 - mse: 1.1657e-04\n",
      "Epoch 1113: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0496 - bpp: 1.1397 - mse: 1.1657e-04\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1275 - bpp: 1.1304 - mse: 1.2189e-04\n",
      "Epoch 1114: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1275 - bpp: 1.1304 - mse: 1.2189e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1708 - bpp: 1.1509 - mse: 1.2328e-04\n",
      "Epoch 1115: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1708 - bpp: 1.1509 - mse: 1.2328e-04\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0561 - bpp: 1.1118 - mse: 1.1867e-04\n",
      "Epoch 1116: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0561 - bpp: 1.1118 - mse: 1.1867e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8646 - bpp: 1.1009 - mse: 1.0764e-04\n",
      "Epoch 1117: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8646 - bpp: 1.1009 - mse: 1.0764e-04\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1142 - bpp: 1.1451 - mse: 1.2019e-04\n",
      "Epoch 1118: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.1142 - bpp: 1.1451 - mse: 1.2019e-04\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0950 - bpp: 1.1466 - mse: 1.1892e-04\n",
      "Epoch 1119: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0950 - bpp: 1.1466 - mse: 1.1892e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9487 - bpp: 1.1404 - mse: 1.1037e-04\n",
      "Epoch 1120: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.9487 - bpp: 1.1404 - mse: 1.1037e-04\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8015 - bpp: 1.0967 - mse: 1.0405e-04\n",
      "Epoch 1121: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8015 - bpp: 1.0967 - mse: 1.0405e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5599 - bpp: 1.1591 - mse: 1.4653e-04\n",
      "Epoch 1122: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 3.5599 - bpp: 1.1591 - mse: 1.4653e-04\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0722 - bpp: 1.1429 - mse: 1.1775e-04\n",
      "Epoch 1123: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0722 - bpp: 1.1429 - mse: 1.1775e-04\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1161 - bpp: 1.1376 - mse: 1.2076e-04\n",
      "Epoch 1124: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.1161 - bpp: 1.1376 - mse: 1.2076e-04\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7487 - bpp: 1.1010 - mse: 1.0057e-04\n",
      "Epoch 1125: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7487 - bpp: 1.1010 - mse: 1.0057e-04\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7876 - bpp: 1.0923 - mse: 1.0347e-04\n",
      "Epoch 1126: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7876 - bpp: 1.0923 - mse: 1.0347e-04\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8596 - bpp: 1.0905 - mse: 1.0798e-04\n",
      "Epoch 1127: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8596 - bpp: 1.0905 - mse: 1.0798e-04\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3522 - bpp: 1.1673 - mse: 1.3336e-04\n",
      "Epoch 1128: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3522 - bpp: 1.1673 - mse: 1.3336e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0746 - bpp: 1.1189 - mse: 1.1937e-04\n",
      "Epoch 1129: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0746 - bpp: 1.1189 - mse: 1.1937e-04\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8610 - bpp: 1.1376 - mse: 1.0519e-04\n",
      "Epoch 1130: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.8610 - bpp: 1.1376 - mse: 1.0519e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9029 - bpp: 1.1275 - mse: 1.0837e-04\n",
      "Epoch 1131: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9029 - bpp: 1.1275 - mse: 1.0837e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2309 - bpp: 1.1314 - mse: 1.2815e-04\n",
      "Epoch 1132: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.2309 - bpp: 1.1314 - mse: 1.2815e-04\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8931 - bpp: 1.1133 - mse: 1.0863e-04\n",
      "Epoch 1133: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8931 - bpp: 1.1133 - mse: 1.0863e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2249 - bpp: 1.1373 - mse: 1.2742e-04\n",
      "Epoch 1134: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 3.2249 - bpp: 1.1373 - mse: 1.2742e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9393 - bpp: 1.1286 - mse: 1.1051e-04\n",
      "Epoch 1135: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 2.9393 - bpp: 1.1286 - mse: 1.1051e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8248 - bpp: 1.1222 - mse: 1.0391e-04\n",
      "Epoch 1136: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8248 - bpp: 1.1222 - mse: 1.0391e-04\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2728 - bpp: 1.1500 - mse: 1.2956e-04\n",
      "Epoch 1137: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.2728 - bpp: 1.1500 - mse: 1.2956e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8567 - bpp: 1.0915 - mse: 1.0774e-04\n",
      "Epoch 1138: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 2.8567 - bpp: 1.0915 - mse: 1.0774e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7934 - bpp: 1.1140 - mse: 1.0250e-04\n",
      "Epoch 1139: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7934 - bpp: 1.1140 - mse: 1.0250e-04\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2925 - bpp: 1.1569 - mse: 1.3035e-04\n",
      "Epoch 1140: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2925 - bpp: 1.1569 - mse: 1.3035e-04\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1550 - bpp: 1.1411 - mse: 1.2292e-04\n",
      "Epoch 1141: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1550 - bpp: 1.1411 - mse: 1.2292e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9743 - bpp: 1.1365 - mse: 1.1217e-04\n",
      "Epoch 1142: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.9743 - bpp: 1.1365 - mse: 1.1217e-04\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2740 - bpp: 1.1671 - mse: 1.2859e-04\n",
      "Epoch 1143: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.2740 - bpp: 1.1671 - mse: 1.2859e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1772 - bpp: 1.1432 - mse: 1.2415e-04\n",
      "Epoch 1144: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1772 - bpp: 1.1432 - mse: 1.2415e-04\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0389 - bpp: 1.1298 - mse: 1.1652e-04\n",
      "Epoch 1145: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0389 - bpp: 1.1298 - mse: 1.1652e-04\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0013 - bpp: 1.1196 - mse: 1.1485e-04\n",
      "Epoch 1146: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0013 - bpp: 1.1196 - mse: 1.1485e-04\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9831 - bpp: 1.1321 - mse: 1.1298e-04\n",
      "Epoch 1147: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9831 - bpp: 1.1321 - mse: 1.1298e-04\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9908 - bpp: 1.1300 - mse: 1.1358e-04\n",
      "Epoch 1148: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9908 - bpp: 1.1300 - mse: 1.1358e-04\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0244 - bpp: 1.1267 - mse: 1.1583e-04\n",
      "Epoch 1149: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 3.0244 - bpp: 1.1267 - mse: 1.1583e-04\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9330 - bpp: 1.0979 - mse: 1.1201e-04\n",
      "Epoch 1150: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.9330 - bpp: 1.0979 - mse: 1.1201e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2332 - bpp: 1.1509 - mse: 1.2709e-04\n",
      "Epoch 1151: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2332 - bpp: 1.1509 - mse: 1.2709e-04\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8640 - bpp: 1.1191 - mse: 1.0650e-04\n",
      "Epoch 1152: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8640 - bpp: 1.1191 - mse: 1.0650e-04\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8637 - bpp: 1.1149 - mse: 1.0674e-04\n",
      "Epoch 1153: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8637 - bpp: 1.1149 - mse: 1.0674e-04\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0582 - bpp: 1.1238 - mse: 1.1806e-04\n",
      "Epoch 1154: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0582 - bpp: 1.1238 - mse: 1.1806e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0848 - bpp: 1.1376 - mse: 1.1885e-04\n",
      "Epoch 1155: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0848 - bpp: 1.1376 - mse: 1.1885e-04\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0838 - bpp: 1.1326 - mse: 1.1909e-04\n",
      "Epoch 1156: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0838 - bpp: 1.1326 - mse: 1.1909e-04\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0741 - bpp: 1.1324 - mse: 1.1851e-04\n",
      "Epoch 1157: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0741 - bpp: 1.1324 - mse: 1.1851e-04\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0822 - bpp: 1.1342 - mse: 1.1889e-04\n",
      "Epoch 1158: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0822 - bpp: 1.1342 - mse: 1.1889e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0797 - bpp: 1.1484 - mse: 1.1787e-04\n",
      "Epoch 1159: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0797 - bpp: 1.1484 - mse: 1.1787e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0166 - bpp: 1.1047 - mse: 1.1669e-04\n",
      "Epoch 1160: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0166 - bpp: 1.1047 - mse: 1.1669e-04\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7800 - bpp: 1.1061 - mse: 1.0217e-04\n",
      "Epoch 1161: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.7800 - bpp: 1.1061 - mse: 1.0217e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1291 - bpp: 1.1176 - mse: 1.2277e-04\n",
      "Epoch 1162: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1291 - bpp: 1.1176 - mse: 1.2277e-04\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0072 - bpp: 1.1261 - mse: 1.1481e-04\n",
      "Epoch 1163: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0072 - bpp: 1.1261 - mse: 1.1481e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8906 - bpp: 1.1130 - mse: 1.0850e-04\n",
      "Epoch 1164: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8906 - bpp: 1.1130 - mse: 1.0850e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3541 - bpp: 1.1443 - mse: 1.3488e-04\n",
      "Epoch 1165: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3541 - bpp: 1.1443 - mse: 1.3488e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0794 - bpp: 1.1308 - mse: 1.1894e-04\n",
      "Epoch 1166: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0794 - bpp: 1.1308 - mse: 1.1894e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8734 - bpp: 1.1165 - mse: 1.0723e-04\n",
      "Epoch 1167: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 238ms/step - loss: 2.8734 - bpp: 1.1165 - mse: 1.0723e-04\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1612 - bpp: 1.1263 - mse: 1.2420e-04\n",
      "Epoch 1168: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.1612 - bpp: 1.1263 - mse: 1.2420e-04\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0476 - bpp: 1.1274 - mse: 1.1720e-04\n",
      "Epoch 1169: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0476 - bpp: 1.1274 - mse: 1.1720e-04\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1484 - bpp: 1.1311 - mse: 1.2313e-04\n",
      "Epoch 1170: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1484 - bpp: 1.1311 - mse: 1.2313e-04\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8455 - bpp: 1.1098 - mse: 1.0594e-04\n",
      "Epoch 1171: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8455 - bpp: 1.1098 - mse: 1.0594e-04\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7565 - bpp: 1.0954 - mse: 1.0139e-04\n",
      "Epoch 1172: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.7565 - bpp: 1.0954 - mse: 1.0139e-04\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0541 - bpp: 1.1396 - mse: 1.1685e-04\n",
      "Epoch 1173: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0541 - bpp: 1.1396 - mse: 1.1685e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1428 - bpp: 1.1477 - mse: 1.2177e-04\n",
      "Epoch 1174: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1428 - bpp: 1.1477 - mse: 1.2177e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7903 - bpp: 1.1076 - mse: 1.0270e-04\n",
      "Epoch 1175: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7903 - bpp: 1.1076 - mse: 1.0270e-04\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3625 - bpp: 1.1579 - mse: 1.3456e-04\n",
      "Epoch 1176: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3625 - bpp: 1.1579 - mse: 1.3456e-04\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8973 - bpp: 1.1084 - mse: 1.0919e-04\n",
      "Epoch 1177: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8973 - bpp: 1.1084 - mse: 1.0919e-04\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2368 - bpp: 1.1392 - mse: 1.2803e-04\n",
      "Epoch 1178: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2368 - bpp: 1.1392 - mse: 1.2803e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0757 - bpp: 1.1242 - mse: 1.1911e-04\n",
      "Epoch 1179: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0757 - bpp: 1.1242 - mse: 1.1911e-04\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1432 - bpp: 1.1420 - mse: 1.2214e-04\n",
      "Epoch 1180: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1432 - bpp: 1.1420 - mse: 1.2214e-04\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1552 - bpp: 1.1224 - mse: 1.2407e-04\n",
      "Epoch 1181: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1552 - bpp: 1.1224 - mse: 1.2407e-04\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3345 - bpp: 1.1285 - mse: 1.3465e-04\n",
      "Epoch 1182: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.3345 - bpp: 1.1285 - mse: 1.3465e-04\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8844 - bpp: 1.1410 - mse: 1.0641e-04\n",
      "Epoch 1183: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8844 - bpp: 1.1410 - mse: 1.0641e-04\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2919 - bpp: 1.1589 - mse: 1.3019e-04\n",
      "Epoch 1184: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2919 - bpp: 1.1589 - mse: 1.3019e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0676 - bpp: 1.1206 - mse: 1.1883e-04\n",
      "Epoch 1185: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0676 - bpp: 1.1206 - mse: 1.1883e-04\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8870 - bpp: 1.0985 - mse: 1.0916e-04\n",
      "Epoch 1186: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.8870 - bpp: 1.0985 - mse: 1.0916e-04\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0427 - bpp: 1.1196 - mse: 1.1738e-04\n",
      "Epoch 1187: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0427 - bpp: 1.1196 - mse: 1.1738e-04\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6070 - bpp: 1.0879 - mse: 9.2719e-05\n",
      "Epoch 1188: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.6070 - bpp: 1.0879 - mse: 9.2719e-05\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1778 - bpp: 1.1333 - mse: 1.2479e-04\n",
      "Epoch 1189: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1778 - bpp: 1.1333 - mse: 1.2479e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0309 - bpp: 1.1217 - mse: 1.1653e-04\n",
      "Epoch 1190: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.0309 - bpp: 1.1217 - mse: 1.1653e-04\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1771 - bpp: 1.1576 - mse: 1.2326e-04\n",
      "Epoch 1191: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 264ms/step - loss: 3.1771 - bpp: 1.1576 - mse: 1.2326e-04\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1350 - bpp: 1.1519 - mse: 1.2104e-04\n",
      "Epoch 1192: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1350 - bpp: 1.1519 - mse: 1.2104e-04\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6469 - bpp: 1.1506 - mse: 1.5236e-04\n",
      "Epoch 1193: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.6469 - bpp: 1.1506 - mse: 1.5236e-04\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0180 - bpp: 1.1217 - mse: 1.1574e-04\n",
      "Epoch 1194: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0180 - bpp: 1.1217 - mse: 1.1574e-04\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0827 - bpp: 1.1112 - mse: 1.2033e-04\n",
      "Epoch 1195: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0827 - bpp: 1.1112 - mse: 1.2033e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7602 - bpp: 1.0978 - mse: 1.0147e-04\n",
      "Epoch 1196: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7602 - bpp: 1.0978 - mse: 1.0147e-04\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4349 - bpp: 1.1630 - mse: 1.3867e-04\n",
      "Epoch 1197: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.4349 - bpp: 1.1630 - mse: 1.3867e-04\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9645 - bpp: 1.1361 - mse: 1.1160e-04\n",
      "Epoch 1198: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9645 - bpp: 1.1361 - mse: 1.1160e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9988 - bpp: 1.1151 - mse: 1.1497e-04\n",
      "Epoch 1199: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9988 - bpp: 1.1151 - mse: 1.1497e-04\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9360 - bpp: 1.1029 - mse: 1.1188e-04\n",
      "Epoch 1200: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9360 - bpp: 1.1029 - mse: 1.1188e-04\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8998 - bpp: 1.1359 - mse: 1.0766e-04\n",
      "Epoch 1201: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8998 - bpp: 1.1359 - mse: 1.0766e-04\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9169 - bpp: 1.1105 - mse: 1.1025e-04\n",
      "Epoch 1202: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9169 - bpp: 1.1105 - mse: 1.1025e-04\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2487 - bpp: 1.1415 - mse: 1.2861e-04\n",
      "Epoch 1203: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.2487 - bpp: 1.1415 - mse: 1.2861e-04\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5046 - bpp: 1.1486 - mse: 1.4380e-04\n",
      "Epoch 1204: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.5046 - bpp: 1.1486 - mse: 1.4380e-04\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1434 - bpp: 1.1382 - mse: 1.2239e-04\n",
      "Epoch 1205: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1434 - bpp: 1.1382 - mse: 1.2239e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1291 - bpp: 1.1306 - mse: 1.2198e-04\n",
      "Epoch 1206: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1291 - bpp: 1.1306 - mse: 1.2198e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1766 - bpp: 1.1506 - mse: 1.2366e-04\n",
      "Epoch 1207: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1766 - bpp: 1.1506 - mse: 1.2366e-04\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9704 - bpp: 1.1328 - mse: 1.1215e-04\n",
      "Epoch 1208: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9704 - bpp: 1.1328 - mse: 1.1215e-04\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6808 - bpp: 1.0967 - mse: 9.6684e-05\n",
      "Epoch 1209: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.6808 - bpp: 1.0967 - mse: 9.6684e-05\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9097 - bpp: 1.1099 - mse: 1.0985e-04\n",
      "Epoch 1210: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9097 - bpp: 1.1099 - mse: 1.0985e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1162 - bpp: 1.1380 - mse: 1.2074e-04\n",
      "Epoch 1211: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1162 - bpp: 1.1380 - mse: 1.2074e-04\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7317 - bpp: 1.1076 - mse: 9.9125e-05\n",
      "Epoch 1212: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.7317 - bpp: 1.1076 - mse: 9.9125e-05\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8120 - bpp: 1.1145 - mse: 1.0360e-04\n",
      "Epoch 1213: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8120 - bpp: 1.1145 - mse: 1.0360e-04\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9370 - bpp: 1.1101 - mse: 1.1150e-04\n",
      "Epoch 1214: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9370 - bpp: 1.1101 - mse: 1.1150e-04\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9170 - bpp: 1.1092 - mse: 1.1034e-04\n",
      "Epoch 1215: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9170 - bpp: 1.1092 - mse: 1.1034e-04\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8860 - bpp: 1.1125 - mse: 1.0825e-04\n",
      "Epoch 1216: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8860 - bpp: 1.1125 - mse: 1.0825e-04\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0907 - bpp: 1.1439 - mse: 1.1882e-04\n",
      "Epoch 1217: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0907 - bpp: 1.1439 - mse: 1.1882e-04\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9825 - bpp: 1.1114 - mse: 1.1421e-04\n",
      "Epoch 1218: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.9825 - bpp: 1.1114 - mse: 1.1421e-04\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7416 - bpp: 1.1036 - mse: 9.9972e-05\n",
      "Epoch 1219: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7416 - bpp: 1.1036 - mse: 9.9972e-05\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1607 - bpp: 1.1359 - mse: 1.2359e-04\n",
      "Epoch 1220: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1607 - bpp: 1.1359 - mse: 1.2359e-04\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0831 - bpp: 1.1375 - mse: 1.1875e-04\n",
      "Epoch 1221: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0831 - bpp: 1.1375 - mse: 1.1875e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0194 - bpp: 1.1302 - mse: 1.1531e-04\n",
      "Epoch 1222: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0194 - bpp: 1.1302 - mse: 1.1531e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0090 - bpp: 1.1304 - mse: 1.1466e-04\n",
      "Epoch 1223: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0090 - bpp: 1.1304 - mse: 1.1466e-04\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6989 - bpp: 1.1031 - mse: 9.7402e-05\n",
      "Epoch 1224: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.6989 - bpp: 1.1031 - mse: 9.7402e-05\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9583 - bpp: 1.1259 - mse: 1.1184e-04\n",
      "Epoch 1225: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9583 - bpp: 1.1259 - mse: 1.1184e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1152 - bpp: 1.1495 - mse: 1.1998e-04\n",
      "Epoch 1226: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1152 - bpp: 1.1495 - mse: 1.1998e-04\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2638 - bpp: 1.1392 - mse: 1.2968e-04\n",
      "Epoch 1227: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.2638 - bpp: 1.1392 - mse: 1.2968e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2084 - bpp: 1.1463 - mse: 1.2586e-04\n",
      "Epoch 1228: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2084 - bpp: 1.1463 - mse: 1.2586e-04\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2740 - bpp: 1.1506 - mse: 1.2960e-04\n",
      "Epoch 1229: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2740 - bpp: 1.1506 - mse: 1.2960e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9988 - bpp: 1.1385 - mse: 1.1355e-04\n",
      "Epoch 1230: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9988 - bpp: 1.1385 - mse: 1.1355e-04\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6078 - bpp: 1.1086 - mse: 9.1501e-05\n",
      "Epoch 1231: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.6078 - bpp: 1.1086 - mse: 9.1501e-05\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9604 - bpp: 1.1244 - mse: 1.1205e-04\n",
      "Epoch 1232: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9604 - bpp: 1.1244 - mse: 1.1205e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9887 - bpp: 1.1189 - mse: 1.1412e-04\n",
      "Epoch 1233: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9887 - bpp: 1.1189 - mse: 1.1412e-04\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8646 - bpp: 1.1121 - mse: 1.0697e-04\n",
      "Epoch 1234: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8646 - bpp: 1.1121 - mse: 1.0697e-04\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3399 - bpp: 1.1645 - mse: 1.3278e-04\n",
      "Epoch 1235: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.3399 - bpp: 1.1645 - mse: 1.3278e-04\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9071 - bpp: 1.0869 - mse: 1.1110e-04\n",
      "Epoch 1236: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9071 - bpp: 1.0869 - mse: 1.1110e-04\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8786 - bpp: 1.0964 - mse: 1.0878e-04\n",
      "Epoch 1237: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.8786 - bpp: 1.0964 - mse: 1.0878e-04\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8820 - bpp: 1.1064 - mse: 1.0838e-04\n",
      "Epoch 1238: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8820 - bpp: 1.1064 - mse: 1.0838e-04\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8380 - bpp: 1.1158 - mse: 1.0512e-04\n",
      "Epoch 1239: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8380 - bpp: 1.1158 - mse: 1.0512e-04\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8718 - bpp: 1.1052 - mse: 1.0782e-04\n",
      "Epoch 1240: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 2.8718 - bpp: 1.1052 - mse: 1.0782e-04\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0237 - bpp: 1.1426 - mse: 1.1482e-04\n",
      "Epoch 1241: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 3.0237 - bpp: 1.1426 - mse: 1.1482e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8545 - bpp: 1.1022 - mse: 1.0695e-04\n",
      "Epoch 1242: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8545 - bpp: 1.1022 - mse: 1.0695e-04\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9469 - bpp: 1.1197 - mse: 1.1152e-04\n",
      "Epoch 1243: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9469 - bpp: 1.1197 - mse: 1.1152e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0234 - bpp: 1.1378 - mse: 1.1509e-04\n",
      "Epoch 1244: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0234 - bpp: 1.1378 - mse: 1.1509e-04\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7674 - bpp: 1.1152 - mse: 1.0085e-04\n",
      "Epoch 1245: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.7674 - bpp: 1.1152 - mse: 1.0085e-04\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0118 - bpp: 1.1413 - mse: 1.1417e-04\n",
      "Epoch 1246: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0118 - bpp: 1.1413 - mse: 1.1417e-04\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6853 - bpp: 1.0989 - mse: 9.6826e-05\n",
      "Epoch 1247: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.6853 - bpp: 1.0989 - mse: 9.6826e-05\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7409 - bpp: 1.1035 - mse: 9.9939e-05\n",
      "Epoch 1248: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7409 - bpp: 1.1035 - mse: 9.9939e-05\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1013 - bpp: 1.1406 - mse: 1.1967e-04\n",
      "Epoch 1249: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1013 - bpp: 1.1406 - mse: 1.1967e-04\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7659 - bpp: 1.1013 - mse: 1.0160e-04\n",
      "Epoch 1250: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7659 - bpp: 1.1013 - mse: 1.0160e-04\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9345 - bpp: 1.1323 - mse: 1.1000e-04\n",
      "Epoch 1251: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9345 - bpp: 1.1323 - mse: 1.1000e-04\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7893 - bpp: 1.0992 - mse: 1.0316e-04\n",
      "Epoch 1252: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7893 - bpp: 1.0992 - mse: 1.0316e-04\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7816 - bpp: 1.1050 - mse: 1.0233e-04\n",
      "Epoch 1253: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.7816 - bpp: 1.1050 - mse: 1.0233e-04\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2487 - bpp: 1.1409 - mse: 1.2865e-04\n",
      "Epoch 1254: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.2487 - bpp: 1.1409 - mse: 1.2865e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0923 - bpp: 1.1187 - mse: 1.2046e-04\n",
      "Epoch 1255: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0923 - bpp: 1.1187 - mse: 1.2046e-04\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9632 - bpp: 1.1224 - mse: 1.1235e-04\n",
      "Epoch 1256: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.9632 - bpp: 1.1224 - mse: 1.1235e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6001 - bpp: 1.0955 - mse: 9.1838e-05\n",
      "Epoch 1257: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.6001 - bpp: 1.0955 - mse: 9.1838e-05\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0979 - bpp: 1.1339 - mse: 1.1987e-04\n",
      "Epoch 1258: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 3.0979 - bpp: 1.1339 - mse: 1.1987e-04\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6608 - bpp: 1.1053 - mse: 9.4940e-05\n",
      "Epoch 1259: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 2.6608 - bpp: 1.1053 - mse: 9.4940e-05\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8426 - bpp: 1.1076 - mse: 1.0589e-04\n",
      "Epoch 1260: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8426 - bpp: 1.1076 - mse: 1.0589e-04\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0125 - bpp: 1.1328 - mse: 1.1473e-04\n",
      "Epoch 1261: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.0125 - bpp: 1.1328 - mse: 1.1473e-04\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6948 - bpp: 1.0994 - mse: 9.7378e-05\n",
      "Epoch 1262: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.6948 - bpp: 1.0994 - mse: 9.7378e-05\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8525 - bpp: 1.1237 - mse: 1.0551e-04\n",
      "Epoch 1263: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8525 - bpp: 1.1237 - mse: 1.0551e-04\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9274 - bpp: 1.1201 - mse: 1.1031e-04\n",
      "Epoch 1264: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.9274 - bpp: 1.1201 - mse: 1.1031e-04\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7090 - bpp: 1.1044 - mse: 9.7932e-05\n",
      "Epoch 1265: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7090 - bpp: 1.1044 - mse: 9.7932e-05\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0610 - bpp: 1.1245 - mse: 1.1820e-04\n",
      "Epoch 1266: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.0610 - bpp: 1.1245 - mse: 1.1820e-04\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0508 - bpp: 1.1458 - mse: 1.1627e-04\n",
      "Epoch 1267: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0508 - bpp: 1.1458 - mse: 1.1627e-04\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0633 - bpp: 1.1412 - mse: 1.1732e-04\n",
      "Epoch 1268: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3.0633 - bpp: 1.1412 - mse: 1.1732e-04\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8508 - bpp: 1.1070 - mse: 1.0643e-04\n",
      "Epoch 1269: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8508 - bpp: 1.1070 - mse: 1.0643e-04\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8831 - bpp: 1.1215 - mse: 1.0752e-04\n",
      "Epoch 1270: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8831 - bpp: 1.1215 - mse: 1.0752e-04\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6673 - bpp: 1.0723 - mse: 9.7349e-05\n",
      "Epoch 1271: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6673 - bpp: 1.0723 - mse: 9.7349e-05\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7833 - bpp: 1.1163 - mse: 1.0174e-04\n",
      "Epoch 1272: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7833 - bpp: 1.1163 - mse: 1.0174e-04\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8773 - bpp: 1.1377 - mse: 1.0617e-04\n",
      "Epoch 1273: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8773 - bpp: 1.1377 - mse: 1.0617e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4125 - bpp: 1.1687 - mse: 1.3695e-04\n",
      "Epoch 1274: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.4125 - bpp: 1.1687 - mse: 1.3695e-04\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8619 - bpp: 1.1033 - mse: 1.0734e-04\n",
      "Epoch 1275: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8619 - bpp: 1.1033 - mse: 1.0734e-04\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5791 - bpp: 1.0808 - mse: 9.1448e-05\n",
      "Epoch 1276: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.5791 - bpp: 1.0808 - mse: 9.1448e-05\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8911 - bpp: 1.1130 - mse: 1.0853e-04\n",
      "Epoch 1277: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8911 - bpp: 1.1130 - mse: 1.0853e-04\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8094 - bpp: 1.0834 - mse: 1.0534e-04\n",
      "Epoch 1278: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.8094 - bpp: 1.0834 - mse: 1.0534e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0140 - bpp: 1.1252 - mse: 1.1528e-04\n",
      "Epoch 1279: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.0140 - bpp: 1.1252 - mse: 1.1528e-04\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0505 - bpp: 1.1266 - mse: 1.1743e-04\n",
      "Epoch 1280: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0505 - bpp: 1.1266 - mse: 1.1743e-04\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2778 - bpp: 1.1395 - mse: 1.3051e-04\n",
      "Epoch 1281: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 3.2778 - bpp: 1.1395 - mse: 1.3051e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8977 - bpp: 1.1019 - mse: 1.0961e-04\n",
      "Epoch 1282: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 2.8977 - bpp: 1.1019 - mse: 1.0961e-04\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0275 - bpp: 1.1362 - mse: 1.1544e-04\n",
      "Epoch 1283: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0275 - bpp: 1.1362 - mse: 1.1544e-04\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1290 - bpp: 1.1115 - mse: 1.2314e-04\n",
      "Epoch 1284: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1290 - bpp: 1.1115 - mse: 1.2314e-04\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0660 - bpp: 1.1314 - mse: 1.1808e-04\n",
      "Epoch 1285: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 3.0660 - bpp: 1.1314 - mse: 1.1808e-04\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3066 - bpp: 1.1497 - mse: 1.3164e-04\n",
      "Epoch 1286: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.3066 - bpp: 1.1497 - mse: 1.3164e-04\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9719 - bpp: 1.1231 - mse: 1.1284e-04\n",
      "Epoch 1287: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9719 - bpp: 1.1231 - mse: 1.1284e-04\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9354 - bpp: 1.1164 - mse: 1.1102e-04\n",
      "Epoch 1288: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9354 - bpp: 1.1164 - mse: 1.1102e-04\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7184 - bpp: 1.1224 - mse: 9.7416e-05\n",
      "Epoch 1289: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7184 - bpp: 1.1224 - mse: 9.7416e-05\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4701 - bpp: 1.0671 - mse: 8.5631e-05\n",
      "Epoch 1290: loss improved from 2.57346 to 2.47009, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.4701 - bpp: 1.0671 - mse: 8.5631e-05\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1126 - bpp: 1.1426 - mse: 1.2024e-04\n",
      "Epoch 1291: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.1126 - bpp: 1.1426 - mse: 1.2024e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0666 - bpp: 1.1190 - mse: 1.1887e-04\n",
      "Epoch 1292: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0666 - bpp: 1.1190 - mse: 1.1887e-04\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3210 - bpp: 1.1391 - mse: 1.3318e-04\n",
      "Epoch 1293: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.3210 - bpp: 1.1391 - mse: 1.3318e-04\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7266 - bpp: 1.0986 - mse: 9.9370e-05\n",
      "Epoch 1294: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7266 - bpp: 1.0986 - mse: 9.9370e-05\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8234 - bpp: 1.1040 - mse: 1.0495e-04\n",
      "Epoch 1295: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.8234 - bpp: 1.1040 - mse: 1.0495e-04\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3078 - bpp: 1.1362 - mse: 1.3254e-04\n",
      "Epoch 1296: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 3.3078 - bpp: 1.1362 - mse: 1.3254e-04\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1690 - bpp: 1.1463 - mse: 1.2346e-04\n",
      "Epoch 1297: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.1690 - bpp: 1.1463 - mse: 1.2346e-04\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9102 - bpp: 1.1238 - mse: 1.0903e-04\n",
      "Epoch 1298: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9102 - bpp: 1.1238 - mse: 1.0903e-04\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7783 - bpp: 1.0984 - mse: 1.0253e-04\n",
      "Epoch 1299: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7783 - bpp: 1.0984 - mse: 1.0253e-04\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8823 - bpp: 1.1196 - mse: 1.0759e-04\n",
      "Epoch 1300: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 2.8823 - bpp: 1.1196 - mse: 1.0759e-04\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1712 - bpp: 1.1234 - mse: 1.2499e-04\n",
      "Epoch 1301: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.1712 - bpp: 1.1234 - mse: 1.2499e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0324 - bpp: 1.1416 - mse: 1.1540e-04\n",
      "Epoch 1302: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0324 - bpp: 1.1416 - mse: 1.1540e-04\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9644 - bpp: 1.1368 - mse: 1.1155e-04\n",
      "Epoch 1303: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9644 - bpp: 1.1368 - mse: 1.1155e-04\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9941 - bpp: 1.1344 - mse: 1.1350e-04\n",
      "Epoch 1304: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9941 - bpp: 1.1344 - mse: 1.1350e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3352 - bpp: 1.1470 - mse: 1.3356e-04\n",
      "Epoch 1305: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.3352 - bpp: 1.1470 - mse: 1.3356e-04\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1077 - bpp: 1.1453 - mse: 1.1978e-04\n",
      "Epoch 1306: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1077 - bpp: 1.1453 - mse: 1.1978e-04\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2126 - bpp: 1.1389 - mse: 1.2657e-04\n",
      "Epoch 1307: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2126 - bpp: 1.1389 - mse: 1.2657e-04\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0220 - bpp: 1.1549 - mse: 1.1396e-04\n",
      "Epoch 1308: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0220 - bpp: 1.1549 - mse: 1.1396e-04\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7711 - bpp: 1.1106 - mse: 1.0135e-04\n",
      "Epoch 1309: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7711 - bpp: 1.1106 - mse: 1.0135e-04\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1515 - bpp: 1.1156 - mse: 1.2426e-04\n",
      "Epoch 1310: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.1515 - bpp: 1.1156 - mse: 1.2426e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2523 - bpp: 1.1543 - mse: 1.2805e-04\n",
      "Epoch 1311: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2523 - bpp: 1.1543 - mse: 1.2805e-04\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8256 - bpp: 1.1066 - mse: 1.0492e-04\n",
      "Epoch 1312: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8256 - bpp: 1.1066 - mse: 1.0492e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7837 - bpp: 1.1205 - mse: 1.0152e-04\n",
      "Epoch 1313: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.7837 - bpp: 1.1205 - mse: 1.0152e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2853 - bpp: 1.1603 - mse: 1.2970e-04\n",
      "Epoch 1314: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 3.2853 - bpp: 1.1603 - mse: 1.2970e-04\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0711 - bpp: 1.1425 - mse: 1.1771e-04\n",
      "Epoch 1315: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0711 - bpp: 1.1425 - mse: 1.1771e-04\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8718 - bpp: 1.1153 - mse: 1.0720e-04\n",
      "Epoch 1316: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.8718 - bpp: 1.1153 - mse: 1.0720e-04\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8871 - bpp: 1.1279 - mse: 1.0738e-04\n",
      "Epoch 1317: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8871 - bpp: 1.1279 - mse: 1.0738e-04\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6592 - bpp: 1.0842 - mse: 9.6127e-05\n",
      "Epoch 1318: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.6592 - bpp: 1.0842 - mse: 9.6127e-05\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8018 - bpp: 1.0903 - mse: 1.0446e-04\n",
      "Epoch 1319: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8018 - bpp: 1.0903 - mse: 1.0446e-04\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6826 - bpp: 1.0900 - mse: 9.7210e-05\n",
      "Epoch 1320: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6826 - bpp: 1.0900 - mse: 9.7210e-05\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8500 - bpp: 1.1141 - mse: 1.0595e-04\n",
      "Epoch 1321: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8500 - bpp: 1.1141 - mse: 1.0595e-04\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2008 - bpp: 1.1202 - mse: 1.2699e-04\n",
      "Epoch 1322: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2008 - bpp: 1.1202 - mse: 1.2699e-04\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0314 - bpp: 1.1431 - mse: 1.1525e-04\n",
      "Epoch 1323: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0314 - bpp: 1.1431 - mse: 1.1525e-04\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0148 - bpp: 1.1486 - mse: 1.1390e-04\n",
      "Epoch 1324: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0148 - bpp: 1.1486 - mse: 1.1390e-04\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0217 - bpp: 1.1373 - mse: 1.1501e-04\n",
      "Epoch 1325: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0217 - bpp: 1.1373 - mse: 1.1501e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8905 - bpp: 1.1147 - mse: 1.0839e-04\n",
      "Epoch 1326: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8905 - bpp: 1.1147 - mse: 1.0839e-04\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2302 - bpp: 1.1424 - mse: 1.2743e-04\n",
      "Epoch 1327: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2302 - bpp: 1.1424 - mse: 1.2743e-04\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1692 - bpp: 1.1514 - mse: 1.2316e-04\n",
      "Epoch 1328: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1692 - bpp: 1.1514 - mse: 1.2316e-04\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8619 - bpp: 1.1125 - mse: 1.0677e-04\n",
      "Epoch 1329: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8619 - bpp: 1.1125 - mse: 1.0677e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9466 - bpp: 1.1138 - mse: 1.1187e-04\n",
      "Epoch 1330: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9466 - bpp: 1.1138 - mse: 1.1187e-04\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9910 - bpp: 1.1330 - mse: 1.1341e-04\n",
      "Epoch 1331: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9910 - bpp: 1.1330 - mse: 1.1341e-04\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7299 - bpp: 1.0943 - mse: 9.9832e-05\n",
      "Epoch 1332: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.7299 - bpp: 1.0943 - mse: 9.9832e-05\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8976 - bpp: 1.1094 - mse: 1.0914e-04\n",
      "Epoch 1333: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.8976 - bpp: 1.1094 - mse: 1.0914e-04\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2417 - bpp: 1.1561 - mse: 1.2729e-04\n",
      "Epoch 1334: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2417 - bpp: 1.1561 - mse: 1.2729e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0524 - bpp: 1.1210 - mse: 1.1788e-04\n",
      "Epoch 1335: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 3.0524 - bpp: 1.1210 - mse: 1.1788e-04\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8581 - bpp: 1.1071 - mse: 1.0687e-04\n",
      "Epoch 1336: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 2.8581 - bpp: 1.1071 - mse: 1.0687e-04\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9720 - bpp: 1.1323 - mse: 1.1228e-04\n",
      "Epoch 1337: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9720 - bpp: 1.1323 - mse: 1.1228e-04\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9293 - bpp: 1.1244 - mse: 1.1017e-04\n",
      "Epoch 1338: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.9293 - bpp: 1.1244 - mse: 1.1017e-04\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5373 - bpp: 1.1611 - mse: 1.4504e-04\n",
      "Epoch 1339: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.5373 - bpp: 1.1611 - mse: 1.4504e-04\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0696 - bpp: 1.1505 - mse: 1.1713e-04\n",
      "Epoch 1340: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 3.0696 - bpp: 1.1505 - mse: 1.1713e-04\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0883 - bpp: 1.1258 - mse: 1.1978e-04\n",
      "Epoch 1341: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0883 - bpp: 1.1258 - mse: 1.1978e-04\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8606 - bpp: 1.1094 - mse: 1.0688e-04\n",
      "Epoch 1342: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 2.8606 - bpp: 1.1094 - mse: 1.0688e-04\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0660 - bpp: 1.1166 - mse: 1.1898e-04\n",
      "Epoch 1343: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 3.0660 - bpp: 1.1166 - mse: 1.1898e-04\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7995 - bpp: 1.1078 - mse: 1.0325e-04\n",
      "Epoch 1344: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7995 - bpp: 1.1078 - mse: 1.0325e-04\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9466 - bpp: 1.1245 - mse: 1.1121e-04\n",
      "Epoch 1345: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9466 - bpp: 1.1245 - mse: 1.1121e-04\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6043 - bpp: 1.0840 - mse: 9.2791e-05\n",
      "Epoch 1346: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.6043 - bpp: 1.0840 - mse: 9.2791e-05\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9461 - bpp: 1.1229 - mse: 1.1128e-04\n",
      "Epoch 1347: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9461 - bpp: 1.1229 - mse: 1.1128e-04\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9747 - bpp: 1.1172 - mse: 1.1337e-04\n",
      "Epoch 1348: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9747 - bpp: 1.1172 - mse: 1.1337e-04\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1157 - bpp: 1.1562 - mse: 1.1960e-04\n",
      "Epoch 1349: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.1157 - bpp: 1.1562 - mse: 1.1960e-04\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1443 - bpp: 1.1261 - mse: 1.2318e-04\n",
      "Epoch 1350: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1443 - bpp: 1.1261 - mse: 1.2318e-04\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0705 - bpp: 1.1252 - mse: 1.1874e-04\n",
      "Epoch 1351: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0705 - bpp: 1.1252 - mse: 1.1874e-04\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8203 - bpp: 1.0842 - mse: 1.0597e-04\n",
      "Epoch 1352: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8203 - bpp: 1.0842 - mse: 1.0597e-04\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2808 - bpp: 1.1384 - mse: 1.3076e-04\n",
      "Epoch 1353: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2808 - bpp: 1.1384 - mse: 1.3076e-04\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8136 - bpp: 1.1157 - mse: 1.0363e-04\n",
      "Epoch 1354: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.8136 - bpp: 1.1157 - mse: 1.0363e-04\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7708 - bpp: 1.0925 - mse: 1.0243e-04\n",
      "Epoch 1355: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.7708 - bpp: 1.0925 - mse: 1.0243e-04\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7263 - bpp: 1.0969 - mse: 9.9447e-05\n",
      "Epoch 1356: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7263 - bpp: 1.0969 - mse: 9.9447e-05\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3058 - bpp: 1.1306 - mse: 1.3276e-04\n",
      "Epoch 1357: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3.3058 - bpp: 1.1306 - mse: 1.3276e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9872 - bpp: 1.1271 - mse: 1.1353e-04\n",
      "Epoch 1358: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.9872 - bpp: 1.1271 - mse: 1.1353e-04\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0072 - bpp: 1.1198 - mse: 1.1520e-04\n",
      "Epoch 1359: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.0072 - bpp: 1.1198 - mse: 1.1520e-04\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9864 - bpp: 1.1290 - mse: 1.1336e-04\n",
      "Epoch 1360: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9864 - bpp: 1.1290 - mse: 1.1336e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9623 - bpp: 1.1302 - mse: 1.1182e-04\n",
      "Epoch 1361: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9623 - bpp: 1.1302 - mse: 1.1182e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8358 - bpp: 1.1212 - mse: 1.0465e-04\n",
      "Epoch 1362: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8358 - bpp: 1.1212 - mse: 1.0465e-04\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9922 - bpp: 1.1497 - mse: 1.1246e-04\n",
      "Epoch 1363: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9922 - bpp: 1.1497 - mse: 1.1246e-04\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2968 - bpp: 1.1688 - mse: 1.2988e-04\n",
      "Epoch 1364: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 3.2968 - bpp: 1.1688 - mse: 1.2988e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2336 - bpp: 1.1517 - mse: 1.2707e-04\n",
      "Epoch 1365: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2336 - bpp: 1.1517 - mse: 1.2707e-04\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9037 - bpp: 1.1164 - mse: 1.0909e-04\n",
      "Epoch 1366: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.9037 - bpp: 1.1164 - mse: 1.0909e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8815 - bpp: 1.1112 - mse: 1.0805e-04\n",
      "Epoch 1367: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 2.8815 - bpp: 1.1112 - mse: 1.0805e-04\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9183 - bpp: 1.1181 - mse: 1.0988e-04\n",
      "Epoch 1368: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.9183 - bpp: 1.1181 - mse: 1.0988e-04\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3464 - bpp: 1.1354 - mse: 1.3495e-04\n",
      "Epoch 1369: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 3.3464 - bpp: 1.1354 - mse: 1.3495e-04\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0206 - bpp: 1.1293 - mse: 1.1543e-04\n",
      "Epoch 1370: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0206 - bpp: 1.1293 - mse: 1.1543e-04\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0765 - bpp: 1.1192 - mse: 1.1946e-04\n",
      "Epoch 1371: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0765 - bpp: 1.1192 - mse: 1.1946e-04\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1916 - bpp: 1.1378 - mse: 1.2536e-04\n",
      "Epoch 1372: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1916 - bpp: 1.1378 - mse: 1.2536e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6048 - bpp: 1.0719 - mse: 9.3561e-05\n",
      "Epoch 1373: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.6048 - bpp: 1.0719 - mse: 9.3561e-05\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7347 - bpp: 1.0852 - mse: 1.0068e-04\n",
      "Epoch 1374: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7347 - bpp: 1.0852 - mse: 1.0068e-04\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0789 - bpp: 1.1310 - mse: 1.1889e-04\n",
      "Epoch 1375: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.0789 - bpp: 1.1310 - mse: 1.1889e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9855 - bpp: 1.1270 - mse: 1.1343e-04\n",
      "Epoch 1376: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9855 - bpp: 1.1270 - mse: 1.1343e-04\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3055 - bpp: 1.1531 - mse: 1.3137e-04\n",
      "Epoch 1377: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3055 - bpp: 1.1531 - mse: 1.3137e-04\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4424 - bpp: 1.1819 - mse: 1.3797e-04\n",
      "Epoch 1378: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.4424 - bpp: 1.1819 - mse: 1.3797e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8687 - bpp: 1.0971 - mse: 1.0813e-04\n",
      "Epoch 1379: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8687 - bpp: 1.0971 - mse: 1.0813e-04\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9724 - bpp: 1.1148 - mse: 1.1338e-04\n",
      "Epoch 1380: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9724 - bpp: 1.1148 - mse: 1.1338e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2522 - bpp: 1.1492 - mse: 1.2836e-04\n",
      "Epoch 1381: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.2522 - bpp: 1.1492 - mse: 1.2836e-04\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7255 - bpp: 1.1080 - mse: 9.8725e-05\n",
      "Epoch 1382: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7255 - bpp: 1.1080 - mse: 9.8725e-05\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2169 - bpp: 1.1359 - mse: 1.2701e-04\n",
      "Epoch 1383: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2169 - bpp: 1.1359 - mse: 1.2701e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8069 - bpp: 1.1080 - mse: 1.0369e-04\n",
      "Epoch 1384: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8069 - bpp: 1.1080 - mse: 1.0369e-04\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2280 - bpp: 1.1545 - mse: 1.2655e-04\n",
      "Epoch 1385: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2280 - bpp: 1.1545 - mse: 1.2655e-04\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7220 - bpp: 1.1012 - mse: 9.8927e-05\n",
      "Epoch 1386: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.7220 - bpp: 1.1012 - mse: 9.8927e-05\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9982 - bpp: 1.1155 - mse: 1.1491e-04\n",
      "Epoch 1387: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9982 - bpp: 1.1155 - mse: 1.1491e-04\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7517 - bpp: 1.1203 - mse: 9.9572e-05\n",
      "Epoch 1388: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.7517 - bpp: 1.1203 - mse: 9.9572e-05\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1286 - bpp: 1.1481 - mse: 1.2088e-04\n",
      "Epoch 1389: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1286 - bpp: 1.1481 - mse: 1.2088e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8075 - bpp: 1.0976 - mse: 1.0436e-04\n",
      "Epoch 1390: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8075 - bpp: 1.0976 - mse: 1.0436e-04\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0325 - bpp: 1.1457 - mse: 1.1517e-04\n",
      "Epoch 1391: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0325 - bpp: 1.1457 - mse: 1.1517e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9894 - bpp: 1.1278 - mse: 1.1362e-04\n",
      "Epoch 1392: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.9894 - bpp: 1.1278 - mse: 1.1362e-04\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6079 - bpp: 1.0787 - mse: 9.3336e-05\n",
      "Epoch 1393: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6079 - bpp: 1.0787 - mse: 9.3336e-05\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7211 - bpp: 1.0802 - mse: 1.0015e-04\n",
      "Epoch 1394: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7211 - bpp: 1.0802 - mse: 1.0015e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9464 - bpp: 1.1395 - mse: 1.1028e-04\n",
      "Epoch 1395: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9464 - bpp: 1.1395 - mse: 1.1028e-04\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8966 - bpp: 1.1339 - mse: 1.0759e-04\n",
      "Epoch 1396: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8966 - bpp: 1.1339 - mse: 1.0759e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7779 - bpp: 1.1095 - mse: 1.0183e-04\n",
      "Epoch 1397: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7779 - bpp: 1.1095 - mse: 1.0183e-04\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7232 - bpp: 1.0987 - mse: 9.9148e-05\n",
      "Epoch 1398: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.7232 - bpp: 1.0987 - mse: 9.9148e-05\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8361 - bpp: 1.1029 - mse: 1.0578e-04\n",
      "Epoch 1399: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.8361 - bpp: 1.1029 - mse: 1.0578e-04\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6895 - bpp: 1.0762 - mse: 9.8469e-05\n",
      "Epoch 1400: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6895 - bpp: 1.0762 - mse: 9.8469e-05\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7160 - bpp: 1.0965 - mse: 9.8848e-05\n",
      "Epoch 1401: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7160 - bpp: 1.0965 - mse: 9.8848e-05\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3479 - bpp: 1.1618 - mse: 1.3343e-04\n",
      "Epoch 1402: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.3479 - bpp: 1.1618 - mse: 1.3343e-04\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8474 - bpp: 1.1205 - mse: 1.0540e-04\n",
      "Epoch 1403: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 2.8474 - bpp: 1.1205 - mse: 1.0540e-04\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9587 - bpp: 1.1334 - mse: 1.1140e-04\n",
      "Epoch 1404: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9587 - bpp: 1.1334 - mse: 1.1140e-04\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6404 - bpp: 1.1048 - mse: 9.3726e-05\n",
      "Epoch 1405: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.6404 - bpp: 1.1048 - mse: 9.3726e-05\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9829 - bpp: 1.1047 - mse: 1.1464e-04\n",
      "Epoch 1406: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 2.9829 - bpp: 1.1047 - mse: 1.1464e-04\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9464 - bpp: 1.1221 - mse: 1.1135e-04\n",
      "Epoch 1407: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.9464 - bpp: 1.1221 - mse: 1.1135e-04\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9324 - bpp: 1.1304 - mse: 1.0998e-04\n",
      "Epoch 1408: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 2.9324 - bpp: 1.1304 - mse: 1.0998e-04\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2126 - bpp: 1.1256 - mse: 1.2738e-04\n",
      "Epoch 1409: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.2126 - bpp: 1.1256 - mse: 1.2738e-04\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0342 - bpp: 1.1105 - mse: 1.1741e-04\n",
      "Epoch 1410: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0342 - bpp: 1.1105 - mse: 1.1741e-04\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7979 - bpp: 1.1271 - mse: 1.0198e-04\n",
      "Epoch 1411: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.7979 - bpp: 1.1271 - mse: 1.0198e-04\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8453 - bpp: 1.1285 - mse: 1.0478e-04\n",
      "Epoch 1412: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8453 - bpp: 1.1285 - mse: 1.0478e-04\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8992 - bpp: 1.1204 - mse: 1.0857e-04\n",
      "Epoch 1413: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8992 - bpp: 1.1204 - mse: 1.0857e-04\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8992 - bpp: 1.1168 - mse: 1.0879e-04\n",
      "Epoch 1414: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.8992 - bpp: 1.1168 - mse: 1.0879e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8736 - bpp: 1.1215 - mse: 1.0694e-04\n",
      "Epoch 1415: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8736 - bpp: 1.1215 - mse: 1.0694e-04\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8199 - bpp: 1.0986 - mse: 1.0506e-04\n",
      "Epoch 1416: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8199 - bpp: 1.0986 - mse: 1.0506e-04\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0922 - bpp: 1.1325 - mse: 1.1961e-04\n",
      "Epoch 1417: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0922 - bpp: 1.1325 - mse: 1.1961e-04\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6724 - bpp: 1.1043 - mse: 9.5710e-05\n",
      "Epoch 1418: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.6724 - bpp: 1.1043 - mse: 9.5710e-05\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7736 - bpp: 1.0971 - mse: 1.0232e-04\n",
      "Epoch 1419: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7736 - bpp: 1.0971 - mse: 1.0232e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0003 - bpp: 1.1333 - mse: 1.1395e-04\n",
      "Epoch 1420: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0003 - bpp: 1.1333 - mse: 1.1395e-04\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1637 - bpp: 1.1178 - mse: 1.2487e-04\n",
      "Epoch 1421: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.1637 - bpp: 1.1178 - mse: 1.2487e-04\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7938 - bpp: 1.1012 - mse: 1.0330e-04\n",
      "Epoch 1422: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 274ms/step - loss: 2.7938 - bpp: 1.1012 - mse: 1.0330e-04\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7340 - bpp: 1.1109 - mse: 9.9065e-05\n",
      "Epoch 1423: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 2.7340 - bpp: 1.1109 - mse: 9.9065e-05\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7868 - bpp: 1.1126 - mse: 1.0218e-04\n",
      "Epoch 1424: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7868 - bpp: 1.1126 - mse: 1.0218e-04\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9189 - bpp: 1.1366 - mse: 1.0878e-04\n",
      "Epoch 1425: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.9189 - bpp: 1.1366 - mse: 1.0878e-04\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8862 - bpp: 1.1251 - mse: 1.0749e-04\n",
      "Epoch 1426: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 2.8862 - bpp: 1.1251 - mse: 1.0749e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2339 - bpp: 1.1469 - mse: 1.2738e-04\n",
      "Epoch 1427: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.2339 - bpp: 1.1469 - mse: 1.2738e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2223 - bpp: 1.1395 - mse: 1.2713e-04\n",
      "Epoch 1428: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 3.2223 - bpp: 1.1395 - mse: 1.2713e-04\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9844 - bpp: 1.1368 - mse: 1.1277e-04\n",
      "Epoch 1429: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 2.9844 - bpp: 1.1368 - mse: 1.1277e-04\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8448 - bpp: 1.1020 - mse: 1.0638e-04\n",
      "Epoch 1430: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 2.8448 - bpp: 1.1020 - mse: 1.0638e-04\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8748 - bpp: 1.1079 - mse: 1.0784e-04\n",
      "Epoch 1431: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.8748 - bpp: 1.1079 - mse: 1.0784e-04\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0633 - bpp: 1.1555 - mse: 1.1644e-04\n",
      "Epoch 1432: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.0633 - bpp: 1.1555 - mse: 1.1644e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7621 - bpp: 1.0928 - mse: 1.0188e-04\n",
      "Epoch 1433: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.7621 - bpp: 1.0928 - mse: 1.0188e-04\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7061 - bpp: 1.1156 - mse: 9.7077e-05\n",
      "Epoch 1434: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 2.7061 - bpp: 1.1156 - mse: 9.7077e-05\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8983 - bpp: 1.1138 - mse: 1.0892e-04\n",
      "Epoch 1435: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.8983 - bpp: 1.1138 - mse: 1.0892e-04\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8052 - bpp: 1.0971 - mse: 1.0426e-04\n",
      "Epoch 1436: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.8052 - bpp: 1.0971 - mse: 1.0426e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1274 - bpp: 1.1423 - mse: 1.2116e-04\n",
      "Epoch 1437: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1274 - bpp: 1.1423 - mse: 1.2116e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8423 - bpp: 1.0972 - mse: 1.0651e-04\n",
      "Epoch 1438: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 2.8423 - bpp: 1.0972 - mse: 1.0651e-04\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6754 - bpp: 1.1027 - mse: 9.5988e-05\n",
      "Epoch 1439: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 2.6754 - bpp: 1.1027 - mse: 9.5988e-05\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9454 - bpp: 1.1084 - mse: 1.1212e-04\n",
      "Epoch 1440: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.9454 - bpp: 1.1084 - mse: 1.1212e-04\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1561 - bpp: 1.1521 - mse: 1.2231e-04\n",
      "Epoch 1441: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1561 - bpp: 1.1521 - mse: 1.2231e-04\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8487 - bpp: 1.1180 - mse: 1.0564e-04\n",
      "Epoch 1442: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 2.8487 - bpp: 1.1180 - mse: 1.0564e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9046 - bpp: 1.1303 - mse: 1.0829e-04\n",
      "Epoch 1443: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9046 - bpp: 1.1303 - mse: 1.0829e-04\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1796 - bpp: 1.1519 - mse: 1.2376e-04\n",
      "Epoch 1444: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 3.1796 - bpp: 1.1519 - mse: 1.2376e-04\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7794 - bpp: 1.1044 - mse: 1.0223e-04\n",
      "Epoch 1445: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.7794 - bpp: 1.1044 - mse: 1.0223e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8468 - bpp: 1.0948 - mse: 1.0693e-04\n",
      "Epoch 1446: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8468 - bpp: 1.0948 - mse: 1.0693e-04\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7310 - bpp: 1.0966 - mse: 9.9759e-05\n",
      "Epoch 1447: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.7310 - bpp: 1.0966 - mse: 9.9759e-05\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1406 - bpp: 1.1527 - mse: 1.2133e-04\n",
      "Epoch 1448: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 3.1406 - bpp: 1.1527 - mse: 1.2133e-04\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9889 - bpp: 1.1178 - mse: 1.1421e-04\n",
      "Epoch 1449: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9889 - bpp: 1.1178 - mse: 1.1421e-04\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9792 - bpp: 1.1264 - mse: 1.1309e-04\n",
      "Epoch 1450: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 2.9792 - bpp: 1.1264 - mse: 1.1309e-04\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7024 - bpp: 1.1069 - mse: 9.7380e-05\n",
      "Epoch 1451: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7024 - bpp: 1.1069 - mse: 9.7380e-05\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2508 - bpp: 1.1382 - mse: 1.2894e-04\n",
      "Epoch 1452: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.2508 - bpp: 1.1382 - mse: 1.2894e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3426 - bpp: 1.1503 - mse: 1.3380e-04\n",
      "Epoch 1453: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 3.3426 - bpp: 1.1503 - mse: 1.3380e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1479 - bpp: 1.1497 - mse: 1.2196e-04\n",
      "Epoch 1454: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.1479 - bpp: 1.1497 - mse: 1.2196e-04\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7161 - bpp: 1.1044 - mse: 9.8372e-05\n",
      "Epoch 1455: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.7161 - bpp: 1.1044 - mse: 9.8372e-05\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7988 - bpp: 1.1142 - mse: 1.0282e-04\n",
      "Epoch 1456: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7988 - bpp: 1.1142 - mse: 1.0282e-04\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0920 - bpp: 1.1326 - mse: 1.1959e-04\n",
      "Epoch 1457: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0920 - bpp: 1.1326 - mse: 1.1959e-04\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0481 - bpp: 1.1032 - mse: 1.1871e-04\n",
      "Epoch 1458: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0481 - bpp: 1.1032 - mse: 1.1871e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9935 - bpp: 1.1281 - mse: 1.1386e-04\n",
      "Epoch 1459: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9935 - bpp: 1.1281 - mse: 1.1386e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8085 - bpp: 1.0975 - mse: 1.0443e-04\n",
      "Epoch 1460: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 2.8085 - bpp: 1.0975 - mse: 1.0443e-04\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1063 - bpp: 1.1306 - mse: 1.2059e-04\n",
      "Epoch 1461: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 3.1063 - bpp: 1.1306 - mse: 1.2059e-04\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8859 - bpp: 1.1184 - mse: 1.0788e-04\n",
      "Epoch 1462: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.8859 - bpp: 1.1184 - mse: 1.0788e-04\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8811 - bpp: 1.1121 - mse: 1.0797e-04\n",
      "Epoch 1463: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 2.8811 - bpp: 1.1121 - mse: 1.0797e-04\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1132 - bpp: 1.1354 - mse: 1.2072e-04\n",
      "Epoch 1464: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1132 - bpp: 1.1354 - mse: 1.2072e-04\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9277 - bpp: 1.1310 - mse: 1.0967e-04\n",
      "Epoch 1465: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 57s 281ms/step - loss: 2.9277 - bpp: 1.1310 - mse: 1.0967e-04\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8580 - bpp: 1.1119 - mse: 1.0657e-04\n",
      "Epoch 1466: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.8580 - bpp: 1.1119 - mse: 1.0657e-04\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8174 - bpp: 1.1182 - mse: 1.0371e-04\n",
      "Epoch 1467: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 2.8174 - bpp: 1.1182 - mse: 1.0371e-04\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0955 - bpp: 1.1396 - mse: 1.1938e-04\n",
      "Epoch 1468: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0955 - bpp: 1.1396 - mse: 1.1938e-04\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0007 - bpp: 1.1427 - mse: 1.1340e-04\n",
      "Epoch 1469: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.0007 - bpp: 1.1427 - mse: 1.1340e-04\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9585 - bpp: 1.1204 - mse: 1.1219e-04\n",
      "Epoch 1470: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9585 - bpp: 1.1204 - mse: 1.1219e-04\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8266 - bpp: 1.1082 - mse: 1.0488e-04\n",
      "Epoch 1471: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.8266 - bpp: 1.1082 - mse: 1.0488e-04\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5971 - bpp: 1.0886 - mse: 9.2071e-05\n",
      "Epoch 1472: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.5971 - bpp: 1.0886 - mse: 9.2071e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6635 - bpp: 1.0709 - mse: 9.7202e-05\n",
      "Epoch 1473: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 2.6635 - bpp: 1.0709 - mse: 9.7202e-05\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2991 - bpp: 1.1615 - mse: 1.3047e-04\n",
      "Epoch 1474: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 3.2991 - bpp: 1.1615 - mse: 1.3047e-04\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0515 - bpp: 1.1413 - mse: 1.1659e-04\n",
      "Epoch 1475: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.0515 - bpp: 1.1413 - mse: 1.1659e-04\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8714 - bpp: 1.1278 - mse: 1.0642e-04\n",
      "Epoch 1476: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8714 - bpp: 1.1278 - mse: 1.0642e-04\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8407 - bpp: 1.1180 - mse: 1.0515e-04\n",
      "Epoch 1477: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.8407 - bpp: 1.1180 - mse: 1.0515e-04\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0417 - bpp: 1.1476 - mse: 1.1561e-04\n",
      "Epoch 1478: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0417 - bpp: 1.1476 - mse: 1.1561e-04\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0903 - bpp: 1.1331 - mse: 1.1946e-04\n",
      "Epoch 1479: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0903 - bpp: 1.1331 - mse: 1.1946e-04\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7568 - bpp: 1.1002 - mse: 1.0111e-04\n",
      "Epoch 1480: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.7568 - bpp: 1.1002 - mse: 1.0111e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8538 - bpp: 1.1219 - mse: 1.0571e-04\n",
      "Epoch 1481: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8538 - bpp: 1.1219 - mse: 1.0571e-04\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9744 - bpp: 1.1156 - mse: 1.1345e-04\n",
      "Epoch 1482: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 2.9744 - bpp: 1.1156 - mse: 1.1345e-04\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1277 - bpp: 1.1336 - mse: 1.2171e-04\n",
      "Epoch 1483: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1277 - bpp: 1.1336 - mse: 1.2171e-04\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1431 - bpp: 1.1625 - mse: 1.2089e-04\n",
      "Epoch 1484: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.1431 - bpp: 1.1625 - mse: 1.2089e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9626 - bpp: 1.1280 - mse: 1.1198e-04\n",
      "Epoch 1485: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.9626 - bpp: 1.1280 - mse: 1.1198e-04\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0306 - bpp: 1.1337 - mse: 1.1578e-04\n",
      "Epoch 1486: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.0306 - bpp: 1.1337 - mse: 1.1578e-04\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9303 - bpp: 1.1196 - mse: 1.1052e-04\n",
      "Epoch 1487: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9303 - bpp: 1.1196 - mse: 1.1052e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1060 - bpp: 1.1239 - mse: 1.2097e-04\n",
      "Epoch 1488: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1060 - bpp: 1.1239 - mse: 1.2097e-04\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1118 - bpp: 1.1397 - mse: 1.2037e-04\n",
      "Epoch 1489: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 3.1118 - bpp: 1.1397 - mse: 1.2037e-04\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2630 - bpp: 1.1430 - mse: 1.2939e-04\n",
      "Epoch 1490: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.2630 - bpp: 1.1430 - mse: 1.2939e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9118 - bpp: 1.1013 - mse: 1.1051e-04\n",
      "Epoch 1491: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9118 - bpp: 1.1013 - mse: 1.1051e-04\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0821 - bpp: 1.1376 - mse: 1.1868e-04\n",
      "Epoch 1492: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0821 - bpp: 1.1376 - mse: 1.1868e-04\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9534 - bpp: 1.1198 - mse: 1.1191e-04\n",
      "Epoch 1493: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.9534 - bpp: 1.1198 - mse: 1.1191e-04\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9985 - bpp: 1.1267 - mse: 1.1425e-04\n",
      "Epoch 1494: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9985 - bpp: 1.1267 - mse: 1.1425e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0172 - bpp: 1.1553 - mse: 1.1364e-04\n",
      "Epoch 1495: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0172 - bpp: 1.1553 - mse: 1.1364e-04\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0645 - bpp: 1.1249 - mse: 1.1838e-04\n",
      "Epoch 1496: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0645 - bpp: 1.1249 - mse: 1.1838e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6868 - bpp: 1.1058 - mse: 9.6496e-05\n",
      "Epoch 1497: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.6868 - bpp: 1.1058 - mse: 9.6496e-05\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1134 - bpp: 1.1333 - mse: 1.2086e-04\n",
      "Epoch 1498: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 3.1134 - bpp: 1.1333 - mse: 1.2086e-04\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7774 - bpp: 1.1018 - mse: 1.0227e-04\n",
      "Epoch 1499: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.7774 - bpp: 1.1018 - mse: 1.0227e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1022 - bpp: 1.1228 - mse: 1.2081e-04\n",
      "Epoch 1500: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1022 - bpp: 1.1228 - mse: 1.2081e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_3_layer_call_fn, optical_flow_loss_3_layer_call_and_return_conditional_losses, dwt_3_layer_call_fn, dwt_3_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_14 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_14.compile()\n",
    "trainer_14.fit()\n",
    "trainer_14.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 04:34:47.123503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:47.187759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:47.189069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:47.195864: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-08 04:34:47.201746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:47.202780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:47.203549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:49.315766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:49.316718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:49.317539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 04:34:49.318317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 04:35:19.281037: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-05-08 04:35:56.897877: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 363.3542 - bpp: 5.3080 - mse: 0.0109\n",
      "Epoch 1: loss improved from inf to 363.35422, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 104s 233ms/step - loss: 363.3542 - bpp: 5.3080 - mse: 0.0109\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 86.9940 - bpp: 5.1697 - mse: 0.0025\n",
      "Epoch 2: loss improved from 363.35422 to 86.99403, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 86.9940 - bpp: 5.1697 - mse: 0.0025\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 68.0632 - bpp: 5.0343 - mse: 0.0019\n",
      "Epoch 3: loss improved from 86.99403 to 68.06316, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 68.0632 - bpp: 5.0343 - mse: 0.0019\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 78.3591 - bpp: 4.9018 - mse: 0.0022\n",
      "Epoch 4: loss did not improve from 68.06316\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 78.3591 - bpp: 4.9018 - mse: 0.0022\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 50.6516 - bpp: 4.7716 - mse: 0.0014\n",
      "Epoch 5: loss improved from 68.06316 to 50.65164, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 50.6516 - bpp: 4.7716 - mse: 0.0014\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 48.1168 - bpp: 4.6434 - mse: 0.0013\n",
      "Epoch 6: loss improved from 50.65164 to 48.11675, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 48.1168 - bpp: 4.6434 - mse: 0.0013\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 39.0519 - bpp: 4.5178 - mse: 0.0011\n",
      "Epoch 7: loss improved from 48.11675 to 39.05186, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 39.0519 - bpp: 4.5178 - mse: 0.0011\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 43.7735 - bpp: 4.3951 - mse: 0.0012\n",
      "Epoch 8: loss did not improve from 39.05186\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 43.7735 - bpp: 4.3951 - mse: 0.0012\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 35.7394 - bpp: 4.2731 - mse: 9.6028e-04\n",
      "Epoch 9: loss improved from 39.05186 to 35.73941, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 35.7394 - bpp: 4.2731 - mse: 9.6028e-04\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.9911 - bpp: 4.1549 - mse: 8.8001e-04\n",
      "Epoch 10: loss improved from 35.73941 to 32.99113, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 32.9911 - bpp: 4.1549 - mse: 8.8001e-04\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 30.2636 - bpp: 4.0390 - mse: 8.0031e-04\n",
      "Epoch 11: loss improved from 32.99113 to 30.26360, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 30.2636 - bpp: 4.0390 - mse: 8.0031e-04\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 33.0737 - bpp: 3.9237 - mse: 8.8959e-04\n",
      "Epoch 12: loss did not improve from 30.26360\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 33.0737 - bpp: 3.9237 - mse: 8.8959e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 38.0726 - bpp: 3.8138 - mse: 0.0010\n",
      "Epoch 13: loss did not improve from 30.26360\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 38.0726 - bpp: 3.8138 - mse: 0.0010\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 55.3136 - bpp: 3.7098 - mse: 0.0016\n",
      "Epoch 14: loss did not improve from 30.26360\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 55.3136 - bpp: 3.7098 - mse: 0.0016\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 35.0315 - bpp: 3.6058 - mse: 9.5903e-04\n",
      "Epoch 15: loss did not improve from 30.26360\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 35.0315 - bpp: 3.6058 - mse: 9.5903e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 28.1563 - bpp: 3.5038 - mse: 7.5233e-04\n",
      "Epoch 16: loss improved from 30.26360 to 28.15630, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 28.1563 - bpp: 3.5038 - mse: 7.5233e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 24.1920 - bpp: 3.3959 - mse: 6.3464e-04\n",
      "Epoch 17: loss improved from 28.15630 to 24.19196, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 24.1920 - bpp: 3.3959 - mse: 6.3464e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.4975 - bpp: 3.2967 - mse: 5.5544e-04\n",
      "Epoch 18: loss improved from 24.19196 to 21.49748, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 21.4975 - bpp: 3.2967 - mse: 5.5544e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.0307 - bpp: 3.2082 - mse: 6.9649e-04\n",
      "Epoch 19: loss did not improve from 21.49748\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 26.0307 - bpp: 3.2082 - mse: 6.9649e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.3320 - bpp: 3.1126 - mse: 6.7808e-04\n",
      "Epoch 20: loss did not improve from 21.49748\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 25.3320 - bpp: 3.1126 - mse: 6.7808e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.8104 - bpp: 3.0297 - mse: 6.3417e-04\n",
      "Epoch 21: loss did not improve from 21.49748\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 23.8104 - bpp: 3.0297 - mse: 6.3417e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.5389 - bpp: 2.9424 - mse: 6.2856e-04\n",
      "Epoch 22: loss did not improve from 21.49748\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 23.5389 - bpp: 2.9424 - mse: 6.2856e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.9919 - bpp: 2.8518 - mse: 4.6204e-04\n",
      "Epoch 23: loss improved from 21.49748 to 17.99194, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 17.9919 - bpp: 2.8518 - mse: 4.6204e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.9877 - bpp: 2.7815 - mse: 4.3354e-04\n",
      "Epoch 24: loss improved from 17.99194 to 16.98767, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 16.9877 - bpp: 2.7815 - mse: 4.3354e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.7584 - bpp: 2.7058 - mse: 4.5937e-04\n",
      "Epoch 25: loss did not improve from 16.98767\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 17.7584 - bpp: 2.7058 - mse: 4.5937e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.0993 - bpp: 2.6522 - mse: 5.6296e-04\n",
      "Epoch 26: loss did not improve from 16.98767\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 21.0993 - bpp: 2.6522 - mse: 5.6296e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.7790 - bpp: 2.5701 - mse: 4.3362e-04\n",
      "Epoch 27: loss improved from 16.98767 to 16.77902, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 16.7790 - bpp: 2.5701 - mse: 4.3362e-04\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.9433 - bpp: 2.4998 - mse: 4.1026e-04\n",
      "Epoch 28: loss improved from 16.77902 to 15.94328, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 15.9433 - bpp: 2.4998 - mse: 4.1026e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.9804 - bpp: 2.4380 - mse: 3.5225e-04\n",
      "Epoch 29: loss improved from 15.94328 to 13.98042, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 13.9804 - bpp: 2.4380 - mse: 3.5225e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.1016 - bpp: 2.3857 - mse: 4.1858e-04\n",
      "Epoch 30: loss did not improve from 13.98042\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 16.1016 - bpp: 2.3857 - mse: 4.1858e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.1490 - bpp: 2.3515 - mse: 3.9055e-04\n",
      "Epoch 31: loss did not improve from 13.98042\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 15.1490 - bpp: 2.3515 - mse: 3.9055e-04\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.0893 - bpp: 2.3156 - mse: 4.5086e-04\n",
      "Epoch 32: loss did not improve from 13.98042\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 17.0893 - bpp: 2.3156 - mse: 4.5086e-04\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.1859 - bpp: 2.2294 - mse: 3.3437e-04\n",
      "Epoch 33: loss improved from 13.98042 to 13.18590, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 13.1859 - bpp: 2.2294 - mse: 3.3437e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.0857 - bpp: 2.2342 - mse: 4.2272e-04\n",
      "Epoch 34: loss did not improve from 13.18590\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 16.0857 - bpp: 2.2342 - mse: 4.2272e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.5813 - bpp: 2.1332 - mse: 2.8834e-04\n",
      "Epoch 35: loss improved from 13.18590 to 11.58135, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 11.5813 - bpp: 2.1332 - mse: 2.8834e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.2837 - bpp: 2.1656 - mse: 7.0551e-04\n",
      "Epoch 36: loss did not improve from 11.58135\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 25.2837 - bpp: 2.1656 - mse: 7.0551e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 44.4312 - bpp: 2.1916 - mse: 0.0013\n",
      "Epoch 37: loss did not improve from 11.58135\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 44.4312 - bpp: 2.1916 - mse: 0.0013\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.1472 - bpp: 2.0662 - mse: 3.6868e-04\n",
      "Epoch 38: loss did not improve from 11.58135\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 14.1472 - bpp: 2.0662 - mse: 3.6868e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.3911 - bpp: 2.0387 - mse: 3.7697e-04\n",
      "Epoch 39: loss did not improve from 11.58135\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 14.3911 - bpp: 2.0387 - mse: 3.7697e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4024 - bpp: 1.9731 - mse: 2.8776e-04\n",
      "Epoch 40: loss improved from 11.58135 to 11.40236, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 44s 214ms/step - loss: 11.4024 - bpp: 1.9731 - mse: 2.8776e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8295 - bpp: 1.9494 - mse: 2.7100e-04\n",
      "Epoch 41: loss improved from 11.40236 to 10.82948, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 10.8295 - bpp: 1.9494 - mse: 2.7100e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.9520 - bpp: 1.9452 - mse: 3.0538e-04\n",
      "Epoch 42: loss did not improve from 10.82948\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 11.9520 - bpp: 1.9452 - mse: 3.0538e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7737 - bpp: 1.8937 - mse: 2.7100e-04\n",
      "Epoch 43: loss improved from 10.82948 to 10.77374, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 10.7737 - bpp: 1.8937 - mse: 2.7100e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6940 - bpp: 1.9191 - mse: 2.9831e-04\n",
      "Epoch 44: loss did not improve from 10.77374\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 11.6940 - bpp: 1.9191 - mse: 2.9831e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1050 - bpp: 1.8965 - mse: 2.5050e-04\n",
      "Epoch 45: loss improved from 10.77374 to 10.10499, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 10.1050 - bpp: 1.8965 - mse: 2.5050e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3859 - bpp: 1.9300 - mse: 3.1909e-04\n",
      "Epoch 46: loss did not improve from 10.10499\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 12.3859 - bpp: 1.9300 - mse: 3.1909e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.4692 - bpp: 1.8304 - mse: 2.3312e-04\n",
      "Epoch 47: loss improved from 10.10499 to 9.46923, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 9.4692 - bpp: 1.8304 - mse: 2.3312e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0107 - bpp: 1.8343 - mse: 2.4952e-04\n",
      "Epoch 48: loss did not improve from 9.46923\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 10.0107 - bpp: 1.8343 - mse: 2.4952e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2756 - bpp: 1.8516 - mse: 2.2656e-04\n",
      "Epoch 49: loss improved from 9.46923 to 9.27562, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 9.2756 - bpp: 1.8516 - mse: 2.2656e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.5061 - bpp: 1.9020 - mse: 2.6258e-04\n",
      "Epoch 50: loss did not improve from 9.27562\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 10.5061 - bpp: 1.9020 - mse: 2.6258e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1016 - bpp: 1.8934 - mse: 2.5049e-04\n",
      "Epoch 51: loss did not improve from 9.27562\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 10.1016 - bpp: 1.8934 - mse: 2.5049e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9254 - bpp: 1.8385 - mse: 2.4679e-04\n",
      "Epoch 52: loss did not improve from 9.27562\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 9.9254 - bpp: 1.8385 - mse: 2.4679e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3797 - bpp: 1.7999 - mse: 2.3132e-04\n",
      "Epoch 53: loss did not improve from 9.27562\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.3797 - bpp: 1.7999 - mse: 2.3132e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2652 - bpp: 1.8110 - mse: 2.2748e-04\n",
      "Epoch 54: loss improved from 9.27562 to 9.26523, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 9.2652 - bpp: 1.8110 - mse: 2.2748e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8294 - bpp: 1.8678 - mse: 2.4297e-04\n",
      "Epoch 55: loss did not improve from 9.26523\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 9.8294 - bpp: 1.8678 - mse: 2.4297e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6652 - bpp: 1.7720 - mse: 1.7985e-04\n",
      "Epoch 56: loss improved from 9.26523 to 7.66518, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 7.6652 - bpp: 1.7720 - mse: 1.7985e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6460 - bpp: 1.8795 - mse: 2.6753e-04\n",
      "Epoch 57: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 10.6460 - bpp: 1.8795 - mse: 2.6753e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1929 - bpp: 1.8267 - mse: 2.2480e-04\n",
      "Epoch 58: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.1929 - bpp: 1.8267 - mse: 2.2480e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9911 - bpp: 1.8487 - mse: 2.4849e-04\n",
      "Epoch 59: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 9.9911 - bpp: 1.8487 - mse: 2.4849e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 74.0617 - bpp: 2.4237 - mse: 0.0022\n",
      "Epoch 60: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 74.0617 - bpp: 2.4237 - mse: 0.0022\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.9355 - bpp: 2.2790 - mse: 4.7780e-04\n",
      "Epoch 61: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 17.9355 - bpp: 2.2790 - mse: 4.7780e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.1024 - bpp: 2.1029 - mse: 3.9671e-04\n",
      "Epoch 62: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 15.1024 - bpp: 2.1029 - mse: 3.9671e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3507 - bpp: 1.9896 - mse: 3.1620e-04\n",
      "Epoch 63: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 12.3507 - bpp: 1.9896 - mse: 3.1620e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.7880 - bpp: 2.0162 - mse: 2.9821e-04\n",
      "Epoch 64: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 11.7880 - bpp: 2.0162 - mse: 2.9821e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7043 - bpp: 1.9304 - mse: 2.6776e-04\n",
      "Epoch 65: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 10.7043 - bpp: 1.9304 - mse: 2.6776e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7395 - bpp: 1.9284 - mse: 2.6889e-04\n",
      "Epoch 66: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 10.7395 - bpp: 1.9284 - mse: 2.6889e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.9672 - bpp: 1.9495 - mse: 2.7520e-04\n",
      "Epoch 67: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 10.9672 - bpp: 1.9495 - mse: 2.7520e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1888 - bpp: 1.8869 - mse: 2.2284e-04\n",
      "Epoch 68: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 9.1888 - bpp: 1.8869 - mse: 2.2284e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7884 - bpp: 1.9392 - mse: 2.7006e-04\n",
      "Epoch 69: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 10.7884 - bpp: 1.9392 - mse: 2.7006e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3259 - bpp: 1.8897 - mse: 2.2693e-04\n",
      "Epoch 70: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 9.3259 - bpp: 1.8897 - mse: 2.2693e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3863 - bpp: 1.8829 - mse: 2.2899e-04\n",
      "Epoch 71: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 9.3863 - bpp: 1.8829 - mse: 2.2899e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8644 - bpp: 1.8376 - mse: 2.1444e-04\n",
      "Epoch 72: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 8.8644 - bpp: 1.8376 - mse: 2.1444e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7605 - bpp: 1.8468 - mse: 2.1099e-04\n",
      "Epoch 73: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 8.7605 - bpp: 1.8468 - mse: 2.1099e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8406 - bpp: 1.8680 - mse: 2.1279e-04\n",
      "Epoch 74: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 8.8406 - bpp: 1.8680 - mse: 2.1279e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2087 - bpp: 1.9132 - mse: 2.2264e-04\n",
      "Epoch 75: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 9.2087 - bpp: 1.9132 - mse: 2.2264e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2825 - bpp: 1.8922 - mse: 2.2554e-04\n",
      "Epoch 76: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 9.2825 - bpp: 1.8922 - mse: 2.2554e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8499 - bpp: 1.8265 - mse: 1.8382e-04\n",
      "Epoch 77: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 7.8499 - bpp: 1.8265 - mse: 1.8382e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2808 - bpp: 1.8273 - mse: 1.9694e-04\n",
      "Epoch 78: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 8.2808 - bpp: 1.8273 - mse: 1.9694e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 132.2179 - bpp: 2.4114 - mse: 0.0040\n",
      "Epoch 79: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 132.2179 - bpp: 2.4114 - mse: 0.0040\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.4536 - bpp: 2.3519 - mse: 7.0501e-04\n",
      "Epoch 80: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 25.4536 - bpp: 2.3519 - mse: 7.0501e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.3677 - bpp: 2.1929 - mse: 4.3258e-04\n",
      "Epoch 81: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 16.3677 - bpp: 2.1929 - mse: 4.3258e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.8465 - bpp: 2.0784 - mse: 3.8965e-04\n",
      "Epoch 82: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 14.8465 - bpp: 2.0784 - mse: 3.8965e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6998 - bpp: 2.0075 - mse: 2.9579e-04\n",
      "Epoch 83: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 11.6998 - bpp: 2.0075 - mse: 2.9579e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0622 - bpp: 1.9652 - mse: 2.7762e-04\n",
      "Epoch 84: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 11.0622 - bpp: 1.9652 - mse: 2.7762e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8829 - bpp: 1.9367 - mse: 2.4250e-04\n",
      "Epoch 85: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 9.8829 - bpp: 1.9367 - mse: 2.4250e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5194 - bpp: 1.9094 - mse: 2.3224e-04\n",
      "Epoch 86: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 9.5194 - bpp: 1.9094 - mse: 2.3224e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9109 - bpp: 1.8893 - mse: 2.1428e-04\n",
      "Epoch 87: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 8.9109 - bpp: 1.8893 - mse: 2.1428e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.2619 - bpp: 1.9296 - mse: 2.8480e-04\n",
      "Epoch 88: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 11.2619 - bpp: 1.9296 - mse: 2.8480e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4945 - bpp: 1.8780 - mse: 2.0192e-04\n",
      "Epoch 89: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 8.4945 - bpp: 1.8780 - mse: 2.0192e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9322 - bpp: 1.8828 - mse: 2.1513e-04\n",
      "Epoch 90: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 8.9322 - bpp: 1.8828 - mse: 2.1513e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6233 - bpp: 1.8857 - mse: 2.3613e-04\n",
      "Epoch 91: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 9.6233 - bpp: 1.8857 - mse: 2.3613e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.6609 - bpp: 1.8579 - mse: 2.0761e-04\n",
      "Epoch 92: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 8.6609 - bpp: 1.8579 - mse: 2.0761e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7665 - bpp: 1.8843 - mse: 2.1003e-04\n",
      "Epoch 93: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 8.7665 - bpp: 1.8843 - mse: 2.1003e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9305 - bpp: 1.8288 - mse: 1.8621e-04\n",
      "Epoch 94: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 7.9305 - bpp: 1.8288 - mse: 1.8621e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0298 - bpp: 1.8454 - mse: 1.8873e-04\n",
      "Epoch 95: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 8.0298 - bpp: 1.8454 - mse: 1.8873e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3686 - bpp: 1.8583 - mse: 1.9868e-04\n",
      "Epoch 96: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 8.3686 - bpp: 1.8583 - mse: 1.9868e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9647 - bpp: 1.8718 - mse: 1.8594e-04\n",
      "Epoch 97: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 7.9647 - bpp: 1.8718 - mse: 1.8594e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1809 - bpp: 1.9098 - mse: 1.9138e-04\n",
      "Epoch 98: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 8.1809 - bpp: 1.9098 - mse: 1.9138e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3039 - bpp: 1.8515 - mse: 1.9691e-04\n",
      "Epoch 99: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 8.3039 - bpp: 1.8515 - mse: 1.9691e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2379 - bpp: 1.8652 - mse: 1.9448e-04\n",
      "Epoch 100: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 8.2379 - bpp: 1.8652 - mse: 1.9448e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6700 - bpp: 1.8571 - mse: 1.7739e-04\n",
      "Epoch 101: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 7.6700 - bpp: 1.8571 - mse: 1.7739e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4883 - bpp: 1.8585 - mse: 2.0233e-04\n",
      "Epoch 102: loss did not improve from 7.66518\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 8.4883 - bpp: 1.8585 - mse: 2.0233e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5098 - bpp: 1.7525 - mse: 1.4518e-04\n",
      "Epoch 103: loss improved from 7.66518 to 6.50977, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 6.5098 - bpp: 1.7525 - mse: 1.4518e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1041 - bpp: 1.8608 - mse: 1.9053e-04\n",
      "Epoch 104: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 8.1041 - bpp: 1.8608 - mse: 1.9053e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3195 - bpp: 1.8860 - mse: 1.9633e-04\n",
      "Epoch 105: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 8.3195 - bpp: 1.8860 - mse: 1.9633e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0641 - bpp: 1.9082 - mse: 1.8786e-04\n",
      "Epoch 106: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 8.0641 - bpp: 1.9082 - mse: 1.8786e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9222 - bpp: 1.8872 - mse: 1.8418e-04\n",
      "Epoch 107: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 47s 227ms/step - loss: 7.9222 - bpp: 1.8872 - mse: 1.8418e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0358 - bpp: 1.8438 - mse: 1.5845e-04\n",
      "Epoch 108: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 7.0358 - bpp: 1.8438 - mse: 1.5845e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9470 - bpp: 1.9396 - mse: 1.8333e-04\n",
      "Epoch 109: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 7.9470 - bpp: 1.9396 - mse: 1.8333e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7413 - bpp: 1.8696 - mse: 1.7919e-04\n",
      "Epoch 110: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 7.7413 - bpp: 1.8696 - mse: 1.7919e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0539 - bpp: 1.8278 - mse: 1.5949e-04\n",
      "Epoch 111: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 7.0539 - bpp: 1.8278 - mse: 1.5949e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8156 - bpp: 1.9053 - mse: 2.4140e-04\n",
      "Epoch 112: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 9.8156 - bpp: 1.9053 - mse: 2.4140e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.4155 - bpp: 1.9211 - mse: 4.1182e-04\n",
      "Epoch 113: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 15.4155 - bpp: 1.9211 - mse: 4.1182e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7678 - bpp: 1.8460 - mse: 1.8072e-04\n",
      "Epoch 114: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 7.7678 - bpp: 1.8460 - mse: 1.8072e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1018 - bpp: 1.8074 - mse: 1.6157e-04\n",
      "Epoch 115: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 7.1018 - bpp: 1.8074 - mse: 1.6157e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5482 - bpp: 1.8180 - mse: 1.7487e-04\n",
      "Epoch 116: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 7.5482 - bpp: 1.8180 - mse: 1.7487e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4819 - bpp: 1.8779 - mse: 1.7102e-04\n",
      "Epoch 117: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 7.4819 - bpp: 1.8779 - mse: 1.7102e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7826 - bpp: 1.8231 - mse: 1.5135e-04\n",
      "Epoch 118: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 6.7826 - bpp: 1.8231 - mse: 1.5135e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1646 - bpp: 1.8559 - mse: 1.6201e-04\n",
      "Epoch 119: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 7.1646 - bpp: 1.8559 - mse: 1.6201e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3665 - bpp: 1.9284 - mse: 1.9648e-04\n",
      "Epoch 120: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 8.3665 - bpp: 1.9284 - mse: 1.9648e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0892 - bpp: 1.8256 - mse: 1.6063e-04\n",
      "Epoch 121: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 7.0892 - bpp: 1.8256 - mse: 1.6063e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5147 - bpp: 1.8545 - mse: 1.7274e-04\n",
      "Epoch 122: loss did not improve from 6.50977\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 7.5147 - bpp: 1.8545 - mse: 1.7274e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0535 - bpp: 1.7913 - mse: 1.3007e-04\n",
      "Epoch 123: loss improved from 6.50977 to 6.05346, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.0535 - bpp: 1.7913 - mse: 1.3007e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4098 - bpp: 1.8008 - mse: 1.4065e-04\n",
      "Epoch 124: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 6.4098 - bpp: 1.8008 - mse: 1.4065e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7768 - bpp: 1.8191 - mse: 1.5130e-04\n",
      "Epoch 125: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 6.7768 - bpp: 1.8191 - mse: 1.5130e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3518 - bpp: 1.8202 - mse: 1.3829e-04\n",
      "Epoch 126: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 6.3518 - bpp: 1.8202 - mse: 1.3829e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8551 - bpp: 1.8844 - mse: 1.5169e-04\n",
      "Epoch 127: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.8551 - bpp: 1.8844 - mse: 1.5169e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1517 - bpp: 1.7876 - mse: 1.3318e-04\n",
      "Epoch 128: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 6.1517 - bpp: 1.7876 - mse: 1.3318e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 50.5086 - bpp: 2.0719 - mse: 0.0015\n",
      "Epoch 129: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 50.5086 - bpp: 2.0719 - mse: 0.0015\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.0060 - bpp: 2.3514 - mse: 5.3878e-04\n",
      "Epoch 130: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 20.0060 - bpp: 2.3514 - mse: 5.3878e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1386 - bpp: 2.1936 - mse: 2.4246e-04\n",
      "Epoch 131: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 10.1386 - bpp: 2.1936 - mse: 2.4246e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8112 - bpp: 1.9853 - mse: 1.7779e-04\n",
      "Epoch 132: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 7.8112 - bpp: 1.9853 - mse: 1.7779e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4494 - bpp: 2.0190 - mse: 1.9624e-04\n",
      "Epoch 133: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 8.4494 - bpp: 2.0190 - mse: 1.9624e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5789 - bpp: 2.0031 - mse: 2.0068e-04\n",
      "Epoch 134: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 8.5789 - bpp: 2.0031 - mse: 2.0068e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2265 - bpp: 1.8918 - mse: 1.6280e-04\n",
      "Epoch 135: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 7.2265 - bpp: 1.8918 - mse: 1.6280e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0381 - bpp: 1.9231 - mse: 1.5610e-04\n",
      "Epoch 136: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 7.0381 - bpp: 1.9231 - mse: 1.5610e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9305 - bpp: 1.9002 - mse: 1.5351e-04\n",
      "Epoch 137: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 6.9305 - bpp: 1.9002 - mse: 1.5351e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7819 - bpp: 1.9104 - mse: 1.4867e-04\n",
      "Epoch 138: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 6.7819 - bpp: 1.9104 - mse: 1.4867e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5071 - bpp: 1.8768 - mse: 1.7182e-04\n",
      "Epoch 139: loss did not improve from 6.05346\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 7.5071 - bpp: 1.8768 - mse: 1.7182e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7830 - bpp: 1.8239 - mse: 1.2082e-04\n",
      "Epoch 140: loss improved from 6.05346 to 5.78297, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.7830 - bpp: 1.8239 - mse: 1.2082e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5685 - bpp: 1.9471 - mse: 1.4104e-04\n",
      "Epoch 141: loss did not improve from 5.78297\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 6.5685 - bpp: 1.9471 - mse: 1.4104e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9297 - bpp: 1.8759 - mse: 1.5423e-04\n",
      "Epoch 142: loss did not improve from 5.78297\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 6.9297 - bpp: 1.8759 - mse: 1.5423e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5684 - bpp: 1.8844 - mse: 1.4294e-04\n",
      "Epoch 143: loss did not improve from 5.78297\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 6.5684 - bpp: 1.8844 - mse: 1.4294e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7476 - bpp: 1.9039 - mse: 1.4782e-04\n",
      "Epoch 144: loss did not improve from 5.78297\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 6.7476 - bpp: 1.9039 - mse: 1.4782e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3802 - bpp: 1.9010 - mse: 1.3669e-04\n",
      "Epoch 145: loss did not improve from 5.78297\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 6.3802 - bpp: 1.9010 - mse: 1.3669e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5621 - bpp: 1.8199 - mse: 1.1420e-04\n",
      "Epoch 146: loss improved from 5.78297 to 5.56206, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 5.5621 - bpp: 1.8199 - mse: 1.1420e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3765 - bpp: 1.9622 - mse: 1.6523e-04\n",
      "Epoch 147: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 7.3765 - bpp: 1.9622 - mse: 1.6523e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5832 - bpp: 1.9241 - mse: 1.4218e-04\n",
      "Epoch 148: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 6.5832 - bpp: 1.9241 - mse: 1.4218e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8939 - bpp: 1.8869 - mse: 1.5280e-04\n",
      "Epoch 149: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 6.8939 - bpp: 1.8869 - mse: 1.5280e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3425 - bpp: 1.8820 - mse: 1.6664e-04\n",
      "Epoch 150: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 7.3425 - bpp: 1.8820 - mse: 1.6664e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9899 - bpp: 1.8796 - mse: 1.5595e-04\n",
      "Epoch 151: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 6.9899 - bpp: 1.8796 - mse: 1.5595e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1288 - bpp: 1.8979 - mse: 1.5964e-04\n",
      "Epoch 152: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 7.1288 - bpp: 1.8979 - mse: 1.5964e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1972 - bpp: 1.8537 - mse: 1.3255e-04\n",
      "Epoch 153: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 6.1972 - bpp: 1.8537 - mse: 1.3255e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9715 - bpp: 1.8191 - mse: 1.2672e-04\n",
      "Epoch 154: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 5.9715 - bpp: 1.8191 - mse: 1.2672e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1114 - bpp: 1.8383 - mse: 1.3041e-04\n",
      "Epoch 155: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 6.1114 - bpp: 1.8383 - mse: 1.3041e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2374 - bpp: 1.8933 - mse: 1.3257e-04\n",
      "Epoch 156: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.2374 - bpp: 1.8933 - mse: 1.3257e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2846 - bpp: 1.9054 - mse: 1.6416e-04\n",
      "Epoch 157: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 7.2846 - bpp: 1.9054 - mse: 1.6416e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1875 - bpp: 1.8292 - mse: 1.3301e-04\n",
      "Epoch 158: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.1875 - bpp: 1.8292 - mse: 1.3301e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4517 - bpp: 1.8512 - mse: 1.4039e-04\n",
      "Epoch 159: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 6.4517 - bpp: 1.8512 - mse: 1.4039e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7090 - bpp: 1.8115 - mse: 1.1894e-04\n",
      "Epoch 160: loss did not improve from 5.56206\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.7090 - bpp: 1.8115 - mse: 1.1894e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3831 - bpp: 1.8002 - mse: 1.0934e-04\n",
      "Epoch 161: loss improved from 5.56206 to 5.38314, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.3831 - bpp: 1.8002 - mse: 1.0934e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8514 - bpp: 1.8322 - mse: 1.2265e-04\n",
      "Epoch 162: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 5.8514 - bpp: 1.8322 - mse: 1.2265e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2485 - bpp: 1.8755 - mse: 1.3345e-04\n",
      "Epoch 163: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 6.2485 - bpp: 1.8755 - mse: 1.3345e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8640 - bpp: 1.8543 - mse: 1.5288e-04\n",
      "Epoch 164: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 6.8640 - bpp: 1.8543 - mse: 1.5288e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0210 - bpp: 1.9095 - mse: 1.5599e-04\n",
      "Epoch 165: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 7.0210 - bpp: 1.9095 - mse: 1.5599e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1576 - bpp: 1.8874 - mse: 1.3032e-04\n",
      "Epoch 166: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 6.1576 - bpp: 1.8874 - mse: 1.3032e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1199 - bpp: 1.8826 - mse: 2.2087e-04\n",
      "Epoch 167: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 9.1199 - bpp: 1.8826 - mse: 2.2087e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 27.0148 - bpp: 2.1072 - mse: 7.6012e-04\n",
      "Epoch 168: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 27.0148 - bpp: 2.1072 - mse: 7.6012e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8080 - bpp: 2.0119 - mse: 1.7688e-04\n",
      "Epoch 169: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 7.8080 - bpp: 2.0119 - mse: 1.7688e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 36.8615 - bpp: 2.1068 - mse: 0.0011\n",
      "Epoch 170: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 36.8615 - bpp: 2.1068 - mse: 0.0011\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.1442 - bpp: 2.1971 - mse: 3.3408e-04\n",
      "Epoch 171: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 13.1442 - bpp: 2.1971 - mse: 3.3408e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1517 - bpp: 2.0192 - mse: 1.8715e-04\n",
      "Epoch 172: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 8.1517 - bpp: 2.0192 - mse: 1.8715e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5746 - bpp: 1.9637 - mse: 1.7123e-04\n",
      "Epoch 173: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 7.5746 - bpp: 1.9637 - mse: 1.7123e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9529 - bpp: 1.9180 - mse: 1.5365e-04\n",
      "Epoch 174: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 6.9529 - bpp: 1.9180 - mse: 1.5365e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3947 - bpp: 1.9629 - mse: 1.6577e-04\n",
      "Epoch 175: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 7.3947 - bpp: 1.9629 - mse: 1.6577e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8853 - bpp: 1.9168 - mse: 1.5163e-04\n",
      "Epoch 176: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.8853 - bpp: 1.9168 - mse: 1.5163e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0214 - bpp: 1.9656 - mse: 1.5429e-04\n",
      "Epoch 177: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 7.0214 - bpp: 1.9656 - mse: 1.5429e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1447 - bpp: 1.8540 - mse: 1.3094e-04\n",
      "Epoch 178: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 6.1447 - bpp: 1.8540 - mse: 1.3094e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5993 - bpp: 1.8619 - mse: 1.4457e-04\n",
      "Epoch 179: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 6.5993 - bpp: 1.8619 - mse: 1.4457e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4418 - bpp: 1.8881 - mse: 1.3897e-04\n",
      "Epoch 180: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 6.4418 - bpp: 1.8881 - mse: 1.3897e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5702 - bpp: 1.8978 - mse: 1.4259e-04\n",
      "Epoch 181: loss did not improve from 5.38314\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 6.5702 - bpp: 1.8978 - mse: 1.4259e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2469 - bpp: 1.7911 - mse: 1.0546e-04\n",
      "Epoch 182: loss improved from 5.38314 to 5.24685, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.2469 - bpp: 1.7911 - mse: 1.0546e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9564 - bpp: 1.9194 - mse: 1.5372e-04\n",
      "Epoch 183: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 6.9564 - bpp: 1.9194 - mse: 1.5372e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0273 - bpp: 1.8873 - mse: 1.2634e-04\n",
      "Epoch 184: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 6.0273 - bpp: 1.8873 - mse: 1.2634e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3834 - bpp: 1.8852 - mse: 1.3727e-04\n",
      "Epoch 185: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 6.3834 - bpp: 1.8852 - mse: 1.3727e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0378 - bpp: 1.8350 - mse: 1.2826e-04\n",
      "Epoch 186: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 6.0378 - bpp: 1.8350 - mse: 1.2826e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2226 - bpp: 1.8841 - mse: 1.3240e-04\n",
      "Epoch 187: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 6.2226 - bpp: 1.8841 - mse: 1.3240e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6495 - bpp: 1.9186 - mse: 1.4438e-04\n",
      "Epoch 188: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 6.6495 - bpp: 1.9186 - mse: 1.4438e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8983 - bpp: 1.8636 - mse: 1.2313e-04\n",
      "Epoch 189: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.8983 - bpp: 1.8636 - mse: 1.2313e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6159 - bpp: 1.8310 - mse: 1.1550e-04\n",
      "Epoch 190: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.6159 - bpp: 1.8310 - mse: 1.1550e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4189 - bpp: 1.8184 - mse: 1.0988e-04\n",
      "Epoch 191: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 5.4189 - bpp: 1.8184 - mse: 1.0988e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0747 - bpp: 1.8126 - mse: 1.3007e-04\n",
      "Epoch 192: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 6.0747 - bpp: 1.8126 - mse: 1.3007e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4979 - bpp: 1.8148 - mse: 1.1240e-04\n",
      "Epoch 193: loss did not improve from 5.24685\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.4979 - bpp: 1.8148 - mse: 1.1240e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1542 - bpp: 1.7968 - mse: 1.0246e-04\n",
      "Epoch 194: loss improved from 5.24685 to 5.15419, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 5.1542 - bpp: 1.7968 - mse: 1.0246e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6449 - bpp: 1.8519 - mse: 1.1575e-04\n",
      "Epoch 195: loss did not improve from 5.15419\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 5.6449 - bpp: 1.8519 - mse: 1.1575e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1739 - bpp: 1.8377 - mse: 1.3233e-04\n",
      "Epoch 196: loss did not improve from 5.15419\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 6.1739 - bpp: 1.8377 - mse: 1.3233e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0997 - bpp: 1.7663 - mse: 1.0173e-04\n",
      "Epoch 197: loss improved from 5.15419 to 5.09974, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.0997 - bpp: 1.7663 - mse: 1.0173e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5804 - bpp: 1.7929 - mse: 1.1559e-04\n",
      "Epoch 198: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 5.5804 - bpp: 1.7929 - mse: 1.1559e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9532 - bpp: 1.8586 - mse: 1.2496e-04\n",
      "Epoch 199: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 5.9532 - bpp: 1.8586 - mse: 1.2496e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2194 - bpp: 1.8979 - mse: 3.4550e-04\n",
      "Epoch 200: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 13.2194 - bpp: 1.8979 - mse: 3.4550e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7172 - bpp: 1.9563 - mse: 1.7581e-04\n",
      "Epoch 201: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 7.7172 - bpp: 1.9563 - mse: 1.7581e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2123 - bpp: 1.9824 - mse: 1.5960e-04\n",
      "Epoch 202: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 7.2123 - bpp: 1.9824 - mse: 1.5960e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9365 - bpp: 1.8353 - mse: 1.2516e-04\n",
      "Epoch 203: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.9365 - bpp: 1.8353 - mse: 1.2516e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8371 - bpp: 1.8406 - mse: 1.2196e-04\n",
      "Epoch 204: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 5.8371 - bpp: 1.8406 - mse: 1.2196e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2002 - bpp: 1.9030 - mse: 1.3114e-04\n",
      "Epoch 205: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.2002 - bpp: 1.9030 - mse: 1.3114e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1764 - bpp: 1.8539 - mse: 1.3191e-04\n",
      "Epoch 206: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 6.1764 - bpp: 1.8539 - mse: 1.3191e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6692 - bpp: 1.7696 - mse: 1.1901e-04\n",
      "Epoch 207: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 5.6692 - bpp: 1.7696 - mse: 1.1901e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4982 - bpp: 1.7864 - mse: 1.1328e-04\n",
      "Epoch 208: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.4982 - bpp: 1.7864 - mse: 1.1328e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2551 - bpp: 1.8191 - mse: 1.0486e-04\n",
      "Epoch 209: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 49s 237ms/step - loss: 5.2551 - bpp: 1.8191 - mse: 1.0486e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1246 - bpp: 1.7628 - mse: 1.0259e-04\n",
      "Epoch 210: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.1246 - bpp: 1.7628 - mse: 1.0259e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5891 - bpp: 1.8675 - mse: 1.4409e-04\n",
      "Epoch 211: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 6.5891 - bpp: 1.8675 - mse: 1.4409e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5791 - bpp: 1.7971 - mse: 1.1542e-04\n",
      "Epoch 212: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 5.5791 - bpp: 1.7971 - mse: 1.1542e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5096 - bpp: 1.7826 - mse: 1.1374e-04\n",
      "Epoch 213: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 5.5096 - bpp: 1.7826 - mse: 1.1374e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3777 - bpp: 1.7815 - mse: 1.0975e-04\n",
      "Epoch 214: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 5.3777 - bpp: 1.7815 - mse: 1.0975e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.3097 - bpp: 2.0407 - mse: 4.6597e-04\n",
      "Epoch 215: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 17.3097 - bpp: 2.0407 - mse: 4.6597e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1753 - bpp: 1.9271 - mse: 1.6016e-04\n",
      "Epoch 216: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 7.1753 - bpp: 1.9271 - mse: 1.6016e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1142 - bpp: 1.8722 - mse: 1.2946e-04\n",
      "Epoch 217: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 47s 229ms/step - loss: 6.1142 - bpp: 1.8722 - mse: 1.2946e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9310 - bpp: 1.8832 - mse: 1.2353e-04\n",
      "Epoch 218: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.9310 - bpp: 1.8832 - mse: 1.2353e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5596 - bpp: 1.8162 - mse: 1.1424e-04\n",
      "Epoch 219: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.5596 - bpp: 1.8162 - mse: 1.1424e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9216 - bpp: 1.8365 - mse: 1.2467e-04\n",
      "Epoch 220: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.9216 - bpp: 1.8365 - mse: 1.2467e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1944 - bpp: 1.8492 - mse: 1.3261e-04\n",
      "Epoch 221: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 6.1944 - bpp: 1.8492 - mse: 1.3261e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8626 - bpp: 1.8746 - mse: 1.2171e-04\n",
      "Epoch 222: loss did not improve from 5.09974\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 5.8626 - bpp: 1.8746 - mse: 1.2171e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6526 - bpp: 1.7396 - mse: 8.8897e-05\n",
      "Epoch 223: loss improved from 5.09974 to 4.65259, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.6526 - bpp: 1.7396 - mse: 8.8897e-05\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6796 - bpp: 1.8426 - mse: 1.1710e-04\n",
      "Epoch 224: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 5.6796 - bpp: 1.8426 - mse: 1.1710e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5032 - bpp: 1.8372 - mse: 1.1188e-04\n",
      "Epoch 225: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.5032 - bpp: 1.8372 - mse: 1.1188e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3572 - bpp: 1.7659 - mse: 1.0960e-04\n",
      "Epoch 226: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.3572 - bpp: 1.7659 - mse: 1.0960e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0680 - bpp: 1.7297 - mse: 1.0188e-04\n",
      "Epoch 227: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.0680 - bpp: 1.7297 - mse: 1.0188e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4425 - bpp: 1.9138 - mse: 1.3821e-04\n",
      "Epoch 228: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 6.4425 - bpp: 1.9138 - mse: 1.3821e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4081 - bpp: 1.7899 - mse: 1.1042e-04\n",
      "Epoch 229: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.4081 - bpp: 1.7899 - mse: 1.1042e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0493 - bpp: 1.8435 - mse: 1.2835e-04\n",
      "Epoch 230: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 6.0493 - bpp: 1.8435 - mse: 1.2835e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3154 - bpp: 1.7618 - mse: 1.0845e-04\n",
      "Epoch 231: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.3154 - bpp: 1.7618 - mse: 1.0845e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1028 - bpp: 1.7662 - mse: 1.0182e-04\n",
      "Epoch 232: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.1028 - bpp: 1.7662 - mse: 1.0182e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2927 - bpp: 1.7931 - mse: 1.0680e-04\n",
      "Epoch 233: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 5.2927 - bpp: 1.7931 - mse: 1.0680e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5817 - bpp: 1.8472 - mse: 1.1397e-04\n",
      "Epoch 234: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.5817 - bpp: 1.8472 - mse: 1.1397e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 48.9440 - bpp: 2.0361 - mse: 0.0014\n",
      "Epoch 235: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 48.9440 - bpp: 2.0361 - mse: 0.0014\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.9874 - bpp: 2.0996 - mse: 3.3227e-04\n",
      "Epoch 236: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 12.9874 - bpp: 2.0996 - mse: 3.3227e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2081 - bpp: 2.0639 - mse: 2.1802e-04\n",
      "Epoch 237: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 9.2081 - bpp: 2.0639 - mse: 2.1802e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1329 - bpp: 1.9695 - mse: 1.5757e-04\n",
      "Epoch 238: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 7.1329 - bpp: 1.9695 - mse: 1.5757e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2939 - bpp: 1.8903 - mse: 1.3439e-04\n",
      "Epoch 239: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 6.2939 - bpp: 1.8903 - mse: 1.3439e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1999 - bpp: 1.7870 - mse: 1.0415e-04\n",
      "Epoch 240: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 5.1999 - bpp: 1.7870 - mse: 1.0415e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8071 - bpp: 1.8768 - mse: 1.5046e-04\n",
      "Epoch 241: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 6.8071 - bpp: 1.8768 - mse: 1.5046e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7850 - bpp: 1.8087 - mse: 1.2135e-04\n",
      "Epoch 242: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 5.7850 - bpp: 1.8087 - mse: 1.2135e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7076 - bpp: 1.8125 - mse: 1.1887e-04\n",
      "Epoch 243: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.7076 - bpp: 1.8125 - mse: 1.1887e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2090 - bpp: 1.8741 - mse: 1.3229e-04\n",
      "Epoch 244: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 6.2090 - bpp: 1.8741 - mse: 1.3229e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5712 - bpp: 1.8340 - mse: 1.1405e-04\n",
      "Epoch 245: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.5712 - bpp: 1.8340 - mse: 1.1405e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9151 - bpp: 1.8211 - mse: 1.2494e-04\n",
      "Epoch 246: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 5.9151 - bpp: 1.8211 - mse: 1.2494e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4162 - bpp: 1.8191 - mse: 1.0977e-04\n",
      "Epoch 247: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.4162 - bpp: 1.8191 - mse: 1.0977e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4730 - bpp: 1.8078 - mse: 1.1185e-04\n",
      "Epoch 248: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 5.4730 - bpp: 1.8078 - mse: 1.1185e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3445 - bpp: 1.7979 - mse: 1.0823e-04\n",
      "Epoch 249: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.3445 - bpp: 1.7979 - mse: 1.0823e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9473 - bpp: 1.8699 - mse: 1.2443e-04\n",
      "Epoch 250: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.9473 - bpp: 1.8699 - mse: 1.2443e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7773 - bpp: 1.8357 - mse: 1.2029e-04\n",
      "Epoch 251: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 5.7773 - bpp: 1.8357 - mse: 1.2029e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6596 - bpp: 1.8313 - mse: 1.1683e-04\n",
      "Epoch 252: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 5.6596 - bpp: 1.8313 - mse: 1.1683e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0387 - bpp: 1.7742 - mse: 9.9626e-05\n",
      "Epoch 253: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 5.0387 - bpp: 1.7742 - mse: 9.9626e-05\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1168 - bpp: 1.8129 - mse: 1.0083e-04\n",
      "Epoch 254: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.1168 - bpp: 1.8129 - mse: 1.0083e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8468 - bpp: 1.7419 - mse: 9.4755e-05\n",
      "Epoch 255: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.8468 - bpp: 1.7419 - mse: 9.4755e-05\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6628 - bpp: 1.8589 - mse: 1.1609e-04\n",
      "Epoch 256: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 48s 234ms/step - loss: 5.6628 - bpp: 1.8589 - mse: 1.1609e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3748 - bpp: 1.7855 - mse: 1.0954e-04\n",
      "Epoch 257: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.3748 - bpp: 1.7855 - mse: 1.0954e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1763 - bpp: 1.8769 - mse: 1.6173e-04\n",
      "Epoch 258: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 7.1763 - bpp: 1.8769 - mse: 1.6173e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4348 - bpp: 1.8344 - mse: 1.0987e-04\n",
      "Epoch 259: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.4348 - bpp: 1.8344 - mse: 1.0987e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2235 - bpp: 1.7699 - mse: 1.0540e-04\n",
      "Epoch 260: loss did not improve from 4.65259\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 5.2235 - bpp: 1.7699 - mse: 1.0540e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6365 - bpp: 1.7518 - mse: 8.8032e-05\n",
      "Epoch 261: loss improved from 4.65259 to 4.63645, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.6365 - bpp: 1.7518 - mse: 8.8032e-05\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8466 - bpp: 1.7841 - mse: 9.3462e-05\n",
      "Epoch 262: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 4.8466 - bpp: 1.7841 - mse: 9.3462e-05\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 24.3327 - bpp: 2.1029 - mse: 6.7840e-04\n",
      "Epoch 263: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 24.3327 - bpp: 2.1029 - mse: 6.7840e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2656 - bpp: 2.0009 - mse: 1.6066e-04\n",
      "Epoch 264: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 7.2656 - bpp: 2.0009 - mse: 1.6066e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6160 - bpp: 1.9967 - mse: 1.4097e-04\n",
      "Epoch 265: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 6.6160 - bpp: 1.9967 - mse: 1.4097e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1551 - bpp: 1.9496 - mse: 1.2834e-04\n",
      "Epoch 266: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 6.1551 - bpp: 1.9496 - mse: 1.2834e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5311 - bpp: 1.8756 - mse: 1.1156e-04\n",
      "Epoch 267: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 5.5311 - bpp: 1.8756 - mse: 1.1156e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8899 - bpp: 1.8524 - mse: 1.5373e-04\n",
      "Epoch 268: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 6.8899 - bpp: 1.8524 - mse: 1.5373e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0369 - bpp: 1.9618 - mse: 2.4643e-04\n",
      "Epoch 269: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 10.0369 - bpp: 1.9618 - mse: 2.4643e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7884 - bpp: 1.8769 - mse: 1.1937e-04\n",
      "Epoch 270: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.7884 - bpp: 1.8769 - mse: 1.1937e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2220 - bpp: 1.8413 - mse: 1.0317e-04\n",
      "Epoch 271: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.2220 - bpp: 1.8413 - mse: 1.0317e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3768 - bpp: 1.8361 - mse: 1.0806e-04\n",
      "Epoch 272: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 5.3768 - bpp: 1.8361 - mse: 1.0806e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5846 - bpp: 1.8544 - mse: 1.1384e-04\n",
      "Epoch 273: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 227ms/step - loss: 5.5846 - bpp: 1.8544 - mse: 1.1384e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2730 - bpp: 1.8312 - mse: 1.0504e-04\n",
      "Epoch 274: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.2730 - bpp: 1.8312 - mse: 1.0504e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1941 - bpp: 1.8080 - mse: 1.0334e-04\n",
      "Epoch 275: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.1941 - bpp: 1.8080 - mse: 1.0334e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1080 - bpp: 1.7992 - mse: 1.0098e-04\n",
      "Epoch 276: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 5.1080 - bpp: 1.7992 - mse: 1.0098e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0108 - bpp: 1.8066 - mse: 9.7786e-05\n",
      "Epoch 277: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.0108 - bpp: 1.8066 - mse: 9.7786e-05\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9370 - bpp: 1.7964 - mse: 9.5842e-05\n",
      "Epoch 278: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.9370 - bpp: 1.7964 - mse: 9.5842e-05\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3492 - bpp: 1.8784 - mse: 1.0592e-04\n",
      "Epoch 279: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 5.3492 - bpp: 1.8784 - mse: 1.0592e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3407 - bpp: 1.8250 - mse: 1.0729e-04\n",
      "Epoch 280: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.3407 - bpp: 1.8250 - mse: 1.0729e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4215 - bpp: 1.8076 - mse: 1.1029e-04\n",
      "Epoch 281: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.4215 - bpp: 1.8076 - mse: 1.1029e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5662 - bpp: 1.8612 - mse: 1.1307e-04\n",
      "Epoch 282: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 5.5662 - bpp: 1.8612 - mse: 1.1307e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0746 - bpp: 1.7723 - mse: 1.0078e-04\n",
      "Epoch 283: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.0746 - bpp: 1.7723 - mse: 1.0078e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9822 - bpp: 1.7800 - mse: 9.7723e-05\n",
      "Epoch 284: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 4.9822 - bpp: 1.7800 - mse: 9.7723e-05\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1681 - bpp: 1.8410 - mse: 1.0153e-04\n",
      "Epoch 285: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.1681 - bpp: 1.8410 - mse: 1.0153e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6159 - bpp: 1.8251 - mse: 1.1569e-04\n",
      "Epoch 286: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.6159 - bpp: 1.8251 - mse: 1.1569e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3661 - bpp: 1.7924 - mse: 1.0906e-04\n",
      "Epoch 287: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 5.3661 - bpp: 1.7924 - mse: 1.0906e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8471 - bpp: 1.8236 - mse: 9.2271e-05\n",
      "Epoch 288: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.8471 - bpp: 1.8236 - mse: 9.2271e-05\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5587 - bpp: 1.8173 - mse: 1.1418e-04\n",
      "Epoch 289: loss did not improve from 4.63645\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 5.5587 - bpp: 1.8173 - mse: 1.1418e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6346 - bpp: 1.7052 - mse: 8.9399e-05\n",
      "Epoch 290: loss improved from 4.63645 to 4.63461, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.6346 - bpp: 1.7052 - mse: 8.9399e-05\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0063 - bpp: 1.7951 - mse: 9.7998e-05\n",
      "Epoch 291: loss did not improve from 4.63461\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 5.0063 - bpp: 1.7951 - mse: 9.7998e-05\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4967 - bpp: 1.8348 - mse: 1.1175e-04\n",
      "Epoch 292: loss did not improve from 4.63461\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 5.4967 - bpp: 1.8348 - mse: 1.1175e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1174 - bpp: 1.8002 - mse: 1.0123e-04\n",
      "Epoch 293: loss did not improve from 4.63461\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 5.1174 - bpp: 1.8002 - mse: 1.0123e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2590 - bpp: 1.7873 - mse: 1.0595e-04\n",
      "Epoch 294: loss did not improve from 4.63461\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 5.2590 - bpp: 1.7873 - mse: 1.0595e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6550 - bpp: 1.7355 - mse: 8.9096e-05\n",
      "Epoch 295: loss did not improve from 4.63461\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.6550 - bpp: 1.7355 - mse: 8.9096e-05\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5917 - bpp: 1.7306 - mse: 8.7313e-05\n",
      "Epoch 296: loss improved from 4.63461 to 4.59173, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.5917 - bpp: 1.7306 - mse: 8.7313e-05\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8238 - bpp: 1.7487 - mse: 9.3845e-05\n",
      "Epoch 297: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.8238 - bpp: 1.7487 - mse: 9.3845e-05\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 20.8945 - bpp: 1.8621 - mse: 5.8082e-04\n",
      "Epoch 298: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 20.8945 - bpp: 1.8621 - mse: 5.8082e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.4062 - bpp: 2.0079 - mse: 1.9526e-04\n",
      "Epoch 299: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 8.4062 - bpp: 2.0079 - mse: 1.9526e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8320 - bpp: 1.8931 - mse: 1.2020e-04\n",
      "Epoch 300: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.8320 - bpp: 1.8931 - mse: 1.2020e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9028 - bpp: 1.8078 - mse: 9.4452e-05\n",
      "Epoch 301: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.9028 - bpp: 1.8078 - mse: 9.4452e-05\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0438 - bpp: 1.7678 - mse: 9.9974e-05\n",
      "Epoch 302: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.0438 - bpp: 1.7678 - mse: 9.9974e-05\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4554 - bpp: 1.8357 - mse: 1.1047e-04\n",
      "Epoch 303: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.4554 - bpp: 1.8357 - mse: 1.1047e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4004 - bpp: 1.8092 - mse: 1.0959e-04\n",
      "Epoch 304: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 5.4004 - bpp: 1.8092 - mse: 1.0959e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6078 - bpp: 1.7538 - mse: 8.7098e-05\n",
      "Epoch 305: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.6078 - bpp: 1.7538 - mse: 8.7098e-05\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0145 - bpp: 1.8039 - mse: 9.7977e-05\n",
      "Epoch 306: loss did not improve from 4.59173\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.0145 - bpp: 1.8039 - mse: 9.7977e-05\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5730 - bpp: 1.7594 - mse: 8.5863e-05\n",
      "Epoch 307: loss improved from 4.59173 to 4.57296, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 4.5730 - bpp: 1.7594 - mse: 8.5863e-05\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5615 - bpp: 1.7660 - mse: 8.5311e-05\n",
      "Epoch 308: loss improved from 4.57296 to 4.56147, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.5615 - bpp: 1.7660 - mse: 8.5311e-05\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8903 - bpp: 1.8053 - mse: 9.4145e-05\n",
      "Epoch 309: loss did not improve from 4.56147\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 4.8903 - bpp: 1.8053 - mse: 9.4145e-05\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6794 - bpp: 1.7852 - mse: 8.8323e-05\n",
      "Epoch 310: loss did not improve from 4.56147\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.6794 - bpp: 1.7852 - mse: 8.8323e-05\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5315 - bpp: 1.7365 - mse: 8.5295e-05\n",
      "Epoch 311: loss improved from 4.56147 to 4.53147, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.5315 - bpp: 1.7365 - mse: 8.5295e-05\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3336 - bpp: 1.8498 - mse: 1.0632e-04\n",
      "Epoch 312: loss did not improve from 4.53147\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 5.3336 - bpp: 1.8498 - mse: 1.0632e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7020 - bpp: 1.7618 - mse: 8.9727e-05\n",
      "Epoch 313: loss did not improve from 4.53147\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.7020 - bpp: 1.7618 - mse: 8.9727e-05\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7447 - bpp: 1.7551 - mse: 9.1235e-05\n",
      "Epoch 314: loss did not improve from 4.53147\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.7447 - bpp: 1.7551 - mse: 9.1235e-05\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2184 - bpp: 1.8040 - mse: 1.0420e-04\n",
      "Epoch 315: loss did not improve from 4.53147\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 5.2184 - bpp: 1.8040 - mse: 1.0420e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5548 - bpp: 1.8507 - mse: 1.4356e-04\n",
      "Epoch 316: loss did not improve from 4.53147\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 6.5548 - bpp: 1.8507 - mse: 1.4356e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3437 - bpp: 1.7619 - mse: 1.0931e-04\n",
      "Epoch 317: loss did not improve from 4.53147\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 5.3437 - bpp: 1.7619 - mse: 1.0931e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4321 - bpp: 1.7350 - mse: 8.2309e-05\n",
      "Epoch 318: loss improved from 4.53147 to 4.43208, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 4.4321 - bpp: 1.7350 - mse: 8.2309e-05\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2085 - bpp: 1.6997 - mse: 7.6561e-05\n",
      "Epoch 319: loss improved from 4.43208 to 4.20850, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.2085 - bpp: 1.6997 - mse: 7.6561e-05\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6941 - bpp: 1.7798 - mse: 8.8937e-05\n",
      "Epoch 320: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.6941 - bpp: 1.7798 - mse: 8.8937e-05\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3662 - bpp: 1.7127 - mse: 8.0980e-05\n",
      "Epoch 321: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 4.3662 - bpp: 1.7127 - mse: 8.0980e-05\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9746 - bpp: 1.8065 - mse: 1.5772e-04\n",
      "Epoch 322: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 6.9746 - bpp: 1.8065 - mse: 1.5772e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4092 - bpp: 1.8255 - mse: 1.0936e-04\n",
      "Epoch 323: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.4092 - bpp: 1.8255 - mse: 1.0936e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3468 - bpp: 1.7282 - mse: 7.9914e-05\n",
      "Epoch 324: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.3468 - bpp: 1.7282 - mse: 7.9914e-05\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6962 - bpp: 1.7691 - mse: 8.9326e-05\n",
      "Epoch 325: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.6962 - bpp: 1.7691 - mse: 8.9326e-05\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9382 - bpp: 1.7725 - mse: 9.6612e-05\n",
      "Epoch 326: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 4.9382 - bpp: 1.7725 - mse: 9.6612e-05\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7647 - bpp: 1.7765 - mse: 9.1191e-05\n",
      "Epoch 327: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.7647 - bpp: 1.7765 - mse: 9.1191e-05\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8400 - bpp: 1.7671 - mse: 9.3779e-05\n",
      "Epoch 328: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.8400 - bpp: 1.7671 - mse: 9.3779e-05\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5025 - bpp: 1.7483 - mse: 8.4053e-05\n",
      "Epoch 329: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.5025 - bpp: 1.7483 - mse: 8.4053e-05\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5768 - bpp: 1.7290 - mse: 8.6906e-05\n",
      "Epoch 330: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.5768 - bpp: 1.7290 - mse: 8.6906e-05\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6264 - bpp: 1.7578 - mse: 8.7541e-05\n",
      "Epoch 331: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.6264 - bpp: 1.7578 - mse: 8.7541e-05\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5988 - bpp: 1.7264 - mse: 8.7659e-05\n",
      "Epoch 332: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.5988 - bpp: 1.7264 - mse: 8.7659e-05\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4609 - bpp: 1.7644 - mse: 8.2292e-05\n",
      "Epoch 333: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 4.4609 - bpp: 1.7644 - mse: 8.2292e-05\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2884 - bpp: 1.6775 - mse: 7.9679e-05\n",
      "Epoch 334: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.2884 - bpp: 1.6775 - mse: 7.9679e-05\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9766 - bpp: 1.8275 - mse: 1.8766e-04\n",
      "Epoch 335: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 7.9766 - bpp: 1.8275 - mse: 1.8766e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3179 - bpp: 1.8196 - mse: 1.0676e-04\n",
      "Epoch 336: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.3179 - bpp: 1.8196 - mse: 1.0676e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2899 - bpp: 1.7976 - mse: 1.0658e-04\n",
      "Epoch 337: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 49s 238ms/step - loss: 5.2899 - bpp: 1.7976 - mse: 1.0658e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0370 - bpp: 1.7676 - mse: 9.9774e-05\n",
      "Epoch 338: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 5.0370 - bpp: 1.7676 - mse: 9.9774e-05\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5786 - bpp: 1.7436 - mse: 8.6516e-05\n",
      "Epoch 339: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.5786 - bpp: 1.7436 - mse: 8.6516e-05\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7323 - bpp: 1.7898 - mse: 8.9798e-05\n",
      "Epoch 340: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.7323 - bpp: 1.7898 - mse: 8.9798e-05\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4377 - bpp: 1.7132 - mse: 8.3144e-05\n",
      "Epoch 341: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.4377 - bpp: 1.7132 - mse: 8.3144e-05\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2801 - bpp: 1.7034 - mse: 7.8636e-05\n",
      "Epoch 342: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 4.2801 - bpp: 1.7034 - mse: 7.8636e-05\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6946 - bpp: 1.8748 - mse: 1.7761e-04\n",
      "Epoch 343: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 7.6946 - bpp: 1.8748 - mse: 1.7761e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7169 - bpp: 1.7455 - mse: 9.0680e-05\n",
      "Epoch 344: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.7169 - bpp: 1.7455 - mse: 9.0680e-05\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5895 - bpp: 1.7566 - mse: 8.6453e-05\n",
      "Epoch 345: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.5895 - bpp: 1.7566 - mse: 8.6453e-05\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3574 - bpp: 1.7433 - mse: 7.9775e-05\n",
      "Epoch 346: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.3574 - bpp: 1.7433 - mse: 7.9775e-05\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4979 - bpp: 1.7468 - mse: 8.3957e-05\n",
      "Epoch 347: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 4.4979 - bpp: 1.7468 - mse: 8.3957e-05\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3011 - bpp: 1.7282 - mse: 7.8520e-05\n",
      "Epoch 348: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 4.3011 - bpp: 1.7282 - mse: 7.8520e-05\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3000 - bpp: 1.7170 - mse: 7.8827e-05\n",
      "Epoch 349: loss did not improve from 4.20850\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.3000 - bpp: 1.7170 - mse: 7.8827e-05\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0006 - bpp: 1.6852 - mse: 7.0659e-05\n",
      "Epoch 350: loss improved from 4.20850 to 4.00056, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 4.0006 - bpp: 1.6852 - mse: 7.0659e-05\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5358 - bpp: 1.7199 - mse: 8.5933e-05\n",
      "Epoch 351: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 4.5358 - bpp: 1.7199 - mse: 8.5933e-05\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2517 - bpp: 1.7050 - mse: 7.7718e-05\n",
      "Epoch 352: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 4.2517 - bpp: 1.7050 - mse: 7.7718e-05\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2739 - bpp: 1.7278 - mse: 7.7704e-05\n",
      "Epoch 353: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 4.2739 - bpp: 1.7278 - mse: 7.7704e-05\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3793 - bpp: 1.7163 - mse: 8.1268e-05\n",
      "Epoch 354: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 4.3793 - bpp: 1.7163 - mse: 8.1268e-05\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9668 - bpp: 1.7541 - mse: 9.8043e-05\n",
      "Epoch 355: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.9668 - bpp: 1.7541 - mse: 9.8043e-05\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2457 - bpp: 1.6722 - mse: 7.8537e-05\n",
      "Epoch 356: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 4.2457 - bpp: 1.6722 - mse: 7.8537e-05\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6681 - bpp: 1.7644 - mse: 8.8611e-05\n",
      "Epoch 357: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.6681 - bpp: 1.7644 - mse: 8.8611e-05\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7936 - bpp: 1.7628 - mse: 9.2492e-05\n",
      "Epoch 358: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 4.7936 - bpp: 1.7628 - mse: 9.2492e-05\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3890 - bpp: 1.7216 - mse: 8.1402e-05\n",
      "Epoch 359: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 4.3890 - bpp: 1.7216 - mse: 8.1402e-05\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0684 - bpp: 1.7034 - mse: 7.2175e-05\n",
      "Epoch 360: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.0684 - bpp: 1.7034 - mse: 7.2175e-05\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5542 - bpp: 1.7173 - mse: 8.6576e-05\n",
      "Epoch 361: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.5542 - bpp: 1.7173 - mse: 8.6576e-05\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.6724 - bpp: 1.9310 - mse: 3.8884e-04\n",
      "Epoch 362: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 14.6724 - bpp: 1.9310 - mse: 3.8884e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5591 - bpp: 1.8763 - mse: 1.1239e-04\n",
      "Epoch 363: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 5.5591 - bpp: 1.8763 - mse: 1.1239e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4864 - bpp: 1.7690 - mse: 8.2928e-05\n",
      "Epoch 364: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.4864 - bpp: 1.7690 - mse: 8.2928e-05\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0764 - bpp: 1.8139 - mse: 9.9565e-05\n",
      "Epoch 365: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 5.0764 - bpp: 1.8139 - mse: 9.9565e-05\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3534 - bpp: 1.7420 - mse: 7.9695e-05\n",
      "Epoch 366: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.3534 - bpp: 1.7420 - mse: 7.9695e-05\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0769 - bpp: 1.7397 - mse: 7.1323e-05\n",
      "Epoch 367: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 4.0769 - bpp: 1.7397 - mse: 7.1323e-05\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6789 - bpp: 1.7996 - mse: 8.7869e-05\n",
      "Epoch 368: loss did not improve from 4.00056\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 4.6789 - bpp: 1.7996 - mse: 8.7869e-05\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9182 - bpp: 1.6791 - mse: 6.8331e-05\n",
      "Epoch 369: loss improved from 4.00056 to 3.91816, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.9182 - bpp: 1.6791 - mse: 6.8331e-05\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3862 - bpp: 1.7902 - mse: 7.9223e-05\n",
      "Epoch 370: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.3862 - bpp: 1.7902 - mse: 7.9223e-05\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3896 - bpp: 1.7568 - mse: 8.0347e-05\n",
      "Epoch 371: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 4.3896 - bpp: 1.7568 - mse: 8.0347e-05\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1722 - bpp: 1.7057 - mse: 7.5272e-05\n",
      "Epoch 372: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.1722 - bpp: 1.7057 - mse: 7.5272e-05\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1515 - bpp: 1.6998 - mse: 7.4821e-05\n",
      "Epoch 373: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 4.1515 - bpp: 1.6998 - mse: 7.4821e-05\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1554 - bpp: 1.7031 - mse: 7.4837e-05\n",
      "Epoch 374: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.1554 - bpp: 1.7031 - mse: 7.4837e-05\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0139 - bpp: 1.7254 - mse: 6.9840e-05\n",
      "Epoch 375: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.0139 - bpp: 1.7254 - mse: 6.9840e-05\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6900 - bpp: 1.7478 - mse: 8.9789e-05\n",
      "Epoch 376: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.6900 - bpp: 1.7478 - mse: 8.9789e-05\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3913 - bpp: 1.7730 - mse: 7.9903e-05\n",
      "Epoch 377: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.3913 - bpp: 1.7730 - mse: 7.9903e-05\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2191 - bpp: 1.7356 - mse: 7.5792e-05\n",
      "Epoch 378: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.2191 - bpp: 1.7356 - mse: 7.5792e-05\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3953 - bpp: 1.7144 - mse: 8.1813e-05\n",
      "Epoch 379: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.3953 - bpp: 1.7144 - mse: 8.1813e-05\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7198 - bpp: 1.7327 - mse: 9.1159e-05\n",
      "Epoch 380: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.7198 - bpp: 1.7327 - mse: 9.1159e-05\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5499 - bpp: 1.7099 - mse: 8.6670e-05\n",
      "Epoch 381: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 4.5499 - bpp: 1.7099 - mse: 8.6670e-05\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5832 - bpp: 1.7432 - mse: 8.6668e-05\n",
      "Epoch 382: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.5832 - bpp: 1.7432 - mse: 8.6668e-05\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1694 - bpp: 1.6918 - mse: 7.5612e-05\n",
      "Epoch 383: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.1694 - bpp: 1.6918 - mse: 7.5612e-05\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6837 - bpp: 1.7841 - mse: 8.8491e-05\n",
      "Epoch 384: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.6837 - bpp: 1.7841 - mse: 8.8491e-05\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0753 - bpp: 1.6769 - mse: 7.3194e-05\n",
      "Epoch 385: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.0753 - bpp: 1.6769 - mse: 7.3194e-05\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6699 - bpp: 1.7487 - mse: 8.9150e-05\n",
      "Epoch 386: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.6699 - bpp: 1.7487 - mse: 8.9150e-05\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6937 - bpp: 1.8840 - mse: 1.7730e-04\n",
      "Epoch 387: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 7.6937 - bpp: 1.8840 - mse: 1.7730e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5907 - bpp: 1.7516 - mse: 8.6645e-05\n",
      "Epoch 388: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.5907 - bpp: 1.7516 - mse: 8.6645e-05\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6346 - bpp: 1.7924 - mse: 8.6737e-05\n",
      "Epoch 389: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.6346 - bpp: 1.7924 - mse: 8.6737e-05\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7840 - bpp: 1.7978 - mse: 9.1131e-05\n",
      "Epoch 390: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 4.7840 - bpp: 1.7978 - mse: 9.1131e-05\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6454 - bpp: 1.7780 - mse: 8.7504e-05\n",
      "Epoch 391: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.6454 - bpp: 1.7780 - mse: 8.7504e-05\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1888 - bpp: 1.7193 - mse: 7.5362e-05\n",
      "Epoch 392: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.1888 - bpp: 1.7193 - mse: 7.5362e-05\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5718 - bpp: 1.7520 - mse: 8.6055e-05\n",
      "Epoch 393: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.5718 - bpp: 1.7520 - mse: 8.6055e-05\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3163 - bpp: 1.7143 - mse: 7.9409e-05\n",
      "Epoch 394: loss did not improve from 3.91816\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 4.3163 - bpp: 1.7143 - mse: 7.9409e-05\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6997 - bpp: 1.6495 - mse: 6.2568e-05\n",
      "Epoch 395: loss improved from 3.91816 to 3.69972, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.6997 - bpp: 1.6495 - mse: 6.2568e-05\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1157 - bpp: 1.7134 - mse: 7.3314e-05\n",
      "Epoch 396: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 4.1157 - bpp: 1.7134 - mse: 7.3314e-05\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0315 - bpp: 1.6842 - mse: 7.1634e-05\n",
      "Epoch 397: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.0315 - bpp: 1.6842 - mse: 7.1634e-05\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2926 - bpp: 1.7060 - mse: 7.8939e-05\n",
      "Epoch 398: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 4.2926 - bpp: 1.7060 - mse: 7.8939e-05\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8688 - bpp: 1.7457 - mse: 9.5308e-05\n",
      "Epoch 399: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.8688 - bpp: 1.7457 - mse: 9.5308e-05\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4354 - bpp: 1.6836 - mse: 8.3980e-05\n",
      "Epoch 400: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.4354 - bpp: 1.6836 - mse: 8.3980e-05\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5098 - bpp: 1.7336 - mse: 8.4725e-05\n",
      "Epoch 401: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.5098 - bpp: 1.7336 - mse: 8.4725e-05\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4996 - bpp: 1.7040 - mse: 8.5316e-05\n",
      "Epoch 402: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.4996 - bpp: 1.7040 - mse: 8.5316e-05\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8326 - bpp: 1.6652 - mse: 6.6144e-05\n",
      "Epoch 403: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.8326 - bpp: 1.6652 - mse: 6.6144e-05\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4042 - bpp: 1.7400 - mse: 8.1304e-05\n",
      "Epoch 404: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 4.4042 - bpp: 1.7400 - mse: 8.1304e-05\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3130 - bpp: 1.7026 - mse: 7.9664e-05\n",
      "Epoch 405: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.3130 - bpp: 1.7026 - mse: 7.9664e-05\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4068 - bpp: 1.7473 - mse: 8.1162e-05\n",
      "Epoch 406: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.4068 - bpp: 1.7473 - mse: 8.1162e-05\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2091 - bpp: 1.7095 - mse: 7.6282e-05\n",
      "Epoch 407: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.2091 - bpp: 1.7095 - mse: 7.6282e-05\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2634 - bpp: 1.7217 - mse: 7.7569e-05\n",
      "Epoch 408: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.2634 - bpp: 1.7217 - mse: 7.7569e-05\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4006 - bpp: 1.7457 - mse: 8.1022e-05\n",
      "Epoch 409: loss did not improve from 3.69972\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 4.4006 - bpp: 1.7457 - mse: 8.1022e-05\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6709 - bpp: 1.6681 - mse: 6.1120e-05\n",
      "Epoch 410: loss improved from 3.69972 to 3.67092, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.6709 - bpp: 1.6681 - mse: 6.1120e-05\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8615 - bpp: 1.6724 - mse: 6.6806e-05\n",
      "Epoch 411: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.8615 - bpp: 1.6724 - mse: 6.6806e-05\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0429 - bpp: 1.6660 - mse: 7.2538e-05\n",
      "Epoch 412: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.0429 - bpp: 1.6660 - mse: 7.2538e-05\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1409 - bpp: 1.6942 - mse: 7.4667e-05\n",
      "Epoch 413: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.1409 - bpp: 1.6942 - mse: 7.4667e-05\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6040 - bpp: 1.7893 - mse: 8.5899e-05\n",
      "Epoch 414: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.6040 - bpp: 1.7893 - mse: 8.5899e-05\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6996 - bpp: 1.6419 - mse: 6.2794e-05\n",
      "Epoch 415: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6996 - bpp: 1.6419 - mse: 6.2794e-05\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7225 - bpp: 1.7289 - mse: 9.1360e-05\n",
      "Epoch 416: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.7225 - bpp: 1.7289 - mse: 9.1360e-05\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3956 - bpp: 1.7132 - mse: 8.1861e-05\n",
      "Epoch 417: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.3956 - bpp: 1.7132 - mse: 8.1861e-05\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8038 - bpp: 1.7826 - mse: 1.2272e-04\n",
      "Epoch 418: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.8038 - bpp: 1.7826 - mse: 1.2272e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1991 - bpp: 1.6912 - mse: 7.6536e-05\n",
      "Epoch 419: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.1991 - bpp: 1.6912 - mse: 7.6536e-05\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4355 - bpp: 1.7073 - mse: 8.3257e-05\n",
      "Epoch 420: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.4355 - bpp: 1.7073 - mse: 8.3257e-05\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0481 - bpp: 1.6436 - mse: 7.3381e-05\n",
      "Epoch 421: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.0481 - bpp: 1.6436 - mse: 7.3381e-05\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8105 - bpp: 1.6697 - mse: 6.5332e-05\n",
      "Epoch 422: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8105 - bpp: 1.6697 - mse: 6.5332e-05\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4481 - bpp: 1.7069 - mse: 8.3655e-05\n",
      "Epoch 423: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.4481 - bpp: 1.7069 - mse: 8.3655e-05\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8983 - bpp: 1.6618 - mse: 6.8251e-05\n",
      "Epoch 424: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8983 - bpp: 1.6618 - mse: 6.8251e-05\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8914 - bpp: 1.6568 - mse: 6.8193e-05\n",
      "Epoch 425: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.8914 - bpp: 1.6568 - mse: 6.8193e-05\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2615 - bpp: 1.7089 - mse: 7.7899e-05\n",
      "Epoch 426: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 222ms/step - loss: 4.2615 - bpp: 1.7089 - mse: 7.7899e-05\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4021 - bpp: 1.7337 - mse: 8.1433e-05\n",
      "Epoch 427: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.4021 - bpp: 1.7337 - mse: 8.1433e-05\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1901 - bpp: 1.7254 - mse: 7.5215e-05\n",
      "Epoch 428: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.1901 - bpp: 1.7254 - mse: 7.5215e-05\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0943 - bpp: 1.8382 - mse: 1.6040e-04\n",
      "Epoch 429: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 7.0943 - bpp: 1.8382 - mse: 1.6040e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3060 - bpp: 1.7961 - mse: 1.0711e-04\n",
      "Epoch 430: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.3060 - bpp: 1.7961 - mse: 1.0711e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9659 - bpp: 1.7206 - mse: 6.8519e-05\n",
      "Epoch 431: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.9659 - bpp: 1.7206 - mse: 6.8519e-05\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1688 - bpp: 1.7394 - mse: 7.4141e-05\n",
      "Epoch 432: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.1688 - bpp: 1.7394 - mse: 7.4141e-05\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3890 - bpp: 1.7247 - mse: 8.1306e-05\n",
      "Epoch 433: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.3890 - bpp: 1.7247 - mse: 8.1306e-05\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2183 - bpp: 1.6858 - mse: 7.7286e-05\n",
      "Epoch 434: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 4.2183 - bpp: 1.6858 - mse: 7.7286e-05\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1565 - bpp: 1.7367 - mse: 7.3845e-05\n",
      "Epoch 435: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.1565 - bpp: 1.7367 - mse: 7.3845e-05\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8070 - bpp: 1.6738 - mse: 6.5099e-05\n",
      "Epoch 436: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 3.8070 - bpp: 1.6738 - mse: 6.5099e-05\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0856 - bpp: 1.6844 - mse: 7.3280e-05\n",
      "Epoch 437: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.0856 - bpp: 1.6844 - mse: 7.3280e-05\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1344 - bpp: 1.7538 - mse: 7.2650e-05\n",
      "Epoch 438: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.1344 - bpp: 1.7538 - mse: 7.2650e-05\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7384 - bpp: 1.6188 - mse: 6.4686e-05\n",
      "Epoch 439: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.7384 - bpp: 1.6188 - mse: 6.4686e-05\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9728 - bpp: 1.6627 - mse: 7.0501e-05\n",
      "Epoch 440: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 218ms/step - loss: 3.9728 - bpp: 1.6627 - mse: 7.0501e-05\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4616 - bpp: 1.7109 - mse: 8.3946e-05\n",
      "Epoch 441: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.4616 - bpp: 1.7109 - mse: 8.3946e-05\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3002 - bpp: 1.7257 - mse: 7.8568e-05\n",
      "Epoch 442: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.3002 - bpp: 1.7257 - mse: 7.8568e-05\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1354 - bpp: 1.7079 - mse: 7.4080e-05\n",
      "Epoch 443: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.1354 - bpp: 1.7079 - mse: 7.4080e-05\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0887 - bpp: 1.7141 - mse: 7.2467e-05\n",
      "Epoch 444: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.0887 - bpp: 1.7141 - mse: 7.2467e-05\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7322 - bpp: 1.6594 - mse: 6.3254e-05\n",
      "Epoch 445: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 222ms/step - loss: 3.7322 - bpp: 1.6594 - mse: 6.3254e-05\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2464 - bpp: 1.7343 - mse: 7.6660e-05\n",
      "Epoch 446: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.2464 - bpp: 1.7343 - mse: 7.6660e-05\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5448 - bpp: 1.7543 - mse: 8.5160e-05\n",
      "Epoch 447: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.5448 - bpp: 1.7543 - mse: 8.5160e-05\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2767 - bpp: 1.6852 - mse: 7.9087e-05\n",
      "Epoch 448: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.2767 - bpp: 1.6852 - mse: 7.9087e-05\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0744 - bpp: 1.7049 - mse: 7.2312e-05\n",
      "Epoch 449: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.0744 - bpp: 1.7049 - mse: 7.2312e-05\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5424 - bpp: 1.7621 - mse: 1.1537e-04\n",
      "Epoch 450: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.5424 - bpp: 1.7621 - mse: 1.1537e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2354 - bpp: 1.7577 - mse: 7.5614e-05\n",
      "Epoch 451: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.2354 - bpp: 1.7577 - mse: 7.5614e-05\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9959 - bpp: 1.6999 - mse: 7.0067e-05\n",
      "Epoch 452: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 3.9959 - bpp: 1.6999 - mse: 7.0067e-05\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7727 - bpp: 1.6575 - mse: 6.4550e-05\n",
      "Epoch 453: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.7727 - bpp: 1.6575 - mse: 6.4550e-05\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8233 - bpp: 1.6772 - mse: 6.5496e-05\n",
      "Epoch 454: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.8233 - bpp: 1.6772 - mse: 6.5496e-05\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0408 - bpp: 1.7064 - mse: 7.1241e-05\n",
      "Epoch 455: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 4.0408 - bpp: 1.7064 - mse: 7.1241e-05\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1555 - bpp: 1.7120 - mse: 1.3561e-04\n",
      "Epoch 456: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 6.1555 - bpp: 1.7120 - mse: 1.3561e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9857 - bpp: 1.8445 - mse: 1.2638e-04\n",
      "Epoch 457: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 5.9857 - bpp: 1.8445 - mse: 1.2638e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0719 - bpp: 1.7279 - mse: 7.1532e-05\n",
      "Epoch 458: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.0719 - bpp: 1.7279 - mse: 7.1532e-05\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8774 - bpp: 1.6769 - mse: 6.7153e-05\n",
      "Epoch 459: loss did not improve from 3.67092\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.8774 - bpp: 1.6769 - mse: 6.7153e-05\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5713 - bpp: 1.6521 - mse: 5.8569e-05\n",
      "Epoch 460: loss improved from 3.67092 to 3.57135, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.5713 - bpp: 1.6521 - mse: 5.8569e-05\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8785 - bpp: 1.6739 - mse: 6.7279e-05\n",
      "Epoch 461: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.8785 - bpp: 1.6739 - mse: 6.7279e-05\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6095 - bpp: 1.6483 - mse: 5.9851e-05\n",
      "Epoch 462: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.6095 - bpp: 1.6483 - mse: 5.9851e-05\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7844 - bpp: 1.6674 - mse: 6.4604e-05\n",
      "Epoch 463: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 3.7844 - bpp: 1.6674 - mse: 6.4604e-05\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3894 - bpp: 1.7480 - mse: 8.0607e-05\n",
      "Epoch 464: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.3894 - bpp: 1.7480 - mse: 8.0607e-05\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9202 - bpp: 1.6799 - mse: 6.8371e-05\n",
      "Epoch 465: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.9202 - bpp: 1.6799 - mse: 6.8371e-05\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9325 - bpp: 1.6807 - mse: 6.8718e-05\n",
      "Epoch 466: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9325 - bpp: 1.6807 - mse: 6.8718e-05\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6753 - bpp: 1.6593 - mse: 6.1521e-05\n",
      "Epoch 467: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.6753 - bpp: 1.6593 - mse: 6.1521e-05\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1496 - bpp: 1.6821 - mse: 7.5302e-05\n",
      "Epoch 468: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.1496 - bpp: 1.6821 - mse: 7.5302e-05\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8771 - bpp: 1.6771 - mse: 6.7140e-05\n",
      "Epoch 469: loss did not improve from 3.57135\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.8771 - bpp: 1.6771 - mse: 6.7140e-05\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5583 - bpp: 1.6038 - mse: 5.9648e-05\n",
      "Epoch 470: loss improved from 3.57135 to 3.55835, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.5583 - bpp: 1.6038 - mse: 5.9648e-05\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5743 - bpp: 1.6450 - mse: 5.8876e-05\n",
      "Epoch 471: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.5743 - bpp: 1.6450 - mse: 5.8876e-05\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8555 - bpp: 1.7050 - mse: 6.5629e-05\n",
      "Epoch 472: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.8555 - bpp: 1.7050 - mse: 6.5629e-05\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0032 - bpp: 1.6910 - mse: 7.0561e-05\n",
      "Epoch 473: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.0032 - bpp: 1.6910 - mse: 7.0561e-05\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9320 - bpp: 1.6507 - mse: 6.9620e-05\n",
      "Epoch 474: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.9320 - bpp: 1.6507 - mse: 6.9620e-05\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0404 - bpp: 1.6534 - mse: 7.2846e-05\n",
      "Epoch 475: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.0404 - bpp: 1.6534 - mse: 7.2846e-05\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0759 - bpp: 1.6972 - mse: 7.2592e-05\n",
      "Epoch 476: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.0759 - bpp: 1.6972 - mse: 7.2592e-05\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9238 - bpp: 1.6624 - mse: 6.9012e-05\n",
      "Epoch 477: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.9238 - bpp: 1.6624 - mse: 6.9012e-05\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7596 - bpp: 1.6769 - mse: 6.3559e-05\n",
      "Epoch 478: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.7596 - bpp: 1.6769 - mse: 6.3559e-05\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7495 - bpp: 1.6434 - mse: 6.4273e-05\n",
      "Epoch 479: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.7495 - bpp: 1.6434 - mse: 6.4273e-05\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2663 - bpp: 1.7296 - mse: 7.7412e-05\n",
      "Epoch 480: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.2663 - bpp: 1.7296 - mse: 7.7412e-05\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6427 - bpp: 1.6461 - mse: 6.0934e-05\n",
      "Epoch 481: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.6427 - bpp: 1.6461 - mse: 6.0934e-05\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2584 - bpp: 1.6973 - mse: 7.8158e-05\n",
      "Epoch 482: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.2584 - bpp: 1.6973 - mse: 7.8158e-05\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4817 - bpp: 1.7098 - mse: 8.4593e-05\n",
      "Epoch 483: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 4.4817 - bpp: 1.7098 - mse: 8.4593e-05\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8233 - bpp: 1.6676 - mse: 6.5789e-05\n",
      "Epoch 484: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.8233 - bpp: 1.6676 - mse: 6.5789e-05\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9885 - bpp: 1.7209 - mse: 6.9200e-05\n",
      "Epoch 485: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.9885 - bpp: 1.7209 - mse: 6.9200e-05\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7286 - bpp: 1.6366 - mse: 6.3842e-05\n",
      "Epoch 486: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7286 - bpp: 1.6366 - mse: 6.3842e-05\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8216 - bpp: 1.6564 - mse: 6.6077e-05\n",
      "Epoch 487: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 3.8216 - bpp: 1.6564 - mse: 6.6077e-05\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6452 - bpp: 1.6547 - mse: 6.0744e-05\n",
      "Epoch 488: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.6452 - bpp: 1.6547 - mse: 6.0744e-05\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7565 - bpp: 1.6709 - mse: 6.3650e-05\n",
      "Epoch 489: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.7565 - bpp: 1.6709 - mse: 6.3650e-05\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8302 - bpp: 1.6497 - mse: 6.6542e-05\n",
      "Epoch 490: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.8302 - bpp: 1.6497 - mse: 6.6542e-05\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1992 - bpp: 1.7270 - mse: 7.5445e-05\n",
      "Epoch 491: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.1992 - bpp: 1.7270 - mse: 7.5445e-05\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9552 - bpp: 1.6915 - mse: 6.9081e-05\n",
      "Epoch 492: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.9552 - bpp: 1.6915 - mse: 6.9081e-05\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9947 - bpp: 1.7043 - mse: 6.9898e-05\n",
      "Epoch 493: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.9947 - bpp: 1.7043 - mse: 6.9898e-05\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6326 - bpp: 1.6320 - mse: 6.1055e-05\n",
      "Epoch 494: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.6326 - bpp: 1.6320 - mse: 6.1055e-05\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9031 - bpp: 1.6310 - mse: 6.9339e-05\n",
      "Epoch 495: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9031 - bpp: 1.6310 - mse: 6.9339e-05\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0851 - bpp: 1.7406 - mse: 1.0207e-04\n",
      "Epoch 496: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 5.0851 - bpp: 1.7406 - mse: 1.0207e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0012 - bpp: 1.6880 - mse: 7.0595e-05\n",
      "Epoch 497: loss did not improve from 3.55835\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.0012 - bpp: 1.6880 - mse: 7.0595e-05\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4075 - bpp: 1.5887 - mse: 5.5504e-05\n",
      "Epoch 498: loss improved from 3.55835 to 3.40750, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.4075 - bpp: 1.5887 - mse: 5.5504e-05\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8415 - bpp: 1.6486 - mse: 6.6922e-05\n",
      "Epoch 499: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.8415 - bpp: 1.6486 - mse: 6.6922e-05\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0935 - bpp: 1.6630 - mse: 7.4174e-05\n",
      "Epoch 500: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.0935 - bpp: 1.6630 - mse: 7.4174e-05\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3110 - bpp: 1.7617 - mse: 7.7796e-05\n",
      "Epoch 501: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.3110 - bpp: 1.7617 - mse: 7.7796e-05\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9036 - bpp: 1.6908 - mse: 6.7529e-05\n",
      "Epoch 502: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9036 - bpp: 1.6908 - mse: 6.7529e-05\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8402 - bpp: 1.6626 - mse: 6.6455e-05\n",
      "Epoch 503: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.8402 - bpp: 1.6626 - mse: 6.6455e-05\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7476 - bpp: 1.6265 - mse: 6.4730e-05\n",
      "Epoch 504: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7476 - bpp: 1.6265 - mse: 6.4730e-05\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0485 - bpp: 1.6872 - mse: 7.2061e-05\n",
      "Epoch 505: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.0485 - bpp: 1.6872 - mse: 7.2061e-05\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6525 - bpp: 1.6158 - mse: 6.2156e-05\n",
      "Epoch 506: loss did not improve from 3.40750\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6525 - bpp: 1.6158 - mse: 6.2156e-05\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2438 - bpp: 1.5352 - mse: 5.2142e-05\n",
      "Epoch 507: loss improved from 3.40750 to 3.24379, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2438 - bpp: 1.5352 - mse: 5.2142e-05\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7747 - bpp: 1.6581 - mse: 6.4594e-05\n",
      "Epoch 508: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.7747 - bpp: 1.6581 - mse: 6.4594e-05\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8966 - bpp: 1.6782 - mse: 6.7701e-05\n",
      "Epoch 509: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.8966 - bpp: 1.6782 - mse: 6.7701e-05\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9390 - bpp: 1.6743 - mse: 6.9115e-05\n",
      "Epoch 510: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.9390 - bpp: 1.6743 - mse: 6.9115e-05\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0147 - bpp: 1.6999 - mse: 7.0644e-05\n",
      "Epoch 511: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.0147 - bpp: 1.6999 - mse: 7.0644e-05\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8635 - bpp: 1.6694 - mse: 6.6959e-05\n",
      "Epoch 512: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.8635 - bpp: 1.6694 - mse: 6.6959e-05\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9243 - bpp: 1.6672 - mse: 6.8879e-05\n",
      "Epoch 513: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.9243 - bpp: 1.6672 - mse: 6.8879e-05\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8272 - bpp: 1.6267 - mse: 6.7156e-05\n",
      "Epoch 514: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.8272 - bpp: 1.6267 - mse: 6.7156e-05\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6140 - bpp: 1.6132 - mse: 6.1057e-05\n",
      "Epoch 515: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.6140 - bpp: 1.6132 - mse: 6.1057e-05\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1290 - bpp: 1.7046 - mse: 7.3986e-05\n",
      "Epoch 516: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.1290 - bpp: 1.7046 - mse: 7.3986e-05\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8703 - bpp: 1.8115 - mse: 1.8490e-04\n",
      "Epoch 517: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 7.8703 - bpp: 1.8115 - mse: 1.8490e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9532 - bpp: 1.6832 - mse: 6.9276e-05\n",
      "Epoch 518: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.9532 - bpp: 1.6832 - mse: 6.9276e-05\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8591 - bpp: 1.6780 - mse: 6.6561e-05\n",
      "Epoch 519: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.8591 - bpp: 1.6780 - mse: 6.6561e-05\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8533 - bpp: 1.6690 - mse: 6.6660e-05\n",
      "Epoch 520: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.8533 - bpp: 1.6690 - mse: 6.6660e-05\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5565 - bpp: 1.6284 - mse: 5.8839e-05\n",
      "Epoch 521: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.5565 - bpp: 1.6284 - mse: 5.8839e-05\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6686 - bpp: 1.6477 - mse: 6.1672e-05\n",
      "Epoch 522: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6686 - bpp: 1.6477 - mse: 6.1672e-05\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7323 - bpp: 1.6417 - mse: 6.3798e-05\n",
      "Epoch 523: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.7323 - bpp: 1.6417 - mse: 6.3798e-05\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6229 - bpp: 1.6471 - mse: 6.0296e-05\n",
      "Epoch 524: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6229 - bpp: 1.6471 - mse: 6.0296e-05\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7797 - bpp: 1.6631 - mse: 6.4594e-05\n",
      "Epoch 525: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.7797 - bpp: 1.6631 - mse: 6.4594e-05\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6525 - bpp: 1.6596 - mse: 6.0819e-05\n",
      "Epoch 526: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6525 - bpp: 1.6596 - mse: 6.0819e-05\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6008 - bpp: 1.6183 - mse: 6.0502e-05\n",
      "Epoch 527: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.6008 - bpp: 1.6183 - mse: 6.0502e-05\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5040 - bpp: 1.5778 - mse: 5.8781e-05\n",
      "Epoch 528: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5040 - bpp: 1.5778 - mse: 5.8781e-05\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6968 - bpp: 1.6476 - mse: 6.2538e-05\n",
      "Epoch 529: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.6968 - bpp: 1.6476 - mse: 6.2538e-05\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7940 - bpp: 1.6295 - mse: 6.6053e-05\n",
      "Epoch 530: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7940 - bpp: 1.6295 - mse: 6.6053e-05\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0741 - bpp: 1.6558 - mse: 7.3803e-05\n",
      "Epoch 531: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 4.0741 - bpp: 1.6558 - mse: 7.3803e-05\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5268 - bpp: 1.6188 - mse: 5.8228e-05\n",
      "Epoch 532: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.5268 - bpp: 1.6188 - mse: 5.8228e-05\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5667 - bpp: 1.6293 - mse: 5.9127e-05\n",
      "Epoch 533: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5667 - bpp: 1.6293 - mse: 5.9127e-05\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4323 - bpp: 1.5925 - mse: 5.6146e-05\n",
      "Epoch 534: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.4323 - bpp: 1.5925 - mse: 5.6146e-05\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7638 - bpp: 1.6539 - mse: 6.4390e-05\n",
      "Epoch 535: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.7638 - bpp: 1.6539 - mse: 6.4390e-05\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8624 - bpp: 1.6517 - mse: 6.7467e-05\n",
      "Epoch 536: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.8624 - bpp: 1.6517 - mse: 6.7467e-05\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7186 - bpp: 1.6583 - mse: 6.2875e-05\n",
      "Epoch 537: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.7186 - bpp: 1.6583 - mse: 6.2875e-05\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7020 - bpp: 1.6403 - mse: 6.2921e-05\n",
      "Epoch 538: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.7020 - bpp: 1.6403 - mse: 6.2921e-05\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6288 - bpp: 1.6255 - mse: 6.1135e-05\n",
      "Epoch 539: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.6288 - bpp: 1.6255 - mse: 6.1135e-05\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5923 - bpp: 1.6029 - mse: 6.0712e-05\n",
      "Epoch 540: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.5923 - bpp: 1.6029 - mse: 6.0712e-05\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4975 - bpp: 1.6405 - mse: 5.6671e-05\n",
      "Epoch 541: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4975 - bpp: 1.6405 - mse: 5.6671e-05\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9875 - bpp: 1.6466 - mse: 7.1439e-05\n",
      "Epoch 542: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.9875 - bpp: 1.6466 - mse: 7.1439e-05\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9659 - bpp: 1.6851 - mse: 1.0012e-04\n",
      "Epoch 543: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.9659 - bpp: 1.6851 - mse: 1.0012e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8280 - bpp: 1.6843 - mse: 6.5421e-05\n",
      "Epoch 544: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.8280 - bpp: 1.6843 - mse: 6.5421e-05\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9194 - bpp: 1.6927 - mse: 6.7954e-05\n",
      "Epoch 545: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.9194 - bpp: 1.6927 - mse: 6.7954e-05\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0216 - bpp: 1.7082 - mse: 7.0598e-05\n",
      "Epoch 546: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.0216 - bpp: 1.7082 - mse: 7.0598e-05\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6906 - bpp: 1.6456 - mse: 6.2410e-05\n",
      "Epoch 547: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.6906 - bpp: 1.6456 - mse: 6.2410e-05\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7161 - bpp: 1.6615 - mse: 6.2703e-05\n",
      "Epoch 548: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.7161 - bpp: 1.6615 - mse: 6.2703e-05\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4594 - bpp: 1.6010 - mse: 5.6715e-05\n",
      "Epoch 549: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.4594 - bpp: 1.6010 - mse: 5.6715e-05\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7017 - bpp: 1.6023 - mse: 6.4066e-05\n",
      "Epoch 550: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.7017 - bpp: 1.6023 - mse: 6.4066e-05\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7204 - bpp: 1.6282 - mse: 6.3849e-05\n",
      "Epoch 551: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.7204 - bpp: 1.6282 - mse: 6.3849e-05\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6737 - bpp: 1.6308 - mse: 6.2344e-05\n",
      "Epoch 552: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6737 - bpp: 1.6308 - mse: 6.2344e-05\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7028 - bpp: 1.6355 - mse: 6.3088e-05\n",
      "Epoch 553: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.7028 - bpp: 1.6355 - mse: 6.3088e-05\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6579 - bpp: 1.6273 - mse: 6.1967e-05\n",
      "Epoch 554: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6579 - bpp: 1.6273 - mse: 6.1967e-05\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6901 - bpp: 1.6509 - mse: 6.2232e-05\n",
      "Epoch 555: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6901 - bpp: 1.6509 - mse: 6.2232e-05\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7180 - bpp: 1.6459 - mse: 6.3238e-05\n",
      "Epoch 556: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.7180 - bpp: 1.6459 - mse: 6.3238e-05\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4989 - bpp: 1.5906 - mse: 5.8234e-05\n",
      "Epoch 557: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4989 - bpp: 1.5906 - mse: 5.8234e-05\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8256 - bpp: 1.6745 - mse: 6.5646e-05\n",
      "Epoch 558: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.8256 - bpp: 1.6745 - mse: 6.5646e-05\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0410 - bpp: 1.6744 - mse: 7.2223e-05\n",
      "Epoch 559: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.0410 - bpp: 1.6744 - mse: 7.2223e-05\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6951 - bpp: 1.6071 - mse: 6.3723e-05\n",
      "Epoch 560: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.6951 - bpp: 1.6071 - mse: 6.3723e-05\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6834 - bpp: 1.6460 - mse: 6.2178e-05\n",
      "Epoch 561: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6834 - bpp: 1.6460 - mse: 6.2178e-05\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6190 - bpp: 1.6569 - mse: 5.9879e-05\n",
      "Epoch 562: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.6190 - bpp: 1.6569 - mse: 5.9879e-05\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7677 - bpp: 1.6466 - mse: 6.4729e-05\n",
      "Epoch 563: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.7677 - bpp: 1.6466 - mse: 6.4729e-05\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4248 - bpp: 1.5960 - mse: 5.5811e-05\n",
      "Epoch 564: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.4248 - bpp: 1.5960 - mse: 5.5811e-05\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5103 - bpp: 1.6148 - mse: 5.7847e-05\n",
      "Epoch 565: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5103 - bpp: 1.6148 - mse: 5.7847e-05\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8727 - bpp: 1.6836 - mse: 6.6806e-05\n",
      "Epoch 566: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.8727 - bpp: 1.6836 - mse: 6.6806e-05\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4193 - bpp: 1.6175 - mse: 5.4987e-05\n",
      "Epoch 567: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4193 - bpp: 1.6175 - mse: 5.4987e-05\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3379 - bpp: 1.7322 - mse: 7.9521e-05\n",
      "Epoch 568: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 4.3379 - bpp: 1.7322 - mse: 7.9521e-05\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5492 - bpp: 1.6837 - mse: 8.7447e-05\n",
      "Epoch 569: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.5492 - bpp: 1.6837 - mse: 8.7447e-05\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6558 - bpp: 1.6329 - mse: 6.1733e-05\n",
      "Epoch 570: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6558 - bpp: 1.6329 - mse: 6.1733e-05\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8525 - bpp: 1.6764 - mse: 6.6411e-05\n",
      "Epoch 571: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.8525 - bpp: 1.6764 - mse: 6.6411e-05\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5864 - bpp: 1.6242 - mse: 5.9881e-05\n",
      "Epoch 572: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5864 - bpp: 1.6242 - mse: 5.9881e-05\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4498 - bpp: 1.6297 - mse: 5.5545e-05\n",
      "Epoch 573: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.4498 - bpp: 1.6297 - mse: 5.5545e-05\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9855 - bpp: 1.6836 - mse: 7.0249e-05\n",
      "Epoch 574: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.9855 - bpp: 1.6836 - mse: 7.0249e-05\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9008 - bpp: 1.6393 - mse: 6.9016e-05\n",
      "Epoch 575: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9008 - bpp: 1.6393 - mse: 6.9016e-05\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5502 - bpp: 1.6193 - mse: 5.8927e-05\n",
      "Epoch 576: loss did not improve from 3.24379\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.5502 - bpp: 1.6193 - mse: 5.8927e-05\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1686 - bpp: 1.5563 - mse: 4.9202e-05\n",
      "Epoch 577: loss improved from 3.24379 to 3.16858, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.1686 - bpp: 1.5563 - mse: 4.9202e-05\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8835 - bpp: 1.6653 - mse: 6.7692e-05\n",
      "Epoch 578: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.8835 - bpp: 1.6653 - mse: 6.7692e-05\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7509 - bpp: 1.6386 - mse: 6.4462e-05\n",
      "Epoch 579: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.7509 - bpp: 1.6386 - mse: 6.4462e-05\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5564 - bpp: 1.5900 - mse: 6.0009e-05\n",
      "Epoch 580: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.5564 - bpp: 1.5900 - mse: 6.0009e-05\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3529 - bpp: 1.6079 - mse: 5.3252e-05\n",
      "Epoch 581: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3529 - bpp: 1.6079 - mse: 5.3252e-05\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3222 - bpp: 1.6679 - mse: 8.1002e-05\n",
      "Epoch 582: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.3222 - bpp: 1.6679 - mse: 8.1002e-05\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8519 - bpp: 1.6787 - mse: 6.6319e-05\n",
      "Epoch 583: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.8519 - bpp: 1.6787 - mse: 6.6319e-05\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5466 - bpp: 1.6179 - mse: 5.8859e-05\n",
      "Epoch 584: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.5466 - bpp: 1.6179 - mse: 5.8859e-05\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4089 - bpp: 1.5884 - mse: 5.5558e-05\n",
      "Epoch 585: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.4089 - bpp: 1.5884 - mse: 5.5558e-05\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3946 - bpp: 1.5914 - mse: 5.5028e-05\n",
      "Epoch 586: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.3946 - bpp: 1.5914 - mse: 5.5028e-05\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4633 - bpp: 1.6042 - mse: 5.6734e-05\n",
      "Epoch 587: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 224ms/step - loss: 3.4633 - bpp: 1.6042 - mse: 5.6734e-05\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9113 - bpp: 1.6198 - mse: 6.9931e-05\n",
      "Epoch 588: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.9113 - bpp: 1.6198 - mse: 6.9931e-05\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6215 - bpp: 1.6128 - mse: 6.1300e-05\n",
      "Epoch 589: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.6215 - bpp: 1.6128 - mse: 6.1300e-05\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6931 - bpp: 1.6586 - mse: 6.2090e-05\n",
      "Epoch 590: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.6931 - bpp: 1.6586 - mse: 6.2090e-05\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3565 - bpp: 1.5805 - mse: 5.4200e-05\n",
      "Epoch 591: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.3565 - bpp: 1.5805 - mse: 5.4200e-05\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6082 - bpp: 1.6180 - mse: 6.0736e-05\n",
      "Epoch 592: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6082 - bpp: 1.6180 - mse: 6.0736e-05\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5427 - bpp: 1.6296 - mse: 5.8385e-05\n",
      "Epoch 593: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.5427 - bpp: 1.6296 - mse: 5.8385e-05\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6781 - bpp: 1.6373 - mse: 6.2280e-05\n",
      "Epoch 594: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6781 - bpp: 1.6373 - mse: 6.2280e-05\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3403 - bpp: 1.5837 - mse: 5.3610e-05\n",
      "Epoch 595: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.3403 - bpp: 1.5837 - mse: 5.3610e-05\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8165 - bpp: 1.6582 - mse: 6.5867e-05\n",
      "Epoch 596: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.8165 - bpp: 1.6582 - mse: 6.5867e-05\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4386 - bpp: 1.6678 - mse: 8.4561e-05\n",
      "Epoch 597: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.4386 - bpp: 1.6678 - mse: 8.4561e-05\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8319 - bpp: 1.6909 - mse: 6.5337e-05\n",
      "Epoch 598: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.8319 - bpp: 1.6909 - mse: 6.5337e-05\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1040 - bpp: 1.6868 - mse: 7.3769e-05\n",
      "Epoch 599: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.1040 - bpp: 1.6868 - mse: 7.3769e-05\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6548 - bpp: 1.6411 - mse: 6.1453e-05\n",
      "Epoch 600: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.6548 - bpp: 1.6411 - mse: 6.1453e-05\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3045 - bpp: 1.5840 - mse: 5.2506e-05\n",
      "Epoch 601: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.3045 - bpp: 1.5840 - mse: 5.2506e-05\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5554 - bpp: 1.6211 - mse: 5.9029e-05\n",
      "Epoch 602: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.5554 - bpp: 1.6211 - mse: 5.9029e-05\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6592 - bpp: 1.6398 - mse: 6.1627e-05\n",
      "Epoch 603: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.6592 - bpp: 1.6398 - mse: 6.1627e-05\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8672 - bpp: 1.6427 - mse: 6.7886e-05\n",
      "Epoch 604: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.8672 - bpp: 1.6427 - mse: 6.7886e-05\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8620 - bpp: 1.6531 - mse: 6.7409e-05\n",
      "Epoch 605: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.8620 - bpp: 1.6531 - mse: 6.7409e-05\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5011 - bpp: 1.6064 - mse: 5.7822e-05\n",
      "Epoch 606: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5011 - bpp: 1.6064 - mse: 5.7822e-05\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7448 - bpp: 1.6424 - mse: 6.4158e-05\n",
      "Epoch 607: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7448 - bpp: 1.6424 - mse: 6.4158e-05\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9725 - bpp: 1.7012 - mse: 6.9314e-05\n",
      "Epoch 608: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.9725 - bpp: 1.7012 - mse: 6.9314e-05\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5557 - bpp: 1.6068 - mse: 5.9477e-05\n",
      "Epoch 609: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5557 - bpp: 1.6068 - mse: 5.9477e-05\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9873 - bpp: 1.7010 - mse: 6.9773e-05\n",
      "Epoch 610: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.9873 - bpp: 1.7010 - mse: 6.9773e-05\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5160 - bpp: 1.6286 - mse: 5.7597e-05\n",
      "Epoch 611: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5160 - bpp: 1.6286 - mse: 5.7597e-05\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4864 - bpp: 1.6524 - mse: 5.5970e-05\n",
      "Epoch 612: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.4864 - bpp: 1.6524 - mse: 5.5970e-05\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5194 - bpp: 1.6187 - mse: 5.8003e-05\n",
      "Epoch 613: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.5194 - bpp: 1.6187 - mse: 5.8003e-05\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4521 - bpp: 1.6249 - mse: 5.5762e-05\n",
      "Epoch 614: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.4521 - bpp: 1.6249 - mse: 5.5762e-05\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8913 - bpp: 1.6694 - mse: 6.7808e-05\n",
      "Epoch 615: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.8913 - bpp: 1.6694 - mse: 6.7808e-05\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2469 - bpp: 1.5767 - mse: 5.0968e-05\n",
      "Epoch 616: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2469 - bpp: 1.5767 - mse: 5.0968e-05\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4248 - bpp: 1.6146 - mse: 5.5244e-05\n",
      "Epoch 617: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.4248 - bpp: 1.6146 - mse: 5.5244e-05\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1950 - bpp: 1.7348 - mse: 7.5077e-05\n",
      "Epoch 618: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.1950 - bpp: 1.7348 - mse: 7.5077e-05\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0148 - bpp: 1.7050 - mse: 1.0101e-04\n",
      "Epoch 619: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 5.0148 - bpp: 1.7050 - mse: 1.0101e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4664 - bpp: 1.6213 - mse: 5.6308e-05\n",
      "Epoch 620: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4664 - bpp: 1.6213 - mse: 5.6308e-05\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5063 - bpp: 1.5833 - mse: 5.8685e-05\n",
      "Epoch 621: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.5063 - bpp: 1.5833 - mse: 5.8685e-05\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5137 - bpp: 1.6179 - mse: 5.7855e-05\n",
      "Epoch 622: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.5137 - bpp: 1.6179 - mse: 5.7855e-05\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7942 - bpp: 1.6615 - mse: 6.5084e-05\n",
      "Epoch 623: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.7942 - bpp: 1.6615 - mse: 6.5084e-05\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2147 - bpp: 1.5621 - mse: 5.0433e-05\n",
      "Epoch 624: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2147 - bpp: 1.5621 - mse: 5.0433e-05\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4989 - bpp: 1.6205 - mse: 5.7325e-05\n",
      "Epoch 625: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4989 - bpp: 1.6205 - mse: 5.7325e-05\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7218 - bpp: 1.6720 - mse: 6.2556e-05\n",
      "Epoch 626: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.7218 - bpp: 1.6720 - mse: 6.2556e-05\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9054 - bpp: 1.6851 - mse: 6.7758e-05\n",
      "Epoch 627: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.9054 - bpp: 1.6851 - mse: 6.7758e-05\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3533 - bpp: 1.5625 - mse: 5.4650e-05\n",
      "Epoch 628: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.3533 - bpp: 1.5625 - mse: 5.4650e-05\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2034 - bpp: 1.5871 - mse: 4.9325e-05\n",
      "Epoch 629: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.2034 - bpp: 1.5871 - mse: 4.9325e-05\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4288 - bpp: 1.5903 - mse: 5.6107e-05\n",
      "Epoch 630: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.4288 - bpp: 1.5903 - mse: 5.6107e-05\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7928 - bpp: 1.6602 - mse: 6.5082e-05\n",
      "Epoch 631: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.7928 - bpp: 1.6602 - mse: 6.5082e-05\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5163 - bpp: 1.6376 - mse: 5.7332e-05\n",
      "Epoch 632: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.5163 - bpp: 1.6376 - mse: 5.7332e-05\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5361 - bpp: 1.6167 - mse: 5.8574e-05\n",
      "Epoch 633: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.5361 - bpp: 1.6167 - mse: 5.8574e-05\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8481 - bpp: 1.6413 - mse: 6.7347e-05\n",
      "Epoch 634: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3.8481 - bpp: 1.6413 - mse: 6.7347e-05\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5318 - bpp: 1.6155 - mse: 5.8481e-05\n",
      "Epoch 635: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.5318 - bpp: 1.6155 - mse: 5.8481e-05\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9042 - bpp: 1.6740 - mse: 6.8061e-05\n",
      "Epoch 636: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.9042 - bpp: 1.6740 - mse: 6.8061e-05\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2471 - bpp: 1.5719 - mse: 5.1123e-05\n",
      "Epoch 637: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2471 - bpp: 1.5719 - mse: 5.1123e-05\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9095 - bpp: 1.6017 - mse: 7.0430e-05\n",
      "Epoch 638: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.9095 - bpp: 1.6017 - mse: 7.0430e-05\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8387 - bpp: 1.6790 - mse: 6.5909e-05\n",
      "Epoch 639: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.8387 - bpp: 1.6790 - mse: 6.5909e-05\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7095 - bpp: 1.6535 - mse: 6.2744e-05\n",
      "Epoch 640: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.7095 - bpp: 1.6535 - mse: 6.2744e-05\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6059 - bpp: 1.6506 - mse: 5.9672e-05\n",
      "Epoch 641: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.6059 - bpp: 1.6506 - mse: 5.9672e-05\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3597 - bpp: 1.6169 - mse: 5.3186e-05\n",
      "Epoch 642: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3597 - bpp: 1.6169 - mse: 5.3186e-05\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9660 - bpp: 1.6432 - mse: 7.0886e-05\n",
      "Epoch 643: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.9660 - bpp: 1.6432 - mse: 7.0886e-05\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3880 - bpp: 1.5823 - mse: 5.5107e-05\n",
      "Epoch 644: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.3880 - bpp: 1.5823 - mse: 5.5107e-05\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2426 - bpp: 1.5996 - mse: 5.0142e-05\n",
      "Epoch 645: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2426 - bpp: 1.5996 - mse: 5.0142e-05\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4116 - bpp: 1.6175 - mse: 5.4752e-05\n",
      "Epoch 646: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4116 - bpp: 1.6175 - mse: 5.4752e-05\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4458 - bpp: 1.6207 - mse: 5.5698e-05\n",
      "Epoch 647: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4458 - bpp: 1.6207 - mse: 5.5698e-05\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4942 - bpp: 1.6202 - mse: 5.7190e-05\n",
      "Epoch 648: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4942 - bpp: 1.6202 - mse: 5.7190e-05\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2932 - bpp: 1.5757 - mse: 5.2416e-05\n",
      "Epoch 649: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2932 - bpp: 1.5757 - mse: 5.2416e-05\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0595 - bpp: 1.6658 - mse: 7.3051e-05\n",
      "Epoch 650: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.0595 - bpp: 1.6658 - mse: 7.3051e-05\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4051 - bpp: 1.6025 - mse: 5.5010e-05\n",
      "Epoch 651: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.4051 - bpp: 1.6025 - mse: 5.5010e-05\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3872 - bpp: 1.5861 - mse: 5.4965e-05\n",
      "Epoch 652: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3872 - bpp: 1.5861 - mse: 5.4965e-05\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7083 - bpp: 1.6216 - mse: 6.3679e-05\n",
      "Epoch 653: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7083 - bpp: 1.6216 - mse: 6.3679e-05\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2149 - bpp: 1.5547 - mse: 5.0666e-05\n",
      "Epoch 654: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2149 - bpp: 1.5547 - mse: 5.0666e-05\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8245 - bpp: 1.6559 - mse: 6.6179e-05\n",
      "Epoch 655: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.8245 - bpp: 1.6559 - mse: 6.6179e-05\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5575 - bpp: 1.6122 - mse: 5.9364e-05\n",
      "Epoch 656: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5575 - bpp: 1.6122 - mse: 5.9364e-05\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4694 - bpp: 1.5885 - mse: 5.7401e-05\n",
      "Epoch 657: loss did not improve from 3.16858\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4694 - bpp: 1.5885 - mse: 5.7401e-05\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1243 - bpp: 1.5422 - mse: 4.8281e-05\n",
      "Epoch 658: loss improved from 3.16858 to 3.12432, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1243 - bpp: 1.5422 - mse: 4.8281e-05\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4574 - bpp: 1.6177 - mse: 5.6143e-05\n",
      "Epoch 659: loss did not improve from 3.12432\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.4574 - bpp: 1.6177 - mse: 5.6143e-05\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4820 - bpp: 1.6025 - mse: 5.7359e-05\n",
      "Epoch 660: loss did not improve from 3.12432\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.4820 - bpp: 1.6025 - mse: 5.7359e-05\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6890 - bpp: 1.6061 - mse: 6.3564e-05\n",
      "Epoch 661: loss did not improve from 3.12432\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6890 - bpp: 1.6061 - mse: 6.3564e-05\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4055 - bpp: 1.6002 - mse: 5.5094e-05\n",
      "Epoch 662: loss did not improve from 3.12432\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.4055 - bpp: 1.6002 - mse: 5.5094e-05\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2881 - bpp: 1.5530 - mse: 5.2952e-05\n",
      "Epoch 663: loss did not improve from 3.12432\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2881 - bpp: 1.5530 - mse: 5.2952e-05\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1900 - bpp: 1.5447 - mse: 5.0211e-05\n",
      "Epoch 664: loss did not improve from 3.12432\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.1900 - bpp: 1.5447 - mse: 5.0211e-05\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0759 - bpp: 1.5165 - mse: 4.7589e-05\n",
      "Epoch 665: loss improved from 3.12432 to 3.07593, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0759 - bpp: 1.5165 - mse: 4.7589e-05\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2775 - bpp: 1.5746 - mse: 5.1970e-05\n",
      "Epoch 666: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2775 - bpp: 1.5746 - mse: 5.1970e-05\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4142 - bpp: 1.6124 - mse: 5.4987e-05\n",
      "Epoch 667: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.4142 - bpp: 1.6124 - mse: 5.4987e-05\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4349 - bpp: 1.6154 - mse: 5.5527e-05\n",
      "Epoch 668: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4349 - bpp: 1.6154 - mse: 5.5527e-05\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2106 - bpp: 1.5692 - mse: 5.0093e-05\n",
      "Epoch 669: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.2106 - bpp: 1.5692 - mse: 5.0093e-05\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2534 - bpp: 1.5593 - mse: 5.1700e-05\n",
      "Epoch 670: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.2534 - bpp: 1.5593 - mse: 5.1700e-05\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4403 - bpp: 1.5970 - mse: 5.6255e-05\n",
      "Epoch 671: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4403 - bpp: 1.5970 - mse: 5.6255e-05\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5144 - bpp: 1.6021 - mse: 5.8361e-05\n",
      "Epoch 672: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.5144 - bpp: 1.6021 - mse: 5.8361e-05\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7494 - bpp: 1.6578 - mse: 6.3830e-05\n",
      "Epoch 673: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.7494 - bpp: 1.6578 - mse: 6.3830e-05\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3186 - bpp: 1.6088 - mse: 5.2176e-05\n",
      "Epoch 674: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.3186 - bpp: 1.6088 - mse: 5.2176e-05\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2051 - bpp: 1.5590 - mse: 5.0232e-05\n",
      "Epoch 675: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2051 - bpp: 1.5590 - mse: 5.0232e-05\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4736 - bpp: 1.5954 - mse: 5.7320e-05\n",
      "Epoch 676: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4736 - bpp: 1.5954 - mse: 5.7320e-05\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1899 - bpp: 1.5595 - mse: 4.9756e-05\n",
      "Epoch 677: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1899 - bpp: 1.5595 - mse: 4.9756e-05\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5545 - bpp: 1.6069 - mse: 5.9436e-05\n",
      "Epoch 678: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5545 - bpp: 1.6069 - mse: 5.9436e-05\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3301 - bpp: 1.5788 - mse: 5.3446e-05\n",
      "Epoch 679: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.3301 - bpp: 1.5788 - mse: 5.3446e-05\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3628 - bpp: 1.5740 - mse: 5.4590e-05\n",
      "Epoch 680: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.3628 - bpp: 1.5740 - mse: 5.4590e-05\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2909 - bpp: 1.5884 - mse: 5.1957e-05\n",
      "Epoch 681: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2909 - bpp: 1.5884 - mse: 5.1957e-05\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6749 - bpp: 1.6154 - mse: 6.2850e-05\n",
      "Epoch 682: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6749 - bpp: 1.6154 - mse: 6.2850e-05\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2751 - bpp: 1.5945 - mse: 5.1287e-05\n",
      "Epoch 683: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2751 - bpp: 1.5945 - mse: 5.1287e-05\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4313 - bpp: 1.5744 - mse: 5.6669e-05\n",
      "Epoch 684: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4313 - bpp: 1.5744 - mse: 5.6669e-05\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5072 - bpp: 1.6114 - mse: 5.7853e-05\n",
      "Epoch 685: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5072 - bpp: 1.6114 - mse: 5.7853e-05\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5528 - bpp: 1.6167 - mse: 5.9085e-05\n",
      "Epoch 686: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5528 - bpp: 1.6167 - mse: 5.9085e-05\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0602 - bpp: 1.6855 - mse: 7.2471e-05\n",
      "Epoch 687: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.0602 - bpp: 1.6855 - mse: 7.2471e-05\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5041 - bpp: 1.6086 - mse: 5.7847e-05\n",
      "Epoch 688: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 50s 241ms/step - loss: 3.5041 - bpp: 1.6086 - mse: 5.7847e-05\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5551 - bpp: 1.5967 - mse: 5.9764e-05\n",
      "Epoch 689: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5551 - bpp: 1.5967 - mse: 5.9764e-05\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7888 - bpp: 1.6304 - mse: 6.5869e-05\n",
      "Epoch 690: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.7888 - bpp: 1.6304 - mse: 6.5869e-05\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7340 - bpp: 1.6070 - mse: 6.4910e-05\n",
      "Epoch 691: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.7340 - bpp: 1.6070 - mse: 6.4910e-05\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2080 - bpp: 1.5626 - mse: 5.0212e-05\n",
      "Epoch 692: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.2080 - bpp: 1.5626 - mse: 5.0212e-05\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5454 - bpp: 1.6495 - mse: 5.7858e-05\n",
      "Epoch 693: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.5454 - bpp: 1.6495 - mse: 5.7858e-05\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2962 - bpp: 1.5798 - mse: 5.2381e-05\n",
      "Epoch 694: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2962 - bpp: 1.5798 - mse: 5.2381e-05\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8473 - bpp: 1.6764 - mse: 6.6252e-05\n",
      "Epoch 695: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.8473 - bpp: 1.6764 - mse: 6.6252e-05\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3699 - bpp: 1.5661 - mse: 5.5049e-05\n",
      "Epoch 696: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3699 - bpp: 1.5661 - mse: 5.5049e-05\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5825 - bpp: 1.6146 - mse: 6.0056e-05\n",
      "Epoch 697: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.5825 - bpp: 1.6146 - mse: 6.0056e-05\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1566 - bpp: 1.5602 - mse: 4.8719e-05\n",
      "Epoch 698: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1566 - bpp: 1.5602 - mse: 4.8719e-05\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6539 - bpp: 1.6281 - mse: 6.1820e-05\n",
      "Epoch 699: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.6539 - bpp: 1.6281 - mse: 6.1820e-05\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6062 - bpp: 1.6367 - mse: 6.0102e-05\n",
      "Epoch 700: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.6062 - bpp: 1.6367 - mse: 6.0102e-05\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7359 - bpp: 1.6422 - mse: 6.3894e-05\n",
      "Epoch 701: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.7359 - bpp: 1.6422 - mse: 6.3894e-05\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6017 - bpp: 1.5782 - mse: 6.1754e-05\n",
      "Epoch 702: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.6017 - bpp: 1.5782 - mse: 6.1754e-05\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4683 - bpp: 1.6147 - mse: 5.6567e-05\n",
      "Epoch 703: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.4683 - bpp: 1.6147 - mse: 5.6567e-05\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5004 - bpp: 1.6167 - mse: 5.7486e-05\n",
      "Epoch 704: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5004 - bpp: 1.6167 - mse: 5.7486e-05\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1209 - bpp: 1.5344 - mse: 4.8416e-05\n",
      "Epoch 705: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.1209 - bpp: 1.5344 - mse: 4.8416e-05\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3180 - bpp: 1.5711 - mse: 5.3311e-05\n",
      "Epoch 706: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3180 - bpp: 1.5711 - mse: 5.3311e-05\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4198 - bpp: 1.5961 - mse: 5.5657e-05\n",
      "Epoch 707: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.4198 - bpp: 1.5961 - mse: 5.5657e-05\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2053 - bpp: 1.5552 - mse: 5.0356e-05\n",
      "Epoch 708: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2053 - bpp: 1.5552 - mse: 5.0356e-05\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4860 - bpp: 1.5860 - mse: 5.7983e-05\n",
      "Epoch 709: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.4860 - bpp: 1.5860 - mse: 5.7983e-05\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3198 - bpp: 1.5771 - mse: 5.3184e-05\n",
      "Epoch 710: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3198 - bpp: 1.5771 - mse: 5.3184e-05\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6155 - bpp: 1.6500 - mse: 5.9983e-05\n",
      "Epoch 711: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.6155 - bpp: 1.6500 - mse: 5.9983e-05\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1700 - bpp: 1.5771 - mse: 4.8612e-05\n",
      "Epoch 712: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1700 - bpp: 1.5771 - mse: 4.8612e-05\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3599 - bpp: 1.6100 - mse: 5.3403e-05\n",
      "Epoch 713: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3599 - bpp: 1.6100 - mse: 5.3403e-05\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3421 - bpp: 1.5871 - mse: 5.3560e-05\n",
      "Epoch 714: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3421 - bpp: 1.5871 - mse: 5.3560e-05\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2951 - bpp: 1.5664 - mse: 5.2754e-05\n",
      "Epoch 715: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2951 - bpp: 1.5664 - mse: 5.2754e-05\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8211 - bpp: 1.6083 - mse: 6.7528e-05\n",
      "Epoch 716: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.8211 - bpp: 1.6083 - mse: 6.7528e-05\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5985 - bpp: 1.6425 - mse: 5.9692e-05\n",
      "Epoch 717: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5985 - bpp: 1.6425 - mse: 5.9692e-05\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1954 - bpp: 1.5628 - mse: 4.9823e-05\n",
      "Epoch 718: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1954 - bpp: 1.5628 - mse: 4.9823e-05\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4973 - bpp: 1.6370 - mse: 5.6771e-05\n",
      "Epoch 719: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.4973 - bpp: 1.6370 - mse: 5.6771e-05\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4750 - bpp: 1.6101 - mse: 5.6913e-05\n",
      "Epoch 720: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.4750 - bpp: 1.6101 - mse: 5.6913e-05\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2862 - bpp: 1.5918 - mse: 5.1710e-05\n",
      "Epoch 721: loss did not improve from 3.07593\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.2862 - bpp: 1.5918 - mse: 5.1710e-05\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0528 - bpp: 1.5313 - mse: 4.6433e-05\n",
      "Epoch 722: loss improved from 3.07593 to 3.05281, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0528 - bpp: 1.5313 - mse: 4.6433e-05\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9426 - bpp: 1.6609 - mse: 6.9633e-05\n",
      "Epoch 723: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3.9426 - bpp: 1.6609 - mse: 6.9633e-05\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4378 - bpp: 1.6099 - mse: 5.5784e-05\n",
      "Epoch 724: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.4378 - bpp: 1.6099 - mse: 5.5784e-05\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5131 - bpp: 1.5979 - mse: 5.8447e-05\n",
      "Epoch 725: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.5131 - bpp: 1.5979 - mse: 5.8447e-05\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6226 - bpp: 1.6523 - mse: 6.0129e-05\n",
      "Epoch 726: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.6226 - bpp: 1.6523 - mse: 6.0129e-05\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3238 - bpp: 1.5836 - mse: 5.3107e-05\n",
      "Epoch 727: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.3238 - bpp: 1.5836 - mse: 5.3107e-05\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6743 - bpp: 1.6397 - mse: 6.2091e-05\n",
      "Epoch 728: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.6743 - bpp: 1.6397 - mse: 6.2091e-05\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5012 - bpp: 1.6249 - mse: 5.7261e-05\n",
      "Epoch 729: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.5012 - bpp: 1.6249 - mse: 5.7261e-05\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3230 - bpp: 1.5715 - mse: 5.3452e-05\n",
      "Epoch 730: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3230 - bpp: 1.5715 - mse: 5.3452e-05\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2182 - bpp: 1.5736 - mse: 5.0188e-05\n",
      "Epoch 731: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2182 - bpp: 1.5736 - mse: 5.0188e-05\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5535 - bpp: 1.6230 - mse: 5.8915e-05\n",
      "Epoch 732: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5535 - bpp: 1.6230 - mse: 5.8915e-05\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2082 - bpp: 1.5600 - mse: 5.0301e-05\n",
      "Epoch 733: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.2082 - bpp: 1.5600 - mse: 5.0301e-05\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3252 - bpp: 1.5732 - mse: 5.3466e-05\n",
      "Epoch 734: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3252 - bpp: 1.5732 - mse: 5.3466e-05\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4232 - bpp: 1.6158 - mse: 5.5158e-05\n",
      "Epoch 735: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4232 - bpp: 1.6158 - mse: 5.5158e-05\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1434 - bpp: 1.5396 - mse: 4.8945e-05\n",
      "Epoch 736: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1434 - bpp: 1.5396 - mse: 4.8945e-05\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5331 - bpp: 1.6100 - mse: 5.8689e-05\n",
      "Epoch 737: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.5331 - bpp: 1.6100 - mse: 5.8689e-05\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2056 - bpp: 1.5622 - mse: 5.0153e-05\n",
      "Epoch 738: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.2056 - bpp: 1.5622 - mse: 5.0153e-05\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2282 - bpp: 1.5595 - mse: 5.0923e-05\n",
      "Epoch 739: loss did not improve from 3.05281\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2282 - bpp: 1.5595 - mse: 5.0923e-05\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0303 - bpp: 1.5037 - mse: 4.6589e-05\n",
      "Epoch 740: loss improved from 3.05281 to 3.03029, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0303 - bpp: 1.5037 - mse: 4.6589e-05\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1996 - bpp: 1.5354 - mse: 5.0787e-05\n",
      "Epoch 741: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1996 - bpp: 1.5354 - mse: 5.0787e-05\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1263 - bpp: 1.5245 - mse: 4.8880e-05\n",
      "Epoch 742: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1263 - bpp: 1.5245 - mse: 4.8880e-05\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6414 - bpp: 1.6248 - mse: 6.1541e-05\n",
      "Epoch 743: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.6414 - bpp: 1.6248 - mse: 6.1541e-05\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1632 - bpp: 1.5553 - mse: 4.9068e-05\n",
      "Epoch 744: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1632 - bpp: 1.5553 - mse: 4.9068e-05\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3134 - bpp: 1.5925 - mse: 5.2519e-05\n",
      "Epoch 745: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.3134 - bpp: 1.5925 - mse: 5.2519e-05\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1532 - bpp: 1.5184 - mse: 4.9891e-05\n",
      "Epoch 746: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1532 - bpp: 1.5184 - mse: 4.9891e-05\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4993 - bpp: 1.5674 - mse: 5.8957e-05\n",
      "Epoch 747: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4993 - bpp: 1.5674 - mse: 5.8957e-05\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1578 - bpp: 1.6400 - mse: 7.6837e-05\n",
      "Epoch 748: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 4.1578 - bpp: 1.6400 - mse: 7.6837e-05\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7025 - bpp: 1.6653 - mse: 6.2170e-05\n",
      "Epoch 749: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.7025 - bpp: 1.6653 - mse: 6.2170e-05\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3613 - bpp: 1.5621 - mse: 5.4906e-05\n",
      "Epoch 750: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3613 - bpp: 1.5621 - mse: 5.4906e-05\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4275 - bpp: 1.5860 - mse: 5.6197e-05\n",
      "Epoch 751: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.4275 - bpp: 1.5860 - mse: 5.6197e-05\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2702 - bpp: 1.5522 - mse: 5.2430e-05\n",
      "Epoch 752: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.2702 - bpp: 1.5522 - mse: 5.2430e-05\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2020 - bpp: 1.5668 - mse: 4.9904e-05\n",
      "Epoch 753: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2020 - bpp: 1.5668 - mse: 4.9904e-05\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0595 - bpp: 1.5013 - mse: 4.7552e-05\n",
      "Epoch 754: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0595 - bpp: 1.5013 - mse: 4.7552e-05\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2232 - bpp: 1.5782 - mse: 5.0200e-05\n",
      "Epoch 755: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.2232 - bpp: 1.5782 - mse: 5.0200e-05\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4724 - bpp: 1.6088 - mse: 5.6874e-05\n",
      "Epoch 756: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.4724 - bpp: 1.6088 - mse: 5.6874e-05\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4252 - bpp: 1.5786 - mse: 5.6355e-05\n",
      "Epoch 757: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.4252 - bpp: 1.5786 - mse: 5.6355e-05\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3164 - bpp: 1.6045 - mse: 5.2243e-05\n",
      "Epoch 758: loss did not improve from 3.03029\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3164 - bpp: 1.6045 - mse: 5.2243e-05\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9455 - bpp: 1.5015 - mse: 4.4066e-05\n",
      "Epoch 759: loss improved from 3.03029 to 2.94548, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9455 - bpp: 1.5015 - mse: 4.4066e-05\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4262 - bpp: 1.5823 - mse: 5.6270e-05\n",
      "Epoch 760: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.4262 - bpp: 1.5823 - mse: 5.6270e-05\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1521 - bpp: 1.5766 - mse: 4.8079e-05\n",
      "Epoch 761: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1521 - bpp: 1.5766 - mse: 4.8079e-05\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2748 - bpp: 1.5783 - mse: 5.1772e-05\n",
      "Epoch 762: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.2748 - bpp: 1.5783 - mse: 5.1772e-05\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3548 - bpp: 1.6231 - mse: 5.2848e-05\n",
      "Epoch 763: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3548 - bpp: 1.6231 - mse: 5.2848e-05\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3176 - bpp: 1.5756 - mse: 5.3164e-05\n",
      "Epoch 764: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3176 - bpp: 1.5756 - mse: 5.3164e-05\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2877 - bpp: 1.5945 - mse: 5.1673e-05\n",
      "Epoch 765: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2877 - bpp: 1.5945 - mse: 5.1673e-05\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4254 - bpp: 1.6090 - mse: 5.5434e-05\n",
      "Epoch 766: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4254 - bpp: 1.6090 - mse: 5.5434e-05\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4465 - bpp: 1.6211 - mse: 5.5706e-05\n",
      "Epoch 767: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.4465 - bpp: 1.6211 - mse: 5.5706e-05\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5520 - bpp: 1.6193 - mse: 5.8982e-05\n",
      "Epoch 768: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.5520 - bpp: 1.6193 - mse: 5.8982e-05\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1255 - bpp: 1.5379 - mse: 4.8448e-05\n",
      "Epoch 769: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1255 - bpp: 1.5379 - mse: 4.8448e-05\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4564 - bpp: 1.6112 - mse: 5.6311e-05\n",
      "Epoch 770: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4564 - bpp: 1.6112 - mse: 5.6311e-05\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5576 - bpp: 1.6115 - mse: 5.9388e-05\n",
      "Epoch 771: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 3.5576 - bpp: 1.6115 - mse: 5.9388e-05\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0534 - bpp: 1.5152 - mse: 4.6944e-05\n",
      "Epoch 772: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0534 - bpp: 1.5152 - mse: 4.6944e-05\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3896 - bpp: 1.6221 - mse: 5.3939e-05\n",
      "Epoch 773: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3896 - bpp: 1.6221 - mse: 5.3939e-05\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0687 - bpp: 1.5224 - mse: 4.7190e-05\n",
      "Epoch 774: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0687 - bpp: 1.5224 - mse: 4.7190e-05\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2966 - bpp: 1.5706 - mse: 5.2673e-05\n",
      "Epoch 775: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2966 - bpp: 1.5706 - mse: 5.2673e-05\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9482 - bpp: 1.5104 - mse: 4.3878e-05\n",
      "Epoch 776: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.9482 - bpp: 1.5104 - mse: 4.3878e-05\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0114 - bpp: 1.5155 - mse: 4.5650e-05\n",
      "Epoch 777: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.0114 - bpp: 1.5155 - mse: 4.5650e-05\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3286 - bpp: 1.5803 - mse: 5.3354e-05\n",
      "Epoch 778: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.3286 - bpp: 1.5803 - mse: 5.3354e-05\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7357 - bpp: 1.5902 - mse: 6.5476e-05\n",
      "Epoch 779: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7357 - bpp: 1.5902 - mse: 6.5476e-05\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3929 - bpp: 1.5971 - mse: 5.4804e-05\n",
      "Epoch 780: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.3929 - bpp: 1.5971 - mse: 5.4804e-05\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1226 - bpp: 1.5368 - mse: 4.8395e-05\n",
      "Epoch 781: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1226 - bpp: 1.5368 - mse: 4.8395e-05\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7070 - bpp: 1.6328 - mse: 6.3299e-05\n",
      "Epoch 782: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7070 - bpp: 1.6328 - mse: 6.3299e-05\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3431 - bpp: 1.5804 - mse: 5.3793e-05\n",
      "Epoch 783: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.3431 - bpp: 1.5804 - mse: 5.3793e-05\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2187 - bpp: 1.5542 - mse: 5.0796e-05\n",
      "Epoch 784: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2187 - bpp: 1.5542 - mse: 5.0796e-05\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2317 - bpp: 1.5648 - mse: 5.0871e-05\n",
      "Epoch 785: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.2317 - bpp: 1.5648 - mse: 5.0871e-05\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7647 - bpp: 1.6562 - mse: 6.4347e-05\n",
      "Epoch 786: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.7647 - bpp: 1.6562 - mse: 6.4347e-05\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3060 - bpp: 1.5902 - mse: 5.2361e-05\n",
      "Epoch 787: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3.3060 - bpp: 1.5902 - mse: 5.2361e-05\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2903 - bpp: 1.5745 - mse: 5.2361e-05\n",
      "Epoch 788: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2903 - bpp: 1.5745 - mse: 5.2361e-05\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1127 - bpp: 1.5276 - mse: 4.8375e-05\n",
      "Epoch 789: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1127 - bpp: 1.5276 - mse: 4.8375e-05\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2721 - bpp: 1.5565 - mse: 5.2357e-05\n",
      "Epoch 790: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2721 - bpp: 1.5565 - mse: 5.2357e-05\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3715 - bpp: 1.6167 - mse: 5.3553e-05\n",
      "Epoch 791: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3715 - bpp: 1.6167 - mse: 5.3553e-05\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4164 - bpp: 1.6101 - mse: 5.5125e-05\n",
      "Epoch 792: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.4164 - bpp: 1.6101 - mse: 5.5125e-05\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6461 - bpp: 1.6369 - mse: 6.1315e-05\n",
      "Epoch 793: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.6461 - bpp: 1.6369 - mse: 6.1315e-05\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3318 - bpp: 1.6035 - mse: 5.2743e-05\n",
      "Epoch 794: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3318 - bpp: 1.6035 - mse: 5.2743e-05\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3420 - bpp: 1.5672 - mse: 5.4160e-05\n",
      "Epoch 795: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3420 - bpp: 1.5672 - mse: 5.4160e-05\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0761 - bpp: 1.5400 - mse: 4.6878e-05\n",
      "Epoch 796: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0761 - bpp: 1.5400 - mse: 4.6878e-05\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2768 - bpp: 1.5622 - mse: 5.2326e-05\n",
      "Epoch 797: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2768 - bpp: 1.5622 - mse: 5.2326e-05\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0875 - bpp: 1.5121 - mse: 4.8076e-05\n",
      "Epoch 798: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0875 - bpp: 1.5121 - mse: 4.8076e-05\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5730 - bpp: 1.6366 - mse: 5.9095e-05\n",
      "Epoch 799: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5730 - bpp: 1.6366 - mse: 5.9095e-05\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2801 - bpp: 1.5915 - mse: 5.1532e-05\n",
      "Epoch 800: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.2801 - bpp: 1.5915 - mse: 5.1532e-05\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2670 - bpp: 1.5926 - mse: 5.1100e-05\n",
      "Epoch 801: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2670 - bpp: 1.5926 - mse: 5.1100e-05\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1694 - bpp: 1.5619 - mse: 4.9057e-05\n",
      "Epoch 802: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1694 - bpp: 1.5619 - mse: 4.9057e-05\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2915 - bpp: 1.5719 - mse: 5.2478e-05\n",
      "Epoch 803: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3.2915 - bpp: 1.5719 - mse: 5.2478e-05\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4747 - bpp: 1.6093 - mse: 5.6927e-05\n",
      "Epoch 804: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.4747 - bpp: 1.6093 - mse: 5.6927e-05\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1115 - bpp: 1.5646 - mse: 4.7209e-05\n",
      "Epoch 805: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.1115 - bpp: 1.5646 - mse: 4.7209e-05\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3359 - bpp: 1.5829 - mse: 5.3497e-05\n",
      "Epoch 806: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3359 - bpp: 1.5829 - mse: 5.3497e-05\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4317 - bpp: 1.6158 - mse: 5.5417e-05\n",
      "Epoch 807: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.4317 - bpp: 1.6158 - mse: 5.5417e-05\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3004 - bpp: 1.5533 - mse: 5.3316e-05\n",
      "Epoch 808: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3004 - bpp: 1.5533 - mse: 5.3316e-05\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1773 - bpp: 1.5592 - mse: 4.9382e-05\n",
      "Epoch 809: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1773 - bpp: 1.5592 - mse: 4.9382e-05\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3518 - bpp: 1.5793 - mse: 5.4092e-05\n",
      "Epoch 810: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3518 - bpp: 1.5793 - mse: 5.4092e-05\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9626 - bpp: 1.5348 - mse: 4.3572e-05\n",
      "Epoch 811: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9626 - bpp: 1.5348 - mse: 4.3572e-05\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3414 - bpp: 1.5864 - mse: 5.3559e-05\n",
      "Epoch 812: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3414 - bpp: 1.5864 - mse: 5.3559e-05\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3144 - bpp: 1.5674 - mse: 5.3316e-05\n",
      "Epoch 813: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.3144 - bpp: 1.5674 - mse: 5.3316e-05\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3772 - bpp: 1.5725 - mse: 5.5073e-05\n",
      "Epoch 814: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3772 - bpp: 1.5725 - mse: 5.5073e-05\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2680 - bpp: 1.5814 - mse: 5.1473e-05\n",
      "Epoch 815: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2680 - bpp: 1.5814 - mse: 5.1473e-05\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3022 - bpp: 1.6018 - mse: 5.1890e-05\n",
      "Epoch 816: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3022 - bpp: 1.6018 - mse: 5.1890e-05\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2035 - bpp: 1.5574 - mse: 5.0235e-05\n",
      "Epoch 817: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2035 - bpp: 1.5574 - mse: 5.0235e-05\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1162 - bpp: 1.5580 - mse: 4.7555e-05\n",
      "Epoch 818: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1162 - bpp: 1.5580 - mse: 4.7555e-05\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1247 - bpp: 1.5370 - mse: 4.8451e-05\n",
      "Epoch 819: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.1247 - bpp: 1.5370 - mse: 4.8451e-05\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1351 - bpp: 1.5632 - mse: 4.7971e-05\n",
      "Epoch 820: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.1351 - bpp: 1.5632 - mse: 4.7971e-05\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0916 - bpp: 1.5474 - mse: 4.7126e-05\n",
      "Epoch 821: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.0916 - bpp: 1.5474 - mse: 4.7126e-05\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5210 - bpp: 1.5909 - mse: 5.8903e-05\n",
      "Epoch 822: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.5210 - bpp: 1.5909 - mse: 5.8903e-05\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3678 - bpp: 1.5943 - mse: 5.4124e-05\n",
      "Epoch 823: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.3678 - bpp: 1.5943 - mse: 5.4124e-05\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4560 - bpp: 1.5823 - mse: 5.7181e-05\n",
      "Epoch 824: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4560 - bpp: 1.5823 - mse: 5.7181e-05\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2522 - bpp: 1.5543 - mse: 5.1818e-05\n",
      "Epoch 825: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.2522 - bpp: 1.5543 - mse: 5.1818e-05\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1531 - bpp: 1.5233 - mse: 4.9737e-05\n",
      "Epoch 826: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.1531 - bpp: 1.5233 - mse: 4.9737e-05\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4085 - bpp: 1.5925 - mse: 5.5421e-05\n",
      "Epoch 827: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4085 - bpp: 1.5925 - mse: 5.5421e-05\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4588 - bpp: 1.6050 - mse: 5.6572e-05\n",
      "Epoch 828: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.4588 - bpp: 1.6050 - mse: 5.6572e-05\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2553 - bpp: 1.5872 - mse: 5.0906e-05\n",
      "Epoch 829: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2553 - bpp: 1.5872 - mse: 5.0906e-05\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2884 - bpp: 1.5573 - mse: 5.2831e-05\n",
      "Epoch 830: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2884 - bpp: 1.5573 - mse: 5.2831e-05\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1665 - bpp: 1.5485 - mse: 4.9379e-05\n",
      "Epoch 831: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1665 - bpp: 1.5485 - mse: 4.9379e-05\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1213 - bpp: 1.5314 - mse: 4.8519e-05\n",
      "Epoch 832: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.1213 - bpp: 1.5314 - mse: 4.8519e-05\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2392 - bpp: 1.5517 - mse: 5.1498e-05\n",
      "Epoch 833: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.2392 - bpp: 1.5517 - mse: 5.1498e-05\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2717 - bpp: 1.5487 - mse: 5.2582e-05\n",
      "Epoch 834: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2717 - bpp: 1.5487 - mse: 5.2582e-05\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1743 - bpp: 1.5185 - mse: 5.0530e-05\n",
      "Epoch 835: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1743 - bpp: 1.5185 - mse: 5.0530e-05\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2075 - bpp: 1.5552 - mse: 5.0426e-05\n",
      "Epoch 836: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2075 - bpp: 1.5552 - mse: 5.0426e-05\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4085 - bpp: 1.6141 - mse: 5.4760e-05\n",
      "Epoch 837: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.4085 - bpp: 1.6141 - mse: 5.4760e-05\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2701 - bpp: 1.5531 - mse: 5.2398e-05\n",
      "Epoch 838: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2701 - bpp: 1.5531 - mse: 5.2398e-05\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3423 - bpp: 1.5795 - mse: 5.3797e-05\n",
      "Epoch 839: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.3423 - bpp: 1.5795 - mse: 5.3797e-05\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0230 - bpp: 1.5116 - mse: 4.6125e-05\n",
      "Epoch 840: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3.0230 - bpp: 1.5116 - mse: 4.6125e-05\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0992 - bpp: 1.5228 - mse: 4.8107e-05\n",
      "Epoch 841: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.0992 - bpp: 1.5228 - mse: 4.8107e-05\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0854 - bpp: 1.5367 - mse: 4.7263e-05\n",
      "Epoch 842: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0854 - bpp: 1.5367 - mse: 4.7263e-05\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2794 - bpp: 1.5734 - mse: 5.2063e-05\n",
      "Epoch 843: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2794 - bpp: 1.5734 - mse: 5.2063e-05\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0456 - bpp: 1.5277 - mse: 4.6323e-05\n",
      "Epoch 844: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0456 - bpp: 1.5277 - mse: 4.6323e-05\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6987 - bpp: 1.6228 - mse: 6.3352e-05\n",
      "Epoch 845: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.6987 - bpp: 1.6228 - mse: 6.3352e-05\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9883 - bpp: 1.4964 - mse: 4.5528e-05\n",
      "Epoch 846: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9883 - bpp: 1.4964 - mse: 4.5528e-05\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3772 - bpp: 1.6046 - mse: 5.4097e-05\n",
      "Epoch 847: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3772 - bpp: 1.6046 - mse: 5.4097e-05\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0685 - bpp: 1.5358 - mse: 4.6775e-05\n",
      "Epoch 848: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0685 - bpp: 1.5358 - mse: 4.6775e-05\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1513 - bpp: 1.5617 - mse: 4.8512e-05\n",
      "Epoch 849: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.1513 - bpp: 1.5617 - mse: 4.8512e-05\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1158 - bpp: 1.5472 - mse: 4.7869e-05\n",
      "Epoch 850: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1158 - bpp: 1.5472 - mse: 4.7869e-05\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1128 - bpp: 1.5209 - mse: 4.8582e-05\n",
      "Epoch 851: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.1128 - bpp: 1.5209 - mse: 4.8582e-05\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3584 - bpp: 1.5804 - mse: 5.4262e-05\n",
      "Epoch 852: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.3584 - bpp: 1.5804 - mse: 5.4262e-05\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1008 - bpp: 1.5057 - mse: 4.8680e-05\n",
      "Epoch 853: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1008 - bpp: 1.5057 - mse: 4.8680e-05\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3195 - bpp: 1.5694 - mse: 5.3407e-05\n",
      "Epoch 854: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.3195 - bpp: 1.5694 - mse: 5.3407e-05\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2010 - bpp: 1.5416 - mse: 5.0641e-05\n",
      "Epoch 855: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.2010 - bpp: 1.5416 - mse: 5.0641e-05\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3697 - bpp: 1.5886 - mse: 5.4354e-05\n",
      "Epoch 856: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.3697 - bpp: 1.5886 - mse: 5.4354e-05\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1587 - bpp: 1.5269 - mse: 4.9801e-05\n",
      "Epoch 857: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1587 - bpp: 1.5269 - mse: 4.9801e-05\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1079 - bpp: 1.5306 - mse: 4.8132e-05\n",
      "Epoch 858: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.1079 - bpp: 1.5306 - mse: 4.8132e-05\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1048 - bpp: 1.5075 - mse: 4.8746e-05\n",
      "Epoch 859: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1048 - bpp: 1.5075 - mse: 4.8746e-05\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2757 - bpp: 1.5497 - mse: 5.2673e-05\n",
      "Epoch 860: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.2757 - bpp: 1.5497 - mse: 5.2673e-05\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4223 - bpp: 1.5740 - mse: 5.6406e-05\n",
      "Epoch 861: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.4223 - bpp: 1.5740 - mse: 5.6406e-05\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4555 - bpp: 1.5941 - mse: 5.6805e-05\n",
      "Epoch 862: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.4555 - bpp: 1.5941 - mse: 5.6805e-05\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9996 - bpp: 1.5203 - mse: 4.5143e-05\n",
      "Epoch 863: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.9996 - bpp: 1.5203 - mse: 4.5143e-05\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1437 - bpp: 1.5402 - mse: 4.8937e-05\n",
      "Epoch 864: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1437 - bpp: 1.5402 - mse: 4.8937e-05\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3477 - bpp: 1.6050 - mse: 5.3185e-05\n",
      "Epoch 865: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3477 - bpp: 1.6050 - mse: 5.3185e-05\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0731 - bpp: 1.5192 - mse: 4.7421e-05\n",
      "Epoch 866: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0731 - bpp: 1.5192 - mse: 4.7421e-05\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0778 - bpp: 1.5377 - mse: 4.7001e-05\n",
      "Epoch 867: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0778 - bpp: 1.5377 - mse: 4.7001e-05\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1033 - bpp: 1.5273 - mse: 4.8096e-05\n",
      "Epoch 868: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.1033 - bpp: 1.5273 - mse: 4.8096e-05\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1484 - bpp: 1.5606 - mse: 4.8454e-05\n",
      "Epoch 869: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.1484 - bpp: 1.5606 - mse: 4.8454e-05\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1531 - bpp: 1.5411 - mse: 4.9192e-05\n",
      "Epoch 870: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.1531 - bpp: 1.5411 - mse: 4.9192e-05\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2609 - bpp: 1.5649 - mse: 5.1760e-05\n",
      "Epoch 871: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.2609 - bpp: 1.5649 - mse: 5.1760e-05\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1098 - bpp: 1.5522 - mse: 4.7534e-05\n",
      "Epoch 872: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1098 - bpp: 1.5522 - mse: 4.7534e-05\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1204 - bpp: 1.5359 - mse: 4.8355e-05\n",
      "Epoch 873: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1204 - bpp: 1.5359 - mse: 4.8355e-05\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1154 - bpp: 1.5483 - mse: 4.7824e-05\n",
      "Epoch 874: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.1154 - bpp: 1.5483 - mse: 4.7824e-05\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4226 - bpp: 1.6197 - mse: 5.5020e-05\n",
      "Epoch 875: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4226 - bpp: 1.6197 - mse: 5.5020e-05\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1849 - bpp: 1.5496 - mse: 4.9906e-05\n",
      "Epoch 876: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1849 - bpp: 1.5496 - mse: 4.9906e-05\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9563 - bpp: 1.4960 - mse: 4.4567e-05\n",
      "Epoch 877: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9563 - bpp: 1.4960 - mse: 4.4567e-05\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2983 - bpp: 1.5880 - mse: 5.2193e-05\n",
      "Epoch 878: loss did not improve from 2.94548\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2983 - bpp: 1.5880 - mse: 5.2193e-05\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9201 - bpp: 1.4841 - mse: 4.3825e-05\n",
      "Epoch 879: loss improved from 2.94548 to 2.92013, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9201 - bpp: 1.4841 - mse: 4.3825e-05\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1515 - bpp: 1.5388 - mse: 4.9217e-05\n",
      "Epoch 880: loss did not improve from 2.92013\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1515 - bpp: 1.5388 - mse: 4.9217e-05\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2708 - bpp: 1.5871 - mse: 5.1382e-05\n",
      "Epoch 881: loss did not improve from 2.92013\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2708 - bpp: 1.5871 - mse: 5.1382e-05\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9047 - bpp: 1.4848 - mse: 4.3334e-05\n",
      "Epoch 882: loss improved from 2.92013 to 2.90475, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9047 - bpp: 1.4848 - mse: 4.3334e-05\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9121 - bpp: 1.4689 - mse: 4.4044e-05\n",
      "Epoch 883: loss did not improve from 2.90475\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9121 - bpp: 1.4689 - mse: 4.4044e-05\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1704 - bpp: 1.5620 - mse: 4.9083e-05\n",
      "Epoch 884: loss did not improve from 2.90475\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1704 - bpp: 1.5620 - mse: 4.9083e-05\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2801 - bpp: 1.5773 - mse: 5.1965e-05\n",
      "Epoch 885: loss did not improve from 2.90475\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.2801 - bpp: 1.5773 - mse: 5.1965e-05\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1807 - bpp: 1.5453 - mse: 4.9909e-05\n",
      "Epoch 886: loss did not improve from 2.90475\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1807 - bpp: 1.5453 - mse: 4.9909e-05\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2390 - bpp: 1.5331 - mse: 5.2062e-05\n",
      "Epoch 887: loss did not improve from 2.90475\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2390 - bpp: 1.5331 - mse: 5.2062e-05\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2638 - bpp: 1.5707 - mse: 5.1670e-05\n",
      "Epoch 888: loss did not improve from 2.90475\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.2638 - bpp: 1.5707 - mse: 5.1670e-05\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8892 - bpp: 1.4916 - mse: 4.2651e-05\n",
      "Epoch 889: loss improved from 2.90475 to 2.88919, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8892 - bpp: 1.4916 - mse: 4.2651e-05\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2519 - bpp: 1.5937 - mse: 5.0603e-05\n",
      "Epoch 890: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.2519 - bpp: 1.5937 - mse: 5.0603e-05\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2981 - bpp: 1.5415 - mse: 5.3608e-05\n",
      "Epoch 891: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2981 - bpp: 1.5415 - mse: 5.3608e-05\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0741 - bpp: 1.4959 - mse: 4.8164e-05\n",
      "Epoch 892: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0741 - bpp: 1.4959 - mse: 4.8164e-05\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3099 - bpp: 1.5618 - mse: 5.3349e-05\n",
      "Epoch 893: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.3099 - bpp: 1.5618 - mse: 5.3349e-05\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5292 - bpp: 1.6216 - mse: 5.8213e-05\n",
      "Epoch 894: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.5292 - bpp: 1.6216 - mse: 5.8213e-05\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1751 - bpp: 1.5418 - mse: 4.9843e-05\n",
      "Epoch 895: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.1751 - bpp: 1.5418 - mse: 4.9843e-05\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2758 - bpp: 1.5574 - mse: 5.2441e-05\n",
      "Epoch 896: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2758 - bpp: 1.5574 - mse: 5.2441e-05\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2571 - bpp: 1.5644 - mse: 5.1658e-05\n",
      "Epoch 897: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2571 - bpp: 1.5644 - mse: 5.1658e-05\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0532 - bpp: 1.4962 - mse: 4.7517e-05\n",
      "Epoch 898: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.0532 - bpp: 1.4962 - mse: 4.7517e-05\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3563 - bpp: 1.5748 - mse: 5.4366e-05\n",
      "Epoch 899: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.3563 - bpp: 1.5748 - mse: 5.4366e-05\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1855 - bpp: 1.5699 - mse: 4.9303e-05\n",
      "Epoch 900: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.1855 - bpp: 1.5699 - mse: 4.9303e-05\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0525 - bpp: 1.4958 - mse: 4.7508e-05\n",
      "Epoch 901: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0525 - bpp: 1.4958 - mse: 4.7508e-05\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3044 - bpp: 1.5806 - mse: 5.2608e-05\n",
      "Epoch 902: loss did not improve from 2.88919\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3044 - bpp: 1.5806 - mse: 5.2608e-05\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8584 - bpp: 1.4873 - mse: 4.1841e-05\n",
      "Epoch 903: loss improved from 2.88919 to 2.85836, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8584 - bpp: 1.4873 - mse: 4.1841e-05\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1077 - bpp: 1.5570 - mse: 4.7325e-05\n",
      "Epoch 904: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1077 - bpp: 1.5570 - mse: 4.7325e-05\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2008 - bpp: 1.5645 - mse: 4.9934e-05\n",
      "Epoch 905: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2008 - bpp: 1.5645 - mse: 4.9934e-05\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3016 - bpp: 1.5611 - mse: 5.3115e-05\n",
      "Epoch 906: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.3016 - bpp: 1.5611 - mse: 5.3115e-05\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6458 - bpp: 1.6358 - mse: 6.1340e-05\n",
      "Epoch 907: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.6458 - bpp: 1.6358 - mse: 6.1340e-05\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3120 - bpp: 1.5436 - mse: 5.3967e-05\n",
      "Epoch 908: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3120 - bpp: 1.5436 - mse: 5.3967e-05\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2714 - bpp: 1.5900 - mse: 5.1313e-05\n",
      "Epoch 909: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2714 - bpp: 1.5900 - mse: 5.1313e-05\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2034 - bpp: 1.5561 - mse: 5.0272e-05\n",
      "Epoch 910: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2034 - bpp: 1.5561 - mse: 5.0272e-05\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1299 - bpp: 1.5513 - mse: 4.8176e-05\n",
      "Epoch 911: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1299 - bpp: 1.5513 - mse: 4.8176e-05\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9351 - bpp: 1.4879 - mse: 4.4164e-05\n",
      "Epoch 912: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9351 - bpp: 1.4879 - mse: 4.4164e-05\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3371 - bpp: 1.6028 - mse: 5.2929e-05\n",
      "Epoch 913: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.3371 - bpp: 1.6028 - mse: 5.2929e-05\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3911 - bpp: 1.6078 - mse: 5.4421e-05\n",
      "Epoch 914: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.3911 - bpp: 1.6078 - mse: 5.4421e-05\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1760 - bpp: 1.5563 - mse: 4.9428e-05\n",
      "Epoch 915: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.1760 - bpp: 1.5563 - mse: 4.9428e-05\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9695 - bpp: 1.4791 - mse: 4.5483e-05\n",
      "Epoch 916: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9695 - bpp: 1.4791 - mse: 4.5483e-05\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9118 - bpp: 1.5026 - mse: 4.3007e-05\n",
      "Epoch 917: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9118 - bpp: 1.5026 - mse: 4.3007e-05\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5238 - bpp: 1.5759 - mse: 5.9445e-05\n",
      "Epoch 918: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.5238 - bpp: 1.5759 - mse: 5.9445e-05\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2430 - bpp: 1.5412 - mse: 5.1933e-05\n",
      "Epoch 919: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2430 - bpp: 1.5412 - mse: 5.1933e-05\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0676 - bpp: 1.5054 - mse: 4.7672e-05\n",
      "Epoch 920: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0676 - bpp: 1.5054 - mse: 4.7672e-05\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1525 - bpp: 1.5617 - mse: 4.8548e-05\n",
      "Epoch 921: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1525 - bpp: 1.5617 - mse: 4.8548e-05\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4532 - bpp: 1.5922 - mse: 5.6793e-05\n",
      "Epoch 922: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4532 - bpp: 1.5922 - mse: 5.6793e-05\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4906 - bpp: 1.6124 - mse: 5.7318e-05\n",
      "Epoch 923: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.4906 - bpp: 1.6124 - mse: 5.7318e-05\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1190 - bpp: 1.5596 - mse: 4.7590e-05\n",
      "Epoch 924: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.1190 - bpp: 1.5596 - mse: 4.7590e-05\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4418 - bpp: 1.6085 - mse: 5.5946e-05\n",
      "Epoch 925: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.4418 - bpp: 1.6085 - mse: 5.5946e-05\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1606 - bpp: 1.5596 - mse: 4.8860e-05\n",
      "Epoch 926: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.1606 - bpp: 1.5596 - mse: 4.8860e-05\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1899 - bpp: 1.5507 - mse: 5.0025e-05\n",
      "Epoch 927: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1899 - bpp: 1.5507 - mse: 5.0025e-05\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2282 - bpp: 1.5681 - mse: 5.0660e-05\n",
      "Epoch 928: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.2282 - bpp: 1.5681 - mse: 5.0660e-05\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1671 - bpp: 1.5542 - mse: 4.9223e-05\n",
      "Epoch 929: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.1671 - bpp: 1.5542 - mse: 4.9223e-05\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3708 - bpp: 1.5805 - mse: 5.4637e-05\n",
      "Epoch 930: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3708 - bpp: 1.5805 - mse: 5.4637e-05\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4018 - bpp: 1.6008 - mse: 5.4962e-05\n",
      "Epoch 931: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.4018 - bpp: 1.6008 - mse: 5.4962e-05\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2659 - bpp: 1.6036 - mse: 5.0727e-05\n",
      "Epoch 932: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2659 - bpp: 1.6036 - mse: 5.0727e-05\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2474 - bpp: 1.5615 - mse: 5.1450e-05\n",
      "Epoch 933: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.2474 - bpp: 1.5615 - mse: 5.1450e-05\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0457 - bpp: 1.5381 - mse: 4.6010e-05\n",
      "Epoch 934: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0457 - bpp: 1.5381 - mse: 4.6010e-05\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1286 - bpp: 1.5450 - mse: 4.8328e-05\n",
      "Epoch 935: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1286 - bpp: 1.5450 - mse: 4.8328e-05\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2338 - bpp: 1.5625 - mse: 5.1006e-05\n",
      "Epoch 936: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.2338 - bpp: 1.5625 - mse: 5.1006e-05\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1543 - bpp: 1.5284 - mse: 4.9617e-05\n",
      "Epoch 937: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1543 - bpp: 1.5284 - mse: 4.9617e-05\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2321 - bpp: 1.5463 - mse: 5.1447e-05\n",
      "Epoch 938: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2321 - bpp: 1.5463 - mse: 5.1447e-05\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9422 - bpp: 1.5008 - mse: 4.3989e-05\n",
      "Epoch 939: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9422 - bpp: 1.5008 - mse: 4.3989e-05\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1051 - bpp: 1.5285 - mse: 4.8113e-05\n",
      "Epoch 940: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1051 - bpp: 1.5285 - mse: 4.8113e-05\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4892 - bpp: 1.5634 - mse: 5.8769e-05\n",
      "Epoch 941: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.4892 - bpp: 1.5634 - mse: 5.8769e-05\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3672 - bpp: 1.5771 - mse: 5.4630e-05\n",
      "Epoch 942: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3672 - bpp: 1.5771 - mse: 5.4630e-05\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1849 - bpp: 1.5304 - mse: 5.0491e-05\n",
      "Epoch 943: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1849 - bpp: 1.5304 - mse: 5.0491e-05\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9772 - bpp: 1.6642 - mse: 7.0588e-05\n",
      "Epoch 944: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.9772 - bpp: 1.6642 - mse: 7.0588e-05\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9373 - bpp: 1.4978 - mse: 4.3930e-05\n",
      "Epoch 945: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9373 - bpp: 1.4978 - mse: 4.3930e-05\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0746 - bpp: 1.5273 - mse: 4.7218e-05\n",
      "Epoch 946: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0746 - bpp: 1.5273 - mse: 4.7218e-05\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8936 - bpp: 1.5007 - mse: 4.2506e-05\n",
      "Epoch 947: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.8936 - bpp: 1.5007 - mse: 4.2506e-05\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2777 - bpp: 1.5668 - mse: 5.2213e-05\n",
      "Epoch 948: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2777 - bpp: 1.5668 - mse: 5.2213e-05\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2314 - bpp: 1.5802 - mse: 5.0391e-05\n",
      "Epoch 949: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2314 - bpp: 1.5802 - mse: 5.0391e-05\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2008 - bpp: 1.5682 - mse: 4.9821e-05\n",
      "Epoch 950: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2008 - bpp: 1.5682 - mse: 4.9821e-05\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0930 - bpp: 1.5586 - mse: 4.6829e-05\n",
      "Epoch 951: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0930 - bpp: 1.5586 - mse: 4.6829e-05\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1247 - bpp: 1.5360 - mse: 4.8483e-05\n",
      "Epoch 952: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.1247 - bpp: 1.5360 - mse: 4.8483e-05\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1228 - bpp: 1.5612 - mse: 4.7656e-05\n",
      "Epoch 953: loss did not improve from 2.85836\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.1228 - bpp: 1.5612 - mse: 4.7656e-05\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8535 - bpp: 1.4730 - mse: 4.2129e-05\n",
      "Epoch 954: loss improved from 2.85836 to 2.85353, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8535 - bpp: 1.4730 - mse: 4.2129e-05\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0192 - bpp: 1.5466 - mse: 4.4939e-05\n",
      "Epoch 955: loss did not improve from 2.85353\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0192 - bpp: 1.5466 - mse: 4.4939e-05\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2915 - bpp: 1.5821 - mse: 5.2166e-05\n",
      "Epoch 956: loss did not improve from 2.85353\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2915 - bpp: 1.5821 - mse: 5.2166e-05\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8323 - bpp: 1.4703 - mse: 4.1566e-05\n",
      "Epoch 957: loss improved from 2.85353 to 2.83233, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8323 - bpp: 1.4703 - mse: 4.1566e-05\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9154 - bpp: 1.4981 - mse: 4.3252e-05\n",
      "Epoch 958: loss did not improve from 2.83233\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9154 - bpp: 1.4981 - mse: 4.3252e-05\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0840 - bpp: 1.5249 - mse: 4.7581e-05\n",
      "Epoch 959: loss did not improve from 2.83233\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0840 - bpp: 1.5249 - mse: 4.7581e-05\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6181 - bpp: 1.6292 - mse: 6.0697e-05\n",
      "Epoch 960: loss did not improve from 2.83233\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.6181 - bpp: 1.6292 - mse: 6.0697e-05\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2580 - bpp: 1.5695 - mse: 5.1530e-05\n",
      "Epoch 961: loss did not improve from 2.83233\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2580 - bpp: 1.5695 - mse: 5.1530e-05\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8155 - bpp: 1.4722 - mse: 4.0994e-05\n",
      "Epoch 962: loss improved from 2.83233 to 2.81552, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8155 - bpp: 1.4722 - mse: 4.0994e-05\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9307 - bpp: 1.4903 - mse: 4.3960e-05\n",
      "Epoch 963: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.9307 - bpp: 1.4903 - mse: 4.3960e-05\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9124 - bpp: 1.5060 - mse: 4.2923e-05\n",
      "Epoch 964: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9124 - bpp: 1.5060 - mse: 4.2923e-05\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2755 - bpp: 1.5739 - mse: 5.1930e-05\n",
      "Epoch 965: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2755 - bpp: 1.5739 - mse: 5.1930e-05\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8870 - bpp: 1.5054 - mse: 4.2163e-05\n",
      "Epoch 966: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8870 - bpp: 1.5054 - mse: 4.2163e-05\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1454 - bpp: 1.5618 - mse: 4.8326e-05\n",
      "Epoch 967: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.1454 - bpp: 1.5618 - mse: 4.8326e-05\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1015 - bpp: 1.5462 - mse: 4.7465e-05\n",
      "Epoch 968: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1015 - bpp: 1.5462 - mse: 4.7465e-05\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1055 - bpp: 1.5396 - mse: 4.7785e-05\n",
      "Epoch 969: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.1055 - bpp: 1.5396 - mse: 4.7785e-05\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9837 - bpp: 1.5342 - mse: 4.4238e-05\n",
      "Epoch 970: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9837 - bpp: 1.5342 - mse: 4.4238e-05\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1229 - bpp: 1.5543 - mse: 4.7871e-05\n",
      "Epoch 971: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1229 - bpp: 1.5543 - mse: 4.7871e-05\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9828 - bpp: 1.4987 - mse: 4.5290e-05\n",
      "Epoch 972: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9828 - bpp: 1.4987 - mse: 4.5290e-05\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9637 - bpp: 1.5045 - mse: 4.4532e-05\n",
      "Epoch 973: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9637 - bpp: 1.5045 - mse: 4.4532e-05\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2107 - bpp: 1.5641 - mse: 5.0250e-05\n",
      "Epoch 974: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2107 - bpp: 1.5641 - mse: 5.0250e-05\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9976 - bpp: 1.5126 - mse: 4.5317e-05\n",
      "Epoch 975: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9976 - bpp: 1.5126 - mse: 4.5317e-05\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0698 - bpp: 1.5239 - mse: 4.7176e-05\n",
      "Epoch 976: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0698 - bpp: 1.5239 - mse: 4.7176e-05\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5090 - bpp: 1.6002 - mse: 5.8252e-05\n",
      "Epoch 977: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.5090 - bpp: 1.6002 - mse: 5.8252e-05\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2895 - bpp: 1.5755 - mse: 5.2306e-05\n",
      "Epoch 978: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2895 - bpp: 1.5755 - mse: 5.2306e-05\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9207 - bpp: 1.4958 - mse: 4.3486e-05\n",
      "Epoch 979: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9207 - bpp: 1.4958 - mse: 4.3486e-05\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2526 - bpp: 1.5874 - mse: 5.0818e-05\n",
      "Epoch 980: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.2526 - bpp: 1.5874 - mse: 5.0818e-05\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0939 - bpp: 1.5455 - mse: 4.7251e-05\n",
      "Epoch 981: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.0939 - bpp: 1.5455 - mse: 4.7251e-05\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1009 - bpp: 1.5406 - mse: 4.7619e-05\n",
      "Epoch 982: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1009 - bpp: 1.5406 - mse: 4.7619e-05\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0058 - bpp: 1.5057 - mse: 4.5781e-05\n",
      "Epoch 983: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0058 - bpp: 1.5057 - mse: 4.5781e-05\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9221 - bpp: 1.5122 - mse: 4.3025e-05\n",
      "Epoch 984: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9221 - bpp: 1.5122 - mse: 4.3025e-05\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0885 - bpp: 1.5564 - mse: 4.6756e-05\n",
      "Epoch 985: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0885 - bpp: 1.5564 - mse: 4.6756e-05\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1669 - bpp: 1.5497 - mse: 4.9352e-05\n",
      "Epoch 986: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1669 - bpp: 1.5497 - mse: 4.9352e-05\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3344 - bpp: 1.5761 - mse: 5.3659e-05\n",
      "Epoch 987: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.3344 - bpp: 1.5761 - mse: 5.3659e-05\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0438 - bpp: 1.5234 - mse: 4.6399e-05\n",
      "Epoch 988: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0438 - bpp: 1.5234 - mse: 4.6399e-05\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1530 - bpp: 1.5642 - mse: 4.8486e-05\n",
      "Epoch 989: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1530 - bpp: 1.5642 - mse: 4.8486e-05\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2257 - bpp: 1.5453 - mse: 5.1281e-05\n",
      "Epoch 990: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2257 - bpp: 1.5453 - mse: 5.1281e-05\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1560 - bpp: 1.5431 - mse: 4.9224e-05\n",
      "Epoch 991: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1560 - bpp: 1.5431 - mse: 4.9224e-05\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1566 - bpp: 1.5529 - mse: 4.8939e-05\n",
      "Epoch 992: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.1566 - bpp: 1.5529 - mse: 4.8939e-05\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9854 - bpp: 1.5333 - mse: 4.4315e-05\n",
      "Epoch 993: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9854 - bpp: 1.5333 - mse: 4.4315e-05\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1885 - bpp: 1.5296 - mse: 5.0625e-05\n",
      "Epoch 994: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.1885 - bpp: 1.5296 - mse: 5.0625e-05\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3449 - bpp: 1.5756 - mse: 5.3992e-05\n",
      "Epoch 995: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3449 - bpp: 1.5756 - mse: 5.3992e-05\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1854 - bpp: 1.5487 - mse: 4.9949e-05\n",
      "Epoch 996: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1854 - bpp: 1.5487 - mse: 4.9949e-05\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9374 - bpp: 1.4781 - mse: 4.4534e-05\n",
      "Epoch 997: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9374 - bpp: 1.4781 - mse: 4.4534e-05\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0767 - bpp: 1.5254 - mse: 4.7343e-05\n",
      "Epoch 998: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.0767 - bpp: 1.5254 - mse: 4.7343e-05\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0996 - bpp: 1.5097 - mse: 4.8518e-05\n",
      "Epoch 999: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0996 - bpp: 1.5097 - mse: 4.8518e-05\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9695 - bpp: 1.5013 - mse: 4.4808e-05\n",
      "Epoch 1000: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9695 - bpp: 1.5013 - mse: 4.4808e-05\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0690 - bpp: 1.5338 - mse: 4.6853e-05\n",
      "Epoch 1001: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0690 - bpp: 1.5338 - mse: 4.6853e-05\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0525 - bpp: 1.5271 - mse: 4.6553e-05\n",
      "Epoch 1002: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0525 - bpp: 1.5271 - mse: 4.6553e-05\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2041 - bpp: 1.5729 - mse: 4.9780e-05\n",
      "Epoch 1003: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2041 - bpp: 1.5729 - mse: 4.9780e-05\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0966 - bpp: 1.5429 - mse: 4.7414e-05\n",
      "Epoch 1004: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0966 - bpp: 1.5429 - mse: 4.7414e-05\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0238 - bpp: 1.5162 - mse: 4.6009e-05\n",
      "Epoch 1005: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0238 - bpp: 1.5162 - mse: 4.6009e-05\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2637 - bpp: 1.5791 - mse: 5.1408e-05\n",
      "Epoch 1006: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2637 - bpp: 1.5791 - mse: 5.1408e-05\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0033 - bpp: 1.5198 - mse: 4.5273e-05\n",
      "Epoch 1007: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0033 - bpp: 1.5198 - mse: 4.5273e-05\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0596 - bpp: 1.5228 - mse: 4.6901e-05\n",
      "Epoch 1008: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0596 - bpp: 1.5228 - mse: 4.6901e-05\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3207 - bpp: 1.5963 - mse: 5.2624e-05\n",
      "Epoch 1009: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3207 - bpp: 1.5963 - mse: 5.2624e-05\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0556 - bpp: 1.5221 - mse: 4.6796e-05\n",
      "Epoch 1010: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0556 - bpp: 1.5221 - mse: 4.6796e-05\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0636 - bpp: 1.5237 - mse: 4.6994e-05\n",
      "Epoch 1011: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.0636 - bpp: 1.5237 - mse: 4.6994e-05\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0206 - bpp: 1.5226 - mse: 4.5716e-05\n",
      "Epoch 1012: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0206 - bpp: 1.5226 - mse: 4.5716e-05\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9180 - bpp: 1.5049 - mse: 4.3125e-05\n",
      "Epoch 1013: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9180 - bpp: 1.5049 - mse: 4.3125e-05\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0882 - bpp: 1.5302 - mse: 4.7547e-05\n",
      "Epoch 1014: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0882 - bpp: 1.5302 - mse: 4.7547e-05\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5125 - bpp: 1.5613 - mse: 5.9546e-05\n",
      "Epoch 1015: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.5125 - bpp: 1.5613 - mse: 5.9546e-05\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1103 - bpp: 1.5451 - mse: 4.7766e-05\n",
      "Epoch 1016: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1103 - bpp: 1.5451 - mse: 4.7766e-05\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9579 - bpp: 1.4824 - mse: 4.5028e-05\n",
      "Epoch 1017: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9579 - bpp: 1.4824 - mse: 4.5028e-05\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2294 - bpp: 1.5751 - mse: 5.0486e-05\n",
      "Epoch 1018: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.2294 - bpp: 1.5751 - mse: 5.0486e-05\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1384 - bpp: 1.5354 - mse: 4.8918e-05\n",
      "Epoch 1019: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.1384 - bpp: 1.5354 - mse: 4.8918e-05\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0966 - bpp: 1.5420 - mse: 4.7443e-05\n",
      "Epoch 1020: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0966 - bpp: 1.5420 - mse: 4.7443e-05\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1098 - bpp: 1.5403 - mse: 4.7898e-05\n",
      "Epoch 1021: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1098 - bpp: 1.5403 - mse: 4.7898e-05\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8430 - bpp: 1.4888 - mse: 4.1327e-05\n",
      "Epoch 1022: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8430 - bpp: 1.4888 - mse: 4.1327e-05\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0284 - bpp: 1.5047 - mse: 4.6498e-05\n",
      "Epoch 1023: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0284 - bpp: 1.5047 - mse: 4.6498e-05\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2841 - bpp: 1.5593 - mse: 5.2636e-05\n",
      "Epoch 1024: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2841 - bpp: 1.5593 - mse: 5.2636e-05\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5241 - bpp: 1.6210 - mse: 5.8078e-05\n",
      "Epoch 1025: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.5241 - bpp: 1.6210 - mse: 5.8078e-05\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0123 - bpp: 1.5193 - mse: 4.5561e-05\n",
      "Epoch 1026: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0123 - bpp: 1.5193 - mse: 4.5561e-05\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1657 - bpp: 1.5714 - mse: 4.8653e-05\n",
      "Epoch 1027: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1657 - bpp: 1.5714 - mse: 4.8653e-05\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1468 - bpp: 1.5400 - mse: 4.9038e-05\n",
      "Epoch 1028: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1468 - bpp: 1.5400 - mse: 4.9038e-05\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1852 - bpp: 1.5793 - mse: 4.9007e-05\n",
      "Epoch 1029: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.1852 - bpp: 1.5793 - mse: 4.9007e-05\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3977 - bpp: 1.5791 - mse: 5.5497e-05\n",
      "Epoch 1030: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.3977 - bpp: 1.5791 - mse: 5.5497e-05\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0855 - bpp: 1.5281 - mse: 4.7528e-05\n",
      "Epoch 1031: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0855 - bpp: 1.5281 - mse: 4.7528e-05\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0661 - bpp: 1.4983 - mse: 4.7847e-05\n",
      "Epoch 1032: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.0661 - bpp: 1.4983 - mse: 4.7847e-05\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2566 - bpp: 1.5717 - mse: 5.1419e-05\n",
      "Epoch 1033: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.2566 - bpp: 1.5717 - mse: 5.1419e-05\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3729 - bpp: 1.6019 - mse: 5.4048e-05\n",
      "Epoch 1034: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.3729 - bpp: 1.6019 - mse: 5.4048e-05\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1714 - bpp: 1.5539 - mse: 4.9362e-05\n",
      "Epoch 1035: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1714 - bpp: 1.5539 - mse: 4.9362e-05\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9590 - bpp: 1.5277 - mse: 4.3679e-05\n",
      "Epoch 1036: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9590 - bpp: 1.5277 - mse: 4.3679e-05\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0826 - bpp: 1.5628 - mse: 4.6378e-05\n",
      "Epoch 1037: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0826 - bpp: 1.5628 - mse: 4.6378e-05\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3348 - bpp: 1.5877 - mse: 5.3318e-05\n",
      "Epoch 1038: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.3348 - bpp: 1.5877 - mse: 5.3318e-05\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9922 - bpp: 1.4954 - mse: 4.5679e-05\n",
      "Epoch 1039: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9922 - bpp: 1.4954 - mse: 4.5679e-05\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1018 - bpp: 1.5384 - mse: 4.7711e-05\n",
      "Epoch 1040: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1018 - bpp: 1.5384 - mse: 4.7711e-05\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0186 - bpp: 1.5373 - mse: 4.5207e-05\n",
      "Epoch 1041: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0186 - bpp: 1.5373 - mse: 4.5207e-05\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2267 - bpp: 1.5739 - mse: 5.0439e-05\n",
      "Epoch 1042: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.2267 - bpp: 1.5739 - mse: 5.0439e-05\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0017 - bpp: 1.5233 - mse: 4.5117e-05\n",
      "Epoch 1043: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0017 - bpp: 1.5233 - mse: 4.5117e-05\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0656 - bpp: 1.5431 - mse: 4.6464e-05\n",
      "Epoch 1044: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.0656 - bpp: 1.5431 - mse: 4.6464e-05\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1680 - bpp: 1.5480 - mse: 4.9439e-05\n",
      "Epoch 1045: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1680 - bpp: 1.5480 - mse: 4.9439e-05\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8970 - bpp: 1.4788 - mse: 4.3281e-05\n",
      "Epoch 1046: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.8970 - bpp: 1.4788 - mse: 4.3281e-05\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9699 - bpp: 1.5121 - mse: 4.4487e-05\n",
      "Epoch 1047: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9699 - bpp: 1.5121 - mse: 4.4487e-05\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2906 - bpp: 1.5774 - mse: 5.2282e-05\n",
      "Epoch 1048: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2906 - bpp: 1.5774 - mse: 5.2282e-05\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8221 - bpp: 1.4920 - mse: 4.0594e-05\n",
      "Epoch 1049: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8221 - bpp: 1.4920 - mse: 4.0594e-05\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0135 - bpp: 1.5217 - mse: 4.5526e-05\n",
      "Epoch 1050: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0135 - bpp: 1.5217 - mse: 4.5526e-05\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9713 - bpp: 1.4902 - mse: 4.5197e-05\n",
      "Epoch 1051: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9713 - bpp: 1.4902 - mse: 4.5197e-05\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0795 - bpp: 1.5158 - mse: 4.7720e-05\n",
      "Epoch 1052: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0795 - bpp: 1.5158 - mse: 4.7720e-05\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9196 - bpp: 1.4583 - mse: 4.4595e-05\n",
      "Epoch 1053: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9196 - bpp: 1.4583 - mse: 4.4595e-05\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9962 - bpp: 1.5117 - mse: 4.5306e-05\n",
      "Epoch 1054: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9962 - bpp: 1.5117 - mse: 4.5306e-05\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1318 - bpp: 1.5455 - mse: 4.8410e-05\n",
      "Epoch 1055: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1318 - bpp: 1.5455 - mse: 4.8410e-05\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8969 - bpp: 1.4973 - mse: 4.2713e-05\n",
      "Epoch 1056: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8969 - bpp: 1.4973 - mse: 4.2713e-05\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9033 - bpp: 1.5033 - mse: 4.2726e-05\n",
      "Epoch 1057: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9033 - bpp: 1.5033 - mse: 4.2726e-05\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0673 - bpp: 1.5173 - mse: 4.7303e-05\n",
      "Epoch 1058: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0673 - bpp: 1.5173 - mse: 4.7303e-05\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9555 - bpp: 1.5186 - mse: 4.3851e-05\n",
      "Epoch 1059: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9555 - bpp: 1.5186 - mse: 4.3851e-05\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9936 - bpp: 1.5216 - mse: 4.4919e-05\n",
      "Epoch 1060: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.9936 - bpp: 1.5216 - mse: 4.4919e-05\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0845 - bpp: 1.5327 - mse: 4.7354e-05\n",
      "Epoch 1061: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.0845 - bpp: 1.5327 - mse: 4.7354e-05\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9912 - bpp: 1.5105 - mse: 4.5188e-05\n",
      "Epoch 1062: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9912 - bpp: 1.5105 - mse: 4.5188e-05\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4246 - bpp: 1.5645 - mse: 5.6766e-05\n",
      "Epoch 1063: loss did not improve from 2.81552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.4246 - bpp: 1.5645 - mse: 5.6766e-05\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8131 - bpp: 1.4755 - mse: 4.0821e-05\n",
      "Epoch 1064: loss improved from 2.81552 to 2.81315, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8131 - bpp: 1.4755 - mse: 4.0821e-05\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9557 - bpp: 1.4934 - mse: 4.4627e-05\n",
      "Epoch 1065: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9557 - bpp: 1.4934 - mse: 4.4627e-05\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0404 - bpp: 1.5592 - mse: 4.5204e-05\n",
      "Epoch 1066: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0404 - bpp: 1.5592 - mse: 4.5204e-05\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1483 - bpp: 1.5521 - mse: 4.8713e-05\n",
      "Epoch 1067: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.1483 - bpp: 1.5521 - mse: 4.8713e-05\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1967 - bpp: 1.5510 - mse: 5.0226e-05\n",
      "Epoch 1068: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.1967 - bpp: 1.5510 - mse: 5.0226e-05\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9889 - bpp: 1.5210 - mse: 4.4797e-05\n",
      "Epoch 1069: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9889 - bpp: 1.5210 - mse: 4.4797e-05\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2314 - bpp: 1.5745 - mse: 5.0563e-05\n",
      "Epoch 1070: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2314 - bpp: 1.5745 - mse: 5.0563e-05\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0291 - bpp: 1.5235 - mse: 4.5948e-05\n",
      "Epoch 1071: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0291 - bpp: 1.5235 - mse: 4.5948e-05\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0923 - bpp: 1.5462 - mse: 4.7183e-05\n",
      "Epoch 1072: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0923 - bpp: 1.5462 - mse: 4.7183e-05\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9244 - bpp: 1.4887 - mse: 4.3815e-05\n",
      "Epoch 1073: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9244 - bpp: 1.4887 - mse: 4.3815e-05\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4546 - bpp: 1.5931 - mse: 5.6809e-05\n",
      "Epoch 1074: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.4546 - bpp: 1.5931 - mse: 5.6809e-05\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9557 - bpp: 1.4853 - mse: 4.4873e-05\n",
      "Epoch 1075: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9557 - bpp: 1.4853 - mse: 4.4873e-05\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3350 - bpp: 1.6016 - mse: 5.2901e-05\n",
      "Epoch 1076: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.3350 - bpp: 1.6016 - mse: 5.2901e-05\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8750 - bpp: 1.4872 - mse: 4.2353e-05\n",
      "Epoch 1077: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8750 - bpp: 1.4872 - mse: 4.2353e-05\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0812 - bpp: 1.5411 - mse: 4.7000e-05\n",
      "Epoch 1078: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0812 - bpp: 1.5411 - mse: 4.7000e-05\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0818 - bpp: 1.5132 - mse: 4.7868e-05\n",
      "Epoch 1079: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0818 - bpp: 1.5132 - mse: 4.7868e-05\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0764 - bpp: 1.5270 - mse: 4.7284e-05\n",
      "Epoch 1080: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0764 - bpp: 1.5270 - mse: 4.7284e-05\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8962 - bpp: 1.4800 - mse: 4.3221e-05\n",
      "Epoch 1081: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8962 - bpp: 1.4800 - mse: 4.3221e-05\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9411 - bpp: 1.5031 - mse: 4.3886e-05\n",
      "Epoch 1082: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9411 - bpp: 1.5031 - mse: 4.3886e-05\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2606 - bpp: 1.5749 - mse: 5.1444e-05\n",
      "Epoch 1083: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2606 - bpp: 1.5749 - mse: 5.1444e-05\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9454 - bpp: 1.5002 - mse: 4.4102e-05\n",
      "Epoch 1084: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9454 - bpp: 1.5002 - mse: 4.4102e-05\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0437 - bpp: 1.5313 - mse: 4.6154e-05\n",
      "Epoch 1085: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.0437 - bpp: 1.5313 - mse: 4.6154e-05\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0692 - bpp: 1.5370 - mse: 4.6759e-05\n",
      "Epoch 1086: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.0692 - bpp: 1.5370 - mse: 4.6759e-05\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3350 - bpp: 1.5803 - mse: 5.3550e-05\n",
      "Epoch 1087: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3350 - bpp: 1.5803 - mse: 5.3550e-05\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0692 - bpp: 1.5512 - mse: 4.6324e-05\n",
      "Epoch 1088: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0692 - bpp: 1.5512 - mse: 4.6324e-05\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0406 - bpp: 1.5484 - mse: 4.5538e-05\n",
      "Epoch 1089: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0406 - bpp: 1.5484 - mse: 4.5538e-05\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8187 - bpp: 1.4639 - mse: 4.1345e-05\n",
      "Epoch 1090: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8187 - bpp: 1.4639 - mse: 4.1345e-05\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8316 - bpp: 1.4692 - mse: 4.1577e-05\n",
      "Epoch 1091: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8316 - bpp: 1.4692 - mse: 4.1577e-05\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0024 - bpp: 1.5374 - mse: 4.4709e-05\n",
      "Epoch 1092: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0024 - bpp: 1.5374 - mse: 4.4709e-05\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8986 - bpp: 1.4716 - mse: 4.3547e-05\n",
      "Epoch 1093: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8986 - bpp: 1.4716 - mse: 4.3547e-05\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0713 - bpp: 1.5204 - mse: 4.7331e-05\n",
      "Epoch 1094: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0713 - bpp: 1.5204 - mse: 4.7331e-05\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1329 - bpp: 1.5442 - mse: 4.8486e-05\n",
      "Epoch 1095: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.1329 - bpp: 1.5442 - mse: 4.8486e-05\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0431 - bpp: 1.5306 - mse: 4.6159e-05\n",
      "Epoch 1096: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0431 - bpp: 1.5306 - mse: 4.6159e-05\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2194 - bpp: 1.5473 - mse: 5.1031e-05\n",
      "Epoch 1097: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2194 - bpp: 1.5473 - mse: 5.1031e-05\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1767 - bpp: 1.5691 - mse: 4.9061e-05\n",
      "Epoch 1098: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1767 - bpp: 1.5691 - mse: 4.9061e-05\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0730 - bpp: 1.5257 - mse: 4.7218e-05\n",
      "Epoch 1099: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0730 - bpp: 1.5257 - mse: 4.7218e-05\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9543 - bpp: 1.5108 - mse: 4.4053e-05\n",
      "Epoch 1100: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9543 - bpp: 1.5108 - mse: 4.4053e-05\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0504 - bpp: 1.5264 - mse: 4.6506e-05\n",
      "Epoch 1101: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0504 - bpp: 1.5264 - mse: 4.6506e-05\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1362 - bpp: 1.5648 - mse: 4.7956e-05\n",
      "Epoch 1102: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.1362 - bpp: 1.5648 - mse: 4.7956e-05\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2814 - bpp: 1.5545 - mse: 5.2700e-05\n",
      "Epoch 1103: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.2814 - bpp: 1.5545 - mse: 5.2700e-05\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8193 - bpp: 1.4607 - mse: 4.1462e-05\n",
      "Epoch 1104: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8193 - bpp: 1.4607 - mse: 4.1462e-05\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2576 - bpp: 1.5929 - mse: 5.0805e-05\n",
      "Epoch 1105: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.2576 - bpp: 1.5929 - mse: 5.0805e-05\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1133 - bpp: 1.5566 - mse: 4.7505e-05\n",
      "Epoch 1106: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.1133 - bpp: 1.5566 - mse: 4.7505e-05\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0558 - bpp: 1.5416 - mse: 4.6209e-05\n",
      "Epoch 1107: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0558 - bpp: 1.5416 - mse: 4.6209e-05\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0386 - bpp: 1.5131 - mse: 4.6556e-05\n",
      "Epoch 1108: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0386 - bpp: 1.5131 - mse: 4.6556e-05\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8834 - bpp: 1.4744 - mse: 4.2998e-05\n",
      "Epoch 1109: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.8834 - bpp: 1.4744 - mse: 4.2998e-05\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9346 - bpp: 1.4992 - mse: 4.3807e-05\n",
      "Epoch 1110: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9346 - bpp: 1.4992 - mse: 4.3807e-05\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4214 - bpp: 1.6055 - mse: 5.5416e-05\n",
      "Epoch 1111: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.4214 - bpp: 1.6055 - mse: 5.5416e-05\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1486 - bpp: 1.5555 - mse: 4.8617e-05\n",
      "Epoch 1112: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1486 - bpp: 1.5555 - mse: 4.8617e-05\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9808 - bpp: 1.5134 - mse: 4.4781e-05\n",
      "Epoch 1113: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9808 - bpp: 1.5134 - mse: 4.4781e-05\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0292 - bpp: 1.5295 - mse: 4.5767e-05\n",
      "Epoch 1114: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0292 - bpp: 1.5295 - mse: 4.5767e-05\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0112 - bpp: 1.5209 - mse: 4.5482e-05\n",
      "Epoch 1115: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0112 - bpp: 1.5209 - mse: 4.5482e-05\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9455 - bpp: 1.4954 - mse: 4.4253e-05\n",
      "Epoch 1116: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9455 - bpp: 1.4954 - mse: 4.4253e-05\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1335 - bpp: 1.5430 - mse: 4.8538e-05\n",
      "Epoch 1117: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1335 - bpp: 1.5430 - mse: 4.8538e-05\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1985 - bpp: 1.5628 - mse: 4.9919e-05\n",
      "Epoch 1118: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1985 - bpp: 1.5628 - mse: 4.9919e-05\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9397 - bpp: 1.5261 - mse: 4.3140e-05\n",
      "Epoch 1119: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9397 - bpp: 1.5261 - mse: 4.3140e-05\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3051 - bpp: 1.5793 - mse: 5.2667e-05\n",
      "Epoch 1120: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.3051 - bpp: 1.5793 - mse: 5.2667e-05\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0232 - bpp: 1.5262 - mse: 4.5687e-05\n",
      "Epoch 1121: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0232 - bpp: 1.5262 - mse: 4.5687e-05\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0564 - bpp: 1.5357 - mse: 4.6409e-05\n",
      "Epoch 1122: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0564 - bpp: 1.5357 - mse: 4.6409e-05\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0297 - bpp: 1.5054 - mse: 4.6520e-05\n",
      "Epoch 1123: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0297 - bpp: 1.5054 - mse: 4.6520e-05\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9279 - bpp: 1.5039 - mse: 4.3456e-05\n",
      "Epoch 1124: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9279 - bpp: 1.5039 - mse: 4.3456e-05\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0306 - bpp: 1.5261 - mse: 4.5913e-05\n",
      "Epoch 1125: loss did not improve from 2.81315\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0306 - bpp: 1.5261 - mse: 4.5913e-05\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7890 - bpp: 1.4693 - mse: 4.0275e-05\n",
      "Epoch 1126: loss improved from 2.81315 to 2.78900, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7890 - bpp: 1.4693 - mse: 4.0275e-05\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1456 - bpp: 1.5445 - mse: 4.8860e-05\n",
      "Epoch 1127: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1456 - bpp: 1.5445 - mse: 4.8860e-05\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2522 - bpp: 1.5988 - mse: 5.0458e-05\n",
      "Epoch 1128: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 3.2522 - bpp: 1.5988 - mse: 5.0458e-05\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0300 - bpp: 1.5192 - mse: 4.6105e-05\n",
      "Epoch 1129: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0300 - bpp: 1.5192 - mse: 4.6105e-05\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9127 - bpp: 1.4773 - mse: 4.3802e-05\n",
      "Epoch 1130: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9127 - bpp: 1.4773 - mse: 4.3802e-05\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9775 - bpp: 1.4979 - mse: 4.5155e-05\n",
      "Epoch 1131: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 2.9775 - bpp: 1.4979 - mse: 4.5155e-05\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8023 - bpp: 1.4518 - mse: 4.1213e-05\n",
      "Epoch 1132: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8023 - bpp: 1.4518 - mse: 4.1213e-05\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7971 - bpp: 1.4633 - mse: 4.0704e-05\n",
      "Epoch 1133: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7971 - bpp: 1.4633 - mse: 4.0704e-05\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8222 - bpp: 1.4847 - mse: 4.0818e-05\n",
      "Epoch 1134: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8222 - bpp: 1.4847 - mse: 4.0818e-05\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8121 - bpp: 1.4867 - mse: 4.0448e-05\n",
      "Epoch 1135: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8121 - bpp: 1.4867 - mse: 4.0448e-05\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3061 - bpp: 1.5849 - mse: 5.2526e-05\n",
      "Epoch 1136: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.3061 - bpp: 1.5849 - mse: 5.2526e-05\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1341 - bpp: 1.5501 - mse: 4.8337e-05\n",
      "Epoch 1137: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 3.1341 - bpp: 1.5501 - mse: 4.8337e-05\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1341 - bpp: 1.5182 - mse: 4.9314e-05\n",
      "Epoch 1138: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.1341 - bpp: 1.5182 - mse: 4.9314e-05\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1808 - bpp: 1.5235 - mse: 5.0577e-05\n",
      "Epoch 1139: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.1808 - bpp: 1.5235 - mse: 5.0577e-05\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9818 - bpp: 1.4977 - mse: 4.5289e-05\n",
      "Epoch 1140: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9818 - bpp: 1.4977 - mse: 4.5289e-05\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1002 - bpp: 1.5256 - mse: 4.8052e-05\n",
      "Epoch 1141: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1002 - bpp: 1.5256 - mse: 4.8052e-05\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2011 - bpp: 1.5658 - mse: 4.9905e-05\n",
      "Epoch 1142: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.2011 - bpp: 1.5658 - mse: 4.9905e-05\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0113 - bpp: 1.5186 - mse: 4.5554e-05\n",
      "Epoch 1143: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0113 - bpp: 1.5186 - mse: 4.5554e-05\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8881 - bpp: 1.4934 - mse: 4.2564e-05\n",
      "Epoch 1144: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8881 - bpp: 1.4934 - mse: 4.2564e-05\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0482 - bpp: 1.5408 - mse: 4.6004e-05\n",
      "Epoch 1145: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0482 - bpp: 1.5408 - mse: 4.6004e-05\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1164 - bpp: 1.5824 - mse: 4.6815e-05\n",
      "Epoch 1146: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1164 - bpp: 1.5824 - mse: 4.6815e-05\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0916 - bpp: 1.5616 - mse: 4.6693e-05\n",
      "Epoch 1147: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0916 - bpp: 1.5616 - mse: 4.6693e-05\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1662 - bpp: 1.5499 - mse: 4.9326e-05\n",
      "Epoch 1148: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1662 - bpp: 1.5499 - mse: 4.9326e-05\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8534 - bpp: 1.4693 - mse: 4.2240e-05\n",
      "Epoch 1149: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8534 - bpp: 1.4693 - mse: 4.2240e-05\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8879 - bpp: 1.4945 - mse: 4.2522e-05\n",
      "Epoch 1150: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8879 - bpp: 1.4945 - mse: 4.2522e-05\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9872 - bpp: 1.5146 - mse: 4.4941e-05\n",
      "Epoch 1151: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.9872 - bpp: 1.5146 - mse: 4.4941e-05\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2358 - bpp: 1.5607 - mse: 5.1120e-05\n",
      "Epoch 1152: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.2358 - bpp: 1.5607 - mse: 5.1120e-05\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2696 - bpp: 1.5773 - mse: 5.1643e-05\n",
      "Epoch 1153: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2696 - bpp: 1.5773 - mse: 5.1643e-05\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1381 - bpp: 1.5530 - mse: 4.8372e-05\n",
      "Epoch 1154: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1381 - bpp: 1.5530 - mse: 4.8372e-05\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9759 - bpp: 1.4924 - mse: 4.5274e-05\n",
      "Epoch 1155: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.9759 - bpp: 1.4924 - mse: 4.5274e-05\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9852 - bpp: 1.5322 - mse: 4.4342e-05\n",
      "Epoch 1156: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9852 - bpp: 1.5322 - mse: 4.4342e-05\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0235 - bpp: 1.5375 - mse: 4.5351e-05\n",
      "Epoch 1157: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0235 - bpp: 1.5375 - mse: 4.5351e-05\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1651 - bpp: 1.5650 - mse: 4.8831e-05\n",
      "Epoch 1158: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1651 - bpp: 1.5650 - mse: 4.8831e-05\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9033 - bpp: 1.4778 - mse: 4.3502e-05\n",
      "Epoch 1159: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9033 - bpp: 1.4778 - mse: 4.3502e-05\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2215 - bpp: 1.5464 - mse: 5.1121e-05\n",
      "Epoch 1160: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2215 - bpp: 1.5464 - mse: 5.1121e-05\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0381 - bpp: 1.5429 - mse: 4.5630e-05\n",
      "Epoch 1161: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0381 - bpp: 1.5429 - mse: 4.5630e-05\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1926 - bpp: 1.5573 - mse: 4.9906e-05\n",
      "Epoch 1162: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1926 - bpp: 1.5573 - mse: 4.9906e-05\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0729 - bpp: 1.5516 - mse: 4.6427e-05\n",
      "Epoch 1163: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0729 - bpp: 1.5516 - mse: 4.6427e-05\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0817 - bpp: 1.5051 - mse: 4.8115e-05\n",
      "Epoch 1164: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.0817 - bpp: 1.5051 - mse: 4.8115e-05\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0184 - bpp: 1.5351 - mse: 4.5268e-05\n",
      "Epoch 1165: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.0184 - bpp: 1.5351 - mse: 4.5268e-05\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1557 - bpp: 1.5586 - mse: 4.8741e-05\n",
      "Epoch 1166: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1557 - bpp: 1.5586 - mse: 4.8741e-05\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8189 - bpp: 1.4640 - mse: 4.1349e-05\n",
      "Epoch 1167: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8189 - bpp: 1.4640 - mse: 4.1349e-05\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9710 - bpp: 1.4995 - mse: 4.4906e-05\n",
      "Epoch 1168: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.9710 - bpp: 1.4995 - mse: 4.4906e-05\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0357 - bpp: 1.5245 - mse: 4.6118e-05\n",
      "Epoch 1169: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0357 - bpp: 1.5245 - mse: 4.6118e-05\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0832 - bpp: 1.5487 - mse: 4.6828e-05\n",
      "Epoch 1170: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0832 - bpp: 1.5487 - mse: 4.6828e-05\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0299 - bpp: 1.4991 - mse: 4.6716e-05\n",
      "Epoch 1171: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0299 - bpp: 1.4991 - mse: 4.6716e-05\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9741 - bpp: 1.4804 - mse: 4.5584e-05\n",
      "Epoch 1172: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9741 - bpp: 1.4804 - mse: 4.5584e-05\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8932 - bpp: 1.5198 - mse: 4.1912e-05\n",
      "Epoch 1173: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8932 - bpp: 1.5198 - mse: 4.1912e-05\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0513 - bpp: 1.5074 - mse: 4.7115e-05\n",
      "Epoch 1174: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0513 - bpp: 1.5074 - mse: 4.7115e-05\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1059 - bpp: 1.5424 - mse: 4.7713e-05\n",
      "Epoch 1175: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1059 - bpp: 1.5424 - mse: 4.7713e-05\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0754 - bpp: 1.5204 - mse: 4.7457e-05\n",
      "Epoch 1176: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0754 - bpp: 1.5204 - mse: 4.7457e-05\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8601 - bpp: 1.4797 - mse: 4.2126e-05\n",
      "Epoch 1177: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.8601 - bpp: 1.4797 - mse: 4.2126e-05\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9755 - bpp: 1.5077 - mse: 4.4793e-05\n",
      "Epoch 1178: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9755 - bpp: 1.5077 - mse: 4.4793e-05\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9159 - bpp: 1.4919 - mse: 4.3456e-05\n",
      "Epoch 1179: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9159 - bpp: 1.4919 - mse: 4.3456e-05\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0308 - bpp: 1.5425 - mse: 4.5420e-05\n",
      "Epoch 1180: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0308 - bpp: 1.5425 - mse: 4.5420e-05\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0303 - bpp: 1.5376 - mse: 4.5552e-05\n",
      "Epoch 1181: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0303 - bpp: 1.5376 - mse: 4.5552e-05\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0331 - bpp: 1.5240 - mse: 4.6055e-05\n",
      "Epoch 1182: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.0331 - bpp: 1.5240 - mse: 4.6055e-05\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0520 - bpp: 1.5338 - mse: 4.6332e-05\n",
      "Epoch 1183: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0520 - bpp: 1.5338 - mse: 4.6332e-05\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2554 - bpp: 1.5978 - mse: 5.0587e-05\n",
      "Epoch 1184: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2554 - bpp: 1.5978 - mse: 5.0587e-05\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1722 - bpp: 1.5618 - mse: 4.9145e-05\n",
      "Epoch 1185: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1722 - bpp: 1.5618 - mse: 4.9145e-05\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2823 - bpp: 1.5885 - mse: 5.1693e-05\n",
      "Epoch 1186: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2823 - bpp: 1.5885 - mse: 5.1693e-05\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0400 - bpp: 1.5091 - mse: 4.6720e-05\n",
      "Epoch 1187: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0400 - bpp: 1.5091 - mse: 4.6720e-05\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1456 - bpp: 1.5400 - mse: 4.8999e-05\n",
      "Epoch 1188: loss did not improve from 2.78900\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1456 - bpp: 1.5400 - mse: 4.8999e-05\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6332 - bpp: 1.4156 - mse: 3.7156e-05\n",
      "Epoch 1189: loss improved from 2.78900 to 2.63318, saving model to checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.6332 - bpp: 1.4156 - mse: 3.7156e-05\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7715 - bpp: 1.4666 - mse: 3.9821e-05\n",
      "Epoch 1190: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.7715 - bpp: 1.4666 - mse: 3.9821e-05\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1719 - bpp: 1.5474 - mse: 4.9575e-05\n",
      "Epoch 1191: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1719 - bpp: 1.5474 - mse: 4.9575e-05\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0500 - bpp: 1.5377 - mse: 4.6150e-05\n",
      "Epoch 1192: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.0500 - bpp: 1.5377 - mse: 4.6150e-05\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8965 - bpp: 1.4981 - mse: 4.2676e-05\n",
      "Epoch 1193: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8965 - bpp: 1.4981 - mse: 4.2676e-05\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0454 - bpp: 1.5041 - mse: 4.7038e-05\n",
      "Epoch 1194: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0454 - bpp: 1.5041 - mse: 4.7038e-05\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9779 - bpp: 1.5071 - mse: 4.4885e-05\n",
      "Epoch 1195: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9779 - bpp: 1.5071 - mse: 4.4885e-05\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0250 - bpp: 1.5190 - mse: 4.5960e-05\n",
      "Epoch 1196: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0250 - bpp: 1.5190 - mse: 4.5960e-05\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0369 - bpp: 1.5303 - mse: 4.5976e-05\n",
      "Epoch 1197: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.0369 - bpp: 1.5303 - mse: 4.5976e-05\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9237 - bpp: 1.4985 - mse: 4.3493e-05\n",
      "Epoch 1198: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9237 - bpp: 1.4985 - mse: 4.3493e-05\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9700 - bpp: 1.4839 - mse: 4.5351e-05\n",
      "Epoch 1199: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.9700 - bpp: 1.4839 - mse: 4.5351e-05\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2142 - bpp: 1.5784 - mse: 4.9921e-05\n",
      "Epoch 1200: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2142 - bpp: 1.5784 - mse: 4.9921e-05\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9335 - bpp: 1.5205 - mse: 4.3120e-05\n",
      "Epoch 1201: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9335 - bpp: 1.5205 - mse: 4.3120e-05\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8467 - bpp: 1.4782 - mse: 4.1762e-05\n",
      "Epoch 1202: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.8467 - bpp: 1.4782 - mse: 4.1762e-05\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9062 - bpp: 1.4882 - mse: 4.3275e-05\n",
      "Epoch 1203: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9062 - bpp: 1.4882 - mse: 4.3275e-05\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0007 - bpp: 1.5124 - mse: 4.5419e-05\n",
      "Epoch 1204: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0007 - bpp: 1.5124 - mse: 4.5419e-05\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0318 - bpp: 1.5108 - mse: 4.6418e-05\n",
      "Epoch 1205: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0318 - bpp: 1.5108 - mse: 4.6418e-05\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8752 - bpp: 1.4637 - mse: 4.3075e-05\n",
      "Epoch 1206: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.8752 - bpp: 1.4637 - mse: 4.3075e-05\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1465 - bpp: 1.5441 - mse: 4.8902e-05\n",
      "Epoch 1207: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1465 - bpp: 1.5441 - mse: 4.8902e-05\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1165 - bpp: 1.5453 - mse: 4.7949e-05\n",
      "Epoch 1208: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1165 - bpp: 1.5453 - mse: 4.7949e-05\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1130 - bpp: 1.5262 - mse: 4.8426e-05\n",
      "Epoch 1209: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1130 - bpp: 1.5262 - mse: 4.8426e-05\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1826 - bpp: 1.5355 - mse: 5.0266e-05\n",
      "Epoch 1210: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1826 - bpp: 1.5355 - mse: 5.0266e-05\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0650 - bpp: 1.5325 - mse: 4.6769e-05\n",
      "Epoch 1211: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0650 - bpp: 1.5325 - mse: 4.6769e-05\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0142 - bpp: 1.4965 - mse: 4.6318e-05\n",
      "Epoch 1212: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 3.0142 - bpp: 1.4965 - mse: 4.6318e-05\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0785 - bpp: 1.5250 - mse: 4.7407e-05\n",
      "Epoch 1213: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0785 - bpp: 1.5250 - mse: 4.7407e-05\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0832 - bpp: 1.5366 - mse: 4.7201e-05\n",
      "Epoch 1214: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0832 - bpp: 1.5366 - mse: 4.7201e-05\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0214 - bpp: 1.5098 - mse: 4.6128e-05\n",
      "Epoch 1215: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0214 - bpp: 1.5098 - mse: 4.6128e-05\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9622 - bpp: 1.4998 - mse: 4.4628e-05\n",
      "Epoch 1216: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9622 - bpp: 1.4998 - mse: 4.4628e-05\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1446 - bpp: 1.5085 - mse: 4.9929e-05\n",
      "Epoch 1217: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1446 - bpp: 1.5085 - mse: 4.9929e-05\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0929 - bpp: 1.5362 - mse: 4.7508e-05\n",
      "Epoch 1218: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.0929 - bpp: 1.5362 - mse: 4.7508e-05\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9800 - bpp: 1.5145 - mse: 4.4724e-05\n",
      "Epoch 1219: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9800 - bpp: 1.5145 - mse: 4.4724e-05\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0833 - bpp: 1.5060 - mse: 4.8137e-05\n",
      "Epoch 1220: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.0833 - bpp: 1.5060 - mse: 4.8137e-05\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8270 - bpp: 1.4818 - mse: 4.1052e-05\n",
      "Epoch 1221: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.8270 - bpp: 1.4818 - mse: 4.1052e-05\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0293 - bpp: 1.5159 - mse: 4.6186e-05\n",
      "Epoch 1222: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.0293 - bpp: 1.5159 - mse: 4.6186e-05\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9917 - bpp: 1.5283 - mse: 4.4660e-05\n",
      "Epoch 1223: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9917 - bpp: 1.5283 - mse: 4.4660e-05\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0294 - bpp: 1.5501 - mse: 4.5144e-05\n",
      "Epoch 1224: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0294 - bpp: 1.5501 - mse: 4.5144e-05\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9933 - bpp: 1.4878 - mse: 4.5946e-05\n",
      "Epoch 1225: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9933 - bpp: 1.4878 - mse: 4.5946e-05\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9625 - bpp: 1.5022 - mse: 4.4566e-05\n",
      "Epoch 1226: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.9625 - bpp: 1.5022 - mse: 4.4566e-05\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9597 - bpp: 1.5255 - mse: 4.3767e-05\n",
      "Epoch 1227: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9597 - bpp: 1.5255 - mse: 4.3767e-05\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1300 - bpp: 1.5384 - mse: 4.8571e-05\n",
      "Epoch 1228: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1300 - bpp: 1.5384 - mse: 4.8571e-05\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0815 - bpp: 1.5427 - mse: 4.6960e-05\n",
      "Epoch 1229: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.0815 - bpp: 1.5427 - mse: 4.6960e-05\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0921 - bpp: 1.5461 - mse: 4.7179e-05\n",
      "Epoch 1230: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.0921 - bpp: 1.5461 - mse: 4.7179e-05\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0949 - bpp: 1.5309 - mse: 4.7728e-05\n",
      "Epoch 1231: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0949 - bpp: 1.5309 - mse: 4.7728e-05\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7406 - bpp: 1.4722 - mse: 3.8709e-05\n",
      "Epoch 1232: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7406 - bpp: 1.4722 - mse: 3.8709e-05\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9640 - bpp: 1.4971 - mse: 4.4767e-05\n",
      "Epoch 1233: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9640 - bpp: 1.4971 - mse: 4.4767e-05\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9968 - bpp: 1.5056 - mse: 4.5508e-05\n",
      "Epoch 1234: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9968 - bpp: 1.5056 - mse: 4.5508e-05\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7072 - bpp: 1.4617 - mse: 3.8010e-05\n",
      "Epoch 1235: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.7072 - bpp: 1.4617 - mse: 3.8010e-05\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8995 - bpp: 1.5104 - mse: 4.2393e-05\n",
      "Epoch 1236: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.8995 - bpp: 1.5104 - mse: 4.2393e-05\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8087 - bpp: 1.4708 - mse: 4.0828e-05\n",
      "Epoch 1237: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8087 - bpp: 1.4708 - mse: 4.0828e-05\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0928 - bpp: 1.5186 - mse: 4.8041e-05\n",
      "Epoch 1238: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0928 - bpp: 1.5186 - mse: 4.8041e-05\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1288 - bpp: 1.5467 - mse: 4.8282e-05\n",
      "Epoch 1239: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1288 - bpp: 1.5467 - mse: 4.8282e-05\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0681 - bpp: 1.5345 - mse: 4.6802e-05\n",
      "Epoch 1240: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0681 - bpp: 1.5345 - mse: 4.6802e-05\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1054 - bpp: 1.5077 - mse: 4.8758e-05\n",
      "Epoch 1241: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1054 - bpp: 1.5077 - mse: 4.8758e-05\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0964 - bpp: 1.5454 - mse: 4.7333e-05\n",
      "Epoch 1242: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0964 - bpp: 1.5454 - mse: 4.7333e-05\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8228 - bpp: 1.4895 - mse: 4.0688e-05\n",
      "Epoch 1243: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8228 - bpp: 1.4895 - mse: 4.0688e-05\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8469 - bpp: 1.4909 - mse: 4.1381e-05\n",
      "Epoch 1244: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8469 - bpp: 1.4909 - mse: 4.1381e-05\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8973 - bpp: 1.4790 - mse: 4.3284e-05\n",
      "Epoch 1245: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.8973 - bpp: 1.4790 - mse: 4.3284e-05\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9304 - bpp: 1.5171 - mse: 4.3129e-05\n",
      "Epoch 1246: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9304 - bpp: 1.5171 - mse: 4.3129e-05\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2520 - bpp: 1.5704 - mse: 5.1319e-05\n",
      "Epoch 1247: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.2520 - bpp: 1.5704 - mse: 5.1319e-05\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0141 - bpp: 1.5384 - mse: 4.5034e-05\n",
      "Epoch 1248: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.0141 - bpp: 1.5384 - mse: 4.5034e-05\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9034 - bpp: 1.5083 - mse: 4.2573e-05\n",
      "Epoch 1249: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9034 - bpp: 1.5083 - mse: 4.2573e-05\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0358 - bpp: 1.5439 - mse: 4.5529e-05\n",
      "Epoch 1250: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.0358 - bpp: 1.5439 - mse: 4.5529e-05\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9914 - bpp: 1.5261 - mse: 4.4717e-05\n",
      "Epoch 1251: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.9914 - bpp: 1.5261 - mse: 4.4717e-05\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0573 - bpp: 1.5403 - mse: 4.6298e-05\n",
      "Epoch 1252: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.0573 - bpp: 1.5403 - mse: 4.6298e-05\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7771 - bpp: 1.4733 - mse: 3.9789e-05\n",
      "Epoch 1253: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7771 - bpp: 1.4733 - mse: 3.9789e-05\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1517 - bpp: 1.5493 - mse: 4.8903e-05\n",
      "Epoch 1254: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1517 - bpp: 1.5493 - mse: 4.8903e-05\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9032 - bpp: 1.5148 - mse: 4.2371e-05\n",
      "Epoch 1255: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.9032 - bpp: 1.5148 - mse: 4.2371e-05\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0628 - bpp: 1.5128 - mse: 4.7300e-05\n",
      "Epoch 1256: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0628 - bpp: 1.5128 - mse: 4.7300e-05\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8295 - bpp: 1.4875 - mse: 4.0954e-05\n",
      "Epoch 1257: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.8295 - bpp: 1.4875 - mse: 4.0954e-05\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8582 - bpp: 1.4643 - mse: 4.2538e-05\n",
      "Epoch 1258: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.8582 - bpp: 1.4643 - mse: 4.2538e-05\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1123 - bpp: 1.5681 - mse: 4.7125e-05\n",
      "Epoch 1259: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1123 - bpp: 1.5681 - mse: 4.7125e-05\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2675 - bpp: 1.5391 - mse: 5.2747e-05\n",
      "Epoch 1260: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2675 - bpp: 1.5391 - mse: 5.2747e-05\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0659 - bpp: 1.5381 - mse: 4.6624e-05\n",
      "Epoch 1261: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.0659 - bpp: 1.5381 - mse: 4.6624e-05\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1524 - bpp: 1.5704 - mse: 4.8276e-05\n",
      "Epoch 1262: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1524 - bpp: 1.5704 - mse: 4.8276e-05\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0850 - bpp: 1.5497 - mse: 4.6854e-05\n",
      "Epoch 1263: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.0850 - bpp: 1.5497 - mse: 4.6854e-05\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9433 - bpp: 1.5055 - mse: 4.3880e-05\n",
      "Epoch 1264: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9433 - bpp: 1.5055 - mse: 4.3880e-05\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0620 - bpp: 1.5406 - mse: 4.6430e-05\n",
      "Epoch 1265: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.0620 - bpp: 1.5406 - mse: 4.6430e-05\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8601 - bpp: 1.5105 - mse: 4.1187e-05\n",
      "Epoch 1266: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8601 - bpp: 1.5105 - mse: 4.1187e-05\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9969 - bpp: 1.5022 - mse: 4.5617e-05\n",
      "Epoch 1267: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9969 - bpp: 1.5022 - mse: 4.5617e-05\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8736 - bpp: 1.4781 - mse: 4.2586e-05\n",
      "Epoch 1268: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.8736 - bpp: 1.4781 - mse: 4.2586e-05\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9889 - bpp: 1.4969 - mse: 4.5531e-05\n",
      "Epoch 1269: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9889 - bpp: 1.4969 - mse: 4.5531e-05\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2235 - bpp: 1.5571 - mse: 5.0854e-05\n",
      "Epoch 1270: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2235 - bpp: 1.5571 - mse: 5.0854e-05\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8968 - bpp: 1.4733 - mse: 4.3442e-05\n",
      "Epoch 1271: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.8968 - bpp: 1.4733 - mse: 4.3442e-05\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1888 - bpp: 1.5497 - mse: 5.0021e-05\n",
      "Epoch 1272: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.1888 - bpp: 1.5497 - mse: 5.0021e-05\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9690 - bpp: 1.5221 - mse: 4.4156e-05\n",
      "Epoch 1273: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9690 - bpp: 1.5221 - mse: 4.4156e-05\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2136 - bpp: 1.5823 - mse: 4.9784e-05\n",
      "Epoch 1274: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2136 - bpp: 1.5823 - mse: 4.9784e-05\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8988 - bpp: 1.5127 - mse: 4.2300e-05\n",
      "Epoch 1275: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8988 - bpp: 1.5127 - mse: 4.2300e-05\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7695 - bpp: 1.4658 - mse: 3.9787e-05\n",
      "Epoch 1276: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.7695 - bpp: 1.4658 - mse: 3.9787e-05\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1909 - bpp: 1.5485 - mse: 5.0121e-05\n",
      "Epoch 1277: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1909 - bpp: 1.5485 - mse: 5.0121e-05\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7912 - bpp: 1.4757 - mse: 4.0144e-05\n",
      "Epoch 1278: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.7912 - bpp: 1.4757 - mse: 4.0144e-05\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0800 - bpp: 1.5397 - mse: 4.7005e-05\n",
      "Epoch 1279: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0800 - bpp: 1.5397 - mse: 4.7005e-05\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0091 - bpp: 1.5075 - mse: 4.5827e-05\n",
      "Epoch 1280: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0091 - bpp: 1.5075 - mse: 4.5827e-05\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2289 - bpp: 1.5661 - mse: 5.0744e-05\n",
      "Epoch 1281: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2289 - bpp: 1.5661 - mse: 5.0744e-05\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7823 - bpp: 1.4627 - mse: 4.0269e-05\n",
      "Epoch 1282: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.7823 - bpp: 1.4627 - mse: 4.0269e-05\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0740 - bpp: 1.5433 - mse: 4.6712e-05\n",
      "Epoch 1283: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0740 - bpp: 1.5433 - mse: 4.6712e-05\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1695 - bpp: 1.5483 - mse: 4.9477e-05\n",
      "Epoch 1284: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3.1695 - bpp: 1.5483 - mse: 4.9477e-05\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9516 - bpp: 1.4924 - mse: 4.4531e-05\n",
      "Epoch 1285: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.9516 - bpp: 1.4924 - mse: 4.4531e-05\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0322 - bpp: 1.5335 - mse: 4.5737e-05\n",
      "Epoch 1286: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0322 - bpp: 1.5335 - mse: 4.5737e-05\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0139 - bpp: 1.5065 - mse: 4.6002e-05\n",
      "Epoch 1287: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.0139 - bpp: 1.5065 - mse: 4.6002e-05\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7767 - bpp: 1.4765 - mse: 3.9681e-05\n",
      "Epoch 1288: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.7767 - bpp: 1.4765 - mse: 3.9681e-05\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0799 - bpp: 1.5368 - mse: 4.7092e-05\n",
      "Epoch 1289: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0799 - bpp: 1.5368 - mse: 4.7092e-05\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9324 - bpp: 1.5000 - mse: 4.3714e-05\n",
      "Epoch 1290: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9324 - bpp: 1.5000 - mse: 4.3714e-05\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7267 - bpp: 1.4501 - mse: 3.8958e-05\n",
      "Epoch 1291: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.7267 - bpp: 1.4501 - mse: 3.8958e-05\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7066 - bpp: 1.4269 - mse: 3.9056e-05\n",
      "Epoch 1292: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.7066 - bpp: 1.4269 - mse: 3.9056e-05\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0767 - bpp: 1.5458 - mse: 4.6720e-05\n",
      "Epoch 1293: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.0767 - bpp: 1.5458 - mse: 4.6720e-05\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9803 - bpp: 1.5221 - mse: 4.4500e-05\n",
      "Epoch 1294: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9803 - bpp: 1.5221 - mse: 4.4500e-05\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1094 - bpp: 1.5567 - mse: 4.7385e-05\n",
      "Epoch 1295: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1094 - bpp: 1.5567 - mse: 4.7385e-05\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0693 - bpp: 1.5281 - mse: 4.7034e-05\n",
      "Epoch 1296: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.0693 - bpp: 1.5281 - mse: 4.7034e-05\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0343 - bpp: 1.5226 - mse: 4.6133e-05\n",
      "Epoch 1297: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.0343 - bpp: 1.5226 - mse: 4.6133e-05\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9646 - bpp: 1.5104 - mse: 4.4379e-05\n",
      "Epoch 1298: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9646 - bpp: 1.5104 - mse: 4.4379e-05\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9282 - bpp: 1.5029 - mse: 4.3497e-05\n",
      "Epoch 1299: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9282 - bpp: 1.5029 - mse: 4.3497e-05\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9854 - bpp: 1.5102 - mse: 4.5020e-05\n",
      "Epoch 1300: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9854 - bpp: 1.5102 - mse: 4.5020e-05\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0738 - bpp: 1.5284 - mse: 4.7160e-05\n",
      "Epoch 1301: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0738 - bpp: 1.5284 - mse: 4.7160e-05\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1764 - bpp: 1.5468 - mse: 4.9729e-05\n",
      "Epoch 1302: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1764 - bpp: 1.5468 - mse: 4.9729e-05\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8193 - bpp: 1.4404 - mse: 4.2081e-05\n",
      "Epoch 1303: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.8193 - bpp: 1.4404 - mse: 4.2081e-05\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9360 - bpp: 1.5141 - mse: 4.3394e-05\n",
      "Epoch 1304: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9360 - bpp: 1.5141 - mse: 4.3394e-05\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9748 - bpp: 1.5035 - mse: 4.4901e-05\n",
      "Epoch 1305: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9748 - bpp: 1.5035 - mse: 4.4901e-05\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2086 - bpp: 1.5228 - mse: 5.1446e-05\n",
      "Epoch 1306: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2086 - bpp: 1.5228 - mse: 5.1446e-05\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9254 - bpp: 1.4968 - mse: 4.3598e-05\n",
      "Epoch 1307: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9254 - bpp: 1.4968 - mse: 4.3598e-05\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9211 - bpp: 1.5319 - mse: 4.2397e-05\n",
      "Epoch 1308: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9211 - bpp: 1.5319 - mse: 4.2397e-05\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7755 - bpp: 1.4519 - mse: 4.0391e-05\n",
      "Epoch 1309: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.7755 - bpp: 1.4519 - mse: 4.0391e-05\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0118 - bpp: 1.5156 - mse: 4.5663e-05\n",
      "Epoch 1310: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.0118 - bpp: 1.5156 - mse: 4.5663e-05\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7325 - bpp: 1.4680 - mse: 3.8589e-05\n",
      "Epoch 1311: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7325 - bpp: 1.4680 - mse: 3.8589e-05\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9183 - bpp: 1.5059 - mse: 4.3101e-05\n",
      "Epoch 1312: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9183 - bpp: 1.5059 - mse: 4.3101e-05\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0623 - bpp: 1.5403 - mse: 4.6449e-05\n",
      "Epoch 1313: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.0623 - bpp: 1.5403 - mse: 4.6449e-05\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9029 - bpp: 1.5036 - mse: 4.2705e-05\n",
      "Epoch 1314: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.9029 - bpp: 1.5036 - mse: 4.2705e-05\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8666 - bpp: 1.4952 - mse: 4.1852e-05\n",
      "Epoch 1315: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8666 - bpp: 1.4952 - mse: 4.1852e-05\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2458 - bpp: 1.5988 - mse: 5.0264e-05\n",
      "Epoch 1316: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2458 - bpp: 1.5988 - mse: 5.0264e-05\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9646 - bpp: 1.5135 - mse: 4.4283e-05\n",
      "Epoch 1317: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9646 - bpp: 1.5135 - mse: 4.4283e-05\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8430 - bpp: 1.4863 - mse: 4.1404e-05\n",
      "Epoch 1318: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8430 - bpp: 1.4863 - mse: 4.1404e-05\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9647 - bpp: 1.4924 - mse: 4.4931e-05\n",
      "Epoch 1319: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9647 - bpp: 1.4924 - mse: 4.4931e-05\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1013 - bpp: 1.5526 - mse: 4.7261e-05\n",
      "Epoch 1320: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1013 - bpp: 1.5526 - mse: 4.7261e-05\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9705 - bpp: 1.5129 - mse: 4.4484e-05\n",
      "Epoch 1321: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9705 - bpp: 1.5129 - mse: 4.4484e-05\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9669 - bpp: 1.5230 - mse: 4.4062e-05\n",
      "Epoch 1322: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 2.9669 - bpp: 1.5230 - mse: 4.4062e-05\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8973 - bpp: 1.4793 - mse: 4.3276e-05\n",
      "Epoch 1323: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8973 - bpp: 1.4793 - mse: 4.3276e-05\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8366 - bpp: 1.4857 - mse: 4.1228e-05\n",
      "Epoch 1324: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.8366 - bpp: 1.4857 - mse: 4.1228e-05\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1053 - bpp: 1.5624 - mse: 4.7087e-05\n",
      "Epoch 1325: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1053 - bpp: 1.5624 - mse: 4.7087e-05\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2562 - bpp: 1.5658 - mse: 5.1586e-05\n",
      "Epoch 1326: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2562 - bpp: 1.5658 - mse: 5.1586e-05\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8885 - bpp: 1.5189 - mse: 4.1798e-05\n",
      "Epoch 1327: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8885 - bpp: 1.5189 - mse: 4.1798e-05\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9973 - bpp: 1.4991 - mse: 4.5721e-05\n",
      "Epoch 1328: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9973 - bpp: 1.4991 - mse: 4.5721e-05\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7884 - bpp: 1.4642 - mse: 4.0412e-05\n",
      "Epoch 1329: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.7884 - bpp: 1.4642 - mse: 4.0412e-05\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9559 - bpp: 1.5099 - mse: 4.4128e-05\n",
      "Epoch 1330: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9559 - bpp: 1.5099 - mse: 4.4128e-05\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2195 - bpp: 1.5776 - mse: 5.0107e-05\n",
      "Epoch 1331: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 248ms/step - loss: 3.2195 - bpp: 1.5776 - mse: 5.0107e-05\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0557 - bpp: 1.5407 - mse: 4.6232e-05\n",
      "Epoch 1332: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0557 - bpp: 1.5407 - mse: 4.6232e-05\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0797 - bpp: 1.5111 - mse: 4.7869e-05\n",
      "Epoch 1333: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0797 - bpp: 1.5111 - mse: 4.7869e-05\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7944 - bpp: 1.4612 - mse: 4.0687e-05\n",
      "Epoch 1334: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7944 - bpp: 1.4612 - mse: 4.0687e-05\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0678 - bpp: 1.5487 - mse: 4.6358e-05\n",
      "Epoch 1335: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0678 - bpp: 1.5487 - mse: 4.6358e-05\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0775 - bpp: 1.5251 - mse: 4.7378e-05\n",
      "Epoch 1336: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0775 - bpp: 1.5251 - mse: 4.7378e-05\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9576 - bpp: 1.4857 - mse: 4.4917e-05\n",
      "Epoch 1337: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.9576 - bpp: 1.4857 - mse: 4.4917e-05\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1040 - bpp: 1.5329 - mse: 4.7946e-05\n",
      "Epoch 1338: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1040 - bpp: 1.5329 - mse: 4.7946e-05\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2342 - bpp: 1.5595 - mse: 5.1110e-05\n",
      "Epoch 1339: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2342 - bpp: 1.5595 - mse: 5.1110e-05\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0964 - bpp: 1.5205 - mse: 4.8094e-05\n",
      "Epoch 1340: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0964 - bpp: 1.5205 - mse: 4.8094e-05\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7629 - bpp: 1.4552 - mse: 3.9907e-05\n",
      "Epoch 1341: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 2.7629 - bpp: 1.4552 - mse: 3.9907e-05\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1849 - bpp: 1.5756 - mse: 4.9112e-05\n",
      "Epoch 1342: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1849 - bpp: 1.5756 - mse: 4.9112e-05\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9093 - bpp: 1.5002 - mse: 4.3004e-05\n",
      "Epoch 1343: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9093 - bpp: 1.5002 - mse: 4.3004e-05\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9630 - bpp: 1.5158 - mse: 4.4166e-05\n",
      "Epoch 1344: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9630 - bpp: 1.5158 - mse: 4.4166e-05\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1282 - bpp: 1.5359 - mse: 4.8591e-05\n",
      "Epoch 1345: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1282 - bpp: 1.5359 - mse: 4.8591e-05\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0395 - bpp: 1.5261 - mse: 4.6184e-05\n",
      "Epoch 1346: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.0395 - bpp: 1.5261 - mse: 4.6184e-05\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1045 - bpp: 1.5414 - mse: 4.7701e-05\n",
      "Epoch 1347: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.1045 - bpp: 1.5414 - mse: 4.7701e-05\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7945 - bpp: 1.4527 - mse: 4.0948e-05\n",
      "Epoch 1348: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.7945 - bpp: 1.4527 - mse: 4.0948e-05\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0720 - bpp: 1.5456 - mse: 4.6582e-05\n",
      "Epoch 1349: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0720 - bpp: 1.5456 - mse: 4.6582e-05\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9004 - bpp: 1.4642 - mse: 4.3832e-05\n",
      "Epoch 1350: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9004 - bpp: 1.4642 - mse: 4.3832e-05\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9510 - bpp: 1.5014 - mse: 4.4241e-05\n",
      "Epoch 1351: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9510 - bpp: 1.5014 - mse: 4.4241e-05\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8680 - bpp: 1.5117 - mse: 4.1394e-05\n",
      "Epoch 1352: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8680 - bpp: 1.5117 - mse: 4.1394e-05\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8229 - bpp: 1.4597 - mse: 4.1600e-05\n",
      "Epoch 1353: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8229 - bpp: 1.4597 - mse: 4.1600e-05\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9673 - bpp: 1.4966 - mse: 4.4884e-05\n",
      "Epoch 1354: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9673 - bpp: 1.4966 - mse: 4.4884e-05\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9255 - bpp: 1.4938 - mse: 4.3694e-05\n",
      "Epoch 1355: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9255 - bpp: 1.4938 - mse: 4.3694e-05\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7807 - bpp: 1.4628 - mse: 4.0220e-05\n",
      "Epoch 1356: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.7807 - bpp: 1.4628 - mse: 4.0220e-05\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0365 - bpp: 1.5187 - mse: 4.6318e-05\n",
      "Epoch 1357: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0365 - bpp: 1.5187 - mse: 4.6318e-05\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0732 - bpp: 1.5214 - mse: 4.7358e-05\n",
      "Epoch 1358: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.0732 - bpp: 1.5214 - mse: 4.7358e-05\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9839 - bpp: 1.4895 - mse: 4.5605e-05\n",
      "Epoch 1359: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9839 - bpp: 1.4895 - mse: 4.5605e-05\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1752 - bpp: 1.5460 - mse: 4.9720e-05\n",
      "Epoch 1360: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1752 - bpp: 1.5460 - mse: 4.9720e-05\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7582 - bpp: 1.4753 - mse: 3.9152e-05\n",
      "Epoch 1361: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7582 - bpp: 1.4753 - mse: 3.9152e-05\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8102 - bpp: 1.4771 - mse: 4.0684e-05\n",
      "Epoch 1362: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8102 - bpp: 1.4771 - mse: 4.0684e-05\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0170 - bpp: 1.5189 - mse: 4.5718e-05\n",
      "Epoch 1363: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.0170 - bpp: 1.5189 - mse: 4.5718e-05\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0280 - bpp: 1.4995 - mse: 4.6645e-05\n",
      "Epoch 1364: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0280 - bpp: 1.4995 - mse: 4.6645e-05\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9125 - bpp: 1.5003 - mse: 4.3097e-05\n",
      "Epoch 1365: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9125 - bpp: 1.5003 - mse: 4.3097e-05\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7321 - bpp: 1.4619 - mse: 3.8763e-05\n",
      "Epoch 1366: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7321 - bpp: 1.4619 - mse: 3.8763e-05\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9263 - bpp: 1.5099 - mse: 4.3224e-05\n",
      "Epoch 1367: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.9263 - bpp: 1.5099 - mse: 4.3224e-05\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0811 - bpp: 1.5096 - mse: 4.7959e-05\n",
      "Epoch 1368: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0811 - bpp: 1.5096 - mse: 4.7959e-05\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9857 - bpp: 1.5056 - mse: 4.5168e-05\n",
      "Epoch 1369: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9857 - bpp: 1.5056 - mse: 4.5168e-05\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9061 - bpp: 1.5274 - mse: 4.2074e-05\n",
      "Epoch 1370: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9061 - bpp: 1.5274 - mse: 4.2074e-05\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7400 - bpp: 1.4408 - mse: 3.9651e-05\n",
      "Epoch 1371: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.7400 - bpp: 1.4408 - mse: 3.9651e-05\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0887 - bpp: 1.5507 - mse: 4.6937e-05\n",
      "Epoch 1372: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0887 - bpp: 1.5507 - mse: 4.6937e-05\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9019 - bpp: 1.4830 - mse: 4.3300e-05\n",
      "Epoch 1373: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 2.9019 - bpp: 1.4830 - mse: 4.3300e-05\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1267 - bpp: 1.5666 - mse: 4.7610e-05\n",
      "Epoch 1374: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1267 - bpp: 1.5666 - mse: 4.7610e-05\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8514 - bpp: 1.4805 - mse: 4.1837e-05\n",
      "Epoch 1375: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8514 - bpp: 1.4805 - mse: 4.1837e-05\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8496 - bpp: 1.4788 - mse: 4.1834e-05\n",
      "Epoch 1376: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8496 - bpp: 1.4788 - mse: 4.1834e-05\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9547 - bpp: 1.5095 - mse: 4.4103e-05\n",
      "Epoch 1377: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9547 - bpp: 1.5095 - mse: 4.4103e-05\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0895 - bpp: 1.5184 - mse: 4.7947e-05\n",
      "Epoch 1378: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0895 - bpp: 1.5184 - mse: 4.7947e-05\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8067 - bpp: 1.4735 - mse: 4.0685e-05\n",
      "Epoch 1379: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8067 - bpp: 1.4735 - mse: 4.0685e-05\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0404 - bpp: 1.5315 - mse: 4.6047e-05\n",
      "Epoch 1380: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.0404 - bpp: 1.5315 - mse: 4.6047e-05\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9390 - bpp: 1.4877 - mse: 4.4290e-05\n",
      "Epoch 1381: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9390 - bpp: 1.4877 - mse: 4.4290e-05\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9165 - bpp: 1.4989 - mse: 4.3262e-05\n",
      "Epoch 1382: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9165 - bpp: 1.4989 - mse: 4.3262e-05\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8980 - bpp: 1.4884 - mse: 4.3016e-05\n",
      "Epoch 1383: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8980 - bpp: 1.4884 - mse: 4.3016e-05\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0406 - bpp: 1.5122 - mse: 4.6642e-05\n",
      "Epoch 1384: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0406 - bpp: 1.5122 - mse: 4.6642e-05\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9314 - bpp: 1.5114 - mse: 4.3336e-05\n",
      "Epoch 1385: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9314 - bpp: 1.5114 - mse: 4.3336e-05\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0264 - bpp: 1.5217 - mse: 4.5919e-05\n",
      "Epoch 1386: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.0264 - bpp: 1.5217 - mse: 4.5919e-05\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9218 - bpp: 1.4912 - mse: 4.3660e-05\n",
      "Epoch 1387: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9218 - bpp: 1.4912 - mse: 4.3660e-05\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8662 - bpp: 1.5086 - mse: 4.1428e-05\n",
      "Epoch 1388: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8662 - bpp: 1.5086 - mse: 4.1428e-05\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7109 - bpp: 1.4428 - mse: 3.8699e-05\n",
      "Epoch 1389: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 2.7109 - bpp: 1.4428 - mse: 3.8699e-05\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9493 - bpp: 1.4734 - mse: 4.5039e-05\n",
      "Epoch 1390: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9493 - bpp: 1.4734 - mse: 4.5039e-05\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9781 - bpp: 1.4819 - mse: 4.5659e-05\n",
      "Epoch 1391: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9781 - bpp: 1.4819 - mse: 4.5659e-05\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8095 - bpp: 1.5004 - mse: 3.9953e-05\n",
      "Epoch 1392: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.8095 - bpp: 1.5004 - mse: 3.9953e-05\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9217 - bpp: 1.5351 - mse: 4.2314e-05\n",
      "Epoch 1393: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9217 - bpp: 1.5351 - mse: 4.2314e-05\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7670 - bpp: 1.4605 - mse: 3.9871e-05\n",
      "Epoch 1394: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.7670 - bpp: 1.4605 - mse: 3.9871e-05\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9490 - bpp: 1.5048 - mse: 4.4073e-05\n",
      "Epoch 1395: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 2.9490 - bpp: 1.5048 - mse: 4.4073e-05\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1147 - bpp: 1.5152 - mse: 4.8813e-05\n",
      "Epoch 1396: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1147 - bpp: 1.5152 - mse: 4.8813e-05\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6985 - bpp: 1.4410 - mse: 3.8377e-05\n",
      "Epoch 1397: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.6985 - bpp: 1.4410 - mse: 3.8377e-05\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6800 - bpp: 1.4397 - mse: 3.7850e-05\n",
      "Epoch 1398: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.6800 - bpp: 1.4397 - mse: 3.7850e-05\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8066 - bpp: 1.4753 - mse: 4.0627e-05\n",
      "Epoch 1399: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.8066 - bpp: 1.4753 - mse: 4.0627e-05\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8286 - bpp: 1.4623 - mse: 4.1696e-05\n",
      "Epoch 1400: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8286 - bpp: 1.4623 - mse: 4.1696e-05\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9186 - bpp: 1.5027 - mse: 4.3211e-05\n",
      "Epoch 1401: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9186 - bpp: 1.5027 - mse: 4.3211e-05\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0475 - bpp: 1.5310 - mse: 4.6280e-05\n",
      "Epoch 1402: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0475 - bpp: 1.5310 - mse: 4.6280e-05\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2881 - bpp: 1.5700 - mse: 5.2431e-05\n",
      "Epoch 1403: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2881 - bpp: 1.5700 - mse: 5.2431e-05\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2699 - bpp: 1.5568 - mse: 5.2279e-05\n",
      "Epoch 1404: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2699 - bpp: 1.5568 - mse: 5.2279e-05\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0298 - bpp: 1.5399 - mse: 4.5469e-05\n",
      "Epoch 1405: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0298 - bpp: 1.5399 - mse: 4.5469e-05\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9640 - bpp: 1.5143 - mse: 4.4241e-05\n",
      "Epoch 1406: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9640 - bpp: 1.5143 - mse: 4.4241e-05\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9982 - bpp: 1.5218 - mse: 4.5057e-05\n",
      "Epoch 1407: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.9982 - bpp: 1.5218 - mse: 4.5057e-05\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9929 - bpp: 1.4992 - mse: 4.5586e-05\n",
      "Epoch 1408: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 2.9929 - bpp: 1.4992 - mse: 4.5586e-05\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8827 - bpp: 1.4850 - mse: 4.2653e-05\n",
      "Epoch 1409: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8827 - bpp: 1.4850 - mse: 4.2653e-05\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9313 - bpp: 1.4897 - mse: 4.3994e-05\n",
      "Epoch 1410: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9313 - bpp: 1.4897 - mse: 4.3994e-05\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0390 - bpp: 1.5462 - mse: 4.5556e-05\n",
      "Epoch 1411: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 3.0390 - bpp: 1.5462 - mse: 4.5556e-05\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7431 - bpp: 1.4570 - mse: 3.9246e-05\n",
      "Epoch 1412: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.7431 - bpp: 1.4570 - mse: 3.9246e-05\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8832 - bpp: 1.4960 - mse: 4.2334e-05\n",
      "Epoch 1413: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8832 - bpp: 1.4960 - mse: 4.2334e-05\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3318 - bpp: 1.6025 - mse: 5.2776e-05\n",
      "Epoch 1414: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3318 - bpp: 1.6025 - mse: 5.2776e-05\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9328 - bpp: 1.4747 - mse: 4.4497e-05\n",
      "Epoch 1415: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9328 - bpp: 1.4747 - mse: 4.4497e-05\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7146 - bpp: 1.4428 - mse: 3.8811e-05\n",
      "Epoch 1416: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 2.7146 - bpp: 1.4428 - mse: 3.8811e-05\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1324 - bpp: 1.5493 - mse: 4.8315e-05\n",
      "Epoch 1417: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1324 - bpp: 1.5493 - mse: 4.8315e-05\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1259 - bpp: 1.5566 - mse: 4.7890e-05\n",
      "Epoch 1418: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1259 - bpp: 1.5566 - mse: 4.7890e-05\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9477 - bpp: 1.5183 - mse: 4.3623e-05\n",
      "Epoch 1419: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9477 - bpp: 1.5183 - mse: 4.3623e-05\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0710 - bpp: 1.5676 - mse: 4.5878e-05\n",
      "Epoch 1420: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0710 - bpp: 1.5676 - mse: 4.5878e-05\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1286 - bpp: 1.5092 - mse: 4.9421e-05\n",
      "Epoch 1421: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1286 - bpp: 1.5092 - mse: 4.9421e-05\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8560 - bpp: 1.4711 - mse: 4.2265e-05\n",
      "Epoch 1422: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.8560 - bpp: 1.4711 - mse: 4.2265e-05\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0850 - bpp: 1.5140 - mse: 4.7943e-05\n",
      "Epoch 1423: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.0850 - bpp: 1.5140 - mse: 4.7943e-05\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1326 - bpp: 1.5503 - mse: 4.8290e-05\n",
      "Epoch 1424: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 3.1326 - bpp: 1.5503 - mse: 4.8290e-05\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2496 - bpp: 1.5548 - mse: 5.1721e-05\n",
      "Epoch 1425: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.2496 - bpp: 1.5548 - mse: 5.1721e-05\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0225 - bpp: 1.5492 - mse: 4.4961e-05\n",
      "Epoch 1426: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.0225 - bpp: 1.5492 - mse: 4.4961e-05\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2279 - bpp: 1.5416 - mse: 5.1464e-05\n",
      "Epoch 1427: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2279 - bpp: 1.5416 - mse: 5.1464e-05\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8766 - bpp: 1.4887 - mse: 4.2356e-05\n",
      "Epoch 1428: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.8766 - bpp: 1.4887 - mse: 4.2356e-05\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1141 - bpp: 1.5379 - mse: 4.8103e-05\n",
      "Epoch 1429: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1141 - bpp: 1.5379 - mse: 4.8103e-05\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8933 - bpp: 1.4826 - mse: 4.3049e-05\n",
      "Epoch 1430: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8933 - bpp: 1.4826 - mse: 4.3049e-05\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0792 - bpp: 1.5200 - mse: 4.7583e-05\n",
      "Epoch 1431: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.0792 - bpp: 1.5200 - mse: 4.7583e-05\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9086 - bpp: 1.4984 - mse: 4.3035e-05\n",
      "Epoch 1432: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9086 - bpp: 1.4984 - mse: 4.3035e-05\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7221 - bpp: 1.4539 - mse: 3.8704e-05\n",
      "Epoch 1433: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.7221 - bpp: 1.4539 - mse: 3.8704e-05\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9445 - bpp: 1.4952 - mse: 4.4229e-05\n",
      "Epoch 1434: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9445 - bpp: 1.4952 - mse: 4.4229e-05\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9304 - bpp: 1.4950 - mse: 4.3805e-05\n",
      "Epoch 1435: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.9304 - bpp: 1.4950 - mse: 4.3805e-05\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8751 - bpp: 1.4969 - mse: 4.2060e-05\n",
      "Epoch 1436: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.8751 - bpp: 1.4969 - mse: 4.2060e-05\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1606 - bpp: 1.5556 - mse: 4.8980e-05\n",
      "Epoch 1437: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1606 - bpp: 1.5556 - mse: 4.8980e-05\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8973 - bpp: 1.4405 - mse: 4.4459e-05\n",
      "Epoch 1438: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.8973 - bpp: 1.4405 - mse: 4.4459e-05\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1960 - bpp: 1.5486 - mse: 5.0275e-05\n",
      "Epoch 1439: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 3.1960 - bpp: 1.5486 - mse: 5.0275e-05\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1910 - bpp: 1.5544 - mse: 4.9945e-05\n",
      "Epoch 1440: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1910 - bpp: 1.5544 - mse: 4.9945e-05\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0131 - bpp: 1.5268 - mse: 4.5358e-05\n",
      "Epoch 1441: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0131 - bpp: 1.5268 - mse: 4.5358e-05\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0927 - bpp: 1.5359 - mse: 4.7509e-05\n",
      "Epoch 1442: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.0927 - bpp: 1.5359 - mse: 4.7509e-05\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9715 - bpp: 1.4888 - mse: 4.5250e-05\n",
      "Epoch 1443: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9715 - bpp: 1.4888 - mse: 4.5250e-05\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0046 - bpp: 1.5025 - mse: 4.5841e-05\n",
      "Epoch 1444: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0046 - bpp: 1.5025 - mse: 4.5841e-05\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8921 - bpp: 1.5047 - mse: 4.2341e-05\n",
      "Epoch 1445: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8921 - bpp: 1.5047 - mse: 4.2341e-05\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8200 - bpp: 1.4870 - mse: 4.0681e-05\n",
      "Epoch 1446: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.8200 - bpp: 1.4870 - mse: 4.0681e-05\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8867 - bpp: 1.5017 - mse: 4.2266e-05\n",
      "Epoch 1447: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.8867 - bpp: 1.5017 - mse: 4.2266e-05\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9458 - bpp: 1.5127 - mse: 4.3735e-05\n",
      "Epoch 1448: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9458 - bpp: 1.5127 - mse: 4.3735e-05\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0613 - bpp: 1.5340 - mse: 4.6610e-05\n",
      "Epoch 1449: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0613 - bpp: 1.5340 - mse: 4.6610e-05\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0363 - bpp: 1.5346 - mse: 4.5829e-05\n",
      "Epoch 1450: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0363 - bpp: 1.5346 - mse: 4.5829e-05\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8504 - bpp: 1.4843 - mse: 4.1691e-05\n",
      "Epoch 1451: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.8504 - bpp: 1.4843 - mse: 4.1691e-05\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3204 - bpp: 1.6031 - mse: 5.2407e-05\n",
      "Epoch 1452: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3204 - bpp: 1.6031 - mse: 5.2407e-05\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9345 - bpp: 1.5082 - mse: 4.3526e-05\n",
      "Epoch 1453: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9345 - bpp: 1.5082 - mse: 4.3526e-05\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9231 - bpp: 1.5028 - mse: 4.3344e-05\n",
      "Epoch 1454: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.9231 - bpp: 1.5028 - mse: 4.3344e-05\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0536 - bpp: 1.5269 - mse: 4.6591e-05\n",
      "Epoch 1455: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0536 - bpp: 1.5269 - mse: 4.6591e-05\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2922 - bpp: 1.5786 - mse: 5.2293e-05\n",
      "Epoch 1456: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2922 - bpp: 1.5786 - mse: 5.2293e-05\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0685 - bpp: 1.5338 - mse: 4.6835e-05\n",
      "Epoch 1457: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0685 - bpp: 1.5338 - mse: 4.6835e-05\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8386 - bpp: 1.4582 - mse: 4.2126e-05\n",
      "Epoch 1458: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8386 - bpp: 1.4582 - mse: 4.2126e-05\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2474 - bpp: 1.5594 - mse: 5.1512e-05\n",
      "Epoch 1459: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2474 - bpp: 1.5594 - mse: 5.1512e-05\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1981 - bpp: 1.5500 - mse: 5.0298e-05\n",
      "Epoch 1460: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.1981 - bpp: 1.5500 - mse: 5.0298e-05\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8711 - bpp: 1.4790 - mse: 4.2482e-05\n",
      "Epoch 1461: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8711 - bpp: 1.4790 - mse: 4.2482e-05\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6908 - bpp: 1.4292 - mse: 3.8499e-05\n",
      "Epoch 1462: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.6908 - bpp: 1.4292 - mse: 3.8499e-05\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0797 - bpp: 1.5333 - mse: 4.7193e-05\n",
      "Epoch 1463: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0797 - bpp: 1.5333 - mse: 4.7193e-05\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0324 - bpp: 1.5198 - mse: 4.6161e-05\n",
      "Epoch 1464: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.0324 - bpp: 1.5198 - mse: 4.6161e-05\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1285 - bpp: 1.5626 - mse: 4.7787e-05\n",
      "Epoch 1465: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.1285 - bpp: 1.5626 - mse: 4.7787e-05\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1679 - bpp: 1.5831 - mse: 4.8364e-05\n",
      "Epoch 1466: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1679 - bpp: 1.5831 - mse: 4.8364e-05\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9122 - bpp: 1.5220 - mse: 4.2427e-05\n",
      "Epoch 1467: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.9122 - bpp: 1.5220 - mse: 4.2427e-05\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9534 - bpp: 1.4842 - mse: 4.4836e-05\n",
      "Epoch 1468: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 2.9534 - bpp: 1.4842 - mse: 4.4836e-05\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0123 - bpp: 1.5382 - mse: 4.4988e-05\n",
      "Epoch 1469: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0123 - bpp: 1.5382 - mse: 4.4988e-05\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9412 - bpp: 1.5128 - mse: 4.3593e-05\n",
      "Epoch 1470: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.9412 - bpp: 1.5128 - mse: 4.3593e-05\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9917 - bpp: 1.5205 - mse: 4.4900e-05\n",
      "Epoch 1471: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9917 - bpp: 1.5205 - mse: 4.4900e-05\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0635 - bpp: 1.5537 - mse: 4.6075e-05\n",
      "Epoch 1472: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0635 - bpp: 1.5537 - mse: 4.6075e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8411 - bpp: 1.4855 - mse: 4.1368e-05\n",
      "Epoch 1473: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.8411 - bpp: 1.4855 - mse: 4.1368e-05\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0543 - bpp: 1.5164 - mse: 4.6933e-05\n",
      "Epoch 1474: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0543 - bpp: 1.5164 - mse: 4.6933e-05\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9518 - bpp: 1.5025 - mse: 4.4229e-05\n",
      "Epoch 1475: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9518 - bpp: 1.5025 - mse: 4.4229e-05\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9922 - bpp: 1.5093 - mse: 4.5255e-05\n",
      "Epoch 1476: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9922 - bpp: 1.5093 - mse: 4.5255e-05\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9455 - bpp: 1.5079 - mse: 4.3871e-05\n",
      "Epoch 1477: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9455 - bpp: 1.5079 - mse: 4.3871e-05\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8777 - bpp: 1.4953 - mse: 4.2188e-05\n",
      "Epoch 1478: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.8777 - bpp: 1.4953 - mse: 4.2188e-05\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8343 - bpp: 1.4699 - mse: 4.1639e-05\n",
      "Epoch 1479: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.8343 - bpp: 1.4699 - mse: 4.1639e-05\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8795 - bpp: 1.4952 - mse: 4.2243e-05\n",
      "Epoch 1480: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8795 - bpp: 1.4952 - mse: 4.2243e-05\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8979 - bpp: 1.4721 - mse: 4.3512e-05\n",
      "Epoch 1481: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.8979 - bpp: 1.4721 - mse: 4.3512e-05\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2135 - bpp: 1.5579 - mse: 5.0525e-05\n",
      "Epoch 1482: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2135 - bpp: 1.5579 - mse: 5.0525e-05\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9131 - bpp: 1.4976 - mse: 4.3199e-05\n",
      "Epoch 1483: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9131 - bpp: 1.4976 - mse: 4.3199e-05\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0244 - bpp: 1.5531 - mse: 4.4902e-05\n",
      "Epoch 1484: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0244 - bpp: 1.5531 - mse: 4.4902e-05\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1573 - bpp: 1.5553 - mse: 4.8889e-05\n",
      "Epoch 1485: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.1573 - bpp: 1.5553 - mse: 4.8889e-05\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9802 - bpp: 1.5215 - mse: 4.4517e-05\n",
      "Epoch 1486: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.9802 - bpp: 1.5215 - mse: 4.4517e-05\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9571 - bpp: 1.5062 - mse: 4.4277e-05\n",
      "Epoch 1487: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.9571 - bpp: 1.5062 - mse: 4.4277e-05\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0753 - bpp: 1.5351 - mse: 4.7002e-05\n",
      "Epoch 1488: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.0753 - bpp: 1.5351 - mse: 4.7002e-05\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7788 - bpp: 1.4779 - mse: 3.9701e-05\n",
      "Epoch 1489: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7788 - bpp: 1.4779 - mse: 3.9701e-05\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9974 - bpp: 1.5201 - mse: 4.5083e-05\n",
      "Epoch 1490: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.9974 - bpp: 1.5201 - mse: 4.5083e-05\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9067 - bpp: 1.4906 - mse: 4.3214e-05\n",
      "Epoch 1491: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.9067 - bpp: 1.4906 - mse: 4.3214e-05\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1232 - bpp: 1.5429 - mse: 4.8226e-05\n",
      "Epoch 1492: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1232 - bpp: 1.5429 - mse: 4.8226e-05\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1093 - bpp: 1.5252 - mse: 4.8342e-05\n",
      "Epoch 1493: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.1093 - bpp: 1.5252 - mse: 4.8342e-05\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2020 - bpp: 1.5582 - mse: 5.0164e-05\n",
      "Epoch 1494: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2020 - bpp: 1.5582 - mse: 5.0164e-05\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0477 - bpp: 1.5519 - mse: 4.5649e-05\n",
      "Epoch 1495: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0477 - bpp: 1.5519 - mse: 4.5649e-05\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1317 - bpp: 1.5569 - mse: 4.8058e-05\n",
      "Epoch 1496: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.1317 - bpp: 1.5569 - mse: 4.8058e-05\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1197 - bpp: 1.5440 - mse: 4.8084e-05\n",
      "Epoch 1497: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1197 - bpp: 1.5440 - mse: 4.8084e-05\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0524 - bpp: 1.5263 - mse: 4.6572e-05\n",
      "Epoch 1498: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.0524 - bpp: 1.5263 - mse: 4.6572e-05\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8393 - bpp: 1.4825 - mse: 4.1408e-05\n",
      "Epoch 1499: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8393 - bpp: 1.4825 - mse: 4.1408e-05\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8436 - bpp: 1.4724 - mse: 4.1843e-05\n",
      "Epoch 1500: loss did not improve from 2.63318\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.8436 - bpp: 1.4724 - mse: 4.1843e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_32768_epcs_1500_I_QP_27_240x240_CosineDecay_20220508-043447/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_15 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_15.compile()\n",
    "trainer_15.fit()\n",
    "trainer_15.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load\n",
    "import OpenDVCW\n",
    "\n",
    "# img_path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "img_path = \"/mnt/WindowsDev/DataSets/Beauty_1920x1080_120fps_420_8bit_YUV_RAW/\"\n",
    "i_frame = img_path + 'im0' + '.png'\n",
    "p_frame = img_path + 'im1' + '.png'\n",
    "out_bin = \"Test_com/test{}.bin\".format(0)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(0)\n",
    "\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(0)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(0)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, Width, Height))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, Width, Height))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  2282 psnr:  37.022711351569335 bpp:  75.72304995617878\n",
      "compress\n",
      "decompress\n",
      "bin size:  1514 psnr:  38.266512930758694 bpp:  114.13474240422721\n",
      "compress\n",
      "decompress\n",
      "bin size:  2859 psnr:  39.35762683804636 bpp:  60.44071353620147\n",
      "compress\n",
      "decompress\n",
      "bin size:  7484 psnr:  39.09203802192782 bpp:  23.089257081774452\n"
     ]
    }
   ],
   "source": [
    "trainer_11.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_11.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_12.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_12.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_13.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_13.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_14.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_14.check_psnr(p_on_test, out_decom, out_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n",
      "bin size:  2062 psnr:  37.20515859837617 bpp:  0.01193287037037037\n"
     ]
    }
   ],
   "source": [
    "trainer_11.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_11.check_psnr(p_on_test, out_decom, out_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n",
      "bin size:  8912 psnr:  40.95658849699145 bpp:  0.05157407407407407\n"
     ]
    }
   ],
   "source": [
    "trainer_15.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_15.check_psnr(p_on_test, out_decom, out_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
