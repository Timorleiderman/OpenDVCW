{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "from train import TrainOpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import OpenDVCW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_folder = \"train_set_iqp22.npy\"\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 3\n",
    "# STEPS_PER_EPOCH = len(np.load(np_folder))\n",
    "STEPS_PER_EPOCH = 800\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "NUM_FILTERS = 256\n",
    "MV_KERNEL_SIZE=3\n",
    "RES_KERNEL_SIZE=5\n",
    "M=256\n",
    "lmbda = 2048\n",
    "lr_init = 1e-4\n",
    "lr_alpha = 1e-8\n",
    "early_stop = 3\n",
    "I_QP=22\n",
    "wavelet_name = \"haar\"\n",
    "\n",
    "checkponts_prev_path = \"\"\n",
    "checkpoints_target_path = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 20:06:02.703952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:02.716063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:02.716882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:02.718918: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-06 20:06:02.722584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:02.723457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:02.724274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:03.653652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:03.654446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:03.655207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 20:06:03.656023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# img_path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "img_path = \"/mnt/WindowsDev/DataSets/Beauty_1920x1080_120fps_420_8bit_YUV_RAW/\"\n",
    "i_frame = img_path + 'im0' + '.png'\n",
    "p_frame = img_path + 'im1' + '.png'\n",
    "out_bin = \"Test_com/test{}.bin\".format(0)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(0)\n",
    "\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(0)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(0)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, Width, Height))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, Width, Height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Loading weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 20:06:14.545564: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 20:06:45.690674: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - ETA: 0s - loss: 1.7782 - bpp: 0.9308 - mse: 1.0344e-04\n",
      "Epoch 1: loss improved from inf to 1.77815, saving model to checkpoints_wavelets_haar_Lmbd_8192_nfilt_256_epcs_3_stps_800_I_QP_22_240x240_CosineDecay_20220606-200604/\n",
      "800/800 [==============================] - 150s 145ms/step - loss: 1.7782 - bpp: 0.9308 - mse: 1.0344e-04\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7870 - bpp: 0.9434 - mse: 1.0298e-04\n",
      "Epoch 2: loss did not improve from 1.77815\n",
      "800/800 [==============================] - 116s 144ms/step - loss: 1.7870 - bpp: 0.9434 - mse: 1.0298e-04\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8354 - bpp: 0.9465 - mse: 1.0850e-04\n",
      "Epoch 3: loss did not improve from 1.77815\n",
      "800/800 [==============================] - 116s 144ms/step - loss: 1.8354 - bpp: 0.9465 - mse: 1.0850e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_nfilt_256_epcs_3_stps_800_I_QP_22_240x240_CosineDecay_20220606-200604/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_nfilt_256_epcs_3_stps_800_I_QP_22_240x240_CosineDecay_20220606-200604/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  3689 psnr:  39.00052465446409 bpp:  0.02134837962962963\n"
     ]
    }
   ],
   "source": [
    "I_QP=22\n",
    "lmbda = 8192\n",
    "np_folder = \"train_set_iqp22.npy\"\n",
    "checkponts_prev_path = \"checkpoints_wavelets_haar_Lmbd_8192_nfilt_256_epcs_12_stps_6000_I_QP_22_240x240_CosineDecay_20220603-201441/\"\n",
    "checkpoints_target_path = \"\"\n",
    "trainer_8192 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, checkpoints_target_path, np_folder)\n",
    "trainer_8192.compile()\n",
    "trainer_8192.fit()\n",
    "trainer_8192.save()\n",
    "trainer_8192.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Loading weights\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6806 - bpp: 0.8594 - mse: 2.0048e-04\n",
      "Epoch 1: loss improved from inf to 1.68056, saving model to checkpoints_wavelets_haar_Lmbd_4096_nfilt_256_epcs_3_stps_800_I_QP_27_240x240_CosineDecay_20220606-201421/\n",
      "800/800 [==============================] - 144s 148ms/step - loss: 1.6806 - bpp: 0.8594 - mse: 2.0048e-04\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6700 - bpp: 0.8562 - mse: 1.9868e-04\n",
      "Epoch 2: loss improved from 1.68056 to 1.66995, saving model to checkpoints_wavelets_haar_Lmbd_4096_nfilt_256_epcs_3_stps_800_I_QP_27_240x240_CosineDecay_20220606-201421/\n",
      "800/800 [==============================] - 119s 148ms/step - loss: 1.6700 - bpp: 0.8562 - mse: 1.9868e-04\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7535 - bpp: 0.8683 - mse: 2.1613e-04\n",
      "Epoch 3: loss did not improve from 1.66995\n",
      "800/800 [==============================] - 117s 146ms/step - loss: 1.7535 - bpp: 0.8683 - mse: 2.1613e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Found untraced functions such as optical_flow_loss_1_layer_call_fn, optical_flow_loss_1_layer_call_and_return_conditional_losses, dwt_1_layer_call_fn, dwt_1_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_nfilt_256_epcs_3_stps_800_I_QP_27_240x240_CosineDecay_20220606-201421/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_nfilt_256_epcs_3_stps_800_I_QP_27_240x240_CosineDecay_20220606-201421/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  4474 psnr:  37.50672056042535 bpp:  0.025891203703703704\n"
     ]
    }
   ],
   "source": [
    "I_QP=27\n",
    "lmbda = 4096\n",
    "np_folder = \"train_set_iqp27.npy\"\n",
    "checkponts_prev_path = \"checkpoints_wavelets_haar_Lmbd_4096_nfilt_256_epcs_12_stps_6000_I_QP_27_240x240_CosineDecay_20220603-223006/\"\n",
    "checkpoints_target_path = \"\"\n",
    "trainer_4096 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, checkpoints_target_path, np_folder)\n",
    "trainer_4096.compile()\n",
    "trainer_4096.fit()\n",
    "trainer_4096.save()\n",
    "trainer_4096.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Loading weights\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.8798 - bpp: 0.4683 - mse: 2.0095e-04\n",
      "Epoch 1: loss improved from inf to 0.87984, saving model to checkpoints_wavelets_haar_Lmbd_2048_nfilt_256_epcs_3_stps_800_I_QP_30_240x240_CosineDecay_20220606-202228/\n",
      "800/800 [==============================] - 144s 147ms/step - loss: 0.8798 - bpp: 0.4683 - mse: 2.0095e-04\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9332 - bpp: 0.4781 - mse: 2.2219e-04\n",
      "Epoch 2: loss did not improve from 0.87984\n",
      "800/800 [==============================] - 118s 147ms/step - loss: 0.9332 - bpp: 0.4781 - mse: 2.2219e-04\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9491 - bpp: 0.4841 - mse: 2.2708e-04\n",
      "Epoch 3: loss did not improve from 0.87984\n",
      "800/800 [==============================] - 118s 146ms/step - loss: 0.9491 - bpp: 0.4841 - mse: 2.2708e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Found untraced functions such as optical_flow_loss_2_layer_call_fn, optical_flow_loss_2_layer_call_and_return_conditional_losses, dwt_2_layer_call_fn, dwt_2_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_nfilt_256_epcs_3_stps_800_I_QP_30_240x240_CosineDecay_20220606-202228/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_nfilt_256_epcs_3_stps_800_I_QP_30_240x240_CosineDecay_20220606-202228/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  1313 psnr:  37.649821895777094 bpp:  0.007598379629629629\n"
     ]
    }
   ],
   "source": [
    "I_QP=30\n",
    "lmbda = 2048\n",
    "np_folder = \"train_set_iqp30.npy\"\n",
    "checkponts_prev_path = \"checkpoints_wavelets_haar_Lmbd_2048_nfilt_256_epcs_12_stps_6000_I_QP_30_240x240_CosineDecay_20220604-001653/\"\n",
    "checkpoints_target_path = \"\"\n",
    "trainer_2048 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, checkpoints_target_path, np_folder)\n",
    "trainer_2048.compile()\n",
    "trainer_2048.fit()\n",
    "trainer_2048.save()\n",
    "trainer_2048.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Loading weights\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7626 - bpp: 0.3849 - mse: 3.6878e-04\n",
      "Epoch 1: loss improved from inf to 0.76257, saving model to checkpoints_wavelets_haar_Lmbd_1024_nfilt_256_epcs_3_stps_800_I_QP_35_240x240_CosineDecay_20220606-203103/\n",
      "800/800 [==============================] - 144s 147ms/step - loss: 0.7626 - bpp: 0.3849 - mse: 3.6878e-04\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7597 - bpp: 0.3842 - mse: 3.6673e-04\n",
      "Epoch 2: loss improved from 0.76257 to 0.75970, saving model to checkpoints_wavelets_haar_Lmbd_1024_nfilt_256_epcs_3_stps_800_I_QP_35_240x240_CosineDecay_20220606-203103/\n",
      "800/800 [==============================] - 121s 150ms/step - loss: 0.7597 - bpp: 0.3842 - mse: 3.6673e-04\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7497 - bpp: 0.3835 - mse: 3.5759e-04\n",
      "Epoch 3: loss improved from 0.75970 to 0.74967, saving model to checkpoints_wavelets_haar_Lmbd_1024_nfilt_256_epcs_3_stps_800_I_QP_35_240x240_CosineDecay_20220606-203103/\n",
      "800/800 [==============================] - 121s 150ms/step - loss: 0.7497 - bpp: 0.3835 - mse: 3.5759e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Found untraced functions such as optical_flow_loss_3_layer_call_fn, optical_flow_loss_3_layer_call_and_return_conditional_losses, dwt_3_layer_call_fn, dwt_3_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_1024_nfilt_256_epcs_3_stps_800_I_QP_35_240x240_CosineDecay_20220606-203103/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_1024_nfilt_256_epcs_3_stps_800_I_QP_35_240x240_CosineDecay_20220606-203103/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  1754 psnr:  35.848933564290206 bpp:  0.010150462962962964\n"
     ]
    }
   ],
   "source": [
    "I_QP=35\n",
    "lmbda = 1024\n",
    "np_folder = \"train_set_iqp35.npy\"\n",
    "checkponts_prev_path = \"checkpoints_wavelets_haar_Lmbd_1024_nfilt_256_epcs_12_stps_6000_I_QP_35_240x240_CosineDecay_20220604-024605/\"\n",
    "checkpoints_target_path = \"\"\n",
    "trainer_1024 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, checkpoints_target_path, np_folder)\n",
    "trainer_1024.compile()\n",
    "trainer_1024.fit()\n",
    "trainer_1024.save()\n",
    "trainer_1024.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Loading weights\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4615 - bpp: 0.2189 - mse: 4.7394e-04\n",
      "Epoch 1: loss improved from inf to 0.46154, saving model to checkpoints_wavelets_haar_Lmbd_512_nfilt_256_epcs_3_stps_800_I_QP_40_240x240_CosineDecay_20220606-203915/\n",
      "800/800 [==============================] - 150s 148ms/step - loss: 0.4615 - bpp: 0.2189 - mse: 4.7394e-04\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4386 - bpp: 0.2098 - mse: 4.4693e-04\n",
      "Epoch 2: loss improved from 0.46154 to 0.43862, saving model to checkpoints_wavelets_haar_Lmbd_512_nfilt_256_epcs_3_stps_800_I_QP_40_240x240_CosineDecay_20220606-203915/\n",
      "800/800 [==============================] - 119s 148ms/step - loss: 0.4386 - bpp: 0.2098 - mse: 4.4693e-04\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4350 - bpp: 0.2120 - mse: 4.3559e-04\n",
      "Epoch 3: loss improved from 0.43862 to 0.43499, saving model to checkpoints_wavelets_haar_Lmbd_512_nfilt_256_epcs_3_stps_800_I_QP_40_240x240_CosineDecay_20220606-203915/\n",
      "800/800 [==============================] - 120s 149ms/step - loss: 0.4350 - bpp: 0.2120 - mse: 4.3559e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Found untraced functions such as optical_flow_loss_4_layer_call_fn, optical_flow_loss_4_layer_call_and_return_conditional_losses, dwt_4_layer_call_fn, dwt_4_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_512_nfilt_256_epcs_3_stps_800_I_QP_40_240x240_CosineDecay_20220606-203915/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_512_nfilt_256_epcs_3_stps_800_I_QP_40_240x240_CosineDecay_20220606-203915/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function OpenDVCW.compress at 0x7ff0a9855dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function OpenDVCW.compress at 0x7ff0a9855dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decompress\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function OpenDVCW.decompress at 0x7ff0a99604c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function OpenDVCW.decompress at 0x7ff0a99604c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin size:  463 psnr:  36.69520214394472 bpp:  0.002679398148148148\n"
     ]
    }
   ],
   "source": [
    "I_QP=40\n",
    "lmbda = 512\n",
    "np_folder = \"train_set_iqp40.npy\"\n",
    "checkponts_prev_path = \"checkpoints_wavelets_haar_Lmbd_512_nfilt_256_epcs_12_stps_6000_I_QP_40_240x240_CosineDecay_20220604-041729/\"\n",
    "checkpoints_target_path = \"\"\n",
    "trainer_512 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, checkpoints_target_path, np_folder)\n",
    "trainer_512.compile()\n",
    "trainer_512.fit()\n",
    "trainer_512.save()\n",
    "trainer_512.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Loading weights\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3480 - bpp: 0.1585 - mse: 7.4004e-04\n",
      "Epoch 1: loss improved from inf to 0.34797, saving model to checkpoints_wavelets_haar_Lmbd_256_nfilt_256_epcs_3_stps_800_I_QP_42_240x240_CosineDecay_20220606-204734/\n",
      "800/800 [==============================] - 142s 145ms/step - loss: 0.3480 - bpp: 0.1585 - mse: 7.4004e-04\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3477 - bpp: 0.1583 - mse: 7.3976e-04\n",
      "Epoch 2: loss improved from 0.34797 to 0.34767, saving model to checkpoints_wavelets_haar_Lmbd_256_nfilt_256_epcs_3_stps_800_I_QP_42_240x240_CosineDecay_20220606-204734/\n",
      "800/800 [==============================] - 121s 150ms/step - loss: 0.3477 - bpp: 0.1583 - mse: 7.3976e-04\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3563 - bpp: 0.1600 - mse: 7.6666e-04\n",
      "Epoch 3: loss did not improve from 0.34767\n",
      "800/800 [==============================] - 118s 146ms/step - loss: 0.3563 - bpp: 0.1600 - mse: 7.6666e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Found untraced functions such as optical_flow_loss_5_layer_call_fn, optical_flow_loss_5_layer_call_and_return_conditional_losses, dwt_5_layer_call_fn, dwt_5_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_256_nfilt_256_epcs_3_stps_800_I_QP_42_240x240_CosineDecay_20220606-204734/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_256_nfilt_256_epcs_3_stps_800_I_QP_42_240x240_CosineDecay_20220606-204734/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function OpenDVCW.compress at 0x7ff0195094c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function OpenDVCW.compress at 0x7ff0195094c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decompress\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function OpenDVCW.decompress at 0x7ff02055fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function OpenDVCW.decompress at 0x7ff02055fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin size:  720 psnr:  34.54284907937003 bpp:  0.004166666666666667\n"
     ]
    }
   ],
   "source": [
    "I_QP=42\n",
    "lmbda = 256\n",
    "np_folder = \"train_set_iqp42.npy\"\n",
    "checkponts_prev_path = \"checkpoints_wavelets_haar_Lmbd_256_nfilt_256_epcs_10_stps_10000_I_QP_42_240x240_CosineDecay_20220606-050526/\"\n",
    "checkpoints_target_path = \"\"\n",
    "trainer_256 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH,\n",
    "                           Height, Width, Channel, NUM_FILTERS, MV_KERNEL_SIZE, RES_KERNEL_SIZE, M,\n",
    "                           lmbda, lr_init, lr_alpha, early_stop,\n",
    "                           I_QP, wavelet_name, checkponts_prev_path, checkpoints_target_path, np_folder)\n",
    "trainer_256.compile()\n",
    "trainer_256.fit()\n",
    "trainer_256.save()\n",
    "trainer_256.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  3689 psnr:  38.99991980310481 bpp:  0.02134837962962963\n",
      "compress\n",
      "decompress\n",
      "bin size:  4474 psnr:  37.50672056042535 bpp:  0.025891203703703704\n",
      "compress\n",
      "decompress\n",
      "bin size:  1313 psnr:  37.649821895777094 bpp:  0.007598379629629629\n",
      "compress\n",
      "decompress\n",
      "bin size:  1754 psnr:  35.848933564290206 bpp:  0.010150462962962964\n",
      "compress\n",
      "decompress\n",
      "bin size:  463 psnr:  36.695193114730024 bpp:  0.002679398148148148\n",
      "compress\n",
      "decompress\n",
      "bin size:  720 psnr:  34.54284907937003 bpp:  0.004166666666666667\n"
     ]
    }
   ],
   "source": [
    "trainer_8192.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_4096.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_2048.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_1024.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_512.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_256.test(i_frame, p_frame, out_bin, out_decom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
