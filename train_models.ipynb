{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW/train_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "from train import TrainOpenDVCW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1000\n",
    "STEPS_PER_EPOCH = 100\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "NUM_FILTERS = 128\n",
    "lmbda = 2**11 # 2048\n",
    "lr_init = 1e-4\n",
    "lr_alpha = 1e-8\n",
    "early_stop = 600\n",
    "I_QP=27\n",
    "wavelet_name = \"haar\"\n",
    "np_folder = \"folder_cloud_test.npy\"\n",
    "checkponts_prev_path = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 14:14:30.950096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:30.974644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:30.975377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:30.977034: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-29 14:14:30.979717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:30.980595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:30.981335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:32.111038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:32.111859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:32.112734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 14:14:32.113565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 14:14:49.360450: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-29 14:15:15.109122: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 81.6576 - bpp: 5.3411 - mse: 0.0373\n",
      "Epoch 1: loss improved from inf to 81.65765, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 54s 141ms/step - loss: 81.6576 - bpp: 5.3411 - mse: 0.0373\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 16.0085 - bpp: 5.2734 - mse: 0.0052\n",
      "Epoch 2: loss improved from 81.65765 to 16.00848, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 16.0085 - bpp: 5.2734 - mse: 0.0052\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 13.4547 - bpp: 5.2114 - mse: 0.0040\n",
      "Epoch 3: loss improved from 16.00848 to 13.45470, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 17s 164ms/step - loss: 13.4547 - bpp: 5.2114 - mse: 0.0040\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 12.9542 - bpp: 5.1570 - mse: 0.0038\n",
      "Epoch 4: loss improved from 13.45470 to 12.95420, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 12.9542 - bpp: 5.1570 - mse: 0.0038\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 12.5646 - bpp: 5.1125 - mse: 0.0036\n",
      "Epoch 5: loss improved from 12.95420 to 12.56458, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 12.5646 - bpp: 5.1125 - mse: 0.0036\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 12.7841 - bpp: 5.0785 - mse: 0.0038\n",
      "Epoch 6: loss did not improve from 12.56458\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 12.7841 - bpp: 5.0785 - mse: 0.0038\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.5655 - bpp: 5.0553 - mse: 0.0032\n",
      "Epoch 7: loss improved from 12.56458 to 11.56546, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 11.5655 - bpp: 5.0553 - mse: 0.0032\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.3906 - bpp: 5.0416 - mse: 0.0031\n",
      "Epoch 8: loss improved from 11.56546 to 11.39057, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 11.3906 - bpp: 5.0416 - mse: 0.0031\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.0666 - bpp: 5.0344 - mse: 0.0025\n",
      "Epoch 9: loss improved from 11.39057 to 10.06664, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 10.0666 - bpp: 5.0344 - mse: 0.0025\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.7835 - bpp: 5.0325 - mse: 0.0023\n",
      "Epoch 10: loss improved from 10.06664 to 9.78346, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 9.7835 - bpp: 5.0325 - mse: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141430/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_11 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_11.compile()\n",
    "trainer_11.fit()\n",
    "trainer_11.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 106.2689 - bpp: 5.3491 - mse: 0.0246\n",
      "Epoch 1: loss improved from inf to 106.26890, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 41s 132ms/step - loss: 106.2689 - bpp: 5.3491 - mse: 0.0246\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 23.3341 - bpp: 5.2802 - mse: 0.0044\n",
      "Epoch 2: loss improved from 106.26890 to 23.33413, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 23.3341 - bpp: 5.2802 - mse: 0.0044\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 18.6515 - bpp: 5.2170 - mse: 0.0033\n",
      "Epoch 3: loss improved from 23.33413 to 18.65153, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 18.6515 - bpp: 5.2170 - mse: 0.0033\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 17.7587 - bpp: 5.1619 - mse: 0.0031\n",
      "Epoch 4: loss improved from 18.65153 to 17.75867, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 17.7587 - bpp: 5.1619 - mse: 0.0031\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 13.1715 - bpp: 5.1164 - mse: 0.0020\n",
      "Epoch 5: loss improved from 17.75867 to 13.17146, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 13.1715 - bpp: 5.1164 - mse: 0.0020\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.5251 - bpp: 5.0819 - mse: 0.0016\n",
      "Epoch 6: loss improved from 13.17146 to 11.52509, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 11.5251 - bpp: 5.0819 - mse: 0.0016\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.5291 - bpp: 5.0580 - mse: 0.0013\n",
      "Epoch 7: loss improved from 11.52509 to 10.52905, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 10.5291 - bpp: 5.0580 - mse: 0.0013\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 12.4055 - bpp: 5.0438 - mse: 0.0018\n",
      "Epoch 8: loss did not improve from 10.52905\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 12.4055 - bpp: 5.0438 - mse: 0.0018\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 10.9819 - bpp: 5.0369 - mse: 0.0015\n",
      "Epoch 9: loss did not improve from 10.52905\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 10.9819 - bpp: 5.0369 - mse: 0.0015\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 11.7489 - bpp: 5.0349 - mse: 0.0016\n",
      "Epoch 10: loss did not improve from 10.52905\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 11.7489 - bpp: 5.0349 - mse: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_1_layer_call_fn, optical_flow_loss_1_layer_call_and_return_conditional_losses, dwt_1_layer_call_fn, dwt_1_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_10_I_QP_27_240x240_CosineDecay_20220429-141927/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_12 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_12.compile()\n",
    "trainer_12.fit()\n",
    "trainer_12.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 448.7399 - bpp: 5.3412 - mse: 0.0541\n",
      "Epoch 1: loss improved from inf to 448.73987, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 41s 137ms/step - loss: 448.7399 - bpp: 5.3412 - mse: 0.0541\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 75.3853 - bpp: 5.2723 - mse: 0.0086\n",
      "Epoch 2: loss improved from 448.73987 to 75.38526, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 75.3853 - bpp: 5.2723 - mse: 0.0086\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 45.2176 - bpp: 5.2095 - mse: 0.0049\n",
      "Epoch 3: loss improved from 75.38526 to 45.21759, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 45.2176 - bpp: 5.2095 - mse: 0.0049\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 37.3063 - bpp: 5.1552 - mse: 0.0039\n",
      "Epoch 4: loss improved from 45.21759 to 37.30632, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 37.3063 - bpp: 5.1552 - mse: 0.0039\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 31.2494 - bpp: 5.1106 - mse: 0.0032\n",
      "Epoch 5: loss improved from 37.30632 to 31.24940, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 31.2494 - bpp: 5.1106 - mse: 0.0032\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 28.3807 - bpp: 5.0767 - mse: 0.0028\n",
      "Epoch 6: loss improved from 31.24940 to 28.38066, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 28.3807 - bpp: 5.0767 - mse: 0.0028\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 28.1624 - bpp: 5.0533 - mse: 0.0028\n",
      "Epoch 7: loss improved from 28.38066 to 28.16245, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 28.1624 - bpp: 5.0533 - mse: 0.0028\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 25.3480 - bpp: 5.0392 - mse: 0.0025\n",
      "Epoch 8: loss improved from 28.16245 to 25.34802, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 25.3480 - bpp: 5.0392 - mse: 0.0025\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 27.4126 - bpp: 5.0324 - mse: 0.0027\n",
      "Epoch 9: loss did not improve from 25.34802\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 27.4126 - bpp: 5.0324 - mse: 0.0027\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 29.5587 - bpp: 5.0306 - mse: 0.0030\n",
      "Epoch 10: loss did not improve from 25.34802\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 29.5587 - bpp: 5.0306 - mse: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_2_layer_call_fn, optical_flow_loss_2_layer_call_and_return_conditional_losses, dwt_2_layer_call_fn, dwt_2_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142403/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_13 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_13.compile()\n",
    "trainer_13.fit()\n",
    "trainer_13.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 485.4152 - bpp: 5.3424 - mse: 0.0293\n",
      "Epoch 1: loss improved from inf to 485.41516, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 43s 144ms/step - loss: 485.4152 - bpp: 5.3424 - mse: 0.0293\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 100.7963 - bpp: 5.2739 - mse: 0.0058\n",
      "Epoch 2: loss improved from 485.41516 to 100.79634, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 100.7963 - bpp: 5.2739 - mse: 0.0058\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 77.8486 - bpp: 5.2114 - mse: 0.0044\n",
      "Epoch 3: loss improved from 100.79634 to 77.84861, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 77.8486 - bpp: 5.2114 - mse: 0.0044\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 62.3131 - bpp: 5.1564 - mse: 0.0035\n",
      "Epoch 4: loss improved from 77.84861 to 62.31308, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 62.3131 - bpp: 5.1564 - mse: 0.0035\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 45.7924 - bpp: 5.1117 - mse: 0.0025\n",
      "Epoch 5: loss improved from 62.31308 to 45.79239, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 45.7924 - bpp: 5.1117 - mse: 0.0025\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 47.0519 - bpp: 5.0778 - mse: 0.0026\n",
      "Epoch 6: loss did not improve from 45.79239\n",
      "100/100 [==============================] - 14s 133ms/step - loss: 47.0519 - bpp: 5.0778 - mse: 0.0026\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 44.4448 - bpp: 5.0543 - mse: 0.0024\n",
      "Epoch 7: loss improved from 45.79239 to 44.44482, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 44.4448 - bpp: 5.0543 - mse: 0.0024\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 40.7252 - bpp: 5.0400 - mse: 0.0022\n",
      "Epoch 8: loss improved from 44.44482 to 40.72521, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 40.7252 - bpp: 5.0400 - mse: 0.0022\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 41.8704 - bpp: 5.0333 - mse: 0.0022\n",
      "Epoch 9: loss did not improve from 40.72521\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 41.8704 - bpp: 5.0333 - mse: 0.0022\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 44.2590 - bpp: 5.0315 - mse: 0.0024\n",
      "Epoch 10: loss did not improve from 40.72521\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 44.2590 - bpp: 5.0315 - mse: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_3_layer_call_fn, optical_flow_loss_3_layer_call_and_return_conditional_losses, dwt_3_layer_call_fn, dwt_3_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_16384_epcs_10_I_QP_27_240x240_CosineDecay_20220429-142853/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_14 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_14.compile()\n",
    "trainer_14.fit()\n",
    "trainer_14.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load\n",
    "import OpenDVCW\n",
    "\n",
    "img_path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "i_frame = img_path + 'im1' + '.png'\n",
    "p_frame = img_path + 'im2' + '.png'\n",
    "out_bin = \"Test_com/test{}.bin\".format(0)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(0)\n",
    "\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(0)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(0)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, Width, Height))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, Width, Height))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  36317 psnr:  31.869162558122834\n",
      "compress\n",
      "decompress\n",
      "bin size:  36330 psnr:  34.4324596881105\n",
      "compress\n",
      "decompress\n",
      "bin size:  36304 psnr:  32.85701636708525\n",
      "compress\n",
      "decompress\n",
      "bin size:  36306 psnr:  33.128819363905954\n"
     ]
    }
   ],
   "source": [
    "trainer_11.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_11.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_12.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_12.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_13.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_13.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_14.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_14.check_psnr(p_on_test, out_decom, out_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n",
      "bin size:  36304 psnr:  32.857332772222165\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n",
      "bin size:  36330 psnr:  34.434357393958166\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "in the compress\n",
      "decompress\n",
      "in decompress\n",
      "bin size:  36317 psnr:  31.86915958613981\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
