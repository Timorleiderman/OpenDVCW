{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/tensorflow-wavelets/Development/OpenDVC'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/tensorflow-wavelets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:12:55.540292: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/tensorflow-wavelets\n",
    "import OpenDVCW\n",
    "import numpy as np\n",
    "import load\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import DataGen\n",
    "import Callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "EPOCHS = 10000\n",
    "STEPS_PER_EPOCH = 60\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "lmbda = 1024\n",
    "lr_init = 1e-7\n",
    "# samples = 1200\n",
    "early_stop = 10\n",
    "I_QP=27\n",
    "\n",
    "args = OpenDVCW.Arguments()\n",
    "last = 0\n",
    "checkponts_last_path = \"checkpoints_L_{}_{}_{}x{}/\".format(lmbda, last, Width, Height)\n",
    "checkponts_new_path = \"checkpoints_L_{}_{}_{}x{}/\".format(lmbda, last+1, Width, Height)\n",
    "save_name = \"model_save_l_256_\" + str(last+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:12:59.071080: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-06 18:12:59.106939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:12:59.107711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:09.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2022-02-06 18:12:59.107754: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-06 18:12:59.114856: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-02-06 18:12:59.114925: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-02-06 18:12:59.117173: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-06 18:12:59.117585: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-06 18:12:59.119179: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-02-06 18:12:59.120671: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-02-06 18:12:59.120912: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-02-06 18:12:59.121087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:12:59.121822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:12:59.122525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-02-06 18:12:59.123235: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-06 18:12:59.124942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:12:59.125688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:09.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2022-02-06 18:12:59.125783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:12:59.126528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:12:59.127098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-02-06 18:12:59.127170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-06 18:13:00.031049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-06 18:13:00.031106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-02-06 18:13:00.031118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-02-06 18:13:00.031514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:13:00.032335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:13:00.033080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-06 18:13:00.033771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10250 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:13:02.801902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "* [Loading dataset]...\n",
      "Loading weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:13:08.159973: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to fit\n"
     ]
    }
   ],
   "source": [
    "model = OpenDVCW.OpenDVC(width=Width, height=Height, batch_size=batch_size, num_filters=128, lmbda=lmbda)\n",
    "# model = OpenDVC2.OpenDVC(width=Width, height=Height, batch_size=batch_size, num_filters=128, lmbda=lmbda)\n",
    "# model = OpenDVC2.OpenDVC_SSIM(width=Width, height=Height, batch_size=batch_size, num_filters=128, lmbda=lmbda)\n",
    "# model = OpenDVC2.OpenDVC_NORM(width=Width, height=Height, batch_size=batch_size, num_filters=128, lmbda=lmbda)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init),)\n",
    "print(\"* [Model compiled]...\")\n",
    "\n",
    "print(\"* [Loading dataset]...\")\n",
    "data = DataGen.DataVimeo90kGenerator(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\", \n",
    "                                    batch_size,\n",
    "                                    (Height,Width,Channel),\n",
    "                                    Channel,\n",
    "                                    True, \n",
    "                                    I_QP,\n",
    "                                    True)\n",
    "\n",
    "print(\"Loading weights\")\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(checkponts_last_path)\n",
    "print(\"Going to fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].trainable = False\n",
    "# model.layers[1].trainable = False\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[3].trainable = True\n",
    "# model.layers[4].trainable = False\n",
    "# model.layers[5].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_analysis True\n",
      "mv_synthesis True\n",
      "res_analysis True\n",
      "res_synthesis True\n",
      "optical_flow True\n",
      "motion_compensation True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:13:08.945436: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-02-06 18:13:08.945495: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-02-06 18:13:08.945587: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2022-02-06 18:13:08.947759: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so.11.2\n",
      "2022-02-06 18:13:09.282731: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-02-06 18:13:09.286216: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2022-02-06 18:13:09.542939: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-06 18:13:09.543793: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:13:33.302090: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-02-06 18:13:34.333438: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2022-02-06 18:13:34.341992: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-02-06 18:13:35.209350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/60 [..............................] - ETA: 29:07 - loss: 0.8482 - bpp: 0.0996 - mse: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:13:40.032100: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-02-06 18:13:40.032347: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/60 [>.............................] - ETA: 2:09 - loss: 0.5499 - bpp: 0.0918 - mse: 8.9483e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:13:41.424824: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-02-06 18:13:41.438158: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2022-02-06 18:13:41.559853: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 3518 callback api events and 3482 activity events. \n",
      "2022-02-06 18:13:41.673007: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-02-06 18:13:41.837747: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41\n",
      "2022-02-06 18:13:41.916400: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.trace.json.gz\n",
      "2022-02-06 18:13:42.095813: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41\n",
      "2022-02-06 18:13:42.105515: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.memory_profile.json.gz\n",
      "2022-02-06 18:13:42.115388: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41Dumped tool data for xplane.pb to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20220206-181258/train/plugins/profile/2022_02_06_18_13_41/bb6aa9fd969d.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/60 [==>...........................] - ETA: 36s - loss: 0.8009 - bpp: 0.0973 - mse: 0.0014WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1138s vs `on_train_batch_begin` time: 0.2059s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1138s vs `on_train_batch_end` time: 0.2673s). Check your callbacks.\n",
      "60/60 [==============================] - 39s 161ms/step - loss: 1.1020 - bpp: 0.0995 - mse: 0.0020\n",
      "[MemoryCallback]:  6416316\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.10205, saving model to checkpoints_Lagrangian_256_10/\n",
      "Epoch 2/10000\n",
      "60/60 [==============================] - 7s 116ms/step - loss: 0.9410 - bpp: 0.0974 - mse: 0.0016\n",
      "[MemoryCallback]:  6425328\n",
      "\n",
      "Epoch 00002: loss improved from 1.10205 to 0.94102, saving model to checkpoints_Lagrangian_256_10/\n",
      "Epoch 3/10000\n",
      "60/60 [==============================] - 7s 115ms/step - loss: 0.9437 - bpp: 0.0957 - mse: 0.0017\n",
      "[MemoryCallback]:  6514196\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.94102\n",
      "Epoch 4/10000\n",
      "60/60 [==============================] - 7s 112ms/step - loss: 1.0329 - bpp: 0.0982 - mse: 0.0018\n",
      "[MemoryCallback]:  6552036\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.94102\n",
      "Epoch 5/10000\n",
      "60/60 [==============================] - 7s 112ms/step - loss: 0.9816 - bpp: 0.0958 - mse: 0.0017\n",
      "[MemoryCallback]:  6553420\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.94102\n",
      "Epoch 6/10000\n",
      "60/60 [==============================] - 7s 112ms/step - loss: 0.9752 - bpp: 0.0962 - mse: 0.0017\n",
      "[MemoryCallback]:  6553452\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.94102\n",
      "Epoch 7/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.1643 - bpp: 0.0998 - mse: 0.0021\n",
      "[MemoryCallback]:  6570332\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.94102\n",
      "Epoch 8/10000\n",
      "60/60 [==============================] - 7s 122ms/step - loss: 0.8396 - bpp: 0.0940 - mse: 0.0015\n",
      "[MemoryCallback]:  6589616\n",
      "\n",
      "Epoch 00008: loss improved from 0.94102 to 0.83961, saving model to checkpoints_Lagrangian_256_10/\n",
      "Epoch 9/10000\n",
      "60/60 [==============================] - 7s 116ms/step - loss: 0.6788 - bpp: 0.0944 - mse: 0.0011\n",
      "[MemoryCallback]:  6590164\n",
      "\n",
      "Epoch 00009: loss improved from 0.83961 to 0.67878, saving model to checkpoints_Lagrangian_256_10/\n",
      "Epoch 10/10000\n",
      "60/60 [==============================] - 7s 115ms/step - loss: 0.6399 - bpp: 0.0936 - mse: 0.0011\n",
      "[MemoryCallback]:  6590164\n",
      "\n",
      "Epoch 00010: loss improved from 0.67878 to 0.63986, saving model to checkpoints_Lagrangian_256_10/\n",
      "Epoch 11/10000\n",
      "60/60 [==============================] - 7s 117ms/step - loss: 0.9688 - bpp: 0.0968 - mse: 0.0017\n",
      "[MemoryCallback]:  6590164\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.63986\n",
      "Epoch 12/10000\n",
      "60/60 [==============================] - 7s 115ms/step - loss: 0.7921 - bpp: 0.0944 - mse: 0.0014\n",
      "[MemoryCallback]:  6590164\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.63986\n",
      "Epoch 13/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.0076 - bpp: 0.0945 - mse: 0.0018\n",
      "[MemoryCallback]:  6605664\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.63986\n",
      "Epoch 14/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.8341 - bpp: 0.0946 - mse: 0.0014\n",
      "[MemoryCallback]:  6608296\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.63986\n",
      "Epoch 15/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.1338 - bpp: 0.0968 - mse: 0.0020\n",
      "[MemoryCallback]:  6608296\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.63986\n",
      "Epoch 16/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.0376 - bpp: 0.0977 - mse: 0.0018\n",
      "[MemoryCallback]:  6609848\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.63986\n",
      "Epoch 17/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1705 - bpp: 0.0982 - mse: 0.0021\n",
      "[MemoryCallback]:  6609848\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.63986\n",
      "Epoch 18/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9495 - bpp: 0.0967 - mse: 0.0017\n",
      "[MemoryCallback]:  6625912\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.63986\n",
      "Epoch 19/10000\n",
      "60/60 [==============================] - 7s 114ms/step - loss: 1.1645 - bpp: 0.0972 - mse: 0.0021\n",
      "[MemoryCallback]:  6625924\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.63986\n",
      "Epoch 20/10000\n",
      "60/60 [==============================] - 9s 151ms/step - loss: 1.0289 - bpp: 0.0963 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.63986\n",
      "Epoch 21/10000\n",
      "60/60 [==============================] - 7s 115ms/step - loss: 1.3579 - bpp: 0.0969 - mse: 0.0025\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.63986\n",
      "Epoch 22/10000\n",
      "60/60 [==============================] - 7s 112ms/step - loss: 1.2473 - bpp: 0.0961 - mse: 0.0022\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.63986\n",
      "Epoch 23/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9842 - bpp: 0.0945 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.63986\n",
      "Epoch 24/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.1072 - bpp: 0.0970 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.63986\n",
      "Epoch 25/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.1269 - bpp: 0.0974 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.63986\n",
      "Epoch 26/10000\n",
      "60/60 [==============================] - 7s 112ms/step - loss: 1.0971 - bpp: 0.0975 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.63986\n",
      "Epoch 27/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.8151 - bpp: 0.0937 - mse: 0.0014\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.63986\n",
      "Epoch 28/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.8298 - bpp: 0.0935 - mse: 0.0014\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.63986\n",
      "Epoch 29/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.4076 - bpp: 0.0989 - mse: 0.0026\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.63986\n",
      "Epoch 30/10000\n",
      "60/60 [==============================] - 7s 107ms/step - loss: 0.8762 - bpp: 0.0938 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.63986\n",
      "Epoch 31/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1770 - bpp: 0.0966 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.63986\n",
      "Epoch 32/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9630 - bpp: 0.0949 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.63986\n",
      "Epoch 33/10000\n",
      "60/60 [==============================] - 7s 107ms/step - loss: 1.2178 - bpp: 0.0966 - mse: 0.0022\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.63986\n",
      "Epoch 34/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0619 - bpp: 0.0945 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.63986\n",
      "Epoch 35/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.0909 - bpp: 0.0968 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.63986\n",
      "Epoch 36/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0249 - bpp: 0.0950 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.63986\n",
      "Epoch 37/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 0.9224 - bpp: 0.0961 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.63986\n",
      "Epoch 38/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1752 - bpp: 0.0963 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.63986\n",
      "Epoch 39/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0091 - bpp: 0.0957 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.63986\n",
      "Epoch 40/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.8251 - bpp: 0.0939 - mse: 0.0014\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.63986\n",
      "Epoch 41/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.8662 - bpp: 0.0927 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.63986\n",
      "Epoch 42/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0883 - bpp: 0.0970 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.63986\n",
      "Epoch 43/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9582 - bpp: 0.0980 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.63986\n",
      "Epoch 44/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1408 - bpp: 0.0978 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.63986\n",
      "Epoch 45/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.0392 - bpp: 0.0973 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.63986\n",
      "Epoch 46/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.2811 - bpp: 0.0966 - mse: 0.0023\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.63986\n",
      "Epoch 47/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.0407 - bpp: 0.0951 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.63986\n",
      "Epoch 48/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.7695 - bpp: 0.0940 - mse: 0.0013\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.63986\n",
      "Epoch 49/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9728 - bpp: 0.0973 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.63986\n",
      "Epoch 50/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9361 - bpp: 0.0960 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.63986\n",
      "Epoch 51/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9477 - bpp: 0.0952 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.63986\n",
      "Epoch 52/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.3334 - bpp: 0.0988 - mse: 0.0024\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.63986\n",
      "Epoch 53/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1860 - bpp: 0.0959 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.63986\n",
      "Epoch 54/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9877 - bpp: 0.0969 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.63986\n",
      "Epoch 55/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.3530 - bpp: 0.0984 - mse: 0.0025\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.63986\n",
      "Epoch 56/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.0743 - bpp: 0.0969 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.63986\n",
      "Epoch 57/10000\n",
      "60/60 [==============================] - 7s 113ms/step - loss: 0.9764 - bpp: 0.0963 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.63986\n",
      "Epoch 58/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9663 - bpp: 0.0962 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.63986\n",
      "Epoch 59/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1014 - bpp: 0.1004 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.63986\n",
      "Epoch 60/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.0533 - bpp: 0.0977 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.63986\n",
      "Epoch 61/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.1207 - bpp: 0.0986 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.63986\n",
      "Epoch 62/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0561 - bpp: 0.0958 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.63986\n",
      "Epoch 63/10000\n",
      "60/60 [==============================] - 9s 150ms/step - loss: 1.0758 - bpp: 0.0955 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.63986\n",
      "Epoch 64/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1177 - bpp: 0.0969 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.63986\n",
      "Epoch 65/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.8549 - bpp: 0.0942 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.63986\n",
      "Epoch 66/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9950 - bpp: 0.0966 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.63986\n",
      "Epoch 67/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9130 - bpp: 0.0953 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.63986\n",
      "Epoch 68/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9203 - bpp: 0.0954 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.63986\n",
      "Epoch 69/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.0480 - bpp: 0.0985 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.63986\n",
      "Epoch 70/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.8991 - bpp: 0.0939 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.63986\n",
      "Epoch 71/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1758 - bpp: 0.0982 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.63986\n",
      "Epoch 72/10000\n",
      "60/60 [==============================] - 8s 128ms/step - loss: 0.9528 - bpp: 0.0970 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.63986\n",
      "Epoch 73/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9980 - bpp: 0.0968 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.63986\n",
      "Epoch 74/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.8901 - bpp: 0.0958 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.63986\n",
      "Epoch 75/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.2244 - bpp: 0.0993 - mse: 0.0022\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.63986\n",
      "Epoch 76/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 0.9624 - bpp: 0.0966 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.63986\n",
      "Epoch 77/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9596 - bpp: 0.0966 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.63986\n",
      "Epoch 78/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9121 - bpp: 0.0975 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.63986\n",
      "Epoch 79/10000\n",
      "60/60 [==============================] - 7s 107ms/step - loss: 1.0988 - bpp: 0.0964 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.63986\n",
      "Epoch 80/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9934 - bpp: 0.0969 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.63986\n",
      "Epoch 81/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.8877 - bpp: 0.0977 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.63986\n",
      "Epoch 82/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9594 - bpp: 0.0970 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.63986\n",
      "Epoch 83/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 0.9798 - bpp: 0.0975 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.63986\n",
      "Epoch 84/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.1257 - bpp: 0.0978 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.63986\n",
      "Epoch 85/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0812 - bpp: 0.0968 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.63986\n",
      "Epoch 86/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.0039 - bpp: 0.0982 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.63986\n",
      "Epoch 87/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0342 - bpp: 0.0986 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.63986\n",
      "Epoch 88/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.0439 - bpp: 0.0983 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.63986\n",
      "Epoch 89/10000\n",
      "60/60 [==============================] - 7s 113ms/step - loss: 0.9156 - bpp: 0.0955 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.63986\n",
      "Epoch 90/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9601 - bpp: 0.0972 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.63986\n",
      "Epoch 91/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.9657 - bpp: 0.0945 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.63986\n",
      "Epoch 92/10000\n",
      "60/60 [==============================] - 7s 114ms/step - loss: 0.8883 - bpp: 0.0962 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.63986\n",
      "Epoch 93/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9171 - bpp: 0.0963 - mse: 0.0016\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.63986\n",
      "Epoch 94/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0142 - bpp: 0.0972 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.63986\n",
      "Epoch 95/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1631 - bpp: 0.0965 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.63986\n",
      "Epoch 96/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.7849 - bpp: 0.0940 - mse: 0.0013\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.63986\n",
      "Epoch 97/10000\n",
      "60/60 [==============================] - 7s 112ms/step - loss: 1.0147 - bpp: 0.0971 - mse: 0.0018\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.63986\n",
      "Epoch 98/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1172 - bpp: 0.0998 - mse: 0.0020\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.63986\n",
      "Epoch 99/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.8675 - bpp: 0.0967 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.63986\n",
      "Epoch 100/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1747 - bpp: 0.1007 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.63986\n",
      "Epoch 101/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.8433 - bpp: 0.0948 - mse: 0.0015\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00101: loss did not improve from 0.63986\n",
      "Epoch 102/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.2599 - bpp: 0.0985 - mse: 0.0023\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.63986\n",
      "Epoch 103/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 0.7756 - bpp: 0.0940 - mse: 0.0013\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00103: loss did not improve from 0.63986\n",
      "Epoch 104/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 0.9493 - bpp: 0.0961 - mse: 0.0017\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00104: loss did not improve from 0.63986\n",
      "Epoch 105/10000\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1780 - bpp: 0.0985 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00105: loss did not improve from 0.63986\n",
      "Epoch 106/10000\n",
      "60/60 [==============================] - 9s 154ms/step - loss: 0.7924 - bpp: 0.0937 - mse: 0.0014\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.63986\n",
      "Epoch 107/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.1608 - bpp: 0.0988 - mse: 0.0021\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00107: loss did not improve from 0.63986\n",
      "Epoch 108/10000\n",
      "60/60 [==============================] - 7s 111ms/step - loss: 1.3956 - bpp: 0.0983 - mse: 0.0025\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00108: loss did not improve from 0.63986\n",
      "Epoch 109/10000\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.2382 - bpp: 0.0974 - mse: 0.0022\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.63986\n",
      "Epoch 110/10000\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.0918 - bpp: 0.0994 - mse: 0.0019\n",
      "[MemoryCallback]:  6651780\n",
      "\n",
      "Epoch 00110: loss did not improve from 0.63986\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "hist = model.fit(x=data, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, verbose=1, batch_size=batch_size,\n",
    "                callbacks=[\n",
    "                    Callbacks.MemoryCallback(),\n",
    "                    # Callbacks.LearningRateReducer(),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath=checkponts_new_path, save_weights_only=True, save_freq='epoch', monitor=\"loss\", mode='min',  save_best_only=True, verbose=1), \n",
    "                    tf.keras.callbacks.TerminateOnNaN(),\n",
    "                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stop),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq=\"epoch\"),            \n",
    "                    ],\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/WindowsDev/DataSets/vimeo_septuplet/sequences/00070/0362/im1.png\n",
      "compress\n",
      "in the compress\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "in decompress\n"
     ]
    }
   ],
   "source": [
    "path = load.load_random_path(\"/mnt/WindowsDev/Developer/tensorflow-wavelets/folder_cloud.npy\")\n",
    "i=0\n",
    "out_bin = \"Test_com/test{}.bin\".format(i)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(i)\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(i)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(i)\n",
    "\n",
    "i_frame = path + 'im1' + '.png'\n",
    "p_frame = path + 'im2' + '.png'\n",
    "print(i_frame)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, 240, 240))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, 240, 240))\n",
    "\n",
    "OpenDVCW.compress(model, i_frame, p_frame, out_bin, 240, 240)\n",
    "OpenDVCW.decompress(model, i_frame, out_bin, out_decom, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, mc1_layer_call_fn, mc1_layer_call_and_return_conditional_losses, res_block_layer_call_fn while saving (showing 5 of 135). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_l_256_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_l_256_10/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
