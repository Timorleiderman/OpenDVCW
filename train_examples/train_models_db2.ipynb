{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/OpenDVCW'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/OpenDVCW\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubu-admin/Developer/tensorflow-wavelets\n",
    "%cd /workspaces/OpenDVCW\n",
    "from train import TrainOpenDVCW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1500\n",
    "STEPS_PER_EPOCH = 200\n",
    "Height = 240\n",
    "Width = 240\n",
    "Channel = 3\n",
    "NUM_FILTERS = 128\n",
    "lmbda = 2**11 # 2048\n",
    "lr_init = 1e-4\n",
    "lr_alpha = 1e-8\n",
    "early_stop = 800\n",
    "I_QP=27\n",
    "wavelet_name = \"haar\"\n",
    "np_folder = \"folder_cloud_test.npy\"\n",
    "checkponts_prev_path = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 20:17:45.591912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:45.789671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:45.790664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:45.796141: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 20:17:45.802208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:45.803068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:45.803818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:47.882084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:47.882999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:47.883753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 20:17:47.884705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10244 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:00:09.0, compute capability: 8.6\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 20:18:06.507918: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-05-02 20:18:35.641539: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 53.6973 - bpp: 5.3031 - mse: 0.0236\n",
      "Epoch 1: loss improved from inf to 53.69730, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 81s 176ms/step - loss: 53.6973 - bpp: 5.3031 - mse: 0.0236\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3391 - bpp: 5.1640 - mse: 0.0035\n",
      "Epoch 2: loss improved from 53.69730 to 12.33906, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 12.3391 - bpp: 5.1640 - mse: 0.0035\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6921 - bpp: 5.0290 - mse: 0.0028\n",
      "Epoch 3: loss improved from 12.33906 to 10.69211, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 10.6921 - bpp: 5.0290 - mse: 0.0028\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1275 - bpp: 4.8983 - mse: 0.0026\n",
      "Epoch 4: loss improved from 10.69211 to 10.12750, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 10.1275 - bpp: 4.8983 - mse: 0.0026\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9935 - bpp: 4.7706 - mse: 0.0021\n",
      "Epoch 5: loss improved from 10.12750 to 8.99352, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 8.9935 - bpp: 4.7706 - mse: 0.0021\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6842 - bpp: 4.6429 - mse: 0.0015\n",
      "Epoch 6: loss improved from 8.99352 to 7.68416, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 7.6842 - bpp: 4.6429 - mse: 0.0015\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9911 - bpp: 4.5174 - mse: 0.0012\n",
      "Epoch 7: loss improved from 7.68416 to 6.99113, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 6.9911 - bpp: 4.5174 - mse: 0.0012\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8134 - bpp: 4.3960 - mse: 0.0012\n",
      "Epoch 8: loss improved from 6.99113 to 6.81337, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 6.8134 - bpp: 4.3960 - mse: 0.0012\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3699 - bpp: 4.2751 - mse: 0.0010\n",
      "Epoch 9: loss improved from 6.81337 to 6.36990, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 6.3699 - bpp: 4.2751 - mse: 0.0010\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9338 - bpp: 4.1560 - mse: 8.6807e-04\n",
      "Epoch 10: loss improved from 6.36990 to 5.93376, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 5.9338 - bpp: 4.1560 - mse: 8.6807e-04\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6736 - bpp: 4.0401 - mse: 7.9759e-04\n",
      "Epoch 11: loss improved from 5.93376 to 5.67357, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 5.6736 - bpp: 4.0401 - mse: 7.9759e-04\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3752 - bpp: 3.9266 - mse: 7.0731e-04\n",
      "Epoch 12: loss improved from 5.67357 to 5.37519, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 5.3752 - bpp: 3.9266 - mse: 7.0731e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2855 - bpp: 3.8174 - mse: 7.1684e-04\n",
      "Epoch 13: loss improved from 5.37519 to 5.28552, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 5.2855 - bpp: 3.8174 - mse: 7.1684e-04\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0442 - bpp: 3.7067 - mse: 6.5308e-04\n",
      "Epoch 14: loss improved from 5.28552 to 5.04416, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 5.0442 - bpp: 3.7067 - mse: 6.5308e-04\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8470 - bpp: 3.5986 - mse: 6.0957e-04\n",
      "Epoch 15: loss improved from 5.04416 to 4.84696, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 4.8470 - bpp: 3.5986 - mse: 6.0957e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5424 - bpp: 3.4934 - mse: 5.1219e-04\n",
      "Epoch 16: loss improved from 4.84696 to 4.54239, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 4.5424 - bpp: 3.4934 - mse: 5.1219e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4638 - bpp: 3.3905 - mse: 5.2407e-04\n",
      "Epoch 17: loss improved from 4.54239 to 4.46380, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 4.4638 - bpp: 3.3905 - mse: 5.2407e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3396 - bpp: 3.2906 - mse: 5.1220e-04\n",
      "Epoch 18: loss improved from 4.46380 to 4.33958, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 4.3396 - bpp: 3.2906 - mse: 5.1220e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2594 - bpp: 3.1934 - mse: 5.2050e-04\n",
      "Epoch 19: loss improved from 4.33958 to 4.25941, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 4.2594 - bpp: 3.1934 - mse: 5.2050e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0003 - bpp: 3.0908 - mse: 4.4410e-04\n",
      "Epoch 20: loss improved from 4.25941 to 4.00027, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 4.0003 - bpp: 3.0908 - mse: 4.4410e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9867 - bpp: 2.9997 - mse: 4.8192e-04\n",
      "Epoch 21: loss improved from 4.00027 to 3.98671, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 3.9867 - bpp: 2.9997 - mse: 4.8192e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6693 - bpp: 2.9060 - mse: 3.7274e-04\n",
      "Epoch 22: loss improved from 3.98671 to 3.66934, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 3.6693 - bpp: 2.9060 - mse: 3.7274e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7132 - bpp: 2.8210 - mse: 4.3564e-04\n",
      "Epoch 23: loss did not improve from 3.66934\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 3.7132 - bpp: 2.8210 - mse: 4.3564e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5847 - bpp: 2.7322 - mse: 4.1624e-04\n",
      "Epoch 24: loss improved from 3.66934 to 3.58466, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 3.5847 - bpp: 2.7322 - mse: 4.1624e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3072 - bpp: 2.6404 - mse: 3.2556e-04\n",
      "Epoch 25: loss improved from 3.58466 to 3.30716, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 3.3072 - bpp: 2.6404 - mse: 3.2556e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2886 - bpp: 2.5578 - mse: 3.5686e-04\n",
      "Epoch 26: loss improved from 3.30716 to 3.28863, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 3.2886 - bpp: 2.5578 - mse: 3.5686e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6769 - bpp: 2.5308 - mse: 0.0010\n",
      "Epoch 27: loss did not improve from 3.28863\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 4.6769 - bpp: 2.5308 - mse: 0.0010\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2471 - bpp: 2.4039 - mse: 4.1173e-04\n",
      "Epoch 28: loss improved from 3.28863 to 3.24710, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 3.2471 - bpp: 2.4039 - mse: 4.1173e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0957 - bpp: 2.3248 - mse: 3.7639e-04\n",
      "Epoch 29: loss improved from 3.24710 to 3.09567, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 3.0957 - bpp: 2.3248 - mse: 3.7639e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9609 - bpp: 2.2449 - mse: 3.4956e-04\n",
      "Epoch 30: loss improved from 3.09567 to 2.96085, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 2.9609 - bpp: 2.2449 - mse: 3.4956e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9815 - bpp: 2.1840 - mse: 3.8942e-04\n",
      "Epoch 31: loss did not improve from 2.96085\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 2.9815 - bpp: 2.1840 - mse: 3.8942e-04\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7537 - bpp: 2.0969 - mse: 3.2067e-04\n",
      "Epoch 32: loss improved from 2.96085 to 2.75366, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 2.7537 - bpp: 2.0969 - mse: 3.2067e-04\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6997 - bpp: 2.0279 - mse: 3.2800e-04\n",
      "Epoch 33: loss improved from 2.75366 to 2.69968, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 2.6997 - bpp: 2.0279 - mse: 3.2800e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6058 - bpp: 1.9511 - mse: 3.1965e-04\n",
      "Epoch 34: loss improved from 2.69968 to 2.60576, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 2.6058 - bpp: 1.9511 - mse: 3.1965e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5595 - bpp: 1.8931 - mse: 3.2538e-04\n",
      "Epoch 35: loss improved from 2.60576 to 2.55952, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 2.5595 - bpp: 1.8931 - mse: 3.2538e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4994 - bpp: 1.8305 - mse: 3.2661e-04\n",
      "Epoch 36: loss improved from 2.55952 to 2.49938, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 2.4994 - bpp: 1.8305 - mse: 3.2661e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5146 - bpp: 1.7700 - mse: 3.6357e-04\n",
      "Epoch 37: loss did not improve from 2.49938\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 2.5146 - bpp: 1.7700 - mse: 3.6357e-04\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4830 - bpp: 1.7296 - mse: 3.6785e-04\n",
      "Epoch 38: loss improved from 2.49938 to 2.48296, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.4830 - bpp: 1.7296 - mse: 3.6785e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5413 - bpp: 1.6851 - mse: 4.1806e-04\n",
      "Epoch 39: loss did not improve from 2.48296\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 2.5413 - bpp: 1.6851 - mse: 4.1806e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3116 - bpp: 1.6226 - mse: 3.3642e-04\n",
      "Epoch 40: loss improved from 2.48296 to 2.31155, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 2.3116 - bpp: 1.6226 - mse: 3.3642e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3096 - bpp: 1.5521 - mse: 3.6986e-04\n",
      "Epoch 41: loss improved from 2.31155 to 2.30958, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 2.3096 - bpp: 1.5521 - mse: 3.6986e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1041 - bpp: 1.4917 - mse: 2.9902e-04\n",
      "Epoch 42: loss improved from 2.30958 to 2.10408, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 2.1041 - bpp: 1.4917 - mse: 2.9902e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1208 - bpp: 1.4552 - mse: 3.2502e-04\n",
      "Epoch 43: loss did not improve from 2.10408\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 2.1208 - bpp: 1.4552 - mse: 3.2502e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2234 - bpp: 1.4292 - mse: 3.8781e-04\n",
      "Epoch 44: loss did not improve from 2.10408\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 2.2234 - bpp: 1.4292 - mse: 3.8781e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9975 - bpp: 1.3553 - mse: 3.1361e-04\n",
      "Epoch 45: loss improved from 2.10408 to 1.99754, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.9975 - bpp: 1.3553 - mse: 3.1361e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9180 - bpp: 1.3143 - mse: 2.9478e-04\n",
      "Epoch 46: loss improved from 1.99754 to 1.91804, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.9180 - bpp: 1.3143 - mse: 2.9478e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9680 - bpp: 1.2990 - mse: 3.2666e-04\n",
      "Epoch 47: loss did not improve from 1.91804\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.9680 - bpp: 1.2990 - mse: 3.2666e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8255 - bpp: 1.2327 - mse: 2.8945e-04\n",
      "Epoch 48: loss improved from 1.91804 to 1.82553, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.8255 - bpp: 1.2327 - mse: 2.8945e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8667 - bpp: 1.2059 - mse: 3.2264e-04\n",
      "Epoch 49: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.8667 - bpp: 1.2059 - mse: 3.2264e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8667 - bpp: 1.1794 - mse: 3.3561e-04\n",
      "Epoch 50: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.8667 - bpp: 1.1794 - mse: 3.3561e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8123 - bpp: 1.2030 - mse: 7.8578e-04\n",
      "Epoch 51: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 2.8123 - bpp: 1.2030 - mse: 7.8578e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9539 - bpp: 1.2722 - mse: 0.0018\n",
      "Epoch 52: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 4.9539 - bpp: 1.2722 - mse: 0.0018\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0919 - bpp: 1.1380 - mse: 4.6578e-04\n",
      "Epoch 53: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 2.0919 - bpp: 1.1380 - mse: 4.6578e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9022 - bpp: 1.1177 - mse: 3.8309e-04\n",
      "Epoch 54: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.9022 - bpp: 1.1177 - mse: 3.8309e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0283 - bpp: 1.0863 - mse: 4.5996e-04\n",
      "Epoch 55: loss did not improve from 1.82553\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 2.0283 - bpp: 1.0863 - mse: 4.5996e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6963 - bpp: 1.0289 - mse: 3.2590e-04\n",
      "Epoch 56: loss improved from 1.82553 to 1.69631, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.6963 - bpp: 1.0289 - mse: 3.2590e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7046 - bpp: 1.0216 - mse: 3.3352e-04\n",
      "Epoch 57: loss did not improve from 1.69631\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.7046 - bpp: 1.0216 - mse: 3.3352e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5957 - bpp: 0.9682 - mse: 3.0638e-04\n",
      "Epoch 58: loss improved from 1.69631 to 1.59570, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5957 - bpp: 0.9682 - mse: 3.0638e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6421 - bpp: 0.9558 - mse: 3.3512e-04\n",
      "Epoch 59: loss did not improve from 1.59570\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.6421 - bpp: 0.9558 - mse: 3.3512e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7340 - bpp: 0.9796 - mse: 3.6836e-04\n",
      "Epoch 60: loss did not improve from 1.59570\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.7340 - bpp: 0.9796 - mse: 3.6836e-04\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5838 - bpp: 0.9247 - mse: 3.2187e-04\n",
      "Epoch 61: loss improved from 1.59570 to 1.58384, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5838 - bpp: 0.9247 - mse: 3.2187e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6135 - bpp: 0.9218 - mse: 3.3770e-04\n",
      "Epoch 62: loss did not improve from 1.58384\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.6135 - bpp: 0.9218 - mse: 3.3770e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6394 - bpp: 0.9226 - mse: 3.4998e-04\n",
      "Epoch 63: loss did not improve from 1.58384\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.6394 - bpp: 0.9226 - mse: 3.4998e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5653 - bpp: 0.8841 - mse: 3.3261e-04\n",
      "Epoch 64: loss improved from 1.58384 to 1.56530, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5653 - bpp: 0.8841 - mse: 3.3261e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6056 - bpp: 0.8815 - mse: 3.5356e-04\n",
      "Epoch 65: loss did not improve from 1.56530\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.6056 - bpp: 0.8815 - mse: 3.5356e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4155 - bpp: 0.8367 - mse: 2.8266e-04\n",
      "Epoch 66: loss improved from 1.56530 to 1.41554, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.4155 - bpp: 0.8367 - mse: 2.8266e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4978 - bpp: 0.8409 - mse: 3.2078e-04\n",
      "Epoch 67: loss did not improve from 1.41554\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4978 - bpp: 0.8409 - mse: 3.2078e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5382 - bpp: 0.8451 - mse: 3.3841e-04\n",
      "Epoch 68: loss did not improve from 1.41554\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5382 - bpp: 0.8451 - mse: 3.3841e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5165 - bpp: 0.8182 - mse: 3.4099e-04\n",
      "Epoch 69: loss did not improve from 1.41554\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5165 - bpp: 0.8182 - mse: 3.4099e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4688 - bpp: 0.8096 - mse: 3.2191e-04\n",
      "Epoch 70: loss did not improve from 1.41554\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4688 - bpp: 0.8096 - mse: 3.2191e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4030 - bpp: 0.7885 - mse: 3.0005e-04\n",
      "Epoch 71: loss improved from 1.41554 to 1.40300, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.4030 - bpp: 0.7885 - mse: 3.0005e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4503 - bpp: 0.7887 - mse: 3.2304e-04\n",
      "Epoch 72: loss did not improve from 1.40300\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4503 - bpp: 0.7887 - mse: 3.2304e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6064 - bpp: 0.8154 - mse: 3.8623e-04\n",
      "Epoch 73: loss did not improve from 1.40300\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.6064 - bpp: 0.8154 - mse: 3.8623e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3830 - bpp: 0.7508 - mse: 3.0866e-04\n",
      "Epoch 74: loss improved from 1.40300 to 1.38296, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.3830 - bpp: 0.7508 - mse: 3.0866e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4121 - bpp: 0.7676 - mse: 3.1468e-04\n",
      "Epoch 75: loss did not improve from 1.38296\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4121 - bpp: 0.7676 - mse: 3.1468e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4816 - bpp: 0.7692 - mse: 3.4786e-04\n",
      "Epoch 76: loss did not improve from 1.38296\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.4816 - bpp: 0.7692 - mse: 3.4786e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3584 - bpp: 0.7311 - mse: 3.0632e-04\n",
      "Epoch 77: loss improved from 1.38296 to 1.35844, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.3584 - bpp: 0.7311 - mse: 3.0632e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4034 - bpp: 0.7358 - mse: 3.2596e-04\n",
      "Epoch 78: loss did not improve from 1.35844\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 1.4034 - bpp: 0.7358 - mse: 3.2596e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2342 - bpp: 0.6877 - mse: 2.6684e-04\n",
      "Epoch 79: loss improved from 1.35844 to 1.23423, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.2342 - bpp: 0.6877 - mse: 2.6684e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4309 - bpp: 0.7295 - mse: 3.4250e-04\n",
      "Epoch 80: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4309 - bpp: 0.7295 - mse: 3.4250e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3928 - bpp: 0.7175 - mse: 3.2972e-04\n",
      "Epoch 81: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.3928 - bpp: 0.7175 - mse: 3.2972e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3307 - bpp: 0.6926 - mse: 3.1159e-04\n",
      "Epoch 82: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3307 - bpp: 0.6926 - mse: 3.1159e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3501 - bpp: 0.6950 - mse: 3.1988e-04\n",
      "Epoch 83: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.3501 - bpp: 0.6950 - mse: 3.1988e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2945 - bpp: 0.6777 - mse: 3.0119e-04\n",
      "Epoch 84: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2945 - bpp: 0.6777 - mse: 3.0119e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3226 - bpp: 0.6810 - mse: 3.1329e-04\n",
      "Epoch 85: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.3226 - bpp: 0.6810 - mse: 3.1329e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3739 - bpp: 0.6854 - mse: 3.3617e-04\n",
      "Epoch 86: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 1.3739 - bpp: 0.6854 - mse: 3.3617e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3479 - bpp: 0.6725 - mse: 3.2978e-04\n",
      "Epoch 87: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.3479 - bpp: 0.6725 - mse: 3.2978e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2435 - bpp: 0.6418 - mse: 2.9383e-04\n",
      "Epoch 88: loss did not improve from 1.23423\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2435 - bpp: 0.6418 - mse: 2.9383e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1488 - bpp: 0.6173 - mse: 2.5950e-04\n",
      "Epoch 89: loss improved from 1.23423 to 1.14877, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.1488 - bpp: 0.6173 - mse: 2.5950e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2797 - bpp: 0.6414 - mse: 3.1168e-04\n",
      "Epoch 90: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2797 - bpp: 0.6414 - mse: 3.1168e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3329 - bpp: 0.6459 - mse: 3.3541e-04\n",
      "Epoch 91: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.3329 - bpp: 0.6459 - mse: 3.3541e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2156 - bpp: 0.6189 - mse: 2.9134e-04\n",
      "Epoch 92: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.2156 - bpp: 0.6189 - mse: 2.9134e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0961 - bpp: 0.6532 - mse: 7.0456e-04\n",
      "Epoch 93: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 2.0961 - bpp: 0.6532 - mse: 7.0456e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7033 - bpp: 0.7029 - mse: 4.8851e-04\n",
      "Epoch 94: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.7033 - bpp: 0.7029 - mse: 4.8851e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3466 - bpp: 0.6648 - mse: 3.3292e-04\n",
      "Epoch 95: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.3466 - bpp: 0.6648 - mse: 3.3292e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2097 - bpp: 0.6175 - mse: 2.8918e-04\n",
      "Epoch 96: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2097 - bpp: 0.6175 - mse: 2.8918e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1909 - bpp: 0.6086 - mse: 2.8431e-04\n",
      "Epoch 97: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.1909 - bpp: 0.6086 - mse: 2.8431e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1733 - bpp: 0.5987 - mse: 2.8058e-04\n",
      "Epoch 98: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1733 - bpp: 0.5987 - mse: 2.8058e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2308 - bpp: 0.6163 - mse: 3.0007e-04\n",
      "Epoch 99: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.2308 - bpp: 0.6163 - mse: 3.0007e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1752 - bpp: 0.5919 - mse: 2.8481e-04\n",
      "Epoch 100: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1752 - bpp: 0.5919 - mse: 2.8481e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3255 - bpp: 0.6377 - mse: 3.3581e-04\n",
      "Epoch 101: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.3255 - bpp: 0.6377 - mse: 3.3581e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1981 - bpp: 0.5936 - mse: 2.9514e-04\n",
      "Epoch 102: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1981 - bpp: 0.5936 - mse: 2.9514e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2178 - bpp: 0.6089 - mse: 2.9729e-04\n",
      "Epoch 103: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.2178 - bpp: 0.6089 - mse: 2.9729e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2385 - bpp: 0.6144 - mse: 3.0472e-04\n",
      "Epoch 104: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2385 - bpp: 0.6144 - mse: 3.0472e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1603 - bpp: 0.5849 - mse: 2.8096e-04\n",
      "Epoch 105: loss did not improve from 1.14877\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1603 - bpp: 0.5849 - mse: 2.8096e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0702 - bpp: 0.5536 - mse: 2.5227e-04\n",
      "Epoch 106: loss improved from 1.14877 to 1.07022, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.0702 - bpp: 0.5536 - mse: 2.5227e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1390 - bpp: 0.5710 - mse: 2.7731e-04\n",
      "Epoch 107: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1390 - bpp: 0.5710 - mse: 2.7731e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2154 - bpp: 0.5775 - mse: 3.1145e-04\n",
      "Epoch 108: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.2154 - bpp: 0.5775 - mse: 3.1145e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2468 - bpp: 0.5924 - mse: 3.1950e-04\n",
      "Epoch 109: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2468 - bpp: 0.5924 - mse: 3.1950e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1407 - bpp: 0.5686 - mse: 2.7935e-04\n",
      "Epoch 110: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.1407 - bpp: 0.5686 - mse: 2.7935e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1121 - bpp: 0.5672 - mse: 2.6606e-04\n",
      "Epoch 111: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.1121 - bpp: 0.5672 - mse: 2.6606e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1562 - bpp: 0.5731 - mse: 2.8474e-04\n",
      "Epoch 112: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.1562 - bpp: 0.5731 - mse: 2.8474e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1562 - bpp: 0.5594 - mse: 2.9140e-04\n",
      "Epoch 113: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1562 - bpp: 0.5594 - mse: 2.9140e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3236 - bpp: 0.6049 - mse: 3.5093e-04\n",
      "Epoch 114: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.3236 - bpp: 0.6049 - mse: 3.5093e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1543 - bpp: 0.5658 - mse: 2.8732e-04\n",
      "Epoch 115: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.1543 - bpp: 0.5658 - mse: 2.8732e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1516 - bpp: 0.5645 - mse: 2.8669e-04\n",
      "Epoch 116: loss did not improve from 1.07022\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.1516 - bpp: 0.5645 - mse: 2.8669e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0666 - bpp: 0.5372 - mse: 2.5851e-04\n",
      "Epoch 117: loss improved from 1.07022 to 1.06658, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.0666 - bpp: 0.5372 - mse: 2.5851e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1235 - bpp: 0.5472 - mse: 2.8141e-04\n",
      "Epoch 118: loss did not improve from 1.06658\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1235 - bpp: 0.5472 - mse: 2.8141e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1022 - bpp: 0.5464 - mse: 2.7138e-04\n",
      "Epoch 119: loss did not improve from 1.06658\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.1022 - bpp: 0.5464 - mse: 2.7138e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0260 - bpp: 0.5264 - mse: 2.4397e-04\n",
      "Epoch 120: loss improved from 1.06658 to 1.02602, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0260 - bpp: 0.5264 - mse: 2.4397e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1602 - bpp: 0.5469 - mse: 2.9948e-04\n",
      "Epoch 121: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1602 - bpp: 0.5469 - mse: 2.9948e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4784 - bpp: 0.6948 - mse: 0.0023\n",
      "Epoch 122: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 5.4784 - bpp: 0.6948 - mse: 0.0023\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5666 - bpp: 0.5958 - mse: 9.6229e-04\n",
      "Epoch 123: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 2.5666 - bpp: 0.5958 - mse: 9.6229e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3044 - bpp: 0.5728 - mse: 8.4554e-04\n",
      "Epoch 124: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 2.3044 - bpp: 0.5728 - mse: 8.4554e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9812 - bpp: 0.5257 - mse: 7.1069e-04\n",
      "Epoch 125: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.9812 - bpp: 0.5257 - mse: 7.1069e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3348 - bpp: 0.5330 - mse: 8.7978e-04\n",
      "Epoch 126: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 2.3348 - bpp: 0.5330 - mse: 8.7978e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9682 - bpp: 0.5265 - mse: 7.0394e-04\n",
      "Epoch 127: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.9682 - bpp: 0.5265 - mse: 7.0394e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6996 - bpp: 0.5019 - mse: 5.8480e-04\n",
      "Epoch 128: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.6996 - bpp: 0.5019 - mse: 5.8480e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1106 - bpp: 0.5198 - mse: 7.7677e-04\n",
      "Epoch 129: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 2.1106 - bpp: 0.5198 - mse: 7.7677e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1022 - bpp: 0.5188 - mse: 7.7312e-04\n",
      "Epoch 130: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 2.1022 - bpp: 0.5188 - mse: 7.7312e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9628 - bpp: 0.5186 - mse: 7.0520e-04\n",
      "Epoch 131: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.9628 - bpp: 0.5186 - mse: 7.0520e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9684 - bpp: 0.5163 - mse: 7.0900e-04\n",
      "Epoch 132: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.9684 - bpp: 0.5163 - mse: 7.0900e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9222 - bpp: 0.5070 - mse: 6.9103e-04\n",
      "Epoch 133: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.9222 - bpp: 0.5070 - mse: 6.9103e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7178 - bpp: 0.4978 - mse: 5.9568e-04\n",
      "Epoch 134: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.7178 - bpp: 0.4978 - mse: 5.9568e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7913 - bpp: 0.4928 - mse: 6.3403e-04\n",
      "Epoch 135: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 174ms/step - loss: 1.7913 - bpp: 0.4928 - mse: 6.3403e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7460 - bpp: 0.4932 - mse: 6.1171e-04\n",
      "Epoch 136: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.7460 - bpp: 0.4932 - mse: 6.1171e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8328 - bpp: 0.5014 - mse: 6.5009e-04\n",
      "Epoch 137: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.8328 - bpp: 0.5014 - mse: 6.5009e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9053 - bpp: 0.4990 - mse: 6.8667e-04\n",
      "Epoch 138: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.9053 - bpp: 0.4990 - mse: 6.8667e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7085 - bpp: 0.4834 - mse: 5.9820e-04\n",
      "Epoch 139: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.7085 - bpp: 0.4834 - mse: 5.9820e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8433 - bpp: 0.4975 - mse: 6.5711e-04\n",
      "Epoch 140: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.8433 - bpp: 0.4975 - mse: 6.5711e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8287 - bpp: 0.4982 - mse: 6.4967e-04\n",
      "Epoch 141: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.8287 - bpp: 0.4982 - mse: 6.4967e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0387 - bpp: 0.5185 - mse: 7.4228e-04\n",
      "Epoch 142: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 2.0387 - bpp: 0.5185 - mse: 7.4228e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8857 - bpp: 0.4996 - mse: 6.7681e-04\n",
      "Epoch 143: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.8857 - bpp: 0.4996 - mse: 6.7681e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7415 - bpp: 0.4878 - mse: 6.1217e-04\n",
      "Epoch 144: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.7415 - bpp: 0.4878 - mse: 6.1217e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5031 - bpp: 0.4768 - mse: 5.0111e-04\n",
      "Epoch 145: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5031 - bpp: 0.4768 - mse: 5.0111e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6664 - bpp: 0.4843 - mse: 5.7718e-04\n",
      "Epoch 146: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.6664 - bpp: 0.4843 - mse: 5.7718e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6096 - bpp: 0.4771 - mse: 5.5298e-04\n",
      "Epoch 147: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.6096 - bpp: 0.4771 - mse: 5.5298e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6345 - bpp: 0.4795 - mse: 5.6400e-04\n",
      "Epoch 148: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.6345 - bpp: 0.4795 - mse: 5.6400e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1273 - bpp: 0.5064 - mse: 7.9144e-04\n",
      "Epoch 149: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 2.1273 - bpp: 0.5064 - mse: 7.9144e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7941 - bpp: 0.5012 - mse: 6.3127e-04\n",
      "Epoch 150: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.7941 - bpp: 0.5012 - mse: 6.3127e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8184 - bpp: 0.5100 - mse: 6.3888e-04\n",
      "Epoch 151: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 1.8184 - bpp: 0.5100 - mse: 6.3888e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7066 - bpp: 0.4986 - mse: 5.8987e-04\n",
      "Epoch 152: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.7066 - bpp: 0.4986 - mse: 5.8987e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7736 - bpp: 0.5125 - mse: 6.1577e-04\n",
      "Epoch 153: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.7736 - bpp: 0.5125 - mse: 6.1577e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5964 - bpp: 0.4902 - mse: 5.4018e-04\n",
      "Epoch 154: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5964 - bpp: 0.4902 - mse: 5.4018e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5128 - bpp: 0.4858 - mse: 5.0148e-04\n",
      "Epoch 155: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 1.5128 - bpp: 0.4858 - mse: 5.0148e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6011 - bpp: 0.4787 - mse: 5.4805e-04\n",
      "Epoch 156: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6011 - bpp: 0.4787 - mse: 5.4805e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6665 - bpp: 0.4976 - mse: 5.7076e-04\n",
      "Epoch 157: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.6665 - bpp: 0.4976 - mse: 5.7076e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6517 - bpp: 0.4858 - mse: 5.6930e-04\n",
      "Epoch 158: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.6517 - bpp: 0.4858 - mse: 5.6930e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4372 - bpp: 0.4772 - mse: 4.6874e-04\n",
      "Epoch 159: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4372 - bpp: 0.4772 - mse: 4.6874e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6082 - bpp: 0.4884 - mse: 5.4681e-04\n",
      "Epoch 160: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.6082 - bpp: 0.4884 - mse: 5.4681e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8592 - bpp: 0.4968 - mse: 6.6523e-04\n",
      "Epoch 161: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.8592 - bpp: 0.4968 - mse: 6.6523e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7089 - bpp: 0.4976 - mse: 5.9148e-04\n",
      "Epoch 162: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.7089 - bpp: 0.4976 - mse: 5.9148e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5857 - bpp: 0.5035 - mse: 0.0015\n",
      "Epoch 163: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 3.5857 - bpp: 0.5035 - mse: 0.0015\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8163 - bpp: 0.5396 - mse: 6.2336e-04\n",
      "Epoch 164: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.8163 - bpp: 0.5396 - mse: 6.2336e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6406 - bpp: 0.5147 - mse: 5.4975e-04\n",
      "Epoch 165: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.6406 - bpp: 0.5147 - mse: 5.4975e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6206 - bpp: 0.5089 - mse: 5.4282e-04\n",
      "Epoch 166: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6206 - bpp: 0.5089 - mse: 5.4282e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4767 - bpp: 0.4858 - mse: 4.8386e-04\n",
      "Epoch 167: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4767 - bpp: 0.4858 - mse: 4.8386e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3031 - bpp: 0.4728 - mse: 4.0543e-04\n",
      "Epoch 168: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.3031 - bpp: 0.4728 - mse: 4.0543e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6827 - bpp: 0.5056 - mse: 5.7476e-04\n",
      "Epoch 169: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.6827 - bpp: 0.5056 - mse: 5.7476e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4941 - bpp: 0.4906 - mse: 4.9002e-04\n",
      "Epoch 170: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.4941 - bpp: 0.4906 - mse: 4.9002e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5906 - bpp: 0.4935 - mse: 5.3567e-04\n",
      "Epoch 171: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5906 - bpp: 0.4935 - mse: 5.3567e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5115 - bpp: 0.4934 - mse: 4.9711e-04\n",
      "Epoch 172: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5115 - bpp: 0.4934 - mse: 4.9711e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4248 - bpp: 0.4711 - mse: 4.6568e-04\n",
      "Epoch 173: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4248 - bpp: 0.4711 - mse: 4.6568e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3445 - bpp: 0.5038 - mse: 8.9881e-04\n",
      "Epoch 174: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.3445 - bpp: 0.5038 - mse: 8.9881e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4145 - bpp: 0.4794 - mse: 4.5663e-04\n",
      "Epoch 175: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.4145 - bpp: 0.4794 - mse: 4.5663e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5688 - bpp: 0.4989 - mse: 5.2238e-04\n",
      "Epoch 176: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5688 - bpp: 0.4989 - mse: 5.2238e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4526 - bpp: 0.4883 - mse: 4.7086e-04\n",
      "Epoch 177: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.4526 - bpp: 0.4883 - mse: 4.7086e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6374 - bpp: 0.4895 - mse: 5.6054e-04\n",
      "Epoch 178: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.6374 - bpp: 0.4895 - mse: 5.6054e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5515 - bpp: 0.4849 - mse: 5.2083e-04\n",
      "Epoch 179: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.5515 - bpp: 0.4849 - mse: 5.2083e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5485 - bpp: 0.4956 - mse: 5.1411e-04\n",
      "Epoch 180: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5485 - bpp: 0.4956 - mse: 5.1411e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3487 - bpp: 0.4758 - mse: 4.2621e-04\n",
      "Epoch 181: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.3487 - bpp: 0.4758 - mse: 4.2621e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5060 - bpp: 0.4895 - mse: 4.9630e-04\n",
      "Epoch 182: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5060 - bpp: 0.4895 - mse: 4.9630e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4812 - bpp: 0.4765 - mse: 4.9057e-04\n",
      "Epoch 183: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4812 - bpp: 0.4765 - mse: 4.9057e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5180 - bpp: 0.4839 - mse: 5.0492e-04\n",
      "Epoch 184: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.5180 - bpp: 0.4839 - mse: 5.0492e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4309 - bpp: 0.4794 - mse: 4.6461e-04\n",
      "Epoch 185: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4309 - bpp: 0.4794 - mse: 4.6461e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4622 - bpp: 0.4774 - mse: 4.8087e-04\n",
      "Epoch 186: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4622 - bpp: 0.4774 - mse: 4.8087e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5081 - bpp: 0.4847 - mse: 4.9973e-04\n",
      "Epoch 187: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5081 - bpp: 0.4847 - mse: 4.9973e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2182 - bpp: 0.4520 - mse: 3.7413e-04\n",
      "Epoch 188: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.2182 - bpp: 0.4520 - mse: 3.7413e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4279 - bpp: 0.4774 - mse: 4.6410e-04\n",
      "Epoch 189: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4279 - bpp: 0.4774 - mse: 4.6410e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3874 - bpp: 0.4719 - mse: 4.4704e-04\n",
      "Epoch 190: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.3874 - bpp: 0.4719 - mse: 4.4704e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8396 - bpp: 0.4863 - mse: 6.6076e-04\n",
      "Epoch 191: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.8396 - bpp: 0.4863 - mse: 6.6076e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4648 - bpp: 0.4742 - mse: 4.8370e-04\n",
      "Epoch 192: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4648 - bpp: 0.4742 - mse: 4.8370e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5377 - bpp: 0.4929 - mse: 5.1019e-04\n",
      "Epoch 193: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5377 - bpp: 0.4929 - mse: 5.1019e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2960 - bpp: 0.4616 - mse: 4.0745e-04\n",
      "Epoch 194: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.2960 - bpp: 0.4616 - mse: 4.0745e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4300 - bpp: 0.4771 - mse: 4.6528e-04\n",
      "Epoch 195: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4300 - bpp: 0.4771 - mse: 4.6528e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4254 - bpp: 0.4766 - mse: 4.6331e-04\n",
      "Epoch 196: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4254 - bpp: 0.4766 - mse: 4.6331e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4966 - bpp: 0.4822 - mse: 4.9531e-04\n",
      "Epoch 197: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.4966 - bpp: 0.4822 - mse: 4.9531e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5330 - bpp: 0.4787 - mse: 5.1481e-04\n",
      "Epoch 198: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5330 - bpp: 0.4787 - mse: 5.1481e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5860 - bpp: 0.4730 - mse: 5.4350e-04\n",
      "Epoch 199: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 1.5860 - bpp: 0.4730 - mse: 5.4350e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3088 - bpp: 0.4672 - mse: 4.1098e-04\n",
      "Epoch 200: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.3088 - bpp: 0.4672 - mse: 4.1098e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4625 - bpp: 0.4749 - mse: 4.8224e-04\n",
      "Epoch 201: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4625 - bpp: 0.4749 - mse: 4.8224e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4325 - bpp: 0.4727 - mse: 4.6864e-04\n",
      "Epoch 202: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 174ms/step - loss: 1.4325 - bpp: 0.4727 - mse: 4.6864e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2145 - bpp: 0.4554 - mse: 3.7065e-04\n",
      "Epoch 203: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.2145 - bpp: 0.4554 - mse: 3.7065e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2607 - bpp: 0.4628 - mse: 3.8962e-04\n",
      "Epoch 204: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.2607 - bpp: 0.4628 - mse: 3.8962e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8091 - bpp: 0.4844 - mse: 6.4682e-04\n",
      "Epoch 205: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.8091 - bpp: 0.4844 - mse: 6.4682e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2629 - bpp: 0.4592 - mse: 3.9242e-04\n",
      "Epoch 206: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.2629 - bpp: 0.4592 - mse: 3.9242e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5341 - bpp: 0.4721 - mse: 5.1855e-04\n",
      "Epoch 207: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.5341 - bpp: 0.4721 - mse: 5.1855e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3533 - bpp: 0.4715 - mse: 4.3060e-04\n",
      "Epoch 208: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.3533 - bpp: 0.4715 - mse: 4.3060e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4265 - bpp: 0.4722 - mse: 4.6597e-04\n",
      "Epoch 209: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.4265 - bpp: 0.4722 - mse: 4.6597e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3594 - bpp: 0.4629 - mse: 4.3776e-04\n",
      "Epoch 210: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.3594 - bpp: 0.4629 - mse: 4.3776e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3291 - bpp: 0.4713 - mse: 4.1886e-04\n",
      "Epoch 211: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.3291 - bpp: 0.4713 - mse: 4.1886e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6065 - bpp: 0.4830 - mse: 5.4861e-04\n",
      "Epoch 212: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.6065 - bpp: 0.4830 - mse: 5.4861e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0181 - bpp: 0.5061 - mse: 7.3832e-04\n",
      "Epoch 213: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 2.0181 - bpp: 0.5061 - mse: 7.3832e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2494 - bpp: 0.4553 - mse: 3.8774e-04\n",
      "Epoch 214: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.2494 - bpp: 0.4553 - mse: 3.8774e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2664 - bpp: 0.4621 - mse: 3.9272e-04\n",
      "Epoch 215: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2664 - bpp: 0.4621 - mse: 3.9272e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3095 - bpp: 0.4697 - mse: 4.1003e-04\n",
      "Epoch 216: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.3095 - bpp: 0.4697 - mse: 4.1003e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3490 - bpp: 0.4770 - mse: 4.2577e-04\n",
      "Epoch 217: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.3490 - bpp: 0.4770 - mse: 4.2577e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2899 - bpp: 0.4613 - mse: 4.0458e-04\n",
      "Epoch 218: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2899 - bpp: 0.4613 - mse: 4.0458e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3476 - bpp: 0.4750 - mse: 4.2608e-04\n",
      "Epoch 219: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.3476 - bpp: 0.4750 - mse: 4.2608e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4008 - bpp: 0.4779 - mse: 4.5065e-04\n",
      "Epoch 220: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.4008 - bpp: 0.4779 - mse: 4.5065e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4039 - bpp: 0.4827 - mse: 4.4981e-04\n",
      "Epoch 221: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.4039 - bpp: 0.4827 - mse: 4.4981e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3434 - bpp: 0.4756 - mse: 4.2372e-04\n",
      "Epoch 222: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.3434 - bpp: 0.4756 - mse: 4.2372e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3382 - bpp: 0.4732 - mse: 4.2240e-04\n",
      "Epoch 223: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.3382 - bpp: 0.4732 - mse: 4.2240e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2524 - bpp: 0.4624 - mse: 3.8574e-04\n",
      "Epoch 224: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2524 - bpp: 0.4624 - mse: 3.8574e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4185 - bpp: 0.4712 - mse: 4.6259e-04\n",
      "Epoch 225: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.4185 - bpp: 0.4712 - mse: 4.6259e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5567 - bpp: 0.4896 - mse: 5.2108e-04\n",
      "Epoch 226: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5567 - bpp: 0.4896 - mse: 5.2108e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2523 - bpp: 0.4660 - mse: 3.8396e-04\n",
      "Epoch 227: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.2523 - bpp: 0.4660 - mse: 3.8396e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2573 - bpp: 0.4650 - mse: 3.8683e-04\n",
      "Epoch 228: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.2573 - bpp: 0.4650 - mse: 3.8683e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4844 - bpp: 0.4685 - mse: 4.9604e-04\n",
      "Epoch 229: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4844 - bpp: 0.4685 - mse: 4.9604e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8392 - bpp: 0.4866 - mse: 6.6045e-04\n",
      "Epoch 230: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.8392 - bpp: 0.4866 - mse: 6.6045e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4427 - bpp: 0.4881 - mse: 4.6612e-04\n",
      "Epoch 231: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4427 - bpp: 0.4881 - mse: 4.6612e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4667 - bpp: 0.4767 - mse: 4.8340e-04\n",
      "Epoch 232: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.4667 - bpp: 0.4767 - mse: 4.8340e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3071 - bpp: 0.4720 - mse: 4.0775e-04\n",
      "Epoch 233: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.3071 - bpp: 0.4720 - mse: 4.0775e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3435 - bpp: 0.4632 - mse: 4.2984e-04\n",
      "Epoch 234: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.3435 - bpp: 0.4632 - mse: 4.2984e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3494 - bpp: 0.4720 - mse: 4.2839e-04\n",
      "Epoch 235: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.3494 - bpp: 0.4720 - mse: 4.2839e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2392 - bpp: 0.4658 - mse: 3.7765e-04\n",
      "Epoch 236: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.2392 - bpp: 0.4658 - mse: 3.7765e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2243 - bpp: 0.4618 - mse: 3.7230e-04\n",
      "Epoch 237: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.2243 - bpp: 0.4618 - mse: 3.7230e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2163 - bpp: 0.4656 - mse: 3.6654e-04\n",
      "Epoch 238: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2163 - bpp: 0.4656 - mse: 3.6654e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2862 - bpp: 0.4749 - mse: 3.9615e-04\n",
      "Epoch 239: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.2862 - bpp: 0.4749 - mse: 3.9615e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6095 - bpp: 0.4780 - mse: 5.5247e-04\n",
      "Epoch 240: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 1.6095 - bpp: 0.4780 - mse: 5.5247e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5270 - bpp: 0.4916 - mse: 5.0559e-04\n",
      "Epoch 241: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.5270 - bpp: 0.4916 - mse: 5.0559e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3531 - bpp: 0.4804 - mse: 4.2612e-04\n",
      "Epoch 242: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.3531 - bpp: 0.4804 - mse: 4.2612e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3012 - bpp: 0.4696 - mse: 4.0602e-04\n",
      "Epoch 243: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.3012 - bpp: 0.4696 - mse: 4.0602e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3573 - bpp: 0.4789 - mse: 4.2890e-04\n",
      "Epoch 244: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.3573 - bpp: 0.4789 - mse: 4.2890e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2451 - bpp: 0.4594 - mse: 3.8366e-04\n",
      "Epoch 245: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.2451 - bpp: 0.4594 - mse: 3.8366e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1660 - bpp: 0.4542 - mse: 3.4757e-04\n",
      "Epoch 246: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.1660 - bpp: 0.4542 - mse: 3.4757e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3056 - bpp: 0.4706 - mse: 4.0769e-04\n",
      "Epoch 247: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.3056 - bpp: 0.4706 - mse: 4.0769e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2764 - bpp: 0.4631 - mse: 3.9712e-04\n",
      "Epoch 248: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.2764 - bpp: 0.4631 - mse: 3.9712e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2096 - bpp: 0.4580 - mse: 3.6697e-04\n",
      "Epoch 249: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.2096 - bpp: 0.4580 - mse: 3.6697e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3888 - bpp: 0.4683 - mse: 4.4947e-04\n",
      "Epoch 250: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 189ms/step - loss: 1.3888 - bpp: 0.4683 - mse: 4.4947e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3272 - bpp: 0.4632 - mse: 4.2187e-04\n",
      "Epoch 251: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.3272 - bpp: 0.4632 - mse: 4.2187e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5643 - bpp: 0.4741 - mse: 5.3234e-04\n",
      "Epoch 252: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5643 - bpp: 0.4741 - mse: 5.3234e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3425 - bpp: 0.4802 - mse: 4.2102e-04\n",
      "Epoch 253: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.3425 - bpp: 0.4802 - mse: 4.2102e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2468 - bpp: 0.4548 - mse: 3.8674e-04\n",
      "Epoch 254: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.2468 - bpp: 0.4548 - mse: 3.8674e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4130 - bpp: 0.4702 - mse: 4.6035e-04\n",
      "Epoch 255: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4130 - bpp: 0.4702 - mse: 4.6035e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3166 - bpp: 0.4692 - mse: 4.1376e-04\n",
      "Epoch 256: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.3166 - bpp: 0.4692 - mse: 4.1376e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3957 - bpp: 0.4766 - mse: 4.4879e-04\n",
      "Epoch 257: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.3957 - bpp: 0.4766 - mse: 4.4879e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3759 - bpp: 0.4746 - mse: 4.4006e-04\n",
      "Epoch 258: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.3759 - bpp: 0.4746 - mse: 4.4006e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1253 - bpp: 0.4459 - mse: 3.3172e-04\n",
      "Epoch 259: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.1253 - bpp: 0.4459 - mse: 3.3172e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2416 - bpp: 0.4696 - mse: 3.7698e-04\n",
      "Epoch 260: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2416 - bpp: 0.4696 - mse: 3.7698e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3514 - bpp: 0.4683 - mse: 4.3120e-04\n",
      "Epoch 261: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.3514 - bpp: 0.4683 - mse: 4.3120e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3701 - bpp: 0.4763 - mse: 4.3641e-04\n",
      "Epoch 262: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.3701 - bpp: 0.4763 - mse: 4.3641e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3722 - bpp: 0.4584 - mse: 4.4615e-04\n",
      "Epoch 263: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.3722 - bpp: 0.4584 - mse: 4.4615e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3871 - bpp: 0.4725 - mse: 4.4662e-04\n",
      "Epoch 264: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.3871 - bpp: 0.4725 - mse: 4.4662e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2372 - bpp: 0.4770 - mse: 3.7119e-04\n",
      "Epoch 265: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2372 - bpp: 0.4770 - mse: 3.7119e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2134 - bpp: 0.4609 - mse: 3.6739e-04\n",
      "Epoch 266: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2134 - bpp: 0.4609 - mse: 3.6739e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2012 - bpp: 0.4671 - mse: 3.5844e-04\n",
      "Epoch 267: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2012 - bpp: 0.4671 - mse: 3.5844e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2686 - bpp: 0.4715 - mse: 3.8919e-04\n",
      "Epoch 268: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.2686 - bpp: 0.4715 - mse: 3.8919e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1458 - bpp: 0.4584 - mse: 3.3566e-04\n",
      "Epoch 269: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.1458 - bpp: 0.4584 - mse: 3.3566e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4529 - bpp: 0.4762 - mse: 4.7689e-04\n",
      "Epoch 270: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 1.4529 - bpp: 0.4762 - mse: 4.7689e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3301 - bpp: 0.4644 - mse: 4.2269e-04\n",
      "Epoch 271: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.3301 - bpp: 0.4644 - mse: 4.2269e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2097 - bpp: 0.4462 - mse: 3.7281e-04\n",
      "Epoch 272: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2097 - bpp: 0.4462 - mse: 3.7281e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3578 - bpp: 0.4760 - mse: 4.3059e-04\n",
      "Epoch 273: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.3578 - bpp: 0.4760 - mse: 4.3059e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3138 - bpp: 0.4803 - mse: 4.0694e-04\n",
      "Epoch 274: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.3138 - bpp: 0.4803 - mse: 4.0694e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2214 - bpp: 0.4555 - mse: 3.7397e-04\n",
      "Epoch 275: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.2214 - bpp: 0.4555 - mse: 3.7397e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2838 - bpp: 0.4659 - mse: 3.9936e-04\n",
      "Epoch 276: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2838 - bpp: 0.4659 - mse: 3.9936e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1324 - bpp: 0.4486 - mse: 3.3389e-04\n",
      "Epoch 277: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.1324 - bpp: 0.4486 - mse: 3.3389e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1970 - bpp: 0.4625 - mse: 3.5866e-04\n",
      "Epoch 278: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.1970 - bpp: 0.4625 - mse: 3.5866e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2081 - bpp: 0.4591 - mse: 3.6575e-04\n",
      "Epoch 279: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.2081 - bpp: 0.4591 - mse: 3.6575e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2009 - bpp: 0.4538 - mse: 3.6478e-04\n",
      "Epoch 280: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2009 - bpp: 0.4538 - mse: 3.6478e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2167 - bpp: 0.4631 - mse: 3.6796e-04\n",
      "Epoch 281: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2167 - bpp: 0.4631 - mse: 3.6796e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3287 - bpp: 0.4700 - mse: 4.1930e-04\n",
      "Epoch 282: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.3287 - bpp: 0.4700 - mse: 4.1930e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5767 - bpp: 0.4750 - mse: 5.3792e-04\n",
      "Epoch 283: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5767 - bpp: 0.4750 - mse: 5.3792e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2215 - bpp: 0.4728 - mse: 3.6558e-04\n",
      "Epoch 284: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2215 - bpp: 0.4728 - mse: 3.6558e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2090 - bpp: 0.4685 - mse: 3.6153e-04\n",
      "Epoch 285: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.2090 - bpp: 0.4685 - mse: 3.6153e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2409 - bpp: 0.4609 - mse: 3.8087e-04\n",
      "Epoch 286: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.2409 - bpp: 0.4609 - mse: 3.8087e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2173 - bpp: 0.4639 - mse: 3.6790e-04\n",
      "Epoch 287: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2173 - bpp: 0.4639 - mse: 3.6790e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1877 - bpp: 0.4573 - mse: 3.5663e-04\n",
      "Epoch 288: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1877 - bpp: 0.4573 - mse: 3.5663e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2751 - bpp: 0.4684 - mse: 3.9391e-04\n",
      "Epoch 289: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.2751 - bpp: 0.4684 - mse: 3.9391e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2408 - bpp: 0.4679 - mse: 3.7740e-04\n",
      "Epoch 290: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2408 - bpp: 0.4679 - mse: 3.7740e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2631 - bpp: 0.4728 - mse: 3.8588e-04\n",
      "Epoch 291: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.2631 - bpp: 0.4728 - mse: 3.8588e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2504 - bpp: 0.4633 - mse: 3.8436e-04\n",
      "Epoch 292: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2504 - bpp: 0.4633 - mse: 3.8436e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2465 - bpp: 0.4612 - mse: 3.8346e-04\n",
      "Epoch 293: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.2465 - bpp: 0.4612 - mse: 3.8346e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2346 - bpp: 0.4704 - mse: 3.7313e-04\n",
      "Epoch 294: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2346 - bpp: 0.4704 - mse: 3.7313e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3177 - bpp: 0.4738 - mse: 4.1206e-04\n",
      "Epoch 295: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.3177 - bpp: 0.4738 - mse: 4.1206e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2767 - bpp: 0.4716 - mse: 3.9310e-04\n",
      "Epoch 296: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.2767 - bpp: 0.4716 - mse: 3.9310e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2226 - bpp: 0.4611 - mse: 3.7180e-04\n",
      "Epoch 297: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 173ms/step - loss: 1.2226 - bpp: 0.4611 - mse: 3.7180e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3857 - bpp: 0.4757 - mse: 4.4435e-04\n",
      "Epoch 298: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.3857 - bpp: 0.4757 - mse: 4.4435e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3334 - bpp: 0.4757 - mse: 4.1881e-04\n",
      "Epoch 299: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.3334 - bpp: 0.4757 - mse: 4.1881e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1498 - bpp: 0.4580 - mse: 3.3776e-04\n",
      "Epoch 300: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1498 - bpp: 0.4580 - mse: 3.3776e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0863 - bpp: 0.4536 - mse: 3.0892e-04\n",
      "Epoch 301: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.0863 - bpp: 0.4536 - mse: 3.0892e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2966 - bpp: 0.4605 - mse: 4.0826e-04\n",
      "Epoch 302: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.2966 - bpp: 0.4605 - mse: 4.0826e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4383 - bpp: 0.4641 - mse: 4.7568e-04\n",
      "Epoch 303: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4383 - bpp: 0.4641 - mse: 4.7568e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3040 - bpp: 0.4745 - mse: 4.0504e-04\n",
      "Epoch 304: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.3040 - bpp: 0.4745 - mse: 4.0504e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1567 - bpp: 0.4660 - mse: 3.3725e-04\n",
      "Epoch 305: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.1567 - bpp: 0.4660 - mse: 3.3725e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3211 - bpp: 0.4840 - mse: 4.0878e-04\n",
      "Epoch 306: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.3211 - bpp: 0.4840 - mse: 4.0878e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2309 - bpp: 0.4609 - mse: 3.7600e-04\n",
      "Epoch 307: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.2309 - bpp: 0.4609 - mse: 3.7600e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2343 - bpp: 0.4625 - mse: 3.7686e-04\n",
      "Epoch 308: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.2343 - bpp: 0.4625 - mse: 3.7686e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2099 - bpp: 0.4568 - mse: 3.6774e-04\n",
      "Epoch 309: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2099 - bpp: 0.4568 - mse: 3.6774e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3095 - bpp: 0.4726 - mse: 4.0861e-04\n",
      "Epoch 310: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.3095 - bpp: 0.4726 - mse: 4.0861e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2857 - bpp: 0.4743 - mse: 3.9620e-04\n",
      "Epoch 311: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.2857 - bpp: 0.4743 - mse: 3.9620e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2997 - bpp: 0.4576 - mse: 4.1118e-04\n",
      "Epoch 312: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2997 - bpp: 0.4576 - mse: 4.1118e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2427 - bpp: 0.4630 - mse: 3.8071e-04\n",
      "Epoch 313: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2427 - bpp: 0.4630 - mse: 3.8071e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2353 - bpp: 0.4655 - mse: 3.7590e-04\n",
      "Epoch 314: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2353 - bpp: 0.4655 - mse: 3.7590e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.4646 - mse: 3.5748e-04\n",
      "Epoch 315: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.1967 - bpp: 0.4646 - mse: 3.5748e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2846 - bpp: 0.4720 - mse: 3.9682e-04\n",
      "Epoch 316: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.2846 - bpp: 0.4720 - mse: 3.9682e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3441 - bpp: 0.4904 - mse: 4.1684e-04\n",
      "Epoch 317: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.3441 - bpp: 0.4904 - mse: 4.1684e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0609 - bpp: 0.4474 - mse: 2.9955e-04\n",
      "Epoch 318: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0609 - bpp: 0.4474 - mse: 2.9955e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2549 - bpp: 0.4782 - mse: 3.7924e-04\n",
      "Epoch 319: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2549 - bpp: 0.4782 - mse: 3.7924e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2617 - bpp: 0.4740 - mse: 3.8462e-04\n",
      "Epoch 320: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2617 - bpp: 0.4740 - mse: 3.8462e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2416 - bpp: 0.4680 - mse: 3.7775e-04\n",
      "Epoch 321: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2416 - bpp: 0.4680 - mse: 3.7775e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1995 - bpp: 0.4619 - mse: 3.6014e-04\n",
      "Epoch 322: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.1995 - bpp: 0.4619 - mse: 3.6014e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2369 - bpp: 0.4565 - mse: 3.8106e-04\n",
      "Epoch 323: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2369 - bpp: 0.4565 - mse: 3.8106e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2463 - bpp: 0.4736 - mse: 3.7727e-04\n",
      "Epoch 324: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.2463 - bpp: 0.4736 - mse: 3.7727e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2054 - bpp: 0.4751 - mse: 3.5659e-04\n",
      "Epoch 325: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2054 - bpp: 0.4751 - mse: 3.5659e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1478 - bpp: 0.4559 - mse: 3.3787e-04\n",
      "Epoch 326: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1478 - bpp: 0.4559 - mse: 3.3787e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2062 - bpp: 0.4663 - mse: 3.6132e-04\n",
      "Epoch 327: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2062 - bpp: 0.4663 - mse: 3.6132e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2991 - bpp: 0.4767 - mse: 4.0156e-04\n",
      "Epoch 328: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2991 - bpp: 0.4767 - mse: 4.0156e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2249 - bpp: 0.4652 - mse: 3.7095e-04\n",
      "Epoch 329: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2249 - bpp: 0.4652 - mse: 3.7095e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1791 - bpp: 0.4584 - mse: 3.5190e-04\n",
      "Epoch 330: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.1791 - bpp: 0.4584 - mse: 3.5190e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1720 - bpp: 0.4596 - mse: 3.4787e-04\n",
      "Epoch 331: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.1720 - bpp: 0.4596 - mse: 3.4787e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0960 - bpp: 0.4490 - mse: 3.1590e-04\n",
      "Epoch 332: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.0960 - bpp: 0.4490 - mse: 3.1590e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2099 - bpp: 0.4798 - mse: 3.5648e-04\n",
      "Epoch 333: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2099 - bpp: 0.4798 - mse: 3.5648e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4760 - bpp: 0.4793 - mse: 4.8663e-04\n",
      "Epoch 334: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4760 - bpp: 0.4793 - mse: 4.8663e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1682 - bpp: 0.4618 - mse: 3.4490e-04\n",
      "Epoch 335: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1682 - bpp: 0.4618 - mse: 3.4490e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2202 - bpp: 0.4643 - mse: 3.6906e-04\n",
      "Epoch 336: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2202 - bpp: 0.4643 - mse: 3.6906e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1766 - bpp: 0.4541 - mse: 3.5282e-04\n",
      "Epoch 337: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1766 - bpp: 0.4541 - mse: 3.5282e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2729 - bpp: 0.4751 - mse: 3.8955e-04\n",
      "Epoch 338: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2729 - bpp: 0.4751 - mse: 3.8955e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2188 - bpp: 0.4557 - mse: 3.7261e-04\n",
      "Epoch 339: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.2188 - bpp: 0.4557 - mse: 3.7261e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1751 - bpp: 0.4616 - mse: 3.4836e-04\n",
      "Epoch 340: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1751 - bpp: 0.4616 - mse: 3.4836e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1189 - bpp: 0.4542 - mse: 3.2453e-04\n",
      "Epoch 341: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1189 - bpp: 0.4542 - mse: 3.2453e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0837 - bpp: 0.4525 - mse: 3.0819e-04\n",
      "Epoch 342: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0837 - bpp: 0.4525 - mse: 3.0819e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2284 - bpp: 0.4678 - mse: 3.7139e-04\n",
      "Epoch 343: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2284 - bpp: 0.4678 - mse: 3.7139e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0527 - bpp: 0.4435 - mse: 2.9747e-04\n",
      "Epoch 344: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0527 - bpp: 0.4435 - mse: 2.9747e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2457 - bpp: 0.4680 - mse: 3.7975e-04\n",
      "Epoch 345: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.2457 - bpp: 0.4680 - mse: 3.7975e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2863 - bpp: 0.4694 - mse: 3.9885e-04\n",
      "Epoch 346: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2863 - bpp: 0.4694 - mse: 3.9885e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3025 - bpp: 0.4798 - mse: 4.0171e-04\n",
      "Epoch 347: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.3025 - bpp: 0.4798 - mse: 4.0171e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2616 - bpp: 0.4620 - mse: 3.9042e-04\n",
      "Epoch 348: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2616 - bpp: 0.4620 - mse: 3.9042e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2264 - bpp: 0.4670 - mse: 3.7082e-04\n",
      "Epoch 349: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2264 - bpp: 0.4670 - mse: 3.7082e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1066 - bpp: 0.4577 - mse: 3.1685e-04\n",
      "Epoch 350: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.1066 - bpp: 0.4577 - mse: 3.1685e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2896 - bpp: 0.4806 - mse: 3.9502e-04\n",
      "Epoch 351: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.2896 - bpp: 0.4806 - mse: 3.9502e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2425 - bpp: 0.4720 - mse: 3.7619e-04\n",
      "Epoch 352: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.2425 - bpp: 0.4720 - mse: 3.7619e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1848 - bpp: 0.4547 - mse: 3.5650e-04\n",
      "Epoch 353: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.1848 - bpp: 0.4547 - mse: 3.5650e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3080 - bpp: 0.4706 - mse: 4.0888e-04\n",
      "Epoch 354: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.3080 - bpp: 0.4706 - mse: 4.0888e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1372 - bpp: 0.4537 - mse: 3.3378e-04\n",
      "Epoch 355: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 180ms/step - loss: 1.1372 - bpp: 0.4537 - mse: 3.3378e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2549 - bpp: 0.4568 - mse: 3.8966e-04\n",
      "Epoch 356: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2549 - bpp: 0.4568 - mse: 3.8966e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2057 - bpp: 0.4654 - mse: 3.6148e-04\n",
      "Epoch 357: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2057 - bpp: 0.4654 - mse: 3.6148e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4744 - bpp: 0.4663 - mse: 4.9226e-04\n",
      "Epoch 358: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4744 - bpp: 0.4663 - mse: 4.9226e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2484 - bpp: 0.4669 - mse: 3.8159e-04\n",
      "Epoch 359: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.2484 - bpp: 0.4669 - mse: 3.8159e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2429 - bpp: 0.4785 - mse: 3.7323e-04\n",
      "Epoch 360: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.2429 - bpp: 0.4785 - mse: 3.7323e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1324 - bpp: 0.4612 - mse: 3.2772e-04\n",
      "Epoch 361: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.1324 - bpp: 0.4612 - mse: 3.2772e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1862 - bpp: 0.4666 - mse: 3.5135e-04\n",
      "Epoch 362: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1862 - bpp: 0.4666 - mse: 3.5135e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1490 - bpp: 0.4570 - mse: 3.3790e-04\n",
      "Epoch 363: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1490 - bpp: 0.4570 - mse: 3.3790e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1555 - bpp: 0.4606 - mse: 3.3929e-04\n",
      "Epoch 364: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.1555 - bpp: 0.4606 - mse: 3.3929e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0719 - bpp: 0.4477 - mse: 3.0476e-04\n",
      "Epoch 365: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0719 - bpp: 0.4477 - mse: 3.0476e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1978 - bpp: 0.4682 - mse: 3.5627e-04\n",
      "Epoch 366: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1978 - bpp: 0.4682 - mse: 3.5627e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1135 - bpp: 0.4553 - mse: 3.2137e-04\n",
      "Epoch 367: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1135 - bpp: 0.4553 - mse: 3.2137e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1537 - bpp: 0.4594 - mse: 3.3899e-04\n",
      "Epoch 368: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.1537 - bpp: 0.4594 - mse: 3.3899e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1795 - bpp: 0.4672 - mse: 3.4783e-04\n",
      "Epoch 369: loss did not improve from 1.02602\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1795 - bpp: 0.4672 - mse: 3.4783e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0020 - bpp: 0.4398 - mse: 2.7449e-04\n",
      "Epoch 370: loss improved from 1.02602 to 1.00198, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0020 - bpp: 0.4398 - mse: 2.7449e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1340 - bpp: 0.4583 - mse: 3.2995e-04\n",
      "Epoch 371: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.1340 - bpp: 0.4583 - mse: 3.2995e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0955 - bpp: 0.4456 - mse: 3.1737e-04\n",
      "Epoch 372: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0955 - bpp: 0.4456 - mse: 3.1737e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2671 - bpp: 0.4724 - mse: 3.8805e-04\n",
      "Epoch 373: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2671 - bpp: 0.4724 - mse: 3.8805e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1840 - bpp: 0.4561 - mse: 3.5539e-04\n",
      "Epoch 374: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1840 - bpp: 0.4561 - mse: 3.5539e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1468 - bpp: 0.4594 - mse: 3.3562e-04\n",
      "Epoch 375: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1468 - bpp: 0.4594 - mse: 3.3562e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2101 - bpp: 0.4666 - mse: 3.6302e-04\n",
      "Epoch 376: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.2101 - bpp: 0.4666 - mse: 3.6302e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1656 - bpp: 0.4629 - mse: 3.4309e-04\n",
      "Epoch 377: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1656 - bpp: 0.4629 - mse: 3.4309e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2047 - bpp: 0.4451 - mse: 3.7089e-04\n",
      "Epoch 378: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2047 - bpp: 0.4451 - mse: 3.7089e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4082 - bpp: 0.4732 - mse: 4.5654e-04\n",
      "Epoch 379: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.4082 - bpp: 0.4732 - mse: 4.5654e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1470 - bpp: 0.4626 - mse: 3.3415e-04\n",
      "Epoch 380: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1470 - bpp: 0.4626 - mse: 3.3415e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0810 - bpp: 0.4504 - mse: 3.0790e-04\n",
      "Epoch 381: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0810 - bpp: 0.4504 - mse: 3.0790e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1847 - bpp: 0.4659 - mse: 3.5097e-04\n",
      "Epoch 382: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1847 - bpp: 0.4659 - mse: 3.5097e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2096 - bpp: 0.4631 - mse: 3.6450e-04\n",
      "Epoch 383: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2096 - bpp: 0.4631 - mse: 3.6450e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1499 - bpp: 0.4606 - mse: 3.3659e-04\n",
      "Epoch 384: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1499 - bpp: 0.4606 - mse: 3.3659e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2971 - bpp: 0.4781 - mse: 3.9988e-04\n",
      "Epoch 385: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.2971 - bpp: 0.4781 - mse: 3.9988e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2137 - bpp: 0.4639 - mse: 3.6611e-04\n",
      "Epoch 386: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2137 - bpp: 0.4639 - mse: 3.6611e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1354 - bpp: 0.4594 - mse: 3.3009e-04\n",
      "Epoch 387: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1354 - bpp: 0.4594 - mse: 3.3009e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1893 - bpp: 0.4651 - mse: 3.5358e-04\n",
      "Epoch 388: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1893 - bpp: 0.4651 - mse: 3.5358e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3141 - bpp: 0.4671 - mse: 4.1362e-04\n",
      "Epoch 389: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.3141 - bpp: 0.4671 - mse: 4.1362e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2638 - bpp: 0.4742 - mse: 3.8553e-04\n",
      "Epoch 390: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.2638 - bpp: 0.4742 - mse: 3.8553e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1023 - bpp: 0.4507 - mse: 3.1820e-04\n",
      "Epoch 391: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1023 - bpp: 0.4507 - mse: 3.1820e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2402 - bpp: 0.4691 - mse: 3.7651e-04\n",
      "Epoch 392: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2402 - bpp: 0.4691 - mse: 3.7651e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1456 - bpp: 0.4518 - mse: 3.3878e-04\n",
      "Epoch 393: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1456 - bpp: 0.4518 - mse: 3.3878e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2292 - bpp: 0.4648 - mse: 3.7322e-04\n",
      "Epoch 394: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2292 - bpp: 0.4648 - mse: 3.7322e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0382 - bpp: 0.4427 - mse: 2.9079e-04\n",
      "Epoch 395: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.0382 - bpp: 0.4427 - mse: 2.9079e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1172 - bpp: 0.4572 - mse: 3.2227e-04\n",
      "Epoch 396: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1172 - bpp: 0.4572 - mse: 3.2227e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2452 - bpp: 0.4723 - mse: 3.7738e-04\n",
      "Epoch 397: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2452 - bpp: 0.4723 - mse: 3.7738e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2765 - bpp: 0.4776 - mse: 3.9010e-04\n",
      "Epoch 398: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.2765 - bpp: 0.4776 - mse: 3.9010e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1286 - bpp: 0.4538 - mse: 3.2950e-04\n",
      "Epoch 399: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.1286 - bpp: 0.4538 - mse: 3.2950e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1882 - bpp: 0.4666 - mse: 3.5234e-04\n",
      "Epoch 400: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1882 - bpp: 0.4666 - mse: 3.5234e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1511 - bpp: 0.4575 - mse: 3.3869e-04\n",
      "Epoch 401: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1511 - bpp: 0.4575 - mse: 3.3869e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1821 - bpp: 0.4655 - mse: 3.4987e-04\n",
      "Epoch 402: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1821 - bpp: 0.4655 - mse: 3.4987e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1335 - bpp: 0.4555 - mse: 3.3109e-04\n",
      "Epoch 403: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1335 - bpp: 0.4555 - mse: 3.3109e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2851 - bpp: 0.4755 - mse: 3.9528e-04\n",
      "Epoch 404: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2851 - bpp: 0.4755 - mse: 3.9528e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1503 - bpp: 0.4635 - mse: 3.3536e-04\n",
      "Epoch 405: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1503 - bpp: 0.4635 - mse: 3.3536e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0553 - bpp: 0.4449 - mse: 2.9802e-04\n",
      "Epoch 406: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0553 - bpp: 0.4449 - mse: 2.9802e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3900 - bpp: 0.4684 - mse: 4.5001e-04\n",
      "Epoch 407: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.3900 - bpp: 0.4684 - mse: 4.5001e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2679 - bpp: 0.4734 - mse: 3.8794e-04\n",
      "Epoch 408: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2679 - bpp: 0.4734 - mse: 3.8794e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1672 - bpp: 0.4550 - mse: 3.4780e-04\n",
      "Epoch 409: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 184ms/step - loss: 1.1672 - bpp: 0.4550 - mse: 3.4780e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1239 - bpp: 0.4609 - mse: 3.2372e-04\n",
      "Epoch 410: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1239 - bpp: 0.4609 - mse: 3.2372e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0837 - bpp: 0.4454 - mse: 3.1167e-04\n",
      "Epoch 411: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0837 - bpp: 0.4454 - mse: 3.1167e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2004 - bpp: 0.4705 - mse: 3.5642e-04\n",
      "Epoch 412: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.2004 - bpp: 0.4705 - mse: 3.5642e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1617 - bpp: 0.4596 - mse: 3.4281e-04\n",
      "Epoch 413: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1617 - bpp: 0.4596 - mse: 3.4281e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1397 - bpp: 0.4664 - mse: 3.2877e-04\n",
      "Epoch 414: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1397 - bpp: 0.4664 - mse: 3.2877e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1590 - bpp: 0.4637 - mse: 3.3949e-04\n",
      "Epoch 415: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1590 - bpp: 0.4637 - mse: 3.3949e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1581 - bpp: 0.4409 - mse: 3.5022e-04\n",
      "Epoch 416: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1581 - bpp: 0.4409 - mse: 3.5022e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1631 - bpp: 0.4512 - mse: 3.4758e-04\n",
      "Epoch 417: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.1631 - bpp: 0.4512 - mse: 3.4758e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2552 - bpp: 0.4754 - mse: 3.8078e-04\n",
      "Epoch 418: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2552 - bpp: 0.4754 - mse: 3.8078e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2624 - bpp: 0.4759 - mse: 3.8403e-04\n",
      "Epoch 419: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.2624 - bpp: 0.4759 - mse: 3.8403e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2614 - bpp: 0.4774 - mse: 3.8281e-04\n",
      "Epoch 420: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2614 - bpp: 0.4774 - mse: 3.8281e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0853 - bpp: 0.4559 - mse: 3.0735e-04\n",
      "Epoch 421: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.0853 - bpp: 0.4559 - mse: 3.0735e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1512 - bpp: 0.4577 - mse: 3.3859e-04\n",
      "Epoch 422: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1512 - bpp: 0.4577 - mse: 3.3859e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2317 - bpp: 0.4635 - mse: 3.7511e-04\n",
      "Epoch 423: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2317 - bpp: 0.4635 - mse: 3.7511e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1193 - bpp: 0.4486 - mse: 3.2752e-04\n",
      "Epoch 424: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1193 - bpp: 0.4486 - mse: 3.2752e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1085 - bpp: 0.4539 - mse: 3.1964e-04\n",
      "Epoch 425: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1085 - bpp: 0.4539 - mse: 3.1964e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1833 - bpp: 0.4587 - mse: 3.5380e-04\n",
      "Epoch 426: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1833 - bpp: 0.4587 - mse: 3.5380e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1330 - bpp: 0.4631 - mse: 3.2712e-04\n",
      "Epoch 427: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1330 - bpp: 0.4631 - mse: 3.2712e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1403 - bpp: 0.4525 - mse: 3.3582e-04\n",
      "Epoch 428: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1403 - bpp: 0.4525 - mse: 3.3582e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1765 - bpp: 0.4518 - mse: 3.5388e-04\n",
      "Epoch 429: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1765 - bpp: 0.4518 - mse: 3.5388e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1829 - bpp: 0.4591 - mse: 3.5341e-04\n",
      "Epoch 430: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1829 - bpp: 0.4591 - mse: 3.5341e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1026 - bpp: 0.4500 - mse: 3.1865e-04\n",
      "Epoch 431: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1026 - bpp: 0.4500 - mse: 3.1865e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2211 - bpp: 0.4684 - mse: 3.6755e-04\n",
      "Epoch 432: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.2211 - bpp: 0.4684 - mse: 3.6755e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1035 - bpp: 0.4476 - mse: 3.2025e-04\n",
      "Epoch 433: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1035 - bpp: 0.4476 - mse: 3.2025e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0912 - bpp: 0.4457 - mse: 3.1518e-04\n",
      "Epoch 434: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0912 - bpp: 0.4457 - mse: 3.1518e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1502 - bpp: 0.4556 - mse: 3.3915e-04\n",
      "Epoch 435: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1502 - bpp: 0.4556 - mse: 3.3915e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2078 - bpp: 0.4675 - mse: 3.6149e-04\n",
      "Epoch 436: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2078 - bpp: 0.4675 - mse: 3.6149e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3404 - bpp: 0.4744 - mse: 4.2283e-04\n",
      "Epoch 437: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.3404 - bpp: 0.4744 - mse: 4.2283e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2511 - bpp: 0.4714 - mse: 3.8073e-04\n",
      "Epoch 438: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2511 - bpp: 0.4714 - mse: 3.8073e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0974 - bpp: 0.4476 - mse: 3.1728e-04\n",
      "Epoch 439: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0974 - bpp: 0.4476 - mse: 3.1728e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1039 - bpp: 0.4538 - mse: 3.1746e-04\n",
      "Epoch 440: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1039 - bpp: 0.4538 - mse: 3.1746e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2014 - bpp: 0.4643 - mse: 3.5989e-04\n",
      "Epoch 441: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.2014 - bpp: 0.4643 - mse: 3.5989e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.4692 - mse: 3.5303e-04\n",
      "Epoch 442: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1922 - bpp: 0.4692 - mse: 3.5303e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1458 - bpp: 0.4508 - mse: 3.3939e-04\n",
      "Epoch 443: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1458 - bpp: 0.4508 - mse: 3.3939e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2499 - bpp: 0.4647 - mse: 3.8342e-04\n",
      "Epoch 444: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2499 - bpp: 0.4647 - mse: 3.8342e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0931 - bpp: 0.4492 - mse: 3.1438e-04\n",
      "Epoch 445: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0931 - bpp: 0.4492 - mse: 3.1438e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1380 - bpp: 0.4503 - mse: 3.3580e-04\n",
      "Epoch 446: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1380 - bpp: 0.4503 - mse: 3.3580e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1046 - bpp: 0.4559 - mse: 3.1672e-04\n",
      "Epoch 447: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1046 - bpp: 0.4559 - mse: 3.1672e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2178 - bpp: 0.4731 - mse: 3.6361e-04\n",
      "Epoch 448: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2178 - bpp: 0.4731 - mse: 3.6361e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1212 - bpp: 0.4561 - mse: 3.2474e-04\n",
      "Epoch 449: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1212 - bpp: 0.4561 - mse: 3.2474e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1844 - bpp: 0.4674 - mse: 3.5008e-04\n",
      "Epoch 450: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.1844 - bpp: 0.4674 - mse: 3.5008e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0950 - bpp: 0.4522 - mse: 3.1387e-04\n",
      "Epoch 451: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0950 - bpp: 0.4522 - mse: 3.1387e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1131 - bpp: 0.4568 - mse: 3.2044e-04\n",
      "Epoch 452: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1131 - bpp: 0.4568 - mse: 3.2044e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1916 - bpp: 0.4587 - mse: 3.5785e-04\n",
      "Epoch 453: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1916 - bpp: 0.4587 - mse: 3.5785e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1385 - bpp: 0.4554 - mse: 3.3356e-04\n",
      "Epoch 454: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1385 - bpp: 0.4554 - mse: 3.3356e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.4492 - mse: 2.9584e-04\n",
      "Epoch 455: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.0551 - bpp: 0.4492 - mse: 2.9584e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1242 - bpp: 0.4475 - mse: 3.3042e-04\n",
      "Epoch 456: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1242 - bpp: 0.4475 - mse: 3.3042e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1357 - bpp: 0.4603 - mse: 3.2977e-04\n",
      "Epoch 457: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1357 - bpp: 0.4603 - mse: 3.2977e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2459 - bpp: 0.4682 - mse: 3.7976e-04\n",
      "Epoch 458: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.2459 - bpp: 0.4682 - mse: 3.7976e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0808 - bpp: 0.4492 - mse: 3.0840e-04\n",
      "Epoch 459: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.0808 - bpp: 0.4492 - mse: 3.0840e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1647 - bpp: 0.4603 - mse: 3.4395e-04\n",
      "Epoch 460: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1647 - bpp: 0.4603 - mse: 3.4395e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0312 - bpp: 0.4434 - mse: 2.8702e-04\n",
      "Epoch 461: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0312 - bpp: 0.4434 - mse: 2.8702e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0518 - bpp: 0.4432 - mse: 2.9713e-04\n",
      "Epoch 462: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0518 - bpp: 0.4432 - mse: 2.9713e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2380 - bpp: 0.4586 - mse: 3.8059e-04\n",
      "Epoch 463: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.2380 - bpp: 0.4586 - mse: 3.8059e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1181 - bpp: 0.4454 - mse: 3.2851e-04\n",
      "Epoch 464: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1181 - bpp: 0.4454 - mse: 3.2851e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1708 - bpp: 0.4572 - mse: 3.4844e-04\n",
      "Epoch 465: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1708 - bpp: 0.4572 - mse: 3.4844e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0487 - bpp: 0.4499 - mse: 2.9239e-04\n",
      "Epoch 466: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0487 - bpp: 0.4499 - mse: 2.9239e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1697 - bpp: 0.4571 - mse: 3.4792e-04\n",
      "Epoch 467: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.1697 - bpp: 0.4571 - mse: 3.4792e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1987 - bpp: 0.4640 - mse: 3.5870e-04\n",
      "Epoch 468: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1987 - bpp: 0.4640 - mse: 3.5870e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0347 - bpp: 0.4431 - mse: 2.8889e-04\n",
      "Epoch 469: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0347 - bpp: 0.4431 - mse: 2.8889e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2329 - bpp: 0.4631 - mse: 3.7585e-04\n",
      "Epoch 470: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.2329 - bpp: 0.4631 - mse: 3.7585e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1499 - bpp: 0.4597 - mse: 3.3701e-04\n",
      "Epoch 471: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1499 - bpp: 0.4597 - mse: 3.3701e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0171 - bpp: 0.4389 - mse: 2.8231e-04\n",
      "Epoch 472: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0171 - bpp: 0.4389 - mse: 2.8231e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1877 - bpp: 0.4567 - mse: 3.5696e-04\n",
      "Epoch 473: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1877 - bpp: 0.4567 - mse: 3.5696e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1014 - bpp: 0.4449 - mse: 3.2054e-04\n",
      "Epoch 474: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1014 - bpp: 0.4449 - mse: 3.2054e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2211 - bpp: 0.4650 - mse: 3.6920e-04\n",
      "Epoch 475: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.2211 - bpp: 0.4650 - mse: 3.6920e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2578 - bpp: 0.4581 - mse: 3.9048e-04\n",
      "Epoch 476: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2578 - bpp: 0.4581 - mse: 3.9048e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1264 - bpp: 0.4574 - mse: 3.2665e-04\n",
      "Epoch 477: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1264 - bpp: 0.4574 - mse: 3.2665e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1051 - bpp: 0.4505 - mse: 3.1964e-04\n",
      "Epoch 478: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1051 - bpp: 0.4505 - mse: 3.1964e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2370 - bpp: 0.4632 - mse: 3.7783e-04\n",
      "Epoch 479: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 184ms/step - loss: 1.2370 - bpp: 0.4632 - mse: 3.7783e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1190 - bpp: 0.4488 - mse: 3.2722e-04\n",
      "Epoch 480: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1190 - bpp: 0.4488 - mse: 3.2722e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.4433 - mse: 2.9742e-04\n",
      "Epoch 481: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0524 - bpp: 0.4433 - mse: 2.9742e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0759 - bpp: 0.4491 - mse: 3.0604e-04\n",
      "Epoch 482: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0759 - bpp: 0.4491 - mse: 3.0604e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1545 - bpp: 0.4568 - mse: 3.4066e-04\n",
      "Epoch 483: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1545 - bpp: 0.4568 - mse: 3.4066e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1920 - bpp: 0.4589 - mse: 3.5798e-04\n",
      "Epoch 484: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1920 - bpp: 0.4589 - mse: 3.5798e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1284 - bpp: 0.4494 - mse: 3.3154e-04\n",
      "Epoch 485: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.1284 - bpp: 0.4494 - mse: 3.3154e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1399 - bpp: 0.4578 - mse: 3.3307e-04\n",
      "Epoch 486: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1399 - bpp: 0.4578 - mse: 3.3307e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1277 - bpp: 0.4554 - mse: 3.2828e-04\n",
      "Epoch 487: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1277 - bpp: 0.4554 - mse: 3.2828e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0595 - bpp: 0.4396 - mse: 3.0268e-04\n",
      "Epoch 488: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0595 - bpp: 0.4396 - mse: 3.0268e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1643 - bpp: 0.4552 - mse: 3.4625e-04\n",
      "Epoch 489: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 1.1643 - bpp: 0.4552 - mse: 3.4625e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1335 - bpp: 0.4468 - mse: 3.3528e-04\n",
      "Epoch 490: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1335 - bpp: 0.4468 - mse: 3.3528e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2140 - bpp: 0.4666 - mse: 3.6496e-04\n",
      "Epoch 491: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2140 - bpp: 0.4666 - mse: 3.6496e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0204 - bpp: 0.4406 - mse: 2.8310e-04\n",
      "Epoch 492: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0204 - bpp: 0.4406 - mse: 2.8310e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1455 - bpp: 0.4521 - mse: 3.3856e-04\n",
      "Epoch 493: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.1455 - bpp: 0.4521 - mse: 3.3856e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1377 - bpp: 0.4491 - mse: 3.3625e-04\n",
      "Epoch 494: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1377 - bpp: 0.4491 - mse: 3.3625e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2237 - bpp: 0.4666 - mse: 3.6968e-04\n",
      "Epoch 495: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2237 - bpp: 0.4666 - mse: 3.6968e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1168 - bpp: 0.4511 - mse: 3.2505e-04\n",
      "Epoch 496: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1168 - bpp: 0.4511 - mse: 3.2505e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1503 - bpp: 0.4516 - mse: 3.4121e-04\n",
      "Epoch 497: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.1503 - bpp: 0.4516 - mse: 3.4121e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1607 - bpp: 0.4542 - mse: 3.4498e-04\n",
      "Epoch 498: loss did not improve from 1.00198\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1607 - bpp: 0.4542 - mse: 3.4498e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9811 - bpp: 0.4264 - mse: 2.7082e-04\n",
      "Epoch 499: loss improved from 1.00198 to 0.98106, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9811 - bpp: 0.4264 - mse: 2.7082e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2394 - bpp: 0.4658 - mse: 3.7773e-04\n",
      "Epoch 500: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.2394 - bpp: 0.4658 - mse: 3.7773e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1813 - bpp: 0.4518 - mse: 3.5620e-04\n",
      "Epoch 501: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.1813 - bpp: 0.4518 - mse: 3.5620e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1292 - bpp: 0.4498 - mse: 3.3172e-04\n",
      "Epoch 502: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1292 - bpp: 0.4498 - mse: 3.3172e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1767 - bpp: 0.4560 - mse: 3.5192e-04\n",
      "Epoch 503: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.1767 - bpp: 0.4560 - mse: 3.5192e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1910 - bpp: 0.4599 - mse: 3.5699e-04\n",
      "Epoch 504: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1910 - bpp: 0.4599 - mse: 3.5699e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0842 - bpp: 0.4461 - mse: 3.1157e-04\n",
      "Epoch 505: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0842 - bpp: 0.4461 - mse: 3.1157e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0616 - bpp: 0.4486 - mse: 2.9934e-04\n",
      "Epoch 506: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0616 - bpp: 0.4486 - mse: 2.9934e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2712 - bpp: 0.4587 - mse: 3.9672e-04\n",
      "Epoch 507: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.2712 - bpp: 0.4587 - mse: 3.9672e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1804 - bpp: 0.4634 - mse: 3.5008e-04\n",
      "Epoch 508: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1804 - bpp: 0.4634 - mse: 3.5008e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0698 - bpp: 0.4493 - mse: 3.0299e-04\n",
      "Epoch 509: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0698 - bpp: 0.4493 - mse: 3.0299e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1647 - bpp: 0.4601 - mse: 3.4402e-04\n",
      "Epoch 510: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1647 - bpp: 0.4601 - mse: 3.4402e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0699 - bpp: 0.4450 - mse: 3.0512e-04\n",
      "Epoch 511: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.0699 - bpp: 0.4450 - mse: 3.0512e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2021 - bpp: 0.4589 - mse: 3.6290e-04\n",
      "Epoch 512: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.2021 - bpp: 0.4589 - mse: 3.6290e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0792 - bpp: 0.4490 - mse: 3.0773e-04\n",
      "Epoch 513: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0792 - bpp: 0.4490 - mse: 3.0773e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1005 - bpp: 0.4438 - mse: 3.2065e-04\n",
      "Epoch 514: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1005 - bpp: 0.4438 - mse: 3.2065e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1633 - bpp: 0.4523 - mse: 3.4718e-04\n",
      "Epoch 515: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1633 - bpp: 0.4523 - mse: 3.4718e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1247 - bpp: 0.4490 - mse: 3.2993e-04\n",
      "Epoch 516: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1247 - bpp: 0.4490 - mse: 3.2993e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0918 - bpp: 0.4519 - mse: 3.1247e-04\n",
      "Epoch 517: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0918 - bpp: 0.4519 - mse: 3.1247e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1039 - bpp: 0.4516 - mse: 3.1849e-04\n",
      "Epoch 518: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1039 - bpp: 0.4516 - mse: 3.1849e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0393 - bpp: 0.4446 - mse: 2.9035e-04\n",
      "Epoch 519: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0393 - bpp: 0.4446 - mse: 2.9035e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0890 - bpp: 0.4495 - mse: 3.1228e-04\n",
      "Epoch 520: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0890 - bpp: 0.4495 - mse: 3.1228e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0412 - bpp: 0.4450 - mse: 2.9111e-04\n",
      "Epoch 521: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0412 - bpp: 0.4450 - mse: 2.9111e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0777 - bpp: 0.4462 - mse: 3.0836e-04\n",
      "Epoch 522: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0777 - bpp: 0.4462 - mse: 3.0836e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1923 - bpp: 0.4476 - mse: 3.6364e-04\n",
      "Epoch 523: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1923 - bpp: 0.4476 - mse: 3.6364e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2209 - bpp: 0.4626 - mse: 3.7027e-04\n",
      "Epoch 524: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2209 - bpp: 0.4626 - mse: 3.7027e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1053 - bpp: 0.4435 - mse: 3.2314e-04\n",
      "Epoch 525: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1053 - bpp: 0.4435 - mse: 3.2314e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1040 - bpp: 0.4472 - mse: 3.2067e-04\n",
      "Epoch 526: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1040 - bpp: 0.4472 - mse: 3.2067e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1159 - bpp: 0.4556 - mse: 3.2243e-04\n",
      "Epoch 527: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.1159 - bpp: 0.4556 - mse: 3.2243e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0941 - bpp: 0.4572 - mse: 3.1099e-04\n",
      "Epoch 528: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0941 - bpp: 0.4572 - mse: 3.1099e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0795 - bpp: 0.4488 - mse: 3.0796e-04\n",
      "Epoch 529: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.0795 - bpp: 0.4488 - mse: 3.0796e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0799 - bpp: 0.4431 - mse: 3.1092e-04\n",
      "Epoch 530: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0799 - bpp: 0.4431 - mse: 3.1092e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1021 - bpp: 0.4515 - mse: 3.1767e-04\n",
      "Epoch 531: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1021 - bpp: 0.4515 - mse: 3.1767e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0611 - bpp: 0.4471 - mse: 2.9979e-04\n",
      "Epoch 532: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0611 - bpp: 0.4471 - mse: 2.9979e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0203 - bpp: 0.4400 - mse: 2.8336e-04\n",
      "Epoch 533: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.0203 - bpp: 0.4400 - mse: 2.8336e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1609 - bpp: 0.4480 - mse: 3.4810e-04\n",
      "Epoch 534: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1609 - bpp: 0.4480 - mse: 3.4810e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1716 - bpp: 0.4490 - mse: 3.5283e-04\n",
      "Epoch 535: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.1716 - bpp: 0.4490 - mse: 3.5283e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.4430 - mse: 3.1207e-04\n",
      "Epoch 536: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0821 - bpp: 0.4430 - mse: 3.1207e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1329 - bpp: 0.4467 - mse: 3.3509e-04\n",
      "Epoch 537: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1329 - bpp: 0.4467 - mse: 3.3509e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1333 - bpp: 0.4508 - mse: 3.3322e-04\n",
      "Epoch 538: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1333 - bpp: 0.4508 - mse: 3.3322e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0994 - bpp: 0.4459 - mse: 3.1906e-04\n",
      "Epoch 539: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.0994 - bpp: 0.4459 - mse: 3.1906e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1161 - bpp: 0.4604 - mse: 3.2016e-04\n",
      "Epoch 540: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1161 - bpp: 0.4604 - mse: 3.2016e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1292 - bpp: 0.4482 - mse: 3.3253e-04\n",
      "Epoch 541: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1292 - bpp: 0.4482 - mse: 3.3253e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0917 - bpp: 0.4492 - mse: 3.1373e-04\n",
      "Epoch 542: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0917 - bpp: 0.4492 - mse: 3.1373e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1004 - bpp: 0.4458 - mse: 3.1961e-04\n",
      "Epoch 543: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1004 - bpp: 0.4458 - mse: 3.1961e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0708 - bpp: 0.4477 - mse: 3.0423e-04\n",
      "Epoch 544: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.0708 - bpp: 0.4477 - mse: 3.0423e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0987 - bpp: 0.4460 - mse: 3.1871e-04\n",
      "Epoch 545: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0987 - bpp: 0.4460 - mse: 3.1871e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2607 - bpp: 0.4680 - mse: 3.8707e-04\n",
      "Epoch 546: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2607 - bpp: 0.4680 - mse: 3.8707e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0226 - bpp: 0.4379 - mse: 2.8551e-04\n",
      "Epoch 547: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0226 - bpp: 0.4379 - mse: 2.8551e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0590 - bpp: 0.4383 - mse: 3.0306e-04\n",
      "Epoch 548: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0590 - bpp: 0.4383 - mse: 3.0306e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2411 - bpp: 0.4586 - mse: 3.8207e-04\n",
      "Epoch 549: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2411 - bpp: 0.4586 - mse: 3.8207e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1985 - bpp: 0.4602 - mse: 3.6049e-04\n",
      "Epoch 550: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1985 - bpp: 0.4602 - mse: 3.6049e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0762 - bpp: 0.4468 - mse: 3.0731e-04\n",
      "Epoch 551: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0762 - bpp: 0.4468 - mse: 3.0731e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0963 - bpp: 0.4528 - mse: 3.1420e-04\n",
      "Epoch 552: loss did not improve from 0.98106\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.0963 - bpp: 0.4528 - mse: 3.1420e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9661 - bpp: 0.4317 - mse: 2.6093e-04\n",
      "Epoch 553: loss improved from 0.98106 to 0.96609, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9661 - bpp: 0.4317 - mse: 2.6093e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1590 - bpp: 0.4577 - mse: 3.4244e-04\n",
      "Epoch 554: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1590 - bpp: 0.4577 - mse: 3.4244e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0635 - bpp: 0.4448 - mse: 3.0210e-04\n",
      "Epoch 555: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.0635 - bpp: 0.4448 - mse: 3.0210e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0521 - bpp: 0.4480 - mse: 2.9496e-04\n",
      "Epoch 556: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0521 - bpp: 0.4480 - mse: 2.9496e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0608 - bpp: 0.4436 - mse: 3.0139e-04\n",
      "Epoch 557: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0608 - bpp: 0.4436 - mse: 3.0139e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1450 - bpp: 0.4530 - mse: 3.3791e-04\n",
      "Epoch 558: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1450 - bpp: 0.4530 - mse: 3.3791e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1354 - bpp: 0.4555 - mse: 3.3199e-04\n",
      "Epoch 559: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.1354 - bpp: 0.4555 - mse: 3.3199e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1243 - bpp: 0.4491 - mse: 3.2970e-04\n",
      "Epoch 560: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1243 - bpp: 0.4491 - mse: 3.2970e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1615 - bpp: 0.4546 - mse: 3.4520e-04\n",
      "Epoch 561: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.1615 - bpp: 0.4546 - mse: 3.4520e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0719 - bpp: 0.4407 - mse: 3.0820e-04\n",
      "Epoch 562: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0719 - bpp: 0.4407 - mse: 3.0820e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0150 - bpp: 0.4379 - mse: 2.8178e-04\n",
      "Epoch 563: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.0150 - bpp: 0.4379 - mse: 2.8178e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0177 - bpp: 0.4397 - mse: 2.8224e-04\n",
      "Epoch 564: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0177 - bpp: 0.4397 - mse: 2.8224e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1187 - bpp: 0.4473 - mse: 3.2785e-04\n",
      "Epoch 565: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.1187 - bpp: 0.4473 - mse: 3.2785e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0967 - bpp: 0.4448 - mse: 3.1831e-04\n",
      "Epoch 566: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0967 - bpp: 0.4448 - mse: 3.1831e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1553 - bpp: 0.4555 - mse: 3.4168e-04\n",
      "Epoch 567: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.1553 - bpp: 0.4555 - mse: 3.4168e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1717 - bpp: 0.4586 - mse: 3.4822e-04\n",
      "Epoch 568: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1717 - bpp: 0.4586 - mse: 3.4822e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0659 - bpp: 0.4434 - mse: 3.0392e-04\n",
      "Epoch 569: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0659 - bpp: 0.4434 - mse: 3.0392e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0366 - bpp: 0.4334 - mse: 2.9451e-04\n",
      "Epoch 570: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.0366 - bpp: 0.4334 - mse: 2.9451e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0737 - bpp: 0.4430 - mse: 3.0795e-04\n",
      "Epoch 571: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.0737 - bpp: 0.4430 - mse: 3.0795e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1553 - bpp: 0.4487 - mse: 3.4503e-04\n",
      "Epoch 572: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1553 - bpp: 0.4487 - mse: 3.4503e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1775 - bpp: 0.4624 - mse: 3.4917e-04\n",
      "Epoch 573: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1775 - bpp: 0.4624 - mse: 3.4917e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0947 - bpp: 0.4440 - mse: 3.1770e-04\n",
      "Epoch 574: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.0947 - bpp: 0.4440 - mse: 3.1770e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1750 - bpp: 0.4528 - mse: 3.5262e-04\n",
      "Epoch 575: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1750 - bpp: 0.4528 - mse: 3.5262e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1824 - bpp: 0.4545 - mse: 3.5541e-04\n",
      "Epoch 576: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1824 - bpp: 0.4545 - mse: 3.5541e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1035 - bpp: 0.4523 - mse: 3.1797e-04\n",
      "Epoch 577: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1035 - bpp: 0.4523 - mse: 3.1797e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1499 - bpp: 0.4564 - mse: 3.3864e-04\n",
      "Epoch 578: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1499 - bpp: 0.4564 - mse: 3.3864e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0926 - bpp: 0.4450 - mse: 3.1620e-04\n",
      "Epoch 579: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0926 - bpp: 0.4450 - mse: 3.1620e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1073 - bpp: 0.4535 - mse: 3.1922e-04\n",
      "Epoch 580: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1073 - bpp: 0.4535 - mse: 3.1922e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9714 - bpp: 0.4293 - mse: 2.6470e-04\n",
      "Epoch 581: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.9714 - bpp: 0.4293 - mse: 2.6470e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0195 - bpp: 0.4363 - mse: 2.8477e-04\n",
      "Epoch 582: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0195 - bpp: 0.4363 - mse: 2.8477e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0127 - bpp: 0.4386 - mse: 2.8033e-04\n",
      "Epoch 583: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0127 - bpp: 0.4386 - mse: 2.8033e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1303 - bpp: 0.4432 - mse: 3.3550e-04\n",
      "Epoch 584: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1303 - bpp: 0.4432 - mse: 3.3550e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0717 - bpp: 0.4468 - mse: 3.0510e-04\n",
      "Epoch 585: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0717 - bpp: 0.4468 - mse: 3.0510e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1471 - bpp: 0.4515 - mse: 3.3963e-04\n",
      "Epoch 586: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1471 - bpp: 0.4515 - mse: 3.3963e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0190 - bpp: 0.4297 - mse: 2.8771e-04\n",
      "Epoch 587: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0190 - bpp: 0.4297 - mse: 2.8771e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1652 - bpp: 0.4456 - mse: 3.5133e-04\n",
      "Epoch 588: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1652 - bpp: 0.4456 - mse: 3.5133e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1710 - bpp: 0.4528 - mse: 3.5065e-04\n",
      "Epoch 589: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1710 - bpp: 0.4528 - mse: 3.5065e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1412 - bpp: 0.4569 - mse: 3.3414e-04\n",
      "Epoch 590: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1412 - bpp: 0.4569 - mse: 3.3414e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1075 - bpp: 0.4557 - mse: 3.1823e-04\n",
      "Epoch 591: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1075 - bpp: 0.4557 - mse: 3.1823e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0536 - bpp: 0.4388 - mse: 3.0020e-04\n",
      "Epoch 592: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 187ms/step - loss: 1.0536 - bpp: 0.4388 - mse: 3.0020e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1892 - bpp: 0.4645 - mse: 3.5386e-04\n",
      "Epoch 593: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1892 - bpp: 0.4645 - mse: 3.5386e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1222 - bpp: 0.4492 - mse: 3.2860e-04\n",
      "Epoch 594: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1222 - bpp: 0.4492 - mse: 3.2860e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0747 - bpp: 0.4453 - mse: 3.0732e-04\n",
      "Epoch 595: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0747 - bpp: 0.4453 - mse: 3.0732e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1779 - bpp: 0.4607 - mse: 3.5016e-04\n",
      "Epoch 596: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1779 - bpp: 0.4607 - mse: 3.5016e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1285 - bpp: 0.4665 - mse: 3.2324e-04\n",
      "Epoch 597: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1285 - bpp: 0.4665 - mse: 3.2324e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2015 - bpp: 0.4650 - mse: 3.5962e-04\n",
      "Epoch 598: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.2015 - bpp: 0.4650 - mse: 3.5962e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.4491 - mse: 3.1196e-04\n",
      "Epoch 599: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0879 - bpp: 0.4491 - mse: 3.1196e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0513 - bpp: 0.4370 - mse: 2.9997e-04\n",
      "Epoch 600: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.0513 - bpp: 0.4370 - mse: 2.9997e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0530 - bpp: 0.4509 - mse: 2.9397e-04\n",
      "Epoch 601: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0530 - bpp: 0.4509 - mse: 2.9397e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0801 - bpp: 0.4528 - mse: 3.0627e-04\n",
      "Epoch 602: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0801 - bpp: 0.4528 - mse: 3.0627e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1583 - bpp: 0.4551 - mse: 3.4337e-04\n",
      "Epoch 603: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.1583 - bpp: 0.4551 - mse: 3.4337e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0501 - bpp: 0.4393 - mse: 2.9827e-04\n",
      "Epoch 604: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0501 - bpp: 0.4393 - mse: 2.9827e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0078 - bpp: 0.4387 - mse: 2.7789e-04\n",
      "Epoch 605: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0078 - bpp: 0.4387 - mse: 2.7789e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.4640 - mse: 3.5776e-04\n",
      "Epoch 606: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1967 - bpp: 0.4640 - mse: 3.5776e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0470 - bpp: 0.4397 - mse: 2.9655e-04\n",
      "Epoch 607: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0470 - bpp: 0.4397 - mse: 2.9655e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1205 - bpp: 0.4527 - mse: 3.2604e-04\n",
      "Epoch 608: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1205 - bpp: 0.4527 - mse: 3.2604e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9951 - bpp: 0.4354 - mse: 2.7329e-04\n",
      "Epoch 609: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 0.9951 - bpp: 0.4354 - mse: 2.7329e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0723 - bpp: 0.4433 - mse: 3.0713e-04\n",
      "Epoch 610: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0723 - bpp: 0.4433 - mse: 3.0713e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1355 - bpp: 0.4570 - mse: 3.3129e-04\n",
      "Epoch 611: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1355 - bpp: 0.4570 - mse: 3.3129e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0553 - bpp: 0.4501 - mse: 2.9551e-04\n",
      "Epoch 612: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0553 - bpp: 0.4501 - mse: 2.9551e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0735 - bpp: 0.4466 - mse: 3.0609e-04\n",
      "Epoch 613: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0735 - bpp: 0.4466 - mse: 3.0609e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9873 - bpp: 0.4331 - mse: 2.7058e-04\n",
      "Epoch 614: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 0.9873 - bpp: 0.4331 - mse: 2.7058e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0883 - bpp: 0.4423 - mse: 3.1542e-04\n",
      "Epoch 615: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.0883 - bpp: 0.4423 - mse: 3.1542e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1405 - bpp: 0.4567 - mse: 3.3390e-04\n",
      "Epoch 616: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1405 - bpp: 0.4567 - mse: 3.3390e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1915 - bpp: 0.4599 - mse: 3.5725e-04\n",
      "Epoch 617: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1915 - bpp: 0.4599 - mse: 3.5725e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2139 - bpp: 0.4594 - mse: 3.6842e-04\n",
      "Epoch 618: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2139 - bpp: 0.4594 - mse: 3.6842e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0686 - bpp: 0.4493 - mse: 3.0240e-04\n",
      "Epoch 619: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0686 - bpp: 0.4493 - mse: 3.0240e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0310 - bpp: 0.4378 - mse: 2.8962e-04\n",
      "Epoch 620: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0310 - bpp: 0.4378 - mse: 2.8962e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1206 - bpp: 0.4471 - mse: 3.2883e-04\n",
      "Epoch 621: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1206 - bpp: 0.4471 - mse: 3.2883e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0657 - bpp: 0.4437 - mse: 3.0372e-04\n",
      "Epoch 622: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0657 - bpp: 0.4437 - mse: 3.0372e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2294 - bpp: 0.4622 - mse: 3.7460e-04\n",
      "Epoch 623: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2294 - bpp: 0.4622 - mse: 3.7460e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1145 - bpp: 0.4483 - mse: 3.2532e-04\n",
      "Epoch 624: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1145 - bpp: 0.4483 - mse: 3.2532e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.4435 - mse: 3.1183e-04\n",
      "Epoch 625: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0821 - bpp: 0.4435 - mse: 3.1183e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9744 - bpp: 0.4290 - mse: 2.6630e-04\n",
      "Epoch 626: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9744 - bpp: 0.4290 - mse: 2.6630e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1373 - bpp: 0.4481 - mse: 3.3649e-04\n",
      "Epoch 627: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1373 - bpp: 0.4481 - mse: 3.3649e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1789 - bpp: 0.4647 - mse: 3.4872e-04\n",
      "Epoch 628: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.1789 - bpp: 0.4647 - mse: 3.4872e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1018 - bpp: 0.4398 - mse: 3.2327e-04\n",
      "Epoch 629: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1018 - bpp: 0.4398 - mse: 3.2327e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0584 - bpp: 0.4450 - mse: 2.9952e-04\n",
      "Epoch 630: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0584 - bpp: 0.4450 - mse: 2.9952e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1729 - bpp: 0.4573 - mse: 3.4946e-04\n",
      "Epoch 631: loss did not improve from 0.96609\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1729 - bpp: 0.4573 - mse: 3.4946e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9472 - bpp: 0.4260 - mse: 2.5447e-04\n",
      "Epoch 632: loss improved from 0.96609 to 0.94717, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9472 - bpp: 0.4260 - mse: 2.5447e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0169 - bpp: 0.4408 - mse: 2.8132e-04\n",
      "Epoch 633: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0169 - bpp: 0.4408 - mse: 2.8132e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0281 - bpp: 0.4401 - mse: 2.8709e-04\n",
      "Epoch 634: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0281 - bpp: 0.4401 - mse: 2.8709e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0874 - bpp: 0.4499 - mse: 3.1128e-04\n",
      "Epoch 635: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0874 - bpp: 0.4499 - mse: 3.1128e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0260 - bpp: 0.4358 - mse: 2.8821e-04\n",
      "Epoch 636: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0260 - bpp: 0.4358 - mse: 2.8821e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1958 - bpp: 0.4641 - mse: 3.5729e-04\n",
      "Epoch 637: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1958 - bpp: 0.4641 - mse: 3.5729e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0091 - bpp: 0.4344 - mse: 2.8063e-04\n",
      "Epoch 638: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0091 - bpp: 0.4344 - mse: 2.8063e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0027 - bpp: 0.4339 - mse: 2.7772e-04\n",
      "Epoch 639: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0027 - bpp: 0.4339 - mse: 2.7772e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0700 - bpp: 0.4404 - mse: 3.0743e-04\n",
      "Epoch 640: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0700 - bpp: 0.4404 - mse: 3.0743e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1742 - bpp: 0.4621 - mse: 3.4766e-04\n",
      "Epoch 641: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1742 - bpp: 0.4621 - mse: 3.4766e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1017 - bpp: 0.4481 - mse: 3.1918e-04\n",
      "Epoch 642: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1017 - bpp: 0.4481 - mse: 3.1918e-04\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1093 - bpp: 0.4498 - mse: 3.2200e-04\n",
      "Epoch 643: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1093 - bpp: 0.4498 - mse: 3.2200e-04\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1445 - bpp: 0.4398 - mse: 3.4408e-04\n",
      "Epoch 644: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1445 - bpp: 0.4398 - mse: 3.4408e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2117 - bpp: 0.4595 - mse: 3.6728e-04\n",
      "Epoch 645: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2117 - bpp: 0.4595 - mse: 3.6728e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0517 - bpp: 0.4372 - mse: 3.0008e-04\n",
      "Epoch 646: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0517 - bpp: 0.4372 - mse: 3.0008e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0618 - bpp: 0.4396 - mse: 3.0381e-04\n",
      "Epoch 647: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0618 - bpp: 0.4396 - mse: 3.0381e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0320 - bpp: 0.4441 - mse: 2.8710e-04\n",
      "Epoch 648: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0320 - bpp: 0.4441 - mse: 2.8710e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0513 - bpp: 0.4428 - mse: 2.9711e-04\n",
      "Epoch 649: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0513 - bpp: 0.4428 - mse: 2.9711e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0720 - bpp: 0.4443 - mse: 3.0647e-04\n",
      "Epoch 650: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0720 - bpp: 0.4443 - mse: 3.0647e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0999 - bpp: 0.4430 - mse: 3.2079e-04\n",
      "Epoch 651: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0999 - bpp: 0.4430 - mse: 3.2079e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0242 - bpp: 0.4451 - mse: 2.8278e-04\n",
      "Epoch 652: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0242 - bpp: 0.4451 - mse: 2.8278e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0217 - bpp: 0.4334 - mse: 2.8729e-04\n",
      "Epoch 653: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.0217 - bpp: 0.4334 - mse: 2.8729e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2606 - bpp: 0.4639 - mse: 3.8904e-04\n",
      "Epoch 654: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2606 - bpp: 0.4639 - mse: 3.8904e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0976 - bpp: 0.4519 - mse: 3.1530e-04\n",
      "Epoch 655: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0976 - bpp: 0.4519 - mse: 3.1530e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0990 - bpp: 0.4532 - mse: 3.1531e-04\n",
      "Epoch 656: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.0990 - bpp: 0.4532 - mse: 3.1531e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0014 - bpp: 0.4347 - mse: 2.7674e-04\n",
      "Epoch 657: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0014 - bpp: 0.4347 - mse: 2.7674e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0463 - bpp: 0.4325 - mse: 2.9970e-04\n",
      "Epoch 658: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0463 - bpp: 0.4325 - mse: 2.9970e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0804 - bpp: 0.4486 - mse: 3.0848e-04\n",
      "Epoch 659: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0804 - bpp: 0.4486 - mse: 3.0848e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0367 - bpp: 0.4437 - mse: 2.8956e-04\n",
      "Epoch 660: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0367 - bpp: 0.4437 - mse: 2.8956e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1178 - bpp: 0.4428 - mse: 3.2957e-04\n",
      "Epoch 661: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1178 - bpp: 0.4428 - mse: 3.2957e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1221 - bpp: 0.4533 - mse: 3.2656e-04\n",
      "Epoch 662: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1221 - bpp: 0.4533 - mse: 3.2656e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9697 - bpp: 0.4374 - mse: 2.5990e-04\n",
      "Epoch 663: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 0.9697 - bpp: 0.4374 - mse: 2.5990e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0291 - bpp: 0.4390 - mse: 2.8814e-04\n",
      "Epoch 664: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0291 - bpp: 0.4390 - mse: 2.8814e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0374 - bpp: 0.4320 - mse: 2.9560e-04\n",
      "Epoch 665: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0374 - bpp: 0.4320 - mse: 2.9560e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0886 - bpp: 0.4505 - mse: 3.1157e-04\n",
      "Epoch 666: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0886 - bpp: 0.4505 - mse: 3.1157e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1292 - bpp: 0.4512 - mse: 3.3104e-04\n",
      "Epoch 667: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1292 - bpp: 0.4512 - mse: 3.3104e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9799 - bpp: 0.4332 - mse: 2.6697e-04\n",
      "Epoch 668: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.9799 - bpp: 0.4332 - mse: 2.6697e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0926 - bpp: 0.4401 - mse: 3.1860e-04\n",
      "Epoch 669: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0926 - bpp: 0.4401 - mse: 3.1860e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0454 - bpp: 0.4430 - mse: 2.9416e-04\n",
      "Epoch 670: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0454 - bpp: 0.4430 - mse: 2.9416e-04\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1300 - bpp: 0.4498 - mse: 3.3213e-04\n",
      "Epoch 671: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1300 - bpp: 0.4498 - mse: 3.3213e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.4435 - mse: 2.9731e-04\n",
      "Epoch 672: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0524 - bpp: 0.4435 - mse: 2.9731e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1153 - bpp: 0.4588 - mse: 3.2054e-04\n",
      "Epoch 673: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1153 - bpp: 0.4588 - mse: 3.2054e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0652 - bpp: 0.4387 - mse: 3.0591e-04\n",
      "Epoch 674: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.0652 - bpp: 0.4387 - mse: 3.0591e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9910 - bpp: 0.4275 - mse: 2.7513e-04\n",
      "Epoch 675: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9910 - bpp: 0.4275 - mse: 2.7513e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1275 - bpp: 0.4464 - mse: 3.3257e-04\n",
      "Epoch 676: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1275 - bpp: 0.4464 - mse: 3.3257e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0803 - bpp: 0.4484 - mse: 3.0854e-04\n",
      "Epoch 677: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0803 - bpp: 0.4484 - mse: 3.0854e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0455 - bpp: 0.4304 - mse: 3.0036e-04\n",
      "Epoch 678: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0455 - bpp: 0.4304 - mse: 3.0036e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0449 - bpp: 0.4474 - mse: 2.9176e-04\n",
      "Epoch 679: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0449 - bpp: 0.4474 - mse: 2.9176e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0190 - bpp: 0.4393 - mse: 2.8305e-04\n",
      "Epoch 680: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0190 - bpp: 0.4393 - mse: 2.8305e-04\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1693 - bpp: 0.4572 - mse: 3.4772e-04\n",
      "Epoch 681: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1693 - bpp: 0.4572 - mse: 3.4772e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1983 - bpp: 0.4604 - mse: 3.6032e-04\n",
      "Epoch 682: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1983 - bpp: 0.4604 - mse: 3.6032e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0807 - bpp: 0.4409 - mse: 3.1240e-04\n",
      "Epoch 683: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0807 - bpp: 0.4409 - mse: 3.1240e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0330 - bpp: 0.4359 - mse: 2.9157e-04\n",
      "Epoch 684: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0330 - bpp: 0.4359 - mse: 2.9157e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0063 - bpp: 0.4359 - mse: 2.7854e-04\n",
      "Epoch 685: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0063 - bpp: 0.4359 - mse: 2.7854e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1077 - bpp: 0.4479 - mse: 3.2213e-04\n",
      "Epoch 686: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1077 - bpp: 0.4479 - mse: 3.2213e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1043 - bpp: 0.4448 - mse: 3.2202e-04\n",
      "Epoch 687: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1043 - bpp: 0.4448 - mse: 3.2202e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1257 - bpp: 0.4551 - mse: 3.2743e-04\n",
      "Epoch 688: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1257 - bpp: 0.4551 - mse: 3.2743e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0768 - bpp: 0.4403 - mse: 3.1079e-04\n",
      "Epoch 689: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0768 - bpp: 0.4403 - mse: 3.1079e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0951 - bpp: 0.4502 - mse: 3.1485e-04\n",
      "Epoch 690: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0951 - bpp: 0.4502 - mse: 3.1485e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0900 - bpp: 0.4466 - mse: 3.1419e-04\n",
      "Epoch 691: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0900 - bpp: 0.4466 - mse: 3.1419e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0369 - bpp: 0.4392 - mse: 2.9181e-04\n",
      "Epoch 692: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0369 - bpp: 0.4392 - mse: 2.9181e-04\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9684 - bpp: 0.4224 - mse: 2.6663e-04\n",
      "Epoch 693: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 0.9684 - bpp: 0.4224 - mse: 2.6663e-04\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0685 - bpp: 0.4432 - mse: 3.0535e-04\n",
      "Epoch 694: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0685 - bpp: 0.4432 - mse: 3.0535e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1681 - bpp: 0.4586 - mse: 3.4645e-04\n",
      "Epoch 695: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1681 - bpp: 0.4586 - mse: 3.4645e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0484 - bpp: 0.4426 - mse: 2.9580e-04\n",
      "Epoch 696: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0484 - bpp: 0.4426 - mse: 2.9580e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0410 - bpp: 0.4445 - mse: 2.9124e-04\n",
      "Epoch 697: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0410 - bpp: 0.4445 - mse: 2.9124e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9927 - bpp: 0.4377 - mse: 2.7103e-04\n",
      "Epoch 698: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.9927 - bpp: 0.4377 - mse: 2.7103e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0169 - bpp: 0.4316 - mse: 2.8582e-04\n",
      "Epoch 699: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0169 - bpp: 0.4316 - mse: 2.8582e-04\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1004 - bpp: 0.4458 - mse: 3.1963e-04\n",
      "Epoch 700: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1004 - bpp: 0.4458 - mse: 3.1963e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2435 - bpp: 0.4769 - mse: 3.7431e-04\n",
      "Epoch 701: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.2435 - bpp: 0.4769 - mse: 3.7431e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2064 - bpp: 0.4602 - mse: 3.6436e-04\n",
      "Epoch 702: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2064 - bpp: 0.4602 - mse: 3.6436e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0909 - bpp: 0.4480 - mse: 3.1393e-04\n",
      "Epoch 703: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0909 - bpp: 0.4480 - mse: 3.1393e-04\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0939 - bpp: 0.4586 - mse: 3.1022e-04\n",
      "Epoch 704: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0939 - bpp: 0.4586 - mse: 3.1022e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1364 - bpp: 0.4520 - mse: 3.3416e-04\n",
      "Epoch 705: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1364 - bpp: 0.4520 - mse: 3.3416e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1096 - bpp: 0.4549 - mse: 3.1969e-04\n",
      "Epoch 706: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1096 - bpp: 0.4549 - mse: 3.1969e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1411 - bpp: 0.4611 - mse: 3.3203e-04\n",
      "Epoch 707: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1411 - bpp: 0.4611 - mse: 3.3203e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0387 - bpp: 0.4417 - mse: 2.9147e-04\n",
      "Epoch 708: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0387 - bpp: 0.4417 - mse: 2.9147e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0231 - bpp: 0.4338 - mse: 2.8779e-04\n",
      "Epoch 709: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.0231 - bpp: 0.4338 - mse: 2.8779e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0932 - bpp: 0.4438 - mse: 3.1709e-04\n",
      "Epoch 710: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0932 - bpp: 0.4438 - mse: 3.1709e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0570 - bpp: 0.4432 - mse: 2.9972e-04\n",
      "Epoch 711: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0570 - bpp: 0.4432 - mse: 2.9972e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0605 - bpp: 0.4425 - mse: 3.0177e-04\n",
      "Epoch 712: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0605 - bpp: 0.4425 - mse: 3.0177e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0306 - bpp: 0.4385 - mse: 2.8908e-04\n",
      "Epoch 713: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.0306 - bpp: 0.4385 - mse: 2.8908e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0788 - bpp: 0.4477 - mse: 3.0817e-04\n",
      "Epoch 714: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0788 - bpp: 0.4477 - mse: 3.0817e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1129 - bpp: 0.4490 - mse: 3.2420e-04\n",
      "Epoch 715: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1129 - bpp: 0.4490 - mse: 3.2420e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9803 - bpp: 0.4374 - mse: 2.6509e-04\n",
      "Epoch 716: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9803 - bpp: 0.4374 - mse: 2.6509e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1063 - bpp: 0.4480 - mse: 3.2142e-04\n",
      "Epoch 717: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1063 - bpp: 0.4480 - mse: 3.2142e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0242 - bpp: 0.4422 - mse: 2.8415e-04\n",
      "Epoch 718: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0242 - bpp: 0.4422 - mse: 2.8415e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.4443 - mse: 2.8467e-04\n",
      "Epoch 719: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0273 - bpp: 0.4443 - mse: 2.8467e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0716 - bpp: 0.4437 - mse: 3.0657e-04\n",
      "Epoch 720: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0716 - bpp: 0.4437 - mse: 3.0657e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0789 - bpp: 0.4494 - mse: 3.0735e-04\n",
      "Epoch 721: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0789 - bpp: 0.4494 - mse: 3.0735e-04\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0332 - bpp: 0.4408 - mse: 2.8924e-04\n",
      "Epoch 722: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0332 - bpp: 0.4408 - mse: 2.8924e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0115 - bpp: 0.4373 - mse: 2.8037e-04\n",
      "Epoch 723: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0115 - bpp: 0.4373 - mse: 2.8037e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0257 - bpp: 0.4405 - mse: 2.8575e-04\n",
      "Epoch 724: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0257 - bpp: 0.4405 - mse: 2.8575e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0629 - bpp: 0.4384 - mse: 3.0494e-04\n",
      "Epoch 725: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0629 - bpp: 0.4384 - mse: 3.0494e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1826 - bpp: 0.4702 - mse: 3.4783e-04\n",
      "Epoch 726: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1826 - bpp: 0.4702 - mse: 3.4783e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9840 - bpp: 0.4379 - mse: 2.6664e-04\n",
      "Epoch 727: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9840 - bpp: 0.4379 - mse: 2.6664e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0689 - bpp: 0.4425 - mse: 3.0582e-04\n",
      "Epoch 728: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0689 - bpp: 0.4425 - mse: 3.0582e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.4503 - mse: 3.0384e-04\n",
      "Epoch 729: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0725 - bpp: 0.4503 - mse: 3.0384e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1512 - bpp: 0.4590 - mse: 3.3800e-04\n",
      "Epoch 730: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1512 - bpp: 0.4590 - mse: 3.3800e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0746 - bpp: 0.4533 - mse: 3.0337e-04\n",
      "Epoch 731: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0746 - bpp: 0.4533 - mse: 3.0337e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0597 - bpp: 0.4421 - mse: 3.0159e-04\n",
      "Epoch 732: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0597 - bpp: 0.4421 - mse: 3.0159e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0783 - bpp: 0.4426 - mse: 3.1036e-04\n",
      "Epoch 733: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0783 - bpp: 0.4426 - mse: 3.1036e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0411 - bpp: 0.4425 - mse: 2.9226e-04\n",
      "Epoch 734: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0411 - bpp: 0.4425 - mse: 2.9226e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0596 - bpp: 0.4383 - mse: 3.0336e-04\n",
      "Epoch 735: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0596 - bpp: 0.4383 - mse: 3.0336e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0918 - bpp: 0.4412 - mse: 3.1771e-04\n",
      "Epoch 736: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0918 - bpp: 0.4412 - mse: 3.1771e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0154 - bpp: 0.4350 - mse: 2.8338e-04\n",
      "Epoch 737: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0154 - bpp: 0.4350 - mse: 2.8338e-04\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0063 - bpp: 0.4311 - mse: 2.8086e-04\n",
      "Epoch 738: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0063 - bpp: 0.4311 - mse: 2.8086e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0546 - bpp: 0.4392 - mse: 3.0049e-04\n",
      "Epoch 739: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0546 - bpp: 0.4392 - mse: 3.0049e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1506 - bpp: 0.4563 - mse: 3.3904e-04\n",
      "Epoch 740: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1506 - bpp: 0.4563 - mse: 3.3904e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0887 - bpp: 0.4529 - mse: 3.1043e-04\n",
      "Epoch 741: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0887 - bpp: 0.4529 - mse: 3.1043e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0264 - bpp: 0.4360 - mse: 2.8827e-04\n",
      "Epoch 742: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0264 - bpp: 0.4360 - mse: 2.8827e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0615 - bpp: 0.4456 - mse: 3.0073e-04\n",
      "Epoch 743: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0615 - bpp: 0.4456 - mse: 3.0073e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0855 - bpp: 0.4398 - mse: 3.1529e-04\n",
      "Epoch 744: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0855 - bpp: 0.4398 - mse: 3.1529e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0195 - bpp: 0.4401 - mse: 2.8289e-04\n",
      "Epoch 745: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0195 - bpp: 0.4401 - mse: 2.8289e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0697 - bpp: 0.4398 - mse: 3.0758e-04\n",
      "Epoch 746: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0697 - bpp: 0.4398 - mse: 3.0758e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0076 - bpp: 0.4336 - mse: 2.8028e-04\n",
      "Epoch 747: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0076 - bpp: 0.4336 - mse: 2.8028e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0371 - bpp: 0.4417 - mse: 2.9069e-04\n",
      "Epoch 748: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.0371 - bpp: 0.4417 - mse: 2.9069e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9948 - bpp: 0.4323 - mse: 2.7469e-04\n",
      "Epoch 749: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.9948 - bpp: 0.4323 - mse: 2.7469e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9600 - bpp: 0.4331 - mse: 2.5726e-04\n",
      "Epoch 750: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9600 - bpp: 0.4331 - mse: 2.5726e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0637 - bpp: 0.4497 - mse: 2.9978e-04\n",
      "Epoch 751: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0637 - bpp: 0.4497 - mse: 2.9978e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0497 - bpp: 0.4376 - mse: 2.9891e-04\n",
      "Epoch 752: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0497 - bpp: 0.4376 - mse: 2.9891e-04\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0119 - bpp: 0.4398 - mse: 2.7936e-04\n",
      "Epoch 753: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0119 - bpp: 0.4398 - mse: 2.7936e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0422 - bpp: 0.4358 - mse: 2.9611e-04\n",
      "Epoch 754: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 193ms/step - loss: 1.0422 - bpp: 0.4358 - mse: 2.9611e-04\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0134 - bpp: 0.4364 - mse: 2.8171e-04\n",
      "Epoch 755: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0134 - bpp: 0.4364 - mse: 2.8171e-04\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0074 - bpp: 0.4336 - mse: 2.8020e-04\n",
      "Epoch 756: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0074 - bpp: 0.4336 - mse: 2.8020e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0495 - bpp: 0.4378 - mse: 2.9867e-04\n",
      "Epoch 757: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0495 - bpp: 0.4378 - mse: 2.9867e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0315 - bpp: 0.4374 - mse: 2.9008e-04\n",
      "Epoch 758: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0315 - bpp: 0.4374 - mse: 2.9008e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0611 - bpp: 0.4514 - mse: 2.9773e-04\n",
      "Epoch 759: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0611 - bpp: 0.4514 - mse: 2.9773e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0798 - bpp: 0.4451 - mse: 3.0990e-04\n",
      "Epoch 760: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0798 - bpp: 0.4451 - mse: 3.0990e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0385 - bpp: 0.4438 - mse: 2.9038e-04\n",
      "Epoch 761: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0385 - bpp: 0.4438 - mse: 2.9038e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1241 - bpp: 0.4537 - mse: 3.2734e-04\n",
      "Epoch 762: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1241 - bpp: 0.4537 - mse: 3.2734e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0259 - bpp: 0.4371 - mse: 2.8749e-04\n",
      "Epoch 763: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0259 - bpp: 0.4371 - mse: 2.8749e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0632 - bpp: 0.4445 - mse: 3.0213e-04\n",
      "Epoch 764: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0632 - bpp: 0.4445 - mse: 3.0213e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0730 - bpp: 0.4425 - mse: 3.0784e-04\n",
      "Epoch 765: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0730 - bpp: 0.4425 - mse: 3.0784e-04\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0443 - bpp: 0.4387 - mse: 2.9570e-04\n",
      "Epoch 766: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0443 - bpp: 0.4387 - mse: 2.9570e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0628 - bpp: 0.4406 - mse: 3.0382e-04\n",
      "Epoch 767: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0628 - bpp: 0.4406 - mse: 3.0382e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0016 - bpp: 0.4384 - mse: 2.7500e-04\n",
      "Epoch 768: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0016 - bpp: 0.4384 - mse: 2.7500e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1032 - bpp: 0.4509 - mse: 3.1852e-04\n",
      "Epoch 769: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1032 - bpp: 0.4509 - mse: 3.1852e-04\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0688 - bpp: 0.4366 - mse: 3.0869e-04\n",
      "Epoch 770: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0688 - bpp: 0.4366 - mse: 3.0869e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0637 - bpp: 0.4472 - mse: 3.0103e-04\n",
      "Epoch 771: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0637 - bpp: 0.4472 - mse: 3.0103e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0410 - bpp: 0.4381 - mse: 2.9438e-04\n",
      "Epoch 772: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0410 - bpp: 0.4381 - mse: 2.9438e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0096 - bpp: 0.4363 - mse: 2.7995e-04\n",
      "Epoch 773: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.0096 - bpp: 0.4363 - mse: 2.7995e-04\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.4449 - mse: 2.8221e-04\n",
      "Epoch 774: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0229 - bpp: 0.4449 - mse: 2.8221e-04\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0773 - bpp: 0.4469 - mse: 3.0782e-04\n",
      "Epoch 775: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0773 - bpp: 0.4469 - mse: 3.0782e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0832 - bpp: 0.4449 - mse: 3.1167e-04\n",
      "Epoch 776: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0832 - bpp: 0.4449 - mse: 3.1167e-04\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1857 - bpp: 0.4606 - mse: 3.5405e-04\n",
      "Epoch 777: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.1857 - bpp: 0.4606 - mse: 3.5405e-04\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0981 - bpp: 0.4451 - mse: 3.1883e-04\n",
      "Epoch 778: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0981 - bpp: 0.4451 - mse: 3.1883e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0587 - bpp: 0.4495 - mse: 2.9747e-04\n",
      "Epoch 779: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0587 - bpp: 0.4495 - mse: 2.9747e-04\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0254 - bpp: 0.4394 - mse: 2.8610e-04\n",
      "Epoch 780: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0254 - bpp: 0.4394 - mse: 2.8610e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0527 - bpp: 0.4429 - mse: 2.9776e-04\n",
      "Epoch 781: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0527 - bpp: 0.4429 - mse: 2.9776e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0740 - bpp: 0.4440 - mse: 3.0759e-04\n",
      "Epoch 782: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0740 - bpp: 0.4440 - mse: 3.0759e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0869 - bpp: 0.4441 - mse: 3.1391e-04\n",
      "Epoch 783: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.0869 - bpp: 0.4441 - mse: 3.1391e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0057 - bpp: 0.4351 - mse: 2.7861e-04\n",
      "Epoch 784: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0057 - bpp: 0.4351 - mse: 2.7861e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0856 - bpp: 0.4486 - mse: 3.1103e-04\n",
      "Epoch 785: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0856 - bpp: 0.4486 - mse: 3.1103e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0391 - bpp: 0.4376 - mse: 2.9369e-04\n",
      "Epoch 786: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0391 - bpp: 0.4376 - mse: 2.9369e-04\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1284 - bpp: 0.4530 - mse: 3.2979e-04\n",
      "Epoch 787: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1284 - bpp: 0.4530 - mse: 3.2979e-04\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0765 - bpp: 0.4454 - mse: 3.0816e-04\n",
      "Epoch 788: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0765 - bpp: 0.4454 - mse: 3.0816e-04\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0680 - bpp: 0.4384 - mse: 3.0746e-04\n",
      "Epoch 789: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.0680 - bpp: 0.4384 - mse: 3.0746e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0170 - bpp: 0.4455 - mse: 2.7907e-04\n",
      "Epoch 790: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0170 - bpp: 0.4455 - mse: 2.7907e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0573 - bpp: 0.4419 - mse: 3.0049e-04\n",
      "Epoch 791: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0573 - bpp: 0.4419 - mse: 3.0049e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0681 - bpp: 0.4483 - mse: 3.0268e-04\n",
      "Epoch 792: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0681 - bpp: 0.4483 - mse: 3.0268e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9924 - bpp: 0.4330 - mse: 2.7313e-04\n",
      "Epoch 793: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.9924 - bpp: 0.4330 - mse: 2.7313e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1501 - bpp: 0.4604 - mse: 3.3677e-04\n",
      "Epoch 794: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1501 - bpp: 0.4604 - mse: 3.3677e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0457 - bpp: 0.4483 - mse: 2.9167e-04\n",
      "Epoch 795: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.0457 - bpp: 0.4483 - mse: 2.9167e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0048 - bpp: 0.4308 - mse: 2.8031e-04\n",
      "Epoch 796: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.0048 - bpp: 0.4308 - mse: 2.8031e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.4498 - mse: 3.0179e-04\n",
      "Epoch 797: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0678 - bpp: 0.4498 - mse: 3.0179e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0302 - bpp: 0.4436 - mse: 2.8643e-04\n",
      "Epoch 798: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0302 - bpp: 0.4436 - mse: 2.8643e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0378 - bpp: 0.4495 - mse: 2.8726e-04\n",
      "Epoch 799: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0378 - bpp: 0.4495 - mse: 2.8726e-04\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1272 - bpp: 0.4542 - mse: 3.2858e-04\n",
      "Epoch 800: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1272 - bpp: 0.4542 - mse: 3.2858e-04\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0590 - bpp: 0.4439 - mse: 3.0032e-04\n",
      "Epoch 801: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0590 - bpp: 0.4439 - mse: 3.0032e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9962 - bpp: 0.4317 - mse: 2.7565e-04\n",
      "Epoch 802: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.9962 - bpp: 0.4317 - mse: 2.7565e-04\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0767 - bpp: 0.4464 - mse: 3.0777e-04\n",
      "Epoch 803: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0767 - bpp: 0.4464 - mse: 3.0777e-04\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0186 - bpp: 0.4402 - mse: 2.8241e-04\n",
      "Epoch 804: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0186 - bpp: 0.4402 - mse: 2.8241e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9729 - bpp: 0.4314 - mse: 2.6444e-04\n",
      "Epoch 805: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.9729 - bpp: 0.4314 - mse: 2.6444e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0568 - bpp: 0.4472 - mse: 2.9764e-04\n",
      "Epoch 806: loss did not improve from 0.94717\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0568 - bpp: 0.4472 - mse: 2.9764e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9281 - bpp: 0.4237 - mse: 2.4626e-04\n",
      "Epoch 807: loss improved from 0.94717 to 0.92809, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.9281 - bpp: 0.4237 - mse: 2.4626e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0612 - bpp: 0.4490 - mse: 2.9891e-04\n",
      "Epoch 808: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0612 - bpp: 0.4490 - mse: 2.9891e-04\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0712 - bpp: 0.4494 - mse: 3.0361e-04\n",
      "Epoch 809: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.0712 - bpp: 0.4494 - mse: 3.0361e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0193 - bpp: 0.4394 - mse: 2.8316e-04\n",
      "Epoch 810: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0193 - bpp: 0.4394 - mse: 2.8316e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0616 - bpp: 0.4444 - mse: 3.0138e-04\n",
      "Epoch 811: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.0616 - bpp: 0.4444 - mse: 3.0138e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0016 - bpp: 0.4291 - mse: 2.7953e-04\n",
      "Epoch 812: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0016 - bpp: 0.4291 - mse: 2.7953e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9952 - bpp: 0.4342 - mse: 2.7395e-04\n",
      "Epoch 813: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9952 - bpp: 0.4342 - mse: 2.7395e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0545 - bpp: 0.4483 - mse: 2.9598e-04\n",
      "Epoch 814: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0545 - bpp: 0.4483 - mse: 2.9598e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0576 - bpp: 0.4414 - mse: 3.0087e-04\n",
      "Epoch 815: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0576 - bpp: 0.4414 - mse: 3.0087e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9943 - bpp: 0.4298 - mse: 2.7562e-04\n",
      "Epoch 816: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9943 - bpp: 0.4298 - mse: 2.7562e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0248 - bpp: 0.4333 - mse: 2.8883e-04\n",
      "Epoch 817: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0248 - bpp: 0.4333 - mse: 2.8883e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0660 - bpp: 0.4488 - mse: 3.0136e-04\n",
      "Epoch 818: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0660 - bpp: 0.4488 - mse: 3.0136e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1136 - bpp: 0.4531 - mse: 3.2248e-04\n",
      "Epoch 819: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.1136 - bpp: 0.4531 - mse: 3.2248e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9723 - bpp: 0.4320 - mse: 2.6380e-04\n",
      "Epoch 820: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.9723 - bpp: 0.4320 - mse: 2.6380e-04\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1059 - bpp: 0.4432 - mse: 3.2358e-04\n",
      "Epoch 821: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.1059 - bpp: 0.4432 - mse: 3.2358e-04\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0874 - bpp: 0.4434 - mse: 3.1444e-04\n",
      "Epoch 822: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0874 - bpp: 0.4434 - mse: 3.1444e-04\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0892 - bpp: 0.4505 - mse: 3.1189e-04\n",
      "Epoch 823: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0892 - bpp: 0.4505 - mse: 3.1189e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0201 - bpp: 0.4355 - mse: 2.8547e-04\n",
      "Epoch 824: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0201 - bpp: 0.4355 - mse: 2.8547e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1089 - bpp: 0.4527 - mse: 3.2041e-04\n",
      "Epoch 825: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.1089 - bpp: 0.4527 - mse: 3.2041e-04\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0319 - bpp: 0.4414 - mse: 2.8831e-04\n",
      "Epoch 826: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0319 - bpp: 0.4414 - mse: 2.8831e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0301 - bpp: 0.4427 - mse: 2.8679e-04\n",
      "Epoch 827: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0301 - bpp: 0.4427 - mse: 2.8679e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0404 - bpp: 0.4284 - mse: 2.9882e-04\n",
      "Epoch 828: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0404 - bpp: 0.4284 - mse: 2.9882e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0942 - bpp: 0.4373 - mse: 3.2078e-04\n",
      "Epoch 829: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0942 - bpp: 0.4373 - mse: 3.2078e-04\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0577 - bpp: 0.4503 - mse: 2.9659e-04\n",
      "Epoch 830: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0577 - bpp: 0.4503 - mse: 2.9659e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0940 - bpp: 0.4459 - mse: 3.1644e-04\n",
      "Epoch 831: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0940 - bpp: 0.4459 - mse: 3.1644e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1545 - bpp: 0.4533 - mse: 3.4235e-04\n",
      "Epoch 832: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1545 - bpp: 0.4533 - mse: 3.4235e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0488 - bpp: 0.4410 - mse: 2.9680e-04\n",
      "Epoch 833: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0488 - bpp: 0.4410 - mse: 2.9680e-04\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1130 - bpp: 0.4534 - mse: 3.2206e-04\n",
      "Epoch 834: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1130 - bpp: 0.4534 - mse: 3.2206e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9887 - bpp: 0.4320 - mse: 2.7186e-04\n",
      "Epoch 835: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9887 - bpp: 0.4320 - mse: 2.7186e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9826 - bpp: 0.4368 - mse: 2.6650e-04\n",
      "Epoch 836: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9826 - bpp: 0.4368 - mse: 2.6650e-04\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0371 - bpp: 0.4388 - mse: 2.9214e-04\n",
      "Epoch 837: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0371 - bpp: 0.4388 - mse: 2.9214e-04\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0338 - bpp: 0.4417 - mse: 2.8911e-04\n",
      "Epoch 838: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0338 - bpp: 0.4417 - mse: 2.8911e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0032 - bpp: 0.4327 - mse: 2.7855e-04\n",
      "Epoch 839: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0032 - bpp: 0.4327 - mse: 2.7855e-04\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0613 - bpp: 0.4430 - mse: 3.0190e-04\n",
      "Epoch 840: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0613 - bpp: 0.4430 - mse: 3.0190e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0073 - bpp: 0.4371 - mse: 2.7845e-04\n",
      "Epoch 841: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0073 - bpp: 0.4371 - mse: 2.7845e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0933 - bpp: 0.4467 - mse: 3.1573e-04\n",
      "Epoch 842: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.0933 - bpp: 0.4467 - mse: 3.1573e-04\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1280 - bpp: 0.4551 - mse: 3.2854e-04\n",
      "Epoch 843: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1280 - bpp: 0.4551 - mse: 3.2854e-04\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0215 - bpp: 0.4336 - mse: 2.8703e-04\n",
      "Epoch 844: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0215 - bpp: 0.4336 - mse: 2.8703e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0174 - bpp: 0.4334 - mse: 2.8512e-04\n",
      "Epoch 845: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0174 - bpp: 0.4334 - mse: 2.8512e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9973 - bpp: 0.4433 - mse: 2.7051e-04\n",
      "Epoch 846: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9973 - bpp: 0.4433 - mse: 2.7051e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9793 - bpp: 0.4278 - mse: 2.6927e-04\n",
      "Epoch 847: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.9793 - bpp: 0.4278 - mse: 2.6927e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0814 - bpp: 0.4482 - mse: 3.0920e-04\n",
      "Epoch 848: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0814 - bpp: 0.4482 - mse: 3.0920e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9883 - bpp: 0.4287 - mse: 2.7322e-04\n",
      "Epoch 849: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 0.9883 - bpp: 0.4287 - mse: 2.7322e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1074 - bpp: 0.4572 - mse: 3.1749e-04\n",
      "Epoch 850: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1074 - bpp: 0.4572 - mse: 3.1749e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9858 - bpp: 0.4402 - mse: 2.6643e-04\n",
      "Epoch 851: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.9858 - bpp: 0.4402 - mse: 2.6643e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1069 - bpp: 0.4485 - mse: 3.2147e-04\n",
      "Epoch 852: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1069 - bpp: 0.4485 - mse: 3.2147e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0625 - bpp: 0.4519 - mse: 2.9811e-04\n",
      "Epoch 853: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0625 - bpp: 0.4519 - mse: 2.9811e-04\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0177 - bpp: 0.4375 - mse: 2.8329e-04\n",
      "Epoch 854: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0177 - bpp: 0.4375 - mse: 2.8329e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9709 - bpp: 0.4249 - mse: 2.6660e-04\n",
      "Epoch 855: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 0.9709 - bpp: 0.4249 - mse: 2.6660e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0113 - bpp: 0.4395 - mse: 2.7923e-04\n",
      "Epoch 856: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.0113 - bpp: 0.4395 - mse: 2.7923e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0569 - bpp: 0.4427 - mse: 2.9991e-04\n",
      "Epoch 857: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0569 - bpp: 0.4427 - mse: 2.9991e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0504 - bpp: 0.4483 - mse: 2.9398e-04\n",
      "Epoch 858: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0504 - bpp: 0.4483 - mse: 2.9398e-04\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0758 - bpp: 0.4382 - mse: 3.1135e-04\n",
      "Epoch 859: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0758 - bpp: 0.4382 - mse: 3.1135e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0363 - bpp: 0.4390 - mse: 2.9164e-04\n",
      "Epoch 860: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0363 - bpp: 0.4390 - mse: 2.9164e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9912 - bpp: 0.4327 - mse: 2.7270e-04\n",
      "Epoch 861: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.9912 - bpp: 0.4327 - mse: 2.7270e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.4427 - mse: 3.0525e-04\n",
      "Epoch 862: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0678 - bpp: 0.4427 - mse: 3.0525e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1268 - bpp: 0.4561 - mse: 3.2749e-04\n",
      "Epoch 863: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1268 - bpp: 0.4561 - mse: 3.2749e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0542 - bpp: 0.4430 - mse: 2.9844e-04\n",
      "Epoch 864: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 1.0542 - bpp: 0.4430 - mse: 2.9844e-04\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0240 - bpp: 0.4397 - mse: 2.8529e-04\n",
      "Epoch 865: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0240 - bpp: 0.4397 - mse: 2.8529e-04\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0605 - bpp: 0.4458 - mse: 3.0016e-04\n",
      "Epoch 866: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0605 - bpp: 0.4458 - mse: 3.0016e-04\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1678 - bpp: 0.4640 - mse: 3.4361e-04\n",
      "Epoch 867: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1678 - bpp: 0.4640 - mse: 3.4361e-04\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1064 - bpp: 0.4520 - mse: 3.1953e-04\n",
      "Epoch 868: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1064 - bpp: 0.4520 - mse: 3.1953e-04\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0189 - bpp: 0.4325 - mse: 2.8632e-04\n",
      "Epoch 869: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.0189 - bpp: 0.4325 - mse: 2.8632e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9765 - bpp: 0.4291 - mse: 2.6730e-04\n",
      "Epoch 870: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9765 - bpp: 0.4291 - mse: 2.6730e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1433 - bpp: 0.4573 - mse: 3.3495e-04\n",
      "Epoch 871: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.1433 - bpp: 0.4573 - mse: 3.3495e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0123 - bpp: 0.4360 - mse: 2.8140e-04\n",
      "Epoch 872: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0123 - bpp: 0.4360 - mse: 2.8140e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9729 - bpp: 0.4251 - mse: 2.6749e-04\n",
      "Epoch 873: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.9729 - bpp: 0.4251 - mse: 2.6749e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0624 - bpp: 0.4464 - mse: 3.0079e-04\n",
      "Epoch 874: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0624 - bpp: 0.4464 - mse: 3.0079e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0296 - bpp: 0.4352 - mse: 2.9023e-04\n",
      "Epoch 875: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.0296 - bpp: 0.4352 - mse: 2.9023e-04\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0910 - bpp: 0.4502 - mse: 3.1287e-04\n",
      "Epoch 876: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0910 - bpp: 0.4502 - mse: 3.1287e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0573 - bpp: 0.4462 - mse: 2.9841e-04\n",
      "Epoch 877: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.0573 - bpp: 0.4462 - mse: 2.9841e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9361 - bpp: 0.4212 - mse: 2.5140e-04\n",
      "Epoch 878: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9361 - bpp: 0.4212 - mse: 2.5140e-04\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0045 - bpp: 0.4342 - mse: 2.7846e-04\n",
      "Epoch 879: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0045 - bpp: 0.4342 - mse: 2.7846e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9521 - bpp: 0.4207 - mse: 2.5949e-04\n",
      "Epoch 880: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9521 - bpp: 0.4207 - mse: 2.5949e-04\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0477 - bpp: 0.4472 - mse: 2.9322e-04\n",
      "Epoch 881: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0477 - bpp: 0.4472 - mse: 2.9322e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0716 - bpp: 0.4593 - mse: 2.9898e-04\n",
      "Epoch 882: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.0716 - bpp: 0.4593 - mse: 2.9898e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9737 - bpp: 0.4328 - mse: 2.6409e-04\n",
      "Epoch 883: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 0.9737 - bpp: 0.4328 - mse: 2.6409e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9461 - bpp: 0.4233 - mse: 2.5528e-04\n",
      "Epoch 884: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9461 - bpp: 0.4233 - mse: 2.5528e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0836 - bpp: 0.4499 - mse: 3.0940e-04\n",
      "Epoch 885: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.0836 - bpp: 0.4499 - mse: 3.0940e-04\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0650 - bpp: 0.4474 - mse: 3.0154e-04\n",
      "Epoch 886: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0650 - bpp: 0.4474 - mse: 3.0154e-04\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9695 - bpp: 0.4285 - mse: 2.6416e-04\n",
      "Epoch 887: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9695 - bpp: 0.4285 - mse: 2.6416e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9897 - bpp: 0.4332 - mse: 2.7172e-04\n",
      "Epoch 888: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9897 - bpp: 0.4332 - mse: 2.7172e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2191 - bpp: 0.4643 - mse: 3.6854e-04\n",
      "Epoch 889: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2191 - bpp: 0.4643 - mse: 3.6854e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1148 - bpp: 0.4497 - mse: 3.2474e-04\n",
      "Epoch 890: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1148 - bpp: 0.4497 - mse: 3.2474e-04\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0936 - bpp: 0.4503 - mse: 3.1414e-04\n",
      "Epoch 891: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0936 - bpp: 0.4503 - mse: 3.1414e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.4429 - mse: 2.8317e-04\n",
      "Epoch 892: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0229 - bpp: 0.4429 - mse: 2.8317e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0290 - bpp: 0.4432 - mse: 2.8604e-04\n",
      "Epoch 893: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0290 - bpp: 0.4432 - mse: 2.8604e-04\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0237 - bpp: 0.4315 - mse: 2.8913e-04\n",
      "Epoch 894: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0237 - bpp: 0.4315 - mse: 2.8913e-04\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0346 - bpp: 0.4428 - mse: 2.8896e-04\n",
      "Epoch 895: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0346 - bpp: 0.4428 - mse: 2.8896e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0431 - bpp: 0.4454 - mse: 2.9185e-04\n",
      "Epoch 896: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0431 - bpp: 0.4454 - mse: 2.9185e-04\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0062 - bpp: 0.4422 - mse: 2.7538e-04\n",
      "Epoch 897: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0062 - bpp: 0.4422 - mse: 2.7538e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1134 - bpp: 0.4607 - mse: 3.1871e-04\n",
      "Epoch 898: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1134 - bpp: 0.4607 - mse: 3.1871e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1129 - bpp: 0.4401 - mse: 3.2853e-04\n",
      "Epoch 899: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1129 - bpp: 0.4401 - mse: 3.2853e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9895 - bpp: 0.4338 - mse: 2.7133e-04\n",
      "Epoch 900: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9895 - bpp: 0.4338 - mse: 2.7133e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0290 - bpp: 0.4410 - mse: 2.8715e-04\n",
      "Epoch 901: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0290 - bpp: 0.4410 - mse: 2.8715e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1619 - bpp: 0.4657 - mse: 3.3995e-04\n",
      "Epoch 902: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1619 - bpp: 0.4657 - mse: 3.3995e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0544 - bpp: 0.4446 - mse: 2.9777e-04\n",
      "Epoch 903: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0544 - bpp: 0.4446 - mse: 2.9777e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9697 - bpp: 0.4365 - mse: 2.6037e-04\n",
      "Epoch 904: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9697 - bpp: 0.4365 - mse: 2.6037e-04\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0520 - bpp: 0.4381 - mse: 2.9976e-04\n",
      "Epoch 905: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0520 - bpp: 0.4381 - mse: 2.9976e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0059 - bpp: 0.4343 - mse: 2.7908e-04\n",
      "Epoch 906: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0059 - bpp: 0.4343 - mse: 2.7908e-04\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0681 - bpp: 0.4405 - mse: 3.0646e-04\n",
      "Epoch 907: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0681 - bpp: 0.4405 - mse: 3.0646e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9756 - bpp: 0.4327 - mse: 2.6506e-04\n",
      "Epoch 908: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9756 - bpp: 0.4327 - mse: 2.6506e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1863 - bpp: 0.4624 - mse: 3.5342e-04\n",
      "Epoch 909: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1863 - bpp: 0.4624 - mse: 3.5342e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9872 - bpp: 0.4298 - mse: 2.7220e-04\n",
      "Epoch 910: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9872 - bpp: 0.4298 - mse: 2.7220e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0217 - bpp: 0.4363 - mse: 2.8583e-04\n",
      "Epoch 911: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0217 - bpp: 0.4363 - mse: 2.8583e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0094 - bpp: 0.4379 - mse: 2.7905e-04\n",
      "Epoch 912: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0094 - bpp: 0.4379 - mse: 2.7905e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9871 - bpp: 0.4402 - mse: 2.6707e-04\n",
      "Epoch 913: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9871 - bpp: 0.4402 - mse: 2.6707e-04\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9436 - bpp: 0.4256 - mse: 2.5293e-04\n",
      "Epoch 914: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9436 - bpp: 0.4256 - mse: 2.5293e-04\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0323 - bpp: 0.4413 - mse: 2.8860e-04\n",
      "Epoch 915: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0323 - bpp: 0.4413 - mse: 2.8860e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9628 - bpp: 0.4229 - mse: 2.6361e-04\n",
      "Epoch 916: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9628 - bpp: 0.4229 - mse: 2.6361e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0171 - bpp: 0.4378 - mse: 2.8287e-04\n",
      "Epoch 917: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0171 - bpp: 0.4378 - mse: 2.8287e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9826 - bpp: 0.4188 - mse: 2.7526e-04\n",
      "Epoch 918: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9826 - bpp: 0.4188 - mse: 2.7526e-04\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9734 - bpp: 0.4237 - mse: 2.6840e-04\n",
      "Epoch 919: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.9734 - bpp: 0.4237 - mse: 2.6840e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0900 - bpp: 0.4530 - mse: 3.1101e-04\n",
      "Epoch 920: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.0900 - bpp: 0.4530 - mse: 3.1101e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9583 - bpp: 0.4308 - mse: 2.5757e-04\n",
      "Epoch 921: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9583 - bpp: 0.4308 - mse: 2.5757e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9850 - bpp: 0.4324 - mse: 2.6985e-04\n",
      "Epoch 922: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9850 - bpp: 0.4324 - mse: 2.6985e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9297 - bpp: 0.4190 - mse: 2.4937e-04\n",
      "Epoch 923: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9297 - bpp: 0.4190 - mse: 2.4937e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9953 - bpp: 0.4329 - mse: 2.7460e-04\n",
      "Epoch 924: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9953 - bpp: 0.4329 - mse: 2.7460e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0603 - bpp: 0.4397 - mse: 3.0302e-04\n",
      "Epoch 925: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0603 - bpp: 0.4397 - mse: 3.0302e-04\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0245 - bpp: 0.4297 - mse: 2.9043e-04\n",
      "Epoch 926: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0245 - bpp: 0.4297 - mse: 2.9043e-04\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0569 - bpp: 0.4389 - mse: 3.0176e-04\n",
      "Epoch 927: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0569 - bpp: 0.4389 - mse: 3.0176e-04\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9665 - bpp: 0.4316 - mse: 2.6119e-04\n",
      "Epoch 928: loss did not improve from 0.92809\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9665 - bpp: 0.4316 - mse: 2.6119e-04\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8906 - bpp: 0.4148 - mse: 2.3229e-04\n",
      "Epoch 929: loss improved from 0.92809 to 0.89055, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.8906 - bpp: 0.4148 - mse: 2.3229e-04\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9194 - bpp: 0.4241 - mse: 2.4183e-04\n",
      "Epoch 930: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9194 - bpp: 0.4241 - mse: 2.4183e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0517 - bpp: 0.4384 - mse: 2.9948e-04\n",
      "Epoch 931: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0517 - bpp: 0.4384 - mse: 2.9948e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0166 - bpp: 0.4330 - mse: 2.8495e-04\n",
      "Epoch 932: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0166 - bpp: 0.4330 - mse: 2.8495e-04\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9761 - bpp: 0.4231 - mse: 2.7004e-04\n",
      "Epoch 933: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.9761 - bpp: 0.4231 - mse: 2.7004e-04\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9677 - bpp: 0.4347 - mse: 2.6026e-04\n",
      "Epoch 934: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9677 - bpp: 0.4347 - mse: 2.6026e-04\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0324 - bpp: 0.4371 - mse: 2.9067e-04\n",
      "Epoch 935: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0324 - bpp: 0.4371 - mse: 2.9067e-04\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0873 - bpp: 0.4447 - mse: 3.1378e-04\n",
      "Epoch 936: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0873 - bpp: 0.4447 - mse: 3.1378e-04\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.4344 - mse: 3.0173e-04\n",
      "Epoch 937: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0524 - bpp: 0.4344 - mse: 3.0173e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1508 - bpp: 0.4588 - mse: 3.3788e-04\n",
      "Epoch 938: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1508 - bpp: 0.4588 - mse: 3.3788e-04\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0119 - bpp: 0.4378 - mse: 2.8035e-04\n",
      "Epoch 939: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0119 - bpp: 0.4378 - mse: 2.8035e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9985 - bpp: 0.4293 - mse: 2.7794e-04\n",
      "Epoch 940: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9985 - bpp: 0.4293 - mse: 2.7794e-04\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1192 - bpp: 0.4474 - mse: 3.2803e-04\n",
      "Epoch 941: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1192 - bpp: 0.4474 - mse: 3.2803e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0999 - bpp: 0.4522 - mse: 3.1628e-04\n",
      "Epoch 942: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.0999 - bpp: 0.4522 - mse: 3.1628e-04\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9926 - bpp: 0.4326 - mse: 2.7344e-04\n",
      "Epoch 943: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9926 - bpp: 0.4326 - mse: 2.7344e-04\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.4444 - mse: 3.0435e-04\n",
      "Epoch 944: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0678 - bpp: 0.4444 - mse: 3.0435e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0021 - bpp: 0.4300 - mse: 2.7933e-04\n",
      "Epoch 945: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0021 - bpp: 0.4300 - mse: 2.7933e-04\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0176 - bpp: 0.4426 - mse: 2.8077e-04\n",
      "Epoch 946: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0176 - bpp: 0.4426 - mse: 2.8077e-04\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0043 - bpp: 0.4411 - mse: 2.7504e-04\n",
      "Epoch 947: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0043 - bpp: 0.4411 - mse: 2.7504e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0100 - bpp: 0.4320 - mse: 2.8222e-04\n",
      "Epoch 948: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0100 - bpp: 0.4320 - mse: 2.8222e-04\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9770 - bpp: 0.4339 - mse: 2.6518e-04\n",
      "Epoch 949: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9770 - bpp: 0.4339 - mse: 2.6518e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0526 - bpp: 0.4359 - mse: 3.0112e-04\n",
      "Epoch 950: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0526 - bpp: 0.4359 - mse: 3.0112e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1189 - bpp: 0.4544 - mse: 3.2445e-04\n",
      "Epoch 951: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1189 - bpp: 0.4544 - mse: 3.2445e-04\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0253 - bpp: 0.4429 - mse: 2.8438e-04\n",
      "Epoch 952: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0253 - bpp: 0.4429 - mse: 2.8438e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0457 - bpp: 0.4395 - mse: 2.9602e-04\n",
      "Epoch 953: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0457 - bpp: 0.4395 - mse: 2.9602e-04\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0557 - bpp: 0.4464 - mse: 2.9754e-04\n",
      "Epoch 954: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0557 - bpp: 0.4464 - mse: 2.9754e-04\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0506 - bpp: 0.4409 - mse: 2.9775e-04\n",
      "Epoch 955: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0506 - bpp: 0.4409 - mse: 2.9775e-04\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0349 - bpp: 0.4323 - mse: 2.9421e-04\n",
      "Epoch 956: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0349 - bpp: 0.4323 - mse: 2.9421e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0108 - bpp: 0.4372 - mse: 2.8005e-04\n",
      "Epoch 957: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0108 - bpp: 0.4372 - mse: 2.8005e-04\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0933 - bpp: 0.4525 - mse: 3.1289e-04\n",
      "Epoch 958: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0933 - bpp: 0.4525 - mse: 3.1289e-04\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0191 - bpp: 0.4454 - mse: 2.8013e-04\n",
      "Epoch 959: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0191 - bpp: 0.4454 - mse: 2.8013e-04\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1198 - bpp: 0.4462 - mse: 3.2889e-04\n",
      "Epoch 960: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1198 - bpp: 0.4462 - mse: 3.2889e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0503 - bpp: 0.4463 - mse: 2.9491e-04\n",
      "Epoch 961: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0503 - bpp: 0.4463 - mse: 2.9491e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0029 - bpp: 0.4341 - mse: 2.7772e-04\n",
      "Epoch 962: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0029 - bpp: 0.4341 - mse: 2.7772e-04\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9227 - bpp: 0.4183 - mse: 2.4632e-04\n",
      "Epoch 963: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9227 - bpp: 0.4183 - mse: 2.4632e-04\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0534 - bpp: 0.4410 - mse: 2.9902e-04\n",
      "Epoch 964: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0534 - bpp: 0.4410 - mse: 2.9902e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0110 - bpp: 0.4356 - mse: 2.8092e-04\n",
      "Epoch 965: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0110 - bpp: 0.4356 - mse: 2.8092e-04\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0179 - bpp: 0.4322 - mse: 2.8601e-04\n",
      "Epoch 966: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0179 - bpp: 0.4322 - mse: 2.8601e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0095 - bpp: 0.4377 - mse: 2.7917e-04\n",
      "Epoch 967: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0095 - bpp: 0.4377 - mse: 2.7917e-04\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9715 - bpp: 0.4277 - mse: 2.6556e-04\n",
      "Epoch 968: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 0.9715 - bpp: 0.4277 - mse: 2.6556e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0693 - bpp: 0.4417 - mse: 3.0646e-04\n",
      "Epoch 969: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0693 - bpp: 0.4417 - mse: 3.0646e-04\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9681 - bpp: 0.4245 - mse: 2.6544e-04\n",
      "Epoch 970: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9681 - bpp: 0.4245 - mse: 2.6544e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.4305 - mse: 2.9171e-04\n",
      "Epoch 971: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0279 - bpp: 0.4305 - mse: 2.9171e-04\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0152 - bpp: 0.4362 - mse: 2.8274e-04\n",
      "Epoch 972: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0152 - bpp: 0.4362 - mse: 2.8274e-04\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0608 - bpp: 0.4432 - mse: 3.0153e-04\n",
      "Epoch 973: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0608 - bpp: 0.4432 - mse: 3.0153e-04\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9745 - bpp: 0.4303 - mse: 2.6573e-04\n",
      "Epoch 974: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9745 - bpp: 0.4303 - mse: 2.6573e-04\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9973 - bpp: 0.4280 - mse: 2.7799e-04\n",
      "Epoch 975: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 0.9973 - bpp: 0.4280 - mse: 2.7799e-04\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0335 - bpp: 0.4332 - mse: 2.9312e-04\n",
      "Epoch 976: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 1.0335 - bpp: 0.4332 - mse: 2.9312e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1363 - bpp: 0.4562 - mse: 3.3211e-04\n",
      "Epoch 977: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1363 - bpp: 0.4562 - mse: 3.3211e-04\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1082 - bpp: 0.4503 - mse: 3.2123e-04\n",
      "Epoch 978: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1082 - bpp: 0.4503 - mse: 3.2123e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0694 - bpp: 0.4454 - mse: 3.0471e-04\n",
      "Epoch 979: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0694 - bpp: 0.4454 - mse: 3.0471e-04\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9938 - bpp: 0.4388 - mse: 2.7100e-04\n",
      "Epoch 980: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 0.9938 - bpp: 0.4388 - mse: 2.7100e-04\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9449 - bpp: 0.4249 - mse: 2.5392e-04\n",
      "Epoch 981: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9449 - bpp: 0.4249 - mse: 2.5392e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0124 - bpp: 0.4331 - mse: 2.8286e-04\n",
      "Epoch 982: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0124 - bpp: 0.4331 - mse: 2.8286e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0090 - bpp: 0.4364 - mse: 2.7959e-04\n",
      "Epoch 983: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0090 - bpp: 0.4364 - mse: 2.7959e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0773 - bpp: 0.4413 - mse: 3.1053e-04\n",
      "Epoch 984: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0773 - bpp: 0.4413 - mse: 3.1053e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0183 - bpp: 0.4366 - mse: 2.8401e-04\n",
      "Epoch 985: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 44s 212ms/step - loss: 1.0183 - bpp: 0.4366 - mse: 2.8401e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9591 - bpp: 0.4320 - mse: 2.5736e-04\n",
      "Epoch 986: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9591 - bpp: 0.4320 - mse: 2.5736e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9898 - bpp: 0.4325 - mse: 2.7215e-04\n",
      "Epoch 987: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9898 - bpp: 0.4325 - mse: 2.7215e-04\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9576 - bpp: 0.4251 - mse: 2.6001e-04\n",
      "Epoch 988: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9576 - bpp: 0.4251 - mse: 2.6001e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9321 - bpp: 0.4279 - mse: 2.4618e-04\n",
      "Epoch 989: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 0.9321 - bpp: 0.4279 - mse: 2.4618e-04\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0111 - bpp: 0.4317 - mse: 2.8292e-04\n",
      "Epoch 990: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0111 - bpp: 0.4317 - mse: 2.8292e-04\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0421 - bpp: 0.4306 - mse: 2.9860e-04\n",
      "Epoch 991: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0421 - bpp: 0.4306 - mse: 2.9860e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9935 - bpp: 0.4321 - mse: 2.7412e-04\n",
      "Epoch 992: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9935 - bpp: 0.4321 - mse: 2.7412e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9385 - bpp: 0.4225 - mse: 2.5196e-04\n",
      "Epoch 993: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9385 - bpp: 0.4225 - mse: 2.5196e-04\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.4368 - mse: 2.8864e-04\n",
      "Epoch 994: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0279 - bpp: 0.4368 - mse: 2.8864e-04\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0193 - bpp: 0.4349 - mse: 2.8534e-04\n",
      "Epoch 995: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0193 - bpp: 0.4349 - mse: 2.8534e-04\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0443 - bpp: 0.4410 - mse: 2.9458e-04\n",
      "Epoch 996: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0443 - bpp: 0.4410 - mse: 2.9458e-04\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0312 - bpp: 0.4333 - mse: 2.9196e-04\n",
      "Epoch 997: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0312 - bpp: 0.4333 - mse: 2.9196e-04\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0174 - bpp: 0.4415 - mse: 2.8124e-04\n",
      "Epoch 998: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0174 - bpp: 0.4415 - mse: 2.8124e-04\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0720 - bpp: 0.4410 - mse: 3.0811e-04\n",
      "Epoch 999: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0720 - bpp: 0.4410 - mse: 3.0811e-04\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9418 - bpp: 0.4275 - mse: 2.5112e-04\n",
      "Epoch 1000: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9418 - bpp: 0.4275 - mse: 2.5112e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0453 - bpp: 0.4344 - mse: 2.9829e-04\n",
      "Epoch 1001: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0453 - bpp: 0.4344 - mse: 2.9829e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9705 - bpp: 0.4287 - mse: 2.6452e-04\n",
      "Epoch 1002: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9705 - bpp: 0.4287 - mse: 2.6452e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9962 - bpp: 0.4284 - mse: 2.7727e-04\n",
      "Epoch 1003: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9962 - bpp: 0.4284 - mse: 2.7727e-04\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1104 - bpp: 0.4511 - mse: 3.2189e-04\n",
      "Epoch 1004: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1104 - bpp: 0.4511 - mse: 3.2189e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0885 - bpp: 0.4493 - mse: 3.1212e-04\n",
      "Epoch 1005: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0885 - bpp: 0.4493 - mse: 3.1212e-04\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9221 - bpp: 0.4186 - mse: 2.4587e-04\n",
      "Epoch 1006: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9221 - bpp: 0.4186 - mse: 2.4587e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0914 - bpp: 0.4407 - mse: 3.1774e-04\n",
      "Epoch 1007: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0914 - bpp: 0.4407 - mse: 3.1774e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0025 - bpp: 0.4373 - mse: 2.7595e-04\n",
      "Epoch 1008: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0025 - bpp: 0.4373 - mse: 2.7595e-04\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0319 - bpp: 0.4467 - mse: 2.8574e-04\n",
      "Epoch 1009: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 44s 213ms/step - loss: 1.0319 - bpp: 0.4467 - mse: 2.8574e-04\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0194 - bpp: 0.4385 - mse: 2.8368e-04\n",
      "Epoch 1010: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0194 - bpp: 0.4385 - mse: 2.8368e-04\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9470 - bpp: 0.4289 - mse: 2.5295e-04\n",
      "Epoch 1011: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9470 - bpp: 0.4289 - mse: 2.5295e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0454 - bpp: 0.4437 - mse: 2.9376e-04\n",
      "Epoch 1012: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0454 - bpp: 0.4437 - mse: 2.9376e-04\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0433 - bpp: 0.4378 - mse: 2.9564e-04\n",
      "Epoch 1013: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0433 - bpp: 0.4378 - mse: 2.9564e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0256 - bpp: 0.4301 - mse: 2.9078e-04\n",
      "Epoch 1014: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0256 - bpp: 0.4301 - mse: 2.9078e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9329 - bpp: 0.4175 - mse: 2.5165e-04\n",
      "Epoch 1015: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 0.9329 - bpp: 0.4175 - mse: 2.5165e-04\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9281 - bpp: 0.4211 - mse: 2.4757e-04\n",
      "Epoch 1016: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9281 - bpp: 0.4211 - mse: 2.4757e-04\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9290 - bpp: 0.4178 - mse: 2.4960e-04\n",
      "Epoch 1017: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9290 - bpp: 0.4178 - mse: 2.4960e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1134 - bpp: 0.4505 - mse: 3.2370e-04\n",
      "Epoch 1018: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1134 - bpp: 0.4505 - mse: 3.2370e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0376 - bpp: 0.4408 - mse: 2.9143e-04\n",
      "Epoch 1019: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0376 - bpp: 0.4408 - mse: 2.9143e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0185 - bpp: 0.4378 - mse: 2.8355e-04\n",
      "Epoch 1020: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.0185 - bpp: 0.4378 - mse: 2.8355e-04\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9895 - bpp: 0.4334 - mse: 2.7150e-04\n",
      "Epoch 1021: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9895 - bpp: 0.4334 - mse: 2.7150e-04\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0679 - bpp: 0.4453 - mse: 3.0398e-04\n",
      "Epoch 1022: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0679 - bpp: 0.4453 - mse: 3.0398e-04\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0498 - bpp: 0.4356 - mse: 2.9989e-04\n",
      "Epoch 1023: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0498 - bpp: 0.4356 - mse: 2.9989e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0008 - bpp: 0.4344 - mse: 2.7656e-04\n",
      "Epoch 1024: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0008 - bpp: 0.4344 - mse: 2.7656e-04\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0207 - bpp: 0.4354 - mse: 2.8578e-04\n",
      "Epoch 1025: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0207 - bpp: 0.4354 - mse: 2.8578e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9915 - bpp: 0.4274 - mse: 2.7542e-04\n",
      "Epoch 1026: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9915 - bpp: 0.4274 - mse: 2.7542e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0213 - bpp: 0.4359 - mse: 2.8583e-04\n",
      "Epoch 1027: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0213 - bpp: 0.4359 - mse: 2.8583e-04\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9987 - bpp: 0.4313 - mse: 2.7702e-04\n",
      "Epoch 1028: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9987 - bpp: 0.4313 - mse: 2.7702e-04\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0113 - bpp: 0.4331 - mse: 2.8233e-04\n",
      "Epoch 1029: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0113 - bpp: 0.4331 - mse: 2.8233e-04\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9056 - bpp: 0.4123 - mse: 2.4084e-04\n",
      "Epoch 1030: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9056 - bpp: 0.4123 - mse: 2.4084e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0416 - bpp: 0.4388 - mse: 2.9434e-04\n",
      "Epoch 1031: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0416 - bpp: 0.4388 - mse: 2.9434e-04\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0529 - bpp: 0.4373 - mse: 3.0059e-04\n",
      "Epoch 1032: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0529 - bpp: 0.4373 - mse: 3.0059e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0561 - bpp: 0.4373 - mse: 3.0215e-04\n",
      "Epoch 1033: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0561 - bpp: 0.4373 - mse: 3.0215e-04\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0758 - bpp: 0.4418 - mse: 3.0961e-04\n",
      "Epoch 1034: loss did not improve from 0.89055\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0758 - bpp: 0.4418 - mse: 3.0961e-04\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8848 - bpp: 0.4174 - mse: 2.2823e-04\n",
      "Epoch 1035: loss improved from 0.89055 to 0.88477, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.8848 - bpp: 0.4174 - mse: 2.2823e-04\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9777 - bpp: 0.4357 - mse: 2.6468e-04\n",
      "Epoch 1036: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9777 - bpp: 0.4357 - mse: 2.6468e-04\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0403 - bpp: 0.4422 - mse: 2.9204e-04\n",
      "Epoch 1037: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0403 - bpp: 0.4422 - mse: 2.9204e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9080 - bpp: 0.4212 - mse: 2.3768e-04\n",
      "Epoch 1038: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9080 - bpp: 0.4212 - mse: 2.3768e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0219 - bpp: 0.4315 - mse: 2.8827e-04\n",
      "Epoch 1039: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0219 - bpp: 0.4315 - mse: 2.8827e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9786 - bpp: 0.4254 - mse: 2.7013e-04\n",
      "Epoch 1040: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9786 - bpp: 0.4254 - mse: 2.7013e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9669 - bpp: 0.4280 - mse: 2.6316e-04\n",
      "Epoch 1041: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9669 - bpp: 0.4280 - mse: 2.6316e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0051 - bpp: 0.4286 - mse: 2.8148e-04\n",
      "Epoch 1042: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0051 - bpp: 0.4286 - mse: 2.8148e-04\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9933 - bpp: 0.4321 - mse: 2.7401e-04\n",
      "Epoch 1043: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9933 - bpp: 0.4321 - mse: 2.7401e-04\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0533 - bpp: 0.4370 - mse: 3.0092e-04\n",
      "Epoch 1044: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0533 - bpp: 0.4370 - mse: 3.0092e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0258 - bpp: 0.4379 - mse: 2.8703e-04\n",
      "Epoch 1045: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0258 - bpp: 0.4379 - mse: 2.8703e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9218 - bpp: 0.4184 - mse: 2.4582e-04\n",
      "Epoch 1046: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9218 - bpp: 0.4184 - mse: 2.4582e-04\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9869 - bpp: 0.4297 - mse: 2.7209e-04\n",
      "Epoch 1047: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9869 - bpp: 0.4297 - mse: 2.7209e-04\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9859 - bpp: 0.4284 - mse: 2.7219e-04\n",
      "Epoch 1048: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9859 - bpp: 0.4284 - mse: 2.7219e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9754 - bpp: 0.4335 - mse: 2.6461e-04\n",
      "Epoch 1049: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9754 - bpp: 0.4335 - mse: 2.6461e-04\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0519 - bpp: 0.4354 - mse: 3.0104e-04\n",
      "Epoch 1050: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0519 - bpp: 0.4354 - mse: 3.0104e-04\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0048 - bpp: 0.4358 - mse: 2.7783e-04\n",
      "Epoch 1051: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0048 - bpp: 0.4358 - mse: 2.7783e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0807 - bpp: 0.4440 - mse: 3.1086e-04\n",
      "Epoch 1052: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0807 - bpp: 0.4440 - mse: 3.1086e-04\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9828 - bpp: 0.4238 - mse: 2.7295e-04\n",
      "Epoch 1053: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 0.9828 - bpp: 0.4238 - mse: 2.7295e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9413 - bpp: 0.4219 - mse: 2.5362e-04\n",
      "Epoch 1054: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9413 - bpp: 0.4219 - mse: 2.5362e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9995 - bpp: 0.4326 - mse: 2.7678e-04\n",
      "Epoch 1055: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9995 - bpp: 0.4326 - mse: 2.7678e-04\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9618 - bpp: 0.4300 - mse: 2.5969e-04\n",
      "Epoch 1056: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9618 - bpp: 0.4300 - mse: 2.5969e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0173 - bpp: 0.4347 - mse: 2.8447e-04\n",
      "Epoch 1057: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.0173 - bpp: 0.4347 - mse: 2.8447e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0181 - bpp: 0.4397 - mse: 2.8238e-04\n",
      "Epoch 1058: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0181 - bpp: 0.4397 - mse: 2.8238e-04\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0282 - bpp: 0.4416 - mse: 2.8646e-04\n",
      "Epoch 1059: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.0282 - bpp: 0.4416 - mse: 2.8646e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9030 - bpp: 0.4161 - mse: 2.3773e-04\n",
      "Epoch 1060: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9030 - bpp: 0.4161 - mse: 2.3773e-04\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9855 - bpp: 0.4280 - mse: 2.7223e-04\n",
      "Epoch 1061: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 0.9855 - bpp: 0.4280 - mse: 2.7223e-04\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0037 - bpp: 0.4335 - mse: 2.7844e-04\n",
      "Epoch 1062: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0037 - bpp: 0.4335 - mse: 2.7844e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9723 - bpp: 0.4298 - mse: 2.6487e-04\n",
      "Epoch 1063: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9723 - bpp: 0.4298 - mse: 2.6487e-04\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0177 - bpp: 0.4381 - mse: 2.8301e-04\n",
      "Epoch 1064: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0177 - bpp: 0.4381 - mse: 2.8301e-04\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9619 - bpp: 0.4265 - mse: 2.6144e-04\n",
      "Epoch 1065: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 222ms/step - loss: 0.9619 - bpp: 0.4265 - mse: 2.6144e-04\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9021 - bpp: 0.4166 - mse: 2.3706e-04\n",
      "Epoch 1066: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9021 - bpp: 0.4166 - mse: 2.3706e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9658 - bpp: 0.4308 - mse: 2.6121e-04\n",
      "Epoch 1067: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.9658 - bpp: 0.4308 - mse: 2.6121e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9961 - bpp: 0.4429 - mse: 2.7015e-04\n",
      "Epoch 1068: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9961 - bpp: 0.4429 - mse: 2.7015e-04\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1360 - bpp: 0.4415 - mse: 3.3908e-04\n",
      "Epoch 1069: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1360 - bpp: 0.4415 - mse: 3.3908e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9183 - bpp: 0.4208 - mse: 2.4291e-04\n",
      "Epoch 1070: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 0.9183 - bpp: 0.4208 - mse: 2.4291e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0056 - bpp: 0.4294 - mse: 2.8138e-04\n",
      "Epoch 1071: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0056 - bpp: 0.4294 - mse: 2.8138e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9839 - bpp: 0.4263 - mse: 2.7226e-04\n",
      "Epoch 1072: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.9839 - bpp: 0.4263 - mse: 2.7226e-04\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9998 - bpp: 0.4311 - mse: 2.7768e-04\n",
      "Epoch 1073: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9998 - bpp: 0.4311 - mse: 2.7768e-04\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0532 - bpp: 0.4369 - mse: 3.0090e-04\n",
      "Epoch 1074: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.0532 - bpp: 0.4369 - mse: 3.0090e-04\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1019 - bpp: 0.4468 - mse: 3.1988e-04\n",
      "Epoch 1075: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1019 - bpp: 0.4468 - mse: 3.1988e-04\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0082 - bpp: 0.4337 - mse: 2.8048e-04\n",
      "Epoch 1076: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0082 - bpp: 0.4337 - mse: 2.8048e-04\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9957 - bpp: 0.4331 - mse: 2.7468e-04\n",
      "Epoch 1077: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9957 - bpp: 0.4331 - mse: 2.7468e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1246 - bpp: 0.4481 - mse: 3.3035e-04\n",
      "Epoch 1078: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 1.1246 - bpp: 0.4481 - mse: 3.3035e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9520 - bpp: 0.4258 - mse: 2.5694e-04\n",
      "Epoch 1079: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9520 - bpp: 0.4258 - mse: 2.5694e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9767 - bpp: 0.4313 - mse: 2.6633e-04\n",
      "Epoch 1080: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9767 - bpp: 0.4313 - mse: 2.6633e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0332 - bpp: 0.4449 - mse: 2.8724e-04\n",
      "Epoch 1081: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0332 - bpp: 0.4449 - mse: 2.8724e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0415 - bpp: 0.4475 - mse: 2.9002e-04\n",
      "Epoch 1082: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0415 - bpp: 0.4475 - mse: 2.9002e-04\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0187 - bpp: 0.4331 - mse: 2.8593e-04\n",
      "Epoch 1083: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0187 - bpp: 0.4331 - mse: 2.8593e-04\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0420 - bpp: 0.4434 - mse: 2.9231e-04\n",
      "Epoch 1084: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0420 - bpp: 0.4434 - mse: 2.9231e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0574 - bpp: 0.4420 - mse: 3.0051e-04\n",
      "Epoch 1085: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0574 - bpp: 0.4420 - mse: 3.0051e-04\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0228 - bpp: 0.4364 - mse: 2.8630e-04\n",
      "Epoch 1086: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0228 - bpp: 0.4364 - mse: 2.8630e-04\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9636 - bpp: 0.4250 - mse: 2.6297e-04\n",
      "Epoch 1087: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9636 - bpp: 0.4250 - mse: 2.6297e-04\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9450 - bpp: 0.4198 - mse: 2.5646e-04\n",
      "Epoch 1088: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9450 - bpp: 0.4198 - mse: 2.5646e-04\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9910 - bpp: 0.4362 - mse: 2.7088e-04\n",
      "Epoch 1089: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9910 - bpp: 0.4362 - mse: 2.7088e-04\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9940 - bpp: 0.4313 - mse: 2.7476e-04\n",
      "Epoch 1090: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9940 - bpp: 0.4313 - mse: 2.7476e-04\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0417 - bpp: 0.4301 - mse: 2.9865e-04\n",
      "Epoch 1091: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0417 - bpp: 0.4301 - mse: 2.9865e-04\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0433 - bpp: 0.4454 - mse: 2.9196e-04\n",
      "Epoch 1092: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0433 - bpp: 0.4454 - mse: 2.9196e-04\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9541 - bpp: 0.4292 - mse: 2.5630e-04\n",
      "Epoch 1093: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9541 - bpp: 0.4292 - mse: 2.5630e-04\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0528 - bpp: 0.4384 - mse: 3.0002e-04\n",
      "Epoch 1094: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0528 - bpp: 0.4384 - mse: 3.0002e-04\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0329 - bpp: 0.4423 - mse: 2.8839e-04\n",
      "Epoch 1095: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.0329 - bpp: 0.4423 - mse: 2.8839e-04\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9725 - bpp: 0.4209 - mse: 2.6933e-04\n",
      "Epoch 1096: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.9725 - bpp: 0.4209 - mse: 2.6933e-04\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9359 - bpp: 0.4198 - mse: 2.5198e-04\n",
      "Epoch 1097: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9359 - bpp: 0.4198 - mse: 2.5198e-04\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9358 - bpp: 0.4210 - mse: 2.5138e-04\n",
      "Epoch 1098: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9358 - bpp: 0.4210 - mse: 2.5138e-04\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9267 - bpp: 0.4146 - mse: 2.5002e-04\n",
      "Epoch 1099: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9267 - bpp: 0.4146 - mse: 2.5002e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0203 - bpp: 0.4412 - mse: 2.8278e-04\n",
      "Epoch 1100: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0203 - bpp: 0.4412 - mse: 2.8278e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9687 - bpp: 0.4225 - mse: 2.6667e-04\n",
      "Epoch 1101: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9687 - bpp: 0.4225 - mse: 2.6667e-04\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9862 - bpp: 0.4205 - mse: 2.7621e-04\n",
      "Epoch 1102: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 0.9862 - bpp: 0.4205 - mse: 2.7621e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9760 - bpp: 0.4298 - mse: 2.6670e-04\n",
      "Epoch 1103: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9760 - bpp: 0.4298 - mse: 2.6670e-04\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0110 - bpp: 0.4323 - mse: 2.8257e-04\n",
      "Epoch 1104: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0110 - bpp: 0.4323 - mse: 2.8257e-04\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0114 - bpp: 0.4374 - mse: 2.8025e-04\n",
      "Epoch 1105: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0114 - bpp: 0.4374 - mse: 2.8025e-04\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9815 - bpp: 0.4325 - mse: 2.6805e-04\n",
      "Epoch 1106: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9815 - bpp: 0.4325 - mse: 2.6805e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9687 - bpp: 0.4271 - mse: 2.6446e-04\n",
      "Epoch 1107: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 210ms/step - loss: 0.9687 - bpp: 0.4271 - mse: 2.6446e-04\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0034 - bpp: 0.4312 - mse: 2.7938e-04\n",
      "Epoch 1108: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0034 - bpp: 0.4312 - mse: 2.7938e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9682 - bpp: 0.4279 - mse: 2.6380e-04\n",
      "Epoch 1109: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9682 - bpp: 0.4279 - mse: 2.6380e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0027 - bpp: 0.4346 - mse: 2.7740e-04\n",
      "Epoch 1110: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0027 - bpp: 0.4346 - mse: 2.7740e-04\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0313 - bpp: 0.4465 - mse: 2.8557e-04\n",
      "Epoch 1111: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0313 - bpp: 0.4465 - mse: 2.8557e-04\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0036 - bpp: 0.4297 - mse: 2.8022e-04\n",
      "Epoch 1112: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0036 - bpp: 0.4297 - mse: 2.8022e-04\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9394 - bpp: 0.4267 - mse: 2.5036e-04\n",
      "Epoch 1113: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9394 - bpp: 0.4267 - mse: 2.5036e-04\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0564 - bpp: 0.4379 - mse: 3.0197e-04\n",
      "Epoch 1114: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0564 - bpp: 0.4379 - mse: 3.0197e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0306 - bpp: 0.4279 - mse: 2.9428e-04\n",
      "Epoch 1115: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0306 - bpp: 0.4279 - mse: 2.9428e-04\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0349 - bpp: 0.4458 - mse: 2.8765e-04\n",
      "Epoch 1116: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0349 - bpp: 0.4458 - mse: 2.8765e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0083 - bpp: 0.4398 - mse: 2.7760e-04\n",
      "Epoch 1117: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0083 - bpp: 0.4398 - mse: 2.7760e-04\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0694 - bpp: 0.4479 - mse: 3.0343e-04\n",
      "Epoch 1118: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0694 - bpp: 0.4479 - mse: 3.0343e-04\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1152 - bpp: 0.4473 - mse: 3.2614e-04\n",
      "Epoch 1119: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1152 - bpp: 0.4473 - mse: 3.2614e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0000 - bpp: 0.4361 - mse: 2.7530e-04\n",
      "Epoch 1120: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0000 - bpp: 0.4361 - mse: 2.7530e-04\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9545 - bpp: 0.4238 - mse: 2.5911e-04\n",
      "Epoch 1121: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9545 - bpp: 0.4238 - mse: 2.5911e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0206 - bpp: 0.4370 - mse: 2.8496e-04\n",
      "Epoch 1122: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0206 - bpp: 0.4370 - mse: 2.8496e-04\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0364 - bpp: 0.4376 - mse: 2.9237e-04\n",
      "Epoch 1123: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0364 - bpp: 0.4376 - mse: 2.9237e-04\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9950 - bpp: 0.4342 - mse: 2.7385e-04\n",
      "Epoch 1124: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9950 - bpp: 0.4342 - mse: 2.7385e-04\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9919 - bpp: 0.4305 - mse: 2.7414e-04\n",
      "Epoch 1125: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9919 - bpp: 0.4305 - mse: 2.7414e-04\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0072 - bpp: 0.4315 - mse: 2.8112e-04\n",
      "Epoch 1126: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0072 - bpp: 0.4315 - mse: 2.8112e-04\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9501 - bpp: 0.4268 - mse: 2.5550e-04\n",
      "Epoch 1127: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9501 - bpp: 0.4268 - mse: 2.5550e-04\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0241 - bpp: 0.4279 - mse: 2.9115e-04\n",
      "Epoch 1128: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0241 - bpp: 0.4279 - mse: 2.9115e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9355 - bpp: 0.4243 - mse: 2.4963e-04\n",
      "Epoch 1129: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.9355 - bpp: 0.4243 - mse: 2.4963e-04\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1123 - bpp: 0.4499 - mse: 3.2349e-04\n",
      "Epoch 1130: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1123 - bpp: 0.4499 - mse: 3.2349e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0793 - bpp: 0.4464 - mse: 3.0904e-04\n",
      "Epoch 1131: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0793 - bpp: 0.4464 - mse: 3.0904e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0515 - bpp: 0.4428 - mse: 2.9721e-04\n",
      "Epoch 1132: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0515 - bpp: 0.4428 - mse: 2.9721e-04\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0130 - bpp: 0.4444 - mse: 2.7762e-04\n",
      "Epoch 1133: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0130 - bpp: 0.4444 - mse: 2.7762e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9209 - bpp: 0.4177 - mse: 2.4566e-04\n",
      "Epoch 1134: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9209 - bpp: 0.4177 - mse: 2.4566e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0318 - bpp: 0.4389 - mse: 2.8953e-04\n",
      "Epoch 1135: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0318 - bpp: 0.4389 - mse: 2.8953e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0149 - bpp: 0.4349 - mse: 2.8319e-04\n",
      "Epoch 1136: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0149 - bpp: 0.4349 - mse: 2.8319e-04\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9561 - bpp: 0.4231 - mse: 2.6026e-04\n",
      "Epoch 1137: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9561 - bpp: 0.4231 - mse: 2.6026e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9513 - bpp: 0.4235 - mse: 2.5772e-04\n",
      "Epoch 1138: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9513 - bpp: 0.4235 - mse: 2.5772e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9712 - bpp: 0.4227 - mse: 2.6780e-04\n",
      "Epoch 1139: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.9712 - bpp: 0.4227 - mse: 2.6780e-04\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0732 - bpp: 0.4427 - mse: 3.0785e-04\n",
      "Epoch 1140: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0732 - bpp: 0.4427 - mse: 3.0785e-04\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9804 - bpp: 0.4271 - mse: 2.7015e-04\n",
      "Epoch 1141: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9804 - bpp: 0.4271 - mse: 2.7015e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9655 - bpp: 0.4187 - mse: 2.6698e-04\n",
      "Epoch 1142: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9655 - bpp: 0.4187 - mse: 2.6698e-04\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0196 - bpp: 0.4395 - mse: 2.8323e-04\n",
      "Epoch 1143: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0196 - bpp: 0.4395 - mse: 2.8323e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9265 - bpp: 0.4146 - mse: 2.4993e-04\n",
      "Epoch 1144: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.9265 - bpp: 0.4146 - mse: 2.4993e-04\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9783 - bpp: 0.4266 - mse: 2.6939e-04\n",
      "Epoch 1145: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9783 - bpp: 0.4266 - mse: 2.6939e-04\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0202 - bpp: 0.4383 - mse: 2.8415e-04\n",
      "Epoch 1146: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0202 - bpp: 0.4383 - mse: 2.8415e-04\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9190 - bpp: 0.4202 - mse: 2.4356e-04\n",
      "Epoch 1147: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9190 - bpp: 0.4202 - mse: 2.4356e-04\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9391 - bpp: 0.4179 - mse: 2.5447e-04\n",
      "Epoch 1148: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9391 - bpp: 0.4179 - mse: 2.5447e-04\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0301 - bpp: 0.4336 - mse: 2.9122e-04\n",
      "Epoch 1149: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0301 - bpp: 0.4336 - mse: 2.9122e-04\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9674 - bpp: 0.4277 - mse: 2.6349e-04\n",
      "Epoch 1150: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 0.9674 - bpp: 0.4277 - mse: 2.6349e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9022 - bpp: 0.4188 - mse: 2.3606e-04\n",
      "Epoch 1151: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9022 - bpp: 0.4188 - mse: 2.3606e-04\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0798 - bpp: 0.4361 - mse: 3.1429e-04\n",
      "Epoch 1152: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0798 - bpp: 0.4361 - mse: 3.1429e-04\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0974 - bpp: 0.4507 - mse: 3.1577e-04\n",
      "Epoch 1153: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.0974 - bpp: 0.4507 - mse: 3.1577e-04\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9836 - bpp: 0.4229 - mse: 2.7377e-04\n",
      "Epoch 1154: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9836 - bpp: 0.4229 - mse: 2.7377e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9930 - bpp: 0.4267 - mse: 2.7653e-04\n",
      "Epoch 1155: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.9930 - bpp: 0.4267 - mse: 2.7653e-04\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9973 - bpp: 0.4257 - mse: 2.7914e-04\n",
      "Epoch 1156: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9973 - bpp: 0.4257 - mse: 2.7914e-04\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0348 - bpp: 0.4396 - mse: 2.9062e-04\n",
      "Epoch 1157: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0348 - bpp: 0.4396 - mse: 2.9062e-04\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0409 - bpp: 0.4396 - mse: 2.9360e-04\n",
      "Epoch 1158: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0409 - bpp: 0.4396 - mse: 2.9360e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9730 - bpp: 0.4330 - mse: 2.6363e-04\n",
      "Epoch 1159: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.9730 - bpp: 0.4330 - mse: 2.6363e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9708 - bpp: 0.4210 - mse: 2.6842e-04\n",
      "Epoch 1160: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.9708 - bpp: 0.4210 - mse: 2.6842e-04\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9584 - bpp: 0.4306 - mse: 2.5770e-04\n",
      "Epoch 1161: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9584 - bpp: 0.4306 - mse: 2.5770e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1133 - bpp: 0.4524 - mse: 3.2271e-04\n",
      "Epoch 1162: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1133 - bpp: 0.4524 - mse: 3.2271e-04\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9300 - bpp: 0.4187 - mse: 2.4964e-04\n",
      "Epoch 1163: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9300 - bpp: 0.4187 - mse: 2.4964e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0995 - bpp: 0.4415 - mse: 3.2129e-04\n",
      "Epoch 1164: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0995 - bpp: 0.4415 - mse: 3.2129e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0226 - bpp: 0.4363 - mse: 2.8628e-04\n",
      "Epoch 1165: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.0226 - bpp: 0.4363 - mse: 2.8628e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0205 - bpp: 0.4351 - mse: 2.8586e-04\n",
      "Epoch 1166: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0205 - bpp: 0.4351 - mse: 2.8586e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9700 - bpp: 0.4331 - mse: 2.6214e-04\n",
      "Epoch 1167: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9700 - bpp: 0.4331 - mse: 2.6214e-04\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9443 - bpp: 0.4200 - mse: 2.5602e-04\n",
      "Epoch 1168: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9443 - bpp: 0.4200 - mse: 2.5602e-04\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9785 - bpp: 0.4333 - mse: 2.6621e-04\n",
      "Epoch 1169: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.9785 - bpp: 0.4333 - mse: 2.6621e-04\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9774 - bpp: 0.4325 - mse: 2.6603e-04\n",
      "Epoch 1170: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.9774 - bpp: 0.4325 - mse: 2.6603e-04\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9132 - bpp: 0.4200 - mse: 2.4081e-04\n",
      "Epoch 1171: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.9132 - bpp: 0.4200 - mse: 2.4081e-04\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0241 - bpp: 0.4321 - mse: 2.8903e-04\n",
      "Epoch 1172: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.0241 - bpp: 0.4321 - mse: 2.8903e-04\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9628 - bpp: 0.4300 - mse: 2.6015e-04\n",
      "Epoch 1173: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9628 - bpp: 0.4300 - mse: 2.6015e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9642 - bpp: 0.4271 - mse: 2.6227e-04\n",
      "Epoch 1174: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.9642 - bpp: 0.4271 - mse: 2.6227e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0437 - bpp: 0.4416 - mse: 2.9402e-04\n",
      "Epoch 1175: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0437 - bpp: 0.4416 - mse: 2.9402e-04\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0218 - bpp: 0.4348 - mse: 2.8664e-04\n",
      "Epoch 1176: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0218 - bpp: 0.4348 - mse: 2.8664e-04\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9887 - bpp: 0.4268 - mse: 2.7437e-04\n",
      "Epoch 1177: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 0.9887 - bpp: 0.4268 - mse: 2.7437e-04\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9150 - bpp: 0.4168 - mse: 2.4326e-04\n",
      "Epoch 1178: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9150 - bpp: 0.4168 - mse: 2.4326e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0979 - bpp: 0.4497 - mse: 3.1652e-04\n",
      "Epoch 1179: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.0979 - bpp: 0.4497 - mse: 3.1652e-04\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0307 - bpp: 0.4386 - mse: 2.8911e-04\n",
      "Epoch 1180: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0307 - bpp: 0.4386 - mse: 2.8911e-04\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.4415 - mse: 3.0170e-04\n",
      "Epoch 1181: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0594 - bpp: 0.4415 - mse: 3.0170e-04\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9386 - bpp: 0.4223 - mse: 2.5212e-04\n",
      "Epoch 1182: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 0.9386 - bpp: 0.4223 - mse: 2.5212e-04\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9721 - bpp: 0.4250 - mse: 2.6714e-04\n",
      "Epoch 1183: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9721 - bpp: 0.4250 - mse: 2.6714e-04\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0864 - bpp: 0.4448 - mse: 3.1331e-04\n",
      "Epoch 1184: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0864 - bpp: 0.4448 - mse: 3.1331e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9842 - bpp: 0.4331 - mse: 2.6911e-04\n",
      "Epoch 1185: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9842 - bpp: 0.4331 - mse: 2.6911e-04\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0804 - bpp: 0.4456 - mse: 3.0995e-04\n",
      "Epoch 1186: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0804 - bpp: 0.4456 - mse: 3.0995e-04\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9209 - bpp: 0.4192 - mse: 2.4496e-04\n",
      "Epoch 1187: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.9209 - bpp: 0.4192 - mse: 2.4496e-04\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0700 - bpp: 0.4413 - mse: 3.0697e-04\n",
      "Epoch 1188: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0700 - bpp: 0.4413 - mse: 3.0697e-04\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9042 - bpp: 0.4197 - mse: 2.3654e-04\n",
      "Epoch 1189: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9042 - bpp: 0.4197 - mse: 2.3654e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9369 - bpp: 0.4256 - mse: 2.4964e-04\n",
      "Epoch 1190: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9369 - bpp: 0.4256 - mse: 2.4964e-04\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9726 - bpp: 0.4265 - mse: 2.6665e-04\n",
      "Epoch 1191: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 0.9726 - bpp: 0.4265 - mse: 2.6665e-04\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9748 - bpp: 0.4262 - mse: 2.6787e-04\n",
      "Epoch 1192: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9748 - bpp: 0.4262 - mse: 2.6787e-04\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9696 - bpp: 0.4217 - mse: 2.6750e-04\n",
      "Epoch 1193: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.9696 - bpp: 0.4217 - mse: 2.6750e-04\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9504 - bpp: 0.4300 - mse: 2.5411e-04\n",
      "Epoch 1194: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9504 - bpp: 0.4300 - mse: 2.5411e-04\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9674 - bpp: 0.4214 - mse: 2.6661e-04\n",
      "Epoch 1195: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9674 - bpp: 0.4214 - mse: 2.6661e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9120 - bpp: 0.4217 - mse: 2.3944e-04\n",
      "Epoch 1196: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9120 - bpp: 0.4217 - mse: 2.3944e-04\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9885 - bpp: 0.4285 - mse: 2.7344e-04\n",
      "Epoch 1197: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9885 - bpp: 0.4285 - mse: 2.7344e-04\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0415 - bpp: 0.4400 - mse: 2.9368e-04\n",
      "Epoch 1198: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0415 - bpp: 0.4400 - mse: 2.9368e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0530 - bpp: 0.4446 - mse: 2.9707e-04\n",
      "Epoch 1199: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0530 - bpp: 0.4446 - mse: 2.9707e-04\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9790 - bpp: 0.4268 - mse: 2.6965e-04\n",
      "Epoch 1200: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9790 - bpp: 0.4268 - mse: 2.6965e-04\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0173 - bpp: 0.4369 - mse: 2.8337e-04\n",
      "Epoch 1201: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0173 - bpp: 0.4369 - mse: 2.8337e-04\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1357 - bpp: 0.4520 - mse: 3.3382e-04\n",
      "Epoch 1202: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1357 - bpp: 0.4520 - mse: 3.3382e-04\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9790 - bpp: 0.4250 - mse: 2.7051e-04\n",
      "Epoch 1203: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9790 - bpp: 0.4250 - mse: 2.7051e-04\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9885 - bpp: 0.4262 - mse: 2.7455e-04\n",
      "Epoch 1204: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 0.9885 - bpp: 0.4262 - mse: 2.7455e-04\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9916 - bpp: 0.4269 - mse: 2.7574e-04\n",
      "Epoch 1205: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9916 - bpp: 0.4269 - mse: 2.7574e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1973 - bpp: 0.4579 - mse: 3.6103e-04\n",
      "Epoch 1206: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1973 - bpp: 0.4579 - mse: 3.6103e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0037 - bpp: 0.4365 - mse: 2.7696e-04\n",
      "Epoch 1207: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.0037 - bpp: 0.4365 - mse: 2.7696e-04\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0063 - bpp: 0.4345 - mse: 2.7922e-04\n",
      "Epoch 1208: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0063 - bpp: 0.4345 - mse: 2.7922e-04\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1480 - bpp: 0.4576 - mse: 3.3710e-04\n",
      "Epoch 1209: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1480 - bpp: 0.4576 - mse: 3.3710e-04\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0900 - bpp: 0.4495 - mse: 3.1270e-04\n",
      "Epoch 1210: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0900 - bpp: 0.4495 - mse: 3.1270e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0043 - bpp: 0.4383 - mse: 2.7639e-04\n",
      "Epoch 1211: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0043 - bpp: 0.4383 - mse: 2.7639e-04\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9243 - bpp: 0.4165 - mse: 2.4793e-04\n",
      "Epoch 1212: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9243 - bpp: 0.4165 - mse: 2.4793e-04\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9849 - bpp: 0.4269 - mse: 2.7248e-04\n",
      "Epoch 1213: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9849 - bpp: 0.4269 - mse: 2.7248e-04\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9518 - bpp: 0.4256 - mse: 2.5694e-04\n",
      "Epoch 1214: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.9518 - bpp: 0.4256 - mse: 2.5694e-04\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0470 - bpp: 0.4438 - mse: 2.9454e-04\n",
      "Epoch 1215: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0470 - bpp: 0.4438 - mse: 2.9454e-04\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9845 - bpp: 0.4401 - mse: 2.6584e-04\n",
      "Epoch 1216: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9845 - bpp: 0.4401 - mse: 2.6584e-04\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9654 - bpp: 0.4265 - mse: 2.6313e-04\n",
      "Epoch 1217: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 0.9654 - bpp: 0.4265 - mse: 2.6313e-04\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9971 - bpp: 0.4343 - mse: 2.7484e-04\n",
      "Epoch 1218: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9971 - bpp: 0.4343 - mse: 2.7484e-04\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0648 - bpp: 0.4399 - mse: 3.0513e-04\n",
      "Epoch 1219: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0648 - bpp: 0.4399 - mse: 3.0513e-04\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9539 - bpp: 0.4301 - mse: 2.5576e-04\n",
      "Epoch 1220: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9539 - bpp: 0.4301 - mse: 2.5576e-04\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9103 - bpp: 0.4057 - mse: 2.4639e-04\n",
      "Epoch 1221: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9103 - bpp: 0.4057 - mse: 2.4639e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0402 - bpp: 0.4425 - mse: 2.9185e-04\n",
      "Epoch 1222: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0402 - bpp: 0.4425 - mse: 2.9185e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9827 - bpp: 0.4308 - mse: 2.6950e-04\n",
      "Epoch 1223: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9827 - bpp: 0.4308 - mse: 2.6950e-04\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0241 - bpp: 0.4320 - mse: 2.8908e-04\n",
      "Epoch 1224: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0241 - bpp: 0.4320 - mse: 2.8908e-04\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9589 - bpp: 0.4257 - mse: 2.6034e-04\n",
      "Epoch 1225: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9589 - bpp: 0.4257 - mse: 2.6034e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9431 - bpp: 0.4260 - mse: 2.5250e-04\n",
      "Epoch 1226: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9431 - bpp: 0.4260 - mse: 2.5250e-04\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9747 - bpp: 0.4296 - mse: 2.6618e-04\n",
      "Epoch 1227: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9747 - bpp: 0.4296 - mse: 2.6618e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9917 - bpp: 0.4343 - mse: 2.7216e-04\n",
      "Epoch 1228: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9917 - bpp: 0.4343 - mse: 2.7216e-04\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9594 - bpp: 0.4224 - mse: 2.6223e-04\n",
      "Epoch 1229: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.9594 - bpp: 0.4224 - mse: 2.6223e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9476 - bpp: 0.4238 - mse: 2.5575e-04\n",
      "Epoch 1230: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9476 - bpp: 0.4238 - mse: 2.5575e-04\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0274 - bpp: 0.4404 - mse: 2.8662e-04\n",
      "Epoch 1231: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0274 - bpp: 0.4404 - mse: 2.8662e-04\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9670 - bpp: 0.4295 - mse: 2.6245e-04\n",
      "Epoch 1232: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9670 - bpp: 0.4295 - mse: 2.6245e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9909 - bpp: 0.4354 - mse: 2.7125e-04\n",
      "Epoch 1233: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9909 - bpp: 0.4354 - mse: 2.7125e-04\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0465 - bpp: 0.4378 - mse: 2.9724e-04\n",
      "Epoch 1234: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.0465 - bpp: 0.4378 - mse: 2.9724e-04\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0266 - bpp: 0.4337 - mse: 2.8951e-04\n",
      "Epoch 1235: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0266 - bpp: 0.4337 - mse: 2.8951e-04\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9834 - bpp: 0.4351 - mse: 2.6775e-04\n",
      "Epoch 1236: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9834 - bpp: 0.4351 - mse: 2.6775e-04\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9631 - bpp: 0.4238 - mse: 2.6334e-04\n",
      "Epoch 1237: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9631 - bpp: 0.4238 - mse: 2.6334e-04\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9008 - bpp: 0.4187 - mse: 2.3536e-04\n",
      "Epoch 1238: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9008 - bpp: 0.4187 - mse: 2.3536e-04\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0052 - bpp: 0.4314 - mse: 2.8022e-04\n",
      "Epoch 1239: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0052 - bpp: 0.4314 - mse: 2.8022e-04\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9658 - bpp: 0.4265 - mse: 2.6337e-04\n",
      "Epoch 1240: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9658 - bpp: 0.4265 - mse: 2.6337e-04\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1335 - bpp: 0.4564 - mse: 3.3062e-04\n",
      "Epoch 1241: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1335 - bpp: 0.4564 - mse: 3.3062e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0444 - bpp: 0.4323 - mse: 2.9889e-04\n",
      "Epoch 1242: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0444 - bpp: 0.4323 - mse: 2.9889e-04\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9418 - bpp: 0.4277 - mse: 2.5101e-04\n",
      "Epoch 1243: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9418 - bpp: 0.4277 - mse: 2.5101e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.4359 - mse: 2.8935e-04\n",
      "Epoch 1244: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0285 - bpp: 0.4359 - mse: 2.8935e-04\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9607 - bpp: 0.4248 - mse: 2.6169e-04\n",
      "Epoch 1245: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9607 - bpp: 0.4248 - mse: 2.6169e-04\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0374 - bpp: 0.4336 - mse: 2.9482e-04\n",
      "Epoch 1246: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.0374 - bpp: 0.4336 - mse: 2.9482e-04\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0144 - bpp: 0.4288 - mse: 2.8590e-04\n",
      "Epoch 1247: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0144 - bpp: 0.4288 - mse: 2.8590e-04\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0320 - bpp: 0.4401 - mse: 2.8902e-04\n",
      "Epoch 1248: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0320 - bpp: 0.4401 - mse: 2.8902e-04\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9529 - bpp: 0.4265 - mse: 2.5705e-04\n",
      "Epoch 1249: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 0.9529 - bpp: 0.4265 - mse: 2.5705e-04\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0160 - bpp: 0.4403 - mse: 2.8113e-04\n",
      "Epoch 1250: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0160 - bpp: 0.4403 - mse: 2.8113e-04\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9762 - bpp: 0.4238 - mse: 2.6972e-04\n",
      "Epoch 1251: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.9762 - bpp: 0.4238 - mse: 2.6972e-04\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9765 - bpp: 0.4265 - mse: 2.6858e-04\n",
      "Epoch 1252: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.9765 - bpp: 0.4265 - mse: 2.6858e-04\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0395 - bpp: 0.4326 - mse: 2.9634e-04\n",
      "Epoch 1253: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.0395 - bpp: 0.4326 - mse: 2.9634e-04\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0006 - bpp: 0.4371 - mse: 2.7512e-04\n",
      "Epoch 1254: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0006 - bpp: 0.4371 - mse: 2.7512e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9741 - bpp: 0.4317 - mse: 2.6483e-04\n",
      "Epoch 1255: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9741 - bpp: 0.4317 - mse: 2.6483e-04\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9741 - bpp: 0.4239 - mse: 2.6866e-04\n",
      "Epoch 1256: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9741 - bpp: 0.4239 - mse: 2.6866e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9967 - bpp: 0.4277 - mse: 2.7785e-04\n",
      "Epoch 1257: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9967 - bpp: 0.4277 - mse: 2.7785e-04\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9571 - bpp: 0.4227 - mse: 2.6092e-04\n",
      "Epoch 1258: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9571 - bpp: 0.4227 - mse: 2.6092e-04\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0685 - bpp: 0.4436 - mse: 3.0512e-04\n",
      "Epoch 1259: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0685 - bpp: 0.4436 - mse: 3.0512e-04\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0451 - bpp: 0.4414 - mse: 2.9480e-04\n",
      "Epoch 1260: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0451 - bpp: 0.4414 - mse: 2.9480e-04\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0407 - bpp: 0.4391 - mse: 2.9375e-04\n",
      "Epoch 1261: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0407 - bpp: 0.4391 - mse: 2.9375e-04\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0469 - bpp: 0.4367 - mse: 2.9797e-04\n",
      "Epoch 1262: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.0469 - bpp: 0.4367 - mse: 2.9797e-04\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0001 - bpp: 0.4345 - mse: 2.7619e-04\n",
      "Epoch 1263: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.0001 - bpp: 0.4345 - mse: 2.7619e-04\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9293 - bpp: 0.4183 - mse: 2.4952e-04\n",
      "Epoch 1264: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9293 - bpp: 0.4183 - mse: 2.4952e-04\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9477 - bpp: 0.4274 - mse: 2.5407e-04\n",
      "Epoch 1265: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9477 - bpp: 0.4274 - mse: 2.5407e-04\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9268 - bpp: 0.4188 - mse: 2.4807e-04\n",
      "Epoch 1266: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.9268 - bpp: 0.4188 - mse: 2.4807e-04\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0458 - bpp: 0.4397 - mse: 2.9592e-04\n",
      "Epoch 1267: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0458 - bpp: 0.4397 - mse: 2.9592e-04\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0706 - bpp: 0.4489 - mse: 3.0354e-04\n",
      "Epoch 1268: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0706 - bpp: 0.4489 - mse: 3.0354e-04\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9126 - bpp: 0.4220 - mse: 2.3958e-04\n",
      "Epoch 1269: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9126 - bpp: 0.4220 - mse: 2.3958e-04\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9279 - bpp: 0.4276 - mse: 2.4431e-04\n",
      "Epoch 1270: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 0.9279 - bpp: 0.4276 - mse: 2.4431e-04\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0308 - bpp: 0.4370 - mse: 2.8995e-04\n",
      "Epoch 1271: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0308 - bpp: 0.4370 - mse: 2.8995e-04\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0202 - bpp: 0.4315 - mse: 2.8748e-04\n",
      "Epoch 1272: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0202 - bpp: 0.4315 - mse: 2.8748e-04\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9580 - bpp: 0.4227 - mse: 2.6136e-04\n",
      "Epoch 1273: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9580 - bpp: 0.4227 - mse: 2.6136e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9216 - bpp: 0.4158 - mse: 2.4694e-04\n",
      "Epoch 1274: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9216 - bpp: 0.4158 - mse: 2.4694e-04\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9428 - bpp: 0.4241 - mse: 2.5324e-04\n",
      "Epoch 1275: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9428 - bpp: 0.4241 - mse: 2.5324e-04\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9763 - bpp: 0.4270 - mse: 2.6822e-04\n",
      "Epoch 1276: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9763 - bpp: 0.4270 - mse: 2.6822e-04\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9955 - bpp: 0.4349 - mse: 2.7373e-04\n",
      "Epoch 1277: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9955 - bpp: 0.4349 - mse: 2.7373e-04\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9303 - bpp: 0.4227 - mse: 2.4785e-04\n",
      "Epoch 1278: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9303 - bpp: 0.4227 - mse: 2.4785e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9735 - bpp: 0.4275 - mse: 2.6658e-04\n",
      "Epoch 1279: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9735 - bpp: 0.4275 - mse: 2.6658e-04\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0122 - bpp: 0.4361 - mse: 2.8130e-04\n",
      "Epoch 1280: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0122 - bpp: 0.4361 - mse: 2.8130e-04\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0729 - bpp: 0.4455 - mse: 3.0632e-04\n",
      "Epoch 1281: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0729 - bpp: 0.4455 - mse: 3.0632e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0328 - bpp: 0.4283 - mse: 2.9517e-04\n",
      "Epoch 1282: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0328 - bpp: 0.4283 - mse: 2.9517e-04\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0035 - bpp: 0.4347 - mse: 2.7773e-04\n",
      "Epoch 1283: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0035 - bpp: 0.4347 - mse: 2.7773e-04\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0122 - bpp: 0.4329 - mse: 2.8288e-04\n",
      "Epoch 1284: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0122 - bpp: 0.4329 - mse: 2.8288e-04\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0464 - bpp: 0.4425 - mse: 2.9487e-04\n",
      "Epoch 1285: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 210ms/step - loss: 1.0464 - bpp: 0.4425 - mse: 2.9487e-04\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9741 - bpp: 0.4345 - mse: 2.6346e-04\n",
      "Epoch 1286: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.9741 - bpp: 0.4345 - mse: 2.6346e-04\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9856 - bpp: 0.4364 - mse: 2.6815e-04\n",
      "Epoch 1287: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9856 - bpp: 0.4364 - mse: 2.6815e-04\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0176 - bpp: 0.4333 - mse: 2.8529e-04\n",
      "Epoch 1288: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0176 - bpp: 0.4333 - mse: 2.8529e-04\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.4392 - mse: 2.8714e-04\n",
      "Epoch 1289: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0273 - bpp: 0.4392 - mse: 2.8714e-04\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9393 - bpp: 0.4260 - mse: 2.5065e-04\n",
      "Epoch 1290: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 0.9393 - bpp: 0.4260 - mse: 2.5065e-04\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0240 - bpp: 0.4386 - mse: 2.8585e-04\n",
      "Epoch 1291: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0240 - bpp: 0.4386 - mse: 2.8585e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0603 - bpp: 0.4352 - mse: 3.0521e-04\n",
      "Epoch 1292: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0603 - bpp: 0.4352 - mse: 3.0521e-04\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9569 - bpp: 0.4235 - mse: 2.6042e-04\n",
      "Epoch 1293: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9569 - bpp: 0.4235 - mse: 2.6042e-04\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9274 - bpp: 0.4199 - mse: 2.4783e-04\n",
      "Epoch 1294: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9274 - bpp: 0.4199 - mse: 2.4783e-04\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9613 - bpp: 0.4257 - mse: 2.6154e-04\n",
      "Epoch 1295: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9613 - bpp: 0.4257 - mse: 2.6154e-04\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9989 - bpp: 0.4321 - mse: 2.7674e-04\n",
      "Epoch 1296: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.9989 - bpp: 0.4321 - mse: 2.7674e-04\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0531 - bpp: 0.4454 - mse: 2.9673e-04\n",
      "Epoch 1297: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0531 - bpp: 0.4454 - mse: 2.9673e-04\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9594 - bpp: 0.4289 - mse: 2.5906e-04\n",
      "Epoch 1298: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9594 - bpp: 0.4289 - mse: 2.5906e-04\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9987 - bpp: 0.4433 - mse: 2.7120e-04\n",
      "Epoch 1299: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9987 - bpp: 0.4433 - mse: 2.7120e-04\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9850 - bpp: 0.4425 - mse: 2.6488e-04\n",
      "Epoch 1300: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.9850 - bpp: 0.4425 - mse: 2.6488e-04\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9299 - bpp: 0.4146 - mse: 2.5165e-04\n",
      "Epoch 1301: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.9299 - bpp: 0.4146 - mse: 2.5165e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0381 - bpp: 0.4400 - mse: 2.9205e-04\n",
      "Epoch 1302: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0381 - bpp: 0.4400 - mse: 2.9205e-04\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9992 - bpp: 0.4343 - mse: 2.7582e-04\n",
      "Epoch 1303: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.9992 - bpp: 0.4343 - mse: 2.7582e-04\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0754 - bpp: 0.4470 - mse: 3.0682e-04\n",
      "Epoch 1304: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0754 - bpp: 0.4470 - mse: 3.0682e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9086 - bpp: 0.4195 - mse: 2.3882e-04\n",
      "Epoch 1305: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9086 - bpp: 0.4195 - mse: 2.3882e-04\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0616 - bpp: 0.4318 - mse: 3.0754e-04\n",
      "Epoch 1306: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.0616 - bpp: 0.4318 - mse: 3.0754e-04\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0511 - bpp: 0.4412 - mse: 2.9782e-04\n",
      "Epoch 1307: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0511 - bpp: 0.4412 - mse: 2.9782e-04\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9350 - bpp: 0.4201 - mse: 2.5141e-04\n",
      "Epoch 1308: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9350 - bpp: 0.4201 - mse: 2.5141e-04\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.4365 - mse: 2.8633e-04\n",
      "Epoch 1309: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0229 - bpp: 0.4365 - mse: 2.8633e-04\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0951 - bpp: 0.4375 - mse: 3.2110e-04\n",
      "Epoch 1310: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0951 - bpp: 0.4375 - mse: 3.2110e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0096 - bpp: 0.4382 - mse: 2.7897e-04\n",
      "Epoch 1311: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0096 - bpp: 0.4382 - mse: 2.7897e-04\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1019 - bpp: 0.4474 - mse: 3.1960e-04\n",
      "Epoch 1312: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1019 - bpp: 0.4474 - mse: 3.1960e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9538 - bpp: 0.4318 - mse: 2.5490e-04\n",
      "Epoch 1313: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9538 - bpp: 0.4318 - mse: 2.5490e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9835 - bpp: 0.4289 - mse: 2.7078e-04\n",
      "Epoch 1314: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9835 - bpp: 0.4289 - mse: 2.7078e-04\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0621 - bpp: 0.4372 - mse: 3.0515e-04\n",
      "Epoch 1315: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0621 - bpp: 0.4372 - mse: 3.0515e-04\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9970 - bpp: 0.4308 - mse: 2.7646e-04\n",
      "Epoch 1316: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9970 - bpp: 0.4308 - mse: 2.7646e-04\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0326 - bpp: 0.4393 - mse: 2.8971e-04\n",
      "Epoch 1317: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0326 - bpp: 0.4393 - mse: 2.8971e-04\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0036 - bpp: 0.4374 - mse: 2.7647e-04\n",
      "Epoch 1318: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0036 - bpp: 0.4374 - mse: 2.7647e-04\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0742 - bpp: 0.4426 - mse: 3.0839e-04\n",
      "Epoch 1319: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0742 - bpp: 0.4426 - mse: 3.0839e-04\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9446 - bpp: 0.4286 - mse: 2.5193e-04\n",
      "Epoch 1320: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9446 - bpp: 0.4286 - mse: 2.5193e-04\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9158 - bpp: 0.4208 - mse: 2.4172e-04\n",
      "Epoch 1321: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9158 - bpp: 0.4208 - mse: 2.4172e-04\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9938 - bpp: 0.4372 - mse: 2.7174e-04\n",
      "Epoch 1322: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9938 - bpp: 0.4372 - mse: 2.7174e-04\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0593 - bpp: 0.4500 - mse: 2.9751e-04\n",
      "Epoch 1323: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0593 - bpp: 0.4500 - mse: 2.9751e-04\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0330 - bpp: 0.4421 - mse: 2.8854e-04\n",
      "Epoch 1324: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0330 - bpp: 0.4421 - mse: 2.8854e-04\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9856 - bpp: 0.4306 - mse: 2.7097e-04\n",
      "Epoch 1325: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9856 - bpp: 0.4306 - mse: 2.7097e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9354 - bpp: 0.4290 - mse: 2.4727e-04\n",
      "Epoch 1326: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9354 - bpp: 0.4290 - mse: 2.4727e-04\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0603 - bpp: 0.4415 - mse: 3.0213e-04\n",
      "Epoch 1327: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0603 - bpp: 0.4415 - mse: 3.0213e-04\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9249 - bpp: 0.4222 - mse: 2.4548e-04\n",
      "Epoch 1328: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9249 - bpp: 0.4222 - mse: 2.4548e-04\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9557 - bpp: 0.4196 - mse: 2.6174e-04\n",
      "Epoch 1329: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9557 - bpp: 0.4196 - mse: 2.6174e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9991 - bpp: 0.4366 - mse: 2.7467e-04\n",
      "Epoch 1330: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9991 - bpp: 0.4366 - mse: 2.7467e-04\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0948 - bpp: 0.4436 - mse: 3.1794e-04\n",
      "Epoch 1331: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0948 - bpp: 0.4436 - mse: 3.1794e-04\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9834 - bpp: 0.4369 - mse: 2.6687e-04\n",
      "Epoch 1332: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 214ms/step - loss: 0.9834 - bpp: 0.4369 - mse: 2.6687e-04\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0437 - bpp: 0.4451 - mse: 2.9232e-04\n",
      "Epoch 1333: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.0437 - bpp: 0.4451 - mse: 2.9232e-04\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0967 - bpp: 0.4352 - mse: 3.2302e-04\n",
      "Epoch 1334: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0967 - bpp: 0.4352 - mse: 3.2302e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0051 - bpp: 0.4396 - mse: 2.7612e-04\n",
      "Epoch 1335: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0051 - bpp: 0.4396 - mse: 2.7612e-04\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0669 - bpp: 0.4478 - mse: 3.0230e-04\n",
      "Epoch 1336: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0669 - bpp: 0.4478 - mse: 3.0230e-04\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9358 - bpp: 0.4261 - mse: 2.4890e-04\n",
      "Epoch 1337: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9358 - bpp: 0.4261 - mse: 2.4890e-04\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9860 - bpp: 0.4377 - mse: 2.6774e-04\n",
      "Epoch 1338: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 0.9860 - bpp: 0.4377 - mse: 2.6774e-04\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0977 - bpp: 0.4494 - mse: 3.1654e-04\n",
      "Epoch 1339: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0977 - bpp: 0.4494 - mse: 3.1654e-04\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.4372 - mse: 2.8871e-04\n",
      "Epoch 1340: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.0285 - bpp: 0.4372 - mse: 2.8871e-04\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9705 - bpp: 0.4336 - mse: 2.6212e-04\n",
      "Epoch 1341: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9705 - bpp: 0.4336 - mse: 2.6212e-04\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0987 - bpp: 0.4573 - mse: 3.1320e-04\n",
      "Epoch 1342: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0987 - bpp: 0.4573 - mse: 3.1320e-04\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0139 - bpp: 0.4336 - mse: 2.8337e-04\n",
      "Epoch 1343: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0139 - bpp: 0.4336 - mse: 2.8337e-04\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1384 - bpp: 0.4569 - mse: 3.3276e-04\n",
      "Epoch 1344: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 1.1384 - bpp: 0.4569 - mse: 3.3276e-04\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8956 - bpp: 0.4216 - mse: 2.3143e-04\n",
      "Epoch 1345: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.8956 - bpp: 0.4216 - mse: 2.3143e-04\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9639 - bpp: 0.4307 - mse: 2.6035e-04\n",
      "Epoch 1346: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.9639 - bpp: 0.4307 - mse: 2.6035e-04\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9752 - bpp: 0.4265 - mse: 2.6793e-04\n",
      "Epoch 1347: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 0.9752 - bpp: 0.4265 - mse: 2.6793e-04\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1334 - bpp: 0.4583 - mse: 3.2962e-04\n",
      "Epoch 1348: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1334 - bpp: 0.4583 - mse: 3.2962e-04\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0440 - bpp: 0.4402 - mse: 2.9483e-04\n",
      "Epoch 1349: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0440 - bpp: 0.4402 - mse: 2.9483e-04\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9165 - bpp: 0.4140 - mse: 2.4534e-04\n",
      "Epoch 1350: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 0.9165 - bpp: 0.4140 - mse: 2.4534e-04\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0018 - bpp: 0.4348 - mse: 2.7685e-04\n",
      "Epoch 1351: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0018 - bpp: 0.4348 - mse: 2.7685e-04\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0325 - bpp: 0.4358 - mse: 2.9136e-04\n",
      "Epoch 1352: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0325 - bpp: 0.4358 - mse: 2.9136e-04\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9022 - bpp: 0.4212 - mse: 2.3484e-04\n",
      "Epoch 1353: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.9022 - bpp: 0.4212 - mse: 2.3484e-04\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0465 - bpp: 0.4384 - mse: 2.9693e-04\n",
      "Epoch 1354: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0465 - bpp: 0.4384 - mse: 2.9693e-04\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9861 - bpp: 0.4334 - mse: 2.6986e-04\n",
      "Epoch 1355: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 0.9861 - bpp: 0.4334 - mse: 2.6986e-04\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9246 - bpp: 0.4245 - mse: 2.4417e-04\n",
      "Epoch 1356: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9246 - bpp: 0.4245 - mse: 2.4417e-04\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0384 - bpp: 0.4385 - mse: 2.9291e-04\n",
      "Epoch 1357: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0384 - bpp: 0.4385 - mse: 2.9291e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0635 - bpp: 0.4469 - mse: 3.0107e-04\n",
      "Epoch 1358: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0635 - bpp: 0.4469 - mse: 3.0107e-04\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9835 - bpp: 0.4273 - mse: 2.7156e-04\n",
      "Epoch 1359: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.9835 - bpp: 0.4273 - mse: 2.7156e-04\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9034 - bpp: 0.4186 - mse: 2.3672e-04\n",
      "Epoch 1360: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9034 - bpp: 0.4186 - mse: 2.3672e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0897 - bpp: 0.4437 - mse: 3.1544e-04\n",
      "Epoch 1361: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0897 - bpp: 0.4437 - mse: 3.1544e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9869 - bpp: 0.4385 - mse: 2.6778e-04\n",
      "Epoch 1362: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 0.9869 - bpp: 0.4385 - mse: 2.6778e-04\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9420 - bpp: 0.4273 - mse: 2.5134e-04\n",
      "Epoch 1363: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9420 - bpp: 0.4273 - mse: 2.5134e-04\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0606 - bpp: 0.4408 - mse: 3.0266e-04\n",
      "Epoch 1364: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.0606 - bpp: 0.4408 - mse: 3.0266e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9664 - bpp: 0.4255 - mse: 2.6411e-04\n",
      "Epoch 1365: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9664 - bpp: 0.4255 - mse: 2.6411e-04\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9676 - bpp: 0.4309 - mse: 2.6207e-04\n",
      "Epoch 1366: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9676 - bpp: 0.4309 - mse: 2.6207e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0472 - bpp: 0.4278 - mse: 3.0247e-04\n",
      "Epoch 1367: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0472 - bpp: 0.4278 - mse: 3.0247e-04\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9115 - bpp: 0.4161 - mse: 2.4188e-04\n",
      "Epoch 1368: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 0.9115 - bpp: 0.4161 - mse: 2.4188e-04\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9184 - bpp: 0.4220 - mse: 2.4238e-04\n",
      "Epoch 1369: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.9184 - bpp: 0.4220 - mse: 2.4238e-04\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0872 - bpp: 0.4532 - mse: 3.0958e-04\n",
      "Epoch 1370: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0872 - bpp: 0.4532 - mse: 3.0958e-04\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0700 - bpp: 0.4456 - mse: 3.0487e-04\n",
      "Epoch 1371: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0700 - bpp: 0.4456 - mse: 3.0487e-04\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0738 - bpp: 0.4408 - mse: 3.0909e-04\n",
      "Epoch 1372: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0738 - bpp: 0.4408 - mse: 3.0909e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0087 - bpp: 0.4352 - mse: 2.8003e-04\n",
      "Epoch 1373: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0087 - bpp: 0.4352 - mse: 2.8003e-04\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0013 - bpp: 0.4336 - mse: 2.7722e-04\n",
      "Epoch 1374: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0013 - bpp: 0.4336 - mse: 2.7722e-04\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9654 - bpp: 0.4322 - mse: 2.6033e-04\n",
      "Epoch 1375: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9654 - bpp: 0.4322 - mse: 2.6033e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0045 - bpp: 0.4364 - mse: 2.7738e-04\n",
      "Epoch 1376: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0045 - bpp: 0.4364 - mse: 2.7738e-04\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9866 - bpp: 0.4274 - mse: 2.7308e-04\n",
      "Epoch 1377: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9866 - bpp: 0.4274 - mse: 2.7308e-04\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0337 - bpp: 0.4379 - mse: 2.9089e-04\n",
      "Epoch 1378: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0337 - bpp: 0.4379 - mse: 2.9089e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1205 - bpp: 0.4547 - mse: 3.2511e-04\n",
      "Epoch 1379: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1205 - bpp: 0.4547 - mse: 3.2511e-04\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0407 - bpp: 0.4352 - mse: 2.9563e-04\n",
      "Epoch 1380: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0407 - bpp: 0.4352 - mse: 2.9563e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9206 - bpp: 0.4219 - mse: 2.4350e-04\n",
      "Epoch 1381: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9206 - bpp: 0.4219 - mse: 2.4350e-04\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0182 - bpp: 0.4361 - mse: 2.8421e-04\n",
      "Epoch 1382: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.0182 - bpp: 0.4361 - mse: 2.8421e-04\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9662 - bpp: 0.4318 - mse: 2.6096e-04\n",
      "Epoch 1383: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9662 - bpp: 0.4318 - mse: 2.6096e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9813 - bpp: 0.4318 - mse: 2.6833e-04\n",
      "Epoch 1384: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9813 - bpp: 0.4318 - mse: 2.6833e-04\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9634 - bpp: 0.4295 - mse: 2.6068e-04\n",
      "Epoch 1385: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9634 - bpp: 0.4295 - mse: 2.6068e-04\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9179 - bpp: 0.4156 - mse: 2.4525e-04\n",
      "Epoch 1386: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9179 - bpp: 0.4156 - mse: 2.4525e-04\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9839 - bpp: 0.4281 - mse: 2.7139e-04\n",
      "Epoch 1387: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.9839 - bpp: 0.4281 - mse: 2.7139e-04\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0729 - bpp: 0.4448 - mse: 3.0670e-04\n",
      "Epoch 1388: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0729 - bpp: 0.4448 - mse: 3.0670e-04\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9855 - bpp: 0.4350 - mse: 2.6878e-04\n",
      "Epoch 1389: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9855 - bpp: 0.4350 - mse: 2.6878e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9943 - bpp: 0.4292 - mse: 2.7595e-04\n",
      "Epoch 1390: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.9943 - bpp: 0.4292 - mse: 2.7595e-04\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0161 - bpp: 0.4276 - mse: 2.8733e-04\n",
      "Epoch 1391: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0161 - bpp: 0.4276 - mse: 2.8733e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0388 - bpp: 0.4421 - mse: 2.9135e-04\n",
      "Epoch 1392: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0388 - bpp: 0.4421 - mse: 2.9135e-04\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0433 - bpp: 0.4390 - mse: 2.9506e-04\n",
      "Epoch 1393: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0433 - bpp: 0.4390 - mse: 2.9506e-04\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0702 - bpp: 0.4359 - mse: 3.0970e-04\n",
      "Epoch 1394: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0702 - bpp: 0.4359 - mse: 3.0970e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9890 - bpp: 0.4221 - mse: 2.7680e-04\n",
      "Epoch 1395: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9890 - bpp: 0.4221 - mse: 2.7680e-04\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0144 - bpp: 0.4389 - mse: 2.8098e-04\n",
      "Epoch 1396: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0144 - bpp: 0.4389 - mse: 2.8098e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9250 - bpp: 0.4229 - mse: 2.4518e-04\n",
      "Epoch 1397: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9250 - bpp: 0.4229 - mse: 2.4518e-04\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8900 - bpp: 0.4203 - mse: 2.2936e-04\n",
      "Epoch 1398: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.8900 - bpp: 0.4203 - mse: 2.2936e-04\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0319 - bpp: 0.4401 - mse: 2.8897e-04\n",
      "Epoch 1399: loss did not improve from 0.88477\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0319 - bpp: 0.4401 - mse: 2.8897e-04\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8781 - bpp: 0.4080 - mse: 2.2955e-04\n",
      "Epoch 1400: loss improved from 0.88477 to 0.87809, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.8781 - bpp: 0.4080 - mse: 2.2955e-04\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0715 - bpp: 0.4403 - mse: 3.0821e-04\n",
      "Epoch 1401: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0715 - bpp: 0.4403 - mse: 3.0821e-04\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9482 - bpp: 0.4228 - mse: 2.5657e-04\n",
      "Epoch 1402: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.9482 - bpp: 0.4228 - mse: 2.5657e-04\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0054 - bpp: 0.4302 - mse: 2.8088e-04\n",
      "Epoch 1403: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 1.0054 - bpp: 0.4302 - mse: 2.8088e-04\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1661 - bpp: 0.4516 - mse: 3.4886e-04\n",
      "Epoch 1404: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 1.1661 - bpp: 0.4516 - mse: 3.4886e-04\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9496 - bpp: 0.4230 - mse: 2.5713e-04\n",
      "Epoch 1405: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 0.9496 - bpp: 0.4230 - mse: 2.5713e-04\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9774 - bpp: 0.4293 - mse: 2.6761e-04\n",
      "Epoch 1406: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9774 - bpp: 0.4293 - mse: 2.6761e-04\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9878 - bpp: 0.4248 - mse: 2.7490e-04\n",
      "Epoch 1407: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 0.9878 - bpp: 0.4248 - mse: 2.7490e-04\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0291 - bpp: 0.4444 - mse: 2.8549e-04\n",
      "Epoch 1408: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0291 - bpp: 0.4444 - mse: 2.8549e-04\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9481 - bpp: 0.4268 - mse: 2.5457e-04\n",
      "Epoch 1409: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9481 - bpp: 0.4268 - mse: 2.5457e-04\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0546 - bpp: 0.4476 - mse: 2.9637e-04\n",
      "Epoch 1410: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0546 - bpp: 0.4476 - mse: 2.9637e-04\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9847 - bpp: 0.4390 - mse: 2.6645e-04\n",
      "Epoch 1411: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.9847 - bpp: 0.4390 - mse: 2.6645e-04\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1216 - bpp: 0.4516 - mse: 3.2713e-04\n",
      "Epoch 1412: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1216 - bpp: 0.4516 - mse: 3.2713e-04\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9481 - bpp: 0.4279 - mse: 2.5398e-04\n",
      "Epoch 1413: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9481 - bpp: 0.4279 - mse: 2.5398e-04\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.4332 - mse: 2.8794e-04\n",
      "Epoch 1414: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0229 - bpp: 0.4332 - mse: 2.8794e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0005 - bpp: 0.4372 - mse: 2.7506e-04\n",
      "Epoch 1415: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.0005 - bpp: 0.4372 - mse: 2.7506e-04\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0764 - bpp: 0.4425 - mse: 3.0953e-04\n",
      "Epoch 1416: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0764 - bpp: 0.4425 - mse: 3.0953e-04\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9802 - bpp: 0.4359 - mse: 2.6577e-04\n",
      "Epoch 1417: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9802 - bpp: 0.4359 - mse: 2.6577e-04\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9416 - bpp: 0.4240 - mse: 2.5275e-04\n",
      "Epoch 1418: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9416 - bpp: 0.4240 - mse: 2.5275e-04\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9873 - bpp: 0.4422 - mse: 2.6616e-04\n",
      "Epoch 1419: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 0.9873 - bpp: 0.4422 - mse: 2.6616e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9796 - bpp: 0.4288 - mse: 2.6894e-04\n",
      "Epoch 1420: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 0.9796 - bpp: 0.4288 - mse: 2.6894e-04\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0499 - bpp: 0.4450 - mse: 2.9539e-04\n",
      "Epoch 1421: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0499 - bpp: 0.4450 - mse: 2.9539e-04\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0157 - bpp: 0.4385 - mse: 2.8180e-04\n",
      "Epoch 1422: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0157 - bpp: 0.4385 - mse: 2.8180e-04\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9163 - bpp: 0.4172 - mse: 2.4368e-04\n",
      "Epoch 1423: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9163 - bpp: 0.4172 - mse: 2.4368e-04\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9809 - bpp: 0.4346 - mse: 2.6671e-04\n",
      "Epoch 1424: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9809 - bpp: 0.4346 - mse: 2.6671e-04\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0415 - bpp: 0.4456 - mse: 2.9095e-04\n",
      "Epoch 1425: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.0415 - bpp: 0.4456 - mse: 2.9095e-04\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8990 - bpp: 0.4192 - mse: 2.3431e-04\n",
      "Epoch 1426: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 0.8990 - bpp: 0.4192 - mse: 2.3431e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9431 - bpp: 0.4220 - mse: 2.5441e-04\n",
      "Epoch 1427: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.9431 - bpp: 0.4220 - mse: 2.5441e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0151 - bpp: 0.4449 - mse: 2.7846e-04\n",
      "Epoch 1428: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0151 - bpp: 0.4449 - mse: 2.7846e-04\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9345 - bpp: 0.4202 - mse: 2.5112e-04\n",
      "Epoch 1429: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 0.9345 - bpp: 0.4202 - mse: 2.5112e-04\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9230 - bpp: 0.4221 - mse: 2.4455e-04\n",
      "Epoch 1430: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 0.9230 - bpp: 0.4221 - mse: 2.4455e-04\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9909 - bpp: 0.4343 - mse: 2.7176e-04\n",
      "Epoch 1431: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9909 - bpp: 0.4343 - mse: 2.7176e-04\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9715 - bpp: 0.4303 - mse: 2.6426e-04\n",
      "Epoch 1432: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.9715 - bpp: 0.4303 - mse: 2.6426e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9536 - bpp: 0.4228 - mse: 2.5917e-04\n",
      "Epoch 1433: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.9536 - bpp: 0.4228 - mse: 2.5917e-04\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9312 - bpp: 0.4245 - mse: 2.4742e-04\n",
      "Epoch 1434: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 0.9312 - bpp: 0.4245 - mse: 2.4742e-04\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9565 - bpp: 0.4216 - mse: 2.6116e-04\n",
      "Epoch 1435: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.9565 - bpp: 0.4216 - mse: 2.6116e-04\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9775 - bpp: 0.4292 - mse: 2.6771e-04\n",
      "Epoch 1436: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 0.9775 - bpp: 0.4292 - mse: 2.6771e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0532 - bpp: 0.4440 - mse: 2.9745e-04\n",
      "Epoch 1437: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0532 - bpp: 0.4440 - mse: 2.9745e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9980 - bpp: 0.4334 - mse: 2.7567e-04\n",
      "Epoch 1438: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.9980 - bpp: 0.4334 - mse: 2.7567e-04\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0451 - bpp: 0.4405 - mse: 2.9519e-04\n",
      "Epoch 1439: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0451 - bpp: 0.4405 - mse: 2.9519e-04\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0117 - bpp: 0.4354 - mse: 2.8140e-04\n",
      "Epoch 1440: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.0117 - bpp: 0.4354 - mse: 2.8140e-04\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0465 - bpp: 0.4375 - mse: 2.9736e-04\n",
      "Epoch 1441: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0465 - bpp: 0.4375 - mse: 2.9736e-04\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0772 - bpp: 0.4519 - mse: 3.0532e-04\n",
      "Epoch 1442: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0772 - bpp: 0.4519 - mse: 3.0532e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0328 - bpp: 0.4427 - mse: 2.8815e-04\n",
      "Epoch 1443: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.0328 - bpp: 0.4427 - mse: 2.8815e-04\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0562 - bpp: 0.4471 - mse: 2.9741e-04\n",
      "Epoch 1444: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0562 - bpp: 0.4471 - mse: 2.9741e-04\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0433 - bpp: 0.4436 - mse: 2.9280e-04\n",
      "Epoch 1445: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0433 - bpp: 0.4436 - mse: 2.9280e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0361 - bpp: 0.4423 - mse: 2.8997e-04\n",
      "Epoch 1446: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0361 - bpp: 0.4423 - mse: 2.8997e-04\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9835 - bpp: 0.4303 - mse: 2.7009e-04\n",
      "Epoch 1447: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9835 - bpp: 0.4303 - mse: 2.7009e-04\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9828 - bpp: 0.4305 - mse: 2.6965e-04\n",
      "Epoch 1448: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 0.9828 - bpp: 0.4305 - mse: 2.6965e-04\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9683 - bpp: 0.4234 - mse: 2.6607e-04\n",
      "Epoch 1449: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 222ms/step - loss: 0.9683 - bpp: 0.4234 - mse: 2.6607e-04\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0292 - bpp: 0.4395 - mse: 2.8793e-04\n",
      "Epoch 1450: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0292 - bpp: 0.4395 - mse: 2.8793e-04\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0335 - bpp: 0.4347 - mse: 2.9240e-04\n",
      "Epoch 1451: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.0335 - bpp: 0.4347 - mse: 2.9240e-04\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0039 - bpp: 0.4365 - mse: 2.7703e-04\n",
      "Epoch 1452: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0039 - bpp: 0.4365 - mse: 2.7703e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9179 - bpp: 0.4214 - mse: 2.4246e-04\n",
      "Epoch 1453: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9179 - bpp: 0.4214 - mse: 2.4246e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9959 - bpp: 0.4301 - mse: 2.7626e-04\n",
      "Epoch 1454: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 0.9959 - bpp: 0.4301 - mse: 2.7626e-04\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9690 - bpp: 0.4283 - mse: 2.6402e-04\n",
      "Epoch 1455: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 0.9690 - bpp: 0.4283 - mse: 2.6402e-04\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9170 - bpp: 0.4204 - mse: 2.4249e-04\n",
      "Epoch 1456: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9170 - bpp: 0.4204 - mse: 2.4249e-04\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1254 - bpp: 0.4471 - mse: 3.3116e-04\n",
      "Epoch 1457: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.1254 - bpp: 0.4471 - mse: 3.3116e-04\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0083 - bpp: 0.4354 - mse: 2.7974e-04\n",
      "Epoch 1458: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.0083 - bpp: 0.4354 - mse: 2.7974e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9688 - bpp: 0.4284 - mse: 2.6383e-04\n",
      "Epoch 1459: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.9688 - bpp: 0.4284 - mse: 2.6383e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9888 - bpp: 0.4344 - mse: 2.7072e-04\n",
      "Epoch 1460: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 0.9888 - bpp: 0.4344 - mse: 2.7072e-04\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9721 - bpp: 0.4334 - mse: 2.6303e-04\n",
      "Epoch 1461: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 0.9721 - bpp: 0.4334 - mse: 2.6303e-04\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9317 - bpp: 0.4224 - mse: 2.4868e-04\n",
      "Epoch 1462: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.9317 - bpp: 0.4224 - mse: 2.4868e-04\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0592 - bpp: 0.4388 - mse: 3.0289e-04\n",
      "Epoch 1463: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0592 - bpp: 0.4388 - mse: 3.0289e-04\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9180 - bpp: 0.4166 - mse: 2.4483e-04\n",
      "Epoch 1464: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 0.9180 - bpp: 0.4166 - mse: 2.4483e-04\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0083 - bpp: 0.4387 - mse: 2.7813e-04\n",
      "Epoch 1465: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0083 - bpp: 0.4387 - mse: 2.7813e-04\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0459 - bpp: 0.4330 - mse: 2.9928e-04\n",
      "Epoch 1466: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0459 - bpp: 0.4330 - mse: 2.9928e-04\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9329 - bpp: 0.4236 - mse: 2.4865e-04\n",
      "Epoch 1467: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.9329 - bpp: 0.4236 - mse: 2.4865e-04\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9735 - bpp: 0.4275 - mse: 2.6659e-04\n",
      "Epoch 1468: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9735 - bpp: 0.4275 - mse: 2.6659e-04\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8946 - bpp: 0.4176 - mse: 2.3293e-04\n",
      "Epoch 1469: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 0.8946 - bpp: 0.4176 - mse: 2.3293e-04\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0109 - bpp: 0.4314 - mse: 2.8298e-04\n",
      "Epoch 1470: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0109 - bpp: 0.4314 - mse: 2.8298e-04\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0870 - bpp: 0.4461 - mse: 3.1293e-04\n",
      "Epoch 1471: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0870 - bpp: 0.4461 - mse: 3.1293e-04\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0757 - bpp: 0.4421 - mse: 3.0937e-04\n",
      "Epoch 1472: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0757 - bpp: 0.4421 - mse: 3.0937e-04\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9714 - bpp: 0.4340 - mse: 2.6242e-04\n",
      "Epoch 1473: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.9714 - bpp: 0.4340 - mse: 2.6242e-04\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0043 - bpp: 0.4323 - mse: 2.7927e-04\n",
      "Epoch 1474: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0043 - bpp: 0.4323 - mse: 2.7927e-04\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9569 - bpp: 0.4272 - mse: 2.5865e-04\n",
      "Epoch 1475: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.9569 - bpp: 0.4272 - mse: 2.5865e-04\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0503 - bpp: 0.4359 - mse: 2.9999e-04\n",
      "Epoch 1476: loss did not improve from 0.87809\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0503 - bpp: 0.4359 - mse: 2.9999e-04\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8414 - bpp: 0.4054 - mse: 2.1286e-04\n",
      "Epoch 1477: loss improved from 0.87809 to 0.84137, saving model to checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 0.8414 - bpp: 0.4054 - mse: 2.1286e-04\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9855 - bpp: 0.4339 - mse: 2.6934e-04\n",
      "Epoch 1478: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 0.9855 - bpp: 0.4339 - mse: 2.6934e-04\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0191 - bpp: 0.4406 - mse: 2.8243e-04\n",
      "Epoch 1479: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 1.0191 - bpp: 0.4406 - mse: 2.8243e-04\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0035 - bpp: 0.4344 - mse: 2.7790e-04\n",
      "Epoch 1480: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.0035 - bpp: 0.4344 - mse: 2.7790e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9671 - bpp: 0.4371 - mse: 2.5880e-04\n",
      "Epoch 1481: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9671 - bpp: 0.4371 - mse: 2.5880e-04\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9111 - bpp: 0.4104 - mse: 2.4447e-04\n",
      "Epoch 1482: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.9111 - bpp: 0.4104 - mse: 2.4447e-04\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9383 - bpp: 0.4226 - mse: 2.5181e-04\n",
      "Epoch 1483: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 0.9383 - bpp: 0.4226 - mse: 2.5181e-04\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0840 - bpp: 0.4465 - mse: 3.1128e-04\n",
      "Epoch 1484: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 1.0840 - bpp: 0.4465 - mse: 3.1128e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0266 - bpp: 0.4394 - mse: 2.8670e-04\n",
      "Epoch 1485: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0266 - bpp: 0.4394 - mse: 2.8670e-04\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0212 - bpp: 0.4344 - mse: 2.8654e-04\n",
      "Epoch 1486: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0212 - bpp: 0.4344 - mse: 2.8654e-04\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0136 - bpp: 0.4295 - mse: 2.8521e-04\n",
      "Epoch 1487: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0136 - bpp: 0.4295 - mse: 2.8521e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9753 - bpp: 0.4306 - mse: 2.6599e-04\n",
      "Epoch 1488: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9753 - bpp: 0.4306 - mse: 2.6599e-04\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0035 - bpp: 0.4324 - mse: 2.7882e-04\n",
      "Epoch 1489: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.0035 - bpp: 0.4324 - mse: 2.7882e-04\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9981 - bpp: 0.4367 - mse: 2.7410e-04\n",
      "Epoch 1490: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.9981 - bpp: 0.4367 - mse: 2.7410e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9070 - bpp: 0.4229 - mse: 2.3638e-04\n",
      "Epoch 1491: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 0.9070 - bpp: 0.4229 - mse: 2.3638e-04\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9918 - bpp: 0.4294 - mse: 2.7461e-04\n",
      "Epoch 1492: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 0.9918 - bpp: 0.4294 - mse: 2.7461e-04\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0023 - bpp: 0.4317 - mse: 2.7861e-04\n",
      "Epoch 1493: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.0023 - bpp: 0.4317 - mse: 2.7861e-04\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9598 - bpp: 0.4270 - mse: 2.6014e-04\n",
      "Epoch 1494: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 0.9598 - bpp: 0.4270 - mse: 2.6014e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1077 - bpp: 0.4486 - mse: 3.2183e-04\n",
      "Epoch 1495: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.1077 - bpp: 0.4486 - mse: 3.2183e-04\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9196 - bpp: 0.4242 - mse: 2.4190e-04\n",
      "Epoch 1496: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9196 - bpp: 0.4242 - mse: 2.4190e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0715 - bpp: 0.4454 - mse: 3.0571e-04\n",
      "Epoch 1497: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 1.0715 - bpp: 0.4454 - mse: 3.0571e-04\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9525 - bpp: 0.4306 - mse: 2.5482e-04\n",
      "Epoch 1498: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 0.9525 - bpp: 0.4306 - mse: 2.5482e-04\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0704 - bpp: 0.4553 - mse: 3.0035e-04\n",
      "Epoch 1499: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 1.0704 - bpp: 0.4553 - mse: 3.0035e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9843 - bpp: 0.4279 - mse: 2.7166e-04\n",
      "Epoch 1500: loss did not improve from 0.84137\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.9843 - bpp: 0.4279 - mse: 2.7166e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_layer_call_fn, optical_flow_loss_layer_call_and_return_conditional_losses, dwt_layer_call_fn, dwt_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_2048_epcs_1500_I_QP_27_240x240_CosineDecay_20220502-201745/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_11 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_11.compile()\n",
    "trainer_11.fit()\n",
    "trainer_11.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 68.6722 - bpp: 5.3060 - mse: 0.0155\n",
      "Epoch 1: loss improved from inf to 68.67219, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 72s 181ms/step - loss: 68.6722 - bpp: 5.3060 - mse: 0.0155\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4483 - bpp: 5.1678 - mse: 0.0028\n",
      "Epoch 2: loss improved from 68.67219 to 16.44827, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 16.4483 - bpp: 5.1678 - mse: 0.0028\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2616 - bpp: 5.0324 - mse: 0.0020\n",
      "Epoch 3: loss improved from 16.44827 to 13.26156, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 13.2616 - bpp: 5.0324 - mse: 0.0020\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.1388 - bpp: 4.8998 - mse: 0.0015\n",
      "Epoch 4: loss improved from 13.26156 to 11.13884, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 11.1388 - bpp: 4.8998 - mse: 0.0015\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8837 - bpp: 4.7697 - mse: 0.0015\n",
      "Epoch 5: loss improved from 11.13884 to 10.88369, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 10.8837 - bpp: 4.7697 - mse: 0.0015\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.8961 - bpp: 4.6425 - mse: 0.0018\n",
      "Epoch 6: loss did not improve from 10.88369\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 11.8961 - bpp: 4.6425 - mse: 0.0018\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.3413 - bpp: 4.5195 - mse: 0.0012\n",
      "Epoch 7: loss improved from 10.88369 to 9.34128, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 9.3413 - bpp: 4.5195 - mse: 0.0012\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8791 - bpp: 4.3968 - mse: 0.0011\n",
      "Epoch 8: loss improved from 9.34128 to 8.87912, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 8.8791 - bpp: 4.3968 - mse: 0.0011\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0440 - bpp: 4.2754 - mse: 9.2007e-04\n",
      "Epoch 9: loss improved from 8.87912 to 8.04403, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 8.0440 - bpp: 4.2754 - mse: 9.2007e-04\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1708 - bpp: 4.1569 - mse: 7.3582e-04\n",
      "Epoch 10: loss improved from 8.04403 to 7.17080, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 7.1708 - bpp: 4.1569 - mse: 7.3582e-04\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6383 - bpp: 4.0401 - mse: 6.3432e-04\n",
      "Epoch 11: loss improved from 7.17080 to 6.63829, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 6.6383 - bpp: 4.0401 - mse: 6.3432e-04\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6571 - bpp: 3.9269 - mse: 6.6655e-04\n",
      "Epoch 12: loss did not improve from 6.63829\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 6.6571 - bpp: 3.9269 - mse: 6.6655e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2806 - bpp: 3.8154 - mse: 6.0185e-04\n",
      "Epoch 13: loss improved from 6.63829 to 6.28056, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 6.2806 - bpp: 3.8154 - mse: 6.0185e-04\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1429 - bpp: 3.7069 - mse: 5.9473e-04\n",
      "Epoch 14: loss improved from 6.28056 to 6.14291, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 6.1429 - bpp: 3.7069 - mse: 5.9473e-04\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7683 - bpp: 3.6018 - mse: 5.2893e-04\n",
      "Epoch 15: loss improved from 6.14291 to 5.76829, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 5.7683 - bpp: 3.6018 - mse: 5.2893e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3768 - bpp: 3.4964 - mse: 4.5908e-04\n",
      "Epoch 16: loss improved from 5.76829 to 5.37680, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 5.3768 - bpp: 3.4964 - mse: 4.5908e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0867 - bpp: 3.3929 - mse: 4.1351e-04\n",
      "Epoch 17: loss improved from 5.37680 to 5.08666, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 5.0867 - bpp: 3.3929 - mse: 4.1351e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2815 - bpp: 3.2973 - mse: 4.8443e-04\n",
      "Epoch 18: loss did not improve from 5.08666\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 5.2815 - bpp: 3.2973 - mse: 4.8443e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2253 - bpp: 3.2048 - mse: 4.9329e-04\n",
      "Epoch 19: loss did not improve from 5.08666\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 5.2253 - bpp: 3.2048 - mse: 4.9329e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9643 - bpp: 3.1093 - mse: 4.5289e-04\n",
      "Epoch 20: loss improved from 5.08666 to 4.96429, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 4.9643 - bpp: 3.1093 - mse: 4.5289e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7777 - bpp: 3.0132 - mse: 4.3080e-04\n",
      "Epoch 21: loss improved from 4.96429 to 4.77772, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 4.7777 - bpp: 3.0132 - mse: 4.3080e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2561 - bpp: 2.9193 - mse: 3.2638e-04\n",
      "Epoch 22: loss improved from 4.77772 to 4.25615, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 4.2561 - bpp: 2.9193 - mse: 3.2638e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3743 - bpp: 2.8367 - mse: 3.7539e-04\n",
      "Epoch 23: loss did not improve from 4.25615\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 4.3743 - bpp: 2.8367 - mse: 3.7539e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4358 - bpp: 2.7650 - mse: 4.0791e-04\n",
      "Epoch 24: loss did not improve from 4.25615\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 4.4358 - bpp: 2.7650 - mse: 4.0791e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1213 - bpp: 2.6740 - mse: 3.5334e-04\n",
      "Epoch 25: loss improved from 4.25615 to 4.12131, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 4.1213 - bpp: 2.6740 - mse: 3.5334e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.9064 - bpp: 2.6247 - mse: 0.0030\n",
      "Epoch 26: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 14.9064 - bpp: 2.6247 - mse: 0.0030\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3356 - bpp: 2.5724 - mse: 0.0019\n",
      "Epoch 27: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 10.3356 - bpp: 2.5724 - mse: 0.0019\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0001 - bpp: 2.4587 - mse: 6.2047e-04\n",
      "Epoch 28: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 5.0001 - bpp: 2.4587 - mse: 6.2047e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5003 - bpp: 2.3863 - mse: 5.1611e-04\n",
      "Epoch 29: loss did not improve from 4.12131\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 4.5003 - bpp: 2.3863 - mse: 5.1611e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8097 - bpp: 2.2884 - mse: 3.7142e-04\n",
      "Epoch 30: loss improved from 4.12131 to 3.80973, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 3.8097 - bpp: 2.2884 - mse: 3.7142e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1226 - bpp: 2.2370 - mse: 4.6035e-04\n",
      "Epoch 31: loss did not improve from 3.80973\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 4.1226 - bpp: 2.2370 - mse: 4.6035e-04\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7824 - bpp: 2.1723 - mse: 3.9309e-04\n",
      "Epoch 32: loss improved from 3.80973 to 3.78237, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 3.7824 - bpp: 2.1723 - mse: 3.9309e-04\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6854 - bpp: 2.1054 - mse: 3.8576e-04\n",
      "Epoch 33: loss improved from 3.78237 to 3.68542, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 3.6854 - bpp: 2.1054 - mse: 3.8576e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7362 - bpp: 2.0504 - mse: 4.1156e-04\n",
      "Epoch 34: loss did not improve from 3.68542\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 3.7362 - bpp: 2.0504 - mse: 4.1156e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2624 - bpp: 1.9788 - mse: 3.1339e-04\n",
      "Epoch 35: loss improved from 3.68542 to 3.26242, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 3.2624 - bpp: 1.9788 - mse: 3.1339e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2211 - bpp: 1.9124 - mse: 3.1949e-04\n",
      "Epoch 36: loss improved from 3.26242 to 3.22107, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 3.2211 - bpp: 1.9124 - mse: 3.1949e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2101 - bpp: 1.8677 - mse: 3.2775e-04\n",
      "Epoch 37: loss improved from 3.22107 to 3.21012, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 3.2101 - bpp: 1.8677 - mse: 3.2775e-04\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0177 - bpp: 1.7997 - mse: 2.9735e-04\n",
      "Epoch 38: loss improved from 3.21012 to 3.01767, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.0177 - bpp: 1.7997 - mse: 2.9735e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8902 - bpp: 1.7485 - mse: 2.7872e-04\n",
      "Epoch 39: loss improved from 3.01767 to 2.89015, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.8902 - bpp: 1.7485 - mse: 2.7872e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8006 - bpp: 1.6941 - mse: 2.7014e-04\n",
      "Epoch 40: loss improved from 2.89015 to 2.80061, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 198ms/step - loss: 2.8006 - bpp: 1.6941 - mse: 2.7014e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8044 - bpp: 1.6470 - mse: 2.8257e-04\n",
      "Epoch 41: loss did not improve from 2.80061\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.8044 - bpp: 1.6470 - mse: 2.8257e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7494 - bpp: 1.6065 - mse: 2.7902e-04\n",
      "Epoch 42: loss improved from 2.80061 to 2.74939, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.7494 - bpp: 1.6065 - mse: 2.7902e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6235 - bpp: 1.5552 - mse: 2.6081e-04\n",
      "Epoch 43: loss improved from 2.74939 to 2.62347, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.6235 - bpp: 1.5552 - mse: 2.6081e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6555 - bpp: 1.5094 - mse: 2.7982e-04\n",
      "Epoch 44: loss did not improve from 2.62347\n",
      "200/200 [==============================] - 37s 180ms/step - loss: 2.6555 - bpp: 1.5094 - mse: 2.7982e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5936 - bpp: 1.4893 - mse: 2.6961e-04\n",
      "Epoch 45: loss improved from 2.62347 to 2.59363, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.5936 - bpp: 1.4893 - mse: 2.6961e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6515 - bpp: 1.4837 - mse: 2.8511e-04\n",
      "Epoch 46: loss did not improve from 2.59363\n",
      "200/200 [==============================] - 36s 175ms/step - loss: 2.6515 - bpp: 1.4837 - mse: 2.8511e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7061 - bpp: 1.4343 - mse: 3.1052e-04\n",
      "Epoch 47: loss did not improve from 2.59363\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 2.7061 - bpp: 1.4343 - mse: 3.1052e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7228 - bpp: 1.4258 - mse: 3.1666e-04\n",
      "Epoch 48: loss did not improve from 2.59363\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 2.7228 - bpp: 1.4258 - mse: 3.1666e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5242 - bpp: 1.3692 - mse: 2.8197e-04\n",
      "Epoch 49: loss improved from 2.59363 to 2.52417, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.5242 - bpp: 1.3692 - mse: 2.8197e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5347 - bpp: 1.3254 - mse: 2.9525e-04\n",
      "Epoch 50: loss did not improve from 2.52417\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 2.5347 - bpp: 1.3254 - mse: 2.9525e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2714 - bpp: 1.2779 - mse: 2.4256e-04\n",
      "Epoch 51: loss improved from 2.52417 to 2.27142, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.2714 - bpp: 1.2779 - mse: 2.4256e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5155 - bpp: 1.2930 - mse: 2.9848e-04\n",
      "Epoch 52: loss did not improve from 2.27142\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 2.5155 - bpp: 1.2930 - mse: 2.9848e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2514 - bpp: 1.2403 - mse: 2.4685e-04\n",
      "Epoch 53: loss improved from 2.27142 to 2.25144, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.2514 - bpp: 1.2403 - mse: 2.4685e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.2319 - bpp: 1.3859 - mse: 0.0034\n",
      "Epoch 54: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 15.2319 - bpp: 1.3859 - mse: 0.0034\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0597 - bpp: 1.2810 - mse: 0.0012\n",
      "Epoch 55: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 6.0597 - bpp: 1.2810 - mse: 0.0012\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1330 - bpp: 1.2588 - mse: 9.4584e-04\n",
      "Epoch 56: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 5.1330 - bpp: 1.2588 - mse: 9.4584e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6067 - bpp: 1.2128 - mse: 5.8444e-04\n",
      "Epoch 57: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 3.6067 - bpp: 1.2128 - mse: 5.8444e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3044 - bpp: 1.2028 - mse: 5.1308e-04\n",
      "Epoch 58: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.3044 - bpp: 1.2028 - mse: 5.1308e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8740 - bpp: 1.2544 - mse: 6.3953e-04\n",
      "Epoch 59: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 3.8740 - bpp: 1.2544 - mse: 6.3953e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0976 - bpp: 1.2171 - mse: 4.5912e-04\n",
      "Epoch 60: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 3.0976 - bpp: 1.2171 - mse: 4.5912e-04\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1099 - bpp: 1.2394 - mse: 4.5667e-04\n",
      "Epoch 61: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 3.1099 - bpp: 1.2394 - mse: 4.5667e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8433 - bpp: 1.2383 - mse: 3.9186e-04\n",
      "Epoch 62: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.8433 - bpp: 1.2383 - mse: 3.9186e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5307 - bpp: 1.1677 - mse: 3.3278e-04\n",
      "Epoch 63: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 2.5307 - bpp: 1.1677 - mse: 3.3278e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7920 - bpp: 1.2056 - mse: 3.8731e-04\n",
      "Epoch 64: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.7920 - bpp: 1.2056 - mse: 3.8731e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5687 - bpp: 1.1582 - mse: 3.4435e-04\n",
      "Epoch 65: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 2.5687 - bpp: 1.1582 - mse: 3.4435e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3711 - bpp: 1.2362 - mse: 5.2120e-04\n",
      "Epoch 66: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 3.3711 - bpp: 1.2362 - mse: 5.2120e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1415 - bpp: 1.2150 - mse: 4.7034e-04\n",
      "Epoch 67: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 3.1415 - bpp: 1.2150 - mse: 4.7034e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4854 - bpp: 1.1449 - mse: 3.2728e-04\n",
      "Epoch 68: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.4854 - bpp: 1.1449 - mse: 3.2728e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3487 - bpp: 1.1071 - mse: 3.0312e-04\n",
      "Epoch 69: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 2.3487 - bpp: 1.1071 - mse: 3.0312e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4232 - bpp: 1.1200 - mse: 3.1815e-04\n",
      "Epoch 70: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.4232 - bpp: 1.1200 - mse: 3.1815e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3601 - bpp: 1.0999 - mse: 3.0766e-04\n",
      "Epoch 71: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 2.3601 - bpp: 1.0999 - mse: 3.0766e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2558 - bpp: 1.0694 - mse: 2.8964e-04\n",
      "Epoch 72: loss did not improve from 2.25144\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.2558 - bpp: 1.0694 - mse: 2.8964e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1711 - bpp: 1.0483 - mse: 2.7414e-04\n",
      "Epoch 73: loss improved from 2.25144 to 2.17115, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.1711 - bpp: 1.0483 - mse: 2.7414e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3286 - bpp: 1.0623 - mse: 3.0918e-04\n",
      "Epoch 74: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 2.3286 - bpp: 1.0623 - mse: 3.0918e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2320 - bpp: 1.0585 - mse: 2.8650e-04\n",
      "Epoch 75: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.2320 - bpp: 1.0585 - mse: 2.8650e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4526 - bpp: 1.0947 - mse: 3.3153e-04\n",
      "Epoch 76: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.4526 - bpp: 1.0947 - mse: 3.3153e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2476 - bpp: 1.0470 - mse: 2.9311e-04\n",
      "Epoch 77: loss did not improve from 2.17115\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.2476 - bpp: 1.0470 - mse: 2.9311e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1400 - bpp: 1.0298 - mse: 2.7104e-04\n",
      "Epoch 78: loss improved from 2.17115 to 2.14001, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 2.1400 - bpp: 1.0298 - mse: 2.7104e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2091 - bpp: 1.0289 - mse: 2.8811e-04\n",
      "Epoch 79: loss did not improve from 2.14001\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.2091 - bpp: 1.0289 - mse: 2.8811e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2126 - bpp: 1.0278 - mse: 2.8925e-04\n",
      "Epoch 80: loss did not improve from 2.14001\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.2126 - bpp: 1.0278 - mse: 2.8925e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1991 - bpp: 1.0354 - mse: 2.8409e-04\n",
      "Epoch 81: loss did not improve from 2.14001\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1991 - bpp: 1.0354 - mse: 2.8409e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9984 - bpp: 0.9780 - mse: 2.4913e-04\n",
      "Epoch 82: loss improved from 2.14001 to 1.99840, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 37s 187ms/step - loss: 1.9984 - bpp: 0.9780 - mse: 2.4913e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0850 - bpp: 0.9908 - mse: 2.6713e-04\n",
      "Epoch 83: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.0850 - bpp: 0.9908 - mse: 2.6713e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1867 - bpp: 1.0008 - mse: 2.8954e-04\n",
      "Epoch 84: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.1867 - bpp: 1.0008 - mse: 2.8954e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2498 - bpp: 0.9945 - mse: 3.0648e-04\n",
      "Epoch 85: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.2498 - bpp: 0.9945 - mse: 3.0648e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1085 - bpp: 0.9677 - mse: 2.7850e-04\n",
      "Epoch 86: loss did not improve from 1.99840\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.1085 - bpp: 0.9677 - mse: 2.7850e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9382 - bpp: 0.9582 - mse: 2.3926e-04\n",
      "Epoch 87: loss improved from 1.99840 to 1.93824, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.9382 - bpp: 0.9582 - mse: 2.3926e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0673 - bpp: 0.9652 - mse: 2.6908e-04\n",
      "Epoch 88: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.0673 - bpp: 0.9652 - mse: 2.6908e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1659 - bpp: 0.9650 - mse: 2.9318e-04\n",
      "Epoch 89: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1659 - bpp: 0.9650 - mse: 2.9318e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0502 - bpp: 1.0982 - mse: 0.0022\n",
      "Epoch 90: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 10.0502 - bpp: 1.0982 - mse: 0.0022\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5108 - bpp: 1.0079 - mse: 0.0011\n",
      "Epoch 91: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 5.5108 - bpp: 1.0079 - mse: 0.0011\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5029 - bpp: 0.9581 - mse: 6.2131e-04\n",
      "Epoch 92: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 3.5029 - bpp: 0.9581 - mse: 6.2131e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5660 - bpp: 1.0184 - mse: 8.6613e-04\n",
      "Epoch 93: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 4.5660 - bpp: 1.0184 - mse: 8.6613e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0275 - bpp: 1.0147 - mse: 4.9140e-04\n",
      "Epoch 94: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 3.0275 - bpp: 1.0147 - mse: 4.9140e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7894 - bpp: 0.9939 - mse: 4.3835e-04\n",
      "Epoch 95: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.7894 - bpp: 0.9939 - mse: 4.3835e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8865 - bpp: 1.0357 - mse: 4.5187e-04\n",
      "Epoch 96: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 2.8865 - bpp: 1.0357 - mse: 4.5187e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0445 - bpp: 1.0745 - mse: 4.8097e-04\n",
      "Epoch 97: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.0445 - bpp: 1.0745 - mse: 4.8097e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6232 - bpp: 1.0484 - mse: 3.8447e-04\n",
      "Epoch 98: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.6232 - bpp: 1.0484 - mse: 3.8447e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6869 - bpp: 1.0728 - mse: 3.9406e-04\n",
      "Epoch 99: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 2.6869 - bpp: 1.0728 - mse: 3.9406e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5428 - bpp: 1.0527 - mse: 3.6379e-04\n",
      "Epoch 100: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.5428 - bpp: 1.0527 - mse: 3.6379e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2030 - bpp: 1.0015 - mse: 2.9332e-04\n",
      "Epoch 101: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 2.2030 - bpp: 1.0015 - mse: 2.9332e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4146 - bpp: 1.0243 - mse: 3.3942e-04\n",
      "Epoch 102: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.4146 - bpp: 1.0243 - mse: 3.3942e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3354 - bpp: 1.0194 - mse: 3.2130e-04\n",
      "Epoch 103: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.3354 - bpp: 1.0194 - mse: 3.2130e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3422 - bpp: 1.0038 - mse: 3.2677e-04\n",
      "Epoch 104: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.3422 - bpp: 1.0038 - mse: 3.2677e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6078 - bpp: 1.1442 - mse: 6.0147e-04\n",
      "Epoch 105: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 3.6078 - bpp: 1.1442 - mse: 6.0147e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3643 - bpp: 1.0622 - mse: 3.1788e-04\n",
      "Epoch 106: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.3643 - bpp: 1.0622 - mse: 3.1788e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1253 - bpp: 0.9789 - mse: 2.7989e-04\n",
      "Epoch 107: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 180ms/step - loss: 2.1253 - bpp: 0.9789 - mse: 2.7989e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2841 - bpp: 1.0210 - mse: 3.0835e-04\n",
      "Epoch 108: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.2841 - bpp: 1.0210 - mse: 3.0835e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9916 - bpp: 0.9750 - mse: 2.4821e-04\n",
      "Epoch 109: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9916 - bpp: 0.9750 - mse: 2.4821e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0982 - bpp: 0.9775 - mse: 2.7362e-04\n",
      "Epoch 110: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 2.0982 - bpp: 0.9775 - mse: 2.7362e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3236 - bpp: 1.0254 - mse: 3.1693e-04\n",
      "Epoch 111: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.3236 - bpp: 1.0254 - mse: 3.1693e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1281 - bpp: 0.9897 - mse: 2.7792e-04\n",
      "Epoch 112: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 2.1281 - bpp: 0.9897 - mse: 2.7792e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9717 - bpp: 0.9504 - mse: 2.4934e-04\n",
      "Epoch 113: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.9717 - bpp: 0.9504 - mse: 2.4934e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9645 - bpp: 0.9395 - mse: 2.5024e-04\n",
      "Epoch 114: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.9645 - bpp: 0.9395 - mse: 2.5024e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0751 - bpp: 0.9661 - mse: 2.7074e-04\n",
      "Epoch 115: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 2.0751 - bpp: 0.9661 - mse: 2.7074e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4195 - bpp: 1.0398 - mse: 3.3683e-04\n",
      "Epoch 116: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.4195 - bpp: 1.0398 - mse: 3.3683e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9853 - bpp: 0.9346 - mse: 2.5652e-04\n",
      "Epoch 117: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9853 - bpp: 0.9346 - mse: 2.5652e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9575 - bpp: 0.9385 - mse: 2.4878e-04\n",
      "Epoch 118: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.9575 - bpp: 0.9385 - mse: 2.4878e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9402 - bpp: 0.9177 - mse: 2.4964e-04\n",
      "Epoch 119: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.9402 - bpp: 0.9177 - mse: 2.4964e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1504 - bpp: 0.9773 - mse: 2.8638e-04\n",
      "Epoch 120: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.1504 - bpp: 0.9773 - mse: 2.8638e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9399 - bpp: 0.9175 - mse: 2.4959e-04\n",
      "Epoch 121: loss did not improve from 1.93824\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9399 - bpp: 0.9175 - mse: 2.4959e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8710 - bpp: 0.8926 - mse: 2.3887e-04\n",
      "Epoch 122: loss improved from 1.93824 to 1.87103, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.8710 - bpp: 0.8926 - mse: 2.3887e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7935 - bpp: 0.9497 - mse: 4.5015e-04\n",
      "Epoch 123: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 2.7935 - bpp: 0.9497 - mse: 4.5015e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5414 - bpp: 1.0175 - mse: 3.7205e-04\n",
      "Epoch 124: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.5414 - bpp: 1.0175 - mse: 3.7205e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0257 - bpp: 0.9087 - mse: 2.7269e-04\n",
      "Epoch 125: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.0257 - bpp: 0.9087 - mse: 2.7269e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0594 - bpp: 0.9417 - mse: 2.7287e-04\n",
      "Epoch 126: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.0594 - bpp: 0.9417 - mse: 2.7287e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0739 - bpp: 0.9558 - mse: 2.7298e-04\n",
      "Epoch 127: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 2.0739 - bpp: 0.9558 - mse: 2.7298e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9917 - bpp: 0.9504 - mse: 2.5422e-04\n",
      "Epoch 128: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.9917 - bpp: 0.9504 - mse: 2.5422e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0876 - bpp: 0.9379 - mse: 2.8069e-04\n",
      "Epoch 129: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.0876 - bpp: 0.9379 - mse: 2.8069e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6436 - bpp: 0.9551 - mse: 4.1224e-04\n",
      "Epoch 130: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 2.6436 - bpp: 0.9551 - mse: 4.1224e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2651 - bpp: 1.1503 - mse: 0.0022\n",
      "Epoch 131: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 10.2651 - bpp: 1.1503 - mse: 0.0022\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9908 - bpp: 0.9900 - mse: 4.8847e-04\n",
      "Epoch 132: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.9908 - bpp: 0.9900 - mse: 4.8847e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5696 - bpp: 0.9614 - mse: 3.9264e-04\n",
      "Epoch 133: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 2.5696 - bpp: 0.9614 - mse: 3.9264e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4512 - bpp: 0.9660 - mse: 3.6259e-04\n",
      "Epoch 134: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 2.4512 - bpp: 0.9660 - mse: 3.6259e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1531 - bpp: 0.9345 - mse: 2.9751e-04\n",
      "Epoch 135: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 2.1531 - bpp: 0.9345 - mse: 2.9751e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1323 - bpp: 0.9336 - mse: 2.9267e-04\n",
      "Epoch 136: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.1323 - bpp: 0.9336 - mse: 2.9267e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0774 - bpp: 0.9309 - mse: 2.7989e-04\n",
      "Epoch 137: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 2.0774 - bpp: 0.9309 - mse: 2.7989e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0143 - bpp: 0.9353 - mse: 2.6342e-04\n",
      "Epoch 138: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.0143 - bpp: 0.9353 - mse: 2.6342e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1236 - bpp: 0.9473 - mse: 2.8717e-04\n",
      "Epoch 139: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1236 - bpp: 0.9473 - mse: 2.8717e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9407 - bpp: 0.9121 - mse: 2.5111e-04\n",
      "Epoch 140: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.9407 - bpp: 0.9121 - mse: 2.5111e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9809 - bpp: 0.9237 - mse: 2.5810e-04\n",
      "Epoch 141: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.9809 - bpp: 0.9237 - mse: 2.5810e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9969 - bpp: 0.9187 - mse: 2.6322e-04\n",
      "Epoch 142: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.9969 - bpp: 0.9187 - mse: 2.6322e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9608 - bpp: 0.9167 - mse: 2.5491e-04\n",
      "Epoch 143: loss did not improve from 1.87103\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.9608 - bpp: 0.9167 - mse: 2.5491e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8530 - bpp: 0.9015 - mse: 2.3231e-04\n",
      "Epoch 144: loss improved from 1.87103 to 1.85300, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.8530 - bpp: 0.9015 - mse: 2.3231e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7570 - bpp: 0.8719 - mse: 2.1607e-04\n",
      "Epoch 145: loss improved from 1.85300 to 1.75696, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.7570 - bpp: 0.8719 - mse: 2.1607e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9308 - bpp: 0.8948 - mse: 2.5293e-04\n",
      "Epoch 146: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.9308 - bpp: 0.8948 - mse: 2.5293e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9045 - bpp: 0.8705 - mse: 2.5246e-04\n",
      "Epoch 147: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.9045 - bpp: 0.8705 - mse: 2.5246e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8837 - bpp: 0.8864 - mse: 2.4347e-04\n",
      "Epoch 148: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.8837 - bpp: 0.8864 - mse: 2.4347e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8962 - bpp: 0.8842 - mse: 2.4706e-04\n",
      "Epoch 149: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.8962 - bpp: 0.8842 - mse: 2.4706e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8880 - bpp: 0.8767 - mse: 2.4690e-04\n",
      "Epoch 150: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.8880 - bpp: 0.8767 - mse: 2.4690e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8727 - bpp: 0.8642 - mse: 2.4619e-04\n",
      "Epoch 151: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.8727 - bpp: 0.8642 - mse: 2.4619e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8157 - bpp: 0.8650 - mse: 2.3211e-04\n",
      "Epoch 152: loss did not improve from 1.75696\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.8157 - bpp: 0.8650 - mse: 2.3211e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7521 - bpp: 0.8496 - mse: 2.2033e-04\n",
      "Epoch 153: loss improved from 1.75696 to 1.75214, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.7521 - bpp: 0.8496 - mse: 2.2033e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9290 - bpp: 0.8707 - mse: 2.5836e-04\n",
      "Epoch 154: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.9290 - bpp: 0.8707 - mse: 2.5836e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8812 - bpp: 0.8739 - mse: 2.4591e-04\n",
      "Epoch 155: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.8812 - bpp: 0.8739 - mse: 2.4591e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1392 - bpp: 0.8783 - mse: 3.0782e-04\n",
      "Epoch 156: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 2.1392 - bpp: 0.8783 - mse: 3.0782e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9495 - bpp: 0.8504 - mse: 2.6832e-04\n",
      "Epoch 157: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.9495 - bpp: 0.8504 - mse: 2.6832e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8340 - bpp: 0.8521 - mse: 2.3972e-04\n",
      "Epoch 158: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.8340 - bpp: 0.8521 - mse: 2.3972e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5501 - bpp: 0.9437 - mse: 3.9220e-04\n",
      "Epoch 159: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 2.5501 - bpp: 0.9437 - mse: 3.9220e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8861 - bpp: 0.8796 - mse: 2.4572e-04\n",
      "Epoch 160: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.8861 - bpp: 0.8796 - mse: 2.4572e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7760 - bpp: 0.8471 - mse: 2.2679e-04\n",
      "Epoch 161: loss did not improve from 1.75214\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.7760 - bpp: 0.8471 - mse: 2.2679e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7231 - bpp: 0.8414 - mse: 2.1527e-04\n",
      "Epoch 162: loss improved from 1.75214 to 1.72314, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.7231 - bpp: 0.8414 - mse: 2.1527e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0422 - bpp: 0.8715 - mse: 2.8582e-04\n",
      "Epoch 163: loss did not improve from 1.72314\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 2.0422 - bpp: 0.8715 - mse: 2.8582e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8620 - bpp: 0.8520 - mse: 2.4658e-04\n",
      "Epoch 164: loss did not improve from 1.72314\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.8620 - bpp: 0.8520 - mse: 2.4658e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7063 - bpp: 0.8220 - mse: 2.1590e-04\n",
      "Epoch 165: loss improved from 1.72314 to 1.70632, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.7063 - bpp: 0.8220 - mse: 2.1590e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8160 - bpp: 0.8329 - mse: 2.4002e-04\n",
      "Epoch 166: loss did not improve from 1.70632\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.8160 - bpp: 0.8329 - mse: 2.4002e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8498 - bpp: 0.8322 - mse: 2.4843e-04\n",
      "Epoch 167: loss did not improve from 1.70632\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.8498 - bpp: 0.8322 - mse: 2.4843e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6539 - bpp: 0.7911 - mse: 2.1065e-04\n",
      "Epoch 168: loss improved from 1.70632 to 1.65394, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.6539 - bpp: 0.7911 - mse: 2.1065e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7616 - bpp: 0.8278 - mse: 2.2798e-04\n",
      "Epoch 169: loss did not improve from 1.65394\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 1.7616 - bpp: 0.8278 - mse: 2.2798e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6011 - bpp: 0.7882 - mse: 1.9848e-04\n",
      "Epoch 170: loss improved from 1.65394 to 1.60112, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6011 - bpp: 0.7882 - mse: 1.9848e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5699 - bpp: 0.7756 - mse: 1.9393e-04\n",
      "Epoch 171: loss improved from 1.60112 to 1.56994, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5699 - bpp: 0.7756 - mse: 1.9393e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9266 - bpp: 0.8338 - mse: 2.6679e-04\n",
      "Epoch 172: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.9266 - bpp: 0.8338 - mse: 2.6679e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0495 - bpp: 0.8307 - mse: 2.9756e-04\n",
      "Epoch 173: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 2.0495 - bpp: 0.8307 - mse: 2.9756e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0943 - bpp: 0.9057 - mse: 5.3431e-04\n",
      "Epoch 174: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 3.0943 - bpp: 0.9057 - mse: 5.3431e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9737 - bpp: 0.8571 - mse: 2.7259e-04\n",
      "Epoch 175: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.9737 - bpp: 0.8571 - mse: 2.7259e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8294 - bpp: 0.8232 - mse: 2.4564e-04\n",
      "Epoch 176: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.8294 - bpp: 0.8232 - mse: 2.4564e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5815 - bpp: 0.7756 - mse: 1.9673e-04\n",
      "Epoch 177: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5815 - bpp: 0.7756 - mse: 1.9673e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6970 - bpp: 0.7987 - mse: 2.1931e-04\n",
      "Epoch 178: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6970 - bpp: 0.7987 - mse: 2.1931e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6383 - bpp: 0.7793 - mse: 2.0971e-04\n",
      "Epoch 179: loss did not improve from 1.56994\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.6383 - bpp: 0.7793 - mse: 2.0971e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4496 - bpp: 0.7411 - mse: 1.7297e-04\n",
      "Epoch 180: loss improved from 1.56994 to 1.44958, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4496 - bpp: 0.7411 - mse: 1.7297e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6624 - bpp: 0.7932 - mse: 2.1221e-04\n",
      "Epoch 181: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.6624 - bpp: 0.7932 - mse: 2.1221e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6404 - bpp: 0.7661 - mse: 2.1345e-04\n",
      "Epoch 182: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.6404 - bpp: 0.7661 - mse: 2.1345e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5330 - bpp: 0.7571 - mse: 1.8945e-04\n",
      "Epoch 183: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.5330 - bpp: 0.7571 - mse: 1.8945e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4907 - bpp: 0.7500 - mse: 1.8083e-04\n",
      "Epoch 184: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4907 - bpp: 0.7500 - mse: 1.8083e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5378 - bpp: 0.7638 - mse: 1.8896e-04\n",
      "Epoch 185: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5378 - bpp: 0.7638 - mse: 1.8896e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6785 - bpp: 0.7667 - mse: 2.2262e-04\n",
      "Epoch 186: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.6785 - bpp: 0.7667 - mse: 2.2262e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7221 - bpp: 0.7867 - mse: 2.2839e-04\n",
      "Epoch 187: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.7221 - bpp: 0.7867 - mse: 2.2839e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5191 - bpp: 0.7616 - mse: 1.8494e-04\n",
      "Epoch 188: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.5191 - bpp: 0.7616 - mse: 1.8494e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5811 - bpp: 0.7509 - mse: 2.0270e-04\n",
      "Epoch 189: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5811 - bpp: 0.7509 - mse: 2.0270e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6210 - bpp: 0.7701 - mse: 2.0773e-04\n",
      "Epoch 190: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6210 - bpp: 0.7701 - mse: 2.0773e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6036 - bpp: 0.8692 - mse: 4.2343e-04\n",
      "Epoch 191: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 2.6036 - bpp: 0.8692 - mse: 4.2343e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6007 - bpp: 0.7701 - mse: 2.0278e-04\n",
      "Epoch 192: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.6007 - bpp: 0.7701 - mse: 2.0278e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6130 - bpp: 0.7689 - mse: 2.0607e-04\n",
      "Epoch 193: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6130 - bpp: 0.7689 - mse: 2.0607e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6066 - bpp: 0.7629 - mse: 2.0597e-04\n",
      "Epoch 194: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.6066 - bpp: 0.7629 - mse: 2.0597e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5705 - bpp: 0.7512 - mse: 2.0003e-04\n",
      "Epoch 195: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5705 - bpp: 0.7512 - mse: 2.0003e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5607 - bpp: 0.7409 - mse: 2.0015e-04\n",
      "Epoch 196: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5607 - bpp: 0.7409 - mse: 2.0015e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5295 - bpp: 0.7387 - mse: 1.9306e-04\n",
      "Epoch 197: loss did not improve from 1.44958\n",
      "200/200 [==============================] - 40s 193ms/step - loss: 1.5295 - bpp: 0.7387 - mse: 1.9306e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4352 - bpp: 0.7213 - mse: 1.7428e-04\n",
      "Epoch 198: loss improved from 1.44958 to 1.43518, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.4352 - bpp: 0.7213 - mse: 1.7428e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5043 - bpp: 0.7340 - mse: 1.8808e-04\n",
      "Epoch 199: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5043 - bpp: 0.7340 - mse: 1.8808e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5584 - bpp: 0.7440 - mse: 1.9882e-04\n",
      "Epoch 200: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.5584 - bpp: 0.7440 - mse: 1.9882e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6087 - bpp: 0.7446 - mse: 2.1095e-04\n",
      "Epoch 201: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6087 - bpp: 0.7446 - mse: 2.1095e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5568 - bpp: 0.7443 - mse: 1.9837e-04\n",
      "Epoch 202: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.5568 - bpp: 0.7443 - mse: 1.9837e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5330 - bpp: 0.7367 - mse: 1.9440e-04\n",
      "Epoch 203: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5330 - bpp: 0.7367 - mse: 1.9440e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4732 - bpp: 0.7049 - mse: 1.8755e-04\n",
      "Epoch 204: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4732 - bpp: 0.7049 - mse: 1.8755e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5934 - bpp: 0.7389 - mse: 2.0863e-04\n",
      "Epoch 205: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5934 - bpp: 0.7389 - mse: 2.0863e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6407 - bpp: 0.7559 - mse: 2.1603e-04\n",
      "Epoch 206: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.6407 - bpp: 0.7559 - mse: 2.1603e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4452 - bpp: 0.7076 - mse: 1.8007e-04\n",
      "Epoch 207: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4452 - bpp: 0.7076 - mse: 1.8007e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7409 - bpp: 0.7650 - mse: 2.3825e-04\n",
      "Epoch 208: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.7409 - bpp: 0.7650 - mse: 2.3825e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5283 - bpp: 0.7324 - mse: 1.9430e-04\n",
      "Epoch 209: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5283 - bpp: 0.7324 - mse: 1.9430e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5700 - bpp: 0.7353 - mse: 2.0377e-04\n",
      "Epoch 210: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5700 - bpp: 0.7353 - mse: 2.0377e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7577 - bpp: 0.8407 - mse: 4.6802e-04\n",
      "Epoch 211: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 2.7577 - bpp: 0.8407 - mse: 4.6802e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6510 - bpp: 0.7514 - mse: 2.1961e-04\n",
      "Epoch 212: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6510 - bpp: 0.7514 - mse: 2.1961e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5486 - bpp: 0.7248 - mse: 2.0112e-04\n",
      "Epoch 213: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5486 - bpp: 0.7248 - mse: 2.0112e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6316 - bpp: 0.7485 - mse: 2.1561e-04\n",
      "Epoch 214: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6316 - bpp: 0.7485 - mse: 2.1561e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5152 - bpp: 0.7176 - mse: 1.9473e-04\n",
      "Epoch 215: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5152 - bpp: 0.7176 - mse: 1.9473e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4720 - bpp: 0.7184 - mse: 1.8397e-04\n",
      "Epoch 216: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.4720 - bpp: 0.7184 - mse: 1.8397e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5907 - bpp: 0.7403 - mse: 2.0761e-04\n",
      "Epoch 217: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5907 - bpp: 0.7403 - mse: 2.0761e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5817 - bpp: 0.7382 - mse: 2.0592e-04\n",
      "Epoch 218: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.5817 - bpp: 0.7382 - mse: 2.0592e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5008 - bpp: 0.7156 - mse: 1.9170e-04\n",
      "Epoch 219: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5008 - bpp: 0.7156 - mse: 1.9170e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5008 - bpp: 0.7140 - mse: 1.9208e-04\n",
      "Epoch 220: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5008 - bpp: 0.7140 - mse: 1.9208e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5871 - bpp: 0.7397 - mse: 2.0689e-04\n",
      "Epoch 221: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5871 - bpp: 0.7397 - mse: 2.0689e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5141 - bpp: 0.7148 - mse: 1.9514e-04\n",
      "Epoch 222: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5141 - bpp: 0.7148 - mse: 1.9514e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5579 - bpp: 0.7224 - mse: 2.0396e-04\n",
      "Epoch 223: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5579 - bpp: 0.7224 - mse: 2.0396e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5111 - bpp: 0.7182 - mse: 1.9357e-04\n",
      "Epoch 224: loss did not improve from 1.43518\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5111 - bpp: 0.7182 - mse: 1.9357e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4056 - bpp: 0.6974 - mse: 1.7290e-04\n",
      "Epoch 225: loss improved from 1.43518 to 1.40561, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4056 - bpp: 0.6974 - mse: 1.7290e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4761 - bpp: 0.7133 - mse: 1.8623e-04\n",
      "Epoch 226: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.4761 - bpp: 0.7133 - mse: 1.8623e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5237 - bpp: 0.7084 - mse: 1.9905e-04\n",
      "Epoch 227: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5237 - bpp: 0.7084 - mse: 1.9905e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4822 - bpp: 0.7180 - mse: 1.8656e-04\n",
      "Epoch 228: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.4822 - bpp: 0.7180 - mse: 1.8656e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4441 - bpp: 0.6981 - mse: 1.8214e-04\n",
      "Epoch 229: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4441 - bpp: 0.6981 - mse: 1.8214e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6126 - bpp: 0.7312 - mse: 2.1520e-04\n",
      "Epoch 230: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6126 - bpp: 0.7312 - mse: 2.1520e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4195 - bpp: 0.6943 - mse: 1.7704e-04\n",
      "Epoch 231: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.4195 - bpp: 0.6943 - mse: 1.7704e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5497 - bpp: 0.7005 - mse: 2.0732e-04\n",
      "Epoch 232: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.5497 - bpp: 0.7005 - mse: 2.0732e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5313 - bpp: 0.8122 - mse: 4.1970e-04\n",
      "Epoch 233: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 2.5313 - bpp: 0.8122 - mse: 4.1970e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6742 - bpp: 0.7630 - mse: 2.2244e-04\n",
      "Epoch 234: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6742 - bpp: 0.7630 - mse: 2.2244e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5710 - bpp: 0.7351 - mse: 2.0408e-04\n",
      "Epoch 235: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5710 - bpp: 0.7351 - mse: 2.0408e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5710 - bpp: 0.7227 - mse: 2.0709e-04\n",
      "Epoch 236: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5710 - bpp: 0.7227 - mse: 2.0709e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4817 - bpp: 0.7118 - mse: 1.8797e-04\n",
      "Epoch 237: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.4817 - bpp: 0.7118 - mse: 1.8797e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4904 - bpp: 0.6973 - mse: 1.9363e-04\n",
      "Epoch 238: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.4904 - bpp: 0.6973 - mse: 1.9363e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4939 - bpp: 0.7073 - mse: 1.9204e-04\n",
      "Epoch 239: loss did not improve from 1.40561\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.4939 - bpp: 0.7073 - mse: 1.9204e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4018 - bpp: 0.6932 - mse: 1.7300e-04\n",
      "Epoch 240: loss improved from 1.40561 to 1.40185, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.4018 - bpp: 0.6932 - mse: 1.7300e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5485 - bpp: 0.7242 - mse: 2.0127e-04\n",
      "Epoch 241: loss did not improve from 1.40185\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.5485 - bpp: 0.7242 - mse: 2.0127e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5060 - bpp: 0.7022 - mse: 1.9625e-04\n",
      "Epoch 242: loss did not improve from 1.40185\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5060 - bpp: 0.7022 - mse: 1.9625e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4410 - bpp: 0.6895 - mse: 1.8346e-04\n",
      "Epoch 243: loss did not improve from 1.40185\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4410 - bpp: 0.6895 - mse: 1.8346e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3018 - bpp: 0.6688 - mse: 1.5452e-04\n",
      "Epoch 244: loss improved from 1.40185 to 1.30176, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3018 - bpp: 0.6688 - mse: 1.5452e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4586 - bpp: 0.6960 - mse: 1.8617e-04\n",
      "Epoch 245: loss did not improve from 1.30176\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.4586 - bpp: 0.6960 - mse: 1.8617e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4952 - bpp: 0.7153 - mse: 1.9042e-04\n",
      "Epoch 246: loss did not improve from 1.30176\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4952 - bpp: 0.7153 - mse: 1.9042e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4077 - bpp: 0.6849 - mse: 1.7648e-04\n",
      "Epoch 247: loss did not improve from 1.30176\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4077 - bpp: 0.6849 - mse: 1.7648e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2499 - bpp: 0.6539 - mse: 1.4551e-04\n",
      "Epoch 248: loss improved from 1.30176 to 1.24989, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2499 - bpp: 0.6539 - mse: 1.4551e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3409 - bpp: 0.6719 - mse: 1.6334e-04\n",
      "Epoch 249: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3409 - bpp: 0.6719 - mse: 1.6334e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4697 - bpp: 0.6949 - mse: 1.8915e-04\n",
      "Epoch 250: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4697 - bpp: 0.6949 - mse: 1.8915e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5648 - bpp: 0.7261 - mse: 2.0475e-04\n",
      "Epoch 251: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5648 - bpp: 0.7261 - mse: 2.0475e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6837 - bpp: 0.7295 - mse: 2.3297e-04\n",
      "Epoch 252: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.6837 - bpp: 0.7295 - mse: 2.3297e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6437 - bpp: 0.7393 - mse: 2.2080e-04\n",
      "Epoch 253: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.6437 - bpp: 0.7393 - mse: 2.2080e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5243 - bpp: 0.7170 - mse: 1.9710e-04\n",
      "Epoch 254: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5243 - bpp: 0.7170 - mse: 1.9710e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4146 - bpp: 0.6901 - mse: 1.7688e-04\n",
      "Epoch 255: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4146 - bpp: 0.6901 - mse: 1.7688e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9217 - bpp: 0.7275 - mse: 2.9156e-04\n",
      "Epoch 256: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.9217 - bpp: 0.7275 - mse: 2.9156e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6794 - bpp: 0.7608 - mse: 2.2425e-04\n",
      "Epoch 257: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6794 - bpp: 0.7608 - mse: 2.2425e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3917 - bpp: 0.6873 - mse: 1.7197e-04\n",
      "Epoch 258: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.3917 - bpp: 0.6873 - mse: 1.7197e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4579 - bpp: 0.7165 - mse: 1.8101e-04\n",
      "Epoch 259: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4579 - bpp: 0.7165 - mse: 1.8101e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4539 - bpp: 0.6784 - mse: 1.8933e-04\n",
      "Epoch 260: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4539 - bpp: 0.6784 - mse: 1.8933e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5487 - bpp: 0.7140 - mse: 2.0380e-04\n",
      "Epoch 261: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.5487 - bpp: 0.7140 - mse: 2.0380e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4084 - bpp: 0.6844 - mse: 1.7676e-04\n",
      "Epoch 262: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4084 - bpp: 0.6844 - mse: 1.7676e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5090 - bpp: 0.7016 - mse: 1.9711e-04\n",
      "Epoch 263: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5090 - bpp: 0.7016 - mse: 1.9711e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3626 - bpp: 0.6756 - mse: 1.6772e-04\n",
      "Epoch 264: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3626 - bpp: 0.6756 - mse: 1.6772e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4128 - bpp: 0.6842 - mse: 1.7787e-04\n",
      "Epoch 265: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.4128 - bpp: 0.6842 - mse: 1.7787e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4548 - bpp: 0.6898 - mse: 1.8677e-04\n",
      "Epoch 266: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4548 - bpp: 0.6898 - mse: 1.8677e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4253 - bpp: 0.6821 - mse: 1.8147e-04\n",
      "Epoch 267: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4253 - bpp: 0.6821 - mse: 1.8147e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3573 - bpp: 0.6666 - mse: 1.6863e-04\n",
      "Epoch 268: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3573 - bpp: 0.6666 - mse: 1.6863e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4367 - bpp: 0.6821 - mse: 1.8423e-04\n",
      "Epoch 269: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4367 - bpp: 0.6821 - mse: 1.8423e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4221 - bpp: 0.6921 - mse: 1.7821e-04\n",
      "Epoch 270: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4221 - bpp: 0.6921 - mse: 1.7821e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4001 - bpp: 0.6755 - mse: 1.7691e-04\n",
      "Epoch 271: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4001 - bpp: 0.6755 - mse: 1.7691e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3083 - bpp: 0.6600 - mse: 1.5828e-04\n",
      "Epoch 272: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.3083 - bpp: 0.6600 - mse: 1.5828e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4412 - bpp: 0.6785 - mse: 1.8620e-04\n",
      "Epoch 273: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4412 - bpp: 0.6785 - mse: 1.8620e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4552 - bpp: 0.6660 - mse: 1.9269e-04\n",
      "Epoch 274: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.4552 - bpp: 0.6660 - mse: 1.9269e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4125 - bpp: 0.6760 - mse: 1.7981e-04\n",
      "Epoch 275: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4125 - bpp: 0.6760 - mse: 1.7981e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3449 - bpp: 0.6576 - mse: 1.6780e-04\n",
      "Epoch 276: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3449 - bpp: 0.6576 - mse: 1.6780e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4074 - bpp: 0.6737 - mse: 1.7911e-04\n",
      "Epoch 277: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4074 - bpp: 0.6737 - mse: 1.7911e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3660 - bpp: 0.6656 - mse: 1.7101e-04\n",
      "Epoch 278: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3660 - bpp: 0.6656 - mse: 1.7101e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8550 - bpp: 0.8118 - mse: 4.9882e-04\n",
      "Epoch 279: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 189ms/step - loss: 2.8550 - bpp: 0.8118 - mse: 4.9882e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5119 - bpp: 0.7250 - mse: 1.9211e-04\n",
      "Epoch 280: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5119 - bpp: 0.7250 - mse: 1.9211e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4709 - bpp: 0.7047 - mse: 1.8706e-04\n",
      "Epoch 281: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.4709 - bpp: 0.7047 - mse: 1.8706e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5685 - bpp: 0.7311 - mse: 2.0444e-04\n",
      "Epoch 282: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5685 - bpp: 0.7311 - mse: 2.0444e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4181 - bpp: 0.6751 - mse: 1.8140e-04\n",
      "Epoch 283: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4181 - bpp: 0.6751 - mse: 1.8140e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3861 - bpp: 0.6739 - mse: 1.7387e-04\n",
      "Epoch 284: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3861 - bpp: 0.6739 - mse: 1.7387e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4483 - bpp: 0.6907 - mse: 1.8496e-04\n",
      "Epoch 285: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4483 - bpp: 0.6907 - mse: 1.8496e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.6440 - mse: 1.6111e-04\n",
      "Epoch 286: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.3039 - bpp: 0.6440 - mse: 1.6111e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4029 - bpp: 0.6743 - mse: 1.7787e-04\n",
      "Epoch 287: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4029 - bpp: 0.6743 - mse: 1.7787e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3355 - bpp: 0.6572 - mse: 1.6560e-04\n",
      "Epoch 288: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3355 - bpp: 0.6572 - mse: 1.6560e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5114 - bpp: 0.6916 - mse: 2.0014e-04\n",
      "Epoch 289: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.5114 - bpp: 0.6916 - mse: 2.0014e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4294 - bpp: 0.6728 - mse: 1.8473e-04\n",
      "Epoch 290: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4294 - bpp: 0.6728 - mse: 1.8473e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3844 - bpp: 0.6671 - mse: 1.7512e-04\n",
      "Epoch 291: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3844 - bpp: 0.6671 - mse: 1.7512e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4031 - bpp: 0.6780 - mse: 1.7703e-04\n",
      "Epoch 292: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.4031 - bpp: 0.6780 - mse: 1.7703e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2905 - bpp: 0.6403 - mse: 1.5874e-04\n",
      "Epoch 293: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2905 - bpp: 0.6403 - mse: 1.5874e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4675 - bpp: 0.6757 - mse: 1.9330e-04\n",
      "Epoch 294: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4675 - bpp: 0.6757 - mse: 1.9330e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4429 - bpp: 0.6936 - mse: 1.8294e-04\n",
      "Epoch 295: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4429 - bpp: 0.6936 - mse: 1.8294e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5073 - bpp: 0.6961 - mse: 1.9806e-04\n",
      "Epoch 296: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.5073 - bpp: 0.6961 - mse: 1.9806e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3494 - bpp: 0.6532 - mse: 1.6997e-04\n",
      "Epoch 297: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3494 - bpp: 0.6532 - mse: 1.6997e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4561 - bpp: 0.6639 - mse: 1.9342e-04\n",
      "Epoch 298: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4561 - bpp: 0.6639 - mse: 1.9342e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4474 - bpp: 0.6743 - mse: 1.8874e-04\n",
      "Epoch 299: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.4474 - bpp: 0.6743 - mse: 1.8874e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4072 - bpp: 0.6685 - mse: 1.8035e-04\n",
      "Epoch 300: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4072 - bpp: 0.6685 - mse: 1.8035e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3225 - bpp: 0.6514 - mse: 1.6382e-04\n",
      "Epoch 301: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.3225 - bpp: 0.6514 - mse: 1.6382e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3782 - bpp: 0.6650 - mse: 1.7414e-04\n",
      "Epoch 302: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3782 - bpp: 0.6650 - mse: 1.7414e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4570 - bpp: 0.6916 - mse: 1.8686e-04\n",
      "Epoch 303: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4570 - bpp: 0.6916 - mse: 1.8686e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3744 - bpp: 0.6678 - mse: 1.7251e-04\n",
      "Epoch 304: loss did not improve from 1.24989\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3744 - bpp: 0.6678 - mse: 1.7251e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2345 - bpp: 0.6261 - mse: 1.4855e-04\n",
      "Epoch 305: loss improved from 1.24989 to 1.23451, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2345 - bpp: 0.6261 - mse: 1.4855e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3956 - bpp: 0.6729 - mse: 1.7643e-04\n",
      "Epoch 306: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.3956 - bpp: 0.6729 - mse: 1.7643e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2938 - bpp: 0.6457 - mse: 1.5825e-04\n",
      "Epoch 307: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2938 - bpp: 0.6457 - mse: 1.5825e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5765 - bpp: 0.8515 - mse: 6.6526e-04\n",
      "Epoch 308: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 3.5765 - bpp: 0.8515 - mse: 6.6526e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5568 - bpp: 0.7564 - mse: 1.9541e-04\n",
      "Epoch 309: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5568 - bpp: 0.7564 - mse: 1.9541e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4708 - bpp: 0.7059 - mse: 1.8674e-04\n",
      "Epoch 310: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.4708 - bpp: 0.7059 - mse: 1.8674e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3938 - bpp: 0.6920 - mse: 1.7134e-04\n",
      "Epoch 311: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3938 - bpp: 0.6920 - mse: 1.7134e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4383 - bpp: 0.6963 - mse: 1.8117e-04\n",
      "Epoch 312: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.4383 - bpp: 0.6963 - mse: 1.8117e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3722 - bpp: 0.6680 - mse: 1.7193e-04\n",
      "Epoch 313: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3722 - bpp: 0.6680 - mse: 1.7193e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4081 - bpp: 0.6691 - mse: 1.8042e-04\n",
      "Epoch 314: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4081 - bpp: 0.6691 - mse: 1.8042e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3239 - bpp: 0.6629 - mse: 1.6137e-04\n",
      "Epoch 315: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3239 - bpp: 0.6629 - mse: 1.6137e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3339 - bpp: 0.6535 - mse: 1.6611e-04\n",
      "Epoch 316: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3339 - bpp: 0.6535 - mse: 1.6611e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4300 - bpp: 0.6806 - mse: 1.8295e-04\n",
      "Epoch 317: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.4300 - bpp: 0.6806 - mse: 1.8295e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2763 - bpp: 0.6430 - mse: 1.5463e-04\n",
      "Epoch 318: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2763 - bpp: 0.6430 - mse: 1.5463e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2980 - bpp: 0.6468 - mse: 1.5899e-04\n",
      "Epoch 319: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.2980 - bpp: 0.6468 - mse: 1.5899e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3554 - bpp: 0.6638 - mse: 1.6884e-04\n",
      "Epoch 320: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3554 - bpp: 0.6638 - mse: 1.6884e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3303 - bpp: 0.6583 - mse: 1.6407e-04\n",
      "Epoch 321: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3303 - bpp: 0.6583 - mse: 1.6407e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2856 - bpp: 0.6340 - mse: 1.5908e-04\n",
      "Epoch 322: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2856 - bpp: 0.6340 - mse: 1.5908e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3621 - bpp: 0.6607 - mse: 1.7124e-04\n",
      "Epoch 323: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.3621 - bpp: 0.6607 - mse: 1.7124e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3576 - bpp: 0.6605 - mse: 1.7020e-04\n",
      "Epoch 324: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.3576 - bpp: 0.6605 - mse: 1.7020e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4178 - bpp: 0.6692 - mse: 1.8277e-04\n",
      "Epoch 325: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.4178 - bpp: 0.6692 - mse: 1.8277e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3420 - bpp: 0.6557 - mse: 1.6757e-04\n",
      "Epoch 326: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3420 - bpp: 0.6557 - mse: 1.6757e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5164 - bpp: 0.6807 - mse: 2.0401e-04\n",
      "Epoch 327: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5164 - bpp: 0.6807 - mse: 2.0401e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3805 - bpp: 0.6744 - mse: 1.7237e-04\n",
      "Epoch 328: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.3805 - bpp: 0.6744 - mse: 1.7237e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2999 - bpp: 0.6399 - mse: 1.6113e-04\n",
      "Epoch 329: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2999 - bpp: 0.6399 - mse: 1.6113e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.6432 - mse: 1.6130e-04\n",
      "Epoch 330: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3039 - bpp: 0.6432 - mse: 1.6130e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3251 - bpp: 0.6461 - mse: 1.6577e-04\n",
      "Epoch 331: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3251 - bpp: 0.6461 - mse: 1.6577e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3332 - bpp: 0.6398 - mse: 1.6929e-04\n",
      "Epoch 332: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3332 - bpp: 0.6398 - mse: 1.6929e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3481 - bpp: 0.6594 - mse: 1.6814e-04\n",
      "Epoch 333: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.3481 - bpp: 0.6594 - mse: 1.6814e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2566 - bpp: 0.6287 - mse: 1.5329e-04\n",
      "Epoch 334: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2566 - bpp: 0.6287 - mse: 1.5329e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4299 - bpp: 0.6697 - mse: 1.8559e-04\n",
      "Epoch 335: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.4299 - bpp: 0.6697 - mse: 1.8559e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3480 - bpp: 0.6437 - mse: 1.7194e-04\n",
      "Epoch 336: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.3480 - bpp: 0.6437 - mse: 1.7194e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3441 - bpp: 0.6492 - mse: 1.6965e-04\n",
      "Epoch 337: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.3441 - bpp: 0.6492 - mse: 1.6965e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2868 - bpp: 0.6460 - mse: 1.5645e-04\n",
      "Epoch 338: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.2868 - bpp: 0.6460 - mse: 1.5645e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3988 - bpp: 0.6687 - mse: 1.7825e-04\n",
      "Epoch 339: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.3988 - bpp: 0.6687 - mse: 1.7825e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3641 - bpp: 0.6558 - mse: 1.7291e-04\n",
      "Epoch 340: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.3641 - bpp: 0.6558 - mse: 1.7291e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0496 - bpp: 0.7578 - mse: 3.1537e-04\n",
      "Epoch 341: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 2.0496 - bpp: 0.7578 - mse: 3.1537e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4757 - bpp: 0.7037 - mse: 1.8847e-04\n",
      "Epoch 342: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.4757 - bpp: 0.7037 - mse: 1.8847e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3437 - bpp: 0.6662 - mse: 1.6541e-04\n",
      "Epoch 343: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.3437 - bpp: 0.6662 - mse: 1.6541e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3997 - bpp: 0.6715 - mse: 1.7780e-04\n",
      "Epoch 344: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.3997 - bpp: 0.6715 - mse: 1.7780e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3729 - bpp: 0.6674 - mse: 1.7223e-04\n",
      "Epoch 345: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.3729 - bpp: 0.6674 - mse: 1.7223e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3187 - bpp: 0.6530 - mse: 1.6252e-04\n",
      "Epoch 346: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.3187 - bpp: 0.6530 - mse: 1.6252e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2860 - bpp: 0.6424 - mse: 1.5714e-04\n",
      "Epoch 347: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2860 - bpp: 0.6424 - mse: 1.5714e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3166 - bpp: 0.6510 - mse: 1.6250e-04\n",
      "Epoch 348: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.3166 - bpp: 0.6510 - mse: 1.6250e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2921 - bpp: 0.6405 - mse: 1.5907e-04\n",
      "Epoch 349: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2921 - bpp: 0.6405 - mse: 1.5907e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3681 - bpp: 0.6561 - mse: 1.7381e-04\n",
      "Epoch 350: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.3681 - bpp: 0.6561 - mse: 1.7381e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4059 - bpp: 0.6733 - mse: 1.7886e-04\n",
      "Epoch 351: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.4059 - bpp: 0.6733 - mse: 1.7886e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4182 - bpp: 0.6629 - mse: 1.8440e-04\n",
      "Epoch 352: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.4182 - bpp: 0.6629 - mse: 1.8440e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3355 - bpp: 0.6517 - mse: 1.6694e-04\n",
      "Epoch 353: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.3355 - bpp: 0.6517 - mse: 1.6694e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2906 - bpp: 0.6326 - mse: 1.6065e-04\n",
      "Epoch 354: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.2906 - bpp: 0.6326 - mse: 1.6065e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2640 - bpp: 0.6180 - mse: 1.5772e-04\n",
      "Epoch 355: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.2640 - bpp: 0.6180 - mse: 1.5772e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3859 - bpp: 0.6550 - mse: 1.7846e-04\n",
      "Epoch 356: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.3859 - bpp: 0.6550 - mse: 1.7846e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2515 - bpp: 0.6202 - mse: 1.5414e-04\n",
      "Epoch 357: loss did not improve from 1.23451\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.2515 - bpp: 0.6202 - mse: 1.5414e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1979 - bpp: 0.6086 - mse: 1.4387e-04\n",
      "Epoch 358: loss improved from 1.23451 to 1.19793, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.1979 - bpp: 0.6086 - mse: 1.4387e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4254 - bpp: 0.6577 - mse: 1.8742e-04\n",
      "Epoch 359: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.4254 - bpp: 0.6577 - mse: 1.8742e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4449 - bpp: 0.6677 - mse: 1.8975e-04\n",
      "Epoch 360: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.4449 - bpp: 0.6677 - mse: 1.8975e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3486 - bpp: 0.6610 - mse: 1.6787e-04\n",
      "Epoch 361: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.3486 - bpp: 0.6610 - mse: 1.6787e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4440 - bpp: 0.6602 - mse: 1.9135e-04\n",
      "Epoch 362: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4440 - bpp: 0.6602 - mse: 1.9135e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2865 - bpp: 0.6337 - mse: 1.5937e-04\n",
      "Epoch 363: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2865 - bpp: 0.6337 - mse: 1.5937e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2997 - bpp: 0.6458 - mse: 1.5964e-04\n",
      "Epoch 364: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.2997 - bpp: 0.6458 - mse: 1.5964e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4322 - bpp: 0.6681 - mse: 1.8655e-04\n",
      "Epoch 365: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 32s 156ms/step - loss: 1.4322 - bpp: 0.6681 - mse: 1.8655e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3688 - bpp: 0.6607 - mse: 1.7286e-04\n",
      "Epoch 366: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.3688 - bpp: 0.6607 - mse: 1.7286e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3196 - bpp: 0.6503 - mse: 1.6341e-04\n",
      "Epoch 367: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.3196 - bpp: 0.6503 - mse: 1.6341e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2571 - bpp: 0.6252 - mse: 1.5428e-04\n",
      "Epoch 368: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.2571 - bpp: 0.6252 - mse: 1.5428e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3008 - bpp: 0.6308 - mse: 1.6359e-04\n",
      "Epoch 369: loss did not improve from 1.19793\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.3008 - bpp: 0.6308 - mse: 1.6359e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1533 - bpp: 0.5978 - mse: 1.3562e-04\n",
      "Epoch 370: loss improved from 1.19793 to 1.15328, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.1533 - bpp: 0.5978 - mse: 1.3562e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4104 - bpp: 0.6723 - mse: 1.8019e-04\n",
      "Epoch 371: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 1.4104 - bpp: 0.6723 - mse: 1.8019e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2701 - bpp: 0.6219 - mse: 1.5825e-04\n",
      "Epoch 372: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 1.2701 - bpp: 0.6219 - mse: 1.5825e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3150 - bpp: 0.6330 - mse: 1.6651e-04\n",
      "Epoch 373: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 1.3150 - bpp: 0.6330 - mse: 1.6651e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2853 - bpp: 0.6361 - mse: 1.5850e-04\n",
      "Epoch 374: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.2853 - bpp: 0.6361 - mse: 1.5850e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3605 - bpp: 0.6534 - mse: 1.7265e-04\n",
      "Epoch 375: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 1.3605 - bpp: 0.6534 - mse: 1.7265e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4594 - bpp: 0.6751 - mse: 1.9149e-04\n",
      "Epoch 376: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4594 - bpp: 0.6751 - mse: 1.9149e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3530 - bpp: 0.6676 - mse: 1.6733e-04\n",
      "Epoch 377: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.3530 - bpp: 0.6676 - mse: 1.6733e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2657 - bpp: 0.6385 - mse: 1.5313e-04\n",
      "Epoch 378: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.2657 - bpp: 0.6385 - mse: 1.5313e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5708 - bpp: 0.6942 - mse: 2.1402e-04\n",
      "Epoch 379: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5708 - bpp: 0.6942 - mse: 2.1402e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3382 - bpp: 0.6474 - mse: 1.6866e-04\n",
      "Epoch 380: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3382 - bpp: 0.6474 - mse: 1.6866e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4337 - bpp: 0.6777 - mse: 1.8458e-04\n",
      "Epoch 381: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.4337 - bpp: 0.6777 - mse: 1.8458e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3497 - bpp: 0.6524 - mse: 1.7024e-04\n",
      "Epoch 382: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 190ms/step - loss: 1.3497 - bpp: 0.6524 - mse: 1.7024e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2814 - bpp: 0.6329 - mse: 1.5832e-04\n",
      "Epoch 383: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2814 - bpp: 0.6329 - mse: 1.5832e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2430 - bpp: 0.6207 - mse: 1.5194e-04\n",
      "Epoch 384: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2430 - bpp: 0.6207 - mse: 1.5194e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3226 - bpp: 0.6438 - mse: 1.6572e-04\n",
      "Epoch 385: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.3226 - bpp: 0.6438 - mse: 1.6572e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2371 - bpp: 0.6235 - mse: 1.4979e-04\n",
      "Epoch 386: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2371 - bpp: 0.6235 - mse: 1.4979e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4281 - bpp: 0.6656 - mse: 1.8614e-04\n",
      "Epoch 387: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4281 - bpp: 0.6656 - mse: 1.8614e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2461 - bpp: 0.6218 - mse: 1.5240e-04\n",
      "Epoch 388: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2461 - bpp: 0.6218 - mse: 1.5240e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2053 - bpp: 0.6135 - mse: 1.4448e-04\n",
      "Epoch 389: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2053 - bpp: 0.6135 - mse: 1.4448e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5344 - bpp: 0.6848 - mse: 2.0741e-04\n",
      "Epoch 390: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5344 - bpp: 0.6848 - mse: 2.0741e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3485 - bpp: 0.6513 - mse: 1.7020e-04\n",
      "Epoch 391: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.3485 - bpp: 0.6513 - mse: 1.7020e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1691 - bpp: 0.5999 - mse: 1.3895e-04\n",
      "Epoch 392: loss did not improve from 1.15328\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.1691 - bpp: 0.5999 - mse: 1.3895e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1370 - bpp: 0.5980 - mse: 1.3158e-04\n",
      "Epoch 393: loss improved from 1.15328 to 1.13697, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1370 - bpp: 0.5980 - mse: 1.3158e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2778 - bpp: 0.6302 - mse: 1.5812e-04\n",
      "Epoch 394: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2778 - bpp: 0.6302 - mse: 1.5812e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1937 - bpp: 0.6121 - mse: 1.4199e-04\n",
      "Epoch 395: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1937 - bpp: 0.6121 - mse: 1.4199e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2668 - bpp: 0.6292 - mse: 1.5565e-04\n",
      "Epoch 396: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2668 - bpp: 0.6292 - mse: 1.5565e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3443 - bpp: 0.6542 - mse: 1.6848e-04\n",
      "Epoch 397: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.3443 - bpp: 0.6542 - mse: 1.6848e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2916 - bpp: 0.6365 - mse: 1.5993e-04\n",
      "Epoch 398: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2916 - bpp: 0.6365 - mse: 1.5993e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2366 - bpp: 0.6188 - mse: 1.5083e-04\n",
      "Epoch 399: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2366 - bpp: 0.6188 - mse: 1.5083e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4114 - bpp: 0.6622 - mse: 1.8290e-04\n",
      "Epoch 400: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.4114 - bpp: 0.6622 - mse: 1.8290e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2316 - bpp: 0.6140 - mse: 1.5079e-04\n",
      "Epoch 401: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2316 - bpp: 0.6140 - mse: 1.5079e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2771 - bpp: 0.6328 - mse: 1.5730e-04\n",
      "Epoch 402: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2771 - bpp: 0.6328 - mse: 1.5730e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3469 - bpp: 0.6485 - mse: 1.7052e-04\n",
      "Epoch 403: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3469 - bpp: 0.6485 - mse: 1.7052e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3237 - bpp: 0.6396 - mse: 1.6702e-04\n",
      "Epoch 404: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.3237 - bpp: 0.6396 - mse: 1.6702e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2849 - bpp: 0.6402 - mse: 1.5740e-04\n",
      "Epoch 405: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.2849 - bpp: 0.6402 - mse: 1.5740e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1640 - bpp: 0.6048 - mse: 1.3651e-04\n",
      "Epoch 406: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1640 - bpp: 0.6048 - mse: 1.3651e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3017 - bpp: 0.6360 - mse: 1.6251e-04\n",
      "Epoch 407: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3017 - bpp: 0.6360 - mse: 1.6251e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1531 - bpp: 0.5988 - mse: 1.3535e-04\n",
      "Epoch 408: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1531 - bpp: 0.5988 - mse: 1.3535e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2743 - bpp: 0.6219 - mse: 1.5929e-04\n",
      "Epoch 409: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2743 - bpp: 0.6219 - mse: 1.5929e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3964 - bpp: 0.6550 - mse: 1.8100e-04\n",
      "Epoch 410: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3964 - bpp: 0.6550 - mse: 1.8100e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2459 - bpp: 0.6281 - mse: 1.5084e-04\n",
      "Epoch 411: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2459 - bpp: 0.6281 - mse: 1.5084e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2414 - bpp: 0.6313 - mse: 1.4897e-04\n",
      "Epoch 412: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2414 - bpp: 0.6313 - mse: 1.4897e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3506 - bpp: 0.6482 - mse: 1.7150e-04\n",
      "Epoch 413: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3506 - bpp: 0.6482 - mse: 1.7150e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2764 - bpp: 0.6336 - mse: 1.5695e-04\n",
      "Epoch 414: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2764 - bpp: 0.6336 - mse: 1.5695e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3156 - bpp: 0.6357 - mse: 1.6598e-04\n",
      "Epoch 415: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.3156 - bpp: 0.6357 - mse: 1.6598e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3039 - bpp: 0.6315 - mse: 1.6417e-04\n",
      "Epoch 416: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3039 - bpp: 0.6315 - mse: 1.6417e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2765 - bpp: 0.6242 - mse: 1.5923e-04\n",
      "Epoch 417: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2765 - bpp: 0.6242 - mse: 1.5923e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3644 - bpp: 0.6451 - mse: 1.7561e-04\n",
      "Epoch 418: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.3644 - bpp: 0.6451 - mse: 1.7561e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2841 - bpp: 0.6306 - mse: 1.5954e-04\n",
      "Epoch 419: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2841 - bpp: 0.6306 - mse: 1.5954e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2072 - bpp: 0.6123 - mse: 1.4526e-04\n",
      "Epoch 420: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2072 - bpp: 0.6123 - mse: 1.4526e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2139 - bpp: 0.6153 - mse: 1.4614e-04\n",
      "Epoch 421: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.2139 - bpp: 0.6153 - mse: 1.4614e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2047 - bpp: 0.6074 - mse: 1.4583e-04\n",
      "Epoch 422: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2047 - bpp: 0.6074 - mse: 1.4583e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5920 - bpp: 0.6794 - mse: 2.2281e-04\n",
      "Epoch 423: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5920 - bpp: 0.6794 - mse: 2.2281e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2265 - bpp: 0.6101 - mse: 1.5049e-04\n",
      "Epoch 424: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2265 - bpp: 0.6101 - mse: 1.5049e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1886 - bpp: 0.6037 - mse: 1.4281e-04\n",
      "Epoch 425: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.1886 - bpp: 0.6037 - mse: 1.4281e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2002 - bpp: 0.6043 - mse: 1.4549e-04\n",
      "Epoch 426: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2002 - bpp: 0.6043 - mse: 1.4549e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2841 - bpp: 0.6281 - mse: 1.6016e-04\n",
      "Epoch 427: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2841 - bpp: 0.6281 - mse: 1.6016e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2482 - bpp: 0.6230 - mse: 1.5263e-04\n",
      "Epoch 428: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2482 - bpp: 0.6230 - mse: 1.5263e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3010 - bpp: 0.6309 - mse: 1.6358e-04\n",
      "Epoch 429: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.3010 - bpp: 0.6309 - mse: 1.6358e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2113 - bpp: 0.6074 - mse: 1.4744e-04\n",
      "Epoch 430: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2113 - bpp: 0.6074 - mse: 1.4744e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3507 - bpp: 0.6449 - mse: 1.7232e-04\n",
      "Epoch 431: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3507 - bpp: 0.6449 - mse: 1.7232e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2949 - bpp: 0.6353 - mse: 1.6106e-04\n",
      "Epoch 432: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2949 - bpp: 0.6353 - mse: 1.6106e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3391 - bpp: 0.6488 - mse: 1.6853e-04\n",
      "Epoch 433: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.3391 - bpp: 0.6488 - mse: 1.6853e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2042 - bpp: 0.6022 - mse: 1.4697e-04\n",
      "Epoch 434: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2042 - bpp: 0.6022 - mse: 1.4697e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1873 - bpp: 0.5921 - mse: 1.4532e-04\n",
      "Epoch 435: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1873 - bpp: 0.5921 - mse: 1.4532e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4227 - bpp: 0.6640 - mse: 1.8523e-04\n",
      "Epoch 436: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.4227 - bpp: 0.6640 - mse: 1.8523e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1850 - bpp: 0.6069 - mse: 1.4113e-04\n",
      "Epoch 437: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1850 - bpp: 0.6069 - mse: 1.4113e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3517 - bpp: 0.6247 - mse: 1.7749e-04\n",
      "Epoch 438: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.3517 - bpp: 0.6247 - mse: 1.7749e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3704 - bpp: 0.6487 - mse: 1.7619e-04\n",
      "Epoch 439: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.3704 - bpp: 0.6487 - mse: 1.7619e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2111 - bpp: 0.6047 - mse: 1.4804e-04\n",
      "Epoch 440: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2111 - bpp: 0.6047 - mse: 1.4804e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2808 - bpp: 0.6349 - mse: 1.5770e-04\n",
      "Epoch 441: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2808 - bpp: 0.6349 - mse: 1.5770e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2745 - bpp: 0.6305 - mse: 1.5724e-04\n",
      "Epoch 442: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2745 - bpp: 0.6305 - mse: 1.5724e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2770 - bpp: 0.6311 - mse: 1.5769e-04\n",
      "Epoch 443: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2770 - bpp: 0.6311 - mse: 1.5769e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2521 - bpp: 0.6301 - mse: 1.5185e-04\n",
      "Epoch 444: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2521 - bpp: 0.6301 - mse: 1.5185e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3418 - bpp: 0.6315 - mse: 1.7343e-04\n",
      "Epoch 445: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.3418 - bpp: 0.6315 - mse: 1.7343e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2620 - bpp: 0.6197 - mse: 1.5681e-04\n",
      "Epoch 446: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2620 - bpp: 0.6197 - mse: 1.5681e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2420 - bpp: 0.6159 - mse: 1.5286e-04\n",
      "Epoch 447: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2420 - bpp: 0.6159 - mse: 1.5286e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2308 - bpp: 0.6135 - mse: 1.5072e-04\n",
      "Epoch 448: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2308 - bpp: 0.6135 - mse: 1.5072e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2163 - bpp: 0.6107 - mse: 1.4785e-04\n",
      "Epoch 449: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2163 - bpp: 0.6107 - mse: 1.4785e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1531 - bpp: 0.5949 - mse: 1.3627e-04\n",
      "Epoch 450: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1531 - bpp: 0.5949 - mse: 1.3627e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3201 - bpp: 0.6345 - mse: 1.6739e-04\n",
      "Epoch 451: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.3201 - bpp: 0.6345 - mse: 1.6739e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2128 - bpp: 0.6127 - mse: 1.4651e-04\n",
      "Epoch 452: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.2128 - bpp: 0.6127 - mse: 1.4651e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2939 - bpp: 0.6323 - mse: 1.6152e-04\n",
      "Epoch 453: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2939 - bpp: 0.6323 - mse: 1.6152e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5871 - mse: 1.3886e-04\n",
      "Epoch 454: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1559 - bpp: 0.5871 - mse: 1.3886e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2511 - bpp: 0.6214 - mse: 1.5373e-04\n",
      "Epoch 455: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2511 - bpp: 0.6214 - mse: 1.5373e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3020 - bpp: 0.6338 - mse: 1.6312e-04\n",
      "Epoch 456: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3020 - bpp: 0.6338 - mse: 1.6312e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2606 - bpp: 0.6203 - mse: 1.5634e-04\n",
      "Epoch 457: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2606 - bpp: 0.6203 - mse: 1.5634e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1804 - bpp: 0.6100 - mse: 1.3926e-04\n",
      "Epoch 458: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1804 - bpp: 0.6100 - mse: 1.3926e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2008 - bpp: 0.6095 - mse: 1.4436e-04\n",
      "Epoch 459: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2008 - bpp: 0.6095 - mse: 1.4436e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2528 - bpp: 0.6194 - mse: 1.5465e-04\n",
      "Epoch 460: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2528 - bpp: 0.6194 - mse: 1.5465e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3362 - bpp: 0.6360 - mse: 1.7095e-04\n",
      "Epoch 461: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3362 - bpp: 0.6360 - mse: 1.7095e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3488 - bpp: 0.6302 - mse: 1.7543e-04\n",
      "Epoch 462: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3488 - bpp: 0.6302 - mse: 1.7543e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5838 - bpp: 0.6692 - mse: 2.2329e-04\n",
      "Epoch 463: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5838 - bpp: 0.6692 - mse: 2.2329e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2209 - bpp: 0.6153 - mse: 1.4785e-04\n",
      "Epoch 464: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2209 - bpp: 0.6153 - mse: 1.4785e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2933 - bpp: 0.6299 - mse: 1.6197e-04\n",
      "Epoch 465: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2933 - bpp: 0.6299 - mse: 1.6197e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2501 - bpp: 0.6173 - mse: 1.5449e-04\n",
      "Epoch 466: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2501 - bpp: 0.6173 - mse: 1.5449e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2790 - bpp: 0.6317 - mse: 1.5804e-04\n",
      "Epoch 467: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2790 - bpp: 0.6317 - mse: 1.5804e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5949 - bpp: 0.6630 - mse: 2.2751e-04\n",
      "Epoch 468: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5949 - bpp: 0.6630 - mse: 2.2751e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1937 - bpp: 0.6166 - mse: 1.4089e-04\n",
      "Epoch 469: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1937 - bpp: 0.6166 - mse: 1.4089e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2189 - bpp: 0.6224 - mse: 1.4561e-04\n",
      "Epoch 470: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2189 - bpp: 0.6224 - mse: 1.4561e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2131 - bpp: 0.6024 - mse: 1.4910e-04\n",
      "Epoch 471: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2131 - bpp: 0.6024 - mse: 1.4910e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3507 - bpp: 0.6437 - mse: 1.7260e-04\n",
      "Epoch 472: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.3507 - bpp: 0.6437 - mse: 1.7260e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2586 - bpp: 0.6198 - mse: 1.5595e-04\n",
      "Epoch 473: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2586 - bpp: 0.6198 - mse: 1.5595e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1732 - bpp: 0.5950 - mse: 1.4116e-04\n",
      "Epoch 474: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1732 - bpp: 0.5950 - mse: 1.4116e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2518 - bpp: 0.6188 - mse: 1.5455e-04\n",
      "Epoch 475: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.2518 - bpp: 0.6188 - mse: 1.5455e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2061 - bpp: 0.6159 - mse: 1.4408e-04\n",
      "Epoch 476: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2061 - bpp: 0.6159 - mse: 1.4408e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1391 - bpp: 0.5940 - mse: 1.3309e-04\n",
      "Epoch 477: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1391 - bpp: 0.5940 - mse: 1.3309e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2458 - bpp: 0.6211 - mse: 1.5254e-04\n",
      "Epoch 478: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2458 - bpp: 0.6211 - mse: 1.5254e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2282 - bpp: 0.6091 - mse: 1.5116e-04\n",
      "Epoch 479: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2282 - bpp: 0.6091 - mse: 1.5116e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1392 - bpp: 0.5880 - mse: 1.3457e-04\n",
      "Epoch 480: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1392 - bpp: 0.5880 - mse: 1.3457e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3318 - bpp: 0.6354 - mse: 1.7002e-04\n",
      "Epoch 481: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.3318 - bpp: 0.6354 - mse: 1.7002e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1410 - bpp: 0.5894 - mse: 1.3467e-04\n",
      "Epoch 482: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1410 - bpp: 0.5894 - mse: 1.3467e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2333 - bpp: 0.6080 - mse: 1.5267e-04\n",
      "Epoch 483: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.2333 - bpp: 0.6080 - mse: 1.5267e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2882 - bpp: 0.6176 - mse: 1.6374e-04\n",
      "Epoch 484: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2882 - bpp: 0.6176 - mse: 1.6374e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1881 - bpp: 0.5941 - mse: 1.4501e-04\n",
      "Epoch 485: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1881 - bpp: 0.5941 - mse: 1.4501e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2890 - bpp: 0.6283 - mse: 1.6130e-04\n",
      "Epoch 486: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2890 - bpp: 0.6283 - mse: 1.6130e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3140 - bpp: 0.6395 - mse: 1.6468e-04\n",
      "Epoch 487: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3140 - bpp: 0.6395 - mse: 1.6468e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1635 - bpp: 0.5922 - mse: 1.3948e-04\n",
      "Epoch 488: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1635 - bpp: 0.5922 - mse: 1.3948e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2562 - bpp: 0.6183 - mse: 1.5574e-04\n",
      "Epoch 489: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2562 - bpp: 0.6183 - mse: 1.5574e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1990 - bpp: 0.6007 - mse: 1.4608e-04\n",
      "Epoch 490: loss did not improve from 1.13697\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1990 - bpp: 0.6007 - mse: 1.4608e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1103 - bpp: 0.5807 - mse: 1.2930e-04\n",
      "Epoch 491: loss improved from 1.13697 to 1.11033, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1103 - bpp: 0.5807 - mse: 1.2930e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2323 - bpp: 0.6075 - mse: 1.5254e-04\n",
      "Epoch 492: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2323 - bpp: 0.6075 - mse: 1.5254e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2126 - bpp: 0.5989 - mse: 1.4984e-04\n",
      "Epoch 493: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2126 - bpp: 0.5989 - mse: 1.4984e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1759 - bpp: 0.6043 - mse: 1.3956e-04\n",
      "Epoch 494: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1759 - bpp: 0.6043 - mse: 1.3956e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2895 - bpp: 0.6256 - mse: 1.6209e-04\n",
      "Epoch 495: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.2895 - bpp: 0.6256 - mse: 1.6209e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1799 - bpp: 0.5941 - mse: 1.4301e-04\n",
      "Epoch 496: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1799 - bpp: 0.5941 - mse: 1.4301e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4169 - bpp: 0.6212 - mse: 1.9425e-04\n",
      "Epoch 497: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4169 - bpp: 0.6212 - mse: 1.9425e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4162 - bpp: 0.6604 - mse: 1.8453e-04\n",
      "Epoch 498: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4162 - bpp: 0.6604 - mse: 1.8453e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2275 - bpp: 0.6069 - mse: 1.5150e-04\n",
      "Epoch 499: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2275 - bpp: 0.6069 - mse: 1.5150e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1735 - bpp: 0.5989 - mse: 1.4028e-04\n",
      "Epoch 500: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1735 - bpp: 0.5989 - mse: 1.4028e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3980 - bpp: 0.6570 - mse: 1.8091e-04\n",
      "Epoch 501: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.3980 - bpp: 0.6570 - mse: 1.8091e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2637 - bpp: 0.6247 - mse: 1.5601e-04\n",
      "Epoch 502: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2637 - bpp: 0.6247 - mse: 1.5601e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2007 - bpp: 0.5967 - mse: 1.4746e-04\n",
      "Epoch 503: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2007 - bpp: 0.5967 - mse: 1.4746e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2688 - bpp: 0.6215 - mse: 1.5804e-04\n",
      "Epoch 504: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2688 - bpp: 0.6215 - mse: 1.5804e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2750 - bpp: 0.6277 - mse: 1.5802e-04\n",
      "Epoch 505: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2750 - bpp: 0.6277 - mse: 1.5802e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2385 - bpp: 0.6011 - mse: 1.5563e-04\n",
      "Epoch 506: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2385 - bpp: 0.6011 - mse: 1.5563e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.5980 - mse: 1.4506e-04\n",
      "Epoch 507: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1922 - bpp: 0.5980 - mse: 1.4506e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2073 - bpp: 0.5922 - mse: 1.5018e-04\n",
      "Epoch 508: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2073 - bpp: 0.5922 - mse: 1.5018e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2343 - bpp: 0.6115 - mse: 1.5205e-04\n",
      "Epoch 509: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.2343 - bpp: 0.6115 - mse: 1.5205e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4195 - bpp: 0.6587 - mse: 1.8573e-04\n",
      "Epoch 510: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4195 - bpp: 0.6587 - mse: 1.8573e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2950 - bpp: 0.6279 - mse: 1.6288e-04\n",
      "Epoch 511: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2950 - bpp: 0.6279 - mse: 1.6288e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2213 - bpp: 0.6063 - mse: 1.5016e-04\n",
      "Epoch 512: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2213 - bpp: 0.6063 - mse: 1.5016e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3386 - bpp: 0.6270 - mse: 1.7373e-04\n",
      "Epoch 513: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3386 - bpp: 0.6270 - mse: 1.7373e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3374 - bpp: 0.6296 - mse: 1.7279e-04\n",
      "Epoch 514: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3374 - bpp: 0.6296 - mse: 1.7279e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2627 - bpp: 0.6220 - mse: 1.5642e-04\n",
      "Epoch 515: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2627 - bpp: 0.6220 - mse: 1.5642e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3189 - bpp: 0.6408 - mse: 1.6554e-04\n",
      "Epoch 516: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3189 - bpp: 0.6408 - mse: 1.6554e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3003 - bpp: 0.6362 - mse: 1.6214e-04\n",
      "Epoch 517: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.3003 - bpp: 0.6362 - mse: 1.6214e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2998 - bpp: 0.6318 - mse: 1.6307e-04\n",
      "Epoch 518: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2998 - bpp: 0.6318 - mse: 1.6307e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2402 - bpp: 0.6246 - mse: 1.5031e-04\n",
      "Epoch 519: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2402 - bpp: 0.6246 - mse: 1.5031e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1637 - bpp: 0.5961 - mse: 1.3859e-04\n",
      "Epoch 520: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1637 - bpp: 0.5961 - mse: 1.3859e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1940 - bpp: 0.5993 - mse: 1.4520e-04\n",
      "Epoch 521: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.1940 - bpp: 0.5993 - mse: 1.4520e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2587 - bpp: 0.6209 - mse: 1.5571e-04\n",
      "Epoch 522: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2587 - bpp: 0.6209 - mse: 1.5571e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2540 - bpp: 0.6168 - mse: 1.5556e-04\n",
      "Epoch 523: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2540 - bpp: 0.6168 - mse: 1.5556e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3878 - bpp: 0.6581 - mse: 1.7813e-04\n",
      "Epoch 524: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3878 - bpp: 0.6581 - mse: 1.7813e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3554 - bpp: 0.6514 - mse: 1.7189e-04\n",
      "Epoch 525: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.3554 - bpp: 0.6514 - mse: 1.7189e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2948 - bpp: 0.6310 - mse: 1.6206e-04\n",
      "Epoch 526: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2948 - bpp: 0.6310 - mse: 1.6206e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2982 - bpp: 0.6383 - mse: 1.6110e-04\n",
      "Epoch 527: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2982 - bpp: 0.6383 - mse: 1.6110e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2335 - bpp: 0.6146 - mse: 1.5110e-04\n",
      "Epoch 528: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2335 - bpp: 0.6146 - mse: 1.5110e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2674 - bpp: 0.6289 - mse: 1.5587e-04\n",
      "Epoch 529: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2674 - bpp: 0.6289 - mse: 1.5587e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1985 - bpp: 0.6158 - mse: 1.4226e-04\n",
      "Epoch 530: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.1985 - bpp: 0.6158 - mse: 1.4226e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2103 - bpp: 0.6092 - mse: 1.4676e-04\n",
      "Epoch 531: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.2103 - bpp: 0.6092 - mse: 1.4676e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2232 - bpp: 0.6061 - mse: 1.5065e-04\n",
      "Epoch 532: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2232 - bpp: 0.6061 - mse: 1.5065e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1244 - bpp: 0.5897 - mse: 1.3053e-04\n",
      "Epoch 533: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1244 - bpp: 0.5897 - mse: 1.3053e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2812 - bpp: 0.6324 - mse: 1.5841e-04\n",
      "Epoch 534: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.2812 - bpp: 0.6324 - mse: 1.5841e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2961 - bpp: 0.6229 - mse: 1.6435e-04\n",
      "Epoch 535: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2961 - bpp: 0.6229 - mse: 1.6435e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2901 - bpp: 0.6289 - mse: 1.6144e-04\n",
      "Epoch 536: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2901 - bpp: 0.6289 - mse: 1.6144e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3856 - bpp: 0.6354 - mse: 1.8315e-04\n",
      "Epoch 537: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.3856 - bpp: 0.6354 - mse: 1.8315e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1464 - bpp: 0.5888 - mse: 1.3614e-04\n",
      "Epoch 538: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1464 - bpp: 0.5888 - mse: 1.3614e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1542 - bpp: 0.5966 - mse: 1.3614e-04\n",
      "Epoch 539: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1542 - bpp: 0.5966 - mse: 1.3614e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1911 - bpp: 0.6015 - mse: 1.4394e-04\n",
      "Epoch 540: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1911 - bpp: 0.6015 - mse: 1.4394e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3285 - bpp: 0.6300 - mse: 1.7053e-04\n",
      "Epoch 541: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.3285 - bpp: 0.6300 - mse: 1.7053e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1633 - bpp: 0.5937 - mse: 1.3907e-04\n",
      "Epoch 542: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1633 - bpp: 0.5937 - mse: 1.3907e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1224 - bpp: 0.5778 - mse: 1.3296e-04\n",
      "Epoch 543: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1224 - bpp: 0.5778 - mse: 1.3296e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1436 - bpp: 0.5828 - mse: 1.3692e-04\n",
      "Epoch 544: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1436 - bpp: 0.5828 - mse: 1.3692e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2136 - bpp: 0.6086 - mse: 1.4770e-04\n",
      "Epoch 545: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2136 - bpp: 0.6086 - mse: 1.4770e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2514 - bpp: 0.6134 - mse: 1.5576e-04\n",
      "Epoch 546: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2514 - bpp: 0.6134 - mse: 1.5576e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2139 - bpp: 0.6163 - mse: 1.4589e-04\n",
      "Epoch 547: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.2139 - bpp: 0.6163 - mse: 1.4589e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2258 - bpp: 0.6058 - mse: 1.5136e-04\n",
      "Epoch 548: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2258 - bpp: 0.6058 - mse: 1.5136e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2447 - bpp: 0.6192 - mse: 1.5271e-04\n",
      "Epoch 549: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2447 - bpp: 0.6192 - mse: 1.5271e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1646 - bpp: 0.5956 - mse: 1.3890e-04\n",
      "Epoch 550: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1646 - bpp: 0.5956 - mse: 1.3890e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2392 - bpp: 0.6100 - mse: 1.5362e-04\n",
      "Epoch 551: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2392 - bpp: 0.6100 - mse: 1.5362e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2002 - bpp: 0.5949 - mse: 1.4777e-04\n",
      "Epoch 552: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2002 - bpp: 0.5949 - mse: 1.4777e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2717 - bpp: 0.6198 - mse: 1.5917e-04\n",
      "Epoch 553: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2717 - bpp: 0.6198 - mse: 1.5917e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2367 - bpp: 0.6096 - mse: 1.5310e-04\n",
      "Epoch 554: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2367 - bpp: 0.6096 - mse: 1.5310e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2069 - bpp: 0.6059 - mse: 1.4672e-04\n",
      "Epoch 555: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2069 - bpp: 0.6059 - mse: 1.4672e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1313 - bpp: 0.5818 - mse: 1.3415e-04\n",
      "Epoch 556: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1313 - bpp: 0.5818 - mse: 1.3415e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1438 - bpp: 0.5810 - mse: 1.3741e-04\n",
      "Epoch 557: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1438 - bpp: 0.5810 - mse: 1.3741e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2808 - bpp: 0.6190 - mse: 1.6157e-04\n",
      "Epoch 558: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2808 - bpp: 0.6190 - mse: 1.6157e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2264 - bpp: 0.6078 - mse: 1.5103e-04\n",
      "Epoch 559: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2264 - bpp: 0.6078 - mse: 1.5103e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4254 - bpp: 0.6589 - mse: 1.8713e-04\n",
      "Epoch 560: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.4254 - bpp: 0.6589 - mse: 1.8713e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1484 - bpp: 0.5850 - mse: 1.3754e-04\n",
      "Epoch 561: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1484 - bpp: 0.5850 - mse: 1.3754e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2087 - bpp: 0.5983 - mse: 1.4904e-04\n",
      "Epoch 562: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2087 - bpp: 0.5983 - mse: 1.4904e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2761 - bpp: 0.6144 - mse: 1.6154e-04\n",
      "Epoch 563: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2761 - bpp: 0.6144 - mse: 1.6154e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2241 - bpp: 0.6137 - mse: 1.4903e-04\n",
      "Epoch 564: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2241 - bpp: 0.6137 - mse: 1.4903e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3449 - bpp: 0.6221 - mse: 1.7648e-04\n",
      "Epoch 565: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3449 - bpp: 0.6221 - mse: 1.7648e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1918 - bpp: 0.5992 - mse: 1.4468e-04\n",
      "Epoch 566: loss did not improve from 1.11033\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1918 - bpp: 0.5992 - mse: 1.4468e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0839 - bpp: 0.5587 - mse: 1.2823e-04\n",
      "Epoch 567: loss improved from 1.11033 to 1.08390, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0839 - bpp: 0.5587 - mse: 1.2823e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1789 - bpp: 0.6034 - mse: 1.4048e-04\n",
      "Epoch 568: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1789 - bpp: 0.6034 - mse: 1.4048e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1254 - bpp: 0.5873 - mse: 1.3138e-04\n",
      "Epoch 569: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1254 - bpp: 0.5873 - mse: 1.3138e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1708 - bpp: 0.5962 - mse: 1.4029e-04\n",
      "Epoch 570: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1708 - bpp: 0.5962 - mse: 1.4029e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2442 - bpp: 0.6159 - mse: 1.5340e-04\n",
      "Epoch 571: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2442 - bpp: 0.6159 - mse: 1.5340e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2213 - bpp: 0.6079 - mse: 1.4976e-04\n",
      "Epoch 572: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2213 - bpp: 0.6079 - mse: 1.4976e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2008 - bpp: 0.5987 - mse: 1.4701e-04\n",
      "Epoch 573: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2008 - bpp: 0.5987 - mse: 1.4701e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1549 - bpp: 0.5911 - mse: 1.3763e-04\n",
      "Epoch 574: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1549 - bpp: 0.5911 - mse: 1.3763e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1428 - bpp: 0.5944 - mse: 1.3388e-04\n",
      "Epoch 575: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1428 - bpp: 0.5944 - mse: 1.3388e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1835 - bpp: 0.5964 - mse: 1.4334e-04\n",
      "Epoch 576: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1835 - bpp: 0.5964 - mse: 1.4334e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1219 - bpp: 0.5704 - mse: 1.3463e-04\n",
      "Epoch 577: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1219 - bpp: 0.5704 - mse: 1.3463e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2743 - bpp: 0.6243 - mse: 1.5869e-04\n",
      "Epoch 578: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2743 - bpp: 0.6243 - mse: 1.5869e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1738 - bpp: 0.5908 - mse: 1.4232e-04\n",
      "Epoch 579: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1738 - bpp: 0.5908 - mse: 1.4232e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0988 - bpp: 0.5766 - mse: 1.2749e-04\n",
      "Epoch 580: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0988 - bpp: 0.5766 - mse: 1.2749e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2774 - bpp: 0.6248 - mse: 1.5932e-04\n",
      "Epoch 581: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.2774 - bpp: 0.6248 - mse: 1.5932e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.6075 - mse: 1.4273e-04\n",
      "Epoch 582: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1922 - bpp: 0.6075 - mse: 1.4273e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1256 - bpp: 0.5769 - mse: 1.3396e-04\n",
      "Epoch 583: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1256 - bpp: 0.5769 - mse: 1.3396e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1463 - bpp: 0.5879 - mse: 1.3633e-04\n",
      "Epoch 584: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.1463 - bpp: 0.5879 - mse: 1.3633e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2436 - bpp: 0.6126 - mse: 1.5405e-04\n",
      "Epoch 585: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2436 - bpp: 0.6126 - mse: 1.5405e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2545 - bpp: 0.6096 - mse: 1.5744e-04\n",
      "Epoch 586: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.2545 - bpp: 0.6096 - mse: 1.5744e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1982 - bpp: 0.5925 - mse: 1.4788e-04\n",
      "Epoch 587: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1982 - bpp: 0.5925 - mse: 1.4788e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2537 - bpp: 0.6097 - mse: 1.5724e-04\n",
      "Epoch 588: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.2537 - bpp: 0.6097 - mse: 1.5724e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2621 - bpp: 0.6106 - mse: 1.5905e-04\n",
      "Epoch 589: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2621 - bpp: 0.6106 - mse: 1.5905e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2032 - bpp: 0.6057 - mse: 1.4587e-04\n",
      "Epoch 590: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2032 - bpp: 0.6057 - mse: 1.4587e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2909 - bpp: 0.6248 - mse: 1.6262e-04\n",
      "Epoch 591: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2909 - bpp: 0.6248 - mse: 1.6262e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2664 - bpp: 0.6152 - mse: 1.5898e-04\n",
      "Epoch 592: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.2664 - bpp: 0.6152 - mse: 1.5898e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2354 - bpp: 0.6085 - mse: 1.5305e-04\n",
      "Epoch 593: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.2354 - bpp: 0.6085 - mse: 1.5305e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1863 - bpp: 0.5832 - mse: 1.4724e-04\n",
      "Epoch 594: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1863 - bpp: 0.5832 - mse: 1.4724e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1176 - bpp: 0.5691 - mse: 1.3392e-04\n",
      "Epoch 595: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1176 - bpp: 0.5691 - mse: 1.3392e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2268 - bpp: 0.6131 - mse: 1.4984e-04\n",
      "Epoch 596: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2268 - bpp: 0.6131 - mse: 1.4984e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.6074 - mse: 1.4388e-04\n",
      "Epoch 597: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1967 - bpp: 0.6074 - mse: 1.4388e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1802 - bpp: 0.5890 - mse: 1.4434e-04\n",
      "Epoch 598: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1802 - bpp: 0.5890 - mse: 1.4434e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2010 - bpp: 0.6052 - mse: 1.4548e-04\n",
      "Epoch 599: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2010 - bpp: 0.6052 - mse: 1.4548e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3197 - bpp: 0.6318 - mse: 1.6794e-04\n",
      "Epoch 600: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.3197 - bpp: 0.6318 - mse: 1.6794e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1649 - bpp: 0.5940 - mse: 1.3938e-04\n",
      "Epoch 601: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.1649 - bpp: 0.5940 - mse: 1.3938e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2021 - bpp: 0.5989 - mse: 1.4725e-04\n",
      "Epoch 602: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2021 - bpp: 0.5989 - mse: 1.4725e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1995 - bpp: 0.5981 - mse: 1.4683e-04\n",
      "Epoch 603: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1995 - bpp: 0.5981 - mse: 1.4683e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2604 - bpp: 0.6105 - mse: 1.5866e-04\n",
      "Epoch 604: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2604 - bpp: 0.6105 - mse: 1.5866e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2301 - bpp: 0.6075 - mse: 1.5201e-04\n",
      "Epoch 605: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.2301 - bpp: 0.6075 - mse: 1.5201e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1813 - bpp: 0.5964 - mse: 1.4279e-04\n",
      "Epoch 606: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1813 - bpp: 0.5964 - mse: 1.4279e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2083 - bpp: 0.6061 - mse: 1.4700e-04\n",
      "Epoch 607: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2083 - bpp: 0.6061 - mse: 1.4700e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3116 - bpp: 0.6327 - mse: 1.6573e-04\n",
      "Epoch 608: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3116 - bpp: 0.6327 - mse: 1.6573e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2863 - bpp: 0.6114 - mse: 1.6477e-04\n",
      "Epoch 609: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.2863 - bpp: 0.6114 - mse: 1.6477e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1621 - bpp: 0.5885 - mse: 1.4003e-04\n",
      "Epoch 610: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1621 - bpp: 0.5885 - mse: 1.4003e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2812 - bpp: 0.6160 - mse: 1.6241e-04\n",
      "Epoch 611: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2812 - bpp: 0.6160 - mse: 1.6241e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1481 - bpp: 0.5798 - mse: 1.3874e-04\n",
      "Epoch 612: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1481 - bpp: 0.5798 - mse: 1.3874e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1830 - bpp: 0.5988 - mse: 1.4263e-04\n",
      "Epoch 613: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1830 - bpp: 0.5988 - mse: 1.4263e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2198 - bpp: 0.5982 - mse: 1.5177e-04\n",
      "Epoch 614: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2198 - bpp: 0.5982 - mse: 1.5177e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1651 - bpp: 0.5999 - mse: 1.3798e-04\n",
      "Epoch 615: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1651 - bpp: 0.5999 - mse: 1.3798e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1995 - bpp: 0.6054 - mse: 1.4502e-04\n",
      "Epoch 616: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1995 - bpp: 0.6054 - mse: 1.4502e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1397 - bpp: 0.5852 - mse: 1.3538e-04\n",
      "Epoch 617: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1397 - bpp: 0.5852 - mse: 1.3538e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2084 - bpp: 0.5971 - mse: 1.4925e-04\n",
      "Epoch 618: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2084 - bpp: 0.5971 - mse: 1.4925e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2958 - bpp: 0.6365 - mse: 1.6096e-04\n",
      "Epoch 619: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2958 - bpp: 0.6365 - mse: 1.6096e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2373 - bpp: 0.6129 - mse: 1.5245e-04\n",
      "Epoch 620: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2373 - bpp: 0.6129 - mse: 1.5245e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3706 - bpp: 0.6541 - mse: 1.7492e-04\n",
      "Epoch 621: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3706 - bpp: 0.6541 - mse: 1.7492e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1882 - bpp: 0.5936 - mse: 1.4517e-04\n",
      "Epoch 622: loss did not improve from 1.08390\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1882 - bpp: 0.5936 - mse: 1.4517e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0377 - bpp: 0.5571 - mse: 1.1735e-04\n",
      "Epoch 623: loss improved from 1.08390 to 1.03774, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0377 - bpp: 0.5571 - mse: 1.1735e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1653 - bpp: 0.5796 - mse: 1.4299e-04\n",
      "Epoch 624: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.1653 - bpp: 0.5796 - mse: 1.4299e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2339 - bpp: 0.6056 - mse: 1.5337e-04\n",
      "Epoch 625: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.2339 - bpp: 0.6056 - mse: 1.5337e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0809 - bpp: 0.5635 - mse: 1.2631e-04\n",
      "Epoch 626: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.0809 - bpp: 0.5635 - mse: 1.2631e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3189 - bpp: 0.6330 - mse: 1.6746e-04\n",
      "Epoch 627: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3189 - bpp: 0.6330 - mse: 1.6746e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0414 - bpp: 0.5605 - mse: 1.1740e-04\n",
      "Epoch 628: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0414 - bpp: 0.5605 - mse: 1.1740e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1388 - bpp: 0.5855 - mse: 1.3509e-04\n",
      "Epoch 629: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1388 - bpp: 0.5855 - mse: 1.3509e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1820 - bpp: 0.5979 - mse: 1.4259e-04\n",
      "Epoch 630: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1820 - bpp: 0.5979 - mse: 1.4259e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2085 - bpp: 0.6037 - mse: 1.4768e-04\n",
      "Epoch 631: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2085 - bpp: 0.6037 - mse: 1.4768e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1454 - bpp: 0.5833 - mse: 1.3725e-04\n",
      "Epoch 632: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1454 - bpp: 0.5833 - mse: 1.3725e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1980 - bpp: 0.6128 - mse: 1.4286e-04\n",
      "Epoch 633: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1980 - bpp: 0.6128 - mse: 1.4286e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2372 - bpp: 0.6205 - mse: 1.5058e-04\n",
      "Epoch 634: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2372 - bpp: 0.6205 - mse: 1.5058e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2442 - bpp: 0.6101 - mse: 1.5482e-04\n",
      "Epoch 635: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2442 - bpp: 0.6101 - mse: 1.5482e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1673 - bpp: 0.5972 - mse: 1.3919e-04\n",
      "Epoch 636: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1673 - bpp: 0.5972 - mse: 1.3919e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2038 - bpp: 0.6019 - mse: 1.4693e-04\n",
      "Epoch 637: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2038 - bpp: 0.6019 - mse: 1.4693e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1484 - bpp: 0.5841 - mse: 1.3775e-04\n",
      "Epoch 638: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1484 - bpp: 0.5841 - mse: 1.3775e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1752 - bpp: 0.5954 - mse: 1.4154e-04\n",
      "Epoch 639: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1752 - bpp: 0.5954 - mse: 1.4154e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3404 - bpp: 0.6482 - mse: 1.6899e-04\n",
      "Epoch 640: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.3404 - bpp: 0.6482 - mse: 1.6899e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2046 - bpp: 0.5972 - mse: 1.4829e-04\n",
      "Epoch 641: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.2046 - bpp: 0.5972 - mse: 1.4829e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0892 - bpp: 0.5650 - mse: 1.2799e-04\n",
      "Epoch 642: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.0892 - bpp: 0.5650 - mse: 1.2799e-04\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1612 - bpp: 0.5874 - mse: 1.4008e-04\n",
      "Epoch 643: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.1612 - bpp: 0.5874 - mse: 1.4008e-04\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2337 - bpp: 0.6046 - mse: 1.5359e-04\n",
      "Epoch 644: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2337 - bpp: 0.6046 - mse: 1.5359e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2964 - bpp: 0.6314 - mse: 1.6236e-04\n",
      "Epoch 645: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2964 - bpp: 0.6314 - mse: 1.6236e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1599 - bpp: 0.5853 - mse: 1.4029e-04\n",
      "Epoch 646: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1599 - bpp: 0.5853 - mse: 1.4029e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1986 - bpp: 0.5847 - mse: 1.4988e-04\n",
      "Epoch 647: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1986 - bpp: 0.5847 - mse: 1.4988e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1322 - bpp: 0.5661 - mse: 1.3820e-04\n",
      "Epoch 648: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1322 - bpp: 0.5661 - mse: 1.3820e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3143 - bpp: 0.6249 - mse: 1.6831e-04\n",
      "Epoch 649: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.3143 - bpp: 0.6249 - mse: 1.6831e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1140 - bpp: 0.5713 - mse: 1.3250e-04\n",
      "Epoch 650: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1140 - bpp: 0.5713 - mse: 1.3250e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2747 - bpp: 0.6162 - mse: 1.6077e-04\n",
      "Epoch 651: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2747 - bpp: 0.6162 - mse: 1.6077e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1850 - bpp: 0.6032 - mse: 1.4203e-04\n",
      "Epoch 652: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1850 - bpp: 0.6032 - mse: 1.4203e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1800 - bpp: 0.5927 - mse: 1.4338e-04\n",
      "Epoch 653: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1800 - bpp: 0.5927 - mse: 1.4338e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2014 - bpp: 0.6052 - mse: 1.4557e-04\n",
      "Epoch 654: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.2014 - bpp: 0.6052 - mse: 1.4557e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2417 - bpp: 0.6123 - mse: 1.5367e-04\n",
      "Epoch 655: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.2417 - bpp: 0.6123 - mse: 1.5367e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0989 - bpp: 0.5666 - mse: 1.2997e-04\n",
      "Epoch 656: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0989 - bpp: 0.5666 - mse: 1.2997e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1637 - bpp: 0.5867 - mse: 1.4088e-04\n",
      "Epoch 657: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.1637 - bpp: 0.5867 - mse: 1.4088e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0803 - bpp: 0.5717 - mse: 1.2416e-04\n",
      "Epoch 658: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0803 - bpp: 0.5717 - mse: 1.2416e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2094 - bpp: 0.6003 - mse: 1.4872e-04\n",
      "Epoch 659: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2094 - bpp: 0.6003 - mse: 1.4872e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1176 - bpp: 0.5671 - mse: 1.3440e-04\n",
      "Epoch 660: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.1176 - bpp: 0.5671 - mse: 1.3440e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1459 - bpp: 0.5857 - mse: 1.3677e-04\n",
      "Epoch 661: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1459 - bpp: 0.5857 - mse: 1.3677e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0689 - bpp: 0.5568 - mse: 1.2501e-04\n",
      "Epoch 662: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0689 - bpp: 0.5568 - mse: 1.2501e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1092 - bpp: 0.5739 - mse: 1.3067e-04\n",
      "Epoch 663: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1092 - bpp: 0.5739 - mse: 1.3067e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2279 - bpp: 0.5978 - mse: 1.5383e-04\n",
      "Epoch 664: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2279 - bpp: 0.5978 - mse: 1.5383e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1915 - bpp: 0.5882 - mse: 1.4728e-04\n",
      "Epoch 665: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1915 - bpp: 0.5882 - mse: 1.4728e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0554 - bpp: 0.5498 - mse: 1.2343e-04\n",
      "Epoch 666: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0554 - bpp: 0.5498 - mse: 1.2343e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1763 - bpp: 0.5977 - mse: 1.4128e-04\n",
      "Epoch 667: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1763 - bpp: 0.5977 - mse: 1.4128e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1768 - bpp: 0.5889 - mse: 1.4353e-04\n",
      "Epoch 668: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1768 - bpp: 0.5889 - mse: 1.4353e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3337 - bpp: 0.6337 - mse: 1.7090e-04\n",
      "Epoch 669: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.3337 - bpp: 0.6337 - mse: 1.7090e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1644 - bpp: 0.5848 - mse: 1.4150e-04\n",
      "Epoch 670: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1644 - bpp: 0.5848 - mse: 1.4150e-04\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1718 - bpp: 0.5859 - mse: 1.4306e-04\n",
      "Epoch 671: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1718 - bpp: 0.5859 - mse: 1.4306e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1107 - bpp: 0.5819 - mse: 1.2911e-04\n",
      "Epoch 672: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 1.1107 - bpp: 0.5819 - mse: 1.2911e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1051 - bpp: 0.5752 - mse: 1.2938e-04\n",
      "Epoch 673: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.1051 - bpp: 0.5752 - mse: 1.2938e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1133 - bpp: 0.5728 - mse: 1.3196e-04\n",
      "Epoch 674: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1133 - bpp: 0.5728 - mse: 1.3196e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2790 - bpp: 0.6206 - mse: 1.6073e-04\n",
      "Epoch 675: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 205ms/step - loss: 1.2790 - bpp: 0.6206 - mse: 1.6073e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0644 - bpp: 0.5587 - mse: 1.2346e-04\n",
      "Epoch 676: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0644 - bpp: 0.5587 - mse: 1.2346e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1936 - bpp: 0.5879 - mse: 1.4787e-04\n",
      "Epoch 677: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1936 - bpp: 0.5879 - mse: 1.4787e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0630 - bpp: 0.5592 - mse: 1.2301e-04\n",
      "Epoch 678: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0630 - bpp: 0.5592 - mse: 1.2301e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1297 - bpp: 0.5707 - mse: 1.3647e-04\n",
      "Epoch 679: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1297 - bpp: 0.5707 - mse: 1.3647e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1548 - bpp: 0.5820 - mse: 1.3983e-04\n",
      "Epoch 680: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1548 - bpp: 0.5820 - mse: 1.3983e-04\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2793 - bpp: 0.6031 - mse: 1.6510e-04\n",
      "Epoch 681: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.2793 - bpp: 0.6031 - mse: 1.6510e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2157 - bpp: 0.6106 - mse: 1.4772e-04\n",
      "Epoch 682: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.2157 - bpp: 0.6106 - mse: 1.4772e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.5537 - mse: 1.2666e-04\n",
      "Epoch 683: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0725 - bpp: 0.5537 - mse: 1.2666e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2486 - bpp: 0.6137 - mse: 1.5499e-04\n",
      "Epoch 684: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 1.2486 - bpp: 0.6137 - mse: 1.5499e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1259 - bpp: 0.5833 - mse: 1.3249e-04\n",
      "Epoch 685: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1259 - bpp: 0.5833 - mse: 1.3249e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1464 - bpp: 0.5821 - mse: 1.3776e-04\n",
      "Epoch 686: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1464 - bpp: 0.5821 - mse: 1.3776e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1776 - bpp: 0.5883 - mse: 1.4387e-04\n",
      "Epoch 687: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 204ms/step - loss: 1.1776 - bpp: 0.5883 - mse: 1.4387e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2244 - bpp: 0.6155 - mse: 1.4867e-04\n",
      "Epoch 688: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2244 - bpp: 0.6155 - mse: 1.4867e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1513 - bpp: 0.5839 - mse: 1.3853e-04\n",
      "Epoch 689: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1513 - bpp: 0.5839 - mse: 1.3853e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1822 - bpp: 0.6002 - mse: 1.4209e-04\n",
      "Epoch 690: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1822 - bpp: 0.6002 - mse: 1.4209e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2099 - bpp: 0.5940 - mse: 1.5037e-04\n",
      "Epoch 691: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.2099 - bpp: 0.5940 - mse: 1.5037e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1623 - bpp: 0.5918 - mse: 1.3930e-04\n",
      "Epoch 692: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1623 - bpp: 0.5918 - mse: 1.3930e-04\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2167 - bpp: 0.6004 - mse: 1.5046e-04\n",
      "Epoch 693: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.2167 - bpp: 0.6004 - mse: 1.5046e-04\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1824 - bpp: 0.5965 - mse: 1.4304e-04\n",
      "Epoch 694: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1824 - bpp: 0.5965 - mse: 1.4304e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1357 - bpp: 0.5757 - mse: 1.3672e-04\n",
      "Epoch 695: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1357 - bpp: 0.5757 - mse: 1.3672e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2198 - bpp: 0.6081 - mse: 1.4935e-04\n",
      "Epoch 696: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2198 - bpp: 0.6081 - mse: 1.4935e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1258 - bpp: 0.5799 - mse: 1.3330e-04\n",
      "Epoch 697: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1258 - bpp: 0.5799 - mse: 1.3330e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1605 - bpp: 0.5872 - mse: 1.3995e-04\n",
      "Epoch 698: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.1605 - bpp: 0.5872 - mse: 1.3995e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1639 - bpp: 0.5967 - mse: 1.3847e-04\n",
      "Epoch 699: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1639 - bpp: 0.5967 - mse: 1.3847e-04\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1443 - bpp: 0.5784 - mse: 1.3816e-04\n",
      "Epoch 700: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1443 - bpp: 0.5784 - mse: 1.3816e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0896 - bpp: 0.5697 - mse: 1.2691e-04\n",
      "Epoch 701: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0896 - bpp: 0.5697 - mse: 1.2691e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1481 - bpp: 0.5897 - mse: 1.3633e-04\n",
      "Epoch 702: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1481 - bpp: 0.5897 - mse: 1.3633e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1032 - bpp: 0.5624 - mse: 1.3201e-04\n",
      "Epoch 703: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.1032 - bpp: 0.5624 - mse: 1.3201e-04\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0818 - bpp: 0.5611 - mse: 1.2711e-04\n",
      "Epoch 704: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0818 - bpp: 0.5611 - mse: 1.2711e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2515 - bpp: 0.6173 - mse: 1.5484e-04\n",
      "Epoch 705: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2515 - bpp: 0.6173 - mse: 1.5484e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2216 - bpp: 0.6141 - mse: 1.4831e-04\n",
      "Epoch 706: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2216 - bpp: 0.6141 - mse: 1.4831e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1263 - bpp: 0.5857 - mse: 1.3198e-04\n",
      "Epoch 707: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1263 - bpp: 0.5857 - mse: 1.3198e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2009 - bpp: 0.6005 - mse: 1.4656e-04\n",
      "Epoch 708: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2009 - bpp: 0.6005 - mse: 1.4656e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2063 - bpp: 0.5877 - mse: 1.5103e-04\n",
      "Epoch 709: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.2063 - bpp: 0.5877 - mse: 1.5103e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0760 - bpp: 0.5622 - mse: 1.2544e-04\n",
      "Epoch 710: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0760 - bpp: 0.5622 - mse: 1.2544e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0644 - bpp: 0.5617 - mse: 1.2274e-04\n",
      "Epoch 711: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0644 - bpp: 0.5617 - mse: 1.2274e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1919 - bpp: 0.5982 - mse: 1.4495e-04\n",
      "Epoch 712: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1919 - bpp: 0.5982 - mse: 1.4495e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1618 - bpp: 0.5887 - mse: 1.3993e-04\n",
      "Epoch 713: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1618 - bpp: 0.5887 - mse: 1.3993e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0627 - bpp: 0.5572 - mse: 1.2341e-04\n",
      "Epoch 714: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0627 - bpp: 0.5572 - mse: 1.2341e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1139 - bpp: 0.5634 - mse: 1.3441e-04\n",
      "Epoch 715: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1139 - bpp: 0.5634 - mse: 1.3441e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0848 - bpp: 0.5677 - mse: 1.2624e-04\n",
      "Epoch 716: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0848 - bpp: 0.5677 - mse: 1.2624e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1505 - bpp: 0.5785 - mse: 1.3964e-04\n",
      "Epoch 717: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1505 - bpp: 0.5785 - mse: 1.3964e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1470 - bpp: 0.5741 - mse: 1.3985e-04\n",
      "Epoch 718: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1470 - bpp: 0.5741 - mse: 1.3985e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2009 - bpp: 0.5953 - mse: 1.4783e-04\n",
      "Epoch 719: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2009 - bpp: 0.5953 - mse: 1.4783e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1302 - bpp: 0.5856 - mse: 1.3296e-04\n",
      "Epoch 720: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1302 - bpp: 0.5856 - mse: 1.3296e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1710 - bpp: 0.5914 - mse: 1.4151e-04\n",
      "Epoch 721: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1710 - bpp: 0.5914 - mse: 1.4151e-04\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1789 - bpp: 0.5908 - mse: 1.4359e-04\n",
      "Epoch 722: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1789 - bpp: 0.5908 - mse: 1.4359e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1306 - bpp: 0.5836 - mse: 1.3352e-04\n",
      "Epoch 723: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1306 - bpp: 0.5836 - mse: 1.3352e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2070 - bpp: 0.5983 - mse: 1.4861e-04\n",
      "Epoch 724: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2070 - bpp: 0.5983 - mse: 1.4861e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1970 - bpp: 0.6005 - mse: 1.4565e-04\n",
      "Epoch 725: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.1970 - bpp: 0.6005 - mse: 1.4565e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1533 - bpp: 0.5762 - mse: 1.4090e-04\n",
      "Epoch 726: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1533 - bpp: 0.5762 - mse: 1.4090e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1879 - bpp: 0.5748 - mse: 1.4967e-04\n",
      "Epoch 727: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1879 - bpp: 0.5748 - mse: 1.4967e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1933 - bpp: 0.5945 - mse: 1.4618e-04\n",
      "Epoch 728: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 1.1933 - bpp: 0.5945 - mse: 1.4618e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0884 - bpp: 0.5616 - mse: 1.2863e-04\n",
      "Epoch 729: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.0884 - bpp: 0.5616 - mse: 1.2863e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1582 - bpp: 0.5864 - mse: 1.3961e-04\n",
      "Epoch 730: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 1.1582 - bpp: 0.5864 - mse: 1.3961e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1154 - bpp: 0.5689 - mse: 1.3341e-04\n",
      "Epoch 731: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1154 - bpp: 0.5689 - mse: 1.3341e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2420 - bpp: 0.6089 - mse: 1.5458e-04\n",
      "Epoch 732: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2420 - bpp: 0.6089 - mse: 1.5458e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2829 - bpp: 0.6259 - mse: 1.6040e-04\n",
      "Epoch 733: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.2829 - bpp: 0.6259 - mse: 1.6040e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1104 - bpp: 0.5698 - mse: 1.3197e-04\n",
      "Epoch 734: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1104 - bpp: 0.5698 - mse: 1.3197e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2490 - bpp: 0.6083 - mse: 1.5643e-04\n",
      "Epoch 735: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2490 - bpp: 0.6083 - mse: 1.5643e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1566 - bpp: 0.5927 - mse: 1.3768e-04\n",
      "Epoch 736: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1566 - bpp: 0.5927 - mse: 1.3768e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1468 - bpp: 0.5760 - mse: 1.3937e-04\n",
      "Epoch 737: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1468 - bpp: 0.5760 - mse: 1.3937e-04\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1225 - bpp: 0.5686 - mse: 1.3523e-04\n",
      "Epoch 738: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1225 - bpp: 0.5686 - mse: 1.3523e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1674 - bpp: 0.5860 - mse: 1.4195e-04\n",
      "Epoch 739: loss did not improve from 1.03774\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1674 - bpp: 0.5860 - mse: 1.4195e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0353 - bpp: 0.5493 - mse: 1.1867e-04\n",
      "Epoch 740: loss improved from 1.03774 to 1.03535, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0353 - bpp: 0.5493 - mse: 1.1867e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1813 - bpp: 0.5917 - mse: 1.4394e-04\n",
      "Epoch 741: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1813 - bpp: 0.5917 - mse: 1.4394e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1750 - bpp: 0.5926 - mse: 1.4218e-04\n",
      "Epoch 742: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1750 - bpp: 0.5926 - mse: 1.4218e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1987 - bpp: 0.5885 - mse: 1.4898e-04\n",
      "Epoch 743: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1987 - bpp: 0.5885 - mse: 1.4898e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1503 - bpp: 0.5877 - mse: 1.3737e-04\n",
      "Epoch 744: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1503 - bpp: 0.5877 - mse: 1.3737e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1267 - bpp: 0.5718 - mse: 1.3546e-04\n",
      "Epoch 745: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1267 - bpp: 0.5718 - mse: 1.3546e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2029 - bpp: 0.6087 - mse: 1.4507e-04\n",
      "Epoch 746: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2029 - bpp: 0.6087 - mse: 1.4507e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1286 - bpp: 0.5740 - mse: 1.3538e-04\n",
      "Epoch 747: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1286 - bpp: 0.5740 - mse: 1.3538e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1387 - bpp: 0.5755 - mse: 1.3750e-04\n",
      "Epoch 748: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1387 - bpp: 0.5755 - mse: 1.3750e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1926 - bpp: 0.5924 - mse: 1.4652e-04\n",
      "Epoch 749: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1926 - bpp: 0.5924 - mse: 1.4652e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1947 - bpp: 0.5841 - mse: 1.4907e-04\n",
      "Epoch 750: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1947 - bpp: 0.5841 - mse: 1.4907e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1103 - bpp: 0.5717 - mse: 1.3150e-04\n",
      "Epoch 751: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1103 - bpp: 0.5717 - mse: 1.3150e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2344 - bpp: 0.6010 - mse: 1.5464e-04\n",
      "Epoch 752: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2344 - bpp: 0.6010 - mse: 1.5464e-04\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1373 - bpp: 0.5747 - mse: 1.3736e-04\n",
      "Epoch 753: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1373 - bpp: 0.5747 - mse: 1.3736e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0878 - bpp: 0.5650 - mse: 1.2763e-04\n",
      "Epoch 754: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0878 - bpp: 0.5650 - mse: 1.2763e-04\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1185 - bpp: 0.5699 - mse: 1.3393e-04\n",
      "Epoch 755: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.1185 - bpp: 0.5699 - mse: 1.3393e-04\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1122 - bpp: 0.5634 - mse: 1.3398e-04\n",
      "Epoch 756: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1122 - bpp: 0.5634 - mse: 1.3398e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1194 - bpp: 0.5649 - mse: 1.3539e-04\n",
      "Epoch 757: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.1194 - bpp: 0.5649 - mse: 1.3539e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1322 - bpp: 0.5780 - mse: 1.3531e-04\n",
      "Epoch 758: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1322 - bpp: 0.5780 - mse: 1.3531e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1984 - bpp: 0.5930 - mse: 1.4780e-04\n",
      "Epoch 759: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1984 - bpp: 0.5930 - mse: 1.4780e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1596 - bpp: 0.5845 - mse: 1.4042e-04\n",
      "Epoch 760: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1596 - bpp: 0.5845 - mse: 1.4042e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2218 - bpp: 0.6005 - mse: 1.5168e-04\n",
      "Epoch 761: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2218 - bpp: 0.6005 - mse: 1.5168e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0902 - bpp: 0.5605 - mse: 1.2932e-04\n",
      "Epoch 762: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0902 - bpp: 0.5605 - mse: 1.2932e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1777 - bpp: 0.5818 - mse: 1.4547e-04\n",
      "Epoch 763: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1777 - bpp: 0.5818 - mse: 1.4547e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2215 - bpp: 0.5995 - mse: 1.5187e-04\n",
      "Epoch 764: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.2215 - bpp: 0.5995 - mse: 1.5187e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1115 - bpp: 0.5687 - mse: 1.3252e-04\n",
      "Epoch 765: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1115 - bpp: 0.5687 - mse: 1.3252e-04\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2005 - bpp: 0.5907 - mse: 1.4887e-04\n",
      "Epoch 766: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.2005 - bpp: 0.5907 - mse: 1.4887e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0718 - bpp: 0.5585 - mse: 1.2531e-04\n",
      "Epoch 767: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0718 - bpp: 0.5585 - mse: 1.2531e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0685 - bpp: 0.5641 - mse: 1.2315e-04\n",
      "Epoch 768: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.0685 - bpp: 0.5641 - mse: 1.2315e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1742 - bpp: 0.5941 - mse: 1.4161e-04\n",
      "Epoch 769: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1742 - bpp: 0.5941 - mse: 1.4161e-04\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1260 - bpp: 0.5724 - mse: 1.3515e-04\n",
      "Epoch 770: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1260 - bpp: 0.5724 - mse: 1.3515e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0976 - bpp: 0.5650 - mse: 1.3001e-04\n",
      "Epoch 771: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0976 - bpp: 0.5650 - mse: 1.3001e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1967 - bpp: 0.5974 - mse: 1.4630e-04\n",
      "Epoch 772: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1967 - bpp: 0.5974 - mse: 1.4630e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0660 - bpp: 0.5520 - mse: 1.2549e-04\n",
      "Epoch 773: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.0660 - bpp: 0.5520 - mse: 1.2549e-04\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0500 - bpp: 0.5505 - mse: 1.2195e-04\n",
      "Epoch 774: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 210ms/step - loss: 1.0500 - bpp: 0.5505 - mse: 1.2195e-04\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1510 - bpp: 0.5814 - mse: 1.3905e-04\n",
      "Epoch 775: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1510 - bpp: 0.5814 - mse: 1.3905e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1209 - bpp: 0.5837 - mse: 1.3116e-04\n",
      "Epoch 776: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.1209 - bpp: 0.5837 - mse: 1.3116e-04\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1743 - bpp: 0.5924 - mse: 1.4206e-04\n",
      "Epoch 777: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1743 - bpp: 0.5924 - mse: 1.4206e-04\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1872 - bpp: 0.5862 - mse: 1.4672e-04\n",
      "Epoch 778: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1872 - bpp: 0.5862 - mse: 1.4672e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2393 - bpp: 0.6029 - mse: 1.5536e-04\n",
      "Epoch 779: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.2393 - bpp: 0.6029 - mse: 1.5536e-04\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0479 - bpp: 0.5518 - mse: 1.2111e-04\n",
      "Epoch 780: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.0479 - bpp: 0.5518 - mse: 1.2111e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1560 - bpp: 0.5779 - mse: 1.4114e-04\n",
      "Epoch 781: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1560 - bpp: 0.5779 - mse: 1.4114e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1151 - bpp: 0.5718 - mse: 1.3265e-04\n",
      "Epoch 782: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1151 - bpp: 0.5718 - mse: 1.3265e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1350 - bpp: 0.5803 - mse: 1.3542e-04\n",
      "Epoch 783: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1350 - bpp: 0.5803 - mse: 1.3542e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1064 - bpp: 0.5824 - mse: 1.2791e-04\n",
      "Epoch 784: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1064 - bpp: 0.5824 - mse: 1.2791e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0719 - bpp: 0.5551 - mse: 1.2616e-04\n",
      "Epoch 785: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0719 - bpp: 0.5551 - mse: 1.2616e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1922 - bpp: 0.5778 - mse: 1.5001e-04\n",
      "Epoch 786: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1922 - bpp: 0.5778 - mse: 1.5001e-04\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2730 - bpp: 0.6090 - mse: 1.6209e-04\n",
      "Epoch 787: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.2730 - bpp: 0.6090 - mse: 1.6209e-04\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5536 - mse: 1.2347e-04\n",
      "Epoch 788: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0594 - bpp: 0.5536 - mse: 1.2347e-04\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1416 - bpp: 0.5832 - mse: 1.3631e-04\n",
      "Epoch 789: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1416 - bpp: 0.5832 - mse: 1.3631e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0812 - bpp: 0.5565 - mse: 1.2809e-04\n",
      "Epoch 790: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0812 - bpp: 0.5565 - mse: 1.2809e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1253 - bpp: 0.5676 - mse: 1.3615e-04\n",
      "Epoch 791: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1253 - bpp: 0.5676 - mse: 1.3615e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1866 - bpp: 0.5904 - mse: 1.4558e-04\n",
      "Epoch 792: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1866 - bpp: 0.5904 - mse: 1.4558e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1736 - bpp: 0.5948 - mse: 1.4131e-04\n",
      "Epoch 793: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1736 - bpp: 0.5948 - mse: 1.4131e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1353 - bpp: 0.5785 - mse: 1.3595e-04\n",
      "Epoch 794: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1353 - bpp: 0.5785 - mse: 1.3595e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2884 - bpp: 0.6132 - mse: 1.6486e-04\n",
      "Epoch 795: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.2884 - bpp: 0.6132 - mse: 1.6486e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1156 - bpp: 0.5658 - mse: 1.3422e-04\n",
      "Epoch 796: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1156 - bpp: 0.5658 - mse: 1.3422e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1536 - bpp: 0.5838 - mse: 1.3910e-04\n",
      "Epoch 797: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1536 - bpp: 0.5838 - mse: 1.3910e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1189 - bpp: 0.5709 - mse: 1.3379e-04\n",
      "Epoch 798: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1189 - bpp: 0.5709 - mse: 1.3379e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1054 - bpp: 0.5711 - mse: 1.3044e-04\n",
      "Epoch 799: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1054 - bpp: 0.5711 - mse: 1.3044e-04\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0639 - bpp: 0.5568 - mse: 1.2382e-04\n",
      "Epoch 800: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0639 - bpp: 0.5568 - mse: 1.2382e-04\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1797 - bpp: 0.5936 - mse: 1.4311e-04\n",
      "Epoch 801: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1797 - bpp: 0.5936 - mse: 1.4311e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1523 - bpp: 0.5821 - mse: 1.3920e-04\n",
      "Epoch 802: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.1523 - bpp: 0.5821 - mse: 1.3920e-04\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.5620 - mse: 1.2698e-04\n",
      "Epoch 803: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0821 - bpp: 0.5620 - mse: 1.2698e-04\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1065 - bpp: 0.5659 - mse: 1.3197e-04\n",
      "Epoch 804: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1065 - bpp: 0.5659 - mse: 1.3197e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1852 - bpp: 0.5925 - mse: 1.4471e-04\n",
      "Epoch 805: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1852 - bpp: 0.5925 - mse: 1.4471e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1420 - bpp: 0.5841 - mse: 1.3621e-04\n",
      "Epoch 806: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1420 - bpp: 0.5841 - mse: 1.3621e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2272 - bpp: 0.6117 - mse: 1.5025e-04\n",
      "Epoch 807: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.2272 - bpp: 0.6117 - mse: 1.5025e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1443 - bpp: 0.5740 - mse: 1.3923e-04\n",
      "Epoch 808: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1443 - bpp: 0.5740 - mse: 1.3923e-04\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1876 - bpp: 0.5925 - mse: 1.4529e-04\n",
      "Epoch 809: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 1.1876 - bpp: 0.5925 - mse: 1.4529e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1441 - bpp: 0.5855 - mse: 1.3638e-04\n",
      "Epoch 810: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1441 - bpp: 0.5855 - mse: 1.3638e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2483 - bpp: 0.6204 - mse: 1.5331e-04\n",
      "Epoch 811: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.2483 - bpp: 0.6204 - mse: 1.5331e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1908 - bpp: 0.6005 - mse: 1.4412e-04\n",
      "Epoch 812: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1908 - bpp: 0.6005 - mse: 1.4412e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1427 - bpp: 0.5815 - mse: 1.3701e-04\n",
      "Epoch 813: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1427 - bpp: 0.5815 - mse: 1.3701e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0492 - bpp: 0.5550 - mse: 1.2065e-04\n",
      "Epoch 814: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.0492 - bpp: 0.5550 - mse: 1.2065e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1565 - bpp: 0.5748 - mse: 1.4199e-04\n",
      "Epoch 815: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1565 - bpp: 0.5748 - mse: 1.4199e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1964 - bpp: 0.6079 - mse: 1.4368e-04\n",
      "Epoch 816: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1964 - bpp: 0.6079 - mse: 1.4368e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1690 - bpp: 0.5878 - mse: 1.4189e-04\n",
      "Epoch 817: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1690 - bpp: 0.5878 - mse: 1.4189e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1303 - bpp: 0.5701 - mse: 1.3676e-04\n",
      "Epoch 818: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.1303 - bpp: 0.5701 - mse: 1.3676e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0832 - bpp: 0.5645 - mse: 1.2663e-04\n",
      "Epoch 819: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 1.0832 - bpp: 0.5645 - mse: 1.2663e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1376 - bpp: 0.5808 - mse: 1.3594e-04\n",
      "Epoch 820: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1376 - bpp: 0.5808 - mse: 1.3594e-04\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0429 - bpp: 0.5520 - mse: 1.1984e-04\n",
      "Epoch 821: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0429 - bpp: 0.5520 - mse: 1.1984e-04\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1941 - bpp: 0.5722 - mse: 1.5183e-04\n",
      "Epoch 822: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1941 - bpp: 0.5722 - mse: 1.5183e-04\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0922 - bpp: 0.5706 - mse: 1.2735e-04\n",
      "Epoch 823: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0922 - bpp: 0.5706 - mse: 1.2735e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1866 - bpp: 0.5952 - mse: 1.4437e-04\n",
      "Epoch 824: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.1866 - bpp: 0.5952 - mse: 1.4437e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0406 - bpp: 0.5331 - mse: 1.2389e-04\n",
      "Epoch 825: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.0406 - bpp: 0.5331 - mse: 1.2389e-04\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1576 - bpp: 0.5878 - mse: 1.3911e-04\n",
      "Epoch 826: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1576 - bpp: 0.5878 - mse: 1.3911e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2366 - bpp: 0.5989 - mse: 1.5568e-04\n",
      "Epoch 827: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.2366 - bpp: 0.5989 - mse: 1.5568e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1371 - bpp: 0.5802 - mse: 1.3596e-04\n",
      "Epoch 828: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.1371 - bpp: 0.5802 - mse: 1.3596e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0587 - bpp: 0.5541 - mse: 1.2320e-04\n",
      "Epoch 829: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0587 - bpp: 0.5541 - mse: 1.2320e-04\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0694 - bpp: 0.5553 - mse: 1.2551e-04\n",
      "Epoch 830: loss did not improve from 1.03535\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0694 - bpp: 0.5553 - mse: 1.2551e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0335 - bpp: 0.5472 - mse: 1.1872e-04\n",
      "Epoch 831: loss improved from 1.03535 to 1.03346, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0335 - bpp: 0.5472 - mse: 1.1872e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0272 - bpp: 0.5419 - mse: 1.1848e-04\n",
      "Epoch 832: loss improved from 1.03346 to 1.02722, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0272 - bpp: 0.5419 - mse: 1.1848e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1198 - bpp: 0.5729 - mse: 1.3352e-04\n",
      "Epoch 833: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1198 - bpp: 0.5729 - mse: 1.3352e-04\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1430 - bpp: 0.5871 - mse: 1.3573e-04\n",
      "Epoch 834: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1430 - bpp: 0.5871 - mse: 1.3573e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1977 - bpp: 0.5975 - mse: 1.4655e-04\n",
      "Epoch 835: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1977 - bpp: 0.5975 - mse: 1.4655e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1539 - bpp: 0.5874 - mse: 1.3831e-04\n",
      "Epoch 836: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.1539 - bpp: 0.5874 - mse: 1.3831e-04\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1834 - bpp: 0.5881 - mse: 1.4532e-04\n",
      "Epoch 837: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1834 - bpp: 0.5881 - mse: 1.4532e-04\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1586 - bpp: 0.5787 - mse: 1.4156e-04\n",
      "Epoch 838: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1586 - bpp: 0.5787 - mse: 1.4156e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1152 - bpp: 0.5605 - mse: 1.3543e-04\n",
      "Epoch 839: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1152 - bpp: 0.5605 - mse: 1.3543e-04\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1039 - bpp: 0.5709 - mse: 1.3012e-04\n",
      "Epoch 840: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.1039 - bpp: 0.5709 - mse: 1.3012e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1080 - bpp: 0.5683 - mse: 1.3175e-04\n",
      "Epoch 841: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1080 - bpp: 0.5683 - mse: 1.3175e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1609 - bpp: 0.5797 - mse: 1.4190e-04\n",
      "Epoch 842: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.1609 - bpp: 0.5797 - mse: 1.4190e-04\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1401 - bpp: 0.5750 - mse: 1.3795e-04\n",
      "Epoch 843: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.1401 - bpp: 0.5750 - mse: 1.3795e-04\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1230 - bpp: 0.5699 - mse: 1.3503e-04\n",
      "Epoch 844: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.1230 - bpp: 0.5699 - mse: 1.3503e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1110 - bpp: 0.5691 - mse: 1.3230e-04\n",
      "Epoch 845: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.1110 - bpp: 0.5691 - mse: 1.3230e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1361 - bpp: 0.5793 - mse: 1.3592e-04\n",
      "Epoch 846: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1361 - bpp: 0.5793 - mse: 1.3592e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1544 - bpp: 0.5775 - mse: 1.4085e-04\n",
      "Epoch 847: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.1544 - bpp: 0.5775 - mse: 1.4085e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1203 - bpp: 0.5719 - mse: 1.3390e-04\n",
      "Epoch 848: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1203 - bpp: 0.5719 - mse: 1.3390e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0508 - bpp: 0.5393 - mse: 1.2486e-04\n",
      "Epoch 849: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0508 - bpp: 0.5393 - mse: 1.2486e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1625 - bpp: 0.5805 - mse: 1.4208e-04\n",
      "Epoch 850: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1625 - bpp: 0.5805 - mse: 1.4208e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0560 - bpp: 0.5512 - mse: 1.2324e-04\n",
      "Epoch 851: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.0560 - bpp: 0.5512 - mse: 1.2324e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1385 - bpp: 0.5881 - mse: 1.3438e-04\n",
      "Epoch 852: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.1385 - bpp: 0.5881 - mse: 1.3438e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1920 - bpp: 0.5880 - mse: 1.4746e-04\n",
      "Epoch 853: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.1920 - bpp: 0.5880 - mse: 1.4746e-04\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1040 - bpp: 0.5639 - mse: 1.3187e-04\n",
      "Epoch 854: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1040 - bpp: 0.5639 - mse: 1.3187e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0771 - bpp: 0.5671 - mse: 1.2450e-04\n",
      "Epoch 855: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0771 - bpp: 0.5671 - mse: 1.2450e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2091 - bpp: 0.6034 - mse: 1.4786e-04\n",
      "Epoch 856: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.2091 - bpp: 0.6034 - mse: 1.4786e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1880 - bpp: 0.5851 - mse: 1.4720e-04\n",
      "Epoch 857: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1880 - bpp: 0.5851 - mse: 1.4720e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1364 - bpp: 0.5770 - mse: 1.3657e-04\n",
      "Epoch 858: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1364 - bpp: 0.5770 - mse: 1.3657e-04\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1113 - bpp: 0.5665 - mse: 1.3301e-04\n",
      "Epoch 859: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1113 - bpp: 0.5665 - mse: 1.3301e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2661 - bpp: 0.6174 - mse: 1.5837e-04\n",
      "Epoch 860: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2661 - bpp: 0.6174 - mse: 1.5837e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1159 - bpp: 0.5628 - mse: 1.3505e-04\n",
      "Epoch 861: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1159 - bpp: 0.5628 - mse: 1.3505e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1366 - bpp: 0.5769 - mse: 1.3664e-04\n",
      "Epoch 862: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1366 - bpp: 0.5769 - mse: 1.3664e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1637 - bpp: 0.5922 - mse: 1.3952e-04\n",
      "Epoch 863: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1637 - bpp: 0.5922 - mse: 1.3952e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0754 - bpp: 0.5622 - mse: 1.2529e-04\n",
      "Epoch 864: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 1.0754 - bpp: 0.5622 - mse: 1.2529e-04\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0651 - bpp: 0.5540 - mse: 1.2478e-04\n",
      "Epoch 865: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.0651 - bpp: 0.5540 - mse: 1.2478e-04\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1614 - bpp: 0.5847 - mse: 1.4079e-04\n",
      "Epoch 866: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1614 - bpp: 0.5847 - mse: 1.4079e-04\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0982 - bpp: 0.5755 - mse: 1.2760e-04\n",
      "Epoch 867: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0982 - bpp: 0.5755 - mse: 1.2760e-04\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1307 - bpp: 0.5775 - mse: 1.3504e-04\n",
      "Epoch 868: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1307 - bpp: 0.5775 - mse: 1.3504e-04\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.5611 - mse: 1.2860e-04\n",
      "Epoch 869: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.0879 - bpp: 0.5611 - mse: 1.2860e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1672 - bpp: 0.5794 - mse: 1.4351e-04\n",
      "Epoch 870: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.1672 - bpp: 0.5794 - mse: 1.4351e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1357 - bpp: 0.5764 - mse: 1.3653e-04\n",
      "Epoch 871: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 1.1357 - bpp: 0.5764 - mse: 1.3653e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0810 - bpp: 0.5548 - mse: 1.2847e-04\n",
      "Epoch 872: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0810 - bpp: 0.5548 - mse: 1.2847e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1962 - bpp: 0.5924 - mse: 1.4740e-04\n",
      "Epoch 873: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1962 - bpp: 0.5924 - mse: 1.4740e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0613 - bpp: 0.5547 - mse: 1.2367e-04\n",
      "Epoch 874: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0613 - bpp: 0.5547 - mse: 1.2367e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1679 - bpp: 0.5937 - mse: 1.4016e-04\n",
      "Epoch 875: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1679 - bpp: 0.5937 - mse: 1.4016e-04\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5604 - mse: 1.2806e-04\n",
      "Epoch 876: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.0850 - bpp: 0.5604 - mse: 1.2806e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2465 - bpp: 0.6047 - mse: 1.5669e-04\n",
      "Epoch 877: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.2465 - bpp: 0.6047 - mse: 1.5669e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1149 - bpp: 0.5653 - mse: 1.3419e-04\n",
      "Epoch 878: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1149 - bpp: 0.5653 - mse: 1.3419e-04\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0843 - bpp: 0.5599 - mse: 1.2802e-04\n",
      "Epoch 879: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.0843 - bpp: 0.5599 - mse: 1.2802e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1685 - bpp: 0.5850 - mse: 1.4245e-04\n",
      "Epoch 880: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1685 - bpp: 0.5850 - mse: 1.4245e-04\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0522 - bpp: 0.5532 - mse: 1.2181e-04\n",
      "Epoch 881: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0522 - bpp: 0.5532 - mse: 1.2181e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1196 - bpp: 0.5580 - mse: 1.3711e-04\n",
      "Epoch 882: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1196 - bpp: 0.5580 - mse: 1.3711e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1562 - bpp: 0.5864 - mse: 1.3911e-04\n",
      "Epoch 883: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1562 - bpp: 0.5864 - mse: 1.3911e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2418 - bpp: 0.5988 - mse: 1.5699e-04\n",
      "Epoch 884: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.2418 - bpp: 0.5988 - mse: 1.5699e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1251 - bpp: 0.5726 - mse: 1.3487e-04\n",
      "Epoch 885: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 1.1251 - bpp: 0.5726 - mse: 1.3487e-04\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1313 - bpp: 0.5846 - mse: 1.3346e-04\n",
      "Epoch 886: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1313 - bpp: 0.5846 - mse: 1.3346e-04\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0503 - bpp: 0.5548 - mse: 1.2097e-04\n",
      "Epoch 887: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 1.0503 - bpp: 0.5548 - mse: 1.2097e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1483 - bpp: 0.5746 - mse: 1.4007e-04\n",
      "Epoch 888: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.1483 - bpp: 0.5746 - mse: 1.4007e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1059 - bpp: 0.5576 - mse: 1.3386e-04\n",
      "Epoch 889: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.1059 - bpp: 0.5576 - mse: 1.3386e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1612 - bpp: 0.5989 - mse: 1.3727e-04\n",
      "Epoch 890: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 1.1612 - bpp: 0.5989 - mse: 1.3727e-04\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0398 - bpp: 0.5397 - mse: 1.2210e-04\n",
      "Epoch 891: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.0398 - bpp: 0.5397 - mse: 1.2210e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0715 - bpp: 0.5661 - mse: 1.2338e-04\n",
      "Epoch 892: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.0715 - bpp: 0.5661 - mse: 1.2338e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1422 - bpp: 0.5799 - mse: 1.3728e-04\n",
      "Epoch 893: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.1422 - bpp: 0.5799 - mse: 1.3728e-04\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0831 - bpp: 0.5614 - mse: 1.2737e-04\n",
      "Epoch 894: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.0831 - bpp: 0.5614 - mse: 1.2737e-04\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1321 - bpp: 0.5837 - mse: 1.3389e-04\n",
      "Epoch 895: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 1.1321 - bpp: 0.5837 - mse: 1.3389e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5636 - mse: 1.3551e-04\n",
      "Epoch 896: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.1186 - bpp: 0.5636 - mse: 1.3551e-04\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0668 - bpp: 0.5552 - mse: 1.2491e-04\n",
      "Epoch 897: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0668 - bpp: 0.5552 - mse: 1.2491e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0890 - bpp: 0.5612 - mse: 1.2884e-04\n",
      "Epoch 898: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0890 - bpp: 0.5612 - mse: 1.2884e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0786 - bpp: 0.5628 - mse: 1.2591e-04\n",
      "Epoch 899: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 1.0786 - bpp: 0.5628 - mse: 1.2591e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1098 - bpp: 0.5729 - mse: 1.3109e-04\n",
      "Epoch 900: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.1098 - bpp: 0.5729 - mse: 1.3109e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1593 - bpp: 0.5850 - mse: 1.4021e-04\n",
      "Epoch 901: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.1593 - bpp: 0.5850 - mse: 1.4021e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2019 - bpp: 0.6028 - mse: 1.4626e-04\n",
      "Epoch 902: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 1.2019 - bpp: 0.6028 - mse: 1.4626e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0363 - bpp: 0.5454 - mse: 1.1986e-04\n",
      "Epoch 903: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 1.0363 - bpp: 0.5454 - mse: 1.1986e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1453 - bpp: 0.5828 - mse: 1.3731e-04\n",
      "Epoch 904: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.1453 - bpp: 0.5828 - mse: 1.3731e-04\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1398 - bpp: 0.5722 - mse: 1.3857e-04\n",
      "Epoch 905: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1398 - bpp: 0.5722 - mse: 1.3857e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1604 - bpp: 0.5786 - mse: 1.4203e-04\n",
      "Epoch 906: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 1.1604 - bpp: 0.5786 - mse: 1.4203e-04\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2260 - bpp: 0.6051 - mse: 1.5159e-04\n",
      "Epoch 907: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2260 - bpp: 0.6051 - mse: 1.5159e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0502 - bpp: 0.5568 - mse: 1.2045e-04\n",
      "Epoch 908: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.0502 - bpp: 0.5568 - mse: 1.2045e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1285 - bpp: 0.5677 - mse: 1.3689e-04\n",
      "Epoch 909: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 1.1285 - bpp: 0.5677 - mse: 1.3689e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1087 - bpp: 0.5626 - mse: 1.3333e-04\n",
      "Epoch 910: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.1087 - bpp: 0.5626 - mse: 1.3333e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0467 - bpp: 0.5478 - mse: 1.2180e-04\n",
      "Epoch 911: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0467 - bpp: 0.5478 - mse: 1.2180e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1809 - bpp: 0.5931 - mse: 1.4351e-04\n",
      "Epoch 912: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1809 - bpp: 0.5931 - mse: 1.4351e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0350 - bpp: 0.5457 - mse: 1.1946e-04\n",
      "Epoch 913: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0350 - bpp: 0.5457 - mse: 1.1946e-04\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0988 - bpp: 0.5577 - mse: 1.3210e-04\n",
      "Epoch 914: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.0988 - bpp: 0.5577 - mse: 1.3210e-04\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1914 - bpp: 0.5867 - mse: 1.4763e-04\n",
      "Epoch 915: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 1.1914 - bpp: 0.5867 - mse: 1.4763e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0492 - bpp: 0.5476 - mse: 1.2245e-04\n",
      "Epoch 916: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.0492 - bpp: 0.5476 - mse: 1.2245e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0760 - bpp: 0.5617 - mse: 1.2557e-04\n",
      "Epoch 917: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 1.0760 - bpp: 0.5617 - mse: 1.2557e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1335 - bpp: 0.5775 - mse: 1.3574e-04\n",
      "Epoch 918: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1335 - bpp: 0.5775 - mse: 1.3574e-04\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2619 - bpp: 0.6100 - mse: 1.5917e-04\n",
      "Epoch 919: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.2619 - bpp: 0.6100 - mse: 1.5917e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0802 - bpp: 0.5542 - mse: 1.2843e-04\n",
      "Epoch 920: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0802 - bpp: 0.5542 - mse: 1.2843e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0645 - bpp: 0.5428 - mse: 1.2736e-04\n",
      "Epoch 921: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 1.0645 - bpp: 0.5428 - mse: 1.2736e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1360 - bpp: 0.5688 - mse: 1.3847e-04\n",
      "Epoch 922: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1360 - bpp: 0.5688 - mse: 1.3847e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1073 - bpp: 0.5636 - mse: 1.3274e-04\n",
      "Epoch 923: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.1073 - bpp: 0.5636 - mse: 1.3274e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1478 - bpp: 0.5779 - mse: 1.3913e-04\n",
      "Epoch 924: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1478 - bpp: 0.5779 - mse: 1.3913e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0836 - bpp: 0.5645 - mse: 1.2673e-04\n",
      "Epoch 925: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0836 - bpp: 0.5645 - mse: 1.2673e-04\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0374 - bpp: 0.5400 - mse: 1.2144e-04\n",
      "Epoch 926: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.0374 - bpp: 0.5400 - mse: 1.2144e-04\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1206 - bpp: 0.5748 - mse: 1.3325e-04\n",
      "Epoch 927: loss did not improve from 1.02722\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.1206 - bpp: 0.5748 - mse: 1.3325e-04\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9667 - bpp: 0.5144 - mse: 1.1043e-04\n",
      "Epoch 928: loss improved from 1.02722 to 0.96673, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.9667 - bpp: 0.5144 - mse: 1.1043e-04\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1061 - bpp: 0.5579 - mse: 1.3383e-04\n",
      "Epoch 929: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.1061 - bpp: 0.5579 - mse: 1.3383e-04\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0789 - bpp: 0.5508 - mse: 1.2893e-04\n",
      "Epoch 930: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.0789 - bpp: 0.5508 - mse: 1.2893e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1064 - bpp: 0.5596 - mse: 1.3350e-04\n",
      "Epoch 931: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.1064 - bpp: 0.5596 - mse: 1.3350e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1899 - bpp: 0.5875 - mse: 1.4708e-04\n",
      "Epoch 932: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 1.1899 - bpp: 0.5875 - mse: 1.4708e-04\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0818 - bpp: 0.5601 - mse: 1.2738e-04\n",
      "Epoch 933: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.0818 - bpp: 0.5601 - mse: 1.2738e-04\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1516 - bpp: 0.5710 - mse: 1.4173e-04\n",
      "Epoch 934: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.1516 - bpp: 0.5710 - mse: 1.4173e-04\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0860 - bpp: 0.5519 - mse: 1.3041e-04\n",
      "Epoch 935: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 1.0860 - bpp: 0.5519 - mse: 1.3041e-04\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1752 - bpp: 0.5871 - mse: 1.4357e-04\n",
      "Epoch 936: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.1752 - bpp: 0.5871 - mse: 1.4357e-04\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1626 - bpp: 0.5686 - mse: 1.4500e-04\n",
      "Epoch 937: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 1.1626 - bpp: 0.5686 - mse: 1.4500e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0724 - bpp: 0.5565 - mse: 1.2594e-04\n",
      "Epoch 938: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 1.0724 - bpp: 0.5565 - mse: 1.2594e-04\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.5381 - mse: 1.3045e-04\n",
      "Epoch 939: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.0725 - bpp: 0.5381 - mse: 1.3045e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0607 - bpp: 0.5546 - mse: 1.2356e-04\n",
      "Epoch 940: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.0607 - bpp: 0.5546 - mse: 1.2356e-04\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0755 - bpp: 0.5554 - mse: 1.2697e-04\n",
      "Epoch 941: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 1.0755 - bpp: 0.5554 - mse: 1.2697e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1555 - bpp: 0.5775 - mse: 1.4112e-04\n",
      "Epoch 942: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.1555 - bpp: 0.5775 - mse: 1.4112e-04\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0868 - bpp: 0.5698 - mse: 1.2621e-04\n",
      "Epoch 943: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0868 - bpp: 0.5698 - mse: 1.2621e-04\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1461 - bpp: 0.5721 - mse: 1.4014e-04\n",
      "Epoch 944: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1461 - bpp: 0.5721 - mse: 1.4014e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1885 - bpp: 0.5797 - mse: 1.4863e-04\n",
      "Epoch 945: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1885 - bpp: 0.5797 - mse: 1.4863e-04\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1456 - bpp: 0.5755 - mse: 1.3918e-04\n",
      "Epoch 946: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1456 - bpp: 0.5755 - mse: 1.3918e-04\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1998 - bpp: 0.5924 - mse: 1.4830e-04\n",
      "Epoch 947: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1998 - bpp: 0.5924 - mse: 1.4830e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0332 - bpp: 0.5477 - mse: 1.1853e-04\n",
      "Epoch 948: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0332 - bpp: 0.5477 - mse: 1.1853e-04\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1138 - bpp: 0.5591 - mse: 1.3543e-04\n",
      "Epoch 949: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1138 - bpp: 0.5591 - mse: 1.3543e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1352 - bpp: 0.5717 - mse: 1.3757e-04\n",
      "Epoch 950: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1352 - bpp: 0.5717 - mse: 1.3757e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0849 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 951: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.0849 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0911 - bpp: 0.5677 - mse: 1.2777e-04\n",
      "Epoch 952: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.0911 - bpp: 0.5677 - mse: 1.2777e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0737 - bpp: 0.5383 - mse: 1.3073e-04\n",
      "Epoch 953: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0737 - bpp: 0.5383 - mse: 1.3073e-04\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0164 - bpp: 0.5348 - mse: 1.1758e-04\n",
      "Epoch 954: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 1.0164 - bpp: 0.5348 - mse: 1.1758e-04\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1123 - bpp: 0.5679 - mse: 1.3291e-04\n",
      "Epoch 955: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1123 - bpp: 0.5679 - mse: 1.3291e-04\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0045 - bpp: 0.5269 - mse: 1.1658e-04\n",
      "Epoch 956: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0045 - bpp: 0.5269 - mse: 1.1658e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0595 - bpp: 0.5436 - mse: 1.2594e-04\n",
      "Epoch 957: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0595 - bpp: 0.5436 - mse: 1.2594e-04\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0683 - bpp: 0.5534 - mse: 1.2571e-04\n",
      "Epoch 958: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0683 - bpp: 0.5534 - mse: 1.2571e-04\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1049 - bpp: 0.5625 - mse: 1.3242e-04\n",
      "Epoch 959: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1049 - bpp: 0.5625 - mse: 1.3242e-04\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1959 - bpp: 0.5885 - mse: 1.4831e-04\n",
      "Epoch 960: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.1959 - bpp: 0.5885 - mse: 1.4831e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0484 - bpp: 0.5522 - mse: 1.2116e-04\n",
      "Epoch 961: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0484 - bpp: 0.5522 - mse: 1.2116e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1695 - bpp: 0.5765 - mse: 1.4478e-04\n",
      "Epoch 962: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1695 - bpp: 0.5765 - mse: 1.4478e-04\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1691 - bpp: 0.5818 - mse: 1.4338e-04\n",
      "Epoch 963: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1691 - bpp: 0.5818 - mse: 1.4338e-04\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1145 - bpp: 0.5599 - mse: 1.3540e-04\n",
      "Epoch 964: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1145 - bpp: 0.5599 - mse: 1.3540e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1803 - bpp: 0.5852 - mse: 1.4529e-04\n",
      "Epoch 965: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1803 - bpp: 0.5852 - mse: 1.4529e-04\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0472 - bpp: 0.5500 - mse: 1.2139e-04\n",
      "Epoch 966: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0472 - bpp: 0.5500 - mse: 1.2139e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1370 - bpp: 0.5704 - mse: 1.3834e-04\n",
      "Epoch 967: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1370 - bpp: 0.5704 - mse: 1.3834e-04\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1205 - bpp: 0.5727 - mse: 1.3373e-04\n",
      "Epoch 968: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1205 - bpp: 0.5727 - mse: 1.3373e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0526 - bpp: 0.5490 - mse: 1.2296e-04\n",
      "Epoch 969: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0526 - bpp: 0.5490 - mse: 1.2296e-04\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1355 - bpp: 0.5815 - mse: 1.3524e-04\n",
      "Epoch 970: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1355 - bpp: 0.5815 - mse: 1.3524e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1321 - bpp: 0.5643 - mse: 1.3862e-04\n",
      "Epoch 971: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1321 - bpp: 0.5643 - mse: 1.3862e-04\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0167 - bpp: 0.5375 - mse: 1.1700e-04\n",
      "Epoch 972: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0167 - bpp: 0.5375 - mse: 1.1700e-04\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0478 - bpp: 0.5452 - mse: 1.2271e-04\n",
      "Epoch 973: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0478 - bpp: 0.5452 - mse: 1.2271e-04\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0835 - bpp: 0.5502 - mse: 1.3020e-04\n",
      "Epoch 974: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0835 - bpp: 0.5502 - mse: 1.3020e-04\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0493 - bpp: 0.5456 - mse: 1.2296e-04\n",
      "Epoch 975: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0493 - bpp: 0.5456 - mse: 1.2296e-04\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0910 - bpp: 0.5651 - mse: 1.2837e-04\n",
      "Epoch 976: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0910 - bpp: 0.5651 - mse: 1.2837e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0732 - bpp: 0.5415 - mse: 1.2979e-04\n",
      "Epoch 977: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0732 - bpp: 0.5415 - mse: 1.2979e-04\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0311 - bpp: 0.5228 - mse: 1.2408e-04\n",
      "Epoch 978: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0311 - bpp: 0.5228 - mse: 1.2408e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1193 - bpp: 0.5749 - mse: 1.3290e-04\n",
      "Epoch 979: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1193 - bpp: 0.5749 - mse: 1.3290e-04\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0247 - bpp: 0.5307 - mse: 1.2061e-04\n",
      "Epoch 980: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0247 - bpp: 0.5307 - mse: 1.2061e-04\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0048 - bpp: 0.5250 - mse: 1.1714e-04\n",
      "Epoch 981: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0048 - bpp: 0.5250 - mse: 1.1714e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0682 - bpp: 0.5493 - mse: 1.2670e-04\n",
      "Epoch 982: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0682 - bpp: 0.5493 - mse: 1.2670e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1706 - bpp: 0.5714 - mse: 1.4629e-04\n",
      "Epoch 983: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1706 - bpp: 0.5714 - mse: 1.4629e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1277 - bpp: 0.5699 - mse: 1.3617e-04\n",
      "Epoch 984: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1277 - bpp: 0.5699 - mse: 1.3617e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1027 - bpp: 0.5598 - mse: 1.3255e-04\n",
      "Epoch 985: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1027 - bpp: 0.5598 - mse: 1.3255e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1636 - bpp: 0.5865 - mse: 1.4089e-04\n",
      "Epoch 986: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1636 - bpp: 0.5865 - mse: 1.4089e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1363 - bpp: 0.5817 - mse: 1.3541e-04\n",
      "Epoch 987: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1363 - bpp: 0.5817 - mse: 1.3541e-04\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0919 - bpp: 0.5544 - mse: 1.3122e-04\n",
      "Epoch 988: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0919 - bpp: 0.5544 - mse: 1.3122e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0456 - bpp: 0.5445 - mse: 1.2234e-04\n",
      "Epoch 989: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0456 - bpp: 0.5445 - mse: 1.2234e-04\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2013 - bpp: 0.5986 - mse: 1.4714e-04\n",
      "Epoch 990: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.2013 - bpp: 0.5986 - mse: 1.4714e-04\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1116 - bpp: 0.5684 - mse: 1.3263e-04\n",
      "Epoch 991: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1116 - bpp: 0.5684 - mse: 1.3263e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0460 - bpp: 0.5485 - mse: 1.2147e-04\n",
      "Epoch 992: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0460 - bpp: 0.5485 - mse: 1.2147e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0762 - bpp: 0.5551 - mse: 1.2723e-04\n",
      "Epoch 993: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0762 - bpp: 0.5551 - mse: 1.2723e-04\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1547 - bpp: 0.5695 - mse: 1.4286e-04\n",
      "Epoch 994: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1547 - bpp: 0.5695 - mse: 1.4286e-04\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0724 - bpp: 0.5533 - mse: 1.2674e-04\n",
      "Epoch 995: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0724 - bpp: 0.5533 - mse: 1.2674e-04\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0974 - bpp: 0.5668 - mse: 1.2955e-04\n",
      "Epoch 996: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0974 - bpp: 0.5668 - mse: 1.2955e-04\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1315 - bpp: 0.5712 - mse: 1.3680e-04\n",
      "Epoch 997: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1315 - bpp: 0.5712 - mse: 1.3680e-04\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2006 - bpp: 0.5893 - mse: 1.4925e-04\n",
      "Epoch 998: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.2006 - bpp: 0.5893 - mse: 1.4925e-04\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1386 - bpp: 0.5685 - mse: 1.3918e-04\n",
      "Epoch 999: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1386 - bpp: 0.5685 - mse: 1.3918e-04\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0826 - bpp: 0.5608 - mse: 1.2740e-04\n",
      "Epoch 1000: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0826 - bpp: 0.5608 - mse: 1.2740e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1084 - bpp: 0.5555 - mse: 1.3499e-04\n",
      "Epoch 1001: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1084 - bpp: 0.5555 - mse: 1.3499e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1803 - bpp: 0.5960 - mse: 1.4265e-04\n",
      "Epoch 1002: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 243ms/step - loss: 1.1803 - bpp: 0.5960 - mse: 1.4265e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1015 - bpp: 0.5669 - mse: 1.3051e-04\n",
      "Epoch 1003: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1015 - bpp: 0.5669 - mse: 1.3051e-04\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1097 - bpp: 0.5687 - mse: 1.3207e-04\n",
      "Epoch 1004: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1097 - bpp: 0.5687 - mse: 1.3207e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0751 - bpp: 0.5478 - mse: 1.2874e-04\n",
      "Epoch 1005: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0751 - bpp: 0.5478 - mse: 1.2874e-04\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0757 - bpp: 0.5569 - mse: 1.2666e-04\n",
      "Epoch 1006: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0757 - bpp: 0.5569 - mse: 1.2666e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0922 - bpp: 0.5539 - mse: 1.3141e-04\n",
      "Epoch 1007: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0922 - bpp: 0.5539 - mse: 1.3141e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0725 - bpp: 0.5477 - mse: 1.2814e-04\n",
      "Epoch 1008: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0725 - bpp: 0.5477 - mse: 1.2814e-04\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1042 - bpp: 0.5568 - mse: 1.3364e-04\n",
      "Epoch 1009: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1042 - bpp: 0.5568 - mse: 1.3364e-04\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0207 - bpp: 0.5352 - mse: 1.1853e-04\n",
      "Epoch 1010: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0207 - bpp: 0.5352 - mse: 1.1853e-04\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1818 - bpp: 0.5826 - mse: 1.4630e-04\n",
      "Epoch 1011: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1818 - bpp: 0.5826 - mse: 1.4630e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1217 - bpp: 0.5650 - mse: 1.3592e-04\n",
      "Epoch 1012: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1217 - bpp: 0.5650 - mse: 1.3592e-04\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0389 - bpp: 0.5445 - mse: 1.2070e-04\n",
      "Epoch 1013: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0389 - bpp: 0.5445 - mse: 1.2070e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1095 - bpp: 0.5632 - mse: 1.3338e-04\n",
      "Epoch 1014: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1095 - bpp: 0.5632 - mse: 1.3338e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0163 - bpp: 0.5362 - mse: 1.1721e-04\n",
      "Epoch 1015: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0163 - bpp: 0.5362 - mse: 1.1721e-04\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0357 - bpp: 0.5397 - mse: 1.2111e-04\n",
      "Epoch 1016: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0357 - bpp: 0.5397 - mse: 1.2111e-04\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0830 - bpp: 0.5638 - mse: 1.2675e-04\n",
      "Epoch 1017: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0830 - bpp: 0.5638 - mse: 1.2675e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9844 - bpp: 0.5249 - mse: 1.1218e-04\n",
      "Epoch 1018: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9844 - bpp: 0.5249 - mse: 1.1218e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0417 - bpp: 0.5406 - mse: 1.2234e-04\n",
      "Epoch 1019: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0417 - bpp: 0.5406 - mse: 1.2234e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0370 - bpp: 0.5366 - mse: 1.2215e-04\n",
      "Epoch 1020: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0370 - bpp: 0.5366 - mse: 1.2215e-04\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0625 - bpp: 0.5453 - mse: 1.2626e-04\n",
      "Epoch 1021: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 1.0625 - bpp: 0.5453 - mse: 1.2626e-04\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1256 - bpp: 0.5695 - mse: 1.3578e-04\n",
      "Epoch 1022: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1256 - bpp: 0.5695 - mse: 1.3578e-04\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0918 - bpp: 0.5571 - mse: 1.3054e-04\n",
      "Epoch 1023: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0918 - bpp: 0.5571 - mse: 1.3054e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9974 - bpp: 0.5153 - mse: 1.1768e-04\n",
      "Epoch 1024: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.9974 - bpp: 0.5153 - mse: 1.1768e-04\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.5544 - mse: 1.3024e-04\n",
      "Epoch 1025: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0879 - bpp: 0.5544 - mse: 1.3024e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0783 - bpp: 0.5523 - mse: 1.2841e-04\n",
      "Epoch 1026: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0783 - bpp: 0.5523 - mse: 1.2841e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0939 - bpp: 0.5581 - mse: 1.3082e-04\n",
      "Epoch 1027: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0939 - bpp: 0.5581 - mse: 1.3082e-04\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0871 - bpp: 0.5449 - mse: 1.3239e-04\n",
      "Epoch 1028: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0871 - bpp: 0.5449 - mse: 1.3239e-04\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5895 - mse: 1.3827e-04\n",
      "Epoch 1029: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1559 - bpp: 0.5895 - mse: 1.3827e-04\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1599 - bpp: 0.5873 - mse: 1.3977e-04\n",
      "Epoch 1030: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1599 - bpp: 0.5873 - mse: 1.3977e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1891 - bpp: 0.5823 - mse: 1.4813e-04\n",
      "Epoch 1031: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1891 - bpp: 0.5823 - mse: 1.4813e-04\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1093 - bpp: 0.5605 - mse: 1.3397e-04\n",
      "Epoch 1032: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1093 - bpp: 0.5605 - mse: 1.3397e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0631 - bpp: 0.5491 - mse: 1.2551e-04\n",
      "Epoch 1033: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0631 - bpp: 0.5491 - mse: 1.2551e-04\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0814 - bpp: 0.5533 - mse: 1.2892e-04\n",
      "Epoch 1034: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0814 - bpp: 0.5533 - mse: 1.2892e-04\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0668 - bpp: 0.5520 - mse: 1.2568e-04\n",
      "Epoch 1035: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.0668 - bpp: 0.5520 - mse: 1.2568e-04\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1526 - bpp: 0.5780 - mse: 1.4028e-04\n",
      "Epoch 1036: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1526 - bpp: 0.5780 - mse: 1.4028e-04\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1485 - bpp: 0.5688 - mse: 1.4155e-04\n",
      "Epoch 1037: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1485 - bpp: 0.5688 - mse: 1.4155e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0660 - bpp: 0.5491 - mse: 1.2620e-04\n",
      "Epoch 1038: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0660 - bpp: 0.5491 - mse: 1.2620e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0825 - bpp: 0.5623 - mse: 1.2700e-04\n",
      "Epoch 1039: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.0825 - bpp: 0.5623 - mse: 1.2700e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0909 - bpp: 0.5734 - mse: 1.2634e-04\n",
      "Epoch 1040: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0909 - bpp: 0.5734 - mse: 1.2634e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0697 - bpp: 0.5547 - mse: 1.2574e-04\n",
      "Epoch 1041: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0697 - bpp: 0.5547 - mse: 1.2574e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0299 - bpp: 0.5316 - mse: 1.2165e-04\n",
      "Epoch 1042: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 1.0299 - bpp: 0.5316 - mse: 1.2165e-04\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1506 - bpp: 0.5728 - mse: 1.4106e-04\n",
      "Epoch 1043: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1506 - bpp: 0.5728 - mse: 1.4106e-04\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5663 - mse: 1.3484e-04\n",
      "Epoch 1044: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1186 - bpp: 0.5663 - mse: 1.3484e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0144 - bpp: 0.5310 - mse: 1.1802e-04\n",
      "Epoch 1045: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0144 - bpp: 0.5310 - mse: 1.1802e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0450 - bpp: 0.5389 - mse: 1.2356e-04\n",
      "Epoch 1046: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0450 - bpp: 0.5389 - mse: 1.2356e-04\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0530 - bpp: 0.5556 - mse: 1.2144e-04\n",
      "Epoch 1047: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0530 - bpp: 0.5556 - mse: 1.2144e-04\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1589 - bpp: 0.5726 - mse: 1.4314e-04\n",
      "Epoch 1048: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1589 - bpp: 0.5726 - mse: 1.4314e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0473 - bpp: 0.5404 - mse: 1.2375e-04\n",
      "Epoch 1049: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0473 - bpp: 0.5404 - mse: 1.2375e-04\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0763 - bpp: 0.5468 - mse: 1.2928e-04\n",
      "Epoch 1050: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0763 - bpp: 0.5468 - mse: 1.2928e-04\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0823 - bpp: 0.5557 - mse: 1.2856e-04\n",
      "Epoch 1051: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0823 - bpp: 0.5557 - mse: 1.2856e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1575 - bpp: 0.5740 - mse: 1.4245e-04\n",
      "Epoch 1052: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1575 - bpp: 0.5740 - mse: 1.4245e-04\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0989 - bpp: 0.5636 - mse: 1.3071e-04\n",
      "Epoch 1053: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0989 - bpp: 0.5636 - mse: 1.3071e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0805 - bpp: 0.5561 - mse: 1.2802e-04\n",
      "Epoch 1054: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0805 - bpp: 0.5561 - mse: 1.2802e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0448 - bpp: 0.5458 - mse: 1.2182e-04\n",
      "Epoch 1055: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0448 - bpp: 0.5458 - mse: 1.2182e-04\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0616 - bpp: 0.5499 - mse: 1.2493e-04\n",
      "Epoch 1056: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0616 - bpp: 0.5499 - mse: 1.2493e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1149 - bpp: 0.5655 - mse: 1.3413e-04\n",
      "Epoch 1057: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.1149 - bpp: 0.5655 - mse: 1.3413e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0843 - bpp: 0.5566 - mse: 1.2883e-04\n",
      "Epoch 1058: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0843 - bpp: 0.5566 - mse: 1.2883e-04\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0518 - bpp: 0.5476 - mse: 1.2309e-04\n",
      "Epoch 1059: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0518 - bpp: 0.5476 - mse: 1.2309e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1236 - bpp: 0.5661 - mse: 1.3612e-04\n",
      "Epoch 1060: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.1236 - bpp: 0.5661 - mse: 1.3612e-04\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0216 - bpp: 0.5324 - mse: 1.1942e-04\n",
      "Epoch 1061: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0216 - bpp: 0.5324 - mse: 1.1942e-04\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0617 - bpp: 0.5516 - mse: 1.2455e-04\n",
      "Epoch 1062: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0617 - bpp: 0.5516 - mse: 1.2455e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2306 - bpp: 0.6090 - mse: 1.5178e-04\n",
      "Epoch 1063: loss did not improve from 0.96673\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.2306 - bpp: 0.6090 - mse: 1.5178e-04\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9383 - bpp: 0.5129 - mse: 1.0387e-04\n",
      "Epoch 1064: loss improved from 0.96673 to 0.93830, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9383 - bpp: 0.5129 - mse: 1.0387e-04\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2698 - bpp: 0.6054 - mse: 1.6221e-04\n",
      "Epoch 1065: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.2698 - bpp: 0.6054 - mse: 1.6221e-04\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0570 - bpp: 0.5450 - mse: 1.2501e-04\n",
      "Epoch 1066: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0570 - bpp: 0.5450 - mse: 1.2501e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5545 - mse: 1.2951e-04\n",
      "Epoch 1067: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0850 - bpp: 0.5545 - mse: 1.2951e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0788 - bpp: 0.5528 - mse: 1.2840e-04\n",
      "Epoch 1068: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0788 - bpp: 0.5528 - mse: 1.2840e-04\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0269 - bpp: 0.5394 - mse: 1.1902e-04\n",
      "Epoch 1069: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0269 - bpp: 0.5394 - mse: 1.1902e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9732 - bpp: 0.5179 - mse: 1.1114e-04\n",
      "Epoch 1070: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9732 - bpp: 0.5179 - mse: 1.1114e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0225 - bpp: 0.5408 - mse: 1.1762e-04\n",
      "Epoch 1071: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0225 - bpp: 0.5408 - mse: 1.1762e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1265 - bpp: 0.5709 - mse: 1.3565e-04\n",
      "Epoch 1072: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1265 - bpp: 0.5709 - mse: 1.3565e-04\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0993 - bpp: 0.5502 - mse: 1.3406e-04\n",
      "Epoch 1073: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0993 - bpp: 0.5502 - mse: 1.3406e-04\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0221 - bpp: 0.5356 - mse: 1.1878e-04\n",
      "Epoch 1074: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0221 - bpp: 0.5356 - mse: 1.1878e-04\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5317 - mse: 1.2883e-04\n",
      "Epoch 1075: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0594 - bpp: 0.5317 - mse: 1.2883e-04\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1163 - bpp: 0.5758 - mse: 1.3195e-04\n",
      "Epoch 1076: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1163 - bpp: 0.5758 - mse: 1.3195e-04\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1230 - bpp: 0.5597 - mse: 1.3753e-04\n",
      "Epoch 1077: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.1230 - bpp: 0.5597 - mse: 1.3753e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0876 - bpp: 0.5519 - mse: 1.3079e-04\n",
      "Epoch 1078: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0876 - bpp: 0.5519 - mse: 1.3079e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0583 - bpp: 0.5514 - mse: 1.2376e-04\n",
      "Epoch 1079: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0583 - bpp: 0.5514 - mse: 1.2376e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0688 - bpp: 0.5445 - mse: 1.2800e-04\n",
      "Epoch 1080: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0688 - bpp: 0.5445 - mse: 1.2800e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0255 - bpp: 0.5319 - mse: 1.2050e-04\n",
      "Epoch 1081: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0255 - bpp: 0.5319 - mse: 1.2050e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5523 - mse: 1.3005e-04\n",
      "Epoch 1082: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.0850 - bpp: 0.5523 - mse: 1.3005e-04\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0237 - bpp: 0.5364 - mse: 1.1898e-04\n",
      "Epoch 1083: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0237 - bpp: 0.5364 - mse: 1.1898e-04\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1270 - bpp: 0.5672 - mse: 1.3665e-04\n",
      "Epoch 1084: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1270 - bpp: 0.5672 - mse: 1.3665e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1386 - bpp: 0.5648 - mse: 1.4007e-04\n",
      "Epoch 1085: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1386 - bpp: 0.5648 - mse: 1.4007e-04\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1141 - bpp: 0.5626 - mse: 1.3463e-04\n",
      "Epoch 1086: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1141 - bpp: 0.5626 - mse: 1.3463e-04\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1071 - bpp: 0.5704 - mse: 1.3102e-04\n",
      "Epoch 1087: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1071 - bpp: 0.5704 - mse: 1.3102e-04\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1524 - bpp: 0.5773 - mse: 1.4040e-04\n",
      "Epoch 1088: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1524 - bpp: 0.5773 - mse: 1.4040e-04\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9791 - bpp: 0.5282 - mse: 1.1010e-04\n",
      "Epoch 1089: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9791 - bpp: 0.5282 - mse: 1.1010e-04\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1168 - bpp: 0.5659 - mse: 1.3449e-04\n",
      "Epoch 1090: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.1168 - bpp: 0.5659 - mse: 1.3449e-04\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0693 - bpp: 0.5550 - mse: 1.2557e-04\n",
      "Epoch 1091: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0693 - bpp: 0.5550 - mse: 1.2557e-04\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0948 - bpp: 0.5497 - mse: 1.3309e-04\n",
      "Epoch 1092: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0948 - bpp: 0.5497 - mse: 1.3309e-04\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0631 - bpp: 0.5458 - mse: 1.2632e-04\n",
      "Epoch 1093: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0631 - bpp: 0.5458 - mse: 1.2632e-04\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0787 - bpp: 0.5519 - mse: 1.2862e-04\n",
      "Epoch 1094: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0787 - bpp: 0.5519 - mse: 1.2862e-04\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0952 - bpp: 0.5572 - mse: 1.3134e-04\n",
      "Epoch 1095: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0952 - bpp: 0.5572 - mse: 1.3134e-04\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0276 - bpp: 0.5364 - mse: 1.1994e-04\n",
      "Epoch 1096: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0276 - bpp: 0.5364 - mse: 1.1994e-04\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0984 - bpp: 0.5616 - mse: 1.3106e-04\n",
      "Epoch 1097: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0984 - bpp: 0.5616 - mse: 1.3106e-04\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9999 - bpp: 0.5317 - mse: 1.1431e-04\n",
      "Epoch 1098: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9999 - bpp: 0.5317 - mse: 1.1431e-04\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0759 - bpp: 0.5567 - mse: 1.2676e-04\n",
      "Epoch 1099: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0759 - bpp: 0.5567 - mse: 1.2676e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5586 - mse: 1.2976e-04\n",
      "Epoch 1100: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0901 - bpp: 0.5586 - mse: 1.2976e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0864 - bpp: 0.5556 - mse: 1.2959e-04\n",
      "Epoch 1101: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0864 - bpp: 0.5556 - mse: 1.2959e-04\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0208 - bpp: 0.5351 - mse: 1.1858e-04\n",
      "Epoch 1102: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0208 - bpp: 0.5351 - mse: 1.1858e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5568 - mse: 1.3019e-04\n",
      "Epoch 1103: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0901 - bpp: 0.5568 - mse: 1.3019e-04\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1614 - bpp: 0.5725 - mse: 1.4378e-04\n",
      "Epoch 1104: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1614 - bpp: 0.5725 - mse: 1.4378e-04\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1105 - bpp: 0.5593 - mse: 1.3457e-04\n",
      "Epoch 1105: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1105 - bpp: 0.5593 - mse: 1.3457e-04\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1186 - bpp: 0.5605 - mse: 1.3627e-04\n",
      "Epoch 1106: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1186 - bpp: 0.5605 - mse: 1.3627e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0091 - bpp: 0.5327 - mse: 1.1632e-04\n",
      "Epoch 1107: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0091 - bpp: 0.5327 - mse: 1.1632e-04\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0845 - bpp: 0.5514 - mse: 1.3015e-04\n",
      "Epoch 1108: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0845 - bpp: 0.5514 - mse: 1.3015e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0717 - bpp: 0.5505 - mse: 1.2726e-04\n",
      "Epoch 1109: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0717 - bpp: 0.5505 - mse: 1.2726e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1208 - bpp: 0.5650 - mse: 1.3570e-04\n",
      "Epoch 1110: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1208 - bpp: 0.5650 - mse: 1.3570e-04\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0746 - bpp: 0.5472 - mse: 1.2876e-04\n",
      "Epoch 1111: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0746 - bpp: 0.5472 - mse: 1.2876e-04\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0918 - bpp: 0.5558 - mse: 1.3086e-04\n",
      "Epoch 1112: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0918 - bpp: 0.5558 - mse: 1.3086e-04\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0123 - bpp: 0.5375 - mse: 1.1592e-04\n",
      "Epoch 1113: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0123 - bpp: 0.5375 - mse: 1.1592e-04\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1608 - bpp: 0.5861 - mse: 1.4029e-04\n",
      "Epoch 1114: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1608 - bpp: 0.5861 - mse: 1.4029e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0583 - bpp: 0.5435 - mse: 1.2568e-04\n",
      "Epoch 1115: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0583 - bpp: 0.5435 - mse: 1.2568e-04\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0120 - bpp: 0.5314 - mse: 1.1734e-04\n",
      "Epoch 1116: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 1.0120 - bpp: 0.5314 - mse: 1.1734e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1689 - bpp: 0.5761 - mse: 1.4474e-04\n",
      "Epoch 1117: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1689 - bpp: 0.5761 - mse: 1.4474e-04\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1559 - bpp: 0.5839 - mse: 1.3965e-04\n",
      "Epoch 1118: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.1559 - bpp: 0.5839 - mse: 1.3965e-04\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0703 - bpp: 0.5556 - mse: 1.2565e-04\n",
      "Epoch 1119: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0703 - bpp: 0.5556 - mse: 1.2565e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1652 - bpp: 0.5781 - mse: 1.4332e-04\n",
      "Epoch 1120: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1652 - bpp: 0.5781 - mse: 1.4332e-04\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0788 - bpp: 0.5521 - mse: 1.2859e-04\n",
      "Epoch 1121: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0788 - bpp: 0.5521 - mse: 1.2859e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0513 - bpp: 0.5453 - mse: 1.2353e-04\n",
      "Epoch 1122: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0513 - bpp: 0.5453 - mse: 1.2353e-04\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5523 - mse: 1.2380e-04\n",
      "Epoch 1123: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0594 - bpp: 0.5523 - mse: 1.2380e-04\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1062 - bpp: 0.5557 - mse: 1.3440e-04\n",
      "Epoch 1124: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1062 - bpp: 0.5557 - mse: 1.3440e-04\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1078 - bpp: 0.5567 - mse: 1.3456e-04\n",
      "Epoch 1125: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.1078 - bpp: 0.5567 - mse: 1.3456e-04\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0847 - bpp: 0.5507 - mse: 1.3036e-04\n",
      "Epoch 1126: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0847 - bpp: 0.5507 - mse: 1.3036e-04\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0964 - bpp: 0.5709 - mse: 1.2831e-04\n",
      "Epoch 1127: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0964 - bpp: 0.5709 - mse: 1.2831e-04\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1428 - bpp: 0.5766 - mse: 1.3823e-04\n",
      "Epoch 1128: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1428 - bpp: 0.5766 - mse: 1.3823e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0097 - bpp: 0.5315 - mse: 1.1674e-04\n",
      "Epoch 1129: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0097 - bpp: 0.5315 - mse: 1.1674e-04\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0187 - bpp: 0.5258 - mse: 1.2034e-04\n",
      "Epoch 1130: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.0187 - bpp: 0.5258 - mse: 1.2034e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0081 - bpp: 0.5274 - mse: 1.1735e-04\n",
      "Epoch 1131: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0081 - bpp: 0.5274 - mse: 1.1735e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0479 - bpp: 0.5517 - mse: 1.2114e-04\n",
      "Epoch 1132: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0479 - bpp: 0.5517 - mse: 1.2114e-04\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0623 - bpp: 0.5444 - mse: 1.2646e-04\n",
      "Epoch 1133: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0623 - bpp: 0.5444 - mse: 1.2646e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9951 - bpp: 0.5267 - mse: 1.1435e-04\n",
      "Epoch 1134: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.9951 - bpp: 0.5267 - mse: 1.1435e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0397 - bpp: 0.5500 - mse: 1.1955e-04\n",
      "Epoch 1135: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0397 - bpp: 0.5500 - mse: 1.1955e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1621 - bpp: 0.5730 - mse: 1.4381e-04\n",
      "Epoch 1136: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1621 - bpp: 0.5730 - mse: 1.4381e-04\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0488 - bpp: 0.5486 - mse: 1.2214e-04\n",
      "Epoch 1137: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.0488 - bpp: 0.5486 - mse: 1.2214e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1274 - bpp: 0.5642 - mse: 1.3752e-04\n",
      "Epoch 1138: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.1274 - bpp: 0.5642 - mse: 1.3752e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0882 - bpp: 0.5489 - mse: 1.3167e-04\n",
      "Epoch 1139: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0882 - bpp: 0.5489 - mse: 1.3167e-04\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0286 - bpp: 0.5467 - mse: 1.1766e-04\n",
      "Epoch 1140: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0286 - bpp: 0.5467 - mse: 1.1766e-04\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9926 - bpp: 0.5227 - mse: 1.1472e-04\n",
      "Epoch 1141: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.9926 - bpp: 0.5227 - mse: 1.1472e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9918 - bpp: 0.5281 - mse: 1.1322e-04\n",
      "Epoch 1142: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9918 - bpp: 0.5281 - mse: 1.1322e-04\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0149 - bpp: 0.5400 - mse: 1.1595e-04\n",
      "Epoch 1143: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0149 - bpp: 0.5400 - mse: 1.1595e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0556 - bpp: 0.5451 - mse: 1.2465e-04\n",
      "Epoch 1144: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0556 - bpp: 0.5451 - mse: 1.2465e-04\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1390 - bpp: 0.5771 - mse: 1.3717e-04\n",
      "Epoch 1145: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.1390 - bpp: 0.5771 - mse: 1.3717e-04\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0219 - bpp: 0.5322 - mse: 1.1956e-04\n",
      "Epoch 1146: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0219 - bpp: 0.5322 - mse: 1.1956e-04\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0729 - bpp: 0.5501 - mse: 1.2764e-04\n",
      "Epoch 1147: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0729 - bpp: 0.5501 - mse: 1.2764e-04\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0852 - bpp: 0.5526 - mse: 1.3002e-04\n",
      "Epoch 1148: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0852 - bpp: 0.5526 - mse: 1.3002e-04\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1090 - bpp: 0.5615 - mse: 1.3367e-04\n",
      "Epoch 1149: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1090 - bpp: 0.5615 - mse: 1.3367e-04\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9954 - bpp: 0.5330 - mse: 1.1290e-04\n",
      "Epoch 1150: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 0.9954 - bpp: 0.5330 - mse: 1.1290e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1226 - bpp: 0.5573 - mse: 1.3801e-04\n",
      "Epoch 1151: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1226 - bpp: 0.5573 - mse: 1.3801e-04\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1089 - bpp: 0.5636 - mse: 1.3314e-04\n",
      "Epoch 1152: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1089 - bpp: 0.5636 - mse: 1.3314e-04\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0993 - bpp: 0.5558 - mse: 1.3270e-04\n",
      "Epoch 1153: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0993 - bpp: 0.5558 - mse: 1.3270e-04\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0634 - bpp: 0.5538 - mse: 1.2441e-04\n",
      "Epoch 1154: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0634 - bpp: 0.5538 - mse: 1.2441e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0932 - bpp: 0.5547 - mse: 1.3145e-04\n",
      "Epoch 1155: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.0932 - bpp: 0.5547 - mse: 1.3145e-04\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0013 - bpp: 0.5205 - mse: 1.1737e-04\n",
      "Epoch 1156: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0013 - bpp: 0.5205 - mse: 1.1737e-04\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0255 - bpp: 0.5295 - mse: 1.2109e-04\n",
      "Epoch 1157: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0255 - bpp: 0.5295 - mse: 1.2109e-04\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9989 - bpp: 0.5315 - mse: 1.1409e-04\n",
      "Epoch 1158: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 0.9989 - bpp: 0.5315 - mse: 1.1409e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9767 - bpp: 0.5200 - mse: 1.1150e-04\n",
      "Epoch 1159: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 0.9767 - bpp: 0.5200 - mse: 1.1150e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0665 - bpp: 0.5514 - mse: 1.2576e-04\n",
      "Epoch 1160: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0665 - bpp: 0.5514 - mse: 1.2576e-04\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1139 - bpp: 0.5550 - mse: 1.3646e-04\n",
      "Epoch 1161: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1139 - bpp: 0.5550 - mse: 1.3646e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0692 - bpp: 0.5483 - mse: 1.2717e-04\n",
      "Epoch 1162: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0692 - bpp: 0.5483 - mse: 1.2717e-04\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0223 - bpp: 0.5370 - mse: 1.1849e-04\n",
      "Epoch 1163: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0223 - bpp: 0.5370 - mse: 1.1849e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0101 - bpp: 0.5275 - mse: 1.1782e-04\n",
      "Epoch 1164: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0101 - bpp: 0.5275 - mse: 1.1782e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1017 - bpp: 0.5611 - mse: 1.3196e-04\n",
      "Epoch 1165: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1017 - bpp: 0.5611 - mse: 1.3196e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1053 - bpp: 0.5572 - mse: 1.3380e-04\n",
      "Epoch 1166: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1053 - bpp: 0.5572 - mse: 1.3380e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1014 - bpp: 0.5565 - mse: 1.3303e-04\n",
      "Epoch 1167: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1014 - bpp: 0.5565 - mse: 1.3303e-04\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9972 - bpp: 0.5284 - mse: 1.1445e-04\n",
      "Epoch 1168: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 0.9972 - bpp: 0.5284 - mse: 1.1445e-04\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0403 - bpp: 0.5386 - mse: 1.2249e-04\n",
      "Epoch 1169: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.0403 - bpp: 0.5386 - mse: 1.2249e-04\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0509 - bpp: 0.5335 - mse: 1.2632e-04\n",
      "Epoch 1170: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0509 - bpp: 0.5335 - mse: 1.2632e-04\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0965 - bpp: 0.5571 - mse: 1.3169e-04\n",
      "Epoch 1171: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.0965 - bpp: 0.5571 - mse: 1.3169e-04\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0014 - bpp: 0.5179 - mse: 1.1806e-04\n",
      "Epoch 1172: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0014 - bpp: 0.5179 - mse: 1.1806e-04\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1331 - bpp: 0.5748 - mse: 1.3631e-04\n",
      "Epoch 1173: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1331 - bpp: 0.5748 - mse: 1.3631e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1194 - bpp: 0.5620 - mse: 1.3610e-04\n",
      "Epoch 1174: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 1.1194 - bpp: 0.5620 - mse: 1.3610e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0949 - bpp: 0.5540 - mse: 1.3205e-04\n",
      "Epoch 1175: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0949 - bpp: 0.5540 - mse: 1.3205e-04\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0335 - bpp: 0.5336 - mse: 1.2206e-04\n",
      "Epoch 1176: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0335 - bpp: 0.5336 - mse: 1.2206e-04\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1612 - bpp: 0.5732 - mse: 1.4353e-04\n",
      "Epoch 1177: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1612 - bpp: 0.5732 - mse: 1.4353e-04\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0284 - bpp: 0.5324 - mse: 1.2108e-04\n",
      "Epoch 1178: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 1.0284 - bpp: 0.5324 - mse: 1.2108e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0293 - bpp: 0.5328 - mse: 1.2121e-04\n",
      "Epoch 1179: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0293 - bpp: 0.5328 - mse: 1.2121e-04\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0726 - bpp: 0.5452 - mse: 1.2876e-04\n",
      "Epoch 1180: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.0726 - bpp: 0.5452 - mse: 1.2876e-04\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.5397 - mse: 1.1903e-04\n",
      "Epoch 1181: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0273 - bpp: 0.5397 - mse: 1.1903e-04\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0055 - bpp: 0.5240 - mse: 1.1756e-04\n",
      "Epoch 1182: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0055 - bpp: 0.5240 - mse: 1.1756e-04\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0936 - bpp: 0.5486 - mse: 1.3304e-04\n",
      "Epoch 1183: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0936 - bpp: 0.5486 - mse: 1.3304e-04\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0146 - bpp: 0.5338 - mse: 1.1737e-04\n",
      "Epoch 1184: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.0146 - bpp: 0.5338 - mse: 1.1737e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1038 - bpp: 0.5647 - mse: 1.3162e-04\n",
      "Epoch 1185: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1038 - bpp: 0.5647 - mse: 1.3162e-04\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1178 - bpp: 0.5633 - mse: 1.3539e-04\n",
      "Epoch 1186: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.1178 - bpp: 0.5633 - mse: 1.3539e-04\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0226 - bpp: 0.5392 - mse: 1.1801e-04\n",
      "Epoch 1187: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0226 - bpp: 0.5392 - mse: 1.1801e-04\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1098 - bpp: 0.5629 - mse: 1.3352e-04\n",
      "Epoch 1188: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1098 - bpp: 0.5629 - mse: 1.3352e-04\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0111 - bpp: 0.5256 - mse: 1.1855e-04\n",
      "Epoch 1189: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0111 - bpp: 0.5256 - mse: 1.1855e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0421 - bpp: 0.5345 - mse: 1.2391e-04\n",
      "Epoch 1190: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0421 - bpp: 0.5345 - mse: 1.2391e-04\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1314 - bpp: 0.5681 - mse: 1.3754e-04\n",
      "Epoch 1191: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1314 - bpp: 0.5681 - mse: 1.3754e-04\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9875 - bpp: 0.5253 - mse: 1.1286e-04\n",
      "Epoch 1192: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9875 - bpp: 0.5253 - mse: 1.1286e-04\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0238 - bpp: 0.5371 - mse: 1.1881e-04\n",
      "Epoch 1193: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0238 - bpp: 0.5371 - mse: 1.1881e-04\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0574 - bpp: 0.5400 - mse: 1.2630e-04\n",
      "Epoch 1194: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0574 - bpp: 0.5400 - mse: 1.2630e-04\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.5390 - mse: 1.1949e-04\n",
      "Epoch 1195: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0285 - bpp: 0.5390 - mse: 1.1949e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0569 - bpp: 0.5385 - mse: 1.2656e-04\n",
      "Epoch 1196: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0569 - bpp: 0.5385 - mse: 1.2656e-04\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1320 - bpp: 0.5590 - mse: 1.3991e-04\n",
      "Epoch 1197: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1320 - bpp: 0.5590 - mse: 1.3991e-04\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9949 - bpp: 0.5198 - mse: 1.1599e-04\n",
      "Epoch 1198: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.9949 - bpp: 0.5198 - mse: 1.1599e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1302 - bpp: 0.5752 - mse: 1.3549e-04\n",
      "Epoch 1199: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1302 - bpp: 0.5752 - mse: 1.3549e-04\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1308 - bpp: 0.5707 - mse: 1.3675e-04\n",
      "Epoch 1200: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1308 - bpp: 0.5707 - mse: 1.3675e-04\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0923 - bpp: 0.5642 - mse: 1.2893e-04\n",
      "Epoch 1201: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0923 - bpp: 0.5642 - mse: 1.2893e-04\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0588 - bpp: 0.5450 - mse: 1.2545e-04\n",
      "Epoch 1202: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0588 - bpp: 0.5450 - mse: 1.2545e-04\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0727 - bpp: 0.5438 - mse: 1.2911e-04\n",
      "Epoch 1203: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0727 - bpp: 0.5438 - mse: 1.2911e-04\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0423 - bpp: 0.5330 - mse: 1.2435e-04\n",
      "Epoch 1204: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0423 - bpp: 0.5330 - mse: 1.2435e-04\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0229 - bpp: 0.5333 - mse: 1.1952e-04\n",
      "Epoch 1205: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0229 - bpp: 0.5333 - mse: 1.1952e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1581 - bpp: 0.5723 - mse: 1.4302e-04\n",
      "Epoch 1206: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1581 - bpp: 0.5723 - mse: 1.4302e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0353 - bpp: 0.5363 - mse: 1.2184e-04\n",
      "Epoch 1207: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0353 - bpp: 0.5363 - mse: 1.2184e-04\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0277 - bpp: 0.5495 - mse: 1.1674e-04\n",
      "Epoch 1208: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0277 - bpp: 0.5495 - mse: 1.1674e-04\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0753 - bpp: 0.5585 - mse: 1.2619e-04\n",
      "Epoch 1209: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0753 - bpp: 0.5585 - mse: 1.2619e-04\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0827 - bpp: 0.5547 - mse: 1.2892e-04\n",
      "Epoch 1210: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.0827 - bpp: 0.5547 - mse: 1.2892e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0065 - bpp: 0.5285 - mse: 1.1671e-04\n",
      "Epoch 1211: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0065 - bpp: 0.5285 - mse: 1.1671e-04\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9512 - bpp: 0.5087 - mse: 1.0805e-04\n",
      "Epoch 1212: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 0.9512 - bpp: 0.5087 - mse: 1.0805e-04\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1368 - bpp: 0.5765 - mse: 1.3678e-04\n",
      "Epoch 1213: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1368 - bpp: 0.5765 - mse: 1.3678e-04\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1284 - bpp: 0.5649 - mse: 1.3758e-04\n",
      "Epoch 1214: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.1284 - bpp: 0.5649 - mse: 1.3758e-04\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1059 - bpp: 0.5633 - mse: 1.3247e-04\n",
      "Epoch 1215: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1059 - bpp: 0.5633 - mse: 1.3247e-04\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1226 - bpp: 0.5591 - mse: 1.3758e-04\n",
      "Epoch 1216: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1226 - bpp: 0.5591 - mse: 1.3758e-04\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0978 - bpp: 0.5613 - mse: 1.3098e-04\n",
      "Epoch 1217: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0978 - bpp: 0.5613 - mse: 1.3098e-04\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0593 - bpp: 0.5505 - mse: 1.2423e-04\n",
      "Epoch 1218: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0593 - bpp: 0.5505 - mse: 1.2423e-04\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0312 - bpp: 0.5397 - mse: 1.2001e-04\n",
      "Epoch 1219: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0312 - bpp: 0.5397 - mse: 1.2001e-04\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0525 - bpp: 0.5503 - mse: 1.2259e-04\n",
      "Epoch 1220: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0525 - bpp: 0.5503 - mse: 1.2259e-04\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1050 - bpp: 0.5500 - mse: 1.3551e-04\n",
      "Epoch 1221: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1050 - bpp: 0.5500 - mse: 1.3551e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0722 - bpp: 0.5532 - mse: 1.2672e-04\n",
      "Epoch 1222: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0722 - bpp: 0.5532 - mse: 1.2672e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0297 - bpp: 0.5333 - mse: 1.2118e-04\n",
      "Epoch 1223: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0297 - bpp: 0.5333 - mse: 1.2118e-04\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1224 - bpp: 0.5677 - mse: 1.3544e-04\n",
      "Epoch 1224: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.1224 - bpp: 0.5677 - mse: 1.3544e-04\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1220 - bpp: 0.5702 - mse: 1.3473e-04\n",
      "Epoch 1225: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1220 - bpp: 0.5702 - mse: 1.3473e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0593 - bpp: 0.5414 - mse: 1.2646e-04\n",
      "Epoch 1226: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0593 - bpp: 0.5414 - mse: 1.2646e-04\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1026 - bpp: 0.5580 - mse: 1.3296e-04\n",
      "Epoch 1227: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1026 - bpp: 0.5580 - mse: 1.3296e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0087 - bpp: 0.5263 - mse: 1.1778e-04\n",
      "Epoch 1228: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.0087 - bpp: 0.5263 - mse: 1.1778e-04\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1235 - bpp: 0.5700 - mse: 1.3515e-04\n",
      "Epoch 1229: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1235 - bpp: 0.5700 - mse: 1.3515e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0315 - bpp: 0.5365 - mse: 1.2086e-04\n",
      "Epoch 1230: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0315 - bpp: 0.5365 - mse: 1.2086e-04\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0104 - bpp: 0.5349 - mse: 1.1608e-04\n",
      "Epoch 1231: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0104 - bpp: 0.5349 - mse: 1.1608e-04\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0549 - bpp: 0.5466 - mse: 1.2411e-04\n",
      "Epoch 1232: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0549 - bpp: 0.5466 - mse: 1.2411e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1158 - bpp: 0.5636 - mse: 1.3481e-04\n",
      "Epoch 1233: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1158 - bpp: 0.5636 - mse: 1.3481e-04\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0308 - bpp: 0.5250 - mse: 1.2349e-04\n",
      "Epoch 1234: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0308 - bpp: 0.5250 - mse: 1.2349e-04\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1828 - bpp: 0.5864 - mse: 1.4562e-04\n",
      "Epoch 1235: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1828 - bpp: 0.5864 - mse: 1.4562e-04\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0356 - bpp: 0.5415 - mse: 1.2062e-04\n",
      "Epoch 1236: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0356 - bpp: 0.5415 - mse: 1.2062e-04\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0887 - bpp: 0.5588 - mse: 1.2938e-04\n",
      "Epoch 1237: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0887 - bpp: 0.5588 - mse: 1.2938e-04\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1164 - bpp: 0.5633 - mse: 1.3505e-04\n",
      "Epoch 1238: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1164 - bpp: 0.5633 - mse: 1.3505e-04\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0345 - bpp: 0.5381 - mse: 1.2118e-04\n",
      "Epoch 1239: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0345 - bpp: 0.5381 - mse: 1.2118e-04\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1876 - bpp: 0.5877 - mse: 1.4647e-04\n",
      "Epoch 1240: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1876 - bpp: 0.5877 - mse: 1.4647e-04\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0264 - bpp: 0.5345 - mse: 1.2008e-04\n",
      "Epoch 1241: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0264 - bpp: 0.5345 - mse: 1.2008e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1572 - bpp: 0.5753 - mse: 1.4206e-04\n",
      "Epoch 1242: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1572 - bpp: 0.5753 - mse: 1.4206e-04\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9660 - bpp: 0.5037 - mse: 1.1285e-04\n",
      "Epoch 1243: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9660 - bpp: 0.5037 - mse: 1.1285e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0588 - bpp: 0.5444 - mse: 1.2559e-04\n",
      "Epoch 1244: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0588 - bpp: 0.5444 - mse: 1.2559e-04\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0277 - bpp: 0.5354 - mse: 1.2020e-04\n",
      "Epoch 1245: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0277 - bpp: 0.5354 - mse: 1.2020e-04\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0622 - bpp: 0.5550 - mse: 1.2384e-04\n",
      "Epoch 1246: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0622 - bpp: 0.5550 - mse: 1.2384e-04\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0762 - bpp: 0.5499 - mse: 1.2848e-04\n",
      "Epoch 1247: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0762 - bpp: 0.5499 - mse: 1.2848e-04\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1063 - bpp: 0.5548 - mse: 1.3466e-04\n",
      "Epoch 1248: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1063 - bpp: 0.5548 - mse: 1.3466e-04\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0933 - bpp: 0.5593 - mse: 1.3038e-04\n",
      "Epoch 1249: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0933 - bpp: 0.5593 - mse: 1.3038e-04\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0413 - bpp: 0.5335 - mse: 1.2396e-04\n",
      "Epoch 1250: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0413 - bpp: 0.5335 - mse: 1.2396e-04\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1450 - bpp: 0.5704 - mse: 1.4030e-04\n",
      "Epoch 1251: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1450 - bpp: 0.5704 - mse: 1.4030e-04\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0143 - bpp: 0.5306 - mse: 1.1809e-04\n",
      "Epoch 1252: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0143 - bpp: 0.5306 - mse: 1.1809e-04\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1147 - bpp: 0.5627 - mse: 1.3476e-04\n",
      "Epoch 1253: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.1147 - bpp: 0.5627 - mse: 1.3476e-04\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0883 - bpp: 0.5624 - mse: 1.2839e-04\n",
      "Epoch 1254: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0883 - bpp: 0.5624 - mse: 1.2839e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5452 - mse: 1.2665e-04\n",
      "Epoch 1255: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0640 - bpp: 0.5452 - mse: 1.2665e-04\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0875 - bpp: 0.5605 - mse: 1.2865e-04\n",
      "Epoch 1256: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0875 - bpp: 0.5605 - mse: 1.2865e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1012 - bpp: 0.5563 - mse: 1.3303e-04\n",
      "Epoch 1257: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1012 - bpp: 0.5563 - mse: 1.3303e-04\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9942 - bpp: 0.5199 - mse: 1.1578e-04\n",
      "Epoch 1258: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 0.9942 - bpp: 0.5199 - mse: 1.1578e-04\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0486 - bpp: 0.5450 - mse: 1.2294e-04\n",
      "Epoch 1259: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0486 - bpp: 0.5450 - mse: 1.2294e-04\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0270 - bpp: 0.5250 - mse: 1.2256e-04\n",
      "Epoch 1260: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0270 - bpp: 0.5250 - mse: 1.2256e-04\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9514 - bpp: 0.5077 - mse: 1.0833e-04\n",
      "Epoch 1261: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 0.9514 - bpp: 0.5077 - mse: 1.0833e-04\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2654 - bpp: 0.6133 - mse: 1.5920e-04\n",
      "Epoch 1262: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.2654 - bpp: 0.6133 - mse: 1.5920e-04\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0366 - bpp: 0.5461 - mse: 1.1974e-04\n",
      "Epoch 1263: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.0366 - bpp: 0.5461 - mse: 1.1974e-04\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0796 - bpp: 0.5637 - mse: 1.2595e-04\n",
      "Epoch 1264: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0796 - bpp: 0.5637 - mse: 1.2595e-04\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0599 - bpp: 0.5395 - mse: 1.2704e-04\n",
      "Epoch 1265: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0599 - bpp: 0.5395 - mse: 1.2704e-04\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1457 - bpp: 0.5718 - mse: 1.4010e-04\n",
      "Epoch 1266: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.1457 - bpp: 0.5718 - mse: 1.4010e-04\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0968 - bpp: 0.5575 - mse: 1.3165e-04\n",
      "Epoch 1267: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0968 - bpp: 0.5575 - mse: 1.3165e-04\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0699 - bpp: 0.5473 - mse: 1.2759e-04\n",
      "Epoch 1268: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0699 - bpp: 0.5473 - mse: 1.2759e-04\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1163 - bpp: 0.5680 - mse: 1.3388e-04\n",
      "Epoch 1269: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.1163 - bpp: 0.5680 - mse: 1.3388e-04\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0642 - bpp: 0.5462 - mse: 1.2646e-04\n",
      "Epoch 1270: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0642 - bpp: 0.5462 - mse: 1.2646e-04\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0474 - bpp: 0.5456 - mse: 1.2253e-04\n",
      "Epoch 1271: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0474 - bpp: 0.5456 - mse: 1.2253e-04\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9946 - bpp: 0.5214 - mse: 1.1553e-04\n",
      "Epoch 1272: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9946 - bpp: 0.5214 - mse: 1.1553e-04\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0836 - bpp: 0.5509 - mse: 1.3005e-04\n",
      "Epoch 1273: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0836 - bpp: 0.5509 - mse: 1.3005e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0427 - bpp: 0.5370 - mse: 1.2347e-04\n",
      "Epoch 1274: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0427 - bpp: 0.5370 - mse: 1.2347e-04\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0704 - bpp: 0.5444 - mse: 1.2842e-04\n",
      "Epoch 1275: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0704 - bpp: 0.5444 - mse: 1.2842e-04\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0273 - bpp: 0.5277 - mse: 1.2196e-04\n",
      "Epoch 1276: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0273 - bpp: 0.5277 - mse: 1.2196e-04\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0028 - bpp: 0.5310 - mse: 1.1519e-04\n",
      "Epoch 1277: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0028 - bpp: 0.5310 - mse: 1.1519e-04\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9985 - bpp: 0.5287 - mse: 1.1469e-04\n",
      "Epoch 1278: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9985 - bpp: 0.5287 - mse: 1.1469e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5529 - mse: 1.2991e-04\n",
      "Epoch 1279: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0850 - bpp: 0.5529 - mse: 1.2991e-04\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1271 - bpp: 0.5735 - mse: 1.3516e-04\n",
      "Epoch 1280: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.1271 - bpp: 0.5735 - mse: 1.3516e-04\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9969 - bpp: 0.5243 - mse: 1.1539e-04\n",
      "Epoch 1281: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.9969 - bpp: 0.5243 - mse: 1.1539e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0395 - bpp: 0.5339 - mse: 1.2343e-04\n",
      "Epoch 1282: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0395 - bpp: 0.5339 - mse: 1.2343e-04\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2177 - bpp: 0.5954 - mse: 1.5193e-04\n",
      "Epoch 1283: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.2177 - bpp: 0.5954 - mse: 1.5193e-04\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0632 - bpp: 0.5480 - mse: 1.2577e-04\n",
      "Epoch 1284: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0632 - bpp: 0.5480 - mse: 1.2577e-04\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0785 - bpp: 0.5434 - mse: 1.3064e-04\n",
      "Epoch 1285: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0785 - bpp: 0.5434 - mse: 1.3064e-04\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1375 - bpp: 0.5647 - mse: 1.3985e-04\n",
      "Epoch 1286: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1375 - bpp: 0.5647 - mse: 1.3985e-04\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1003 - bpp: 0.5613 - mse: 1.3159e-04\n",
      "Epoch 1287: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1003 - bpp: 0.5613 - mse: 1.3159e-04\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0603 - bpp: 0.5469 - mse: 1.2535e-04\n",
      "Epoch 1288: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0603 - bpp: 0.5469 - mse: 1.2535e-04\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9964 - bpp: 0.5323 - mse: 1.1329e-04\n",
      "Epoch 1289: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9964 - bpp: 0.5323 - mse: 1.1329e-04\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0328 - bpp: 0.5382 - mse: 1.2073e-04\n",
      "Epoch 1290: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0328 - bpp: 0.5382 - mse: 1.2073e-04\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1539 - bpp: 0.5683 - mse: 1.4296e-04\n",
      "Epoch 1291: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.1539 - bpp: 0.5683 - mse: 1.4296e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0559 - bpp: 0.5400 - mse: 1.2597e-04\n",
      "Epoch 1292: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0559 - bpp: 0.5400 - mse: 1.2597e-04\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1394 - bpp: 0.5627 - mse: 1.4080e-04\n",
      "Epoch 1293: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1394 - bpp: 0.5627 - mse: 1.4080e-04\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9975 - bpp: 0.5313 - mse: 1.1381e-04\n",
      "Epoch 1294: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.9975 - bpp: 0.5313 - mse: 1.1381e-04\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0644 - bpp: 0.5499 - mse: 1.2562e-04\n",
      "Epoch 1295: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0644 - bpp: 0.5499 - mse: 1.2562e-04\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1154 - bpp: 0.5634 - mse: 1.3476e-04\n",
      "Epoch 1296: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1154 - bpp: 0.5634 - mse: 1.3476e-04\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0657 - bpp: 0.5477 - mse: 1.2647e-04\n",
      "Epoch 1297: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0657 - bpp: 0.5477 - mse: 1.2647e-04\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1192 - bpp: 0.5537 - mse: 1.3806e-04\n",
      "Epoch 1298: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1192 - bpp: 0.5537 - mse: 1.3806e-04\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0901 - bpp: 0.5494 - mse: 1.3201e-04\n",
      "Epoch 1299: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0901 - bpp: 0.5494 - mse: 1.3201e-04\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0090 - bpp: 0.5272 - mse: 1.1761e-04\n",
      "Epoch 1300: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0090 - bpp: 0.5272 - mse: 1.1761e-04\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1769 - bpp: 0.5834 - mse: 1.4489e-04\n",
      "Epoch 1301: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1769 - bpp: 0.5834 - mse: 1.4489e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0364 - bpp: 0.5320 - mse: 1.2312e-04\n",
      "Epoch 1302: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0364 - bpp: 0.5320 - mse: 1.2312e-04\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0285 - bpp: 0.5281 - mse: 1.2216e-04\n",
      "Epoch 1303: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0285 - bpp: 0.5281 - mse: 1.2216e-04\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1028 - bpp: 0.5581 - mse: 1.3299e-04\n",
      "Epoch 1304: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1028 - bpp: 0.5581 - mse: 1.3299e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0698 - bpp: 0.5498 - mse: 1.2694e-04\n",
      "Epoch 1305: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0698 - bpp: 0.5498 - mse: 1.2694e-04\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0830 - bpp: 0.5614 - mse: 1.2734e-04\n",
      "Epoch 1306: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0830 - bpp: 0.5614 - mse: 1.2734e-04\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0832 - bpp: 0.5626 - mse: 1.2709e-04\n",
      "Epoch 1307: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0832 - bpp: 0.5626 - mse: 1.2709e-04\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0141 - bpp: 0.5355 - mse: 1.1686e-04\n",
      "Epoch 1308: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0141 - bpp: 0.5355 - mse: 1.1686e-04\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0645 - bpp: 0.5473 - mse: 1.2626e-04\n",
      "Epoch 1309: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0645 - bpp: 0.5473 - mse: 1.2626e-04\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0381 - bpp: 0.5401 - mse: 1.2158e-04\n",
      "Epoch 1310: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0381 - bpp: 0.5401 - mse: 1.2158e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0183 - bpp: 0.5398 - mse: 1.1683e-04\n",
      "Epoch 1311: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0183 - bpp: 0.5398 - mse: 1.1683e-04\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0466 - bpp: 0.5353 - mse: 1.2483e-04\n",
      "Epoch 1312: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0466 - bpp: 0.5353 - mse: 1.2483e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9934 - bpp: 0.5199 - mse: 1.1560e-04\n",
      "Epoch 1313: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9934 - bpp: 0.5199 - mse: 1.1560e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0238 - bpp: 0.5359 - mse: 1.1913e-04\n",
      "Epoch 1314: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0238 - bpp: 0.5359 - mse: 1.1913e-04\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0469 - bpp: 0.5339 - mse: 1.2523e-04\n",
      "Epoch 1315: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0469 - bpp: 0.5339 - mse: 1.2523e-04\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0357 - bpp: 0.5437 - mse: 1.2012e-04\n",
      "Epoch 1316: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0357 - bpp: 0.5437 - mse: 1.2012e-04\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9680 - bpp: 0.5219 - mse: 1.0891e-04\n",
      "Epoch 1317: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9680 - bpp: 0.5219 - mse: 1.0891e-04\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0931 - bpp: 0.5564 - mse: 1.3103e-04\n",
      "Epoch 1318: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0931 - bpp: 0.5564 - mse: 1.3103e-04\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0602 - bpp: 0.5510 - mse: 1.2433e-04\n",
      "Epoch 1319: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0602 - bpp: 0.5510 - mse: 1.2433e-04\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0425 - bpp: 0.5414 - mse: 1.2233e-04\n",
      "Epoch 1320: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0425 - bpp: 0.5414 - mse: 1.2233e-04\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0098 - bpp: 0.5348 - mse: 1.1595e-04\n",
      "Epoch 1321: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0098 - bpp: 0.5348 - mse: 1.1595e-04\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0118 - bpp: 0.5252 - mse: 1.1878e-04\n",
      "Epoch 1322: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0118 - bpp: 0.5252 - mse: 1.1878e-04\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0821 - bpp: 0.5547 - mse: 1.2877e-04\n",
      "Epoch 1323: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0821 - bpp: 0.5547 - mse: 1.2877e-04\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0740 - bpp: 0.5517 - mse: 1.2753e-04\n",
      "Epoch 1324: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0740 - bpp: 0.5517 - mse: 1.2753e-04\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0380 - bpp: 0.5382 - mse: 1.2202e-04\n",
      "Epoch 1325: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0380 - bpp: 0.5382 - mse: 1.2202e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1197 - bpp: 0.5692 - mse: 1.3440e-04\n",
      "Epoch 1326: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1197 - bpp: 0.5692 - mse: 1.3440e-04\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0213 - bpp: 0.5282 - mse: 1.2039e-04\n",
      "Epoch 1327: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0213 - bpp: 0.5282 - mse: 1.2039e-04\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0449 - bpp: 0.5465 - mse: 1.2168e-04\n",
      "Epoch 1328: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.0449 - bpp: 0.5465 - mse: 1.2168e-04\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9865 - bpp: 0.5170 - mse: 1.1461e-04\n",
      "Epoch 1329: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9865 - bpp: 0.5170 - mse: 1.1461e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0276 - bpp: 0.5361 - mse: 1.2000e-04\n",
      "Epoch 1330: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0276 - bpp: 0.5361 - mse: 1.2000e-04\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0953 - bpp: 0.5501 - mse: 1.3312e-04\n",
      "Epoch 1331: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0953 - bpp: 0.5501 - mse: 1.3312e-04\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1080 - bpp: 0.5539 - mse: 1.3529e-04\n",
      "Epoch 1332: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1080 - bpp: 0.5539 - mse: 1.3529e-04\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1114 - bpp: 0.5601 - mse: 1.3460e-04\n",
      "Epoch 1333: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.1114 - bpp: 0.5601 - mse: 1.3460e-04\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1442 - bpp: 0.5798 - mse: 1.3781e-04\n",
      "Epoch 1334: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1442 - bpp: 0.5798 - mse: 1.3781e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0695 - bpp: 0.5475 - mse: 1.2745e-04\n",
      "Epoch 1335: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0695 - bpp: 0.5475 - mse: 1.2745e-04\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0599 - bpp: 0.5504 - mse: 1.2441e-04\n",
      "Epoch 1336: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0599 - bpp: 0.5504 - mse: 1.2441e-04\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0021 - bpp: 0.5289 - mse: 1.1552e-04\n",
      "Epoch 1337: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0021 - bpp: 0.5289 - mse: 1.1552e-04\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9453 - bpp: 0.5083 - mse: 1.0669e-04\n",
      "Epoch 1338: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.9453 - bpp: 0.5083 - mse: 1.0669e-04\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9723 - bpp: 0.5206 - mse: 1.1027e-04\n",
      "Epoch 1339: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9723 - bpp: 0.5206 - mse: 1.1027e-04\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9998 - bpp: 0.5332 - mse: 1.1393e-04\n",
      "Epoch 1340: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 0.9998 - bpp: 0.5332 - mse: 1.1393e-04\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0574 - bpp: 0.5421 - mse: 1.2580e-04\n",
      "Epoch 1341: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0574 - bpp: 0.5421 - mse: 1.2580e-04\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0342 - bpp: 0.5369 - mse: 1.2140e-04\n",
      "Epoch 1342: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0342 - bpp: 0.5369 - mse: 1.2140e-04\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9922 - bpp: 0.5186 - mse: 1.1562e-04\n",
      "Epoch 1343: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9922 - bpp: 0.5186 - mse: 1.1562e-04\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9652 - bpp: 0.5129 - mse: 1.1043e-04\n",
      "Epoch 1344: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9652 - bpp: 0.5129 - mse: 1.1043e-04\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0874 - bpp: 0.5519 - mse: 1.3074e-04\n",
      "Epoch 1345: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0874 - bpp: 0.5519 - mse: 1.3074e-04\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9907 - bpp: 0.5339 - mse: 1.1154e-04\n",
      "Epoch 1346: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9907 - bpp: 0.5339 - mse: 1.1154e-04\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5475 - mse: 1.2609e-04\n",
      "Epoch 1347: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.0640 - bpp: 0.5475 - mse: 1.2609e-04\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0393 - bpp: 0.5417 - mse: 1.2149e-04\n",
      "Epoch 1348: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0393 - bpp: 0.5417 - mse: 1.2149e-04\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9897 - bpp: 0.5198 - mse: 1.1471e-04\n",
      "Epoch 1349: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.9897 - bpp: 0.5198 - mse: 1.1471e-04\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0673 - bpp: 0.5523 - mse: 1.2572e-04\n",
      "Epoch 1350: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0673 - bpp: 0.5523 - mse: 1.2572e-04\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9678 - bpp: 0.5248 - mse: 1.0815e-04\n",
      "Epoch 1351: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.9678 - bpp: 0.5248 - mse: 1.0815e-04\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0217 - bpp: 0.5374 - mse: 1.1825e-04\n",
      "Epoch 1352: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0217 - bpp: 0.5374 - mse: 1.1825e-04\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1187 - bpp: 0.5739 - mse: 1.3302e-04\n",
      "Epoch 1353: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1187 - bpp: 0.5739 - mse: 1.3302e-04\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0802 - bpp: 0.5559 - mse: 1.2799e-04\n",
      "Epoch 1354: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0802 - bpp: 0.5559 - mse: 1.2799e-04\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9722 - bpp: 0.5215 - mse: 1.1003e-04\n",
      "Epoch 1355: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9722 - bpp: 0.5215 - mse: 1.1003e-04\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0079 - bpp: 0.5247 - mse: 1.1796e-04\n",
      "Epoch 1356: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.0079 - bpp: 0.5247 - mse: 1.1796e-04\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0242 - bpp: 0.5258 - mse: 1.2167e-04\n",
      "Epoch 1357: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0242 - bpp: 0.5258 - mse: 1.2167e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0253 - bpp: 0.5246 - mse: 1.2224e-04\n",
      "Epoch 1358: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0253 - bpp: 0.5246 - mse: 1.2224e-04\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0745 - bpp: 0.5521 - mse: 1.2753e-04\n",
      "Epoch 1359: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0745 - bpp: 0.5521 - mse: 1.2753e-04\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5365 - mse: 1.2224e-04\n",
      "Epoch 1360: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0372 - bpp: 0.5365 - mse: 1.2224e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1441 - bpp: 0.5695 - mse: 1.4028e-04\n",
      "Epoch 1361: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1441 - bpp: 0.5695 - mse: 1.4028e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5389 - mse: 1.2165e-04\n",
      "Epoch 1362: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0372 - bpp: 0.5389 - mse: 1.2165e-04\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0542 - bpp: 0.5447 - mse: 1.2438e-04\n",
      "Epoch 1363: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0542 - bpp: 0.5447 - mse: 1.2438e-04\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1555 - bpp: 0.5864 - mse: 1.3893e-04\n",
      "Epoch 1364: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1555 - bpp: 0.5864 - mse: 1.3893e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.5473 - mse: 1.2707e-04\n",
      "Epoch 1365: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.0678 - bpp: 0.5473 - mse: 1.2707e-04\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0605 - bpp: 0.5470 - mse: 1.2536e-04\n",
      "Epoch 1366: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0605 - bpp: 0.5470 - mse: 1.2536e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0356 - bpp: 0.5426 - mse: 1.2037e-04\n",
      "Epoch 1367: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0356 - bpp: 0.5426 - mse: 1.2037e-04\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0276 - bpp: 0.5251 - mse: 1.2268e-04\n",
      "Epoch 1368: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0276 - bpp: 0.5251 - mse: 1.2268e-04\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0379 - bpp: 0.5454 - mse: 1.2025e-04\n",
      "Epoch 1369: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0379 - bpp: 0.5454 - mse: 1.2025e-04\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1008 - bpp: 0.5582 - mse: 1.3248e-04\n",
      "Epoch 1370: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1008 - bpp: 0.5582 - mse: 1.3248e-04\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1538 - bpp: 0.5882 - mse: 1.3807e-04\n",
      "Epoch 1371: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.1538 - bpp: 0.5882 - mse: 1.3807e-04\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0305 - bpp: 0.5336 - mse: 1.2133e-04\n",
      "Epoch 1372: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0305 - bpp: 0.5336 - mse: 1.2133e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0749 - bpp: 0.5501 - mse: 1.2813e-04\n",
      "Epoch 1373: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0749 - bpp: 0.5501 - mse: 1.2813e-04\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0061 - bpp: 0.5312 - mse: 1.1596e-04\n",
      "Epoch 1374: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0061 - bpp: 0.5312 - mse: 1.1596e-04\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0395 - bpp: 0.5324 - mse: 1.2382e-04\n",
      "Epoch 1375: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0395 - bpp: 0.5324 - mse: 1.2382e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5385 - mse: 1.2613e-04\n",
      "Epoch 1376: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0551 - bpp: 0.5385 - mse: 1.2613e-04\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1421 - bpp: 0.5672 - mse: 1.4036e-04\n",
      "Epoch 1377: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1421 - bpp: 0.5672 - mse: 1.4036e-04\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0000 - bpp: 0.5219 - mse: 1.1671e-04\n",
      "Epoch 1378: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.0000 - bpp: 0.5219 - mse: 1.1671e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0975 - bpp: 0.5450 - mse: 1.3488e-04\n",
      "Epoch 1379: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0975 - bpp: 0.5450 - mse: 1.3488e-04\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0011 - bpp: 0.5237 - mse: 1.1655e-04\n",
      "Epoch 1380: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0011 - bpp: 0.5237 - mse: 1.1655e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0250 - bpp: 0.5242 - mse: 1.2226e-04\n",
      "Epoch 1381: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0250 - bpp: 0.5242 - mse: 1.2226e-04\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0269 - bpp: 0.5288 - mse: 1.2160e-04\n",
      "Epoch 1382: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0269 - bpp: 0.5288 - mse: 1.2160e-04\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1267 - bpp: 0.5649 - mse: 1.3714e-04\n",
      "Epoch 1383: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.1267 - bpp: 0.5649 - mse: 1.3714e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9924 - bpp: 0.5182 - mse: 1.1577e-04\n",
      "Epoch 1384: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9924 - bpp: 0.5182 - mse: 1.1577e-04\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2248 - bpp: 0.5976 - mse: 1.5311e-04\n",
      "Epoch 1385: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.2248 - bpp: 0.5976 - mse: 1.5311e-04\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0126 - bpp: 0.5287 - mse: 1.1815e-04\n",
      "Epoch 1386: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0126 - bpp: 0.5287 - mse: 1.1815e-04\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9995 - bpp: 0.5170 - mse: 1.1780e-04\n",
      "Epoch 1387: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 0.9995 - bpp: 0.5170 - mse: 1.1780e-04\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0183 - bpp: 0.5306 - mse: 1.1907e-04\n",
      "Epoch 1388: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0183 - bpp: 0.5306 - mse: 1.1907e-04\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0690 - bpp: 0.5482 - mse: 1.2716e-04\n",
      "Epoch 1389: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0690 - bpp: 0.5482 - mse: 1.2716e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0507 - bpp: 0.5440 - mse: 1.2370e-04\n",
      "Epoch 1390: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0507 - bpp: 0.5440 - mse: 1.2370e-04\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9800 - bpp: 0.5246 - mse: 1.1118e-04\n",
      "Epoch 1391: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9800 - bpp: 0.5246 - mse: 1.1118e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1235 - bpp: 0.5626 - mse: 1.3695e-04\n",
      "Epoch 1392: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1235 - bpp: 0.5626 - mse: 1.3695e-04\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0262 - bpp: 0.5389 - mse: 1.1896e-04\n",
      "Epoch 1393: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.0262 - bpp: 0.5389 - mse: 1.1896e-04\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9961 - bpp: 0.5305 - mse: 1.1365e-04\n",
      "Epoch 1394: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.9961 - bpp: 0.5305 - mse: 1.1365e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0880 - bpp: 0.5605 - mse: 1.2877e-04\n",
      "Epoch 1395: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.0880 - bpp: 0.5605 - mse: 1.2877e-04\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0640 - bpp: 0.5410 - mse: 1.2770e-04\n",
      "Epoch 1396: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0640 - bpp: 0.5410 - mse: 1.2770e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0519 - bpp: 0.5346 - mse: 1.2629e-04\n",
      "Epoch 1397: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0519 - bpp: 0.5346 - mse: 1.2629e-04\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0666 - bpp: 0.5382 - mse: 1.2900e-04\n",
      "Epoch 1398: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0666 - bpp: 0.5382 - mse: 1.2900e-04\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0079 - bpp: 0.5305 - mse: 1.1655e-04\n",
      "Epoch 1399: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.0079 - bpp: 0.5305 - mse: 1.1655e-04\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0420 - bpp: 0.5386 - mse: 1.2291e-04\n",
      "Epoch 1400: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0420 - bpp: 0.5386 - mse: 1.2291e-04\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0549 - bpp: 0.5377 - mse: 1.2626e-04\n",
      "Epoch 1401: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.0549 - bpp: 0.5377 - mse: 1.2626e-04\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1285 - bpp: 0.5591 - mse: 1.3901e-04\n",
      "Epoch 1402: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1285 - bpp: 0.5591 - mse: 1.3901e-04\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5518 - mse: 1.2288e-04\n",
      "Epoch 1403: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0551 - bpp: 0.5518 - mse: 1.2288e-04\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0587 - bpp: 0.5415 - mse: 1.2627e-04\n",
      "Epoch 1404: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0587 - bpp: 0.5415 - mse: 1.2627e-04\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9874 - bpp: 0.5252 - mse: 1.1283e-04\n",
      "Epoch 1405: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 0.9874 - bpp: 0.5252 - mse: 1.1283e-04\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0081 - bpp: 0.5325 - mse: 1.1612e-04\n",
      "Epoch 1406: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0081 - bpp: 0.5325 - mse: 1.1612e-04\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0852 - bpp: 0.5461 - mse: 1.3162e-04\n",
      "Epoch 1407: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0852 - bpp: 0.5461 - mse: 1.3162e-04\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0692 - bpp: 0.5451 - mse: 1.2798e-04\n",
      "Epoch 1408: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0692 - bpp: 0.5451 - mse: 1.2798e-04\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0015 - bpp: 0.5183 - mse: 1.1798e-04\n",
      "Epoch 1409: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.0015 - bpp: 0.5183 - mse: 1.1798e-04\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1005 - bpp: 0.5519 - mse: 1.3392e-04\n",
      "Epoch 1410: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.1005 - bpp: 0.5519 - mse: 1.3392e-04\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0566 - bpp: 0.5387 - mse: 1.2645e-04\n",
      "Epoch 1411: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0566 - bpp: 0.5387 - mse: 1.2645e-04\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0142 - bpp: 0.5297 - mse: 1.1828e-04\n",
      "Epoch 1412: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0142 - bpp: 0.5297 - mse: 1.1828e-04\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0320 - bpp: 0.5364 - mse: 1.2100e-04\n",
      "Epoch 1413: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.0320 - bpp: 0.5364 - mse: 1.2100e-04\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0858 - bpp: 0.5461 - mse: 1.3178e-04\n",
      "Epoch 1414: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0858 - bpp: 0.5461 - mse: 1.3178e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0286 - bpp: 0.5283 - mse: 1.2213e-04\n",
      "Epoch 1415: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0286 - bpp: 0.5283 - mse: 1.2213e-04\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0282 - bpp: 0.5349 - mse: 1.2044e-04\n",
      "Epoch 1416: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0282 - bpp: 0.5349 - mse: 1.2044e-04\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9958 - bpp: 0.5294 - mse: 1.1387e-04\n",
      "Epoch 1417: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9958 - bpp: 0.5294 - mse: 1.1387e-04\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0537 - bpp: 0.5537 - mse: 1.2209e-04\n",
      "Epoch 1418: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0537 - bpp: 0.5537 - mse: 1.2209e-04\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9957 - bpp: 0.5286 - mse: 1.1404e-04\n",
      "Epoch 1419: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.9957 - bpp: 0.5286 - mse: 1.1404e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0597 - bpp: 0.5418 - mse: 1.2645e-04\n",
      "Epoch 1420: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0597 - bpp: 0.5418 - mse: 1.2645e-04\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0568 - bpp: 0.5443 - mse: 1.2511e-04\n",
      "Epoch 1421: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.0568 - bpp: 0.5443 - mse: 1.2511e-04\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0362 - bpp: 0.5405 - mse: 1.2100e-04\n",
      "Epoch 1422: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0362 - bpp: 0.5405 - mse: 1.2100e-04\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0793 - bpp: 0.5488 - mse: 1.2952e-04\n",
      "Epoch 1423: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.0793 - bpp: 0.5488 - mse: 1.2952e-04\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0872 - bpp: 0.5523 - mse: 1.3059e-04\n",
      "Epoch 1424: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0872 - bpp: 0.5523 - mse: 1.3059e-04\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1016 - bpp: 0.5713 - mse: 1.2948e-04\n",
      "Epoch 1425: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.1016 - bpp: 0.5713 - mse: 1.2948e-04\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1187 - bpp: 0.5676 - mse: 1.3454e-04\n",
      "Epoch 1426: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.1187 - bpp: 0.5676 - mse: 1.3454e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0246 - bpp: 0.5358 - mse: 1.1933e-04\n",
      "Epoch 1427: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0246 - bpp: 0.5358 - mse: 1.1933e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0856 - bpp: 0.5481 - mse: 1.3123e-04\n",
      "Epoch 1428: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0856 - bpp: 0.5481 - mse: 1.3123e-04\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1153 - bpp: 0.5637 - mse: 1.3465e-04\n",
      "Epoch 1429: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.1153 - bpp: 0.5637 - mse: 1.3465e-04\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1113 - bpp: 0.5478 - mse: 1.3756e-04\n",
      "Epoch 1430: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.1113 - bpp: 0.5478 - mse: 1.3756e-04\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0551 - bpp: 0.5425 - mse: 1.2515e-04\n",
      "Epoch 1431: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0551 - bpp: 0.5425 - mse: 1.2515e-04\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9979 - bpp: 0.5287 - mse: 1.1455e-04\n",
      "Epoch 1432: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 0.9979 - bpp: 0.5287 - mse: 1.1455e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0525 - bpp: 0.5447 - mse: 1.2396e-04\n",
      "Epoch 1433: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0525 - bpp: 0.5447 - mse: 1.2396e-04\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0517 - bpp: 0.5394 - mse: 1.2508e-04\n",
      "Epoch 1434: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0517 - bpp: 0.5394 - mse: 1.2508e-04\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9803 - bpp: 0.5212 - mse: 1.1207e-04\n",
      "Epoch 1435: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9803 - bpp: 0.5212 - mse: 1.1207e-04\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1060 - bpp: 0.5640 - mse: 1.3233e-04\n",
      "Epoch 1436: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1060 - bpp: 0.5640 - mse: 1.3233e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0565 - bpp: 0.5463 - mse: 1.2456e-04\n",
      "Epoch 1437: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0565 - bpp: 0.5463 - mse: 1.2456e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1101 - bpp: 0.5635 - mse: 1.3343e-04\n",
      "Epoch 1438: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1101 - bpp: 0.5635 - mse: 1.3343e-04\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0150 - bpp: 0.5299 - mse: 1.1842e-04\n",
      "Epoch 1439: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0150 - bpp: 0.5299 - mse: 1.1842e-04\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0486 - bpp: 0.5404 - mse: 1.2409e-04\n",
      "Epoch 1440: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 1.0486 - bpp: 0.5404 - mse: 1.2409e-04\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1529 - bpp: 0.5684 - mse: 1.4270e-04\n",
      "Epoch 1441: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.1529 - bpp: 0.5684 - mse: 1.4270e-04\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0614 - bpp: 0.5523 - mse: 1.2428e-04\n",
      "Epoch 1442: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.0614 - bpp: 0.5523 - mse: 1.2428e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1083 - bpp: 0.5622 - mse: 1.3333e-04\n",
      "Epoch 1443: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1083 - bpp: 0.5622 - mse: 1.3333e-04\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0594 - bpp: 0.5508 - mse: 1.2417e-04\n",
      "Epoch 1444: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0594 - bpp: 0.5508 - mse: 1.2417e-04\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0885 - bpp: 0.5621 - mse: 1.2851e-04\n",
      "Epoch 1445: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0885 - bpp: 0.5621 - mse: 1.2851e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0372 - bpp: 0.5403 - mse: 1.2132e-04\n",
      "Epoch 1446: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0372 - bpp: 0.5403 - mse: 1.2132e-04\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1216 - bpp: 0.5695 - mse: 1.3478e-04\n",
      "Epoch 1447: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1216 - bpp: 0.5695 - mse: 1.3478e-04\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0511 - bpp: 0.5439 - mse: 1.2381e-04\n",
      "Epoch 1448: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.0511 - bpp: 0.5439 - mse: 1.2381e-04\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1133 - bpp: 0.5678 - mse: 1.3319e-04\n",
      "Epoch 1449: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.1133 - bpp: 0.5678 - mse: 1.3319e-04\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0598 - bpp: 0.5444 - mse: 1.2585e-04\n",
      "Epoch 1450: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0598 - bpp: 0.5444 - mse: 1.2585e-04\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0621 - bpp: 0.5332 - mse: 1.2913e-04\n",
      "Epoch 1451: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0621 - bpp: 0.5332 - mse: 1.2913e-04\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0299 - bpp: 0.5265 - mse: 1.2292e-04\n",
      "Epoch 1452: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.0299 - bpp: 0.5265 - mse: 1.2292e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0031 - bpp: 0.5258 - mse: 1.1654e-04\n",
      "Epoch 1453: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.0031 - bpp: 0.5258 - mse: 1.1654e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0745 - bpp: 0.5524 - mse: 1.2745e-04\n",
      "Epoch 1454: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.0745 - bpp: 0.5524 - mse: 1.2745e-04\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0519 - bpp: 0.5468 - mse: 1.2332e-04\n",
      "Epoch 1455: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0519 - bpp: 0.5468 - mse: 1.2332e-04\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0238 - bpp: 0.5361 - mse: 1.1906e-04\n",
      "Epoch 1456: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0238 - bpp: 0.5361 - mse: 1.1906e-04\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9971 - bpp: 0.5233 - mse: 1.1566e-04\n",
      "Epoch 1457: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 0.9971 - bpp: 0.5233 - mse: 1.1566e-04\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9688 - bpp: 0.5186 - mse: 1.0991e-04\n",
      "Epoch 1458: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9688 - bpp: 0.5186 - mse: 1.0991e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0029 - bpp: 0.5263 - mse: 1.1635e-04\n",
      "Epoch 1459: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.0029 - bpp: 0.5263 - mse: 1.1635e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9750 - bpp: 0.5181 - mse: 1.1156e-04\n",
      "Epoch 1460: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 0.9750 - bpp: 0.5181 - mse: 1.1156e-04\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0472 - bpp: 0.5400 - mse: 1.2382e-04\n",
      "Epoch 1461: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0472 - bpp: 0.5400 - mse: 1.2382e-04\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0443 - bpp: 0.5454 - mse: 1.2179e-04\n",
      "Epoch 1462: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.0443 - bpp: 0.5454 - mse: 1.2179e-04\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1158 - bpp: 0.5610 - mse: 1.3545e-04\n",
      "Epoch 1463: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1158 - bpp: 0.5610 - mse: 1.3545e-04\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0858 - bpp: 0.5537 - mse: 1.2991e-04\n",
      "Epoch 1464: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.0858 - bpp: 0.5537 - mse: 1.2991e-04\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0923 - bpp: 0.5469 - mse: 1.3315e-04\n",
      "Epoch 1465: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0923 - bpp: 0.5469 - mse: 1.3315e-04\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1303 - bpp: 0.5529 - mse: 1.4098e-04\n",
      "Epoch 1466: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.1303 - bpp: 0.5529 - mse: 1.4098e-04\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0455 - bpp: 0.5475 - mse: 1.2158e-04\n",
      "Epoch 1467: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0455 - bpp: 0.5475 - mse: 1.2158e-04\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2077 - bpp: 0.5964 - mse: 1.4926e-04\n",
      "Epoch 1468: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.2077 - bpp: 0.5964 - mse: 1.4926e-04\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0888 - bpp: 0.5537 - mse: 1.3066e-04\n",
      "Epoch 1469: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 1.0888 - bpp: 0.5537 - mse: 1.3066e-04\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9935 - bpp: 0.5252 - mse: 1.1432e-04\n",
      "Epoch 1470: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.9935 - bpp: 0.5252 - mse: 1.1432e-04\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0850 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 1471: loss did not improve from 0.93830\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0850 - bpp: 0.5549 - mse: 1.2940e-04\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8819 - bpp: 0.4831 - mse: 9.7368e-05\n",
      "Epoch 1472: loss improved from 0.93830 to 0.88193, saving model to checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.8819 - bpp: 0.4831 - mse: 9.7368e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0647 - bpp: 0.5496 - mse: 1.2574e-04\n",
      "Epoch 1473: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0647 - bpp: 0.5496 - mse: 1.2574e-04\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0259 - bpp: 0.5340 - mse: 1.2009e-04\n",
      "Epoch 1474: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.0259 - bpp: 0.5340 - mse: 1.2009e-04\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1516 - bpp: 0.5838 - mse: 1.3861e-04\n",
      "Epoch 1475: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.1516 - bpp: 0.5838 - mse: 1.3861e-04\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0723 - bpp: 0.5531 - mse: 1.2676e-04\n",
      "Epoch 1476: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.0723 - bpp: 0.5531 - mse: 1.2676e-04\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1928 - bpp: 0.5741 - mse: 1.5105e-04\n",
      "Epoch 1477: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.1928 - bpp: 0.5741 - mse: 1.5105e-04\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0879 - bpp: 0.5522 - mse: 1.3078e-04\n",
      "Epoch 1478: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.0879 - bpp: 0.5522 - mse: 1.3078e-04\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0678 - bpp: 0.5501 - mse: 1.2639e-04\n",
      "Epoch 1479: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0678 - bpp: 0.5501 - mse: 1.2639e-04\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0493 - bpp: 0.5343 - mse: 1.2572e-04\n",
      "Epoch 1480: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0493 - bpp: 0.5343 - mse: 1.2572e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0838 - bpp: 0.5606 - mse: 1.2774e-04\n",
      "Epoch 1481: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.0838 - bpp: 0.5606 - mse: 1.2774e-04\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0279 - bpp: 0.5381 - mse: 1.1958e-04\n",
      "Epoch 1482: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.0279 - bpp: 0.5381 - mse: 1.1958e-04\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0721 - bpp: 0.5520 - mse: 1.2698e-04\n",
      "Epoch 1483: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.0721 - bpp: 0.5520 - mse: 1.2698e-04\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9779 - bpp: 0.5289 - mse: 1.0962e-04\n",
      "Epoch 1484: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 0.9779 - bpp: 0.5289 - mse: 1.0962e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0624 - bpp: 0.5544 - mse: 1.2402e-04\n",
      "Epoch 1485: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.0624 - bpp: 0.5544 - mse: 1.2402e-04\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0521 - bpp: 0.5345 - mse: 1.2638e-04\n",
      "Epoch 1486: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 1.0521 - bpp: 0.5345 - mse: 1.2638e-04\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9658 - bpp: 0.5068 - mse: 1.1206e-04\n",
      "Epoch 1487: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.9658 - bpp: 0.5068 - mse: 1.1206e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0805 - bpp: 0.5432 - mse: 1.3117e-04\n",
      "Epoch 1488: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0805 - bpp: 0.5432 - mse: 1.3117e-04\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1300 - bpp: 0.5684 - mse: 1.3711e-04\n",
      "Epoch 1489: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.1300 - bpp: 0.5684 - mse: 1.3711e-04\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0524 - bpp: 0.5359 - mse: 1.2611e-04\n",
      "Epoch 1490: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.0524 - bpp: 0.5359 - mse: 1.2611e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0967 - bpp: 0.5593 - mse: 1.3118e-04\n",
      "Epoch 1491: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.0967 - bpp: 0.5593 - mse: 1.3118e-04\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0153 - bpp: 0.5286 - mse: 1.1883e-04\n",
      "Epoch 1492: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.0153 - bpp: 0.5286 - mse: 1.1883e-04\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0625 - bpp: 0.5425 - mse: 1.2694e-04\n",
      "Epoch 1493: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.0625 - bpp: 0.5425 - mse: 1.2694e-04\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1807 - bpp: 0.5861 - mse: 1.4516e-04\n",
      "Epoch 1494: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 1.1807 - bpp: 0.5861 - mse: 1.4516e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2027 - bpp: 0.6005 - mse: 1.4702e-04\n",
      "Epoch 1495: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.2027 - bpp: 0.6005 - mse: 1.4702e-04\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9574 - bpp: 0.5118 - mse: 1.0880e-04\n",
      "Epoch 1496: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.9574 - bpp: 0.5118 - mse: 1.0880e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1282 - bpp: 0.5674 - mse: 1.3692e-04\n",
      "Epoch 1497: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.1282 - bpp: 0.5674 - mse: 1.3692e-04\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0491 - bpp: 0.5355 - mse: 1.2538e-04\n",
      "Epoch 1498: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.0491 - bpp: 0.5355 - mse: 1.2538e-04\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0694 - bpp: 0.5559 - mse: 1.2535e-04\n",
      "Epoch 1499: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.0694 - bpp: 0.5559 - mse: 1.2535e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9917 - bpp: 0.5232 - mse: 1.1440e-04\n",
      "Epoch 1500: loss did not improve from 0.88193\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 0.9917 - bpp: 0.5232 - mse: 1.1440e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_1_layer_call_fn, optical_flow_loss_1_layer_call_and_return_conditional_losses, dwt_1_layer_call_fn, dwt_1_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_4096_epcs_1500_I_QP_27_240x240_CosineDecay_20220503-160827/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_12 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_12.compile()\n",
    "trainer_12.fit()\n",
    "trainer_12.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 85.1674 - bpp: 5.3091 - mse: 0.0097\n",
      "Epoch 1: loss improved from inf to 85.16737, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 72s 183ms/step - loss: 85.1674 - bpp: 5.3091 - mse: 0.0097\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 26.8944 - bpp: 5.1707 - mse: 0.0027\n",
      "Epoch 2: loss improved from 85.16737 to 26.89436, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 26.8944 - bpp: 5.1707 - mse: 0.0027\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.4823 - bpp: 5.0353 - mse: 0.0016\n",
      "Epoch 3: loss improved from 26.89436 to 18.48234, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 18.4823 - bpp: 5.0353 - mse: 0.0016\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.6875 - bpp: 4.9029 - mse: 0.0018\n",
      "Epoch 4: loss did not improve from 18.48234\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 19.6875 - bpp: 4.9029 - mse: 0.0018\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.1279 - bpp: 4.7726 - mse: 0.0014\n",
      "Epoch 5: loss improved from 18.48234 to 16.12789, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 16.1279 - bpp: 4.7726 - mse: 0.0014\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.1944 - bpp: 4.6446 - mse: 0.0012\n",
      "Epoch 6: loss improved from 16.12789 to 14.19441, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 14.1944 - bpp: 4.6446 - mse: 0.0012\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.2647 - bpp: 4.5190 - mse: 0.0013\n",
      "Epoch 7: loss did not improve from 14.19441\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 15.2647 - bpp: 4.5190 - mse: 0.0013\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.7385 - bpp: 4.3958 - mse: 0.0013\n",
      "Epoch 8: loss did not improve from 14.19441\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 14.7385 - bpp: 4.3958 - mse: 0.0013\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.4750 - bpp: 4.2753 - mse: 0.0014\n",
      "Epoch 9: loss did not improve from 14.19441\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 15.4750 - bpp: 4.2753 - mse: 0.0014\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1904 - bpp: 4.1555 - mse: 9.8082e-04\n",
      "Epoch 10: loss improved from 14.19441 to 12.19039, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 12.1904 - bpp: 4.1555 - mse: 9.8082e-04\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.0311 - bpp: 4.0397 - mse: 0.0013\n",
      "Epoch 11: loss did not improve from 12.19039\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 15.0311 - bpp: 4.0397 - mse: 0.0013\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2684 - bpp: 3.9265 - mse: 0.0010\n",
      "Epoch 12: loss did not improve from 12.19039\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 12.2684 - bpp: 3.9265 - mse: 0.0010\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6372 - bpp: 3.8123 - mse: 8.3312e-04\n",
      "Epoch 13: loss improved from 12.19039 to 10.63724, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 10.6372 - bpp: 3.8123 - mse: 8.3312e-04\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.6028 - bpp: 3.7043 - mse: 8.4209e-04\n",
      "Epoch 14: loss improved from 10.63724 to 10.60276, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 10.6028 - bpp: 3.7043 - mse: 8.4209e-04\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4313 - bpp: 3.5993 - mse: 9.5606e-04\n",
      "Epoch 15: loss did not improve from 10.60276\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 11.4313 - bpp: 3.5993 - mse: 9.5606e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2169 - bpp: 3.4949 - mse: 8.2055e-04\n",
      "Epoch 16: loss improved from 10.60276 to 10.21692, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 10.2169 - bpp: 3.4949 - mse: 8.2055e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8477 - bpp: 3.3916 - mse: 7.8809e-04\n",
      "Epoch 17: loss improved from 10.21692 to 9.84767, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 9.8477 - bpp: 3.3916 - mse: 7.8809e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3938 - bpp: 3.2943 - mse: 8.6664e-04\n",
      "Epoch 18: loss did not improve from 9.84767\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 10.3938 - bpp: 3.2943 - mse: 8.6664e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1991 - bpp: 3.1951 - mse: 7.3292e-04\n",
      "Epoch 19: loss improved from 9.84767 to 9.19915, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 9.1991 - bpp: 3.1951 - mse: 7.3292e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9130 - bpp: 3.1032 - mse: 8.3127e-04\n",
      "Epoch 20: loss did not improve from 9.19915\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 9.9130 - bpp: 3.1032 - mse: 8.3127e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0619 - bpp: 3.0052 - mse: 6.1728e-04\n",
      "Epoch 21: loss improved from 9.19915 to 8.06191, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 8.0619 - bpp: 3.0052 - mse: 6.1728e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.3990 - bpp: 2.9244 - mse: 0.0010  \n",
      "Epoch 22: loss did not improve from 8.06191\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 11.3990 - bpp: 2.9244 - mse: 0.0010\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3033 - bpp: 2.8468 - mse: 0.0012\n",
      "Epoch 23: loss did not improve from 8.06191\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 12.3033 - bpp: 2.8468 - mse: 0.0012\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6094 - bpp: 2.7403 - mse: 4.7231e-04\n",
      "Epoch 24: loss improved from 8.06191 to 6.60939, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 6.6094 - bpp: 2.7403 - mse: 4.7231e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2264 - bpp: 2.6672 - mse: 5.5654e-04\n",
      "Epoch 25: loss did not improve from 6.60939\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 7.2264 - bpp: 2.6672 - mse: 5.5654e-04\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0370 - bpp: 2.5831 - mse: 5.4369e-04\n",
      "Epoch 26: loss did not improve from 6.60939\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 7.0370 - bpp: 2.5831 - mse: 5.4369e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3726 - bpp: 2.5072 - mse: 4.7186e-04\n",
      "Epoch 27: loss improved from 6.60939 to 6.37262, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 6.3726 - bpp: 2.5072 - mse: 4.7186e-04\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2348 - bpp: 2.4414 - mse: 5.8513e-04\n",
      "Epoch 28: loss did not improve from 6.37262\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 7.2348 - bpp: 2.4414 - mse: 5.8513e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1280 - bpp: 2.3669 - mse: 4.5912e-04\n",
      "Epoch 29: loss improved from 6.37262 to 6.12796, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 6.1280 - bpp: 2.3669 - mse: 4.5912e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5599 - bpp: 2.3101 - mse: 5.1877e-04\n",
      "Epoch 30: loss did not improve from 6.12796\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 6.5599 - bpp: 2.3101 - mse: 5.1877e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9899 - bpp: 2.2430 - mse: 4.5738e-04\n",
      "Epoch 31: loss improved from 6.12796 to 5.98988, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 5.9899 - bpp: 2.2430 - mse: 4.5738e-04\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 141.3153 - bpp: 2.3097 - mse: 0.0170\n",
      "Epoch 32: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 141.3153 - bpp: 2.3097 - mse: 0.0170\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 49.2769 - bpp: 2.3677 - mse: 0.0057\n",
      "Epoch 33: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 49.2769 - bpp: 2.3677 - mse: 0.0057\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.2063 - bpp: 2.2122 - mse: 0.0021\n",
      "Epoch 34: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 19.2063 - bpp: 2.2122 - mse: 0.0021\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.6738 - bpp: 2.1296 - mse: 0.0017\n",
      "Epoch 35: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 15.6738 - bpp: 2.1296 - mse: 0.0017\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.0605 - bpp: 2.0634 - mse: 0.0013\n",
      "Epoch 36: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 13.0605 - bpp: 2.0634 - mse: 0.0013\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.1294 - bpp: 2.0075 - mse: 0.0011\n",
      "Epoch 37: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 11.1294 - bpp: 2.0075 - mse: 0.0011\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3753 - bpp: 1.9577 - mse: 0.0010\n",
      "Epoch 38: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 10.3753 - bpp: 1.9577 - mse: 0.0010\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.0660 - bpp: 1.9464 - mse: 0.0014\n",
      "Epoch 39: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 13.0660 - bpp: 1.9464 - mse: 0.0014\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8389 - bpp: 1.8727 - mse: 8.5037e-04\n",
      "Epoch 40: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 8.8389 - bpp: 1.8727 - mse: 8.5037e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0593 - bpp: 1.8352 - mse: 8.8185e-04\n",
      "Epoch 41: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 9.0593 - bpp: 1.8352 - mse: 8.8185e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4139 - bpp: 1.7890 - mse: 0.0011\n",
      "Epoch 42: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 10.4139 - bpp: 1.7890 - mse: 0.0011\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8999 - bpp: 1.7545 - mse: 7.5016e-04\n",
      "Epoch 43: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 7.8999 - bpp: 1.7545 - mse: 7.5016e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9830 - bpp: 1.7492 - mse: 8.8303e-04\n",
      "Epoch 44: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 8.9830 - bpp: 1.7492 - mse: 8.8303e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4181 - bpp: 1.7031 - mse: 6.9763e-04\n",
      "Epoch 45: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 7.4181 - bpp: 1.7031 - mse: 6.9763e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8157 - bpp: 1.6383 - mse: 6.3201e-04\n",
      "Epoch 46: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 6.8157 - bpp: 1.6383 - mse: 6.3201e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5863 - bpp: 1.5638 - mse: 6.1309e-04\n",
      "Epoch 47: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 6.5863 - bpp: 1.5638 - mse: 6.1309e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0790 - bpp: 1.5926 - mse: 6.6973e-04\n",
      "Epoch 48: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 7.0790 - bpp: 1.5926 - mse: 6.6973e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2816 - bpp: 1.5283 - mse: 5.8024e-04\n",
      "Epoch 49: loss did not improve from 5.98988\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 6.2816 - bpp: 1.5283 - mse: 5.8024e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8258 - bpp: 1.4860 - mse: 5.2975e-04\n",
      "Epoch 50: loss improved from 5.98988 to 5.82578, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 5.8258 - bpp: 1.4860 - mse: 5.2975e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9466 - bpp: 1.4741 - mse: 5.4596e-04\n",
      "Epoch 51: loss did not improve from 5.82578\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 5.9466 - bpp: 1.4741 - mse: 5.4596e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6225 - bpp: 1.4452 - mse: 5.0992e-04\n",
      "Epoch 52: loss improved from 5.82578 to 5.62245, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 5.6225 - bpp: 1.4452 - mse: 5.0992e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3137 - bpp: 1.4095 - mse: 4.7659e-04\n",
      "Epoch 53: loss improved from 5.62245 to 5.31374, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 5.3137 - bpp: 1.4095 - mse: 4.7659e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5027 - bpp: 1.4024 - mse: 5.0052e-04\n",
      "Epoch 54: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 5.5027 - bpp: 1.4024 - mse: 5.0052e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3460 - bpp: 1.3901 - mse: 4.8290e-04\n",
      "Epoch 55: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 5.3460 - bpp: 1.3901 - mse: 4.8290e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7867 - bpp: 1.4352 - mse: 5.3120e-04\n",
      "Epoch 56: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 5.7867 - bpp: 1.4352 - mse: 5.3120e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3418 - bpp: 1.3735 - mse: 4.8441e-04\n",
      "Epoch 57: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 5.3418 - bpp: 1.3735 - mse: 4.8441e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4842 - bpp: 1.3701 - mse: 5.0221e-04\n",
      "Epoch 58: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.4842 - bpp: 1.3701 - mse: 5.0221e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4727 - bpp: 1.3600 - mse: 5.0204e-04\n",
      "Epoch 59: loss did not improve from 5.31374\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.4727 - bpp: 1.3600 - mse: 5.0204e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4524 - bpp: 1.2880 - mse: 3.8629e-04\n",
      "Epoch 60: loss improved from 5.31374 to 4.45244, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.4524 - bpp: 1.2880 - mse: 3.8629e-04\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8403 - bpp: 1.3208 - mse: 4.2962e-04\n",
      "Epoch 61: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.8403 - bpp: 1.3208 - mse: 4.2962e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9502 - bpp: 1.3146 - mse: 4.4380e-04\n",
      "Epoch 62: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 4.9502 - bpp: 1.3146 - mse: 4.4380e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7700 - bpp: 1.3051 - mse: 4.2296e-04\n",
      "Epoch 63: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.7700 - bpp: 1.3051 - mse: 4.2296e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8391 - bpp: 1.3114 - mse: 4.3063e-04\n",
      "Epoch 64: loss did not improve from 4.45244\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 4.8391 - bpp: 1.3114 - mse: 4.3063e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3976 - bpp: 1.2567 - mse: 3.8341e-04\n",
      "Epoch 65: loss improved from 4.45244 to 4.39755, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.3976 - bpp: 1.2567 - mse: 3.8341e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9703 - bpp: 1.3104 - mse: 4.4677e-04\n",
      "Epoch 66: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.9703 - bpp: 1.3104 - mse: 4.4677e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9047 - bpp: 1.2493 - mse: 4.4621e-04\n",
      "Epoch 67: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.9047 - bpp: 1.2493 - mse: 4.4621e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6667 - bpp: 1.2796 - mse: 4.1347e-04\n",
      "Epoch 68: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.6667 - bpp: 1.2796 - mse: 4.1347e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6131 - bpp: 1.2596 - mse: 4.0936e-04\n",
      "Epoch 69: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.6131 - bpp: 1.2596 - mse: 4.0936e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5435 - bpp: 1.2366 - mse: 4.0367e-04\n",
      "Epoch 70: loss did not improve from 4.39755\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 4.5435 - bpp: 1.2366 - mse: 4.0367e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1378 - bpp: 1.2202 - mse: 3.5615e-04\n",
      "Epoch 71: loss improved from 4.39755 to 4.13780, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4.1378 - bpp: 1.2202 - mse: 3.5615e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1006 - bpp: 1.2201 - mse: 3.5162e-04\n",
      "Epoch 72: loss improved from 4.13780 to 4.10061, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 4.1006 - bpp: 1.2201 - mse: 3.5162e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2948 - bpp: 1.2363 - mse: 3.7336e-04\n",
      "Epoch 73: loss did not improve from 4.10061\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.2948 - bpp: 1.2363 - mse: 3.7336e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9568 - bpp: 1.2009 - mse: 3.3641e-04\n",
      "Epoch 74: loss improved from 4.10061 to 3.95679, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 242ms/step - loss: 3.9568 - bpp: 1.2009 - mse: 3.3641e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1626 - bpp: 1.2484 - mse: 3.5574e-04\n",
      "Epoch 75: loss did not improve from 3.95679\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.1626 - bpp: 1.2484 - mse: 3.5574e-04\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1499 - bpp: 1.2015 - mse: 3.5991e-04\n",
      "Epoch 76: loss did not improve from 3.95679\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.1499 - bpp: 1.2015 - mse: 3.5991e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6699 - bpp: 1.1857 - mse: 3.0325e-04\n",
      "Epoch 77: loss improved from 3.95679 to 3.66990, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.6699 - bpp: 1.1857 - mse: 3.0325e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9643 - bpp: 1.2138 - mse: 3.3575e-04\n",
      "Epoch 78: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.9643 - bpp: 1.2138 - mse: 3.3575e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8808 - bpp: 1.1992 - mse: 3.2734e-04\n",
      "Epoch 79: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.8808 - bpp: 1.1992 - mse: 3.2734e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9813 - bpp: 1.2004 - mse: 3.3946e-04\n",
      "Epoch 80: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 3.9813 - bpp: 1.2004 - mse: 3.3946e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9985 - bpp: 1.2050 - mse: 3.4100e-04\n",
      "Epoch 81: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.9985 - bpp: 1.2050 - mse: 3.4100e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0266 - bpp: 1.2023 - mse: 3.4476e-04\n",
      "Epoch 82: loss did not improve from 3.66990\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 4.0266 - bpp: 1.2023 - mse: 3.4476e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5693 - bpp: 1.1768 - mse: 2.9205e-04\n",
      "Epoch 83: loss improved from 3.66990 to 3.56931, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5693 - bpp: 1.1768 - mse: 2.9205e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0489 - bpp: 1.2030 - mse: 3.4739e-04\n",
      "Epoch 84: loss did not improve from 3.56931\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.0489 - bpp: 1.2030 - mse: 3.4739e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4248 - bpp: 1.1517 - mse: 2.7748e-04\n",
      "Epoch 85: loss improved from 3.56931 to 3.42485, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4248 - bpp: 1.1517 - mse: 2.7748e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4257 - bpp: 1.1687 - mse: 2.7552e-04\n",
      "Epoch 86: loss did not improve from 3.42485\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.4257 - bpp: 1.1687 - mse: 2.7552e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7657 - bpp: 1.1777 - mse: 3.1592e-04\n",
      "Epoch 87: loss did not improve from 3.42485\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7657 - bpp: 1.1777 - mse: 3.1592e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2940 - bpp: 1.1548 - mse: 2.6112e-04\n",
      "Epoch 88: loss improved from 3.42485 to 3.29395, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.2940 - bpp: 1.1548 - mse: 2.6112e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4713 - bpp: 1.1541 - mse: 2.8287e-04\n",
      "Epoch 89: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.4713 - bpp: 1.1541 - mse: 2.8287e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9899 - bpp: 1.3895 - mse: 9.2777e-04\n",
      "Epoch 90: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 8.9899 - bpp: 1.3895 - mse: 9.2777e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1444 - bpp: 1.2205 - mse: 3.5693e-04\n",
      "Epoch 91: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.1444 - bpp: 1.2205 - mse: 3.5693e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8057 - bpp: 1.1939 - mse: 3.1882e-04\n",
      "Epoch 92: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.8057 - bpp: 1.1939 - mse: 3.1882e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4397 - bpp: 1.1527 - mse: 2.7917e-04\n",
      "Epoch 93: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4397 - bpp: 1.1527 - mse: 2.7917e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3314 - bpp: 1.1116 - mse: 2.7097e-04\n",
      "Epoch 94: loss did not improve from 3.29395\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3314 - bpp: 1.1116 - mse: 2.7097e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2551 - bpp: 1.1257 - mse: 2.5994e-04\n",
      "Epoch 95: loss improved from 3.29395 to 3.25510, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2551 - bpp: 1.1257 - mse: 2.5994e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2429 - bpp: 1.1605 - mse: 2.5419e-04\n",
      "Epoch 96: loss improved from 3.25510 to 3.24288, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2429 - bpp: 1.1605 - mse: 2.5419e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4665 - bpp: 1.1661 - mse: 2.8081e-04\n",
      "Epoch 97: loss did not improve from 3.24288\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.4665 - bpp: 1.1661 - mse: 2.8081e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1847 - bpp: 1.1212 - mse: 2.5189e-04\n",
      "Epoch 98: loss improved from 3.24288 to 3.18472, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.1847 - bpp: 1.1212 - mse: 2.5189e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3540 - bpp: 1.1488 - mse: 2.6919e-04\n",
      "Epoch 99: loss did not improve from 3.18472\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3540 - bpp: 1.1488 - mse: 2.6919e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1016 - bpp: 1.1248 - mse: 2.4131e-04\n",
      "Epoch 100: loss improved from 3.18472 to 3.10164, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1016 - bpp: 1.1248 - mse: 2.4131e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3583 - bpp: 1.1389 - mse: 2.7092e-04\n",
      "Epoch 101: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3583 - bpp: 1.1389 - mse: 2.7092e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2388 - bpp: 1.1570 - mse: 2.5412e-04\n",
      "Epoch 102: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2388 - bpp: 1.1570 - mse: 2.5412e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.8232 - bpp: 1.4129 - mse: 0.0014\n",
      "Epoch 103: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 12.8232 - bpp: 1.4129 - mse: 0.0014\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0910 - bpp: 1.2558 - mse: 3.4610e-04\n",
      "Epoch 104: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 4.0910 - bpp: 1.2558 - mse: 3.4610e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9235 - bpp: 1.2335 - mse: 3.2837e-04\n",
      "Epoch 105: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.9235 - bpp: 1.2335 - mse: 3.2837e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3616 - bpp: 1.1778 - mse: 2.6658e-04\n",
      "Epoch 106: loss did not improve from 3.10164\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3616 - bpp: 1.1778 - mse: 2.6658e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0366 - bpp: 1.1045 - mse: 2.3585e-04\n",
      "Epoch 107: loss improved from 3.10164 to 3.03663, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0366 - bpp: 1.1045 - mse: 2.3585e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0509 - bpp: 1.1143 - mse: 2.3640e-04\n",
      "Epoch 108: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.0509 - bpp: 1.1143 - mse: 2.3640e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1314 - bpp: 1.1143 - mse: 2.4622e-04\n",
      "Epoch 109: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1314 - bpp: 1.1143 - mse: 2.4622e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1605 - bpp: 1.1263 - mse: 2.4832e-04\n",
      "Epoch 110: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1605 - bpp: 1.1263 - mse: 2.4832e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0724 - bpp: 1.1259 - mse: 2.3761e-04\n",
      "Epoch 111: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.0724 - bpp: 1.1259 - mse: 2.3761e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2807 - bpp: 1.1547 - mse: 2.5953e-04\n",
      "Epoch 112: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2807 - bpp: 1.1547 - mse: 2.5953e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1538 - bpp: 1.1258 - mse: 2.4756e-04\n",
      "Epoch 113: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 233ms/step - loss: 3.1538 - bpp: 1.1258 - mse: 2.4756e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2315 - bpp: 1.1359 - mse: 2.5581e-04\n",
      "Epoch 114: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2315 - bpp: 1.1359 - mse: 2.5581e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1119 - bpp: 1.0916 - mse: 2.4662e-04\n",
      "Epoch 115: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.1119 - bpp: 1.0916 - mse: 2.4662e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0637 - bpp: 1.1332 - mse: 2.3566e-04\n",
      "Epoch 116: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.0637 - bpp: 1.1332 - mse: 2.3566e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3637 - bpp: 1.1457 - mse: 2.7075e-04\n",
      "Epoch 117: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3637 - bpp: 1.1457 - mse: 2.7075e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1365 - bpp: 1.1100 - mse: 2.4738e-04\n",
      "Epoch 118: loss did not improve from 3.03663\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1365 - bpp: 1.1100 - mse: 2.4738e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8306 - bpp: 1.0696 - mse: 2.1497e-04\n",
      "Epoch 119: loss improved from 3.03663 to 2.83058, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.8306 - bpp: 1.0696 - mse: 2.1497e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0569 - bpp: 1.1220 - mse: 2.3619e-04\n",
      "Epoch 120: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0569 - bpp: 1.1220 - mse: 2.3619e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9025 - bpp: 1.0800 - mse: 2.2247e-04\n",
      "Epoch 121: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 2.9025 - bpp: 1.0800 - mse: 2.2247e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1629 - bpp: 1.1150 - mse: 2.4998e-04\n",
      "Epoch 122: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1629 - bpp: 1.1150 - mse: 2.4998e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0464 - bpp: 1.1200 - mse: 2.3515e-04\n",
      "Epoch 123: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0464 - bpp: 1.1200 - mse: 2.3515e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9641 - bpp: 1.0973 - mse: 2.2789e-04\n",
      "Epoch 124: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9641 - bpp: 1.0973 - mse: 2.2789e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1519 - bpp: 1.1279 - mse: 2.4706e-04\n",
      "Epoch 125: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1519 - bpp: 1.1279 - mse: 2.4706e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0040 - bpp: 1.2930 - mse: 9.4128e-04\n",
      "Epoch 126: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 9.0040 - bpp: 1.2930 - mse: 9.4128e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7551 - bpp: 1.1740 - mse: 3.1507e-04\n",
      "Epoch 127: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.7551 - bpp: 1.1740 - mse: 3.1507e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1946 - bpp: 1.1457 - mse: 2.5012e-04\n",
      "Epoch 128: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1946 - bpp: 1.1457 - mse: 2.5012e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2436 - bpp: 1.1535 - mse: 2.5513e-04\n",
      "Epoch 129: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.2436 - bpp: 1.1535 - mse: 2.5513e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4344 - bpp: 1.1578 - mse: 2.7791e-04\n",
      "Epoch 130: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.4344 - bpp: 1.1578 - mse: 2.7791e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9728 - bpp: 1.1180 - mse: 2.2641e-04\n",
      "Epoch 131: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9728 - bpp: 1.1180 - mse: 2.2641e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2360 - bpp: 1.1125 - mse: 2.5921e-04\n",
      "Epoch 132: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2360 - bpp: 1.1125 - mse: 2.5921e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9380 - bpp: 1.1092 - mse: 2.2325e-04\n",
      "Epoch 133: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9380 - bpp: 1.1092 - mse: 2.2325e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9654 - bpp: 1.0877 - mse: 2.2921e-04\n",
      "Epoch 134: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9654 - bpp: 1.0877 - mse: 2.2921e-04\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9479 - bpp: 1.0832 - mse: 2.2763e-04\n",
      "Epoch 135: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9479 - bpp: 1.0832 - mse: 2.2763e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0716 - bpp: 1.1374 - mse: 2.3612e-04\n",
      "Epoch 136: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0716 - bpp: 1.1374 - mse: 2.3612e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9645 - bpp: 1.0938 - mse: 2.2836e-04\n",
      "Epoch 137: loss did not improve from 2.83058\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.9645 - bpp: 1.0938 - mse: 2.2836e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6036 - bpp: 1.0508 - mse: 1.8955e-04\n",
      "Epoch 138: loss improved from 2.83058 to 2.60360, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.6036 - bpp: 1.0508 - mse: 1.8955e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5070 - bpp: 1.0409 - mse: 1.7896e-04\n",
      "Epoch 139: loss improved from 2.60360 to 2.50696, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.5070 - bpp: 1.0409 - mse: 1.7896e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8283 - bpp: 1.0880 - mse: 2.1243e-04\n",
      "Epoch 140: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8283 - bpp: 1.0880 - mse: 2.1243e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1821 - bpp: 1.1020 - mse: 2.5393e-04\n",
      "Epoch 141: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1821 - bpp: 1.1020 - mse: 2.5393e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8671 - bpp: 1.0795 - mse: 2.1822e-04\n",
      "Epoch 142: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.8671 - bpp: 1.0795 - mse: 2.1822e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6372 - bpp: 1.0311 - mse: 1.9606e-04\n",
      "Epoch 143: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.6372 - bpp: 1.0311 - mse: 1.9606e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1040 - bpp: 1.1392 - mse: 4.8398e-04\n",
      "Epoch 144: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 5.1040 - bpp: 1.1392 - mse: 4.8398e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8648 - bpp: 1.3523 - mse: 0.0012\n",
      "Epoch 145: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 10.8648 - bpp: 1.3523 - mse: 0.0012\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2063 - bpp: 1.1128 - mse: 2.5556e-04\n",
      "Epoch 146: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2063 - bpp: 1.1128 - mse: 2.5556e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9226 - bpp: 1.0941 - mse: 2.2321e-04\n",
      "Epoch 147: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.9226 - bpp: 1.0941 - mse: 2.2321e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1129 - bpp: 1.1365 - mse: 2.4127e-04\n",
      "Epoch 148: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1129 - bpp: 1.1365 - mse: 2.4127e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8764 - bpp: 1.1137 - mse: 2.1517e-04\n",
      "Epoch 149: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.8764 - bpp: 1.1137 - mse: 2.1517e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5430 - bpp: 1.0469 - mse: 1.8263e-04\n",
      "Epoch 150: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.5430 - bpp: 1.0469 - mse: 1.8263e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2949 - bpp: 1.1579 - mse: 2.6086e-04\n",
      "Epoch 151: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.2949 - bpp: 1.1579 - mse: 2.6086e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7348 - bpp: 1.0713 - mse: 2.0306e-04\n",
      "Epoch 152: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7348 - bpp: 1.0713 - mse: 2.0306e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9855 - bpp: 1.0929 - mse: 2.3104e-04\n",
      "Epoch 153: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.9855 - bpp: 1.0929 - mse: 2.3104e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5444 - bpp: 1.0579 - mse: 1.8146e-04\n",
      "Epoch 154: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.5444 - bpp: 1.0579 - mse: 1.8146e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6564 - bpp: 1.0566 - mse: 1.9528e-04\n",
      "Epoch 155: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.6564 - bpp: 1.0566 - mse: 1.9528e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7921 - bpp: 1.0688 - mse: 2.1037e-04\n",
      "Epoch 156: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.7921 - bpp: 1.0688 - mse: 2.1037e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7771 - bpp: 1.0976 - mse: 2.0502e-04\n",
      "Epoch 157: loss did not improve from 2.50696\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.7771 - bpp: 1.0976 - mse: 2.0502e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3733 - bpp: 1.0245 - mse: 1.6465e-04\n",
      "Epoch 158: loss improved from 2.50696 to 2.37328, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.3733 - bpp: 1.0245 - mse: 1.6465e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7222 - bpp: 1.0685 - mse: 2.0188e-04\n",
      "Epoch 159: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7222 - bpp: 1.0685 - mse: 2.0188e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7108 - bpp: 1.0727 - mse: 1.9996e-04\n",
      "Epoch 160: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7108 - bpp: 1.0727 - mse: 1.9996e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8494 - bpp: 1.0714 - mse: 2.1704e-04\n",
      "Epoch 161: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.8494 - bpp: 1.0714 - mse: 2.1704e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6968 - bpp: 1.0278 - mse: 2.0374e-04\n",
      "Epoch 162: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.6968 - bpp: 1.0278 - mse: 2.0374e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5536 - bpp: 1.0369 - mse: 1.8515e-04\n",
      "Epoch 163: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.5536 - bpp: 1.0369 - mse: 1.8515e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5715 - bpp: 1.0471 - mse: 1.8608e-04\n",
      "Epoch 164: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.5715 - bpp: 1.0471 - mse: 1.8608e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5346 - bpp: 1.0529 - mse: 1.8087e-04\n",
      "Epoch 165: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.5346 - bpp: 1.0529 - mse: 1.8087e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4985 - bpp: 1.0286 - mse: 1.7943e-04\n",
      "Epoch 166: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.4985 - bpp: 1.0286 - mse: 1.7943e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9327 - bpp: 1.0797 - mse: 2.2620e-04\n",
      "Epoch 167: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.9327 - bpp: 1.0797 - mse: 2.2620e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5135 - bpp: 1.0215 - mse: 1.8212e-04\n",
      "Epoch 168: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.5135 - bpp: 1.0215 - mse: 1.8212e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0687 - bpp: 1.1644 - mse: 4.7660e-04\n",
      "Epoch 169: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 5.0687 - bpp: 1.1644 - mse: 4.7660e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9457 - bpp: 1.0833 - mse: 2.2735e-04\n",
      "Epoch 170: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9457 - bpp: 1.0833 - mse: 2.2735e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6619 - bpp: 1.0295 - mse: 1.9926e-04\n",
      "Epoch 171: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.6619 - bpp: 1.0295 - mse: 1.9926e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7935 - bpp: 1.0552 - mse: 2.1220e-04\n",
      "Epoch 172: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.7935 - bpp: 1.0552 - mse: 2.1220e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6965 - bpp: 1.0215 - mse: 2.0446e-04\n",
      "Epoch 173: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.6965 - bpp: 1.0215 - mse: 2.0446e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4958 - bpp: 1.0081 - mse: 1.8161e-04\n",
      "Epoch 174: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.4958 - bpp: 1.0081 - mse: 1.8161e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5883 - bpp: 1.0285 - mse: 1.9040e-04\n",
      "Epoch 175: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.5883 - bpp: 1.0285 - mse: 1.9040e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5803 - bpp: 1.0005 - mse: 1.9284e-04\n",
      "Epoch 176: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.5803 - bpp: 1.0005 - mse: 1.9284e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4880 - bpp: 1.0330 - mse: 1.7761e-04\n",
      "Epoch 177: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.4880 - bpp: 1.0330 - mse: 1.7761e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4309 - bpp: 1.0102 - mse: 1.7342e-04\n",
      "Epoch 178: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.4309 - bpp: 1.0102 - mse: 1.7342e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4985 - bpp: 0.9952 - mse: 1.8351e-04\n",
      "Epoch 179: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.4985 - bpp: 0.9952 - mse: 1.8351e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5311 - bpp: 0.9907 - mse: 1.8804e-04\n",
      "Epoch 180: loss did not improve from 2.37328\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.5311 - bpp: 0.9907 - mse: 1.8804e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2493 - bpp: 0.9852 - mse: 1.5431e-04\n",
      "Epoch 181: loss improved from 2.37328 to 2.24927, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2493 - bpp: 0.9852 - mse: 1.5431e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5610 - bpp: 1.0200 - mse: 1.8811e-04\n",
      "Epoch 182: loss did not improve from 2.24927\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.5610 - bpp: 1.0200 - mse: 1.8811e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4470 - bpp: 0.9784 - mse: 1.7927e-04\n",
      "Epoch 183: loss did not improve from 2.24927\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.4470 - bpp: 0.9784 - mse: 1.7927e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2235 - bpp: 0.9590 - mse: 1.5436e-04\n",
      "Epoch 184: loss improved from 2.24927 to 2.22350, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.2235 - bpp: 0.9590 - mse: 1.5436e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4175 - bpp: 0.9700 - mse: 1.7670e-04\n",
      "Epoch 185: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 2.4175 - bpp: 0.9700 - mse: 1.7670e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.3372 - bpp: 1.2615 - mse: 0.0018\n",
      "Epoch 186: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 16.3372 - bpp: 1.2615 - mse: 0.0018\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6925 - bpp: 1.2071 - mse: 4.2547e-04\n",
      "Epoch 187: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.6925 - bpp: 1.2071 - mse: 4.2547e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2964 - bpp: 1.0952 - mse: 2.6870e-04\n",
      "Epoch 188: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2964 - bpp: 1.0952 - mse: 2.6870e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9347 - bpp: 1.0724 - mse: 2.2733e-04\n",
      "Epoch 189: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9347 - bpp: 1.0724 - mse: 2.2733e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9774 - bpp: 1.0837 - mse: 2.3116e-04\n",
      "Epoch 190: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.9774 - bpp: 1.0837 - mse: 2.3116e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7241 - bpp: 1.0560 - mse: 2.0363e-04\n",
      "Epoch 191: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.7241 - bpp: 1.0560 - mse: 2.0363e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9318 - bpp: 1.0883 - mse: 2.2505e-04\n",
      "Epoch 192: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.9318 - bpp: 1.0883 - mse: 2.2505e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3393 - bpp: 1.0088 - mse: 1.6242e-04\n",
      "Epoch 193: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.3393 - bpp: 1.0088 - mse: 1.6242e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5808 - bpp: 1.0476 - mse: 1.8716e-04\n",
      "Epoch 194: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.5808 - bpp: 1.0476 - mse: 1.8716e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9886 - bpp: 1.0806 - mse: 2.3291e-04\n",
      "Epoch 195: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9886 - bpp: 1.0806 - mse: 2.3291e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4693 - bpp: 1.0064 - mse: 1.7858e-04\n",
      "Epoch 196: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.4693 - bpp: 1.0064 - mse: 1.7858e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4938 - bpp: 1.0105 - mse: 1.8107e-04\n",
      "Epoch 197: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.4938 - bpp: 1.0105 - mse: 1.8107e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4982 - bpp: 1.0230 - mse: 1.8007e-04\n",
      "Epoch 198: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.4982 - bpp: 1.0230 - mse: 1.8007e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5712 - bpp: 1.0247 - mse: 1.8878e-04\n",
      "Epoch 199: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.5712 - bpp: 1.0247 - mse: 1.8878e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4700 - bpp: 1.0265 - mse: 1.7620e-04\n",
      "Epoch 200: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.4700 - bpp: 1.0265 - mse: 1.7620e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6182 - bpp: 1.0165 - mse: 1.9552e-04\n",
      "Epoch 201: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.6182 - bpp: 1.0165 - mse: 1.9552e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6143 - bpp: 1.0347 - mse: 1.9282e-04\n",
      "Epoch 202: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.6143 - bpp: 1.0347 - mse: 1.9282e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3972 - bpp: 0.9877 - mse: 1.7206e-04\n",
      "Epoch 203: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.3972 - bpp: 0.9877 - mse: 1.7206e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4176 - bpp: 1.0015 - mse: 1.7286e-04\n",
      "Epoch 204: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.4176 - bpp: 1.0015 - mse: 1.7286e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4182 - bpp: 0.9823 - mse: 1.7527e-04\n",
      "Epoch 205: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4182 - bpp: 0.9823 - mse: 1.7527e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4194 - bpp: 1.0019 - mse: 1.7303e-04\n",
      "Epoch 206: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.4194 - bpp: 1.0019 - mse: 1.7303e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2601 - bpp: 1.0009 - mse: 1.5371e-04\n",
      "Epoch 207: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.2601 - bpp: 1.0009 - mse: 1.5371e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2534 - bpp: 0.9682 - mse: 1.5688e-04\n",
      "Epoch 208: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.2534 - bpp: 0.9682 - mse: 1.5688e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8160 - bpp: 1.0176 - mse: 2.1953e-04\n",
      "Epoch 209: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.8160 - bpp: 1.0176 - mse: 2.1953e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2709 - bpp: 0.9569 - mse: 1.6040e-04\n",
      "Epoch 210: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.2709 - bpp: 0.9569 - mse: 1.6040e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4853 - bpp: 1.0018 - mse: 1.8109e-04\n",
      "Epoch 211: loss did not improve from 2.22350\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.4853 - bpp: 1.0018 - mse: 1.8109e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1670 - bpp: 0.9750 - mse: 1.4550e-04\n",
      "Epoch 212: loss improved from 2.22350 to 2.16699, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.1670 - bpp: 0.9750 - mse: 1.4550e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1683 - bpp: 0.9538 - mse: 1.4825e-04\n",
      "Epoch 213: loss did not improve from 2.16699\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.1683 - bpp: 0.9538 - mse: 1.4825e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5860 - bpp: 1.0122 - mse: 1.9211e-04\n",
      "Epoch 214: loss did not improve from 2.16699\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.5860 - bpp: 1.0122 - mse: 1.9211e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1515 - bpp: 0.9547 - mse: 1.4609e-04\n",
      "Epoch 215: loss improved from 2.16699 to 2.15146, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.1515 - bpp: 0.9547 - mse: 1.4609e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3605 - bpp: 0.9636 - mse: 1.7051e-04\n",
      "Epoch 216: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.3605 - bpp: 0.9636 - mse: 1.7051e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3337 - bpp: 0.9689 - mse: 1.6660e-04\n",
      "Epoch 217: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 2.3337 - bpp: 0.9689 - mse: 1.6660e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.0340 - bpp: 1.1783 - mse: 0.0012\n",
      "Epoch 218: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 11.0340 - bpp: 1.1783 - mse: 0.0012\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1823 - bpp: 1.1191 - mse: 3.7392e-04\n",
      "Epoch 219: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.1823 - bpp: 1.1191 - mse: 3.7392e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9653 - bpp: 1.0676 - mse: 2.3165e-04\n",
      "Epoch 220: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.9653 - bpp: 1.0676 - mse: 2.3165e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4091 - bpp: 1.0055 - mse: 1.7133e-04\n",
      "Epoch 221: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.4091 - bpp: 1.0055 - mse: 1.7133e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8078 - bpp: 1.0356 - mse: 2.1633e-04\n",
      "Epoch 222: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.8078 - bpp: 1.0356 - mse: 2.1633e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5411 - bpp: 1.0253 - mse: 1.8503e-04\n",
      "Epoch 223: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.5411 - bpp: 1.0253 - mse: 1.8503e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3528 - bpp: 0.9928 - mse: 1.6601e-04\n",
      "Epoch 224: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.3528 - bpp: 0.9928 - mse: 1.6601e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6545 - bpp: 1.0172 - mse: 1.9987e-04\n",
      "Epoch 225: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.6545 - bpp: 1.0172 - mse: 1.9987e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5495 - bpp: 1.0192 - mse: 1.8681e-04\n",
      "Epoch 226: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.5495 - bpp: 1.0192 - mse: 1.8681e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3041 - bpp: 0.9702 - mse: 1.6283e-04\n",
      "Epoch 227: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.3041 - bpp: 0.9702 - mse: 1.6283e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1726 - bpp: 0.9555 - mse: 1.4857e-04\n",
      "Epoch 228: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.1726 - bpp: 0.9555 - mse: 1.4857e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4155 - bpp: 0.9897 - mse: 1.7405e-04\n",
      "Epoch 229: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.4155 - bpp: 0.9897 - mse: 1.7405e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4559 - bpp: 0.9849 - mse: 1.7956e-04\n",
      "Epoch 230: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4559 - bpp: 0.9849 - mse: 1.7956e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2939 - bpp: 0.9648 - mse: 1.6224e-04\n",
      "Epoch 231: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.2939 - bpp: 0.9648 - mse: 1.6224e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2614 - bpp: 0.9578 - mse: 1.5914e-04\n",
      "Epoch 232: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.2614 - bpp: 0.9578 - mse: 1.5914e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5034 - bpp: 1.0012 - mse: 1.8337e-04\n",
      "Epoch 233: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.5034 - bpp: 1.0012 - mse: 1.8337e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4732 - bpp: 0.9926 - mse: 1.8074e-04\n",
      "Epoch 234: loss did not improve from 2.15146\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.4732 - bpp: 0.9926 - mse: 1.8074e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1460 - bpp: 0.9560 - mse: 1.4526e-04\n",
      "Epoch 235: loss improved from 2.15146 to 2.14602, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.1460 - bpp: 0.9560 - mse: 1.4526e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3257 - bpp: 0.9883 - mse: 1.6325e-04\n",
      "Epoch 236: loss did not improve from 2.14602\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.3257 - bpp: 0.9883 - mse: 1.6325e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3909 - bpp: 0.9718 - mse: 1.7323e-04\n",
      "Epoch 237: loss did not improve from 2.14602\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.3909 - bpp: 0.9718 - mse: 1.7323e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1110 - bpp: 0.9262 - mse: 1.4463e-04\n",
      "Epoch 238: loss improved from 2.14602 to 2.11102, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.1110 - bpp: 0.9262 - mse: 1.4463e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5405 - bpp: 0.9887 - mse: 1.8943e-04\n",
      "Epoch 239: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.5405 - bpp: 0.9887 - mse: 1.8943e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2313 - bpp: 0.9634 - mse: 1.5478e-04\n",
      "Epoch 240: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.2313 - bpp: 0.9634 - mse: 1.5478e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1215 - bpp: 0.9340 - mse: 1.4496e-04\n",
      "Epoch 241: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.1215 - bpp: 0.9340 - mse: 1.4496e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6718 - bpp: 0.9915 - mse: 2.0511e-04\n",
      "Epoch 242: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.6718 - bpp: 0.9915 - mse: 2.0511e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3841 - bpp: 0.9789 - mse: 1.7153e-04\n",
      "Epoch 243: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.3841 - bpp: 0.9789 - mse: 1.7153e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4195 - bpp: 0.9880 - mse: 1.7474e-04\n",
      "Epoch 244: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.4195 - bpp: 0.9880 - mse: 1.7474e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5552 - bpp: 1.0014 - mse: 1.8967e-04\n",
      "Epoch 245: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.5552 - bpp: 1.0014 - mse: 1.8967e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3200 - bpp: 0.9708 - mse: 1.6470e-04\n",
      "Epoch 246: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.3200 - bpp: 0.9708 - mse: 1.6470e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4898 - bpp: 0.9826 - mse: 1.8398e-04\n",
      "Epoch 247: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.4898 - bpp: 0.9826 - mse: 1.8398e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4112 - bpp: 0.9558 - mse: 1.7766e-04\n",
      "Epoch 248: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.4112 - bpp: 0.9558 - mse: 1.7766e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3066 - bpp: 0.9530 - mse: 1.6523e-04\n",
      "Epoch 249: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.3066 - bpp: 0.9530 - mse: 1.6523e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0686 - bpp: 1.1099 - mse: 6.0531e-04\n",
      "Epoch 250: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 6.0686 - bpp: 1.1099 - mse: 6.0531e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6529 - bpp: 1.0279 - mse: 1.9836e-04\n",
      "Epoch 251: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.6529 - bpp: 1.0279 - mse: 1.9836e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3644 - bpp: 0.9701 - mse: 1.7020e-04\n",
      "Epoch 252: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.3644 - bpp: 0.9701 - mse: 1.7020e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4828 - bpp: 0.9915 - mse: 1.8205e-04\n",
      "Epoch 253: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.4828 - bpp: 0.9915 - mse: 1.8205e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1166 - bpp: 0.9287 - mse: 1.4501e-04\n",
      "Epoch 254: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.1166 - bpp: 0.9287 - mse: 1.4501e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3941 - bpp: 0.9872 - mse: 1.7174e-04\n",
      "Epoch 255: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.3941 - bpp: 0.9872 - mse: 1.7174e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2175 - bpp: 0.9669 - mse: 1.5266e-04\n",
      "Epoch 256: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.2175 - bpp: 0.9669 - mse: 1.5266e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4059 - bpp: 0.9645 - mse: 1.7596e-04\n",
      "Epoch 257: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.4059 - bpp: 0.9645 - mse: 1.7596e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2869 - bpp: 0.9345 - mse: 1.6509e-04\n",
      "Epoch 258: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.2869 - bpp: 0.9345 - mse: 1.6509e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3839 - bpp: 0.9810 - mse: 1.7125e-04\n",
      "Epoch 259: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.3839 - bpp: 0.9810 - mse: 1.7125e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3388 - bpp: 0.9493 - mse: 1.6961e-04\n",
      "Epoch 260: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.3388 - bpp: 0.9493 - mse: 1.6961e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9001 - bpp: 1.0464 - mse: 2.2628e-04\n",
      "Epoch 261: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.9001 - bpp: 1.0464 - mse: 2.2628e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2607 - bpp: 0.9558 - mse: 1.5929e-04\n",
      "Epoch 262: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.2607 - bpp: 0.9558 - mse: 1.5929e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2115 - bpp: 0.9505 - mse: 1.5393e-04\n",
      "Epoch 263: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.2115 - bpp: 0.9505 - mse: 1.5393e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6698 - bpp: 0.9747 - mse: 2.0692e-04\n",
      "Epoch 264: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.6698 - bpp: 0.9747 - mse: 2.0692e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2918 - bpp: 0.9692 - mse: 1.6145e-04\n",
      "Epoch 265: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.2918 - bpp: 0.9692 - mse: 1.6145e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2581 - bpp: 0.9560 - mse: 1.5894e-04\n",
      "Epoch 266: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.2581 - bpp: 0.9560 - mse: 1.5894e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4573 - bpp: 0.9619 - mse: 1.8255e-04\n",
      "Epoch 267: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.4573 - bpp: 0.9619 - mse: 1.8255e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2390 - bpp: 0.9536 - mse: 1.5691e-04\n",
      "Epoch 268: loss did not improve from 2.11102\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.2390 - bpp: 0.9536 - mse: 1.5691e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9945 - bpp: 0.8980 - mse: 1.3384e-04\n",
      "Epoch 269: loss improved from 2.11102 to 1.99448, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9945 - bpp: 0.8980 - mse: 1.3384e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1999 - bpp: 0.9236 - mse: 1.5581e-04\n",
      "Epoch 270: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.1999 - bpp: 0.9236 - mse: 1.5581e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2726 - bpp: 0.9401 - mse: 1.6265e-04\n",
      "Epoch 271: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.2726 - bpp: 0.9401 - mse: 1.6265e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3300 - bpp: 0.9662 - mse: 1.6648e-04\n",
      "Epoch 272: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.3300 - bpp: 0.9662 - mse: 1.6648e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1596 - bpp: 0.9389 - mse: 1.4901e-04\n",
      "Epoch 273: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.1596 - bpp: 0.9389 - mse: 1.4901e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4322 - bpp: 0.9569 - mse: 1.8009e-04\n",
      "Epoch 274: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4322 - bpp: 0.9569 - mse: 1.8009e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2390 - bpp: 0.9343 - mse: 1.5927e-04\n",
      "Epoch 275: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.2390 - bpp: 0.9343 - mse: 1.5927e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1836 - bpp: 0.9277 - mse: 1.5331e-04\n",
      "Epoch 276: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.1836 - bpp: 0.9277 - mse: 1.5331e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2004 - bpp: 0.9479 - mse: 1.5290e-04\n",
      "Epoch 277: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2004 - bpp: 0.9479 - mse: 1.5290e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4123 - bpp: 0.9632 - mse: 1.7689e-04\n",
      "Epoch 278: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.4123 - bpp: 0.9632 - mse: 1.7689e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0725 - bpp: 0.9236 - mse: 1.4025e-04\n",
      "Epoch 279: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.0725 - bpp: 0.9236 - mse: 1.4025e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3116 - bpp: 0.9443 - mse: 1.6691e-04\n",
      "Epoch 280: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.3116 - bpp: 0.9443 - mse: 1.6691e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2148 - bpp: 0.9531 - mse: 1.5402e-04\n",
      "Epoch 281: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2148 - bpp: 0.9531 - mse: 1.5402e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1710 - bpp: 0.9183 - mse: 1.5292e-04\n",
      "Epoch 282: loss did not improve from 1.99448\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.1710 - bpp: 0.9183 - mse: 1.5292e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9805 - bpp: 0.9016 - mse: 1.3171e-04\n",
      "Epoch 283: loss improved from 1.99448 to 1.98050, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9805 - bpp: 0.9016 - mse: 1.3171e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1600 - bpp: 0.9415 - mse: 1.4875e-04\n",
      "Epoch 284: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.1600 - bpp: 0.9415 - mse: 1.4875e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1796 - bpp: 0.9332 - mse: 1.5215e-04\n",
      "Epoch 285: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.1796 - bpp: 0.9332 - mse: 1.5215e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2425 - bpp: 0.9522 - mse: 1.5751e-04\n",
      "Epoch 286: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.2425 - bpp: 0.9522 - mse: 1.5751e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4722 - bpp: 0.9639 - mse: 1.8411e-04\n",
      "Epoch 287: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.4722 - bpp: 0.9639 - mse: 1.8411e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5605 - bpp: 0.9900 - mse: 4.3585e-04\n",
      "Epoch 288: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 4.5605 - bpp: 0.9900 - mse: 4.3585e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5685 - bpp: 1.0609 - mse: 3.0610e-04\n",
      "Epoch 289: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5685 - bpp: 1.0609 - mse: 3.0610e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2674 - bpp: 0.9631 - mse: 1.5921e-04\n",
      "Epoch 290: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.2674 - bpp: 0.9631 - mse: 1.5921e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1110 - bpp: 0.9241 - mse: 1.4488e-04\n",
      "Epoch 291: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.1110 - bpp: 0.9241 - mse: 1.4488e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2711 - bpp: 0.9505 - mse: 1.6121e-04\n",
      "Epoch 292: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.2711 - bpp: 0.9505 - mse: 1.6121e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1065 - bpp: 0.8992 - mse: 1.4738e-04\n",
      "Epoch 293: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.1065 - bpp: 0.8992 - mse: 1.4738e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0127 - bpp: 0.9219 - mse: 1.3316e-04\n",
      "Epoch 294: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0127 - bpp: 0.9219 - mse: 1.3316e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0739 - bpp: 0.9079 - mse: 1.4233e-04\n",
      "Epoch 295: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0739 - bpp: 0.9079 - mse: 1.4233e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1098 - bpp: 0.9422 - mse: 1.4253e-04\n",
      "Epoch 296: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 2.1098 - bpp: 0.9422 - mse: 1.4253e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1949 - bpp: 0.9162 - mse: 1.5609e-04\n",
      "Epoch 297: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.1949 - bpp: 0.9162 - mse: 1.5609e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1761 - bpp: 0.9272 - mse: 1.5245e-04\n",
      "Epoch 298: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.1761 - bpp: 0.9272 - mse: 1.5245e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2397 - bpp: 0.9412 - mse: 1.5850e-04\n",
      "Epoch 299: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.2397 - bpp: 0.9412 - mse: 1.5850e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2186 - bpp: 0.9252 - mse: 1.5789e-04\n",
      "Epoch 300: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.2186 - bpp: 0.9252 - mse: 1.5789e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1385 - bpp: 0.9041 - mse: 1.5069e-04\n",
      "Epoch 301: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.1385 - bpp: 0.9041 - mse: 1.5069e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1028 - bpp: 0.9190 - mse: 1.4451e-04\n",
      "Epoch 302: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.1028 - bpp: 0.9190 - mse: 1.4451e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1601 - bpp: 0.9212 - mse: 1.5123e-04\n",
      "Epoch 303: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.1601 - bpp: 0.9212 - mse: 1.5123e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1752 - bpp: 0.9295 - mse: 1.5206e-04\n",
      "Epoch 304: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.1752 - bpp: 0.9295 - mse: 1.5206e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1535 - bpp: 0.9209 - mse: 1.5047e-04\n",
      "Epoch 305: loss did not improve from 1.98050\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.1535 - bpp: 0.9209 - mse: 1.5047e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9712 - bpp: 0.8813 - mse: 1.3305e-04\n",
      "Epoch 306: loss improved from 1.98050 to 1.97118, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9712 - bpp: 0.8813 - mse: 1.3305e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0700 - bpp: 0.9051 - mse: 1.4219e-04\n",
      "Epoch 307: loss did not improve from 1.97118\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.0700 - bpp: 0.9051 - mse: 1.4219e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7946 - bpp: 0.8579 - mse: 1.1435e-04\n",
      "Epoch 308: loss improved from 1.97118 to 1.79462, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7946 - bpp: 0.8579 - mse: 1.1435e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3312 - bpp: 0.9336 - mse: 1.7061e-04\n",
      "Epoch 309: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.3312 - bpp: 0.9336 - mse: 1.7061e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3012 - bpp: 0.9099 - mse: 1.6983e-04\n",
      "Epoch 310: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.3012 - bpp: 0.9099 - mse: 1.6983e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1443 - bpp: 0.8974 - mse: 1.5221e-04\n",
      "Epoch 311: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 2.1443 - bpp: 0.8974 - mse: 1.5221e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9796 - bpp: 0.8837 - mse: 1.3378e-04\n",
      "Epoch 312: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.9796 - bpp: 0.8837 - mse: 1.3378e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0538 - bpp: 0.8945 - mse: 1.4152e-04\n",
      "Epoch 313: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.0538 - bpp: 0.8945 - mse: 1.4152e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0139 - bpp: 1.1049 - mse: 5.9925e-04\n",
      "Epoch 314: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 6.0139 - bpp: 1.1049 - mse: 5.9925e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7281 - bpp: 1.0402 - mse: 2.0605e-04\n",
      "Epoch 315: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.7281 - bpp: 1.0402 - mse: 2.0605e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4004 - bpp: 0.9905 - mse: 1.7211e-04\n",
      "Epoch 316: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.4004 - bpp: 0.9905 - mse: 1.7211e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3021 - bpp: 0.9751 - mse: 1.6199e-04\n",
      "Epoch 317: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.3021 - bpp: 0.9751 - mse: 1.6199e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0994 - bpp: 0.9332 - mse: 1.4235e-04\n",
      "Epoch 318: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0994 - bpp: 0.9332 - mse: 1.4235e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0921 - bpp: 0.9419 - mse: 1.4040e-04\n",
      "Epoch 319: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.0921 - bpp: 0.9419 - mse: 1.4040e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1506 - bpp: 0.9284 - mse: 1.4920e-04\n",
      "Epoch 320: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.1506 - bpp: 0.9284 - mse: 1.4920e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9266 - bpp: 0.8825 - mse: 1.2746e-04\n",
      "Epoch 321: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.9266 - bpp: 0.8825 - mse: 1.2746e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9617 - bpp: 0.9025 - mse: 1.2930e-04\n",
      "Epoch 322: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.9617 - bpp: 0.9025 - mse: 1.2930e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0873 - bpp: 0.9267 - mse: 1.4168e-04\n",
      "Epoch 323: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 2.0873 - bpp: 0.9267 - mse: 1.4168e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0137 - bpp: 0.8774 - mse: 1.3872e-04\n",
      "Epoch 324: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 2.0137 - bpp: 0.8774 - mse: 1.3872e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9748 - bpp: 0.9068 - mse: 1.3037e-04\n",
      "Epoch 325: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.9748 - bpp: 0.9068 - mse: 1.3037e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9838 - bpp: 0.8862 - mse: 1.3400e-04\n",
      "Epoch 326: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.9838 - bpp: 0.8862 - mse: 1.3400e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9048 - bpp: 0.8794 - mse: 1.2518e-04\n",
      "Epoch 327: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9048 - bpp: 0.8794 - mse: 1.2518e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0688 - bpp: 0.8872 - mse: 1.4423e-04\n",
      "Epoch 328: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.0688 - bpp: 0.8872 - mse: 1.4423e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4473 - bpp: 1.0772 - mse: 5.3346e-04\n",
      "Epoch 329: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 5.4473 - bpp: 1.0772 - mse: 5.3346e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4584 - bpp: 0.9734 - mse: 1.8127e-04\n",
      "Epoch 330: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 2.4584 - bpp: 0.9734 - mse: 1.8127e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0166 - bpp: 0.9078 - mse: 1.3534e-04\n",
      "Epoch 331: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.0166 - bpp: 0.9078 - mse: 1.3534e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1178 - bpp: 0.9375 - mse: 1.4408e-04\n",
      "Epoch 332: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 2.1178 - bpp: 0.9375 - mse: 1.4408e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2346 - bpp: 0.9439 - mse: 1.5755e-04\n",
      "Epoch 333: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 2.2346 - bpp: 0.9439 - mse: 1.5755e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9595 - bpp: 0.8885 - mse: 1.3074e-04\n",
      "Epoch 334: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 1.9595 - bpp: 0.8885 - mse: 1.3074e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2022 - bpp: 0.9204 - mse: 1.5648e-04\n",
      "Epoch 335: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.2022 - bpp: 0.9204 - mse: 1.5648e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1326 - bpp: 0.9188 - mse: 1.4818e-04\n",
      "Epoch 336: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 2.1326 - bpp: 0.9188 - mse: 1.4818e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1815 - bpp: 0.9417 - mse: 1.5135e-04\n",
      "Epoch 337: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 2.1815 - bpp: 0.9417 - mse: 1.5135e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4647 - bpp: 0.9499 - mse: 1.8492e-04\n",
      "Epoch 338: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 2.4647 - bpp: 0.9499 - mse: 1.8492e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3335 - bpp: 0.9481 - mse: 1.6911e-04\n",
      "Epoch 339: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 2.3335 - bpp: 0.9481 - mse: 1.6911e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9527 - bpp: 0.8951 - mse: 1.2910e-04\n",
      "Epoch 340: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 1.9527 - bpp: 0.8951 - mse: 1.2910e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9463 - bpp: 0.8860 - mse: 1.2943e-04\n",
      "Epoch 341: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.9463 - bpp: 0.8860 - mse: 1.2943e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0421 - bpp: 0.9024 - mse: 1.3913e-04\n",
      "Epoch 342: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 2.0421 - bpp: 0.9024 - mse: 1.3913e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0147 - bpp: 0.8916 - mse: 1.3710e-04\n",
      "Epoch 343: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 2.0147 - bpp: 0.8916 - mse: 1.3710e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9611 - bpp: 0.8792 - mse: 1.3207e-04\n",
      "Epoch 344: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 1.9611 - bpp: 0.8792 - mse: 1.3207e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1355 - bpp: 0.9294 - mse: 1.4723e-04\n",
      "Epoch 345: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.1355 - bpp: 0.9294 - mse: 1.4723e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1479 - bpp: 0.9007 - mse: 1.5224e-04\n",
      "Epoch 346: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 2.1479 - bpp: 0.9007 - mse: 1.5224e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9770 - bpp: 0.8762 - mse: 1.3438e-04\n",
      "Epoch 347: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 1.9770 - bpp: 0.8762 - mse: 1.3438e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0174 - bpp: 0.8944 - mse: 1.3709e-04\n",
      "Epoch 348: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 2.0174 - bpp: 0.8944 - mse: 1.3709e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2066 - bpp: 0.9183 - mse: 1.5726e-04\n",
      "Epoch 349: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 2.2066 - bpp: 0.9183 - mse: 1.5726e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9043 - bpp: 0.8703 - mse: 1.2623e-04\n",
      "Epoch 350: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 1.9043 - bpp: 0.8703 - mse: 1.2623e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1697 - bpp: 0.9023 - mse: 1.5471e-04\n",
      "Epoch 351: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 2.1697 - bpp: 0.9023 - mse: 1.5471e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0354 - bpp: 0.9059 - mse: 1.3788e-04\n",
      "Epoch 352: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 2.0354 - bpp: 0.9059 - mse: 1.3788e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1213 - bpp: 0.9085 - mse: 1.4806e-04\n",
      "Epoch 353: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 2.1213 - bpp: 0.9085 - mse: 1.4806e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0828 - bpp: 0.8867 - mse: 1.4600e-04\n",
      "Epoch 354: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 2.0828 - bpp: 0.8867 - mse: 1.4600e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2082 - bpp: 0.9039 - mse: 1.5922e-04\n",
      "Epoch 355: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 2.2082 - bpp: 0.9039 - mse: 1.5922e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0283 - bpp: 0.8818 - mse: 1.3994e-04\n",
      "Epoch 356: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.0283 - bpp: 0.8818 - mse: 1.3994e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3359 - bpp: 0.9152 - mse: 1.7342e-04\n",
      "Epoch 357: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 2.3359 - bpp: 0.9152 - mse: 1.7342e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9338 - bpp: 0.8847 - mse: 1.2807e-04\n",
      "Epoch 358: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 1.9338 - bpp: 0.8847 - mse: 1.2807e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0365 - bpp: 0.9006 - mse: 1.3866e-04\n",
      "Epoch 359: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 2.0365 - bpp: 0.9006 - mse: 1.3866e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0810 - bpp: 0.8818 - mse: 1.4639e-04\n",
      "Epoch 360: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 2.0810 - bpp: 0.8818 - mse: 1.4639e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0679 - bpp: 0.9006 - mse: 1.4250e-04\n",
      "Epoch 361: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 2.0679 - bpp: 0.9006 - mse: 1.4250e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7381 - bpp: 0.9798 - mse: 2.1464e-04\n",
      "Epoch 362: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 2.7381 - bpp: 0.9798 - mse: 2.1464e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1330 - bpp: 0.9155 - mse: 1.4862e-04\n",
      "Epoch 363: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 2.1330 - bpp: 0.9155 - mse: 1.4862e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1882 - bpp: 0.9070 - mse: 1.5639e-04\n",
      "Epoch 364: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 2.1882 - bpp: 0.9070 - mse: 1.5639e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1004 - bpp: 0.9025 - mse: 1.4623e-04\n",
      "Epoch 365: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.1004 - bpp: 0.9025 - mse: 1.4623e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0123 - bpp: 0.8622 - mse: 1.4040e-04\n",
      "Epoch 366: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0123 - bpp: 0.8622 - mse: 1.4040e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0612 - bpp: 0.8783 - mse: 1.4439e-04\n",
      "Epoch 367: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0612 - bpp: 0.8783 - mse: 1.4439e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9386 - bpp: 0.8724 - mse: 1.3015e-04\n",
      "Epoch 368: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.9386 - bpp: 0.8724 - mse: 1.3015e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1838 - bpp: 0.9038 - mse: 1.5624e-04\n",
      "Epoch 369: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.1838 - bpp: 0.9038 - mse: 1.5624e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0647 - bpp: 0.8855 - mse: 1.4393e-04\n",
      "Epoch 370: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.0647 - bpp: 0.8855 - mse: 1.4393e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7697 - bpp: 1.0492 - mse: 4.5416e-04\n",
      "Epoch 371: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 4.7697 - bpp: 1.0492 - mse: 4.5416e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4408 - bpp: 0.9890 - mse: 1.7722e-04\n",
      "Epoch 372: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.4408 - bpp: 0.9890 - mse: 1.7722e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0412 - bpp: 0.8934 - mse: 1.4011e-04\n",
      "Epoch 373: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.0412 - bpp: 0.8934 - mse: 1.4011e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9123 - bpp: 0.8747 - mse: 1.2666e-04\n",
      "Epoch 374: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.9123 - bpp: 0.8747 - mse: 1.2666e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9335 - bpp: 0.8980 - mse: 1.2641e-04\n",
      "Epoch 375: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.9335 - bpp: 0.8980 - mse: 1.2641e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2818 - bpp: 0.9298 - mse: 1.6504e-04\n",
      "Epoch 376: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 2.2818 - bpp: 0.9298 - mse: 1.6504e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0859 - bpp: 0.9264 - mse: 1.4154e-04\n",
      "Epoch 377: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.0859 - bpp: 0.9264 - mse: 1.4154e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9150 - bpp: 0.8891 - mse: 1.2524e-04\n",
      "Epoch 378: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.9150 - bpp: 0.8891 - mse: 1.2524e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0722 - bpp: 0.9114 - mse: 1.4170e-04\n",
      "Epoch 379: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.0722 - bpp: 0.9114 - mse: 1.4170e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0534 - bpp: 0.8911 - mse: 1.4189e-04\n",
      "Epoch 380: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0534 - bpp: 0.8911 - mse: 1.4189e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9856 - bpp: 0.8989 - mse: 1.3265e-04\n",
      "Epoch 381: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.9856 - bpp: 0.8989 - mse: 1.3265e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1648 - bpp: 0.9266 - mse: 1.5115e-04\n",
      "Epoch 382: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.1648 - bpp: 0.9266 - mse: 1.5115e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0190 - bpp: 0.8996 - mse: 1.3664e-04\n",
      "Epoch 383: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.0190 - bpp: 0.8996 - mse: 1.3664e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9537 - bpp: 0.8839 - mse: 1.3059e-04\n",
      "Epoch 384: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.9537 - bpp: 0.8839 - mse: 1.3059e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1916 - bpp: 0.9318 - mse: 1.5378e-04\n",
      "Epoch 385: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 2.1916 - bpp: 0.9318 - mse: 1.5378e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9496 - bpp: 0.8704 - mse: 1.3174e-04\n",
      "Epoch 386: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9496 - bpp: 0.8704 - mse: 1.3174e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9383 - bpp: 0.8850 - mse: 1.2858e-04\n",
      "Epoch 387: loss did not improve from 1.79462\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9383 - bpp: 0.8850 - mse: 1.2858e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7907 - bpp: 0.8508 - mse: 1.1474e-04\n",
      "Epoch 388: loss improved from 1.79462 to 1.79071, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7907 - bpp: 0.8508 - mse: 1.1474e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9184 - bpp: 0.8595 - mse: 1.2926e-04\n",
      "Epoch 389: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9184 - bpp: 0.8595 - mse: 1.2926e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9891 - bpp: 0.8687 - mse: 1.3676e-04\n",
      "Epoch 390: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9891 - bpp: 0.8687 - mse: 1.3676e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8733 - bpp: 1.0271 - mse: 3.4744e-04\n",
      "Epoch 391: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.8733 - bpp: 1.0271 - mse: 3.4744e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3169 - bpp: 0.9531 - mse: 1.6648e-04\n",
      "Epoch 392: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 2.3169 - bpp: 0.9531 - mse: 1.6648e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0664 - bpp: 0.8997 - mse: 1.4242e-04\n",
      "Epoch 393: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 2.0664 - bpp: 0.8997 - mse: 1.4242e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9257 - bpp: 0.8901 - mse: 1.2642e-04\n",
      "Epoch 394: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 243ms/step - loss: 1.9257 - bpp: 0.8901 - mse: 1.2642e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9351 - bpp: 0.8923 - mse: 1.2729e-04\n",
      "Epoch 395: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.9351 - bpp: 0.8923 - mse: 1.2729e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0101 - bpp: 0.8926 - mse: 1.3642e-04\n",
      "Epoch 396: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0101 - bpp: 0.8926 - mse: 1.3642e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9399 - bpp: 0.8847 - mse: 1.2881e-04\n",
      "Epoch 397: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.9399 - bpp: 0.8847 - mse: 1.2881e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9228 - bpp: 0.8743 - mse: 1.2799e-04\n",
      "Epoch 398: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9228 - bpp: 0.8743 - mse: 1.2799e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0761 - bpp: 0.9082 - mse: 1.4256e-04\n",
      "Epoch 399: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0761 - bpp: 0.9082 - mse: 1.4256e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8067 - bpp: 0.8410 - mse: 1.1788e-04\n",
      "Epoch 400: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.8067 - bpp: 0.8410 - mse: 1.1788e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1377 - bpp: 0.8985 - mse: 1.5127e-04\n",
      "Epoch 401: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 2.1377 - bpp: 0.8985 - mse: 1.5127e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8472 - bpp: 0.8429 - mse: 1.2260e-04\n",
      "Epoch 402: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8472 - bpp: 0.8429 - mse: 1.2260e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5300 - bpp: 0.9258 - mse: 1.9583e-04\n",
      "Epoch 403: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.5300 - bpp: 0.9258 - mse: 1.9583e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0873 - bpp: 0.9008 - mse: 1.4484e-04\n",
      "Epoch 404: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.0873 - bpp: 0.9008 - mse: 1.4484e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0279 - bpp: 0.8874 - mse: 1.3921e-04\n",
      "Epoch 405: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.0279 - bpp: 0.8874 - mse: 1.3921e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0057 - bpp: 0.8776 - mse: 1.3770e-04\n",
      "Epoch 406: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.0057 - bpp: 0.8776 - mse: 1.3770e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9838 - bpp: 0.8868 - mse: 1.3391e-04\n",
      "Epoch 407: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9838 - bpp: 0.8868 - mse: 1.3391e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9720 - bpp: 0.8796 - mse: 1.3335e-04\n",
      "Epoch 408: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.9720 - bpp: 0.8796 - mse: 1.3335e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8975 - bpp: 0.8626 - mse: 1.2633e-04\n",
      "Epoch 409: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8975 - bpp: 0.8626 - mse: 1.2633e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0047 - bpp: 0.8666 - mse: 1.3893e-04\n",
      "Epoch 410: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.0047 - bpp: 0.8666 - mse: 1.3893e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0216 - bpp: 0.8920 - mse: 1.3790e-04\n",
      "Epoch 411: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.0216 - bpp: 0.8920 - mse: 1.3790e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0267 - bpp: 0.8665 - mse: 1.4163e-04\n",
      "Epoch 412: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0267 - bpp: 0.8665 - mse: 1.4163e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8239 - bpp: 0.8428 - mse: 1.1976e-04\n",
      "Epoch 413: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8239 - bpp: 0.8428 - mse: 1.1976e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0813 - bpp: 0.8869 - mse: 1.4579e-04\n",
      "Epoch 414: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.0813 - bpp: 0.8869 - mse: 1.4579e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8537 - bpp: 0.8620 - mse: 1.2106e-04\n",
      "Epoch 415: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8537 - bpp: 0.8620 - mse: 1.2106e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0149 - bpp: 0.9397 - mse: 2.5332e-04\n",
      "Epoch 416: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0149 - bpp: 0.9397 - mse: 2.5332e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1929 - bpp: 0.9205 - mse: 1.5533e-04\n",
      "Epoch 417: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.1929 - bpp: 0.9205 - mse: 1.5533e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0097 - bpp: 0.8906 - mse: 1.3661e-04\n",
      "Epoch 418: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.0097 - bpp: 0.8906 - mse: 1.3661e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9929 - bpp: 0.8874 - mse: 1.3495e-04\n",
      "Epoch 419: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.9929 - bpp: 0.8874 - mse: 1.3495e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0030 - bpp: 0.8737 - mse: 1.3785e-04\n",
      "Epoch 420: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.0030 - bpp: 0.8737 - mse: 1.3785e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0033 - bpp: 0.8825 - mse: 1.3681e-04\n",
      "Epoch 421: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.0033 - bpp: 0.8825 - mse: 1.3681e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9271 - bpp: 0.8493 - mse: 1.3157e-04\n",
      "Epoch 422: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.9271 - bpp: 0.8493 - mse: 1.3157e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9752 - bpp: 0.8648 - mse: 1.3554e-04\n",
      "Epoch 423: loss did not improve from 1.79071\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.9752 - bpp: 0.8648 - mse: 1.3554e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7329 - bpp: 0.8338 - mse: 1.0975e-04\n",
      "Epoch 424: loss improved from 1.79071 to 1.73288, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7329 - bpp: 0.8338 - mse: 1.0975e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8970 - bpp: 0.8627 - mse: 1.2626e-04\n",
      "Epoch 425: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8970 - bpp: 0.8627 - mse: 1.2626e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2275 - bpp: 0.8929 - mse: 1.6292e-04\n",
      "Epoch 426: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2275 - bpp: 0.8929 - mse: 1.6292e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3685 - bpp: 0.9383 - mse: 1.7458e-04\n",
      "Epoch 427: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.3685 - bpp: 0.9383 - mse: 1.7458e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0598 - bpp: 0.9014 - mse: 1.4141e-04\n",
      "Epoch 428: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.0598 - bpp: 0.9014 - mse: 1.4141e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0876 - bpp: 0.8992 - mse: 1.4506e-04\n",
      "Epoch 429: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.0876 - bpp: 0.8992 - mse: 1.4506e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0740 - bpp: 0.8928 - mse: 1.4419e-04\n",
      "Epoch 430: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.0740 - bpp: 0.8928 - mse: 1.4419e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0234 - bpp: 0.8880 - mse: 1.3859e-04\n",
      "Epoch 431: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0234 - bpp: 0.8880 - mse: 1.3859e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8757 - bpp: 0.8471 - mse: 1.2557e-04\n",
      "Epoch 432: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8757 - bpp: 0.8471 - mse: 1.2557e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8912 - bpp: 0.8633 - mse: 1.2548e-04\n",
      "Epoch 433: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.8912 - bpp: 0.8633 - mse: 1.2548e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9277 - bpp: 0.8553 - mse: 1.3091e-04\n",
      "Epoch 434: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9277 - bpp: 0.8553 - mse: 1.3091e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8280 - bpp: 0.8532 - mse: 1.1899e-04\n",
      "Epoch 435: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8280 - bpp: 0.8532 - mse: 1.1899e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9933 - bpp: 0.8851 - mse: 1.3528e-04\n",
      "Epoch 436: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.9933 - bpp: 0.8851 - mse: 1.3528e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1284 - bpp: 0.8870 - mse: 1.5153e-04\n",
      "Epoch 437: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.1284 - bpp: 0.8870 - mse: 1.5153e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8701 - bpp: 0.8489 - mse: 1.2466e-04\n",
      "Epoch 438: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8701 - bpp: 0.8489 - mse: 1.2466e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0276 - bpp: 0.8850 - mse: 1.3948e-04\n",
      "Epoch 439: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0276 - bpp: 0.8850 - mse: 1.3948e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0921 - bpp: 0.8902 - mse: 1.4672e-04\n",
      "Epoch 440: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.0921 - bpp: 0.8902 - mse: 1.4672e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2591 - bpp: 0.9010 - mse: 1.6578e-04\n",
      "Epoch 441: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.2591 - bpp: 0.9010 - mse: 1.6578e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8563 - bpp: 0.8427 - mse: 1.2374e-04\n",
      "Epoch 442: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.8563 - bpp: 0.8427 - mse: 1.2374e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7492 - bpp: 0.8160 - mse: 1.1392e-04\n",
      "Epoch 443: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.7492 - bpp: 0.8160 - mse: 1.1392e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7939 - bpp: 0.8390 - mse: 1.1656e-04\n",
      "Epoch 444: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7939 - bpp: 0.8390 - mse: 1.1656e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9165 - bpp: 0.8686 - mse: 1.2792e-04\n",
      "Epoch 445: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9165 - bpp: 0.8686 - mse: 1.2792e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8889 - bpp: 0.8434 - mse: 1.2762e-04\n",
      "Epoch 446: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8889 - bpp: 0.8434 - mse: 1.2762e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9923 - bpp: 0.8471 - mse: 1.3979e-04\n",
      "Epoch 447: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9923 - bpp: 0.8471 - mse: 1.3979e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0131 - bpp: 0.8713 - mse: 1.3938e-04\n",
      "Epoch 448: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.0131 - bpp: 0.8713 - mse: 1.3938e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0769 - bpp: 0.9081 - mse: 1.4268e-04\n",
      "Epoch 449: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.0769 - bpp: 0.9081 - mse: 1.4268e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8279 - bpp: 0.8472 - mse: 1.1972e-04\n",
      "Epoch 450: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8279 - bpp: 0.8472 - mse: 1.1972e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.2948 - bpp: 0.8872 - mse: 1.7182e-04\n",
      "Epoch 451: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.2948 - bpp: 0.8872 - mse: 1.7182e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1339 - bpp: 0.9087 - mse: 1.4956e-04\n",
      "Epoch 452: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.1339 - bpp: 0.9087 - mse: 1.4956e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8676 - bpp: 0.8383 - mse: 1.2565e-04\n",
      "Epoch 453: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.8676 - bpp: 0.8383 - mse: 1.2565e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8218 - bpp: 0.8469 - mse: 1.1901e-04\n",
      "Epoch 454: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.8218 - bpp: 0.8469 - mse: 1.1901e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9812 - bpp: 0.8652 - mse: 1.3623e-04\n",
      "Epoch 455: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.9812 - bpp: 0.8652 - mse: 1.3623e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9109 - bpp: 0.8681 - mse: 1.2729e-04\n",
      "Epoch 456: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.9109 - bpp: 0.8681 - mse: 1.2729e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9351 - bpp: 0.8542 - mse: 1.3195e-04\n",
      "Epoch 457: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.9351 - bpp: 0.8542 - mse: 1.3195e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0906 - bpp: 0.8752 - mse: 1.4837e-04\n",
      "Epoch 458: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.0906 - bpp: 0.8752 - mse: 1.4837e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9046 - bpp: 0.8593 - mse: 1.2761e-04\n",
      "Epoch 459: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9046 - bpp: 0.8593 - mse: 1.2761e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8952 - bpp: 0.8410 - mse: 1.2868e-04\n",
      "Epoch 460: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8952 - bpp: 0.8410 - mse: 1.2868e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9045 - bpp: 0.8646 - mse: 1.2695e-04\n",
      "Epoch 461: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.9045 - bpp: 0.8646 - mse: 1.2695e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9250 - bpp: 0.8644 - mse: 1.2948e-04\n",
      "Epoch 462: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9250 - bpp: 0.8644 - mse: 1.2948e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7636 - bpp: 0.8290 - mse: 1.1410e-04\n",
      "Epoch 463: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7636 - bpp: 0.8290 - mse: 1.1410e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9585 - bpp: 0.8548 - mse: 1.3473e-04\n",
      "Epoch 464: loss did not improve from 1.73288\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.9585 - bpp: 0.8548 - mse: 1.3473e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7312 - bpp: 0.8363 - mse: 1.0924e-04\n",
      "Epoch 465: loss improved from 1.73288 to 1.73117, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 1.7312 - bpp: 0.8363 - mse: 1.0924e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0049 - bpp: 0.8711 - mse: 1.3840e-04\n",
      "Epoch 466: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.0049 - bpp: 0.8711 - mse: 1.3840e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7656 - bpp: 0.8341 - mse: 1.1371e-04\n",
      "Epoch 467: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7656 - bpp: 0.8341 - mse: 1.1371e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9036 - bpp: 0.8557 - mse: 1.2791e-04\n",
      "Epoch 468: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9036 - bpp: 0.8557 - mse: 1.2791e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9604 - bpp: 0.8523 - mse: 1.3526e-04\n",
      "Epoch 469: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9604 - bpp: 0.8523 - mse: 1.3526e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9310 - bpp: 0.8644 - mse: 1.3019e-04\n",
      "Epoch 470: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9310 - bpp: 0.8644 - mse: 1.3019e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9968 - bpp: 0.8553 - mse: 1.3935e-04\n",
      "Epoch 471: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.9968 - bpp: 0.8553 - mse: 1.3935e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9333 - bpp: 0.8514 - mse: 1.3207e-04\n",
      "Epoch 472: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9333 - bpp: 0.8514 - mse: 1.3207e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9775 - bpp: 0.8641 - mse: 1.3591e-04\n",
      "Epoch 473: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.9775 - bpp: 0.8641 - mse: 1.3591e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8514 - bpp: 0.8425 - mse: 1.2316e-04\n",
      "Epoch 474: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.8514 - bpp: 0.8425 - mse: 1.2316e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1588 - bpp: 0.8929 - mse: 1.5452e-04\n",
      "Epoch 475: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.1588 - bpp: 0.8929 - mse: 1.5452e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0496 - bpp: 0.8726 - mse: 1.4368e-04\n",
      "Epoch 476: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.0496 - bpp: 0.8726 - mse: 1.4368e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0233 - bpp: 0.8896 - mse: 1.3839e-04\n",
      "Epoch 477: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.0233 - bpp: 0.8896 - mse: 1.3839e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7676 - bpp: 0.8326 - mse: 1.1414e-04\n",
      "Epoch 478: loss did not improve from 1.73117\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.7676 - bpp: 0.8326 - mse: 1.1414e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6953 - bpp: 0.8079 - mse: 1.0834e-04\n",
      "Epoch 479: loss improved from 1.73117 to 1.69535, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6953 - bpp: 0.8079 - mse: 1.0834e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8330 - bpp: 0.8453 - mse: 1.2056e-04\n",
      "Epoch 480: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8330 - bpp: 0.8453 - mse: 1.2056e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8121 - bpp: 0.8337 - mse: 1.1944e-04\n",
      "Epoch 481: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 1.8121 - bpp: 0.8337 - mse: 1.1944e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8759 - bpp: 0.8573 - mse: 1.2434e-04\n",
      "Epoch 482: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.8759 - bpp: 0.8573 - mse: 1.2434e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8761 - bpp: 0.8530 - mse: 1.2488e-04\n",
      "Epoch 483: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.8761 - bpp: 0.8530 - mse: 1.2488e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0882 - bpp: 0.8743 - mse: 1.4819e-04\n",
      "Epoch 484: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.0882 - bpp: 0.8743 - mse: 1.4819e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0396 - bpp: 0.8775 - mse: 1.4186e-04\n",
      "Epoch 485: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.0396 - bpp: 0.8775 - mse: 1.4186e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7653 - bpp: 0.8273 - mse: 1.1450e-04\n",
      "Epoch 486: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.7653 - bpp: 0.8273 - mse: 1.1450e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1014 - bpp: 0.8876 - mse: 1.4817e-04\n",
      "Epoch 487: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 2.1014 - bpp: 0.8876 - mse: 1.4817e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8436 - bpp: 0.8257 - mse: 1.2426e-04\n",
      "Epoch 488: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.8436 - bpp: 0.8257 - mse: 1.2426e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9209 - bpp: 0.8699 - mse: 1.2830e-04\n",
      "Epoch 489: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.9209 - bpp: 0.8699 - mse: 1.2830e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9229 - bpp: 0.8580 - mse: 1.2999e-04\n",
      "Epoch 490: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.9229 - bpp: 0.8580 - mse: 1.2999e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7956 - bpp: 0.8400 - mse: 1.1665e-04\n",
      "Epoch 491: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7956 - bpp: 0.8400 - mse: 1.1665e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8339 - bpp: 0.8474 - mse: 1.2042e-04\n",
      "Epoch 492: loss did not improve from 1.69535\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.8339 - bpp: 0.8474 - mse: 1.2042e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6622 - bpp: 0.8137 - mse: 1.0357e-04\n",
      "Epoch 493: loss improved from 1.69535 to 1.66221, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6622 - bpp: 0.8137 - mse: 1.0357e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0472 - bpp: 0.8807 - mse: 1.4239e-04\n",
      "Epoch 494: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.0472 - bpp: 0.8807 - mse: 1.4239e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3381 - bpp: 0.8977 - mse: 1.7583e-04\n",
      "Epoch 495: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.3381 - bpp: 0.8977 - mse: 1.7583e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9216 - bpp: 0.8720 - mse: 1.2813e-04\n",
      "Epoch 496: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.9216 - bpp: 0.8720 - mse: 1.2813e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9738 - bpp: 0.8598 - mse: 1.3599e-04\n",
      "Epoch 497: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9738 - bpp: 0.8598 - mse: 1.3599e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9484 - bpp: 0.8610 - mse: 1.3273e-04\n",
      "Epoch 498: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9484 - bpp: 0.8610 - mse: 1.3273e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7929 - bpp: 0.8313 - mse: 1.1738e-04\n",
      "Epoch 499: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7929 - bpp: 0.8313 - mse: 1.1738e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8476 - bpp: 0.8322 - mse: 1.2395e-04\n",
      "Epoch 500: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8476 - bpp: 0.8322 - mse: 1.2395e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7852 - bpp: 0.8298 - mse: 1.1662e-04\n",
      "Epoch 501: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.7852 - bpp: 0.8298 - mse: 1.1662e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9620 - bpp: 0.8674 - mse: 1.3362e-04\n",
      "Epoch 502: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.9620 - bpp: 0.8674 - mse: 1.3362e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7889 - bpp: 0.8415 - mse: 1.1565e-04\n",
      "Epoch 503: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.7889 - bpp: 0.8415 - mse: 1.1565e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8481 - bpp: 0.8547 - mse: 1.2126e-04\n",
      "Epoch 504: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8481 - bpp: 0.8547 - mse: 1.2126e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8542 - bpp: 0.8542 - mse: 1.2207e-04\n",
      "Epoch 505: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8542 - bpp: 0.8542 - mse: 1.2207e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1465 - bpp: 0.8885 - mse: 1.5357e-04\n",
      "Epoch 506: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.1465 - bpp: 0.8885 - mse: 1.5357e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9441 - bpp: 0.8631 - mse: 1.3195e-04\n",
      "Epoch 507: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9441 - bpp: 0.8631 - mse: 1.3195e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7004 - bpp: 0.8103 - mse: 1.0866e-04\n",
      "Epoch 508: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7004 - bpp: 0.8103 - mse: 1.0866e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9092 - bpp: 0.8468 - mse: 1.2969e-04\n",
      "Epoch 509: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9092 - bpp: 0.8468 - mse: 1.2969e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8633 - bpp: 0.8525 - mse: 1.2339e-04\n",
      "Epoch 510: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8633 - bpp: 0.8525 - mse: 1.2339e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9488 - bpp: 0.8698 - mse: 1.3171e-04\n",
      "Epoch 511: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9488 - bpp: 0.8698 - mse: 1.3171e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7564 - bpp: 0.8209 - mse: 1.1419e-04\n",
      "Epoch 512: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7564 - bpp: 0.8209 - mse: 1.1419e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7875 - bpp: 0.8407 - mse: 1.1557e-04\n",
      "Epoch 513: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7875 - bpp: 0.8407 - mse: 1.1557e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8997 - bpp: 0.8562 - mse: 1.2739e-04\n",
      "Epoch 514: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8997 - bpp: 0.8562 - mse: 1.2739e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7801 - bpp: 0.8412 - mse: 1.1462e-04\n",
      "Epoch 515: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7801 - bpp: 0.8412 - mse: 1.1462e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9034 - bpp: 0.8454 - mse: 1.2915e-04\n",
      "Epoch 516: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.9034 - bpp: 0.8454 - mse: 1.2915e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8816 - bpp: 0.8490 - mse: 1.2605e-04\n",
      "Epoch 517: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8816 - bpp: 0.8490 - mse: 1.2605e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7119 - bpp: 0.8102 - mse: 1.1007e-04\n",
      "Epoch 518: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7119 - bpp: 0.8102 - mse: 1.1007e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7951 - bpp: 0.8265 - mse: 1.1823e-04\n",
      "Epoch 519: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7951 - bpp: 0.8265 - mse: 1.1823e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8193 - bpp: 0.8540 - mse: 1.1783e-04\n",
      "Epoch 520: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8193 - bpp: 0.8540 - mse: 1.1783e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7749 - bpp: 0.8261 - mse: 1.1581e-04\n",
      "Epoch 521: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7749 - bpp: 0.8261 - mse: 1.1581e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7133 - bpp: 0.8257 - mse: 1.0836e-04\n",
      "Epoch 522: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7133 - bpp: 0.8257 - mse: 1.0836e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8225 - bpp: 0.8343 - mse: 1.2063e-04\n",
      "Epoch 523: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8225 - bpp: 0.8343 - mse: 1.2063e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7522 - bpp: 0.8136 - mse: 1.1458e-04\n",
      "Epoch 524: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7522 - bpp: 0.8136 - mse: 1.1458e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8234 - bpp: 0.8401 - mse: 1.2004e-04\n",
      "Epoch 525: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8234 - bpp: 0.8401 - mse: 1.2004e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9344 - bpp: 0.8685 - mse: 1.3011e-04\n",
      "Epoch 526: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 1.9344 - bpp: 0.8685 - mse: 1.3011e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0198 - bpp: 0.8580 - mse: 1.4182e-04\n",
      "Epoch 527: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.0198 - bpp: 0.8580 - mse: 1.4182e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8701 - bpp: 0.8581 - mse: 1.2354e-04\n",
      "Epoch 528: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.8701 - bpp: 0.8581 - mse: 1.2354e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9742 - bpp: 0.8754 - mse: 1.3413e-04\n",
      "Epoch 529: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.9742 - bpp: 0.8754 - mse: 1.3413e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9403 - bpp: 0.8608 - mse: 1.3178e-04\n",
      "Epoch 530: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9403 - bpp: 0.8608 - mse: 1.3178e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9423 - bpp: 0.8674 - mse: 1.3121e-04\n",
      "Epoch 531: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.9423 - bpp: 0.8674 - mse: 1.3121e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7848 - bpp: 0.8253 - mse: 1.1713e-04\n",
      "Epoch 532: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7848 - bpp: 0.8253 - mse: 1.1713e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8094 - bpp: 0.8373 - mse: 1.1866e-04\n",
      "Epoch 533: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8094 - bpp: 0.8373 - mse: 1.1866e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0200 - bpp: 0.8793 - mse: 1.3924e-04\n",
      "Epoch 534: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 244ms/step - loss: 2.0200 - bpp: 0.8793 - mse: 1.3924e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8630 - bpp: 0.8456 - mse: 1.2420e-04\n",
      "Epoch 535: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8630 - bpp: 0.8456 - mse: 1.2420e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7853 - bpp: 0.8211 - mse: 1.1769e-04\n",
      "Epoch 536: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.7853 - bpp: 0.8211 - mse: 1.1769e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8910 - bpp: 0.8593 - mse: 1.2594e-04\n",
      "Epoch 537: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8910 - bpp: 0.8593 - mse: 1.2594e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6875 - bpp: 0.8095 - mse: 1.0717e-04\n",
      "Epoch 538: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6875 - bpp: 0.8095 - mse: 1.0717e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8391 - bpp: 0.8483 - mse: 1.2096e-04\n",
      "Epoch 539: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8391 - bpp: 0.8483 - mse: 1.2096e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3046 - bpp: 0.9096 - mse: 1.7029e-04\n",
      "Epoch 540: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.3046 - bpp: 0.9096 - mse: 1.7029e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9607 - bpp: 0.8610 - mse: 1.3424e-04\n",
      "Epoch 541: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.9607 - bpp: 0.8610 - mse: 1.3424e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.1394 - bpp: 0.9186 - mse: 1.4903e-04\n",
      "Epoch 542: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.1394 - bpp: 0.9186 - mse: 1.4903e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0475 - bpp: 0.8811 - mse: 1.4238e-04\n",
      "Epoch 543: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.0475 - bpp: 0.8811 - mse: 1.4238e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8414 - bpp: 0.8333 - mse: 1.2306e-04\n",
      "Epoch 544: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8414 - bpp: 0.8333 - mse: 1.2306e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7446 - bpp: 0.8290 - mse: 1.1177e-04\n",
      "Epoch 545: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7446 - bpp: 0.8290 - mse: 1.1177e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7189 - bpp: 0.8391 - mse: 1.0740e-04\n",
      "Epoch 546: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.7189 - bpp: 0.8391 - mse: 1.0740e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8601 - bpp: 0.8508 - mse: 1.2320e-04\n",
      "Epoch 547: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8601 - bpp: 0.8508 - mse: 1.2320e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7743 - bpp: 0.8329 - mse: 1.1492e-04\n",
      "Epoch 548: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7743 - bpp: 0.8329 - mse: 1.1492e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8082 - bpp: 0.8516 - mse: 1.1678e-04\n",
      "Epoch 549: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8082 - bpp: 0.8516 - mse: 1.1678e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8885 - bpp: 0.8587 - mse: 1.2570e-04\n",
      "Epoch 550: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8885 - bpp: 0.8587 - mse: 1.2570e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8663 - bpp: 0.8588 - mse: 1.2298e-04\n",
      "Epoch 551: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8663 - bpp: 0.8588 - mse: 1.2298e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0249 - bpp: 0.8662 - mse: 1.4144e-04\n",
      "Epoch 552: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.0249 - bpp: 0.8662 - mse: 1.4144e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8897 - bpp: 0.8508 - mse: 1.2682e-04\n",
      "Epoch 553: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.8897 - bpp: 0.8508 - mse: 1.2682e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9000 - bpp: 0.8536 - mse: 1.2773e-04\n",
      "Epoch 554: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9000 - bpp: 0.8536 - mse: 1.2773e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8979 - bpp: 0.8511 - mse: 1.2778e-04\n",
      "Epoch 555: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.8979 - bpp: 0.8511 - mse: 1.2778e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9176 - bpp: 0.8506 - mse: 1.3025e-04\n",
      "Epoch 556: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.9176 - bpp: 0.8506 - mse: 1.3025e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8037 - bpp: 0.8435 - mse: 1.1721e-04\n",
      "Epoch 557: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.8037 - bpp: 0.8435 - mse: 1.1721e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8895 - bpp: 0.8646 - mse: 1.2511e-04\n",
      "Epoch 558: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.8895 - bpp: 0.8646 - mse: 1.2511e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7310 - bpp: 0.8214 - mse: 1.1104e-04\n",
      "Epoch 559: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7310 - bpp: 0.8214 - mse: 1.1104e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0337 - bpp: 0.8928 - mse: 1.3928e-04\n",
      "Epoch 560: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.0337 - bpp: 0.8928 - mse: 1.3928e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7565 - bpp: 0.8366 - mse: 1.1230e-04\n",
      "Epoch 561: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.7565 - bpp: 0.8366 - mse: 1.1230e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7000 - bpp: 0.8252 - mse: 1.0679e-04\n",
      "Epoch 562: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.7000 - bpp: 0.8252 - mse: 1.0679e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7491 - bpp: 0.8361 - mse: 1.1144e-04\n",
      "Epoch 563: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7491 - bpp: 0.8361 - mse: 1.1144e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7375 - bpp: 0.8370 - mse: 1.0992e-04\n",
      "Epoch 564: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7375 - bpp: 0.8370 - mse: 1.0992e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7397 - bpp: 0.8178 - mse: 1.1253e-04\n",
      "Epoch 565: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.7397 - bpp: 0.8178 - mse: 1.1253e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9573 - bpp: 0.8781 - mse: 1.3173e-04\n",
      "Epoch 566: loss did not improve from 1.66221\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.9573 - bpp: 0.8781 - mse: 1.3173e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6455 - bpp: 0.8024 - mse: 1.0291e-04\n",
      "Epoch 567: loss improved from 1.66221 to 1.64552, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6455 - bpp: 0.8024 - mse: 1.0291e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8468 - bpp: 0.8429 - mse: 1.2255e-04\n",
      "Epoch 568: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.8468 - bpp: 0.8429 - mse: 1.2255e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6682 - bpp: 0.8038 - mse: 1.0551e-04\n",
      "Epoch 569: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6682 - bpp: 0.8038 - mse: 1.0551e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7865 - bpp: 0.8285 - mse: 1.1694e-04\n",
      "Epoch 570: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7865 - bpp: 0.8285 - mse: 1.1694e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0149 - bpp: 0.8785 - mse: 1.3871e-04\n",
      "Epoch 571: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.0149 - bpp: 0.8785 - mse: 1.3871e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8640 - bpp: 0.8414 - mse: 1.2483e-04\n",
      "Epoch 572: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.8640 - bpp: 0.8414 - mse: 1.2483e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9018 - bpp: 0.8668 - mse: 1.2635e-04\n",
      "Epoch 573: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.9018 - bpp: 0.8668 - mse: 1.2635e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8692 - bpp: 0.8639 - mse: 1.2271e-04\n",
      "Epoch 574: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8692 - bpp: 0.8639 - mse: 1.2271e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8338 - bpp: 0.8310 - mse: 1.2242e-04\n",
      "Epoch 575: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.8338 - bpp: 0.8310 - mse: 1.2242e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8082 - bpp: 0.8469 - mse: 1.1734e-04\n",
      "Epoch 576: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8082 - bpp: 0.8469 - mse: 1.1734e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7548 - bpp: 0.8189 - mse: 1.1425e-04\n",
      "Epoch 577: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7548 - bpp: 0.8189 - mse: 1.1425e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9535 - bpp: 0.8838 - mse: 1.3058e-04\n",
      "Epoch 578: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.9535 - bpp: 0.8838 - mse: 1.3058e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7871 - bpp: 0.8353 - mse: 1.1619e-04\n",
      "Epoch 579: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.7871 - bpp: 0.8353 - mse: 1.1619e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7471 - bpp: 0.8281 - mse: 1.1219e-04\n",
      "Epoch 580: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7471 - bpp: 0.8281 - mse: 1.1219e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8680 - bpp: 0.8619 - mse: 1.2282e-04\n",
      "Epoch 581: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.8680 - bpp: 0.8619 - mse: 1.2282e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8892 - bpp: 0.8523 - mse: 1.2657e-04\n",
      "Epoch 582: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8892 - bpp: 0.8523 - mse: 1.2657e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7322 - bpp: 0.8248 - mse: 1.1077e-04\n",
      "Epoch 583: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.7322 - bpp: 0.8248 - mse: 1.1077e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7100 - bpp: 0.8228 - mse: 1.0830e-04\n",
      "Epoch 584: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7100 - bpp: 0.8228 - mse: 1.0830e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0067 - bpp: 0.8891 - mse: 1.3643e-04\n",
      "Epoch 585: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.0067 - bpp: 0.8891 - mse: 1.3643e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8229 - bpp: 0.8587 - mse: 1.1771e-04\n",
      "Epoch 586: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.8229 - bpp: 0.8587 - mse: 1.1771e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8861 - bpp: 0.8522 - mse: 1.2621e-04\n",
      "Epoch 587: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.8861 - bpp: 0.8522 - mse: 1.2621e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7199 - bpp: 0.8265 - mse: 1.0905e-04\n",
      "Epoch 588: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7199 - bpp: 0.8265 - mse: 1.0905e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9062 - bpp: 0.8730 - mse: 1.2612e-04\n",
      "Epoch 589: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.9062 - bpp: 0.8730 - mse: 1.2612e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7609 - bpp: 0.8373 - mse: 1.1274e-04\n",
      "Epoch 590: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7609 - bpp: 0.8373 - mse: 1.1274e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6523 - bpp: 0.8075 - mse: 1.0313e-04\n",
      "Epoch 591: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6523 - bpp: 0.8075 - mse: 1.0313e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7583 - bpp: 0.8414 - mse: 1.1192e-04\n",
      "Epoch 592: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7583 - bpp: 0.8414 - mse: 1.1192e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8378 - bpp: 0.8419 - mse: 1.2157e-04\n",
      "Epoch 593: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8378 - bpp: 0.8419 - mse: 1.2157e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8975 - bpp: 0.8643 - mse: 1.2613e-04\n",
      "Epoch 594: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8975 - bpp: 0.8643 - mse: 1.2613e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8643 - bpp: 0.8424 - mse: 1.2475e-04\n",
      "Epoch 595: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.8643 - bpp: 0.8424 - mse: 1.2475e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8832 - bpp: 0.8129 - mse: 1.3065e-04\n",
      "Epoch 596: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.8832 - bpp: 0.8129 - mse: 1.3065e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7478 - bpp: 0.8473 - mse: 1.0993e-04\n",
      "Epoch 597: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7478 - bpp: 0.8473 - mse: 1.0993e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7827 - bpp: 0.8288 - mse: 1.1645e-04\n",
      "Epoch 598: loss did not improve from 1.64552\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.7827 - bpp: 0.8288 - mse: 1.1645e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6209 - bpp: 0.7920 - mse: 1.0119e-04\n",
      "Epoch 599: loss improved from 1.64552 to 1.62089, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6209 - bpp: 0.7920 - mse: 1.0119e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7219 - bpp: 0.8058 - mse: 1.1182e-04\n",
      "Epoch 600: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.7219 - bpp: 0.8058 - mse: 1.1182e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7824 - bpp: 0.8375 - mse: 1.1534e-04\n",
      "Epoch 601: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7824 - bpp: 0.8375 - mse: 1.1534e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8420 - bpp: 0.8574 - mse: 1.2019e-04\n",
      "Epoch 602: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 253ms/step - loss: 1.8420 - bpp: 0.8574 - mse: 1.2019e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3050 - bpp: 0.9122 - mse: 1.7002e-04\n",
      "Epoch 603: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.3050 - bpp: 0.9122 - mse: 1.7002e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7260 - bpp: 0.8193 - mse: 1.1067e-04\n",
      "Epoch 604: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.7260 - bpp: 0.8193 - mse: 1.1067e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6864 - bpp: 0.8178 - mse: 1.0603e-04\n",
      "Epoch 605: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6864 - bpp: 0.8178 - mse: 1.0603e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0582 - bpp: 0.8766 - mse: 1.4424e-04\n",
      "Epoch 606: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.0582 - bpp: 0.8766 - mse: 1.4424e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8038 - bpp: 0.8386 - mse: 1.1782e-04\n",
      "Epoch 607: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8038 - bpp: 0.8386 - mse: 1.1782e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7383 - bpp: 0.8249 - mse: 1.1149e-04\n",
      "Epoch 608: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7383 - bpp: 0.8249 - mse: 1.1149e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8041 - bpp: 0.8238 - mse: 1.1967e-04\n",
      "Epoch 609: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.8041 - bpp: 0.8238 - mse: 1.1967e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8011 - bpp: 0.8271 - mse: 1.1890e-04\n",
      "Epoch 610: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.8011 - bpp: 0.8271 - mse: 1.1890e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7549 - bpp: 0.8308 - mse: 1.1280e-04\n",
      "Epoch 611: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7549 - bpp: 0.8308 - mse: 1.1280e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7213 - bpp: 0.8188 - mse: 1.1016e-04\n",
      "Epoch 612: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7213 - bpp: 0.8188 - mse: 1.1016e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6669 - bpp: 0.8120 - mse: 1.0436e-04\n",
      "Epoch 613: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6669 - bpp: 0.8120 - mse: 1.0436e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8238 - bpp: 0.8520 - mse: 1.1863e-04\n",
      "Epoch 614: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.8238 - bpp: 0.8520 - mse: 1.1863e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6936 - bpp: 0.8177 - mse: 1.0692e-04\n",
      "Epoch 615: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.6936 - bpp: 0.8177 - mse: 1.0692e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7787 - bpp: 0.8355 - mse: 1.1513e-04\n",
      "Epoch 616: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7787 - bpp: 0.8355 - mse: 1.1513e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9111 - bpp: 0.8671 - mse: 1.2744e-04\n",
      "Epoch 617: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.9111 - bpp: 0.8671 - mse: 1.2744e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7585 - bpp: 0.8244 - mse: 1.1403e-04\n",
      "Epoch 618: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7585 - bpp: 0.8244 - mse: 1.1403e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9183 - bpp: 0.8589 - mse: 1.2931e-04\n",
      "Epoch 619: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.9183 - bpp: 0.8589 - mse: 1.2931e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8115 - bpp: 0.8501 - mse: 1.1736e-04\n",
      "Epoch 620: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8115 - bpp: 0.8501 - mse: 1.1736e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7381 - bpp: 0.8394 - mse: 1.0970e-04\n",
      "Epoch 621: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7381 - bpp: 0.8394 - mse: 1.0970e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7058 - bpp: 0.8171 - mse: 1.0849e-04\n",
      "Epoch 622: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7058 - bpp: 0.8171 - mse: 1.0849e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8941 - bpp: 0.8344 - mse: 1.2936e-04\n",
      "Epoch 623: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.8941 - bpp: 0.8344 - mse: 1.2936e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7854 - bpp: 0.8370 - mse: 1.1577e-04\n",
      "Epoch 624: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7854 - bpp: 0.8370 - mse: 1.1577e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7546 - bpp: 0.8238 - mse: 1.1362e-04\n",
      "Epoch 625: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7546 - bpp: 0.8238 - mse: 1.1362e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7819 - bpp: 0.8325 - mse: 1.1590e-04\n",
      "Epoch 626: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7819 - bpp: 0.8325 - mse: 1.1590e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6531 - bpp: 0.7961 - mse: 1.0463e-04\n",
      "Epoch 627: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6531 - bpp: 0.7961 - mse: 1.0463e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7578 - bpp: 0.8318 - mse: 1.1303e-04\n",
      "Epoch 628: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.7578 - bpp: 0.8318 - mse: 1.1303e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7314 - bpp: 0.8223 - mse: 1.1097e-04\n",
      "Epoch 629: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7314 - bpp: 0.8223 - mse: 1.1097e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8097 - bpp: 0.8298 - mse: 1.1962e-04\n",
      "Epoch 630: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8097 - bpp: 0.8298 - mse: 1.1962e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6308 - bpp: 0.8036 - mse: 1.0098e-04\n",
      "Epoch 631: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.6308 - bpp: 0.8036 - mse: 1.0098e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7861 - bpp: 0.8262 - mse: 1.1718e-04\n",
      "Epoch 632: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7861 - bpp: 0.8262 - mse: 1.1718e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8035 - bpp: 0.8345 - mse: 1.1828e-04\n",
      "Epoch 633: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.8035 - bpp: 0.8345 - mse: 1.1828e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6586 - bpp: 0.8019 - mse: 1.0458e-04\n",
      "Epoch 634: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6586 - bpp: 0.8019 - mse: 1.0458e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6793 - bpp: 0.8081 - mse: 1.0635e-04\n",
      "Epoch 635: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6793 - bpp: 0.8081 - mse: 1.0635e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6865 - bpp: 0.8061 - mse: 1.0746e-04\n",
      "Epoch 636: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.6865 - bpp: 0.8061 - mse: 1.0746e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8016 - bpp: 0.8476 - mse: 1.1645e-04\n",
      "Epoch 637: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.8016 - bpp: 0.8476 - mse: 1.1645e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9616 - bpp: 0.8648 - mse: 1.3388e-04\n",
      "Epoch 638: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.9616 - bpp: 0.8648 - mse: 1.3388e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8151 - bpp: 0.8497 - mse: 1.1785e-04\n",
      "Epoch 639: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8151 - bpp: 0.8497 - mse: 1.1785e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0415 - bpp: 0.9003 - mse: 1.3931e-04\n",
      "Epoch 640: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 2.0415 - bpp: 0.9003 - mse: 1.3931e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7008 - bpp: 0.8170 - mse: 1.0788e-04\n",
      "Epoch 641: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.7008 - bpp: 0.8170 - mse: 1.0788e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6296 - bpp: 0.8116 - mse: 9.9849e-05\n",
      "Epoch 642: loss did not improve from 1.62089\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.6296 - bpp: 0.8116 - mse: 9.9849e-05\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5668 - bpp: 0.7847 - mse: 9.5468e-05\n",
      "Epoch 643: loss improved from 1.62089 to 1.56675, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.5668 - bpp: 0.7847 - mse: 9.5468e-05\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7599 - bpp: 0.8243 - mse: 1.1420e-04\n",
      "Epoch 644: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7599 - bpp: 0.8243 - mse: 1.1420e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8326 - bpp: 0.8437 - mse: 1.2071e-04\n",
      "Epoch 645: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.8326 - bpp: 0.8437 - mse: 1.2071e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6510 - bpp: 0.8098 - mse: 1.0268e-04\n",
      "Epoch 646: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6510 - bpp: 0.8098 - mse: 1.0268e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8060 - bpp: 0.8458 - mse: 1.1721e-04\n",
      "Epoch 647: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8060 - bpp: 0.8458 - mse: 1.1721e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7777 - bpp: 0.8197 - mse: 1.1694e-04\n",
      "Epoch 648: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.7777 - bpp: 0.8197 - mse: 1.1694e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6489 - bpp: 0.8004 - mse: 1.0358e-04\n",
      "Epoch 649: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6489 - bpp: 0.8004 - mse: 1.0358e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8344 - bpp: 0.8379 - mse: 1.2164e-04\n",
      "Epoch 650: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8344 - bpp: 0.8379 - mse: 1.2164e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8055 - bpp: 0.8388 - mse: 1.1800e-04\n",
      "Epoch 651: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8055 - bpp: 0.8388 - mse: 1.1800e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7193 - bpp: 0.8085 - mse: 1.1119e-04\n",
      "Epoch 652: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7193 - bpp: 0.8085 - mse: 1.1119e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7754 - bpp: 0.8255 - mse: 1.1595e-04\n",
      "Epoch 653: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7754 - bpp: 0.8255 - mse: 1.1595e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7933 - bpp: 0.8348 - mse: 1.1701e-04\n",
      "Epoch 654: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7933 - bpp: 0.8348 - mse: 1.1701e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6870 - bpp: 0.8186 - mse: 1.0602e-04\n",
      "Epoch 655: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6870 - bpp: 0.8186 - mse: 1.0602e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7176 - bpp: 0.8257 - mse: 1.0887e-04\n",
      "Epoch 656: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7176 - bpp: 0.8257 - mse: 1.0887e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7936 - bpp: 0.8351 - mse: 1.1701e-04\n",
      "Epoch 657: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7936 - bpp: 0.8351 - mse: 1.1701e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6746 - bpp: 0.7976 - mse: 1.0706e-04\n",
      "Epoch 658: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6746 - bpp: 0.7976 - mse: 1.0706e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6650 - bpp: 0.8033 - mse: 1.0519e-04\n",
      "Epoch 659: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6650 - bpp: 0.8033 - mse: 1.0519e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8376 - bpp: 0.8601 - mse: 1.1931e-04\n",
      "Epoch 660: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.8376 - bpp: 0.8601 - mse: 1.1931e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8280 - bpp: 0.8444 - mse: 1.2007e-04\n",
      "Epoch 661: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8280 - bpp: 0.8444 - mse: 1.2007e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7318 - bpp: 0.8163 - mse: 1.1176e-04\n",
      "Epoch 662: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7318 - bpp: 0.8163 - mse: 1.1176e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7735 - bpp: 0.8252 - mse: 1.1576e-04\n",
      "Epoch 663: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7735 - bpp: 0.8252 - mse: 1.1576e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6773 - bpp: 0.8136 - mse: 1.0543e-04\n",
      "Epoch 664: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6773 - bpp: 0.8136 - mse: 1.0543e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6347 - bpp: 0.7896 - mse: 1.0315e-04\n",
      "Epoch 665: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.6347 - bpp: 0.7896 - mse: 1.0315e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8484 - bpp: 0.8331 - mse: 1.2394e-04\n",
      "Epoch 666: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.8484 - bpp: 0.8331 - mse: 1.2394e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8106 - bpp: 0.8253 - mse: 1.2028e-04\n",
      "Epoch 667: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8106 - bpp: 0.8253 - mse: 1.2028e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9454 - bpp: 0.8547 - mse: 1.3315e-04\n",
      "Epoch 668: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.9454 - bpp: 0.8547 - mse: 1.3315e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6210 - bpp: 0.8014 - mse: 1.0005e-04\n",
      "Epoch 669: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.6210 - bpp: 0.8014 - mse: 1.0005e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6046 - bpp: 0.7871 - mse: 9.9787e-05\n",
      "Epoch 670: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6046 - bpp: 0.7871 - mse: 9.9787e-05\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6331 - bpp: 0.7984 - mse: 1.0189e-04\n",
      "Epoch 671: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6331 - bpp: 0.7984 - mse: 1.0189e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7080 - bpp: 0.8240 - mse: 1.0791e-04\n",
      "Epoch 672: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.7080 - bpp: 0.8240 - mse: 1.0791e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7781 - bpp: 0.8223 - mse: 1.1667e-04\n",
      "Epoch 673: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7781 - bpp: 0.8223 - mse: 1.1667e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7343 - bpp: 0.8150 - mse: 1.1221e-04\n",
      "Epoch 674: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7343 - bpp: 0.8150 - mse: 1.1221e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7443 - bpp: 0.8200 - mse: 1.1283e-04\n",
      "Epoch 675: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7443 - bpp: 0.8200 - mse: 1.1283e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8025 - bpp: 0.8411 - mse: 1.1736e-04\n",
      "Epoch 676: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.8025 - bpp: 0.8411 - mse: 1.1736e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7373 - bpp: 0.8234 - mse: 1.1156e-04\n",
      "Epoch 677: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7373 - bpp: 0.8234 - mse: 1.1156e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6485 - bpp: 0.7937 - mse: 1.0434e-04\n",
      "Epoch 678: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 1.6485 - bpp: 0.7937 - mse: 1.0434e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9275 - bpp: 0.8646 - mse: 1.2974e-04\n",
      "Epoch 679: loss did not improve from 1.56675\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.9275 - bpp: 0.8646 - mse: 1.2974e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5490 - bpp: 0.7872 - mse: 9.2989e-05\n",
      "Epoch 680: loss improved from 1.56675 to 1.54897, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5490 - bpp: 0.7872 - mse: 9.2989e-05\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8086 - bpp: 0.8391 - mse: 1.1834e-04\n",
      "Epoch 681: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.8086 - bpp: 0.8391 - mse: 1.1834e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8200 - bpp: 0.8286 - mse: 1.2102e-04\n",
      "Epoch 682: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8200 - bpp: 0.8286 - mse: 1.2102e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9570 - bpp: 0.8426 - mse: 1.3603e-04\n",
      "Epoch 683: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.9570 - bpp: 0.8426 - mse: 1.3603e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7380 - bpp: 0.8281 - mse: 1.1107e-04\n",
      "Epoch 684: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7380 - bpp: 0.8281 - mse: 1.1107e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6308 - bpp: 0.8065 - mse: 1.0062e-04\n",
      "Epoch 685: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.6308 - bpp: 0.8065 - mse: 1.0062e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6787 - bpp: 0.8008 - mse: 1.0716e-04\n",
      "Epoch 686: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.6787 - bpp: 0.8008 - mse: 1.0716e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7128 - bpp: 0.8172 - mse: 1.0932e-04\n",
      "Epoch 687: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7128 - bpp: 0.8172 - mse: 1.0932e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.7956 - mse: 1.0823e-04\n",
      "Epoch 688: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6823 - bpp: 0.7956 - mse: 1.0823e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7804 - bpp: 0.8143 - mse: 1.1793e-04\n",
      "Epoch 689: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7804 - bpp: 0.8143 - mse: 1.1793e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7159 - bpp: 0.8133 - mse: 1.1018e-04\n",
      "Epoch 690: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.7159 - bpp: 0.8133 - mse: 1.1018e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7582 - bpp: 0.8360 - mse: 1.1258e-04\n",
      "Epoch 691: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7582 - bpp: 0.8360 - mse: 1.1258e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5617 - bpp: 0.7890 - mse: 9.4324e-05\n",
      "Epoch 692: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5617 - bpp: 0.7890 - mse: 9.4324e-05\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6099 - bpp: 0.7957 - mse: 9.9392e-05\n",
      "Epoch 693: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6099 - bpp: 0.7957 - mse: 9.9392e-05\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7603 - bpp: 0.8188 - mse: 1.1493e-04\n",
      "Epoch 694: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7603 - bpp: 0.8188 - mse: 1.1493e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8309 - bpp: 0.8563 - mse: 1.1897e-04\n",
      "Epoch 695: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8309 - bpp: 0.8563 - mse: 1.1897e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7529 - bpp: 0.8228 - mse: 1.1353e-04\n",
      "Epoch 696: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7529 - bpp: 0.8228 - mse: 1.1353e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7226 - bpp: 0.8256 - mse: 1.0950e-04\n",
      "Epoch 697: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7226 - bpp: 0.8256 - mse: 1.0950e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7152 - bpp: 0.8002 - mse: 1.1169e-04\n",
      "Epoch 698: loss did not improve from 1.54897\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7152 - bpp: 0.8002 - mse: 1.1169e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4933 - bpp: 0.7537 - mse: 9.0279e-05\n",
      "Epoch 699: loss improved from 1.54897 to 1.49329, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4933 - bpp: 0.7537 - mse: 9.0279e-05\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6573 - bpp: 0.8024 - mse: 1.0435e-04\n",
      "Epoch 700: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6573 - bpp: 0.8024 - mse: 1.0435e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7616 - bpp: 0.8236 - mse: 1.1451e-04\n",
      "Epoch 701: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7616 - bpp: 0.8236 - mse: 1.1451e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8429 - bpp: 0.8252 - mse: 1.2422e-04\n",
      "Epoch 702: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.8429 - bpp: 0.8252 - mse: 1.2422e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5686 - bpp: 0.7746 - mse: 9.6928e-05\n",
      "Epoch 703: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5686 - bpp: 0.7746 - mse: 9.6928e-05\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6992 - bpp: 0.8080 - mse: 1.0878e-04\n",
      "Epoch 704: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6992 - bpp: 0.8080 - mse: 1.0878e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7485 - bpp: 0.8261 - mse: 1.1259e-04\n",
      "Epoch 705: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7485 - bpp: 0.8261 - mse: 1.1259e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7090 - bpp: 0.8211 - mse: 1.0838e-04\n",
      "Epoch 706: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.7090 - bpp: 0.8211 - mse: 1.0838e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9688 - bpp: 0.8679 - mse: 1.3439e-04\n",
      "Epoch 707: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.9688 - bpp: 0.8679 - mse: 1.3439e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7918 - bpp: 0.8284 - mse: 1.1760e-04\n",
      "Epoch 708: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7918 - bpp: 0.8284 - mse: 1.1760e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6438 - bpp: 0.8163 - mse: 1.0100e-04\n",
      "Epoch 709: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6438 - bpp: 0.8163 - mse: 1.0100e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6232 - bpp: 0.7907 - mse: 1.0162e-04\n",
      "Epoch 710: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6232 - bpp: 0.7907 - mse: 1.0162e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7725 - bpp: 0.8346 - mse: 1.1450e-04\n",
      "Epoch 711: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.7725 - bpp: 0.8346 - mse: 1.1450e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.0929 - bpp: 0.8702 - mse: 1.4925e-04\n",
      "Epoch 712: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.0929 - bpp: 0.8702 - mse: 1.4925e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8332 - bpp: 0.8420 - mse: 1.2100e-04\n",
      "Epoch 713: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8332 - bpp: 0.8420 - mse: 1.2100e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7302 - bpp: 0.8139 - mse: 1.1186e-04\n",
      "Epoch 714: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7302 - bpp: 0.8139 - mse: 1.1186e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7226 - bpp: 0.8305 - mse: 1.0890e-04\n",
      "Epoch 715: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7226 - bpp: 0.8305 - mse: 1.0890e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7787 - bpp: 0.8256 - mse: 1.1635e-04\n",
      "Epoch 716: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7787 - bpp: 0.8256 - mse: 1.1635e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6468 - bpp: 0.8135 - mse: 1.0172e-04\n",
      "Epoch 717: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6468 - bpp: 0.8135 - mse: 1.0172e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6954 - bpp: 0.8178 - mse: 1.0713e-04\n",
      "Epoch 718: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6954 - bpp: 0.8178 - mse: 1.0713e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7149 - bpp: 0.8332 - mse: 1.0763e-04\n",
      "Epoch 719: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7149 - bpp: 0.8332 - mse: 1.0763e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9360 - bpp: 0.8673 - mse: 1.3046e-04\n",
      "Epoch 720: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.9360 - bpp: 0.8673 - mse: 1.3046e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5860 - bpp: 0.7724 - mse: 9.9315e-05\n",
      "Epoch 721: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.5860 - bpp: 0.7724 - mse: 9.9315e-05\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8238 - bpp: 0.8338 - mse: 1.2084e-04\n",
      "Epoch 722: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.8238 - bpp: 0.8338 - mse: 1.2084e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7080 - bpp: 0.8186 - mse: 1.0857e-04\n",
      "Epoch 723: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7080 - bpp: 0.8186 - mse: 1.0857e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8334 - bpp: 0.8564 - mse: 1.1926e-04\n",
      "Epoch 724: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.8334 - bpp: 0.8564 - mse: 1.1926e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8344 - bpp: 0.8561 - mse: 1.1941e-04\n",
      "Epoch 725: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 59s 292ms/step - loss: 1.8344 - bpp: 0.8561 - mse: 1.1941e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6617 - bpp: 0.7981 - mse: 1.0542e-04\n",
      "Epoch 726: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6617 - bpp: 0.7981 - mse: 1.0542e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6557 - bpp: 0.8078 - mse: 1.0350e-04\n",
      "Epoch 727: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6557 - bpp: 0.8078 - mse: 1.0350e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6489 - bpp: 0.8129 - mse: 1.0205e-04\n",
      "Epoch 728: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6489 - bpp: 0.8129 - mse: 1.0205e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8090 - bpp: 0.8319 - mse: 1.1928e-04\n",
      "Epoch 729: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8090 - bpp: 0.8319 - mse: 1.1928e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6193 - bpp: 0.7994 - mse: 1.0009e-04\n",
      "Epoch 730: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.6193 - bpp: 0.7994 - mse: 1.0009e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7805 - bpp: 0.8412 - mse: 1.1466e-04\n",
      "Epoch 731: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7805 - bpp: 0.8412 - mse: 1.1466e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7656 - bpp: 0.8353 - mse: 1.1355e-04\n",
      "Epoch 732: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7656 - bpp: 0.8353 - mse: 1.1355e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6366 - bpp: 0.8019 - mse: 1.0190e-04\n",
      "Epoch 733: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6366 - bpp: 0.8019 - mse: 1.0190e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8594 - bpp: 0.8481 - mse: 1.2345e-04\n",
      "Epoch 734: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.8594 - bpp: 0.8481 - mse: 1.2345e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7004 - bpp: 0.8322 - mse: 1.0599e-04\n",
      "Epoch 735: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7004 - bpp: 0.8322 - mse: 1.0599e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7057 - bpp: 0.8187 - mse: 1.0827e-04\n",
      "Epoch 736: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 1.7057 - bpp: 0.8187 - mse: 1.0827e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5724 - bpp: 0.7822 - mse: 9.6464e-05\n",
      "Epoch 737: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5724 - bpp: 0.7822 - mse: 9.6464e-05\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7230 - bpp: 0.8137 - mse: 1.1099e-04\n",
      "Epoch 738: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7230 - bpp: 0.8137 - mse: 1.1099e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7606 - bpp: 0.8187 - mse: 1.1497e-04\n",
      "Epoch 739: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 56s 274ms/step - loss: 1.7606 - bpp: 0.8187 - mse: 1.1497e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7695 - bpp: 0.8321 - mse: 1.1443e-04\n",
      "Epoch 740: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.7695 - bpp: 0.8321 - mse: 1.1443e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7696 - bpp: 0.8372 - mse: 1.1382e-04\n",
      "Epoch 741: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7696 - bpp: 0.8372 - mse: 1.1382e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6303 - bpp: 0.8015 - mse: 1.0116e-04\n",
      "Epoch 742: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6303 - bpp: 0.8015 - mse: 1.0116e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6627 - bpp: 0.8075 - mse: 1.0440e-04\n",
      "Epoch 743: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6627 - bpp: 0.8075 - mse: 1.0440e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6639 - bpp: 0.8189 - mse: 1.0315e-04\n",
      "Epoch 744: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6639 - bpp: 0.8189 - mse: 1.0315e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7407 - bpp: 0.8361 - mse: 1.1042e-04\n",
      "Epoch 745: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7407 - bpp: 0.8361 - mse: 1.1042e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7898 - bpp: 0.8353 - mse: 1.1652e-04\n",
      "Epoch 746: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7898 - bpp: 0.8353 - mse: 1.1652e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8017 - bpp: 0.8527 - mse: 1.1584e-04\n",
      "Epoch 747: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.8017 - bpp: 0.8527 - mse: 1.1584e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6878 - bpp: 0.8227 - mse: 1.0560e-04\n",
      "Epoch 748: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6878 - bpp: 0.8227 - mse: 1.0560e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8319 - bpp: 0.8430 - mse: 1.2072e-04\n",
      "Epoch 749: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.8319 - bpp: 0.8430 - mse: 1.2072e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7045 - bpp: 0.8129 - mse: 1.0884e-04\n",
      "Epoch 750: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.7045 - bpp: 0.8129 - mse: 1.0884e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6611 - bpp: 0.8140 - mse: 1.0341e-04\n",
      "Epoch 751: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6611 - bpp: 0.8140 - mse: 1.0341e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6196 - bpp: 0.8065 - mse: 9.9256e-05\n",
      "Epoch 752: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.6196 - bpp: 0.8065 - mse: 9.9256e-05\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6400 - bpp: 0.7914 - mse: 1.0359e-04\n",
      "Epoch 753: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6400 - bpp: 0.7914 - mse: 1.0359e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5576 - bpp: 0.7855 - mse: 9.4252e-05\n",
      "Epoch 754: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.5576 - bpp: 0.7855 - mse: 9.4252e-05\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6249 - bpp: 0.8073 - mse: 9.9798e-05\n",
      "Epoch 755: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6249 - bpp: 0.8073 - mse: 9.9798e-05\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7102 - bpp: 0.8257 - mse: 1.0797e-04\n",
      "Epoch 756: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7102 - bpp: 0.8257 - mse: 1.0797e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7016 - bpp: 0.8082 - mse: 1.0907e-04\n",
      "Epoch 757: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.7016 - bpp: 0.8082 - mse: 1.0907e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6792 - bpp: 0.8073 - mse: 1.0644e-04\n",
      "Epoch 758: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6792 - bpp: 0.8073 - mse: 1.0644e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7369 - bpp: 0.8112 - mse: 1.1299e-04\n",
      "Epoch 759: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.7369 - bpp: 0.8112 - mse: 1.1299e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7333 - bpp: 0.8319 - mse: 1.1004e-04\n",
      "Epoch 760: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.7333 - bpp: 0.8319 - mse: 1.1004e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8025 - bpp: 0.8503 - mse: 1.1623e-04\n",
      "Epoch 761: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.8025 - bpp: 0.8503 - mse: 1.1623e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7699 - bpp: 0.8223 - mse: 1.1568e-04\n",
      "Epoch 762: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7699 - bpp: 0.8223 - mse: 1.1568e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6378 - bpp: 0.8069 - mse: 1.0142e-04\n",
      "Epoch 763: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6378 - bpp: 0.8069 - mse: 1.0142e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6661 - bpp: 0.8145 - mse: 1.0395e-04\n",
      "Epoch 764: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6661 - bpp: 0.8145 - mse: 1.0395e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5805 - bpp: 0.7843 - mse: 9.7192e-05\n",
      "Epoch 765: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.5805 - bpp: 0.7843 - mse: 9.7192e-05\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9806 - bpp: 0.8641 - mse: 1.3628e-04\n",
      "Epoch 766: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.9806 - bpp: 0.8641 - mse: 1.3628e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6879 - bpp: 0.8023 - mse: 1.0810e-04\n",
      "Epoch 767: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 264ms/step - loss: 1.6879 - bpp: 0.8023 - mse: 1.0810e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7917 - bpp: 0.8389 - mse: 1.1632e-04\n",
      "Epoch 768: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7917 - bpp: 0.8389 - mse: 1.1632e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7766 - bpp: 0.8323 - mse: 1.1528e-04\n",
      "Epoch 769: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7766 - bpp: 0.8323 - mse: 1.1528e-04\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7718 - bpp: 0.8251 - mse: 1.1557e-04\n",
      "Epoch 770: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7718 - bpp: 0.8251 - mse: 1.1557e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8115 - bpp: 0.8384 - mse: 1.1879e-04\n",
      "Epoch 771: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.8115 - bpp: 0.8384 - mse: 1.1879e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7391 - bpp: 0.8179 - mse: 1.1246e-04\n",
      "Epoch 772: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.7391 - bpp: 0.8179 - mse: 1.1246e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5849 - bpp: 0.7822 - mse: 9.7983e-05\n",
      "Epoch 773: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.5849 - bpp: 0.7822 - mse: 9.7983e-05\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6204 - bpp: 0.8084 - mse: 9.9118e-05\n",
      "Epoch 774: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.6204 - bpp: 0.8084 - mse: 9.9118e-05\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8440 - bpp: 0.8254 - mse: 1.2434e-04\n",
      "Epoch 775: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.8440 - bpp: 0.8254 - mse: 1.2434e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5179 - bpp: 0.7806 - mse: 8.9998e-05\n",
      "Epoch 776: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5179 - bpp: 0.7806 - mse: 8.9998e-05\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6022 - bpp: 0.7947 - mse: 9.8570e-05\n",
      "Epoch 777: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 264ms/step - loss: 1.6022 - bpp: 0.7947 - mse: 9.8570e-05\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6472 - bpp: 0.7950 - mse: 1.0403e-04\n",
      "Epoch 778: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6472 - bpp: 0.7950 - mse: 1.0403e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5936 - bpp: 0.8015 - mse: 9.6699e-05\n",
      "Epoch 779: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5936 - bpp: 0.8015 - mse: 9.6699e-05\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6623 - bpp: 0.8082 - mse: 1.0427e-04\n",
      "Epoch 780: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6623 - bpp: 0.8082 - mse: 1.0427e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6605 - bpp: 0.7972 - mse: 1.0539e-04\n",
      "Epoch 781: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.6605 - bpp: 0.7972 - mse: 1.0539e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7263 - bpp: 0.8223 - mse: 1.1035e-04\n",
      "Epoch 782: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7263 - bpp: 0.8223 - mse: 1.1035e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6537 - bpp: 0.8049 - mse: 1.0361e-04\n",
      "Epoch 783: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6537 - bpp: 0.8049 - mse: 1.0361e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7247 - bpp: 0.8120 - mse: 1.1141e-04\n",
      "Epoch 784: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.7247 - bpp: 0.8120 - mse: 1.1141e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8454 - bpp: 0.8518 - mse: 1.2129e-04\n",
      "Epoch 785: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.8454 - bpp: 0.8518 - mse: 1.2129e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5307 - bpp: 0.7675 - mse: 9.3170e-05\n",
      "Epoch 786: loss did not improve from 1.49329\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5307 - bpp: 0.7675 - mse: 9.3170e-05\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4932 - bpp: 0.7783 - mse: 8.7260e-05\n",
      "Epoch 787: loss improved from 1.49329 to 1.49317, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.4932 - bpp: 0.7783 - mse: 8.7260e-05\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5985 - bpp: 0.8027 - mse: 9.7143e-05\n",
      "Epoch 788: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5985 - bpp: 0.8027 - mse: 9.7143e-05\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7440 - bpp: 0.8276 - mse: 1.1186e-04\n",
      "Epoch 789: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.7440 - bpp: 0.8276 - mse: 1.1186e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6764 - bpp: 0.8049 - mse: 1.0638e-04\n",
      "Epoch 790: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6764 - bpp: 0.8049 - mse: 1.0638e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9668 - bpp: 0.8834 - mse: 1.3225e-04\n",
      "Epoch 791: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.9668 - bpp: 0.8834 - mse: 1.3225e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7328 - bpp: 0.8281 - mse: 1.1043e-04\n",
      "Epoch 792: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.7328 - bpp: 0.8281 - mse: 1.1043e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6834 - bpp: 0.7992 - mse: 1.0793e-04\n",
      "Epoch 793: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6834 - bpp: 0.7992 - mse: 1.0793e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6627 - bpp: 0.7969 - mse: 1.0568e-04\n",
      "Epoch 794: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6627 - bpp: 0.7969 - mse: 1.0568e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.9563 - bpp: 0.8557 - mse: 1.3436e-04\n",
      "Epoch 795: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.9563 - bpp: 0.8557 - mse: 1.3436e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6556 - bpp: 0.8100 - mse: 1.0323e-04\n",
      "Epoch 796: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6556 - bpp: 0.8100 - mse: 1.0323e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8284 - bpp: 0.8284 - mse: 1.2207e-04\n",
      "Epoch 797: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.8284 - bpp: 0.8284 - mse: 1.2207e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6713 - bpp: 0.8027 - mse: 1.0602e-04\n",
      "Epoch 798: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6713 - bpp: 0.8027 - mse: 1.0602e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5671 - bpp: 0.7909 - mse: 9.4745e-05\n",
      "Epoch 799: loss did not improve from 1.49317\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5671 - bpp: 0.7909 - mse: 9.4745e-05\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4848 - bpp: 0.7556 - mse: 8.9019e-05\n",
      "Epoch 800: loss improved from 1.49317 to 1.48480, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.4848 - bpp: 0.7556 - mse: 8.9019e-05\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6188 - bpp: 0.7967 - mse: 1.0036e-04\n",
      "Epoch 801: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6188 - bpp: 0.7967 - mse: 1.0036e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6030 - bpp: 0.7866 - mse: 9.9658e-05\n",
      "Epoch 802: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6030 - bpp: 0.7866 - mse: 9.9658e-05\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6184 - bpp: 0.8059 - mse: 9.9180e-05\n",
      "Epoch 803: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6184 - bpp: 0.8059 - mse: 9.9180e-05\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6892 - bpp: 0.8097 - mse: 1.0736e-04\n",
      "Epoch 804: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6892 - bpp: 0.8097 - mse: 1.0736e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6764 - bpp: 0.7982 - mse: 1.0720e-04\n",
      "Epoch 805: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.6764 - bpp: 0.7982 - mse: 1.0720e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6965 - bpp: 0.8197 - mse: 1.0703e-04\n",
      "Epoch 806: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6965 - bpp: 0.8197 - mse: 1.0703e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6543 - bpp: 0.7903 - mse: 1.0546e-04\n",
      "Epoch 807: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6543 - bpp: 0.7903 - mse: 1.0546e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6892 - bpp: 0.8128 - mse: 1.0697e-04\n",
      "Epoch 808: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6892 - bpp: 0.8128 - mse: 1.0697e-04\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6796 - bpp: 0.8093 - mse: 1.0625e-04\n",
      "Epoch 809: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6796 - bpp: 0.8093 - mse: 1.0625e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7756 - bpp: 0.8363 - mse: 1.1466e-04\n",
      "Epoch 810: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7756 - bpp: 0.8363 - mse: 1.1466e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8004 - bpp: 0.8490 - mse: 1.1613e-04\n",
      "Epoch 811: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.8004 - bpp: 0.8490 - mse: 1.1613e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7125 - bpp: 0.8294 - mse: 1.0780e-04\n",
      "Epoch 812: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7125 - bpp: 0.8294 - mse: 1.0780e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7121 - bpp: 0.8144 - mse: 1.0958e-04\n",
      "Epoch 813: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 254ms/step - loss: 1.7121 - bpp: 0.8144 - mse: 1.0958e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7269 - bpp: 0.8177 - mse: 1.1099e-04\n",
      "Epoch 814: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.7269 - bpp: 0.8177 - mse: 1.1099e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7800 - bpp: 0.8411 - mse: 1.1461e-04\n",
      "Epoch 815: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7800 - bpp: 0.8411 - mse: 1.1461e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6376 - bpp: 0.8011 - mse: 1.0211e-04\n",
      "Epoch 816: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6376 - bpp: 0.8011 - mse: 1.0211e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6616 - bpp: 0.8141 - mse: 1.0345e-04\n",
      "Epoch 817: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6616 - bpp: 0.8141 - mse: 1.0345e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7552 - bpp: 0.8067 - mse: 1.1578e-04\n",
      "Epoch 818: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7552 - bpp: 0.8067 - mse: 1.1578e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6753 - bpp: 0.7944 - mse: 1.0753e-04\n",
      "Epoch 819: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.6753 - bpp: 0.7944 - mse: 1.0753e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6023 - bpp: 0.7849 - mse: 9.9782e-05\n",
      "Epoch 820: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6023 - bpp: 0.7849 - mse: 9.9782e-05\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5777 - bpp: 0.7840 - mse: 9.6892e-05\n",
      "Epoch 821: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.5777 - bpp: 0.7840 - mse: 9.6892e-05\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6009 - bpp: 0.7847 - mse: 9.9633e-05\n",
      "Epoch 822: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6009 - bpp: 0.7847 - mse: 9.9633e-05\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6111 - bpp: 0.7889 - mse: 1.0037e-04\n",
      "Epoch 823: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6111 - bpp: 0.7889 - mse: 1.0037e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6565 - bpp: 0.7999 - mse: 1.0457e-04\n",
      "Epoch 824: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.6565 - bpp: 0.7999 - mse: 1.0457e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5365 - bpp: 0.7604 - mse: 9.4741e-05\n",
      "Epoch 825: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5365 - bpp: 0.7604 - mse: 9.4741e-05\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6935 - bpp: 0.8053 - mse: 1.0843e-04\n",
      "Epoch 826: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6935 - bpp: 0.8053 - mse: 1.0843e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6202 - bpp: 0.7849 - mse: 1.0197e-04\n",
      "Epoch 827: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6202 - bpp: 0.7849 - mse: 1.0197e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6473 - bpp: 0.7976 - mse: 1.0373e-04\n",
      "Epoch 828: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6473 - bpp: 0.7976 - mse: 1.0373e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5463 - bpp: 0.7731 - mse: 9.4387e-05\n",
      "Epoch 829: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5463 - bpp: 0.7731 - mse: 9.4387e-05\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6174 - bpp: 0.7883 - mse: 1.0122e-04\n",
      "Epoch 830: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6174 - bpp: 0.7883 - mse: 1.0122e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7594 - bpp: 0.8222 - mse: 1.1440e-04\n",
      "Epoch 831: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.7594 - bpp: 0.8222 - mse: 1.1440e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6297 - bpp: 0.7861 - mse: 1.0299e-04\n",
      "Epoch 832: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6297 - bpp: 0.7861 - mse: 1.0299e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5290 - bpp: 0.7769 - mse: 9.1803e-05\n",
      "Epoch 833: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.5290 - bpp: 0.7769 - mse: 9.1803e-05\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6179 - bpp: 0.7873 - mse: 1.0139e-04\n",
      "Epoch 834: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.6179 - bpp: 0.7873 - mse: 1.0139e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8271 - bpp: 0.8353 - mse: 1.2107e-04\n",
      "Epoch 835: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.8271 - bpp: 0.8353 - mse: 1.2107e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5181 - bpp: 0.7636 - mse: 9.2109e-05\n",
      "Epoch 836: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.5181 - bpp: 0.7636 - mse: 9.2109e-05\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5381 - bpp: 0.7807 - mse: 9.2455e-05\n",
      "Epoch 837: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5381 - bpp: 0.7807 - mse: 9.2455e-05\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8408 - bpp: 0.8457 - mse: 1.2147e-04\n",
      "Epoch 838: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.8408 - bpp: 0.8457 - mse: 1.2147e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5539 - bpp: 0.7635 - mse: 9.6481e-05\n",
      "Epoch 839: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5539 - bpp: 0.7635 - mse: 9.6481e-05\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6797 - bpp: 0.7940 - mse: 1.0812e-04\n",
      "Epoch 840: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.6797 - bpp: 0.7940 - mse: 1.0812e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6319 - bpp: 0.7964 - mse: 1.0199e-04\n",
      "Epoch 841: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6319 - bpp: 0.7964 - mse: 1.0199e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5196 - bpp: 0.7645 - mse: 9.2184e-05\n",
      "Epoch 842: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5196 - bpp: 0.7645 - mse: 9.2184e-05\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6060 - bpp: 0.7973 - mse: 9.8715e-05\n",
      "Epoch 843: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6060 - bpp: 0.7973 - mse: 9.8715e-05\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8111 - bpp: 0.8380 - mse: 1.1878e-04\n",
      "Epoch 844: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.8111 - bpp: 0.8380 - mse: 1.1878e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6826 - bpp: 0.8084 - mse: 1.0672e-04\n",
      "Epoch 845: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6826 - bpp: 0.8084 - mse: 1.0672e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6582 - bpp: 0.8046 - mse: 1.0420e-04\n",
      "Epoch 846: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 1.6582 - bpp: 0.8046 - mse: 1.0420e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6088 - bpp: 0.7870 - mse: 1.0032e-04\n",
      "Epoch 847: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6088 - bpp: 0.7870 - mse: 1.0032e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6729 - bpp: 0.8093 - mse: 1.0542e-04\n",
      "Epoch 848: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6729 - bpp: 0.8093 - mse: 1.0542e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6487 - bpp: 0.7961 - mse: 1.0407e-04\n",
      "Epoch 849: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6487 - bpp: 0.7961 - mse: 1.0407e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6792 - bpp: 0.8155 - mse: 1.0543e-04\n",
      "Epoch 850: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 1.6792 - bpp: 0.8155 - mse: 1.0543e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6390 - bpp: 0.7935 - mse: 1.0321e-04\n",
      "Epoch 851: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6390 - bpp: 0.7935 - mse: 1.0321e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6778 - bpp: 0.7975 - mse: 1.0746e-04\n",
      "Epoch 852: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6778 - bpp: 0.7975 - mse: 1.0746e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5753 - bpp: 0.7862 - mse: 9.6326e-05\n",
      "Epoch 853: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5753 - bpp: 0.7862 - mse: 9.6326e-05\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7238 - bpp: 0.8071 - mse: 1.1190e-04\n",
      "Epoch 854: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 1.7238 - bpp: 0.8071 - mse: 1.1190e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7252 - bpp: 0.8073 - mse: 1.1205e-04\n",
      "Epoch 855: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7252 - bpp: 0.8073 - mse: 1.1205e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6112 - bpp: 0.7846 - mse: 1.0090e-04\n",
      "Epoch 856: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6112 - bpp: 0.7846 - mse: 1.0090e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6629 - bpp: 0.8142 - mse: 1.0360e-04\n",
      "Epoch 857: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.6629 - bpp: 0.8142 - mse: 1.0360e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5696 - bpp: 0.7641 - mse: 9.8326e-05\n",
      "Epoch 858: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5696 - bpp: 0.7641 - mse: 9.8326e-05\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7477 - bpp: 0.8323 - mse: 1.1174e-04\n",
      "Epoch 859: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7477 - bpp: 0.8323 - mse: 1.1174e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6336 - bpp: 0.7995 - mse: 1.0182e-04\n",
      "Epoch 860: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6336 - bpp: 0.7995 - mse: 1.0182e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7726 - bpp: 0.8166 - mse: 1.1670e-04\n",
      "Epoch 861: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.7726 - bpp: 0.8166 - mse: 1.1670e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7172 - bpp: 0.8099 - mse: 1.1076e-04\n",
      "Epoch 862: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.7172 - bpp: 0.8099 - mse: 1.1076e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6568 - bpp: 0.8008 - mse: 1.0449e-04\n",
      "Epoch 863: loss did not improve from 1.48480\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6568 - bpp: 0.8008 - mse: 1.0449e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4165 - bpp: 0.7477 - mse: 8.1635e-05\n",
      "Epoch 864: loss improved from 1.48480 to 1.41648, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.4165 - bpp: 0.7477 - mse: 8.1635e-05\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6524 - bpp: 0.8004 - mse: 1.0401e-04\n",
      "Epoch 865: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6524 - bpp: 0.8004 - mse: 1.0401e-04\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5800 - bpp: 0.7900 - mse: 9.6440e-05\n",
      "Epoch 866: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5800 - bpp: 0.7900 - mse: 9.6440e-05\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5060 - bpp: 0.7645 - mse: 9.0512e-05\n",
      "Epoch 867: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5060 - bpp: 0.7645 - mse: 9.0512e-05\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5158 - bpp: 0.7643 - mse: 9.1743e-05\n",
      "Epoch 868: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5158 - bpp: 0.7643 - mse: 9.1743e-05\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6094 - bpp: 0.7810 - mse: 1.0112e-04\n",
      "Epoch 869: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6094 - bpp: 0.7810 - mse: 1.0112e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6643 - bpp: 0.7867 - mse: 1.0714e-04\n",
      "Epoch 870: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6643 - bpp: 0.7867 - mse: 1.0714e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6848 - bpp: 0.7967 - mse: 1.0842e-04\n",
      "Epoch 871: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6848 - bpp: 0.7967 - mse: 1.0842e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6117 - bpp: 0.7764 - mse: 1.0197e-04\n",
      "Epoch 872: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6117 - bpp: 0.7764 - mse: 1.0197e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6570 - bpp: 0.8042 - mse: 1.0410e-04\n",
      "Epoch 873: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.6570 - bpp: 0.8042 - mse: 1.0410e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7337 - bpp: 0.8202 - mse: 1.1150e-04\n",
      "Epoch 874: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.7337 - bpp: 0.8202 - mse: 1.1150e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4918 - bpp: 0.7433 - mse: 9.1377e-05\n",
      "Epoch 875: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.4918 - bpp: 0.7433 - mse: 9.1377e-05\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6826 - bpp: 0.8031 - mse: 1.0736e-04\n",
      "Epoch 876: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6826 - bpp: 0.8031 - mse: 1.0736e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7318 - bpp: 0.8092 - mse: 1.1262e-04\n",
      "Epoch 877: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.7318 - bpp: 0.8092 - mse: 1.1262e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5942 - bpp: 0.7902 - mse: 9.8155e-05\n",
      "Epoch 878: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.5942 - bpp: 0.7902 - mse: 9.8155e-05\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6710 - bpp: 0.8040 - mse: 1.0583e-04\n",
      "Epoch 879: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6710 - bpp: 0.8040 - mse: 1.0583e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5714 - bpp: 0.7895 - mse: 9.5443e-05\n",
      "Epoch 880: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.5714 - bpp: 0.7895 - mse: 9.5443e-05\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6327 - bpp: 0.7972 - mse: 1.0198e-04\n",
      "Epoch 881: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 257ms/step - loss: 1.6327 - bpp: 0.7972 - mse: 1.0198e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7876 - bpp: 0.8367 - mse: 1.1608e-04\n",
      "Epoch 882: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.7876 - bpp: 0.8367 - mse: 1.1608e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6090 - bpp: 0.7841 - mse: 1.0069e-04\n",
      "Epoch 883: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6090 - bpp: 0.7841 - mse: 1.0069e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6287 - bpp: 0.7785 - mse: 1.0378e-04\n",
      "Epoch 884: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6287 - bpp: 0.7785 - mse: 1.0378e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5718 - bpp: 0.7626 - mse: 9.8774e-05\n",
      "Epoch 885: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5718 - bpp: 0.7626 - mse: 9.8774e-05\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5599 - bpp: 0.7728 - mse: 9.6077e-05\n",
      "Epoch 886: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5599 - bpp: 0.7728 - mse: 9.6077e-05\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6209 - bpp: 0.7916 - mse: 1.0123e-04\n",
      "Epoch 887: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.6209 - bpp: 0.7916 - mse: 1.0123e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6381 - bpp: 0.7937 - mse: 1.0307e-04\n",
      "Epoch 888: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6381 - bpp: 0.7937 - mse: 1.0307e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7695 - bpp: 0.8161 - mse: 1.1639e-04\n",
      "Epoch 889: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.7695 - bpp: 0.8161 - mse: 1.1639e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5803 - bpp: 0.7836 - mse: 9.7254e-05\n",
      "Epoch 890: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.5803 - bpp: 0.7836 - mse: 9.7254e-05\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7671 - bpp: 0.8122 - mse: 1.1657e-04\n",
      "Epoch 891: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.7671 - bpp: 0.8122 - mse: 1.1657e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7942 - bpp: 0.8462 - mse: 1.1572e-04\n",
      "Epoch 892: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.7942 - bpp: 0.8462 - mse: 1.1572e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5235 - bpp: 0.7656 - mse: 9.2523e-05\n",
      "Epoch 893: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.5235 - bpp: 0.7656 - mse: 9.2523e-05\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5626 - bpp: 0.7752 - mse: 9.6116e-05\n",
      "Epoch 894: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.5626 - bpp: 0.7752 - mse: 9.6116e-05\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6669 - bpp: 0.7896 - mse: 1.0709e-04\n",
      "Epoch 895: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6669 - bpp: 0.7896 - mse: 1.0709e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5879 - bpp: 0.7900 - mse: 9.7399e-05\n",
      "Epoch 896: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5879 - bpp: 0.7900 - mse: 9.7399e-05\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6289 - bpp: 0.7829 - mse: 1.0327e-04\n",
      "Epoch 897: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.6289 - bpp: 0.7829 - mse: 1.0327e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6959 - bpp: 0.7837 - mse: 1.1135e-04\n",
      "Epoch 898: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6959 - bpp: 0.7837 - mse: 1.1135e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8348 - bpp: 0.8532 - mse: 1.1983e-04\n",
      "Epoch 899: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.8348 - bpp: 0.8532 - mse: 1.1983e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7141 - bpp: 0.8067 - mse: 1.1077e-04\n",
      "Epoch 900: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7141 - bpp: 0.8067 - mse: 1.1077e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6959 - bpp: 0.8020 - mse: 1.0912e-04\n",
      "Epoch 901: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6959 - bpp: 0.8020 - mse: 1.0912e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8338 - bpp: 0.8279 - mse: 1.2279e-04\n",
      "Epoch 902: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.8338 - bpp: 0.8279 - mse: 1.2279e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6355 - bpp: 0.7959 - mse: 1.0249e-04\n",
      "Epoch 903: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.6355 - bpp: 0.7959 - mse: 1.0249e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5663 - bpp: 0.7859 - mse: 9.5266e-05\n",
      "Epoch 904: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.5663 - bpp: 0.7859 - mse: 9.5266e-05\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6073 - bpp: 0.7861 - mse: 1.0026e-04\n",
      "Epoch 905: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6073 - bpp: 0.7861 - mse: 1.0026e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5828 - bpp: 0.7867 - mse: 9.7179e-05\n",
      "Epoch 906: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.5828 - bpp: 0.7867 - mse: 9.7179e-05\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7189 - bpp: 0.8105 - mse: 1.1089e-04\n",
      "Epoch 907: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.7189 - bpp: 0.8105 - mse: 1.1089e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8013 - bpp: 0.8263 - mse: 1.1901e-04\n",
      "Epoch 908: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.8013 - bpp: 0.8263 - mse: 1.1901e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6210 - bpp: 0.7918 - mse: 1.0121e-04\n",
      "Epoch 909: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.6210 - bpp: 0.7918 - mse: 1.0121e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6760 - bpp: 0.8014 - mse: 1.0677e-04\n",
      "Epoch 910: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6760 - bpp: 0.8014 - mse: 1.0677e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6786 - bpp: 0.7870 - mse: 1.0884e-04\n",
      "Epoch 911: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6786 - bpp: 0.7870 - mse: 1.0884e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6476 - bpp: 0.7886 - mse: 1.0486e-04\n",
      "Epoch 912: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.6476 - bpp: 0.7886 - mse: 1.0486e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5880 - bpp: 0.7773 - mse: 9.8957e-05\n",
      "Epoch 913: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 1.5880 - bpp: 0.7773 - mse: 9.8957e-05\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5836 - bpp: 0.7899 - mse: 9.6888e-05\n",
      "Epoch 914: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5836 - bpp: 0.7899 - mse: 9.6888e-05\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7353 - bpp: 0.8050 - mse: 1.1355e-04\n",
      "Epoch 915: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.7353 - bpp: 0.8050 - mse: 1.1355e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6424 - bpp: 0.7958 - mse: 1.0335e-04\n",
      "Epoch 916: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.6424 - bpp: 0.7958 - mse: 1.0335e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7918 - bpp: 0.8363 - mse: 1.1664e-04\n",
      "Epoch 917: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.7918 - bpp: 0.8363 - mse: 1.1664e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5629 - bpp: 0.7861 - mse: 9.4824e-05\n",
      "Epoch 918: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 1.5629 - bpp: 0.7861 - mse: 9.4824e-05\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6192 - bpp: 0.7871 - mse: 1.0158e-04\n",
      "Epoch 919: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6192 - bpp: 0.7871 - mse: 1.0158e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6883 - bpp: 0.8201 - mse: 1.0598e-04\n",
      "Epoch 920: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6883 - bpp: 0.8201 - mse: 1.0598e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6497 - bpp: 0.8040 - mse: 1.0323e-04\n",
      "Epoch 921: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.6497 - bpp: 0.8040 - mse: 1.0323e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6756 - bpp: 0.8079 - mse: 1.0592e-04\n",
      "Epoch 922: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.6756 - bpp: 0.8079 - mse: 1.0592e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7254 - bpp: 0.8330 - mse: 1.0894e-04\n",
      "Epoch 923: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.7254 - bpp: 0.8330 - mse: 1.0894e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6999 - bpp: 0.8089 - mse: 1.0876e-04\n",
      "Epoch 924: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.6999 - bpp: 0.8089 - mse: 1.0876e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4887 - bpp: 0.7353 - mse: 9.1966e-05\n",
      "Epoch 925: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.4887 - bpp: 0.7353 - mse: 9.1966e-05\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4981 - bpp: 0.7715 - mse: 8.8703e-05\n",
      "Epoch 926: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.4981 - bpp: 0.7715 - mse: 8.8703e-05\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5859 - bpp: 0.7936 - mse: 9.6716e-05\n",
      "Epoch 927: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 1.5859 - bpp: 0.7936 - mse: 9.6716e-05\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5496 - bpp: 0.7699 - mse: 9.5168e-05\n",
      "Epoch 928: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.5496 - bpp: 0.7699 - mse: 9.5168e-05\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4879 - bpp: 0.7474 - mse: 9.0397e-05\n",
      "Epoch 929: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.4879 - bpp: 0.7474 - mse: 9.0397e-05\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7717 - bpp: 0.8025 - mse: 1.1830e-04\n",
      "Epoch 930: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.7717 - bpp: 0.8025 - mse: 1.1830e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8580 - bpp: 0.8578 - mse: 1.2210e-04\n",
      "Epoch 931: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.8580 - bpp: 0.8578 - mse: 1.2210e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5484 - bpp: 0.7786 - mse: 9.3966e-05\n",
      "Epoch 932: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5484 - bpp: 0.7786 - mse: 9.3966e-05\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5208 - bpp: 0.7747 - mse: 9.1085e-05\n",
      "Epoch 933: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.5208 - bpp: 0.7747 - mse: 9.1085e-05\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5988 - bpp: 0.7868 - mse: 9.9129e-05\n",
      "Epoch 934: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5988 - bpp: 0.7868 - mse: 9.9129e-05\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5615 - bpp: 0.7762 - mse: 9.5859e-05\n",
      "Epoch 935: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.5615 - bpp: 0.7762 - mse: 9.5859e-05\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5882 - bpp: 0.7863 - mse: 9.7892e-05\n",
      "Epoch 936: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5882 - bpp: 0.7863 - mse: 9.7892e-05\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6697 - bpp: 0.8130 - mse: 1.0458e-04\n",
      "Epoch 937: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6697 - bpp: 0.8130 - mse: 1.0458e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5539 - bpp: 0.7727 - mse: 9.5372e-05\n",
      "Epoch 938: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5539 - bpp: 0.7727 - mse: 9.5372e-05\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7521 - bpp: 0.8149 - mse: 1.1440e-04\n",
      "Epoch 939: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.7521 - bpp: 0.8149 - mse: 1.1440e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5553 - bpp: 0.7709 - mse: 9.5758e-05\n",
      "Epoch 940: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5553 - bpp: 0.7709 - mse: 9.5758e-05\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6294 - bpp: 0.7915 - mse: 1.0229e-04\n",
      "Epoch 941: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 1.6294 - bpp: 0.7915 - mse: 1.0229e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5827 - bpp: 0.7977 - mse: 9.5825e-05\n",
      "Epoch 942: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 281ms/step - loss: 1.5827 - bpp: 0.7977 - mse: 9.5825e-05\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5658 - bpp: 0.7797 - mse: 9.5965e-05\n",
      "Epoch 943: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.5658 - bpp: 0.7797 - mse: 9.5965e-05\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6667 - bpp: 0.8067 - mse: 1.0498e-04\n",
      "Epoch 944: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6667 - bpp: 0.8067 - mse: 1.0498e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5870 - bpp: 0.7809 - mse: 9.8393e-05\n",
      "Epoch 945: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5870 - bpp: 0.7809 - mse: 9.8393e-05\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5242 - bpp: 0.7584 - mse: 9.3482e-05\n",
      "Epoch 946: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 1.5242 - bpp: 0.7584 - mse: 9.3482e-05\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6903 - bpp: 0.8159 - mse: 1.0674e-04\n",
      "Epoch 947: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6903 - bpp: 0.8159 - mse: 1.0674e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5098 - bpp: 0.7638 - mse: 9.1072e-05\n",
      "Epoch 948: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5098 - bpp: 0.7638 - mse: 9.1072e-05\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7092 - bpp: 0.8243 - mse: 1.0803e-04\n",
      "Epoch 949: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.7092 - bpp: 0.8243 - mse: 1.0803e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5991 - bpp: 0.7720 - mse: 1.0096e-04\n",
      "Epoch 950: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5991 - bpp: 0.7720 - mse: 1.0096e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5530 - bpp: 0.7808 - mse: 9.4264e-05\n",
      "Epoch 951: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5530 - bpp: 0.7808 - mse: 9.4264e-05\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6930 - bpp: 0.8093 - mse: 1.0786e-04\n",
      "Epoch 952: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.6930 - bpp: 0.8093 - mse: 1.0786e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5956 - bpp: 0.7823 - mse: 9.9285e-05\n",
      "Epoch 953: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5956 - bpp: 0.7823 - mse: 9.9285e-05\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5200 - bpp: 0.7757 - mse: 9.0865e-05\n",
      "Epoch 954: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.5200 - bpp: 0.7757 - mse: 9.0865e-05\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4948 - bpp: 0.7468 - mse: 9.1306e-05\n",
      "Epoch 955: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.4948 - bpp: 0.7468 - mse: 9.1306e-05\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6195 - bpp: 0.7880 - mse: 1.0150e-04\n",
      "Epoch 956: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.6195 - bpp: 0.7880 - mse: 1.0150e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5787 - bpp: 0.7726 - mse: 9.8412e-05\n",
      "Epoch 957: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5787 - bpp: 0.7726 - mse: 9.8412e-05\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5608 - bpp: 0.7674 - mse: 9.6853e-05\n",
      "Epoch 958: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5608 - bpp: 0.7674 - mse: 9.6853e-05\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5345 - bpp: 0.7728 - mse: 9.2985e-05\n",
      "Epoch 959: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 1.5345 - bpp: 0.7728 - mse: 9.2985e-05\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6048 - bpp: 0.7820 - mse: 1.0043e-04\n",
      "Epoch 960: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6048 - bpp: 0.7820 - mse: 1.0043e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6768 - bpp: 0.8023 - mse: 1.0675e-04\n",
      "Epoch 961: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.6768 - bpp: 0.8023 - mse: 1.0675e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5993 - bpp: 0.7893 - mse: 9.8871e-05\n",
      "Epoch 962: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.5993 - bpp: 0.7893 - mse: 9.8871e-05\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5679 - bpp: 0.7880 - mse: 9.5211e-05\n",
      "Epoch 963: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 1.5679 - bpp: 0.7880 - mse: 9.5211e-05\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6711 - bpp: 0.8038 - mse: 1.0586e-04\n",
      "Epoch 964: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6711 - bpp: 0.8038 - mse: 1.0586e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5425 - bpp: 0.7805 - mse: 9.3015e-05\n",
      "Epoch 965: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.5425 - bpp: 0.7805 - mse: 9.3015e-05\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8371 - bpp: 0.8238 - mse: 1.2369e-04\n",
      "Epoch 966: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.8371 - bpp: 0.8238 - mse: 1.2369e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5773 - bpp: 0.7849 - mse: 9.6741e-05\n",
      "Epoch 967: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5773 - bpp: 0.7849 - mse: 9.6741e-05\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7249 - bpp: 0.8326 - mse: 1.0892e-04\n",
      "Epoch 968: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 1.7249 - bpp: 0.8326 - mse: 1.0892e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4989 - bpp: 0.7603 - mse: 9.0163e-05\n",
      "Epoch 969: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.4989 - bpp: 0.7603 - mse: 9.0163e-05\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6233 - bpp: 0.8014 - mse: 1.0034e-04\n",
      "Epoch 970: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6233 - bpp: 0.8014 - mse: 1.0034e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6036 - bpp: 0.7861 - mse: 9.9791e-05\n",
      "Epoch 971: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6036 - bpp: 0.7861 - mse: 9.9791e-05\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4257 - bpp: 0.7395 - mse: 8.3755e-05\n",
      "Epoch 972: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.4257 - bpp: 0.7395 - mse: 8.3755e-05\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5723 - bpp: 0.7825 - mse: 9.6413e-05\n",
      "Epoch 973: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5723 - bpp: 0.7825 - mse: 9.6413e-05\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5292 - bpp: 0.7673 - mse: 9.3007e-05\n",
      "Epoch 974: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 1.5292 - bpp: 0.7673 - mse: 9.3007e-05\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5832 - bpp: 0.7801 - mse: 9.8033e-05\n",
      "Epoch 975: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5832 - bpp: 0.7801 - mse: 9.8033e-05\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6159 - bpp: 0.7784 - mse: 1.0224e-04\n",
      "Epoch 976: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6159 - bpp: 0.7784 - mse: 1.0224e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5280 - bpp: 0.7770 - mse: 9.1674e-05\n",
      "Epoch 977: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.5280 - bpp: 0.7770 - mse: 9.1674e-05\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6054 - bpp: 0.7764 - mse: 1.0120e-04\n",
      "Epoch 978: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.6054 - bpp: 0.7764 - mse: 1.0120e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5880 - bpp: 0.7885 - mse: 9.7595e-05\n",
      "Epoch 979: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.5880 - bpp: 0.7885 - mse: 9.7595e-05\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5950 - bpp: 0.7864 - mse: 9.8705e-05\n",
      "Epoch 980: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5950 - bpp: 0.7864 - mse: 9.8705e-05\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7229 - bpp: 0.8033 - mse: 1.1226e-04\n",
      "Epoch 981: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.7229 - bpp: 0.8033 - mse: 1.1226e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6991 - bpp: 0.8235 - mse: 1.0688e-04\n",
      "Epoch 982: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.6991 - bpp: 0.8235 - mse: 1.0688e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7072 - bpp: 0.8046 - mse: 1.1017e-04\n",
      "Epoch 983: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.7072 - bpp: 0.8046 - mse: 1.1017e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7550 - bpp: 0.8207 - mse: 1.1405e-04\n",
      "Epoch 984: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.7550 - bpp: 0.8207 - mse: 1.1405e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6693 - bpp: 0.8150 - mse: 1.0429e-04\n",
      "Epoch 985: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.6693 - bpp: 0.8150 - mse: 1.0429e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6326 - bpp: 0.8087 - mse: 1.0057e-04\n",
      "Epoch 986: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.6326 - bpp: 0.8087 - mse: 1.0057e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5949 - bpp: 0.7836 - mse: 9.9033e-05\n",
      "Epoch 987: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.5949 - bpp: 0.7836 - mse: 9.9033e-05\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7701 - bpp: 0.8140 - mse: 1.1671e-04\n",
      "Epoch 988: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.7701 - bpp: 0.8140 - mse: 1.1671e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4639 - bpp: 0.7627 - mse: 8.5597e-05\n",
      "Epoch 989: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.4639 - bpp: 0.7627 - mse: 8.5597e-05\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5229 - bpp: 0.7679 - mse: 9.2161e-05\n",
      "Epoch 990: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5229 - bpp: 0.7679 - mse: 9.2161e-05\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6871 - bpp: 0.8165 - mse: 1.0627e-04\n",
      "Epoch 991: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6871 - bpp: 0.8165 - mse: 1.0627e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6804 - bpp: 0.8003 - mse: 1.0743e-04\n",
      "Epoch 992: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.6804 - bpp: 0.8003 - mse: 1.0743e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5191 - bpp: 0.7572 - mse: 9.3013e-05\n",
      "Epoch 993: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.5191 - bpp: 0.7572 - mse: 9.3013e-05\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5484 - bpp: 0.7678 - mse: 9.5288e-05\n",
      "Epoch 994: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5484 - bpp: 0.7678 - mse: 9.5288e-05\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4524 - bpp: 0.7407 - mse: 8.6885e-05\n",
      "Epoch 995: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4524 - bpp: 0.7407 - mse: 8.6885e-05\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5627 - bpp: 0.7762 - mse: 9.6004e-05\n",
      "Epoch 996: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.5627 - bpp: 0.7762 - mse: 9.6004e-05\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5812 - bpp: 0.7831 - mse: 9.7424e-05\n",
      "Epoch 997: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5812 - bpp: 0.7831 - mse: 9.7424e-05\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5402 - bpp: 0.7594 - mse: 9.5321e-05\n",
      "Epoch 998: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5402 - bpp: 0.7594 - mse: 9.5321e-05\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5721 - bpp: 0.7738 - mse: 9.7449e-05\n",
      "Epoch 999: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 1.5721 - bpp: 0.7738 - mse: 9.7449e-05\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6320 - bpp: 0.7781 - mse: 1.0423e-04\n",
      "Epoch 1000: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6320 - bpp: 0.7781 - mse: 1.0423e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7672 - bpp: 0.8312 - mse: 1.1426e-04\n",
      "Epoch 1001: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.7672 - bpp: 0.8312 - mse: 1.1426e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8340 - bpp: 0.8304 - mse: 1.2251e-04\n",
      "Epoch 1002: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 1.8340 - bpp: 0.8304 - mse: 1.2251e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5253 - bpp: 0.7728 - mse: 9.1855e-05\n",
      "Epoch 1003: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.5253 - bpp: 0.7728 - mse: 9.1855e-05\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6717 - bpp: 0.8028 - mse: 1.0607e-04\n",
      "Epoch 1004: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.6717 - bpp: 0.8028 - mse: 1.0607e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4756 - bpp: 0.7562 - mse: 8.7825e-05\n",
      "Epoch 1005: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.4756 - bpp: 0.7562 - mse: 8.7825e-05\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6221 - bpp: 0.7918 - mse: 1.0136e-04\n",
      "Epoch 1006: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 1.6221 - bpp: 0.7918 - mse: 1.0136e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6159 - bpp: 0.7903 - mse: 1.0079e-04\n",
      "Epoch 1007: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.6159 - bpp: 0.7903 - mse: 1.0079e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7707 - bpp: 0.8159 - mse: 1.1656e-04\n",
      "Epoch 1008: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.7707 - bpp: 0.8159 - mse: 1.1656e-04\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5372 - bpp: 0.7466 - mse: 9.6515e-05\n",
      "Epoch 1009: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5372 - bpp: 0.7466 - mse: 9.6515e-05\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5320 - bpp: 0.7691 - mse: 9.3127e-05\n",
      "Epoch 1010: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5320 - bpp: 0.7691 - mse: 9.3127e-05\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7301 - bpp: 0.8415 - mse: 1.0848e-04\n",
      "Epoch 1011: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.7301 - bpp: 0.8415 - mse: 1.0848e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4651 - bpp: 0.7467 - mse: 8.7691e-05\n",
      "Epoch 1012: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.4651 - bpp: 0.7467 - mse: 8.7691e-05\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6189 - bpp: 0.7912 - mse: 1.0104e-04\n",
      "Epoch 1013: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6189 - bpp: 0.7912 - mse: 1.0104e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8187 - bpp: 0.8167 - mse: 1.2232e-04\n",
      "Epoch 1014: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.8187 - bpp: 0.8167 - mse: 1.2232e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5465 - bpp: 0.7776 - mse: 9.3860e-05\n",
      "Epoch 1015: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.5465 - bpp: 0.7776 - mse: 9.3860e-05\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5286 - bpp: 0.7500 - mse: 9.5049e-05\n",
      "Epoch 1016: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5286 - bpp: 0.7500 - mse: 9.5049e-05\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7513 - bpp: 0.8159 - mse: 1.1418e-04\n",
      "Epoch 1017: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.7513 - bpp: 0.8159 - mse: 1.1418e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7417 - bpp: 0.8247 - mse: 1.1194e-04\n",
      "Epoch 1018: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7417 - bpp: 0.8247 - mse: 1.1194e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7317 - bpp: 0.8175 - mse: 1.1159e-04\n",
      "Epoch 1019: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.7317 - bpp: 0.8175 - mse: 1.1159e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5929 - bpp: 0.7940 - mse: 9.7527e-05\n",
      "Epoch 1020: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.5929 - bpp: 0.7940 - mse: 9.7527e-05\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4967 - bpp: 0.7576 - mse: 9.0227e-05\n",
      "Epoch 1021: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4967 - bpp: 0.7576 - mse: 9.0227e-05\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5907 - bpp: 0.7861 - mse: 9.8218e-05\n",
      "Epoch 1022: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5907 - bpp: 0.7861 - mse: 9.8218e-05\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6222 - bpp: 0.7878 - mse: 1.0186e-04\n",
      "Epoch 1023: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.6222 - bpp: 0.7878 - mse: 1.0186e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5744 - bpp: 0.7803 - mse: 9.6937e-05\n",
      "Epoch 1024: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5744 - bpp: 0.7803 - mse: 9.6937e-05\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6719 - bpp: 0.8123 - mse: 1.0494e-04\n",
      "Epoch 1025: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 1.6719 - bpp: 0.8123 - mse: 1.0494e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7273 - bpp: 0.8385 - mse: 1.0850e-04\n",
      "Epoch 1026: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.7273 - bpp: 0.8385 - mse: 1.0850e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5546 - bpp: 0.7783 - mse: 9.4760e-05\n",
      "Epoch 1027: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.5546 - bpp: 0.7783 - mse: 9.4760e-05\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4882 - bpp: 0.7501 - mse: 9.0093e-05\n",
      "Epoch 1028: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.4882 - bpp: 0.7501 - mse: 9.0093e-05\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6194 - bpp: 0.7895 - mse: 1.0131e-04\n",
      "Epoch 1029: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.6194 - bpp: 0.7895 - mse: 1.0131e-04\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6693 - bpp: 0.8086 - mse: 1.0506e-04\n",
      "Epoch 1030: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.6693 - bpp: 0.8086 - mse: 1.0506e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5771 - bpp: 0.7663 - mse: 9.8971e-05\n",
      "Epoch 1031: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.5771 - bpp: 0.7663 - mse: 9.8971e-05\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7880 - bpp: 0.8314 - mse: 1.1678e-04\n",
      "Epoch 1032: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.7880 - bpp: 0.8314 - mse: 1.1678e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4914 - bpp: 0.7604 - mse: 8.9231e-05\n",
      "Epoch 1033: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 1.4914 - bpp: 0.7604 - mse: 8.9231e-05\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5518 - bpp: 0.7593 - mse: 9.6742e-05\n",
      "Epoch 1034: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.5518 - bpp: 0.7593 - mse: 9.6742e-05\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5264 - bpp: 0.7627 - mse: 9.3227e-05\n",
      "Epoch 1035: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5264 - bpp: 0.7627 - mse: 9.3227e-05\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5844 - bpp: 0.7667 - mse: 9.9823e-05\n",
      "Epoch 1036: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5844 - bpp: 0.7667 - mse: 9.9823e-05\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7439 - bpp: 0.7940 - mse: 1.1596e-04\n",
      "Epoch 1037: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.7439 - bpp: 0.7940 - mse: 1.1596e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7306 - bpp: 0.8202 - mse: 1.1114e-04\n",
      "Epoch 1038: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.7306 - bpp: 0.8202 - mse: 1.1114e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6350 - bpp: 0.7932 - mse: 1.0277e-04\n",
      "Epoch 1039: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6350 - bpp: 0.7932 - mse: 1.0277e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6608 - bpp: 0.8021 - mse: 1.0482e-04\n",
      "Epoch 1040: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.6608 - bpp: 0.8021 - mse: 1.0482e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6523 - bpp: 0.8038 - mse: 1.0358e-04\n",
      "Epoch 1041: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.6523 - bpp: 0.8038 - mse: 1.0358e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6071 - bpp: 0.8016 - mse: 9.8331e-05\n",
      "Epoch 1042: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6071 - bpp: 0.8016 - mse: 9.8331e-05\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6333 - bpp: 0.7905 - mse: 1.0288e-04\n",
      "Epoch 1043: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 59s 291ms/step - loss: 1.6333 - bpp: 0.7905 - mse: 1.0288e-04\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6590 - bpp: 0.8091 - mse: 1.0375e-04\n",
      "Epoch 1044: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.6590 - bpp: 0.8091 - mse: 1.0375e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8191 - bpp: 0.8258 - mse: 1.2126e-04\n",
      "Epoch 1045: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.8191 - bpp: 0.8258 - mse: 1.2126e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5447 - bpp: 0.7778 - mse: 9.3622e-05\n",
      "Epoch 1046: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.5447 - bpp: 0.7778 - mse: 9.3622e-05\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5442 - bpp: 0.7738 - mse: 9.4035e-05\n",
      "Epoch 1047: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5442 - bpp: 0.7738 - mse: 9.4035e-05\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6127 - bpp: 0.7845 - mse: 1.0110e-04\n",
      "Epoch 1048: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.6127 - bpp: 0.7845 - mse: 1.0110e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5814 - bpp: 0.7686 - mse: 9.9213e-05\n",
      "Epoch 1049: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5814 - bpp: 0.7686 - mse: 9.9213e-05\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4606 - bpp: 0.7514 - mse: 8.6579e-05\n",
      "Epoch 1050: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 1.4606 - bpp: 0.7514 - mse: 8.6579e-05\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6232 - bpp: 0.7944 - mse: 1.0117e-04\n",
      "Epoch 1051: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.6232 - bpp: 0.7944 - mse: 1.0117e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5834 - bpp: 0.7793 - mse: 9.8152e-05\n",
      "Epoch 1052: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5834 - bpp: 0.7793 - mse: 9.8152e-05\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6217 - bpp: 0.7857 - mse: 1.0204e-04\n",
      "Epoch 1053: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.6217 - bpp: 0.7857 - mse: 1.0204e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7229 - bpp: 0.8142 - mse: 1.1092e-04\n",
      "Epoch 1054: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7229 - bpp: 0.8142 - mse: 1.1092e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4915 - bpp: 0.7590 - mse: 8.9417e-05\n",
      "Epoch 1055: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.4915 - bpp: 0.7590 - mse: 8.9417e-05\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6774 - bpp: 0.7703 - mse: 1.1073e-04\n",
      "Epoch 1056: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6774 - bpp: 0.7703 - mse: 1.1073e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7190 - bpp: 0.7984 - mse: 1.1238e-04\n",
      "Epoch 1057: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.7190 - bpp: 0.7984 - mse: 1.1238e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4586 - bpp: 0.7459 - mse: 8.6994e-05\n",
      "Epoch 1058: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.4586 - bpp: 0.7459 - mse: 8.6994e-05\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7530 - bpp: 0.8132 - mse: 1.1472e-04\n",
      "Epoch 1059: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.7530 - bpp: 0.8132 - mse: 1.1472e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5127 - bpp: 0.7567 - mse: 9.2284e-05\n",
      "Epoch 1060: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.5127 - bpp: 0.7567 - mse: 9.2284e-05\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5037 - bpp: 0.7651 - mse: 9.0159e-05\n",
      "Epoch 1061: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5037 - bpp: 0.7651 - mse: 9.0159e-05\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6913 - bpp: 0.7945 - mse: 1.0947e-04\n",
      "Epoch 1062: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.6913 - bpp: 0.7945 - mse: 1.0947e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5711 - bpp: 0.7862 - mse: 9.5813e-05\n",
      "Epoch 1063: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 1.5711 - bpp: 0.7862 - mse: 9.5813e-05\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5812 - bpp: 0.7854 - mse: 9.7138e-05\n",
      "Epoch 1064: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.5812 - bpp: 0.7854 - mse: 9.7138e-05\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5063 - bpp: 0.7609 - mse: 9.0987e-05\n",
      "Epoch 1065: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5063 - bpp: 0.7609 - mse: 9.0987e-05\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.8003 - mse: 1.0767e-04\n",
      "Epoch 1066: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6823 - bpp: 0.8003 - mse: 1.0767e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6505 - bpp: 0.8040 - mse: 1.0333e-04\n",
      "Epoch 1067: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 1.6505 - bpp: 0.8040 - mse: 1.0333e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6029 - bpp: 0.7851 - mse: 9.9828e-05\n",
      "Epoch 1068: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 1.6029 - bpp: 0.7851 - mse: 9.9828e-05\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6728 - bpp: 0.8029 - mse: 1.0618e-04\n",
      "Epoch 1069: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 1.6728 - bpp: 0.8029 - mse: 1.0618e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6823 - bpp: 0.8129 - mse: 1.0613e-04\n",
      "Epoch 1070: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6823 - bpp: 0.8129 - mse: 1.0613e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7167 - bpp: 0.8106 - mse: 1.1060e-04\n",
      "Epoch 1071: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.7167 - bpp: 0.8106 - mse: 1.1060e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5808 - bpp: 0.7873 - mse: 9.6862e-05\n",
      "Epoch 1072: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 1.5808 - bpp: 0.7873 - mse: 9.6862e-05\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5507 - bpp: 0.7721 - mse: 9.5033e-05\n",
      "Epoch 1073: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5507 - bpp: 0.7721 - mse: 9.5033e-05\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5055 - bpp: 0.7532 - mse: 9.1828e-05\n",
      "Epoch 1074: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 1.5055 - bpp: 0.7532 - mse: 9.1828e-05\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6127 - bpp: 0.7954 - mse: 9.9769e-05\n",
      "Epoch 1075: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.6127 - bpp: 0.7954 - mse: 9.9769e-05\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5411 - bpp: 0.7764 - mse: 9.3340e-05\n",
      "Epoch 1076: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5411 - bpp: 0.7764 - mse: 9.3340e-05\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6045 - bpp: 0.7714 - mse: 1.0170e-04\n",
      "Epoch 1077: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.6045 - bpp: 0.7714 - mse: 1.0170e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7436 - bpp: 0.8133 - mse: 1.1356e-04\n",
      "Epoch 1078: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 1.7436 - bpp: 0.8133 - mse: 1.1356e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7068 - bpp: 0.8081 - mse: 1.0970e-04\n",
      "Epoch 1079: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7068 - bpp: 0.8081 - mse: 1.0970e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7068 - bpp: 0.8136 - mse: 1.0903e-04\n",
      "Epoch 1080: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 1.7068 - bpp: 0.8136 - mse: 1.0903e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6112 - bpp: 0.7771 - mse: 1.0182e-04\n",
      "Epoch 1081: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 1.6112 - bpp: 0.7771 - mse: 1.0182e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4489 - bpp: 0.7444 - mse: 8.5996e-05\n",
      "Epoch 1082: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 1.4489 - bpp: 0.7444 - mse: 8.5996e-05\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5508 - bpp: 0.7666 - mse: 9.5723e-05\n",
      "Epoch 1083: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.5508 - bpp: 0.7666 - mse: 9.5723e-05\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8006 - bpp: 0.8380 - mse: 1.1750e-04\n",
      "Epoch 1084: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.8006 - bpp: 0.8380 - mse: 1.1750e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4171 - bpp: 0.7406 - mse: 8.2587e-05\n",
      "Epoch 1085: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.4171 - bpp: 0.7406 - mse: 8.2587e-05\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5529 - bpp: 0.7627 - mse: 9.6454e-05\n",
      "Epoch 1086: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.5529 - bpp: 0.7627 - mse: 9.6454e-05\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5787 - bpp: 0.7802 - mse: 9.7484e-05\n",
      "Epoch 1087: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 1.5787 - bpp: 0.7802 - mse: 9.7484e-05\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5596 - bpp: 0.7658 - mse: 9.6909e-05\n",
      "Epoch 1088: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 1.5596 - bpp: 0.7658 - mse: 9.6909e-05\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5794 - bpp: 0.8010 - mse: 9.5012e-05\n",
      "Epoch 1089: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.5794 - bpp: 0.8010 - mse: 9.5012e-05\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5550 - bpp: 0.7753 - mse: 9.5188e-05\n",
      "Epoch 1090: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.5550 - bpp: 0.7753 - mse: 9.5188e-05\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5774 - bpp: 0.7948 - mse: 9.5539e-05\n",
      "Epoch 1091: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 1.5774 - bpp: 0.7948 - mse: 9.5539e-05\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5406 - bpp: 0.7637 - mse: 9.4827e-05\n",
      "Epoch 1092: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 1.5406 - bpp: 0.7637 - mse: 9.4827e-05\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4977 - bpp: 0.7540 - mse: 9.0789e-05\n",
      "Epoch 1093: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 1.4977 - bpp: 0.7540 - mse: 9.0789e-05\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4974 - bpp: 0.7584 - mse: 9.0203e-05\n",
      "Epoch 1094: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.4974 - bpp: 0.7584 - mse: 9.0203e-05\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4959 - bpp: 0.7685 - mse: 8.8783e-05\n",
      "Epoch 1095: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 1.4959 - bpp: 0.7685 - mse: 8.8783e-05\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4862 - bpp: 0.7553 - mse: 8.9217e-05\n",
      "Epoch 1096: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.4862 - bpp: 0.7553 - mse: 8.9217e-05\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4552 - bpp: 0.7471 - mse: 8.6436e-05\n",
      "Epoch 1097: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.4552 - bpp: 0.7471 - mse: 8.6436e-05\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5780 - bpp: 0.7695 - mse: 9.8684e-05\n",
      "Epoch 1098: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.5780 - bpp: 0.7695 - mse: 9.8684e-05\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6618 - bpp: 0.7891 - mse: 1.0653e-04\n",
      "Epoch 1099: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6618 - bpp: 0.7891 - mse: 1.0653e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6525 - bpp: 0.8046 - mse: 1.0350e-04\n",
      "Epoch 1100: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 1.6525 - bpp: 0.8046 - mse: 1.0350e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5488 - bpp: 0.7835 - mse: 9.3418e-05\n",
      "Epoch 1101: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 1.5488 - bpp: 0.7835 - mse: 9.3418e-05\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6794 - bpp: 0.8129 - mse: 1.0578e-04\n",
      "Epoch 1102: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6794 - bpp: 0.8129 - mse: 1.0578e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5497 - bpp: 0.7625 - mse: 9.6093e-05\n",
      "Epoch 1103: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.5497 - bpp: 0.7625 - mse: 9.6093e-05\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5645 - bpp: 0.7750 - mse: 9.6384e-05\n",
      "Epoch 1104: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 1.5645 - bpp: 0.7750 - mse: 9.6384e-05\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6056 - bpp: 0.7971 - mse: 9.8697e-05\n",
      "Epoch 1105: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 1.6056 - bpp: 0.7971 - mse: 9.8697e-05\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7118 - bpp: 0.8099 - mse: 1.1010e-04\n",
      "Epoch 1106: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 1.7118 - bpp: 0.8099 - mse: 1.1010e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5189 - bpp: 0.7699 - mse: 9.1421e-05\n",
      "Epoch 1107: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.5189 - bpp: 0.7699 - mse: 9.1421e-05\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6408 - bpp: 0.7865 - mse: 1.0429e-04\n",
      "Epoch 1108: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 1.6408 - bpp: 0.7865 - mse: 1.0429e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6685 - bpp: 0.7913 - mse: 1.0708e-04\n",
      "Epoch 1109: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6685 - bpp: 0.7913 - mse: 1.0708e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5208 - bpp: 0.7517 - mse: 9.3881e-05\n",
      "Epoch 1110: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 1.5208 - bpp: 0.7517 - mse: 9.3881e-05\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4496 - bpp: 0.7490 - mse: 8.5529e-05\n",
      "Epoch 1111: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 1.4496 - bpp: 0.7490 - mse: 8.5529e-05\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5633 - bpp: 0.7775 - mse: 9.5925e-05\n",
      "Epoch 1112: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5633 - bpp: 0.7775 - mse: 9.5925e-05\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5841 - bpp: 0.7936 - mse: 9.6494e-05\n",
      "Epoch 1113: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.5841 - bpp: 0.7936 - mse: 9.6494e-05\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6221 - bpp: 0.7840 - mse: 1.0230e-04\n",
      "Epoch 1114: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6221 - bpp: 0.7840 - mse: 1.0230e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5863 - bpp: 0.7727 - mse: 9.9323e-05\n",
      "Epoch 1115: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.5863 - bpp: 0.7727 - mse: 9.9323e-05\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6181 - bpp: 0.7829 - mse: 1.0196e-04\n",
      "Epoch 1116: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 60s 298ms/step - loss: 1.6181 - bpp: 0.7829 - mse: 1.0196e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5589 - bpp: 0.7611 - mse: 9.7382e-05\n",
      "Epoch 1117: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5589 - bpp: 0.7611 - mse: 9.7382e-05\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5940 - bpp: 0.7763 - mse: 9.9811e-05\n",
      "Epoch 1118: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 1.5940 - bpp: 0.7763 - mse: 9.9811e-05\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6634 - bpp: 0.7996 - mse: 1.0544e-04\n",
      "Epoch 1119: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.6634 - bpp: 0.7996 - mse: 1.0544e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5999 - bpp: 0.7981 - mse: 9.7868e-05\n",
      "Epoch 1120: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5999 - bpp: 0.7981 - mse: 9.7868e-05\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6527 - bpp: 0.7856 - mse: 1.0585e-04\n",
      "Epoch 1121: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6527 - bpp: 0.7856 - mse: 1.0585e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5227 - bpp: 0.7597 - mse: 9.3134e-05\n",
      "Epoch 1122: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5227 - bpp: 0.7597 - mse: 9.3134e-05\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4999 - bpp: 0.7625 - mse: 9.0013e-05\n",
      "Epoch 1123: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 1.4999 - bpp: 0.7625 - mse: 9.0013e-05\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5518 - bpp: 0.7594 - mse: 9.6731e-05\n",
      "Epoch 1124: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5518 - bpp: 0.7594 - mse: 9.6731e-05\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5001 - bpp: 0.7598 - mse: 9.0364e-05\n",
      "Epoch 1125: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5001 - bpp: 0.7598 - mse: 9.0364e-05\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4575 - bpp: 0.7412 - mse: 8.7438e-05\n",
      "Epoch 1126: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4575 - bpp: 0.7412 - mse: 8.7438e-05\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6058 - bpp: 0.7883 - mse: 9.9801e-05\n",
      "Epoch 1127: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 1.6058 - bpp: 0.7883 - mse: 9.9801e-05\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6068 - bpp: 0.7744 - mse: 1.0161e-04\n",
      "Epoch 1128: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.6068 - bpp: 0.7744 - mse: 1.0161e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5052 - bpp: 0.7651 - mse: 9.0342e-05\n",
      "Epoch 1129: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.5052 - bpp: 0.7651 - mse: 9.0342e-05\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6937 - bpp: 0.8147 - mse: 1.0730e-04\n",
      "Epoch 1130: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.6937 - bpp: 0.8147 - mse: 1.0730e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7221 - bpp: 0.8140 - mse: 1.1085e-04\n",
      "Epoch 1131: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.7221 - bpp: 0.8140 - mse: 1.1085e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5934 - bpp: 0.7860 - mse: 9.8560e-05\n",
      "Epoch 1132: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 1.5934 - bpp: 0.7860 - mse: 9.8560e-05\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6106 - bpp: 0.7862 - mse: 1.0064e-04\n",
      "Epoch 1133: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6106 - bpp: 0.7862 - mse: 1.0064e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6337 - bpp: 0.7998 - mse: 1.0180e-04\n",
      "Epoch 1134: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 1.6337 - bpp: 0.7998 - mse: 1.0180e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6802 - bpp: 0.8079 - mse: 1.0648e-04\n",
      "Epoch 1135: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6802 - bpp: 0.8079 - mse: 1.0648e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5220 - bpp: 0.7795 - mse: 9.0637e-05\n",
      "Epoch 1136: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5220 - bpp: 0.7795 - mse: 9.0637e-05\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6025 - bpp: 0.7827 - mse: 1.0007e-04\n",
      "Epoch 1137: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.6025 - bpp: 0.7827 - mse: 1.0007e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6672 - bpp: 0.7985 - mse: 1.0605e-04\n",
      "Epoch 1138: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.6672 - bpp: 0.7985 - mse: 1.0605e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5949 - bpp: 0.7863 - mse: 9.8716e-05\n",
      "Epoch 1139: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.5949 - bpp: 0.7863 - mse: 9.8716e-05\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5320 - bpp: 0.7633 - mse: 9.3830e-05\n",
      "Epoch 1140: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5320 - bpp: 0.7633 - mse: 9.3830e-05\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6100 - bpp: 0.7861 - mse: 1.0057e-04\n",
      "Epoch 1141: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.6100 - bpp: 0.7861 - mse: 1.0057e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5871 - bpp: 0.7746 - mse: 9.9185e-05\n",
      "Epoch 1142: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.5871 - bpp: 0.7746 - mse: 9.9185e-05\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7204 - bpp: 0.8032 - mse: 1.1196e-04\n",
      "Epoch 1143: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.7204 - bpp: 0.8032 - mse: 1.1196e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5107 - bpp: 0.7595 - mse: 9.1693e-05\n",
      "Epoch 1144: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5107 - bpp: 0.7595 - mse: 9.1693e-05\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5744 - bpp: 0.7733 - mse: 9.7796e-05\n",
      "Epoch 1145: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5744 - bpp: 0.7733 - mse: 9.7796e-05\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4894 - bpp: 0.7583 - mse: 8.9250e-05\n",
      "Epoch 1146: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4894 - bpp: 0.7583 - mse: 8.9250e-05\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4983 - bpp: 0.7437 - mse: 9.2123e-05\n",
      "Epoch 1147: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4983 - bpp: 0.7437 - mse: 9.2123e-05\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5931 - bpp: 0.7768 - mse: 9.9652e-05\n",
      "Epoch 1148: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5931 - bpp: 0.7768 - mse: 9.9652e-05\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5483 - bpp: 0.7776 - mse: 9.4078e-05\n",
      "Epoch 1149: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5483 - bpp: 0.7776 - mse: 9.4078e-05\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6213 - bpp: 0.7857 - mse: 1.0200e-04\n",
      "Epoch 1150: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.6213 - bpp: 0.7857 - mse: 1.0200e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5009 - bpp: 0.7560 - mse: 9.0923e-05\n",
      "Epoch 1151: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5009 - bpp: 0.7560 - mse: 9.0923e-05\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5650 - bpp: 0.7748 - mse: 9.6456e-05\n",
      "Epoch 1152: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5650 - bpp: 0.7748 - mse: 9.6456e-05\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5426 - bpp: 0.7834 - mse: 9.2674e-05\n",
      "Epoch 1153: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5426 - bpp: 0.7834 - mse: 9.2674e-05\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5959 - bpp: 0.7705 - mse: 1.0075e-04\n",
      "Epoch 1154: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.5959 - bpp: 0.7705 - mse: 1.0075e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5012 - bpp: 0.7448 - mse: 9.2327e-05\n",
      "Epoch 1155: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.5012 - bpp: 0.7448 - mse: 9.2327e-05\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4771 - bpp: 0.7586 - mse: 8.7716e-05\n",
      "Epoch 1156: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4771 - bpp: 0.7586 - mse: 8.7716e-05\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5441 - bpp: 0.7656 - mse: 9.5032e-05\n",
      "Epoch 1157: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5441 - bpp: 0.7656 - mse: 9.5032e-05\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6409 - bpp: 0.7900 - mse: 1.0387e-04\n",
      "Epoch 1158: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6409 - bpp: 0.7900 - mse: 1.0387e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7055 - bpp: 0.8041 - mse: 1.1003e-04\n",
      "Epoch 1159: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 37s 179ms/step - loss: 1.7055 - bpp: 0.8041 - mse: 1.1003e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5291 - bpp: 0.7556 - mse: 9.4414e-05\n",
      "Epoch 1160: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.5291 - bpp: 0.7556 - mse: 9.4414e-05\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6874 - bpp: 0.8001 - mse: 1.0832e-04\n",
      "Epoch 1161: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.6874 - bpp: 0.8001 - mse: 1.0832e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4619 - bpp: 0.7502 - mse: 8.6876e-05\n",
      "Epoch 1162: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.4619 - bpp: 0.7502 - mse: 8.6876e-05\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6202 - bpp: 0.7845 - mse: 1.0201e-04\n",
      "Epoch 1163: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 38s 183ms/step - loss: 1.6202 - bpp: 0.7845 - mse: 1.0201e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6286 - bpp: 0.7767 - mse: 1.0399e-04\n",
      "Epoch 1164: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 164ms/step - loss: 1.6286 - bpp: 0.7767 - mse: 1.0399e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6759 - bpp: 0.7936 - mse: 1.0771e-04\n",
      "Epoch 1165: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6759 - bpp: 0.7936 - mse: 1.0771e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6205 - bpp: 0.7917 - mse: 1.0118e-04\n",
      "Epoch 1166: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.6205 - bpp: 0.7917 - mse: 1.0118e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5140 - bpp: 0.7562 - mse: 9.2515e-05\n",
      "Epoch 1167: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.5140 - bpp: 0.7562 - mse: 9.2515e-05\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5115 - bpp: 0.7630 - mse: 9.1367e-05\n",
      "Epoch 1168: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.5115 - bpp: 0.7630 - mse: 9.1367e-05\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5015 - bpp: 0.7497 - mse: 9.1782e-05\n",
      "Epoch 1169: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.5015 - bpp: 0.7497 - mse: 9.1782e-05\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4863 - bpp: 0.7518 - mse: 8.9663e-05\n",
      "Epoch 1170: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 1.4863 - bpp: 0.7518 - mse: 8.9663e-05\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5831 - bpp: 0.7719 - mse: 9.9026e-05\n",
      "Epoch 1171: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.5831 - bpp: 0.7719 - mse: 9.9026e-05\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5935 - bpp: 0.7856 - mse: 9.8618e-05\n",
      "Epoch 1172: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.5935 - bpp: 0.7856 - mse: 9.8618e-05\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6138 - bpp: 0.7859 - mse: 1.0107e-04\n",
      "Epoch 1173: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.6138 - bpp: 0.7859 - mse: 1.0107e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6640 - bpp: 0.8026 - mse: 1.0516e-04\n",
      "Epoch 1174: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.6640 - bpp: 0.8026 - mse: 1.0516e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4572 - bpp: 0.7411 - mse: 8.7423e-05\n",
      "Epoch 1175: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4572 - bpp: 0.7411 - mse: 8.7423e-05\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5781 - bpp: 0.7775 - mse: 9.7727e-05\n",
      "Epoch 1176: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.5781 - bpp: 0.7775 - mse: 9.7727e-05\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5765 - bpp: 0.7738 - mse: 9.7988e-05\n",
      "Epoch 1177: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5765 - bpp: 0.7738 - mse: 9.7988e-05\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6783 - bpp: 0.8019 - mse: 1.0698e-04\n",
      "Epoch 1178: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.6783 - bpp: 0.8019 - mse: 1.0698e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4723 - bpp: 0.7589 - mse: 8.7083e-05\n",
      "Epoch 1179: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4723 - bpp: 0.7589 - mse: 8.7083e-05\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5493 - bpp: 0.7754 - mse: 9.4472e-05\n",
      "Epoch 1180: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.5493 - bpp: 0.7754 - mse: 9.4472e-05\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5216 - bpp: 0.7634 - mse: 9.2559e-05\n",
      "Epoch 1181: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 161ms/step - loss: 1.5216 - bpp: 0.7634 - mse: 9.2559e-05\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4375 - bpp: 0.7406 - mse: 8.5079e-05\n",
      "Epoch 1182: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4375 - bpp: 0.7406 - mse: 8.5079e-05\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5640 - bpp: 0.7686 - mse: 9.7098e-05\n",
      "Epoch 1183: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.5640 - bpp: 0.7686 - mse: 9.7098e-05\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6651 - bpp: 0.8150 - mse: 1.0377e-04\n",
      "Epoch 1184: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 1.6651 - bpp: 0.8150 - mse: 1.0377e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5667 - bpp: 0.7701 - mse: 9.7232e-05\n",
      "Epoch 1185: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5667 - bpp: 0.7701 - mse: 9.7232e-05\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4597 - bpp: 0.7396 - mse: 8.7901e-05\n",
      "Epoch 1186: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.4597 - bpp: 0.7396 - mse: 8.7901e-05\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5041 - bpp: 0.7571 - mse: 9.1182e-05\n",
      "Epoch 1187: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 1.5041 - bpp: 0.7571 - mse: 9.1182e-05\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5556 - bpp: 0.7783 - mse: 9.4874e-05\n",
      "Epoch 1188: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.5556 - bpp: 0.7783 - mse: 9.4874e-05\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7065 - bpp: 0.7904 - mse: 1.1182e-04\n",
      "Epoch 1189: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 165ms/step - loss: 1.7065 - bpp: 0.7904 - mse: 1.1182e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5333 - bpp: 0.7661 - mse: 9.3649e-05\n",
      "Epoch 1190: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.5333 - bpp: 0.7661 - mse: 9.3649e-05\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4409 - bpp: 0.7354 - mse: 8.6127e-05\n",
      "Epoch 1191: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4409 - bpp: 0.7354 - mse: 8.6127e-05\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4671 - bpp: 0.7457 - mse: 8.8053e-05\n",
      "Epoch 1192: loss did not improve from 1.41648\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4671 - bpp: 0.7457 - mse: 8.8053e-05\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3182 - bpp: 0.7062 - mse: 7.4712e-05\n",
      "Epoch 1193: loss improved from 1.41648 to 1.31820, saving model to checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.3182 - bpp: 0.7062 - mse: 7.4712e-05\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5480 - bpp: 0.7527 - mse: 9.7083e-05\n",
      "Epoch 1194: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5480 - bpp: 0.7527 - mse: 9.7083e-05\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7172 - bpp: 0.8094 - mse: 1.1081e-04\n",
      "Epoch 1195: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.7172 - bpp: 0.8094 - mse: 1.1081e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5890 - bpp: 0.7750 - mse: 9.9364e-05\n",
      "Epoch 1196: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.5890 - bpp: 0.7750 - mse: 9.9364e-05\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5783 - bpp: 0.7738 - mse: 9.8212e-05\n",
      "Epoch 1197: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5783 - bpp: 0.7738 - mse: 9.8212e-05\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6498 - bpp: 0.8011 - mse: 1.0359e-04\n",
      "Epoch 1198: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.6498 - bpp: 0.8011 - mse: 1.0359e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4810 - bpp: 0.7548 - mse: 8.8654e-05\n",
      "Epoch 1199: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.4810 - bpp: 0.7548 - mse: 8.8654e-05\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4244 - bpp: 0.7427 - mse: 8.3212e-05\n",
      "Epoch 1200: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4244 - bpp: 0.7427 - mse: 8.3212e-05\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5617 - bpp: 0.7620 - mse: 9.7613e-05\n",
      "Epoch 1201: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.5617 - bpp: 0.7620 - mse: 9.7613e-05\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5564 - bpp: 0.7544 - mse: 9.7904e-05\n",
      "Epoch 1202: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.5564 - bpp: 0.7544 - mse: 9.7904e-05\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5543 - bpp: 0.7681 - mse: 9.5976e-05\n",
      "Epoch 1203: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 1.5543 - bpp: 0.7681 - mse: 9.5976e-05\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5437 - bpp: 0.7840 - mse: 9.2737e-05\n",
      "Epoch 1204: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.5437 - bpp: 0.7840 - mse: 9.2737e-05\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6873 - bpp: 0.8052 - mse: 1.0768e-04\n",
      "Epoch 1205: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.6873 - bpp: 0.8052 - mse: 1.0768e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6569 - bpp: 0.7983 - mse: 1.0480e-04\n",
      "Epoch 1206: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6569 - bpp: 0.7983 - mse: 1.0480e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5473 - bpp: 0.7650 - mse: 9.5498e-05\n",
      "Epoch 1207: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.5473 - bpp: 0.7650 - mse: 9.5498e-05\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5542 - bpp: 0.7587 - mse: 9.7102e-05\n",
      "Epoch 1208: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5542 - bpp: 0.7587 - mse: 9.7102e-05\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6491 - bpp: 0.7918 - mse: 1.0465e-04\n",
      "Epoch 1209: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.6491 - bpp: 0.7918 - mse: 1.0465e-04\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6375 - bpp: 0.7906 - mse: 1.0337e-04\n",
      "Epoch 1210: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.6375 - bpp: 0.7906 - mse: 1.0337e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5143 - bpp: 0.7713 - mse: 9.0697e-05\n",
      "Epoch 1211: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.5143 - bpp: 0.7713 - mse: 9.0697e-05\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5530 - bpp: 0.7759 - mse: 9.4868e-05\n",
      "Epoch 1212: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.5530 - bpp: 0.7759 - mse: 9.4868e-05\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4289 - bpp: 0.7367 - mse: 8.4507e-05\n",
      "Epoch 1213: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4289 - bpp: 0.7367 - mse: 8.4507e-05\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4251 - bpp: 0.7238 - mse: 8.5601e-05\n",
      "Epoch 1214: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.4251 - bpp: 0.7238 - mse: 8.5601e-05\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5117 - bpp: 0.7576 - mse: 9.2053e-05\n",
      "Epoch 1215: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 1.5117 - bpp: 0.7576 - mse: 9.2053e-05\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4954 - bpp: 0.7450 - mse: 9.1601e-05\n",
      "Epoch 1216: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4954 - bpp: 0.7450 - mse: 9.1601e-05\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5724 - bpp: 0.7764 - mse: 9.7178e-05\n",
      "Epoch 1217: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.5724 - bpp: 0.7764 - mse: 9.7178e-05\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5300 - bpp: 0.7558 - mse: 9.4515e-05\n",
      "Epoch 1218: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.5300 - bpp: 0.7558 - mse: 9.4515e-05\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6559 - bpp: 0.7891 - mse: 1.0581e-04\n",
      "Epoch 1219: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 1.6559 - bpp: 0.7891 - mse: 1.0581e-04\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4822 - bpp: 0.7545 - mse: 8.8840e-05\n",
      "Epoch 1220: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.4822 - bpp: 0.7545 - mse: 8.8840e-05\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6809 - bpp: 0.7898 - mse: 1.0877e-04\n",
      "Epoch 1221: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6809 - bpp: 0.7898 - mse: 1.0877e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6393 - bpp: 0.8044 - mse: 1.0192e-04\n",
      "Epoch 1222: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.6393 - bpp: 0.8044 - mse: 1.0192e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4360 - bpp: 0.7422 - mse: 8.4695e-05\n",
      "Epoch 1223: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.4360 - bpp: 0.7422 - mse: 8.4695e-05\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6009 - bpp: 0.7873 - mse: 9.9316e-05\n",
      "Epoch 1224: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 1.6009 - bpp: 0.7873 - mse: 9.9316e-05\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7412 - bpp: 0.8249 - mse: 1.1185e-04\n",
      "Epoch 1225: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.7412 - bpp: 0.8249 - mse: 1.1185e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4695 - bpp: 0.7573 - mse: 8.6936e-05\n",
      "Epoch 1226: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.4695 - bpp: 0.7573 - mse: 8.6936e-05\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6241 - bpp: 0.7769 - mse: 1.0342e-04\n",
      "Epoch 1227: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.6241 - bpp: 0.7769 - mse: 1.0342e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4589 - bpp: 0.7323 - mse: 8.8699e-05\n",
      "Epoch 1228: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.4589 - bpp: 0.7323 - mse: 8.8699e-05\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6798 - bpp: 0.8274 - mse: 1.0405e-04\n",
      "Epoch 1229: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.6798 - bpp: 0.8274 - mse: 1.0405e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5601 - bpp: 0.7656 - mse: 9.6991e-05\n",
      "Epoch 1230: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.5601 - bpp: 0.7656 - mse: 9.6991e-05\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4658 - bpp: 0.7372 - mse: 8.8939e-05\n",
      "Epoch 1231: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 1.4658 - bpp: 0.7372 - mse: 8.8939e-05\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6975 - bpp: 0.7973 - mse: 1.0989e-04\n",
      "Epoch 1232: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.6975 - bpp: 0.7973 - mse: 1.0989e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5572 - bpp: 0.7590 - mse: 9.7441e-05\n",
      "Epoch 1233: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 1.5572 - bpp: 0.7590 - mse: 9.7441e-05\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3930 - bpp: 0.7302 - mse: 8.0908e-05\n",
      "Epoch 1234: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.3930 - bpp: 0.7302 - mse: 8.0908e-05\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5191 - bpp: 0.7609 - mse: 9.2561e-05\n",
      "Epoch 1235: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.5191 - bpp: 0.7609 - mse: 9.2561e-05\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4592 - bpp: 0.7411 - mse: 8.7665e-05\n",
      "Epoch 1236: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.4592 - bpp: 0.7411 - mse: 8.7665e-05\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5248 - bpp: 0.7629 - mse: 9.3012e-05\n",
      "Epoch 1237: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.5248 - bpp: 0.7629 - mse: 9.3012e-05\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5007 - bpp: 0.7496 - mse: 9.1685e-05\n",
      "Epoch 1238: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.5007 - bpp: 0.7496 - mse: 9.1685e-05\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5080 - bpp: 0.7585 - mse: 9.1486e-05\n",
      "Epoch 1239: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1.5080 - bpp: 0.7585 - mse: 9.1486e-05\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5372 - bpp: 0.7758 - mse: 9.2954e-05\n",
      "Epoch 1240: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.5372 - bpp: 0.7758 - mse: 9.2954e-05\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5959 - bpp: 0.7693 - mse: 1.0091e-04\n",
      "Epoch 1241: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5959 - bpp: 0.7693 - mse: 1.0091e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3976 - bpp: 0.7274 - mse: 8.1823e-05\n",
      "Epoch 1242: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.3976 - bpp: 0.7274 - mse: 8.1823e-05\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6098 - bpp: 0.7836 - mse: 1.0085e-04\n",
      "Epoch 1243: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 1.6098 - bpp: 0.7836 - mse: 1.0085e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5204 - bpp: 0.7730 - mse: 9.1237e-05\n",
      "Epoch 1244: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5204 - bpp: 0.7730 - mse: 9.1237e-05\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4129 - bpp: 0.7369 - mse: 8.2520e-05\n",
      "Epoch 1245: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.4129 - bpp: 0.7369 - mse: 8.2520e-05\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4231 - bpp: 0.7330 - mse: 8.4238e-05\n",
      "Epoch 1246: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1.4231 - bpp: 0.7330 - mse: 8.4238e-05\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6170 - bpp: 0.7808 - mse: 1.0208e-04\n",
      "Epoch 1247: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.6170 - bpp: 0.7808 - mse: 1.0208e-04\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6383 - bpp: 0.7924 - mse: 1.0326e-04\n",
      "Epoch 1248: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.6383 - bpp: 0.7924 - mse: 1.0326e-04\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4760 - bpp: 0.7442 - mse: 8.9329e-05\n",
      "Epoch 1249: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.4760 - bpp: 0.7442 - mse: 8.9329e-05\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4920 - bpp: 0.7568 - mse: 8.9742e-05\n",
      "Epoch 1250: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.4920 - bpp: 0.7568 - mse: 8.9742e-05\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5705 - bpp: 0.7798 - mse: 9.6520e-05\n",
      "Epoch 1251: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.5705 - bpp: 0.7798 - mse: 9.6520e-05\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5553 - bpp: 0.7738 - mse: 9.5396e-05\n",
      "Epoch 1252: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.5553 - bpp: 0.7738 - mse: 9.5396e-05\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5815 - bpp: 0.7783 - mse: 9.8052e-05\n",
      "Epoch 1253: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5815 - bpp: 0.7783 - mse: 9.8052e-05\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6299 - bpp: 0.7724 - mse: 1.0468e-04\n",
      "Epoch 1254: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6299 - bpp: 0.7724 - mse: 1.0468e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4457 - bpp: 0.7434 - mse: 8.5729e-05\n",
      "Epoch 1255: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.4457 - bpp: 0.7434 - mse: 8.5729e-05\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6217 - bpp: 0.7815 - mse: 1.0256e-04\n",
      "Epoch 1256: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6217 - bpp: 0.7815 - mse: 1.0256e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6183 - bpp: 0.7728 - mse: 1.0321e-04\n",
      "Epoch 1257: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.6183 - bpp: 0.7728 - mse: 1.0321e-04\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5485 - bpp: 0.7610 - mse: 9.6136e-05\n",
      "Epoch 1258: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.5485 - bpp: 0.7610 - mse: 9.6136e-05\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5487 - bpp: 0.7557 - mse: 9.6799e-05\n",
      "Epoch 1259: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 1.5487 - bpp: 0.7557 - mse: 9.6799e-05\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6116 - bpp: 0.7939 - mse: 9.9818e-05\n",
      "Epoch 1260: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 1.6116 - bpp: 0.7939 - mse: 9.9818e-05\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5059 - bpp: 0.7562 - mse: 9.1511e-05\n",
      "Epoch 1261: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.5059 - bpp: 0.7562 - mse: 9.1511e-05\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5272 - bpp: 0.7628 - mse: 9.3312e-05\n",
      "Epoch 1262: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 1.5272 - bpp: 0.7628 - mse: 9.3312e-05\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5596 - bpp: 0.7657 - mse: 9.6913e-05\n",
      "Epoch 1263: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 1.5596 - bpp: 0.7657 - mse: 9.6913e-05\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5878 - bpp: 0.7848 - mse: 9.8024e-05\n",
      "Epoch 1264: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 1.5878 - bpp: 0.7848 - mse: 9.8024e-05\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5932 - bpp: 0.7772 - mse: 9.9610e-05\n",
      "Epoch 1265: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 1.5932 - bpp: 0.7772 - mse: 9.9610e-05\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5323 - bpp: 0.7465 - mse: 9.5915e-05\n",
      "Epoch 1266: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 1.5323 - bpp: 0.7465 - mse: 9.5915e-05\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5302 - bpp: 0.7521 - mse: 9.4986e-05\n",
      "Epoch 1267: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.5302 - bpp: 0.7521 - mse: 9.4986e-05\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5827 - bpp: 0.7828 - mse: 9.7634e-05\n",
      "Epoch 1268: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 1.5827 - bpp: 0.7828 - mse: 9.7634e-05\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4926 - bpp: 0.7414 - mse: 9.1705e-05\n",
      "Epoch 1269: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.4926 - bpp: 0.7414 - mse: 9.1705e-05\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5405 - bpp: 0.7744 - mse: 9.3516e-05\n",
      "Epoch 1270: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.5405 - bpp: 0.7744 - mse: 9.3516e-05\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6480 - bpp: 0.7794 - mse: 1.0604e-04\n",
      "Epoch 1271: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.6480 - bpp: 0.7794 - mse: 1.0604e-04\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5458 - bpp: 0.7746 - mse: 9.4142e-05\n",
      "Epoch 1272: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 1.5458 - bpp: 0.7746 - mse: 9.4142e-05\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6060 - bpp: 0.7659 - mse: 1.0255e-04\n",
      "Epoch 1273: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 1.6060 - bpp: 0.7659 - mse: 1.0255e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4441 - bpp: 0.7449 - mse: 8.5351e-05\n",
      "Epoch 1274: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.4441 - bpp: 0.7449 - mse: 8.5351e-05\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5456 - bpp: 0.7590 - mse: 9.6027e-05\n",
      "Epoch 1275: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.5456 - bpp: 0.7590 - mse: 9.6027e-05\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7018 - bpp: 0.7997 - mse: 1.1012e-04\n",
      "Epoch 1276: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 1.7018 - bpp: 0.7997 - mse: 1.1012e-04\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5311 - bpp: 0.7663 - mse: 9.3358e-05\n",
      "Epoch 1277: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 1.5311 - bpp: 0.7663 - mse: 9.3358e-05\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6339 - bpp: 0.7840 - mse: 1.0375e-04\n",
      "Epoch 1278: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.6339 - bpp: 0.7840 - mse: 1.0375e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4822 - bpp: 0.7390 - mse: 9.0718e-05\n",
      "Epoch 1279: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 1.4822 - bpp: 0.7390 - mse: 9.0718e-05\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5977 - bpp: 0.7809 - mse: 9.9698e-05\n",
      "Epoch 1280: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 1.5977 - bpp: 0.7809 - mse: 9.9698e-05\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5974 - bpp: 0.7775 - mse: 1.0009e-04\n",
      "Epoch 1281: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5974 - bpp: 0.7775 - mse: 1.0009e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5701 - bpp: 0.7790 - mse: 9.6575e-05\n",
      "Epoch 1282: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5701 - bpp: 0.7790 - mse: 9.6575e-05\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4974 - bpp: 0.7525 - mse: 9.0941e-05\n",
      "Epoch 1283: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4974 - bpp: 0.7525 - mse: 9.0941e-05\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5482 - bpp: 0.7629 - mse: 9.5859e-05\n",
      "Epoch 1284: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5482 - bpp: 0.7629 - mse: 9.5859e-05\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5848 - bpp: 0.7837 - mse: 9.7789e-05\n",
      "Epoch 1285: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5848 - bpp: 0.7837 - mse: 9.7789e-05\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5018 - bpp: 0.7424 - mse: 9.2700e-05\n",
      "Epoch 1286: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5018 - bpp: 0.7424 - mse: 9.2700e-05\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4483 - bpp: 0.7481 - mse: 8.5465e-05\n",
      "Epoch 1287: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4483 - bpp: 0.7481 - mse: 8.5465e-05\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5584 - bpp: 0.7765 - mse: 9.5456e-05\n",
      "Epoch 1288: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5584 - bpp: 0.7765 - mse: 9.5456e-05\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6247 - bpp: 0.7796 - mse: 1.0317e-04\n",
      "Epoch 1289: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.6247 - bpp: 0.7796 - mse: 1.0317e-04\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5873 - bpp: 0.7804 - mse: 9.8507e-05\n",
      "Epoch 1290: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5873 - bpp: 0.7804 - mse: 9.8507e-05\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6187 - bpp: 0.7905 - mse: 1.0111e-04\n",
      "Epoch 1291: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 194ms/step - loss: 1.6187 - bpp: 0.7905 - mse: 1.0111e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5698 - bpp: 0.7694 - mse: 9.7704e-05\n",
      "Epoch 1292: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5698 - bpp: 0.7694 - mse: 9.7704e-05\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4818 - bpp: 0.7229 - mse: 9.2634e-05\n",
      "Epoch 1293: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4818 - bpp: 0.7229 - mse: 9.2634e-05\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4640 - bpp: 0.7388 - mse: 8.8523e-05\n",
      "Epoch 1294: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4640 - bpp: 0.7388 - mse: 8.8523e-05\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5523 - bpp: 0.7742 - mse: 9.4986e-05\n",
      "Epoch 1295: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5523 - bpp: 0.7742 - mse: 9.4986e-05\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5010 - bpp: 0.7408 - mse: 9.2797e-05\n",
      "Epoch 1296: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5010 - bpp: 0.7408 - mse: 9.2797e-05\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5481 - bpp: 0.7524 - mse: 9.7135e-05\n",
      "Epoch 1297: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.5481 - bpp: 0.7524 - mse: 9.7135e-05\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5898 - bpp: 0.7799 - mse: 9.8868e-05\n",
      "Epoch 1298: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5898 - bpp: 0.7799 - mse: 9.8868e-05\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5917 - bpp: 0.7747 - mse: 9.9733e-05\n",
      "Epoch 1299: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5917 - bpp: 0.7747 - mse: 9.9733e-05\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5315 - bpp: 0.7532 - mse: 9.5015e-05\n",
      "Epoch 1300: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5315 - bpp: 0.7532 - mse: 9.5015e-05\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7548 - bpp: 0.8342 - mse: 1.1238e-04\n",
      "Epoch 1301: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.7548 - bpp: 0.8342 - mse: 1.1238e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4473 - bpp: 0.7343 - mse: 8.7038e-05\n",
      "Epoch 1302: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4473 - bpp: 0.7343 - mse: 8.7038e-05\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4982 - bpp: 0.7408 - mse: 9.2463e-05\n",
      "Epoch 1303: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.4982 - bpp: 0.7408 - mse: 9.2463e-05\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7476 - bpp: 0.8389 - mse: 1.1091e-04\n",
      "Epoch 1304: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.7476 - bpp: 0.8389 - mse: 1.1091e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4690 - bpp: 0.7429 - mse: 8.8636e-05\n",
      "Epoch 1305: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.4690 - bpp: 0.7429 - mse: 8.8636e-05\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5762 - bpp: 0.7637 - mse: 9.9177e-05\n",
      "Epoch 1306: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5762 - bpp: 0.7637 - mse: 9.9177e-05\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4946 - bpp: 0.7646 - mse: 8.9112e-05\n",
      "Epoch 1307: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4946 - bpp: 0.7646 - mse: 8.9112e-05\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5752 - bpp: 0.7731 - mse: 9.7907e-05\n",
      "Epoch 1308: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 1.5752 - bpp: 0.7731 - mse: 9.7907e-05\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5450 - bpp: 0.7682 - mse: 9.4826e-05\n",
      "Epoch 1309: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5450 - bpp: 0.7682 - mse: 9.4826e-05\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7115 - bpp: 0.8048 - mse: 1.1068e-04\n",
      "Epoch 1310: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 178ms/step - loss: 1.7115 - bpp: 0.8048 - mse: 1.1068e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5787 - bpp: 0.7770 - mse: 9.7864e-05\n",
      "Epoch 1311: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.5787 - bpp: 0.7770 - mse: 9.7864e-05\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6736 - bpp: 0.7790 - mse: 1.0921e-04\n",
      "Epoch 1312: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6736 - bpp: 0.7790 - mse: 1.0921e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6242 - bpp: 0.7995 - mse: 1.0067e-04\n",
      "Epoch 1313: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 1.6242 - bpp: 0.7995 - mse: 1.0067e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5354 - bpp: 0.7597 - mse: 9.4690e-05\n",
      "Epoch 1314: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5354 - bpp: 0.7597 - mse: 9.4690e-05\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5038 - bpp: 0.7562 - mse: 9.1259e-05\n",
      "Epoch 1315: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.5038 - bpp: 0.7562 - mse: 9.1259e-05\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5539 - bpp: 0.7662 - mse: 9.6155e-05\n",
      "Epoch 1316: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5539 - bpp: 0.7662 - mse: 9.6155e-05\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4966 - bpp: 0.7538 - mse: 9.0676e-05\n",
      "Epoch 1317: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4966 - bpp: 0.7538 - mse: 9.0676e-05\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4534 - bpp: 0.7458 - mse: 8.6373e-05\n",
      "Epoch 1318: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.4534 - bpp: 0.7458 - mse: 8.6373e-05\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4918 - bpp: 0.7667 - mse: 8.8501e-05\n",
      "Epoch 1319: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.4918 - bpp: 0.7667 - mse: 8.8501e-05\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6877 - bpp: 0.8088 - mse: 1.0730e-04\n",
      "Epoch 1320: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.6877 - bpp: 0.8088 - mse: 1.0730e-04\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4766 - bpp: 0.7512 - mse: 8.8552e-05\n",
      "Epoch 1321: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4766 - bpp: 0.7512 - mse: 8.8552e-05\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4619 - bpp: 0.7372 - mse: 8.8470e-05\n",
      "Epoch 1322: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.4619 - bpp: 0.7372 - mse: 8.8470e-05\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5028 - bpp: 0.7662 - mse: 8.9927e-05\n",
      "Epoch 1323: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5028 - bpp: 0.7662 - mse: 8.9927e-05\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5603 - bpp: 0.7725 - mse: 9.6168e-05\n",
      "Epoch 1324: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5603 - bpp: 0.7725 - mse: 9.6168e-05\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6262 - bpp: 0.7916 - mse: 1.0188e-04\n",
      "Epoch 1325: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.6262 - bpp: 0.7916 - mse: 1.0188e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5487 - bpp: 0.7649 - mse: 9.5684e-05\n",
      "Epoch 1326: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5487 - bpp: 0.7649 - mse: 9.5684e-05\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4345 - bpp: 0.7457 - mse: 8.4082e-05\n",
      "Epoch 1327: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4345 - bpp: 0.7457 - mse: 8.4082e-05\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5764 - bpp: 0.7815 - mse: 9.7031e-05\n",
      "Epoch 1328: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5764 - bpp: 0.7815 - mse: 9.7031e-05\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6378 - bpp: 0.7994 - mse: 1.0235e-04\n",
      "Epoch 1329: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.6378 - bpp: 0.7994 - mse: 1.0235e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4526 - bpp: 0.7401 - mse: 8.6977e-05\n",
      "Epoch 1330: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4526 - bpp: 0.7401 - mse: 8.6977e-05\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5096 - bpp: 0.7527 - mse: 9.2389e-05\n",
      "Epoch 1331: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 185ms/step - loss: 1.5096 - bpp: 0.7527 - mse: 9.2389e-05\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5828 - bpp: 0.7805 - mse: 9.7940e-05\n",
      "Epoch 1332: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5828 - bpp: 0.7805 - mse: 9.7940e-05\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5580 - bpp: 0.7813 - mse: 9.4815e-05\n",
      "Epoch 1333: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5580 - bpp: 0.7813 - mse: 9.4815e-05\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6286 - bpp: 0.7834 - mse: 1.0317e-04\n",
      "Epoch 1334: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.6286 - bpp: 0.7834 - mse: 1.0317e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5785 - bpp: 0.7846 - mse: 9.6915e-05\n",
      "Epoch 1335: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5785 - bpp: 0.7846 - mse: 9.6915e-05\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5192 - bpp: 0.7676 - mse: 9.1752e-05\n",
      "Epoch 1336: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5192 - bpp: 0.7676 - mse: 9.1752e-05\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5721 - bpp: 0.7722 - mse: 9.7637e-05\n",
      "Epoch 1337: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5721 - bpp: 0.7722 - mse: 9.7637e-05\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5873 - bpp: 0.7696 - mse: 9.9825e-05\n",
      "Epoch 1338: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5873 - bpp: 0.7696 - mse: 9.9825e-05\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5308 - bpp: 0.7613 - mse: 9.3933e-05\n",
      "Epoch 1339: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5308 - bpp: 0.7613 - mse: 9.3933e-05\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5638 - bpp: 0.7818 - mse: 9.5460e-05\n",
      "Epoch 1340: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5638 - bpp: 0.7818 - mse: 9.5460e-05\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4625 - bpp: 0.7508 - mse: 8.6872e-05\n",
      "Epoch 1341: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4625 - bpp: 0.7508 - mse: 8.6872e-05\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5681 - bpp: 0.7804 - mse: 9.6162e-05\n",
      "Epoch 1342: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5681 - bpp: 0.7804 - mse: 9.6162e-05\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5112 - bpp: 0.7602 - mse: 9.1680e-05\n",
      "Epoch 1343: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5112 - bpp: 0.7602 - mse: 9.1680e-05\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5354 - bpp: 0.7652 - mse: 9.4029e-05\n",
      "Epoch 1344: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.5354 - bpp: 0.7652 - mse: 9.4029e-05\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5158 - bpp: 0.7643 - mse: 9.1730e-05\n",
      "Epoch 1345: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5158 - bpp: 0.7643 - mse: 9.1730e-05\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6164 - bpp: 0.7854 - mse: 1.0144e-04\n",
      "Epoch 1346: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6164 - bpp: 0.7854 - mse: 1.0144e-04\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5081 - bpp: 0.7617 - mse: 9.1112e-05\n",
      "Epoch 1347: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.5081 - bpp: 0.7617 - mse: 9.1112e-05\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4429 - bpp: 0.7258 - mse: 8.7536e-05\n",
      "Epoch 1348: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4429 - bpp: 0.7258 - mse: 8.7536e-05\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6157 - bpp: 0.8050 - mse: 9.8956e-05\n",
      "Epoch 1349: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.6157 - bpp: 0.8050 - mse: 9.8956e-05\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5295 - bpp: 0.7615 - mse: 9.3751e-05\n",
      "Epoch 1350: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5295 - bpp: 0.7615 - mse: 9.3751e-05\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5349 - bpp: 0.7546 - mse: 9.5246e-05\n",
      "Epoch 1351: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.5349 - bpp: 0.7546 - mse: 9.5246e-05\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5045 - bpp: 0.7512 - mse: 9.1957e-05\n",
      "Epoch 1352: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.5045 - bpp: 0.7512 - mse: 9.1957e-05\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3540 - bpp: 0.7073 - mse: 7.8953e-05\n",
      "Epoch 1353: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.3540 - bpp: 0.7073 - mse: 7.8953e-05\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4578 - bpp: 0.7427 - mse: 8.7288e-05\n",
      "Epoch 1354: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.4578 - bpp: 0.7427 - mse: 8.7288e-05\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5380 - bpp: 0.7665 - mse: 9.4175e-05\n",
      "Epoch 1355: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5380 - bpp: 0.7665 - mse: 9.4175e-05\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4355 - bpp: 0.7430 - mse: 8.4527e-05\n",
      "Epoch 1356: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.4355 - bpp: 0.7430 - mse: 8.4527e-05\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6274 - bpp: 0.7942 - mse: 1.0171e-04\n",
      "Epoch 1357: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.6274 - bpp: 0.7942 - mse: 1.0171e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5137 - bpp: 0.7570 - mse: 9.2379e-05\n",
      "Epoch 1358: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.5137 - bpp: 0.7570 - mse: 9.2379e-05\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4532 - bpp: 0.7356 - mse: 8.7592e-05\n",
      "Epoch 1359: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4532 - bpp: 0.7356 - mse: 8.7592e-05\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6351 - bpp: 0.7987 - mse: 1.0211e-04\n",
      "Epoch 1360: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.6351 - bpp: 0.7987 - mse: 1.0211e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6193 - bpp: 0.7747 - mse: 1.0309e-04\n",
      "Epoch 1361: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.6193 - bpp: 0.7747 - mse: 1.0309e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5565 - bpp: 0.7670 - mse: 9.6385e-05\n",
      "Epoch 1362: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.5565 - bpp: 0.7670 - mse: 9.6385e-05\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5773 - bpp: 0.7692 - mse: 9.8643e-05\n",
      "Epoch 1363: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5773 - bpp: 0.7692 - mse: 9.8643e-05\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6882 - bpp: 0.7961 - mse: 1.0889e-04\n",
      "Epoch 1364: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.6882 - bpp: 0.7961 - mse: 1.0889e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4058 - bpp: 0.7326 - mse: 8.2175e-05\n",
      "Epoch 1365: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4058 - bpp: 0.7326 - mse: 8.2175e-05\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7504 - bpp: 0.8180 - mse: 1.1381e-04\n",
      "Epoch 1366: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.7504 - bpp: 0.8180 - mse: 1.1381e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4764 - bpp: 0.7517 - mse: 8.8474e-05\n",
      "Epoch 1367: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.4764 - bpp: 0.7517 - mse: 8.8474e-05\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5726 - bpp: 0.7589 - mse: 9.9331e-05\n",
      "Epoch 1368: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.5726 - bpp: 0.7589 - mse: 9.9331e-05\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5681 - bpp: 0.7689 - mse: 9.7561e-05\n",
      "Epoch 1369: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5681 - bpp: 0.7689 - mse: 9.7561e-05\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5175 - bpp: 0.7687 - mse: 9.1406e-05\n",
      "Epoch 1370: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5175 - bpp: 0.7687 - mse: 9.1406e-05\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5634 - bpp: 0.7572 - mse: 9.8421e-05\n",
      "Epoch 1371: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.5634 - bpp: 0.7572 - mse: 9.8421e-05\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6680 - bpp: 0.8098 - mse: 1.0476e-04\n",
      "Epoch 1372: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.6680 - bpp: 0.8098 - mse: 1.0476e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5683 - bpp: 0.7913 - mse: 9.4855e-05\n",
      "Epoch 1373: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5683 - bpp: 0.7913 - mse: 9.4855e-05\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4727 - bpp: 0.7395 - mse: 8.9499e-05\n",
      "Epoch 1374: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.4727 - bpp: 0.7395 - mse: 8.9499e-05\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6814 - bpp: 0.7997 - mse: 1.0763e-04\n",
      "Epoch 1375: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.6814 - bpp: 0.7997 - mse: 1.0763e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5542 - bpp: 0.7773 - mse: 9.4833e-05\n",
      "Epoch 1376: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5542 - bpp: 0.7773 - mse: 9.4833e-05\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5264 - bpp: 0.7650 - mse: 9.2944e-05\n",
      "Epoch 1377: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5264 - bpp: 0.7650 - mse: 9.2944e-05\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6533 - bpp: 0.7985 - mse: 1.0433e-04\n",
      "Epoch 1378: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.6533 - bpp: 0.7985 - mse: 1.0433e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4974 - bpp: 0.7564 - mse: 9.0456e-05\n",
      "Epoch 1379: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4974 - bpp: 0.7564 - mse: 9.0456e-05\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8215 - bpp: 0.8463 - mse: 1.1905e-04\n",
      "Epoch 1380: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.8215 - bpp: 0.8463 - mse: 1.1905e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5974 - bpp: 0.7869 - mse: 9.8939e-05\n",
      "Epoch 1381: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5974 - bpp: 0.7869 - mse: 9.8939e-05\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5335 - bpp: 0.7788 - mse: 9.2119e-05\n",
      "Epoch 1382: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.5335 - bpp: 0.7788 - mse: 9.2119e-05\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6000 - bpp: 0.7763 - mse: 1.0056e-04\n",
      "Epoch 1383: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 1.6000 - bpp: 0.7763 - mse: 1.0056e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4557 - bpp: 0.7465 - mse: 8.6565e-05\n",
      "Epoch 1384: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.4557 - bpp: 0.7465 - mse: 8.6565e-05\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5327 - bpp: 0.7651 - mse: 9.3708e-05\n",
      "Epoch 1385: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5327 - bpp: 0.7651 - mse: 9.3708e-05\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5145 - bpp: 0.7651 - mse: 9.1488e-05\n",
      "Epoch 1386: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5145 - bpp: 0.7651 - mse: 9.1488e-05\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4781 - bpp: 0.7396 - mse: 9.0150e-05\n",
      "Epoch 1387: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4781 - bpp: 0.7396 - mse: 9.0150e-05\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6125 - bpp: 0.7722 - mse: 1.0258e-04\n",
      "Epoch 1388: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6125 - bpp: 0.7722 - mse: 1.0258e-04\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6864 - bpp: 0.7852 - mse: 1.1000e-04\n",
      "Epoch 1389: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 1.6864 - bpp: 0.7852 - mse: 1.1000e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4282 - bpp: 0.7427 - mse: 8.3679e-05\n",
      "Epoch 1390: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.4282 - bpp: 0.7427 - mse: 8.3679e-05\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6170 - bpp: 0.7862 - mse: 1.0142e-04\n",
      "Epoch 1391: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 1.6170 - bpp: 0.7862 - mse: 1.0142e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5562 - bpp: 0.7678 - mse: 9.6242e-05\n",
      "Epoch 1392: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.5562 - bpp: 0.7678 - mse: 9.6242e-05\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5500 - bpp: 0.7773 - mse: 9.4319e-05\n",
      "Epoch 1393: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5500 - bpp: 0.7773 - mse: 9.4319e-05\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6483 - bpp: 0.7869 - mse: 1.0515e-04\n",
      "Epoch 1394: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.6483 - bpp: 0.7869 - mse: 1.0515e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5432 - bpp: 0.7746 - mse: 9.3823e-05\n",
      "Epoch 1395: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5432 - bpp: 0.7746 - mse: 9.3823e-05\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7046 - bpp: 0.8001 - mse: 1.1040e-04\n",
      "Epoch 1396: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.7046 - bpp: 0.8001 - mse: 1.1040e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5800 - bpp: 0.7849 - mse: 9.7059e-05\n",
      "Epoch 1397: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.5800 - bpp: 0.7849 - mse: 9.7059e-05\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5876 - bpp: 0.7670 - mse: 1.0017e-04\n",
      "Epoch 1398: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.5876 - bpp: 0.7670 - mse: 1.0017e-04\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5535 - bpp: 0.7605 - mse: 9.6800e-05\n",
      "Epoch 1399: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5535 - bpp: 0.7605 - mse: 9.6800e-05\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5312 - bpp: 0.7829 - mse: 9.1346e-05\n",
      "Epoch 1400: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5312 - bpp: 0.7829 - mse: 9.1346e-05\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5836 - bpp: 0.7679 - mse: 9.9567e-05\n",
      "Epoch 1401: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5836 - bpp: 0.7679 - mse: 9.9567e-05\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5289 - bpp: 0.7551 - mse: 9.4448e-05\n",
      "Epoch 1402: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5289 - bpp: 0.7551 - mse: 9.4448e-05\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6132 - bpp: 0.7972 - mse: 9.9608e-05\n",
      "Epoch 1403: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 1.6132 - bpp: 0.7972 - mse: 9.9608e-05\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5607 - bpp: 0.7845 - mse: 9.4752e-05\n",
      "Epoch 1404: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5607 - bpp: 0.7845 - mse: 9.4752e-05\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4851 - bpp: 0.7464 - mse: 9.0174e-05\n",
      "Epoch 1405: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.4851 - bpp: 0.7464 - mse: 9.0174e-05\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6029 - bpp: 0.7865 - mse: 9.9655e-05\n",
      "Epoch 1406: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.6029 - bpp: 0.7865 - mse: 9.9655e-05\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5651 - bpp: 0.7521 - mse: 9.9244e-05\n",
      "Epoch 1407: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 1.5651 - bpp: 0.7521 - mse: 9.9244e-05\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4263 - bpp: 0.7179 - mse: 8.6469e-05\n",
      "Epoch 1408: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.4263 - bpp: 0.7179 - mse: 8.6469e-05\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4757 - bpp: 0.7410 - mse: 8.9687e-05\n",
      "Epoch 1409: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4757 - bpp: 0.7410 - mse: 8.9687e-05\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4922 - bpp: 0.7594 - mse: 8.9457e-05\n",
      "Epoch 1410: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.4922 - bpp: 0.7594 - mse: 8.9457e-05\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5883 - bpp: 0.7736 - mse: 9.9444e-05\n",
      "Epoch 1411: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 1.5883 - bpp: 0.7736 - mse: 9.9444e-05\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4459 - bpp: 0.7502 - mse: 8.4923e-05\n",
      "Epoch 1412: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4459 - bpp: 0.7502 - mse: 8.4923e-05\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4981 - bpp: 0.7491 - mse: 9.1427e-05\n",
      "Epoch 1413: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.4981 - bpp: 0.7491 - mse: 9.1427e-05\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6971 - bpp: 0.7820 - mse: 1.1170e-04\n",
      "Epoch 1414: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 1.6971 - bpp: 0.7820 - mse: 1.1170e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5073 - bpp: 0.7476 - mse: 9.2736e-05\n",
      "Epoch 1415: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 1.5073 - bpp: 0.7476 - mse: 9.2736e-05\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5766 - bpp: 0.7632 - mse: 9.9294e-05\n",
      "Epoch 1416: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5766 - bpp: 0.7632 - mse: 9.9294e-05\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4458 - bpp: 0.7483 - mse: 8.5151e-05\n",
      "Epoch 1417: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.4458 - bpp: 0.7483 - mse: 8.5151e-05\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4130 - bpp: 0.7399 - mse: 8.2171e-05\n",
      "Epoch 1418: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.4130 - bpp: 0.7399 - mse: 8.2171e-05\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6120 - bpp: 0.7777 - mse: 1.0184e-04\n",
      "Epoch 1419: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6120 - bpp: 0.7777 - mse: 1.0184e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5373 - bpp: 0.7607 - mse: 9.4801e-05\n",
      "Epoch 1420: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5373 - bpp: 0.7607 - mse: 9.4801e-05\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5597 - bpp: 0.7771 - mse: 9.5534e-05\n",
      "Epoch 1421: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5597 - bpp: 0.7771 - mse: 9.5534e-05\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5256 - bpp: 0.7643 - mse: 9.2932e-05\n",
      "Epoch 1422: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 178ms/step - loss: 1.5256 - bpp: 0.7643 - mse: 9.2932e-05\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5026 - bpp: 0.7597 - mse: 9.0692e-05\n",
      "Epoch 1423: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 1.5026 - bpp: 0.7597 - mse: 9.0692e-05\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5251 - bpp: 0.7727 - mse: 9.1844e-05\n",
      "Epoch 1424: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 1.5251 - bpp: 0.7727 - mse: 9.1844e-05\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5798 - bpp: 0.7779 - mse: 9.7893e-05\n",
      "Epoch 1425: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 1.5798 - bpp: 0.7779 - mse: 9.7893e-05\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6544 - bpp: 0.7869 - mse: 1.0589e-04\n",
      "Epoch 1426: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 1.6544 - bpp: 0.7869 - mse: 1.0589e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6419 - bpp: 0.7859 - mse: 1.0450e-04\n",
      "Epoch 1427: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6419 - bpp: 0.7859 - mse: 1.0450e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5841 - bpp: 0.7829 - mse: 9.7806e-05\n",
      "Epoch 1428: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 1.5841 - bpp: 0.7829 - mse: 9.7806e-05\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5301 - bpp: 0.7584 - mse: 9.4203e-05\n",
      "Epoch 1429: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.5301 - bpp: 0.7584 - mse: 9.4203e-05\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4937 - bpp: 0.7491 - mse: 9.0888e-05\n",
      "Epoch 1430: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.4937 - bpp: 0.7491 - mse: 9.0888e-05\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4708 - bpp: 0.7430 - mse: 8.8842e-05\n",
      "Epoch 1431: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 1.4708 - bpp: 0.7430 - mse: 8.8842e-05\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6408 - bpp: 0.8016 - mse: 1.0244e-04\n",
      "Epoch 1432: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.6408 - bpp: 0.8016 - mse: 1.0244e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4593 - bpp: 0.7341 - mse: 8.8535e-05\n",
      "Epoch 1433: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 1.4593 - bpp: 0.7341 - mse: 8.8535e-05\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5759 - bpp: 0.7468 - mse: 1.0122e-04\n",
      "Epoch 1434: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.5759 - bpp: 0.7468 - mse: 1.0122e-04\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5289 - bpp: 0.7555 - mse: 9.4409e-05\n",
      "Epoch 1435: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.5289 - bpp: 0.7555 - mse: 9.4409e-05\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6662 - bpp: 0.7998 - mse: 1.0576e-04\n",
      "Epoch 1436: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.6662 - bpp: 0.7998 - mse: 1.0576e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6189 - bpp: 0.7760 - mse: 1.0289e-04\n",
      "Epoch 1437: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 1.6189 - bpp: 0.7760 - mse: 1.0289e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5694 - bpp: 0.7783 - mse: 9.6571e-05\n",
      "Epoch 1438: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 1.5694 - bpp: 0.7783 - mse: 9.6571e-05\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5495 - bpp: 0.7570 - mse: 9.6743e-05\n",
      "Epoch 1439: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 1.5495 - bpp: 0.7570 - mse: 9.6743e-05\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5109 - bpp: 0.7659 - mse: 9.0938e-05\n",
      "Epoch 1440: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5109 - bpp: 0.7659 - mse: 9.0938e-05\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5422 - bpp: 0.7655 - mse: 9.4808e-05\n",
      "Epoch 1441: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5422 - bpp: 0.7655 - mse: 9.4808e-05\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6393 - bpp: 0.7939 - mse: 1.0320e-04\n",
      "Epoch 1442: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6393 - bpp: 0.7939 - mse: 1.0320e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4517 - bpp: 0.7450 - mse: 8.6272e-05\n",
      "Epoch 1443: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.4517 - bpp: 0.7450 - mse: 8.6272e-05\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5137 - bpp: 0.7601 - mse: 9.1991e-05\n",
      "Epoch 1444: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 1.5137 - bpp: 0.7601 - mse: 9.1991e-05\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7508 - bpp: 0.8224 - mse: 1.1333e-04\n",
      "Epoch 1445: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 182ms/step - loss: 1.7508 - bpp: 0.8224 - mse: 1.1333e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4857 - bpp: 0.7569 - mse: 8.8966e-05\n",
      "Epoch 1446: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.4857 - bpp: 0.7569 - mse: 8.8966e-05\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4919 - bpp: 0.7476 - mse: 9.0855e-05\n",
      "Epoch 1447: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.4919 - bpp: 0.7476 - mse: 9.0855e-05\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5648 - bpp: 0.7798 - mse: 9.5826e-05\n",
      "Epoch 1448: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5648 - bpp: 0.7798 - mse: 9.5826e-05\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5102 - bpp: 0.7563 - mse: 9.2039e-05\n",
      "Epoch 1449: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5102 - bpp: 0.7563 - mse: 9.2039e-05\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5777 - bpp: 0.7784 - mse: 9.7576e-05\n",
      "Epoch 1450: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5777 - bpp: 0.7784 - mse: 9.7576e-05\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4875 - bpp: 0.7373 - mse: 9.1582e-05\n",
      "Epoch 1451: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4875 - bpp: 0.7373 - mse: 9.1582e-05\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6473 - bpp: 0.7866 - mse: 1.0506e-04\n",
      "Epoch 1452: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 176ms/step - loss: 1.6473 - bpp: 0.7866 - mse: 1.0506e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6194 - bpp: 0.7772 - mse: 1.0281e-04\n",
      "Epoch 1453: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.6194 - bpp: 0.7772 - mse: 1.0281e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5009 - bpp: 0.7573 - mse: 9.0768e-05\n",
      "Epoch 1454: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 1.5009 - bpp: 0.7573 - mse: 9.0768e-05\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5095 - bpp: 0.7605 - mse: 9.1429e-05\n",
      "Epoch 1455: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5095 - bpp: 0.7605 - mse: 9.1429e-05\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4335 - bpp: 0.7386 - mse: 8.4827e-05\n",
      "Epoch 1456: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 1.4335 - bpp: 0.7386 - mse: 8.4827e-05\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5479 - bpp: 0.7680 - mse: 9.5203e-05\n",
      "Epoch 1457: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5479 - bpp: 0.7680 - mse: 9.5203e-05\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6501 - bpp: 0.8081 - mse: 1.0278e-04\n",
      "Epoch 1458: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 1.6501 - bpp: 0.8081 - mse: 1.0278e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6470 - bpp: 0.7918 - mse: 1.0440e-04\n",
      "Epoch 1459: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 177ms/step - loss: 1.6470 - bpp: 0.7918 - mse: 1.0440e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5831 - bpp: 0.7773 - mse: 9.8369e-05\n",
      "Epoch 1460: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.5831 - bpp: 0.7773 - mse: 9.8369e-05\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5220 - bpp: 0.7494 - mse: 9.4317e-05\n",
      "Epoch 1461: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 1.5220 - bpp: 0.7494 - mse: 9.4317e-05\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4753 - bpp: 0.7535 - mse: 8.8108e-05\n",
      "Epoch 1462: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.4753 - bpp: 0.7535 - mse: 8.8108e-05\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5642 - bpp: 0.7838 - mse: 9.5265e-05\n",
      "Epoch 1463: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 1.5642 - bpp: 0.7838 - mse: 9.5265e-05\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4942 - bpp: 0.7352 - mse: 9.2654e-05\n",
      "Epoch 1464: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.4942 - bpp: 0.7352 - mse: 9.2654e-05\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5552 - bpp: 0.7762 - mse: 9.5087e-05\n",
      "Epoch 1465: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5552 - bpp: 0.7762 - mse: 9.5087e-05\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5355 - bpp: 0.7573 - mse: 9.4984e-05\n",
      "Epoch 1466: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 1.5355 - bpp: 0.7573 - mse: 9.4984e-05\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5393 - bpp: 0.7561 - mse: 9.5597e-05\n",
      "Epoch 1467: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.5393 - bpp: 0.7561 - mse: 9.5597e-05\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5332 - bpp: 0.7719 - mse: 9.2934e-05\n",
      "Epoch 1468: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 1.5332 - bpp: 0.7719 - mse: 9.2934e-05\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5440 - bpp: 0.7478 - mse: 9.7199e-05\n",
      "Epoch 1469: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 1.5440 - bpp: 0.7478 - mse: 9.7199e-05\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5654 - bpp: 0.7639 - mse: 9.7846e-05\n",
      "Epoch 1470: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5654 - bpp: 0.7639 - mse: 9.7846e-05\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5130 - bpp: 0.7607 - mse: 9.1827e-05\n",
      "Epoch 1471: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.5130 - bpp: 0.7607 - mse: 9.1827e-05\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4826 - bpp: 0.7540 - mse: 8.8937e-05\n",
      "Epoch 1472: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 1.4826 - bpp: 0.7540 - mse: 8.8937e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4681 - bpp: 0.7304 - mse: 9.0054e-05\n",
      "Epoch 1473: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4681 - bpp: 0.7304 - mse: 9.0054e-05\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4474 - bpp: 0.7524 - mse: 8.4832e-05\n",
      "Epoch 1474: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.4474 - bpp: 0.7524 - mse: 8.4832e-05\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5234 - bpp: 0.7601 - mse: 9.3175e-05\n",
      "Epoch 1475: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5234 - bpp: 0.7601 - mse: 9.3175e-05\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4679 - bpp: 0.7452 - mse: 8.8226e-05\n",
      "Epoch 1476: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 195ms/step - loss: 1.4679 - bpp: 0.7452 - mse: 8.8226e-05\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4912 - bpp: 0.7410 - mse: 9.1574e-05\n",
      "Epoch 1477: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 1.4912 - bpp: 0.7410 - mse: 9.1574e-05\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4520 - bpp: 0.7477 - mse: 8.5979e-05\n",
      "Epoch 1478: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 43s 208ms/step - loss: 1.4520 - bpp: 0.7477 - mse: 8.5979e-05\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5659 - bpp: 0.7797 - mse: 9.5970e-05\n",
      "Epoch 1479: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.5659 - bpp: 0.7797 - mse: 9.5970e-05\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.7596 - bpp: 0.8332 - mse: 1.1308e-04\n",
      "Epoch 1480: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 1.7596 - bpp: 0.8332 - mse: 1.1308e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5797 - bpp: 0.7792 - mse: 9.7723e-05\n",
      "Epoch 1481: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5797 - bpp: 0.7792 - mse: 9.7723e-05\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5577 - bpp: 0.7766 - mse: 9.5356e-05\n",
      "Epoch 1482: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5577 - bpp: 0.7766 - mse: 9.5356e-05\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5778 - bpp: 0.7689 - mse: 9.8743e-05\n",
      "Epoch 1483: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.5778 - bpp: 0.7689 - mse: 9.8743e-05\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6188 - bpp: 0.7807 - mse: 1.0230e-04\n",
      "Epoch 1484: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 1.6188 - bpp: 0.7807 - mse: 1.0230e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5652 - bpp: 0.7825 - mse: 9.5553e-05\n",
      "Epoch 1485: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 191ms/step - loss: 1.5652 - bpp: 0.7825 - mse: 9.5553e-05\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3742 - bpp: 0.7293 - mse: 7.8719e-05\n",
      "Epoch 1486: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 1.3742 - bpp: 0.7293 - mse: 7.8719e-05\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5971 - bpp: 0.7713 - mse: 1.0080e-04\n",
      "Epoch 1487: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5971 - bpp: 0.7713 - mse: 1.0080e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5820 - bpp: 0.7779 - mse: 9.8155e-05\n",
      "Epoch 1488: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5820 - bpp: 0.7779 - mse: 9.8155e-05\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4969 - bpp: 0.7488 - mse: 9.1322e-05\n",
      "Epoch 1489: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.4969 - bpp: 0.7488 - mse: 9.1322e-05\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6050 - bpp: 0.7655 - mse: 1.0248e-04\n",
      "Epoch 1490: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.6050 - bpp: 0.7655 - mse: 1.0248e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4984 - bpp: 0.7542 - mse: 9.0846e-05\n",
      "Epoch 1491: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.4984 - bpp: 0.7542 - mse: 9.0846e-05\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5308 - bpp: 0.7594 - mse: 9.4162e-05\n",
      "Epoch 1492: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 1.5308 - bpp: 0.7594 - mse: 9.4162e-05\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5249 - bpp: 0.7614 - mse: 9.3191e-05\n",
      "Epoch 1493: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5249 - bpp: 0.7614 - mse: 9.3191e-05\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6067 - bpp: 0.7859 - mse: 1.0019e-04\n",
      "Epoch 1494: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6067 - bpp: 0.7859 - mse: 1.0019e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5482 - bpp: 0.7596 - mse: 9.6260e-05\n",
      "Epoch 1495: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 1.5482 - bpp: 0.7596 - mse: 9.6260e-05\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6511 - bpp: 0.8004 - mse: 1.0385e-04\n",
      "Epoch 1496: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.6511 - bpp: 0.8004 - mse: 1.0385e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5750 - bpp: 0.7780 - mse: 9.7298e-05\n",
      "Epoch 1497: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 1.5750 - bpp: 0.7780 - mse: 9.7298e-05\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5676 - bpp: 0.7661 - mse: 9.7839e-05\n",
      "Epoch 1498: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.5676 - bpp: 0.7661 - mse: 9.7839e-05\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.6048 - bpp: 0.7729 - mse: 1.0155e-04\n",
      "Epoch 1499: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.6048 - bpp: 0.7729 - mse: 1.0155e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5940 - bpp: 0.7633 - mse: 1.0140e-04\n",
      "Epoch 1500: loss did not improve from 1.31820\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 1.5940 - bpp: 0.7633 - mse: 1.0140e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_2_layer_call_fn, optical_flow_loss_2_layer_call_and_return_conditional_losses, dwt_2_layer_call_fn, dwt_2_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_8192_epcs_1500_I_QP_27_240x240_CosineDecay_20220504-144848/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_13 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_13.compile()\n",
    "trainer_13.fit()\n",
    "trainer_13.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Model compiled]...\n",
      "Epoch 1/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 298.8000 - bpp: 5.3021 - mse: 0.0179\n",
      "Epoch 1: loss improved from inf to 298.79999, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 57s 146ms/step - loss: 298.8000 - bpp: 5.3021 - mse: 0.0179\n",
      "Epoch 2/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 56.5984 - bpp: 5.1646 - mse: 0.0031\n",
      "Epoch 2: loss improved from 298.79999 to 56.59837, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 56.5984 - bpp: 5.1646 - mse: 0.0031\n",
      "Epoch 3/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 47.4225 - bpp: 5.0300 - mse: 0.0026\n",
      "Epoch 3: loss improved from 56.59837 to 47.42254, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 47.4225 - bpp: 5.0300 - mse: 0.0026\n",
      "Epoch 4/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.0005 - bpp: 4.8977 - mse: 0.0017\n",
      "Epoch 4: loss improved from 47.42254 to 32.00049, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 32.0005 - bpp: 4.8977 - mse: 0.0017\n",
      "Epoch 5/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 34.2923 - bpp: 4.7682 - mse: 0.0018\n",
      "Epoch 5: loss did not improve from 32.00049\n",
      "200/200 [==============================] - 30s 147ms/step - loss: 34.2923 - bpp: 4.7682 - mse: 0.0018\n",
      "Epoch 6/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 32.5312 - bpp: 4.6408 - mse: 0.0017\n",
      "Epoch 6: loss did not improve from 32.00049\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 32.5312 - bpp: 4.6408 - mse: 0.0017\n",
      "Epoch 7/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 25.8706 - bpp: 4.5150 - mse: 0.0013\n",
      "Epoch 7: loss improved from 32.00049 to 25.87061, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 25.8706 - bpp: 4.5150 - mse: 0.0013\n",
      "Epoch 8/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 34.3133 - bpp: 4.3924 - mse: 0.0018\n",
      "Epoch 8: loss did not improve from 25.87061\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 34.3133 - bpp: 4.3924 - mse: 0.0018\n",
      "Epoch 9/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.9948 - bpp: 4.2712 - mse: 0.0011\n",
      "Epoch 9: loss improved from 25.87061 to 22.99475, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 22.9948 - bpp: 4.2712 - mse: 0.0011\n",
      "Epoch 10/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 23.7383 - bpp: 4.1524 - mse: 0.0012\n",
      "Epoch 10: loss did not improve from 22.99475\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 23.7383 - bpp: 4.1524 - mse: 0.0012\n",
      "Epoch 11/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.0457 - bpp: 4.0350 - mse: 0.0011\n",
      "Epoch 11: loss improved from 22.99475 to 22.04570, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 22.0457 - bpp: 4.0350 - mse: 0.0011\n",
      "Epoch 12/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.1082 - bpp: 3.9208 - mse: 9.2697e-04\n",
      "Epoch 12: loss improved from 22.04570 to 19.10817, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 19.1082 - bpp: 3.9208 - mse: 9.2697e-04\n",
      "Epoch 13/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.2205 - bpp: 3.8097 - mse: 0.0011\n",
      "Epoch 13: loss did not improve from 19.10817\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 21.2205 - bpp: 3.8097 - mse: 0.0011\n",
      "Epoch 14/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 21.5870 - bpp: 3.6979 - mse: 0.0011\n",
      "Epoch 14: loss did not improve from 19.10817\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 21.5870 - bpp: 3.6979 - mse: 0.0011\n",
      "Epoch 15/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.8665 - bpp: 3.5916 - mse: 9.3230e-04\n",
      "Epoch 15: loss improved from 19.10817 to 18.86647, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 18.8665 - bpp: 3.5916 - mse: 9.3230e-04\n",
      "Epoch 16/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.6269 - bpp: 3.4869 - mse: 9.8511e-04\n",
      "Epoch 16: loss did not improve from 18.86647\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 19.6269 - bpp: 3.4869 - mse: 9.8511e-04\n",
      "Epoch 17/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.0836 - bpp: 3.3801 - mse: 8.3639e-04\n",
      "Epoch 17: loss improved from 18.86647 to 17.08357, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 17.0836 - bpp: 3.3801 - mse: 8.3639e-04\n",
      "Epoch 18/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.9392 - bpp: 3.2816 - mse: 7.7256e-04\n",
      "Epoch 18: loss improved from 17.08357 to 15.93919, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 35s 171ms/step - loss: 15.9392 - bpp: 3.2816 - mse: 7.7256e-04\n",
      "Epoch 19/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.5858 - bpp: 3.1818 - mse: 7.5707e-04\n",
      "Epoch 19: loss improved from 15.93919 to 15.58576, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 15.5858 - bpp: 3.1818 - mse: 7.5707e-04\n",
      "Epoch 20/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.0717 - bpp: 3.0896 - mse: 7.3133e-04\n",
      "Epoch 20: loss improved from 15.58576 to 15.07166, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 34s 166ms/step - loss: 15.0717 - bpp: 3.0896 - mse: 7.3133e-04\n",
      "Epoch 21/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.0567 - bpp: 2.9999 - mse: 8.5796e-04\n",
      "Epoch 21: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 17.0567 - bpp: 2.9999 - mse: 8.5796e-04\n",
      "Epoch 22/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3912 - bpp: 2.9118 - mse: 7.6168e-04\n",
      "Epoch 22: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 15.3912 - bpp: 2.9118 - mse: 7.6168e-04\n",
      "Epoch 23/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.3593 - bpp: 2.8269 - mse: 9.4802e-04\n",
      "Epoch 23: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 18.3593 - bpp: 2.8269 - mse: 9.4802e-04\n",
      "Epoch 24/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.1031 - bpp: 2.7388 - mse: 8.7672e-04\n",
      "Epoch 24: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 31s 149ms/step - loss: 17.1031 - bpp: 2.7388 - mse: 8.7672e-04\n",
      "Epoch 25/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 31.0728 - bpp: 2.6749 - mse: 0.0017\n",
      "Epoch 25: loss did not improve from 15.07166\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 31.0728 - bpp: 2.6749 - mse: 0.0017\n",
      "Epoch 26/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.2502 - bpp: 2.5746 - mse: 6.5159e-04\n",
      "Epoch 26: loss improved from 15.07166 to 13.25023, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 13.2502 - bpp: 2.5746 - mse: 6.5159e-04\n",
      "Epoch 27/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 17.5089 - bpp: 2.5122 - mse: 9.1533e-04\n",
      "Epoch 27: loss did not improve from 13.25023\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 17.5089 - bpp: 2.5122 - mse: 9.1533e-04\n",
      "Epoch 28/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.9588 - bpp: 2.4304 - mse: 6.4260e-04\n",
      "Epoch 28: loss improved from 13.25023 to 12.95880, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 12.9588 - bpp: 2.4304 - mse: 6.4260e-04\n",
      "Epoch 29/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.4475 - bpp: 2.3638 - mse: 7.3753e-04\n",
      "Epoch 29: loss did not improve from 12.95880\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 14.4475 - bpp: 2.3638 - mse: 7.3753e-04\n",
      "Epoch 30/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2627 - bpp: 2.2989 - mse: 6.0814e-04\n",
      "Epoch 30: loss improved from 12.95880 to 12.26272, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 12.2627 - bpp: 2.2989 - mse: 6.0814e-04\n",
      "Epoch 31/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 42.3166 - bpp: 2.2475 - mse: 0.0024\n",
      "Epoch 31: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 42.3166 - bpp: 2.2475 - mse: 0.0024\n",
      "Epoch 32/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3937 - bpp: 2.1682 - mse: 6.8515e-04\n",
      "Epoch 32: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 13.3937 - bpp: 2.1682 - mse: 6.8515e-04\n",
      "Epoch 33/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.8518 - bpp: 2.1185 - mse: 7.1614e-04\n",
      "Epoch 33: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 13.8518 - bpp: 2.1185 - mse: 7.1614e-04\n",
      "Epoch 34/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3212 - bpp: 2.0518 - mse: 6.2680e-04\n",
      "Epoch 34: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 12.3212 - bpp: 2.0518 - mse: 6.2680e-04\n",
      "Epoch 35/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.6762 - bpp: 1.9985 - mse: 6.5171e-04\n",
      "Epoch 35: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 12.6762 - bpp: 1.9985 - mse: 6.5171e-04\n",
      "Epoch 36/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.8425 - bpp: 1.9782 - mse: 8.4621e-04\n",
      "Epoch 36: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 15.8425 - bpp: 1.9782 - mse: 8.4621e-04\n",
      "Epoch 37/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.6302 - bpp: 1.9382 - mse: 6.5259e-04\n",
      "Epoch 37: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 12.6302 - bpp: 1.9382 - mse: 6.5259e-04\n",
      "Epoch 38/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.8354 - bpp: 1.8834 - mse: 6.6846e-04\n",
      "Epoch 38: loss did not improve from 12.26272\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 12.8354 - bpp: 1.8834 - mse: 6.6846e-04\n",
      "Epoch 39/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7066 - bpp: 1.8298 - mse: 5.4180e-04\n",
      "Epoch 39: loss improved from 12.26272 to 10.70657, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 10.7066 - bpp: 1.8298 - mse: 5.4180e-04\n",
      "Epoch 40/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.5923 - bpp: 1.8010 - mse: 7.1968e-04\n",
      "Epoch 40: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 13.5923 - bpp: 1.8010 - mse: 7.1968e-04\n",
      "Epoch 41/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.9613 - bpp: 1.7893 - mse: 7.4292e-04\n",
      "Epoch 41: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 31s 152ms/step - loss: 13.9613 - bpp: 1.7893 - mse: 7.4292e-04\n",
      "Epoch 42/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3515 - bpp: 1.7618 - mse: 8.2945e-04\n",
      "Epoch 42: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 15.3515 - bpp: 1.7618 - mse: 8.2945e-04\n",
      "Epoch 43/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.5030 - bpp: 1.6902 - mse: 6.5996e-04\n",
      "Epoch 43: loss did not improve from 10.70657\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 12.5030 - bpp: 1.6902 - mse: 6.5996e-04\n",
      "Epoch 44/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3343 - bpp: 1.6836 - mse: 5.2799e-04\n",
      "Epoch 44: loss improved from 10.70657 to 10.33428, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 10.3343 - bpp: 1.6836 - mse: 5.2799e-04\n",
      "Epoch 45/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2964 - bpp: 1.6731 - mse: 6.4840e-04\n",
      "Epoch 45: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 12.2964 - bpp: 1.6731 - mse: 6.4840e-04\n",
      "Epoch 46/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.9567 - bpp: 1.6123 - mse: 5.7034e-04\n",
      "Epoch 46: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 10.9567 - bpp: 1.6123 - mse: 5.7034e-04\n",
      "Epoch 47/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.4450 - bpp: 1.6003 - mse: 9.0605e-04\n",
      "Epoch 47: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 31s 151ms/step - loss: 16.4450 - bpp: 1.6003 - mse: 9.0605e-04\n",
      "Epoch 48/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 15.3603 - bpp: 1.6374 - mse: 8.3758e-04\n",
      "Epoch 48: loss did not improve from 10.33428\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 15.3603 - bpp: 1.6374 - mse: 8.3758e-04\n",
      "Epoch 49/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.9760 - bpp: 1.5765 - mse: 5.1266e-04\n",
      "Epoch 49: loss improved from 10.33428 to 9.97601, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 9.9760 - bpp: 1.5765 - mse: 5.1266e-04\n",
      "Epoch 50/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6397 - bpp: 1.5326 - mse: 4.9482e-04\n",
      "Epoch 50: loss improved from 9.97601 to 9.63970, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 9.6397 - bpp: 1.5326 - mse: 4.9482e-04\n",
      "Epoch 51/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.3640 - bpp: 1.5514 - mse: 7.2098e-04\n",
      "Epoch 51: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 13.3640 - bpp: 1.5514 - mse: 7.2098e-04\n",
      "Epoch 52/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.3117 - bpp: 1.5097 - mse: 6.5930e-04\n",
      "Epoch 52: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 12.3117 - bpp: 1.5097 - mse: 6.5930e-04\n",
      "Epoch 53/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.4420 - bpp: 1.5154 - mse: 6.0587e-04\n",
      "Epoch 53: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 11.4420 - bpp: 1.5154 - mse: 6.0587e-04\n",
      "Epoch 54/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.6059 - bpp: 1.4582 - mse: 6.1937e-04\n",
      "Epoch 54: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 11.6059 - bpp: 1.4582 - mse: 6.1937e-04\n",
      "Epoch 55/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0021 - bpp: 1.4748 - mse: 5.2047e-04\n",
      "Epoch 55: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 10.0021 - bpp: 1.4748 - mse: 5.2047e-04\n",
      "Epoch 56/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.7092 - bpp: 1.4354 - mse: 5.6603e-04\n",
      "Epoch 56: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 10.7092 - bpp: 1.4354 - mse: 5.6603e-04\n",
      "Epoch 57/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1235 - bpp: 1.4302 - mse: 5.3060e-04\n",
      "Epoch 57: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 10.1235 - bpp: 1.4302 - mse: 5.3060e-04\n",
      "Epoch 58/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.0069 - bpp: 1.4534 - mse: 5.2206e-04\n",
      "Epoch 58: loss did not improve from 9.63970\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 10.0069 - bpp: 1.4534 - mse: 5.2206e-04\n",
      "Epoch 59/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1179 - bpp: 1.4233 - mse: 4.6964e-04\n",
      "Epoch 59: loss improved from 9.63970 to 9.11791, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 9.1179 - bpp: 1.4233 - mse: 4.6964e-04\n",
      "Epoch 60/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 19.6766 - bpp: 1.4514 - mse: 0.0011\n",
      "Epoch 60: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 19.6766 - bpp: 1.4514 - mse: 0.0011\n",
      "Epoch 61/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 13.6092 - bpp: 1.4557 - mse: 7.4179e-04\n",
      "Epoch 61: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 13.6092 - bpp: 1.4557 - mse: 7.4179e-04\n",
      "Epoch 62/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.7828 - bpp: 1.4384 - mse: 5.0930e-04\n",
      "Epoch 62: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 9.7828 - bpp: 1.4384 - mse: 5.0930e-04\n",
      "Epoch 63/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1081 - bpp: 1.4284 - mse: 5.2977e-04\n",
      "Epoch 63: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 10.1081 - bpp: 1.4284 - mse: 5.2977e-04\n",
      "Epoch 64/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2671 - bpp: 1.3838 - mse: 4.8116e-04\n",
      "Epoch 64: loss did not improve from 9.11791\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 9.2671 - bpp: 1.3838 - mse: 4.8116e-04\n",
      "Epoch 65/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3308 - bpp: 1.3735 - mse: 4.2464e-04\n",
      "Epoch 65: loss improved from 9.11791 to 8.33084, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 8.3308 - bpp: 1.3735 - mse: 4.2464e-04\n",
      "Epoch 66/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2371 - bpp: 1.3570 - mse: 4.8097e-04\n",
      "Epoch 66: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 9.2371 - bpp: 1.3570 - mse: 4.8097e-04\n",
      "Epoch 67/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.3156 - bpp: 1.3925 - mse: 5.4462e-04\n",
      "Epoch 67: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 10.3156 - bpp: 1.3925 - mse: 5.4462e-04\n",
      "Epoch 68/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6896 - bpp: 1.3475 - mse: 5.0916e-04\n",
      "Epoch 68: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 9.6896 - bpp: 1.3475 - mse: 5.0916e-04\n",
      "Epoch 69/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2969 - bpp: 1.3417 - mse: 4.8555e-04\n",
      "Epoch 69: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 9.2969 - bpp: 1.3417 - mse: 4.8555e-04\n",
      "Epoch 70/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 16.8020 - bpp: 1.3705 - mse: 9.4186e-04\n",
      "Epoch 70: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 16.8020 - bpp: 1.3705 - mse: 9.4186e-04\n",
      "Epoch 71/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.8698 - bpp: 1.3510 - mse: 5.1994e-04\n",
      "Epoch 71: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.8698 - bpp: 1.3510 - mse: 5.1994e-04\n",
      "Epoch 72/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5230 - bpp: 1.3437 - mse: 4.9922e-04\n",
      "Epoch 72: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.5230 - bpp: 1.3437 - mse: 4.9922e-04\n",
      "Epoch 73/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1263 - bpp: 1.3387 - mse: 4.7531e-04\n",
      "Epoch 73: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.1263 - bpp: 1.3387 - mse: 4.7531e-04\n",
      "Epoch 74/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7896 - bpp: 1.3341 - mse: 4.5505e-04\n",
      "Epoch 74: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 8.7896 - bpp: 1.3341 - mse: 4.5505e-04\n",
      "Epoch 75/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 22.2474 - bpp: 1.4133 - mse: 0.0013\n",
      "Epoch 75: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 22.2474 - bpp: 1.4133 - mse: 0.0013\n",
      "Epoch 76/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.2921 - bpp: 1.3237 - mse: 4.8635e-04\n",
      "Epoch 76: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 9.2921 - bpp: 1.3237 - mse: 4.8635e-04\n",
      "Epoch 77/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5032 - bpp: 1.2960 - mse: 4.3989e-04\n",
      "Epoch 77: loss did not improve from 8.33084\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 8.5032 - bpp: 1.2960 - mse: 4.3989e-04\n",
      "Epoch 78/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9211 - bpp: 1.2922 - mse: 4.0460e-04\n",
      "Epoch 78: loss improved from 8.33084 to 7.92108, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 7.9211 - bpp: 1.2922 - mse: 4.0460e-04\n",
      "Epoch 79/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5743 - bpp: 1.2988 - mse: 4.4406e-04\n",
      "Epoch 79: loss did not improve from 7.92108\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 8.5743 - bpp: 1.2988 - mse: 4.4406e-04\n",
      "Epoch 80/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3290 - bpp: 1.3071 - mse: 4.2858e-04\n",
      "Epoch 80: loss did not improve from 7.92108\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 8.3290 - bpp: 1.3071 - mse: 4.2858e-04\n",
      "Epoch 81/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3206 - bpp: 1.2879 - mse: 3.6821e-04\n",
      "Epoch 81: loss improved from 7.92108 to 7.32060, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 7.3206 - bpp: 1.2879 - mse: 3.6821e-04\n",
      "Epoch 82/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2155 - bpp: 1.3063 - mse: 4.2170e-04\n",
      "Epoch 82: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 8.2155 - bpp: 1.3063 - mse: 4.2170e-04\n",
      "Epoch 83/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5041 - bpp: 1.3152 - mse: 4.9981e-04\n",
      "Epoch 83: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 9.5041 - bpp: 1.3152 - mse: 4.9981e-04\n",
      "Epoch 84/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3220 - bpp: 1.2936 - mse: 4.2898e-04\n",
      "Epoch 84: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 8.3220 - bpp: 1.2936 - mse: 4.2898e-04\n",
      "Epoch 85/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0100 - bpp: 1.2825 - mse: 4.1061e-04\n",
      "Epoch 85: loss did not improve from 7.32060\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 8.0100 - bpp: 1.2825 - mse: 4.1061e-04\n",
      "Epoch 86/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1152 - bpp: 1.2720 - mse: 3.5664e-04\n",
      "Epoch 86: loss improved from 7.32060 to 7.11517, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 7.1152 - bpp: 1.2720 - mse: 3.5664e-04\n",
      "Epoch 87/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.0676 - bpp: 1.2803 - mse: 4.7530e-04\n",
      "Epoch 87: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 9.0676 - bpp: 1.2803 - mse: 4.7530e-04\n",
      "Epoch 88/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2917 - bpp: 1.2733 - mse: 3.6734e-04\n",
      "Epoch 88: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 7.2917 - bpp: 1.2733 - mse: 3.6734e-04\n",
      "Epoch 89/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.2083 - bpp: 1.3004 - mse: 5.4370e-04\n",
      "Epoch 89: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 10.2083 - bpp: 1.3004 - mse: 5.4370e-04\n",
      "Epoch 90/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.7020 - bpp: 1.2954 - mse: 4.5206e-04\n",
      "Epoch 90: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 8.7020 - bpp: 1.2954 - mse: 4.5206e-04\n",
      "Epoch 91/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.3745 - bpp: 1.2889 - mse: 4.3247e-04\n",
      "Epoch 91: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 8.3745 - bpp: 1.2889 - mse: 4.3247e-04\n",
      "Epoch 92/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.2160 - bpp: 1.2722 - mse: 3.6278e-04\n",
      "Epoch 92: loss did not improve from 7.11517\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 7.2160 - bpp: 1.2722 - mse: 3.6278e-04\n",
      "Epoch 93/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0656 - bpp: 1.2534 - mse: 3.5475e-04\n",
      "Epoch 93: loss improved from 7.11517 to 7.06557, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 7.0656 - bpp: 1.2534 - mse: 3.5475e-04\n",
      "Epoch 94/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1996 - bpp: 1.2983 - mse: 4.2122e-04\n",
      "Epoch 94: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 8.1996 - bpp: 1.2983 - mse: 4.2122e-04\n",
      "Epoch 95/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.8694 - bpp: 1.2794 - mse: 4.0222e-04\n",
      "Epoch 95: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 7.8694 - bpp: 1.2794 - mse: 4.0222e-04\n",
      "Epoch 96/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 14.8365 - bpp: 1.3394 - mse: 8.2380e-04\n",
      "Epoch 96: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 14.8365 - bpp: 1.3394 - mse: 8.2380e-04\n",
      "Epoch 97/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.1146 - bpp: 1.3165 - mse: 5.3699e-04\n",
      "Epoch 97: loss did not improve from 7.06557\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 10.1146 - bpp: 1.3165 - mse: 5.3699e-04\n",
      "Epoch 98/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9683 - bpp: 1.2568 - mse: 3.4860e-04\n",
      "Epoch 98: loss improved from 7.06557 to 6.96834, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 6.9683 - bpp: 1.2568 - mse: 3.4860e-04\n",
      "Epoch 99/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.4917 - bpp: 1.2896 - mse: 5.6166e-04\n",
      "Epoch 99: loss did not improve from 6.96834\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 10.4917 - bpp: 1.2896 - mse: 5.6166e-04\n",
      "Epoch 100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5552 - bpp: 1.2417 - mse: 3.2431e-04\n",
      "Epoch 100: loss improved from 6.96834 to 6.55519, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.5552 - bpp: 1.2417 - mse: 3.2431e-04\n",
      "Epoch 101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4396 - bpp: 1.2346 - mse: 3.1768e-04\n",
      "Epoch 101: loss improved from 6.55519 to 6.43955, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 6.4396 - bpp: 1.2346 - mse: 3.1768e-04\n",
      "Epoch 102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5057 - bpp: 1.2550 - mse: 3.8151e-04\n",
      "Epoch 102: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 7.5057 - bpp: 1.2550 - mse: 3.8151e-04\n",
      "Epoch 103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6776 - bpp: 1.2441 - mse: 3.3163e-04\n",
      "Epoch 103: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 6.6776 - bpp: 1.2441 - mse: 3.3163e-04\n",
      "Epoch 104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.5047 - bpp: 1.2807 - mse: 3.7988e-04\n",
      "Epoch 104: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 7.5047 - bpp: 1.2807 - mse: 3.7988e-04\n",
      "Epoch 105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5081 - bpp: 1.2736 - mse: 3.1949e-04\n",
      "Epoch 105: loss did not improve from 6.43955\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 6.5081 - bpp: 1.2736 - mse: 3.1949e-04\n",
      "Epoch 106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0799 - bpp: 1.2501 - mse: 2.9479e-04\n",
      "Epoch 106: loss improved from 6.43955 to 6.07990, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 6.0799 - bpp: 1.2501 - mse: 2.9479e-04\n",
      "Epoch 107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.1279 - bpp: 1.3209 - mse: 4.7650e-04\n",
      "Epoch 107: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 9.1279 - bpp: 1.3209 - mse: 4.7650e-04\n",
      "Epoch 108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5623 - bpp: 1.2262 - mse: 3.2569e-04\n",
      "Epoch 108: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 6.5623 - bpp: 1.2262 - mse: 3.2569e-04\n",
      "Epoch 109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7810 - bpp: 1.2650 - mse: 3.3667e-04\n",
      "Epoch 109: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.7810 - bpp: 1.2650 - mse: 3.3667e-04\n",
      "Epoch 110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 11.9841 - bpp: 1.2821 - mse: 6.5320e-04\n",
      "Epoch 110: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 11.9841 - bpp: 1.2821 - mse: 6.5320e-04\n",
      "Epoch 111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.5159 - bpp: 1.3007 - mse: 5.0142e-04\n",
      "Epoch 111: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 9.5159 - bpp: 1.3007 - mse: 5.0142e-04\n",
      "Epoch 112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1518 - bpp: 1.3014 - mse: 4.1812e-04\n",
      "Epoch 112: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 8.1518 - bpp: 1.3014 - mse: 4.1812e-04\n",
      "Epoch 113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3129 - bpp: 1.2443 - mse: 3.0936e-04\n",
      "Epoch 113: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 6.3129 - bpp: 1.2443 - mse: 3.0936e-04\n",
      "Epoch 114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1841 - bpp: 1.2434 - mse: 3.0156e-04\n",
      "Epoch 114: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 6.1841 - bpp: 1.2434 - mse: 3.0156e-04\n",
      "Epoch 115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9505 - bpp: 1.2472 - mse: 3.4810e-04\n",
      "Epoch 115: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.9505 - bpp: 1.2472 - mse: 3.4810e-04\n",
      "Epoch 116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0009 - bpp: 1.2593 - mse: 3.5044e-04\n",
      "Epoch 116: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 7.0009 - bpp: 1.2593 - mse: 3.5044e-04\n",
      "Epoch 117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3643 - bpp: 1.2333 - mse: 3.1317e-04\n",
      "Epoch 117: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.3643 - bpp: 1.2333 - mse: 3.1317e-04\n",
      "Epoch 118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6779 - bpp: 1.2327 - mse: 3.3235e-04\n",
      "Epoch 118: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 6.6779 - bpp: 1.2327 - mse: 3.3235e-04\n",
      "Epoch 119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5964 - bpp: 1.2396 - mse: 3.2695e-04\n",
      "Epoch 119: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 6.5964 - bpp: 1.2396 - mse: 3.2695e-04\n",
      "Epoch 120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8674 - bpp: 1.2526 - mse: 3.4270e-04\n",
      "Epoch 120: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 6.8674 - bpp: 1.2526 - mse: 3.4270e-04\n",
      "Epoch 121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1530 - bpp: 1.2734 - mse: 3.5886e-04\n",
      "Epoch 121: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 7.1530 - bpp: 1.2734 - mse: 3.5886e-04\n",
      "Epoch 122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 10.8529 - bpp: 1.3429 - mse: 5.8044e-04\n",
      "Epoch 122: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 10.8529 - bpp: 1.3429 - mse: 5.8044e-04\n",
      "Epoch 123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8497 - bpp: 1.2358 - mse: 3.4265e-04\n",
      "Epoch 123: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 6.8497 - bpp: 1.2358 - mse: 3.4265e-04\n",
      "Epoch 124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.9486 - bpp: 1.2745 - mse: 3.4632e-04\n",
      "Epoch 124: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 6.9486 - bpp: 1.2745 - mse: 3.4632e-04\n",
      "Epoch 125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2869 - bpp: 1.2451 - mse: 3.0773e-04\n",
      "Epoch 125: loss did not improve from 6.07990\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.2869 - bpp: 1.2451 - mse: 3.0773e-04\n",
      "Epoch 126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8728 - bpp: 1.2268 - mse: 2.8357e-04\n",
      "Epoch 126: loss improved from 6.07990 to 5.87285, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 5.8728 - bpp: 1.2268 - mse: 2.8357e-04\n",
      "Epoch 127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2976 - bpp: 1.2917 - mse: 4.2760e-04\n",
      "Epoch 127: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 8.2976 - bpp: 1.2917 - mse: 4.2760e-04\n",
      "Epoch 128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.1279 - bpp: 1.2813 - mse: 3.5685e-04\n",
      "Epoch 128: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 7.1279 - bpp: 1.2813 - mse: 3.5685e-04\n",
      "Epoch 129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8211 - bpp: 1.2659 - mse: 3.3906e-04\n",
      "Epoch 129: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 6.8211 - bpp: 1.2659 - mse: 3.3906e-04\n",
      "Epoch 130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8123 - bpp: 1.2750 - mse: 3.3797e-04\n",
      "Epoch 130: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 6.8123 - bpp: 1.2750 - mse: 3.3797e-04\n",
      "Epoch 131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7383 - bpp: 1.2667 - mse: 3.3396e-04\n",
      "Epoch 131: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 6.7383 - bpp: 1.2667 - mse: 3.3396e-04\n",
      "Epoch 132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3323 - bpp: 1.2503 - mse: 3.1018e-04\n",
      "Epoch 132: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 6.3323 - bpp: 1.2503 - mse: 3.1018e-04\n",
      "Epoch 133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0552 - bpp: 1.2612 - mse: 3.5364e-04\n",
      "Epoch 133: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 7.0552 - bpp: 1.2612 - mse: 3.5364e-04\n",
      "Epoch 134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 18.6789 - bpp: 1.3512 - mse: 0.0011\n",
      "Epoch 134: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 18.6789 - bpp: 1.3512 - mse: 0.0011\n",
      "Epoch 135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1613 - bpp: 1.2704 - mse: 2.9852e-04\n",
      "Epoch 135: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 6.1613 - bpp: 1.2704 - mse: 2.9852e-04\n",
      "Epoch 136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1465 - bpp: 1.2743 - mse: 2.9738e-04\n",
      "Epoch 136: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 6.1465 - bpp: 1.2743 - mse: 2.9738e-04\n",
      "Epoch 137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0766 - bpp: 1.2718 - mse: 2.9326e-04\n",
      "Epoch 137: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 6.0766 - bpp: 1.2718 - mse: 2.9326e-04\n",
      "Epoch 138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0066 - bpp: 1.2626 - mse: 2.8955e-04\n",
      "Epoch 138: loss did not improve from 5.87285\n",
      "200/200 [==============================] - 39s 192ms/step - loss: 6.0066 - bpp: 1.2626 - mse: 2.8955e-04\n",
      "Epoch 139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4748 - bpp: 1.2419 - mse: 2.5836e-04\n",
      "Epoch 139: loss improved from 5.87285 to 5.47482, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.4748 - bpp: 1.2419 - mse: 2.5836e-04\n",
      "Epoch 140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.3211 - bpp: 1.2657 - mse: 3.6960e-04\n",
      "Epoch 140: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 7.3211 - bpp: 1.2657 - mse: 3.6960e-04\n",
      "Epoch 141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1288 - bpp: 1.2415 - mse: 2.9830e-04\n",
      "Epoch 141: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.1288 - bpp: 1.2415 - mse: 2.9830e-04\n",
      "Epoch 142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9911 - bpp: 1.2903 - mse: 4.0899e-04\n",
      "Epoch 142: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 7.9911 - bpp: 1.2903 - mse: 4.0899e-04\n",
      "Epoch 143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7156 - bpp: 1.2798 - mse: 3.9281e-04\n",
      "Epoch 143: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 7.7156 - bpp: 1.2798 - mse: 3.9281e-04\n",
      "Epoch 144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.7233 - bpp: 1.2815 - mse: 3.9317e-04\n",
      "Epoch 144: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 7.7233 - bpp: 1.2815 - mse: 3.9317e-04\n",
      "Epoch 145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4537 - bpp: 1.2623 - mse: 3.1686e-04\n",
      "Epoch 145: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 6.4537 - bpp: 1.2623 - mse: 3.1686e-04\n",
      "Epoch 146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5840 - bpp: 1.2526 - mse: 2.6437e-04\n",
      "Epoch 146: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 41s 200ms/step - loss: 5.5840 - bpp: 1.2526 - mse: 2.6437e-04\n",
      "Epoch 147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1298 - bpp: 1.2618 - mse: 2.9712e-04\n",
      "Epoch 147: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 6.1298 - bpp: 1.2618 - mse: 2.9712e-04\n",
      "Epoch 148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.6887 - bpp: 1.2652 - mse: 3.3102e-04\n",
      "Epoch 148: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 6.6887 - bpp: 1.2652 - mse: 3.3102e-04\n",
      "Epoch 149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9456 - bpp: 1.2565 - mse: 2.8620e-04\n",
      "Epoch 149: loss did not improve from 5.47482\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.9456 - bpp: 1.2565 - mse: 2.8620e-04\n",
      "Epoch 150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1410 - bpp: 1.2345 - mse: 2.3843e-04\n",
      "Epoch 150: loss improved from 5.47482 to 5.14096, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 5.1410 - bpp: 1.2345 - mse: 2.3843e-04\n",
      "Epoch 151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6990 - bpp: 1.2577 - mse: 2.7107e-04\n",
      "Epoch 151: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 5.6990 - bpp: 1.2577 - mse: 2.7107e-04\n",
      "Epoch 152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3772 - bpp: 1.2683 - mse: 3.1182e-04\n",
      "Epoch 152: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 6.3772 - bpp: 1.2683 - mse: 3.1182e-04\n",
      "Epoch 153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5931 - bpp: 1.2621 - mse: 2.6434e-04\n",
      "Epoch 153: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.5931 - bpp: 1.2621 - mse: 2.6434e-04\n",
      "Epoch 154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.9334 - bpp: 1.2875 - mse: 4.0564e-04\n",
      "Epoch 154: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 205ms/step - loss: 7.9334 - bpp: 1.2875 - mse: 4.0564e-04\n",
      "Epoch 155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0860 - bpp: 1.2701 - mse: 4.1601e-04\n",
      "Epoch 155: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 8.0860 - bpp: 1.2701 - mse: 4.1601e-04\n",
      "Epoch 156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.7972 - bpp: 1.2942 - mse: 3.3588e-04\n",
      "Epoch 156: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 6.7972 - bpp: 1.2942 - mse: 3.3588e-04\n",
      "Epoch 157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9906 - bpp: 1.2558 - mse: 2.8899e-04\n",
      "Epoch 157: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 5.9906 - bpp: 1.2558 - mse: 2.8899e-04\n",
      "Epoch 158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6385 - bpp: 1.2470 - mse: 2.6804e-04\n",
      "Epoch 158: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.6385 - bpp: 1.2470 - mse: 2.6804e-04\n",
      "Epoch 159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5769 - bpp: 1.2683 - mse: 2.6298e-04\n",
      "Epoch 159: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 43s 208ms/step - loss: 5.5769 - bpp: 1.2683 - mse: 2.6298e-04\n",
      "Epoch 160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6298 - bpp: 1.2730 - mse: 2.6592e-04\n",
      "Epoch 160: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 5.6298 - bpp: 1.2730 - mse: 2.6592e-04\n",
      "Epoch 161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.0332 - bpp: 1.2738 - mse: 2.9049e-04\n",
      "Epoch 161: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 6.0332 - bpp: 1.2738 - mse: 2.9049e-04\n",
      "Epoch 162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4067 - bpp: 1.2988 - mse: 3.1176e-04\n",
      "Epoch 162: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 6.4067 - bpp: 1.2988 - mse: 3.1176e-04\n",
      "Epoch 163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.1349 - bpp: 1.2714 - mse: 6.6306e-04\n",
      "Epoch 163: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 12.1349 - bpp: 1.2714 - mse: 6.6306e-04\n",
      "Epoch 164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6732 - bpp: 1.2712 - mse: 2.6868e-04\n",
      "Epoch 164: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.6732 - bpp: 1.2712 - mse: 2.6868e-04\n",
      "Epoch 165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3819 - bpp: 1.2959 - mse: 3.1042e-04\n",
      "Epoch 165: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.3819 - bpp: 1.2959 - mse: 3.1042e-04\n",
      "Epoch 166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2156 - bpp: 1.2850 - mse: 3.0094e-04\n",
      "Epoch 166: loss did not improve from 5.14096\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 6.2156 - bpp: 1.2850 - mse: 3.0094e-04\n",
      "Epoch 167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7307 - bpp: 1.2268 - mse: 2.1386e-04\n",
      "Epoch 167: loss improved from 5.14096 to 4.73069, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.7307 - bpp: 1.2268 - mse: 2.1386e-04\n",
      "Epoch 168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.5823 - bpp: 1.2514 - mse: 3.2537e-04\n",
      "Epoch 168: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 6.5823 - bpp: 1.2514 - mse: 3.2537e-04\n",
      "Epoch 169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4602 - bpp: 1.2468 - mse: 3.1820e-04\n",
      "Epoch 169: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 6.4602 - bpp: 1.2468 - mse: 3.1820e-04\n",
      "Epoch 170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6897 - bpp: 1.2698 - mse: 2.6977e-04\n",
      "Epoch 170: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 5.6897 - bpp: 1.2698 - mse: 2.6977e-04\n",
      "Epoch 171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3022 - bpp: 1.2809 - mse: 3.0647e-04\n",
      "Epoch 171: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 6.3022 - bpp: 1.2809 - mse: 3.0647e-04\n",
      "Epoch 172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.9726 - bpp: 1.2824 - mse: 4.6938e-04\n",
      "Epoch 172: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 8.9726 - bpp: 1.2824 - mse: 4.6938e-04\n",
      "Epoch 173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2654 - bpp: 1.2862 - mse: 3.0391e-04\n",
      "Epoch 173: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 6.2654 - bpp: 1.2862 - mse: 3.0391e-04\n",
      "Epoch 174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5823 - bpp: 1.2617 - mse: 2.6371e-04\n",
      "Epoch 174: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.5823 - bpp: 1.2617 - mse: 2.6371e-04\n",
      "Epoch 175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9267 - bpp: 1.3078 - mse: 2.8192e-04\n",
      "Epoch 175: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 5.9267 - bpp: 1.3078 - mse: 2.8192e-04\n",
      "Epoch 176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.8354 - bpp: 1.2858 - mse: 3.3872e-04\n",
      "Epoch 176: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 6.8354 - bpp: 1.2858 - mse: 3.3872e-04\n",
      "Epoch 177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.2580 - bpp: 1.2867 - mse: 4.2549e-04\n",
      "Epoch 177: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 8.2580 - bpp: 1.2867 - mse: 4.2549e-04\n",
      "Epoch 178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1646 - bpp: 1.2479 - mse: 2.3906e-04\n",
      "Epoch 178: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.1646 - bpp: 1.2479 - mse: 2.3906e-04\n",
      "Epoch 179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1451 - bpp: 1.2508 - mse: 2.3769e-04\n",
      "Epoch 179: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.1451 - bpp: 1.2508 - mse: 2.3769e-04\n",
      "Epoch 180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4580 - bpp: 1.3077 - mse: 3.1435e-04\n",
      "Epoch 180: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 6.4580 - bpp: 1.3077 - mse: 3.1435e-04\n",
      "Epoch 181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.3057 - bpp: 1.3032 - mse: 3.0533e-04\n",
      "Epoch 181: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 6.3057 - bpp: 1.3032 - mse: 3.0533e-04\n",
      "Epoch 182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2790 - bpp: 1.2615 - mse: 2.4521e-04\n",
      "Epoch 182: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.2790 - bpp: 1.2615 - mse: 2.4521e-04\n",
      "Epoch 183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4486 - bpp: 1.2721 - mse: 2.5491e-04\n",
      "Epoch 183: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.4486 - bpp: 1.2721 - mse: 2.5491e-04\n",
      "Epoch 184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3004 - bpp: 1.2901 - mse: 2.4477e-04\n",
      "Epoch 184: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 5.3004 - bpp: 1.2901 - mse: 2.4477e-04\n",
      "Epoch 185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9692 - bpp: 1.2816 - mse: 2.8611e-04\n",
      "Epoch 185: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.9692 - bpp: 1.2816 - mse: 2.8611e-04\n",
      "Epoch 186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2095 - bpp: 1.2443 - mse: 2.4202e-04\n",
      "Epoch 186: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.2095 - bpp: 1.2443 - mse: 2.4202e-04\n",
      "Epoch 187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2081 - bpp: 1.3000 - mse: 2.9957e-04\n",
      "Epoch 187: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 6.2081 - bpp: 1.3000 - mse: 2.9957e-04\n",
      "Epoch 188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0101 - bpp: 1.2498 - mse: 2.2951e-04\n",
      "Epoch 188: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 5.0101 - bpp: 1.2498 - mse: 2.2951e-04\n",
      "Epoch 189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.4854 - bpp: 1.2749 - mse: 3.1803e-04\n",
      "Epoch 189: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 197ms/step - loss: 6.4854 - bpp: 1.2749 - mse: 3.1803e-04\n",
      "Epoch 190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.1946 - bpp: 1.3202 - mse: 4.1958e-04\n",
      "Epoch 190: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 8.1946 - bpp: 1.3202 - mse: 4.1958e-04\n",
      "Epoch 191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3831 - bpp: 1.2886 - mse: 2.4990e-04\n",
      "Epoch 191: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.3831 - bpp: 1.2886 - mse: 2.4990e-04\n",
      "Epoch 192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5927 - bpp: 1.2695 - mse: 2.6387e-04\n",
      "Epoch 192: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 5.5927 - bpp: 1.2695 - mse: 2.6387e-04\n",
      "Epoch 193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.2126 - bpp: 1.2840 - mse: 3.0082e-04\n",
      "Epoch 193: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 6.2126 - bpp: 1.2840 - mse: 3.0082e-04\n",
      "Epoch 194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4492 - bpp: 1.2675 - mse: 2.5523e-04\n",
      "Epoch 194: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.4492 - bpp: 1.2675 - mse: 2.5523e-04\n",
      "Epoch 195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5631 - bpp: 1.2831 - mse: 2.6123e-04\n",
      "Epoch 195: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.5631 - bpp: 1.2831 - mse: 2.6123e-04\n",
      "Epoch 196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.8739 - bpp: 1.3124 - mse: 4.6151e-04\n",
      "Epoch 196: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 8.8739 - bpp: 1.3124 - mse: 4.6151e-04\n",
      "Epoch 197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6007 - bpp: 1.2827 - mse: 2.6355e-04\n",
      "Epoch 197: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.6007 - bpp: 1.2827 - mse: 2.6355e-04\n",
      "Epoch 198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1865 - bpp: 1.2712 - mse: 2.3897e-04\n",
      "Epoch 198: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.1865 - bpp: 1.2712 - mse: 2.3897e-04\n",
      "Epoch 199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7893 - bpp: 1.2729 - mse: 2.1462e-04\n",
      "Epoch 199: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.7893 - bpp: 1.2729 - mse: 2.1462e-04\n",
      "Epoch 200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8233 - bpp: 1.2394 - mse: 2.1875e-04\n",
      "Epoch 200: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 4.8233 - bpp: 1.2394 - mse: 2.1875e-04\n",
      "Epoch 201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4854 - bpp: 1.2653 - mse: 2.5757e-04\n",
      "Epoch 201: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.4854 - bpp: 1.2653 - mse: 2.5757e-04\n",
      "Epoch 202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6424 - bpp: 1.2798 - mse: 2.6627e-04\n",
      "Epoch 202: loss did not improve from 4.73069\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.6424 - bpp: 1.2798 - mse: 2.6627e-04\n",
      "Epoch 203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5648 - bpp: 1.2596 - mse: 2.0173e-04\n",
      "Epoch 203: loss improved from 4.73069 to 4.56479, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.5648 - bpp: 1.2596 - mse: 2.0173e-04\n",
      "Epoch 204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0663 - bpp: 1.2784 - mse: 2.3120e-04\n",
      "Epoch 204: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 5.0663 - bpp: 1.2784 - mse: 2.3120e-04\n",
      "Epoch 205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8007 - bpp: 1.2684 - mse: 2.1559e-04\n",
      "Epoch 205: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 4.8007 - bpp: 1.2684 - mse: 2.1559e-04\n",
      "Epoch 206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9475 - bpp: 1.2803 - mse: 2.8486e-04\n",
      "Epoch 206: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.9475 - bpp: 1.2803 - mse: 2.8486e-04\n",
      "Epoch 207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9825 - bpp: 1.2776 - mse: 2.2613e-04\n",
      "Epoch 207: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.9825 - bpp: 1.2776 - mse: 2.2613e-04\n",
      "Epoch 208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9930 - bpp: 1.2566 - mse: 2.8909e-04\n",
      "Epoch 208: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.9930 - bpp: 1.2566 - mse: 2.8909e-04\n",
      "Epoch 209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3370 - bpp: 1.2830 - mse: 2.4744e-04\n",
      "Epoch 209: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 201ms/step - loss: 5.3370 - bpp: 1.2830 - mse: 2.4744e-04\n",
      "Epoch 210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0187 - bpp: 1.2621 - mse: 2.2928e-04\n",
      "Epoch 210: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.0187 - bpp: 1.2621 - mse: 2.2928e-04\n",
      "Epoch 211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6665 - bpp: 1.2984 - mse: 2.6660e-04\n",
      "Epoch 211: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.6665 - bpp: 1.2984 - mse: 2.6660e-04\n",
      "Epoch 212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2795 - bpp: 1.2766 - mse: 2.4432e-04\n",
      "Epoch 212: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 5.2795 - bpp: 1.2766 - mse: 2.4432e-04\n",
      "Epoch 213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4122 - bpp: 1.2844 - mse: 2.5194e-04\n",
      "Epoch 213: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.4122 - bpp: 1.2844 - mse: 2.5194e-04\n",
      "Epoch 214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3706 - bpp: 1.2823 - mse: 2.4953e-04\n",
      "Epoch 214: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 5.3706 - bpp: 1.2823 - mse: 2.4953e-04\n",
      "Epoch 215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6038 - bpp: 1.3153 - mse: 2.6175e-04\n",
      "Epoch 215: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 5.6038 - bpp: 1.3153 - mse: 2.6175e-04\n",
      "Epoch 216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2646 - bpp: 1.2929 - mse: 2.4241e-04\n",
      "Epoch 216: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.2646 - bpp: 1.2929 - mse: 2.4241e-04\n",
      "Epoch 217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6351 - bpp: 1.2909 - mse: 2.0411e-04\n",
      "Epoch 217: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.6351 - bpp: 1.2909 - mse: 2.0411e-04\n",
      "Epoch 218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.0033 - bpp: 1.3117 - mse: 4.0842e-04\n",
      "Epoch 218: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 8.0033 - bpp: 1.3117 - mse: 4.0842e-04\n",
      "Epoch 219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0164 - bpp: 1.2719 - mse: 2.2854e-04\n",
      "Epoch 219: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 5.0164 - bpp: 1.2719 - mse: 2.2854e-04\n",
      "Epoch 220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0344 - bpp: 1.2621 - mse: 2.3024e-04\n",
      "Epoch 220: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 5.0344 - bpp: 1.2621 - mse: 2.3024e-04\n",
      "Epoch 221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0045 - bpp: 1.2747 - mse: 2.2765e-04\n",
      "Epoch 221: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.0045 - bpp: 1.2747 - mse: 2.2765e-04\n",
      "Epoch 222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8009 - bpp: 1.2712 - mse: 2.1543e-04\n",
      "Epoch 222: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 4.8009 - bpp: 1.2712 - mse: 2.1543e-04\n",
      "Epoch 223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.8193 - bpp: 1.3056 - mse: 2.7549e-04\n",
      "Epoch 223: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 5.8193 - bpp: 1.3056 - mse: 2.7549e-04\n",
      "Epoch 224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 8.5416 - bpp: 1.3255 - mse: 4.4043e-04\n",
      "Epoch 224: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 8.5416 - bpp: 1.3255 - mse: 4.4043e-04\n",
      "Epoch 225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9567 - bpp: 1.3291 - mse: 2.8245e-04\n",
      "Epoch 225: loss did not improve from 4.56479\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.9567 - bpp: 1.3291 - mse: 2.8245e-04\n",
      "Epoch 226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5432 - bpp: 1.2512 - mse: 2.0093e-04\n",
      "Epoch 226: loss improved from 4.56479 to 4.54320, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.5432 - bpp: 1.2512 - mse: 2.0093e-04\n",
      "Epoch 227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 6.1638 - bpp: 1.3100 - mse: 2.9626e-04\n",
      "Epoch 227: loss did not improve from 4.54320\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 6.1638 - bpp: 1.3100 - mse: 2.9626e-04\n",
      "Epoch 228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2851 - bpp: 1.2384 - mse: 1.8596e-04\n",
      "Epoch 228: loss improved from 4.54320 to 4.28514, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.2851 - bpp: 1.2384 - mse: 1.8596e-04\n",
      "Epoch 229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8081 - bpp: 1.2920 - mse: 2.1461e-04\n",
      "Epoch 229: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.8081 - bpp: 1.2920 - mse: 2.1461e-04\n",
      "Epoch 230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4963 - bpp: 1.2757 - mse: 1.9658e-04\n",
      "Epoch 230: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 4.4963 - bpp: 1.2757 - mse: 1.9658e-04\n",
      "Epoch 231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.7283 - bpp: 1.3095 - mse: 2.6970e-04\n",
      "Epoch 231: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.7283 - bpp: 1.3095 - mse: 2.6970e-04\n",
      "Epoch 232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4212 - bpp: 1.2471 - mse: 1.9374e-04\n",
      "Epoch 232: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 4.4212 - bpp: 1.2471 - mse: 1.9374e-04\n",
      "Epoch 233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1983 - bpp: 1.2990 - mse: 2.3799e-04\n",
      "Epoch 233: loss did not improve from 4.28514\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 5.1983 - bpp: 1.2990 - mse: 2.3799e-04\n",
      "Epoch 234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2817 - bpp: 1.2546 - mse: 1.8476e-04\n",
      "Epoch 234: loss improved from 4.28514 to 4.28169, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.2817 - bpp: 1.2546 - mse: 1.8476e-04\n",
      "Epoch 235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5852 - bpp: 1.2751 - mse: 2.0203e-04\n",
      "Epoch 235: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.5852 - bpp: 1.2751 - mse: 2.0203e-04\n",
      "Epoch 236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6952 - bpp: 1.2807 - mse: 2.0840e-04\n",
      "Epoch 236: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.6952 - bpp: 1.2807 - mse: 2.0840e-04\n",
      "Epoch 237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8196 - bpp: 1.2854 - mse: 2.1571e-04\n",
      "Epoch 237: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.8196 - bpp: 1.2854 - mse: 2.1571e-04\n",
      "Epoch 238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 12.2499 - bpp: 1.3337 - mse: 6.6627e-04\n",
      "Epoch 238: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 12.2499 - bpp: 1.3337 - mse: 6.6627e-04\n",
      "Epoch 239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2139 - bpp: 1.2888 - mse: 2.3957e-04\n",
      "Epoch 239: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 5.2139 - bpp: 1.2888 - mse: 2.3957e-04\n",
      "Epoch 240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0730 - bpp: 1.2691 - mse: 2.3217e-04\n",
      "Epoch 240: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 5.0730 - bpp: 1.2691 - mse: 2.3217e-04\n",
      "Epoch 241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2200 - bpp: 1.3020 - mse: 2.3914e-04\n",
      "Epoch 241: loss did not improve from 4.28169\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 5.2200 - bpp: 1.3020 - mse: 2.3914e-04\n",
      "Epoch 242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1103 - bpp: 1.2366 - mse: 1.7540e-04\n",
      "Epoch 242: loss improved from 4.28169 to 4.11032, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.1103 - bpp: 1.2366 - mse: 1.7540e-04\n",
      "Epoch 243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2037 - bpp: 1.3097 - mse: 2.3767e-04\n",
      "Epoch 243: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 5.2037 - bpp: 1.3097 - mse: 2.3767e-04\n",
      "Epoch 244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6133 - bpp: 1.2637 - mse: 2.0444e-04\n",
      "Epoch 244: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.6133 - bpp: 1.2637 - mse: 2.0444e-04\n",
      "Epoch 245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6021 - bpp: 1.3078 - mse: 2.6210e-04\n",
      "Epoch 245: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.6021 - bpp: 1.3078 - mse: 2.6210e-04\n",
      "Epoch 246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5740 - bpp: 1.2826 - mse: 2.0089e-04\n",
      "Epoch 246: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.5740 - bpp: 1.2826 - mse: 2.0089e-04\n",
      "Epoch 247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6628 - bpp: 1.2703 - mse: 2.0706e-04\n",
      "Epoch 247: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 4.6628 - bpp: 1.2703 - mse: 2.0706e-04\n",
      "Epoch 248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1338 - bpp: 1.2672 - mse: 1.7497e-04\n",
      "Epoch 248: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.1338 - bpp: 1.2672 - mse: 1.7497e-04\n",
      "Epoch 249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9974 - bpp: 1.3235 - mse: 2.2424e-04\n",
      "Epoch 249: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 210ms/step - loss: 4.9974 - bpp: 1.3235 - mse: 2.2424e-04\n",
      "Epoch 250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3784 - bpp: 1.2986 - mse: 2.4901e-04\n",
      "Epoch 250: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 5.3784 - bpp: 1.2986 - mse: 2.4901e-04\n",
      "Epoch 251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0157 - bpp: 1.2788 - mse: 2.2809e-04\n",
      "Epoch 251: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.0157 - bpp: 1.2788 - mse: 2.2809e-04\n",
      "Epoch 252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5616 - bpp: 1.2635 - mse: 2.0130e-04\n",
      "Epoch 252: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.5616 - bpp: 1.2635 - mse: 2.0130e-04\n",
      "Epoch 253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9558 - bpp: 1.2888 - mse: 2.2381e-04\n",
      "Epoch 253: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.9558 - bpp: 1.2888 - mse: 2.2381e-04\n",
      "Epoch 254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7272 - bpp: 1.2975 - mse: 2.0933e-04\n",
      "Epoch 254: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.7272 - bpp: 1.2975 - mse: 2.0933e-04\n",
      "Epoch 255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.0474 - bpp: 1.3069 - mse: 3.5038e-04\n",
      "Epoch 255: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 7.0474 - bpp: 1.3069 - mse: 3.5038e-04\n",
      "Epoch 256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9354 - bpp: 1.2829 - mse: 2.2293e-04\n",
      "Epoch 256: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.9354 - bpp: 1.2829 - mse: 2.2293e-04\n",
      "Epoch 257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3366 - bpp: 1.2704 - mse: 1.8714e-04\n",
      "Epoch 257: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.3366 - bpp: 1.2704 - mse: 1.8714e-04\n",
      "Epoch 258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9725 - bpp: 1.2875 - mse: 2.2491e-04\n",
      "Epoch 258: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.9725 - bpp: 1.2875 - mse: 2.2491e-04\n",
      "Epoch 259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9805 - bpp: 1.3322 - mse: 2.8371e-04\n",
      "Epoch 259: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 5.9805 - bpp: 1.3322 - mse: 2.8371e-04\n",
      "Epoch 260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4821 - bpp: 1.2937 - mse: 1.9460e-04\n",
      "Epoch 260: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.4821 - bpp: 1.2937 - mse: 1.9460e-04\n",
      "Epoch 261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2279 - bpp: 1.3058 - mse: 2.3939e-04\n",
      "Epoch 261: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 5.2279 - bpp: 1.3058 - mse: 2.3939e-04\n",
      "Epoch 262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5706 - bpp: 1.2913 - mse: 2.0015e-04\n",
      "Epoch 262: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5706 - bpp: 1.2913 - mse: 2.0015e-04\n",
      "Epoch 263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7048 - bpp: 1.2864 - mse: 2.0864e-04\n",
      "Epoch 263: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.7048 - bpp: 1.2864 - mse: 2.0864e-04\n",
      "Epoch 264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3197 - bpp: 1.2756 - mse: 1.8579e-04\n",
      "Epoch 264: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.3197 - bpp: 1.2756 - mse: 1.8579e-04\n",
      "Epoch 265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4982 - bpp: 1.2799 - mse: 1.9643e-04\n",
      "Epoch 265: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.4982 - bpp: 1.2799 - mse: 1.9643e-04\n",
      "Epoch 266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5301 - bpp: 1.2888 - mse: 2.5887e-04\n",
      "Epoch 266: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.5301 - bpp: 1.2888 - mse: 2.5887e-04\n",
      "Epoch 267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5012 - bpp: 1.3018 - mse: 2.5631e-04\n",
      "Epoch 267: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 5.5012 - bpp: 1.3018 - mse: 2.5631e-04\n",
      "Epoch 268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9661 - bpp: 1.2952 - mse: 2.2406e-04\n",
      "Epoch 268: loss did not improve from 4.11032\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.9661 - bpp: 1.2952 - mse: 2.2406e-04\n",
      "Epoch 269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5216 - bpp: 1.2103 - mse: 1.4107e-04\n",
      "Epoch 269: loss improved from 4.11032 to 3.52158, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 45s 220ms/step - loss: 3.5216 - bpp: 1.2103 - mse: 1.4107e-04\n",
      "Epoch 270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5962 - bpp: 1.2817 - mse: 2.0230e-04\n",
      "Epoch 270: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.5962 - bpp: 1.2817 - mse: 2.0230e-04\n",
      "Epoch 271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1720 - bpp: 1.2904 - mse: 2.3692e-04\n",
      "Epoch 271: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 5.1720 - bpp: 1.2904 - mse: 2.3692e-04\n",
      "Epoch 272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7162 - bpp: 1.2748 - mse: 2.1004e-04\n",
      "Epoch 272: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.7162 - bpp: 1.2748 - mse: 2.1004e-04\n",
      "Epoch 273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.4632 - bpp: 1.3208 - mse: 3.7490e-04\n",
      "Epoch 273: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 7.4632 - bpp: 1.3208 - mse: 3.7490e-04\n",
      "Epoch 274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1700 - bpp: 1.3070 - mse: 2.3578e-04\n",
      "Epoch 274: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 5.1700 - bpp: 1.3070 - mse: 2.3578e-04\n",
      "Epoch 275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2666 - bpp: 1.2489 - mse: 1.8419e-04\n",
      "Epoch 275: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 202ms/step - loss: 4.2666 - bpp: 1.2489 - mse: 1.8419e-04\n",
      "Epoch 276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7855 - bpp: 1.2441 - mse: 1.5512e-04\n",
      "Epoch 276: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 3.7855 - bpp: 1.2441 - mse: 1.5512e-04\n",
      "Epoch 277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0223 - bpp: 1.2534 - mse: 1.6900e-04\n",
      "Epoch 277: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 4.0223 - bpp: 1.2534 - mse: 1.6900e-04\n",
      "Epoch 278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3738 - bpp: 1.2718 - mse: 1.8933e-04\n",
      "Epoch 278: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.3738 - bpp: 1.2718 - mse: 1.8933e-04\n",
      "Epoch 279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8045 - bpp: 1.3139 - mse: 2.1305e-04\n",
      "Epoch 279: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.8045 - bpp: 1.3139 - mse: 2.1305e-04\n",
      "Epoch 280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5487 - bpp: 1.2822 - mse: 1.9937e-04\n",
      "Epoch 280: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5487 - bpp: 1.2822 - mse: 1.9937e-04\n",
      "Epoch 281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5183 - bpp: 1.3098 - mse: 2.5686e-04\n",
      "Epoch 281: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 5.5183 - bpp: 1.3098 - mse: 2.5686e-04\n",
      "Epoch 282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9602 - bpp: 1.2784 - mse: 2.2472e-04\n",
      "Epoch 282: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.9602 - bpp: 1.2784 - mse: 2.2472e-04\n",
      "Epoch 283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1095 - bpp: 1.2629 - mse: 1.7374e-04\n",
      "Epoch 283: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.1095 - bpp: 1.2629 - mse: 1.7374e-04\n",
      "Epoch 284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9309 - bpp: 1.3002 - mse: 2.2160e-04\n",
      "Epoch 284: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.9309 - bpp: 1.3002 - mse: 2.2160e-04\n",
      "Epoch 285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6615 - bpp: 1.3127 - mse: 2.6543e-04\n",
      "Epoch 285: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 5.6615 - bpp: 1.3127 - mse: 2.6543e-04\n",
      "Epoch 286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.4732 - bpp: 1.2689 - mse: 2.5661e-04\n",
      "Epoch 286: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.4732 - bpp: 1.2689 - mse: 2.5661e-04\n",
      "Epoch 287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5994 - bpp: 1.2673 - mse: 2.0338e-04\n",
      "Epoch 287: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 4.5994 - bpp: 1.2673 - mse: 2.0338e-04\n",
      "Epoch 288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8190 - bpp: 1.3035 - mse: 2.1456e-04\n",
      "Epoch 288: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.8190 - bpp: 1.3035 - mse: 2.1456e-04\n",
      "Epoch 289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2417 - bpp: 1.2852 - mse: 1.8045e-04\n",
      "Epoch 289: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.2417 - bpp: 1.2852 - mse: 1.8045e-04\n",
      "Epoch 290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9544 - bpp: 1.2771 - mse: 2.8548e-04\n",
      "Epoch 290: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 5.9544 - bpp: 1.2771 - mse: 2.8548e-04\n",
      "Epoch 291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3640 - bpp: 1.2722 - mse: 1.8871e-04\n",
      "Epoch 291: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 207ms/step - loss: 4.3640 - bpp: 1.2722 - mse: 1.8871e-04\n",
      "Epoch 292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8480 - bpp: 1.3018 - mse: 2.1644e-04\n",
      "Epoch 292: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 4.8480 - bpp: 1.3018 - mse: 2.1644e-04\n",
      "Epoch 293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5904 - bpp: 1.2620 - mse: 2.0315e-04\n",
      "Epoch 293: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.5904 - bpp: 1.2620 - mse: 2.0315e-04\n",
      "Epoch 294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1973 - bpp: 1.2683 - mse: 1.7877e-04\n",
      "Epoch 294: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.1973 - bpp: 1.2683 - mse: 1.7877e-04\n",
      "Epoch 295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.0386 - bpp: 1.3106 - mse: 2.2754e-04\n",
      "Epoch 295: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.0386 - bpp: 1.3106 - mse: 2.2754e-04\n",
      "Epoch 296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2660 - bpp: 1.2742 - mse: 1.8261e-04\n",
      "Epoch 296: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 206ms/step - loss: 4.2660 - bpp: 1.2742 - mse: 1.8261e-04\n",
      "Epoch 297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2989 - bpp: 1.2650 - mse: 1.8517e-04\n",
      "Epoch 297: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.2989 - bpp: 1.2650 - mse: 1.8517e-04\n",
      "Epoch 298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1986 - bpp: 1.3184 - mse: 2.3683e-04\n",
      "Epoch 298: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.1986 - bpp: 1.3184 - mse: 2.3683e-04\n",
      "Epoch 299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3504 - bpp: 1.2572 - mse: 1.8879e-04\n",
      "Epoch 299: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.3504 - bpp: 1.2572 - mse: 1.8879e-04\n",
      "Epoch 300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4288 - bpp: 1.3026 - mse: 1.9081e-04\n",
      "Epoch 300: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.4288 - bpp: 1.3026 - mse: 1.9081e-04\n",
      "Epoch 301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 7.6450 - bpp: 1.3059 - mse: 3.8691e-04\n",
      "Epoch 301: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 7.6450 - bpp: 1.3059 - mse: 3.8691e-04\n",
      "Epoch 302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.6991 - bpp: 1.3067 - mse: 2.6809e-04\n",
      "Epoch 302: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.6991 - bpp: 1.3067 - mse: 2.6809e-04\n",
      "Epoch 303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1075 - bpp: 1.2736 - mse: 1.7297e-04\n",
      "Epoch 303: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.1075 - bpp: 1.2736 - mse: 1.7297e-04\n",
      "Epoch 304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4643 - bpp: 1.2881 - mse: 1.9386e-04\n",
      "Epoch 304: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 212ms/step - loss: 4.4643 - bpp: 1.2881 - mse: 1.9386e-04\n",
      "Epoch 305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5877 - bpp: 1.2826 - mse: 2.0173e-04\n",
      "Epoch 305: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.5877 - bpp: 1.2826 - mse: 2.0173e-04\n",
      "Epoch 306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3473 - bpp: 1.2920 - mse: 1.8648e-04\n",
      "Epoch 306: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.3473 - bpp: 1.2920 - mse: 1.8648e-04\n",
      "Epoch 307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0541 - bpp: 1.2815 - mse: 1.6922e-04\n",
      "Epoch 307: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.0541 - bpp: 1.2815 - mse: 1.6922e-04\n",
      "Epoch 308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3493 - bpp: 1.2811 - mse: 1.8727e-04\n",
      "Epoch 308: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.3493 - bpp: 1.2811 - mse: 1.8727e-04\n",
      "Epoch 309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6823 - bpp: 1.2870 - mse: 2.0723e-04\n",
      "Epoch 309: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.6823 - bpp: 1.2870 - mse: 2.0723e-04\n",
      "Epoch 310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1604 - bpp: 1.2589 - mse: 1.7710e-04\n",
      "Epoch 310: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 4.1604 - bpp: 1.2589 - mse: 1.7710e-04\n",
      "Epoch 311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0295 - bpp: 1.2795 - mse: 1.6785e-04\n",
      "Epoch 311: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 4.0295 - bpp: 1.2795 - mse: 1.6785e-04\n",
      "Epoch 312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5867 - bpp: 1.2603 - mse: 2.0303e-04\n",
      "Epoch 312: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 215ms/step - loss: 4.5867 - bpp: 1.2603 - mse: 2.0303e-04\n",
      "Epoch 313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3620 - bpp: 1.2815 - mse: 2.4905e-04\n",
      "Epoch 313: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 5.3620 - bpp: 1.2815 - mse: 2.4905e-04\n",
      "Epoch 314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3172 - bpp: 1.2645 - mse: 1.8632e-04\n",
      "Epoch 314: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.3172 - bpp: 1.2645 - mse: 1.8632e-04\n",
      "Epoch 315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6586 - bpp: 1.2672 - mse: 2.0699e-04\n",
      "Epoch 315: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 211ms/step - loss: 4.6586 - bpp: 1.2672 - mse: 2.0699e-04\n",
      "Epoch 316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3135 - bpp: 1.2978 - mse: 1.8406e-04\n",
      "Epoch 316: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.3135 - bpp: 1.2978 - mse: 1.8406e-04\n",
      "Epoch 317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0686 - bpp: 1.2692 - mse: 1.7087e-04\n",
      "Epoch 317: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.0686 - bpp: 1.2692 - mse: 1.7087e-04\n",
      "Epoch 318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5010 - bpp: 1.2928 - mse: 1.9581e-04\n",
      "Epoch 318: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5010 - bpp: 1.2928 - mse: 1.9581e-04\n",
      "Epoch 319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5093 - bpp: 1.2835 - mse: 1.9689e-04\n",
      "Epoch 319: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 4.5093 - bpp: 1.2835 - mse: 1.9689e-04\n",
      "Epoch 320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9879 - bpp: 1.2856 - mse: 2.2597e-04\n",
      "Epoch 320: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.9879 - bpp: 1.2856 - mse: 2.2597e-04\n",
      "Epoch 321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3496 - bpp: 1.2785 - mse: 1.8745e-04\n",
      "Epoch 321: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.3496 - bpp: 1.2785 - mse: 1.8745e-04\n",
      "Epoch 322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9262 - bpp: 1.2666 - mse: 1.6233e-04\n",
      "Epoch 322: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 3.9262 - bpp: 1.2666 - mse: 1.6233e-04\n",
      "Epoch 323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8275 - bpp: 1.2528 - mse: 1.5715e-04\n",
      "Epoch 323: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 3.8275 - bpp: 1.2528 - mse: 1.5715e-04\n",
      "Epoch 324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9210 - bpp: 1.3188 - mse: 2.1986e-04\n",
      "Epoch 324: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 4.9210 - bpp: 1.3188 - mse: 2.1986e-04\n",
      "Epoch 325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.3194 - bpp: 1.2931 - mse: 2.4575e-04\n",
      "Epoch 325: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 5.3194 - bpp: 1.2931 - mse: 2.4575e-04\n",
      "Epoch 326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2320 - bpp: 1.2696 - mse: 1.8081e-04\n",
      "Epoch 326: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 4.2320 - bpp: 1.2696 - mse: 1.8081e-04\n",
      "Epoch 327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9755 - bpp: 1.2702 - mse: 2.2616e-04\n",
      "Epoch 327: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 4.9755 - bpp: 1.2702 - mse: 2.2616e-04\n",
      "Epoch 328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4886 - bpp: 1.2524 - mse: 1.9752e-04\n",
      "Epoch 328: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 4.4886 - bpp: 1.2524 - mse: 1.9752e-04\n",
      "Epoch 329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1794 - bpp: 1.2880 - mse: 2.3751e-04\n",
      "Epoch 329: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.1794 - bpp: 1.2880 - mse: 2.3751e-04\n",
      "Epoch 330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4605 - bpp: 1.2755 - mse: 1.9440e-04\n",
      "Epoch 330: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.4605 - bpp: 1.2755 - mse: 1.9440e-04\n",
      "Epoch 331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0590 - bpp: 1.2659 - mse: 1.7048e-04\n",
      "Epoch 331: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.0590 - bpp: 1.2659 - mse: 1.7048e-04\n",
      "Epoch 332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9001 - bpp: 1.2385 - mse: 1.6245e-04\n",
      "Epoch 332: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.9001 - bpp: 1.2385 - mse: 1.6245e-04\n",
      "Epoch 333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9418 - bpp: 1.2765 - mse: 1.6268e-04\n",
      "Epoch 333: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.9418 - bpp: 1.2765 - mse: 1.6268e-04\n",
      "Epoch 334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5571 - bpp: 1.3024 - mse: 1.9865e-04\n",
      "Epoch 334: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.5571 - bpp: 1.3024 - mse: 1.9865e-04\n",
      "Epoch 335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2754 - bpp: 1.2789 - mse: 1.8289e-04\n",
      "Epoch 335: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.2754 - bpp: 1.2789 - mse: 1.8289e-04\n",
      "Epoch 336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1751 - bpp: 1.3090 - mse: 2.3597e-04\n",
      "Epoch 336: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 5.1751 - bpp: 1.3090 - mse: 2.3597e-04\n",
      "Epoch 337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0014 - bpp: 1.2511 - mse: 1.6787e-04\n",
      "Epoch 337: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.0014 - bpp: 1.2511 - mse: 1.6787e-04\n",
      "Epoch 338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.5248 - bpp: 1.2865 - mse: 2.5869e-04\n",
      "Epoch 338: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 5.5248 - bpp: 1.2865 - mse: 2.5869e-04\n",
      "Epoch 339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7290 - bpp: 1.2892 - mse: 2.0995e-04\n",
      "Epoch 339: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 4.7290 - bpp: 1.2892 - mse: 2.0995e-04\n",
      "Epoch 340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3667 - bpp: 1.2854 - mse: 1.8807e-04\n",
      "Epoch 340: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.3667 - bpp: 1.2854 - mse: 1.8807e-04\n",
      "Epoch 341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5110 - bpp: 1.2979 - mse: 1.9612e-04\n",
      "Epoch 341: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.5110 - bpp: 1.2979 - mse: 1.9612e-04\n",
      "Epoch 342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9170 - bpp: 1.2466 - mse: 1.6299e-04\n",
      "Epoch 342: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.9170 - bpp: 1.2466 - mse: 1.6299e-04\n",
      "Epoch 343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1411 - bpp: 1.2616 - mse: 1.7575e-04\n",
      "Epoch 343: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.1411 - bpp: 1.2616 - mse: 1.7575e-04\n",
      "Epoch 344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9374 - bpp: 1.2625 - mse: 1.6327e-04\n",
      "Epoch 344: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.9374 - bpp: 1.2625 - mse: 1.6327e-04\n",
      "Epoch 345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1627 - bpp: 1.2534 - mse: 2.3860e-04\n",
      "Epoch 345: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 5.1627 - bpp: 1.2534 - mse: 2.3860e-04\n",
      "Epoch 346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3646 - bpp: 1.2737 - mse: 1.8866e-04\n",
      "Epoch 346: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.3646 - bpp: 1.2737 - mse: 1.8866e-04\n",
      "Epoch 347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6630 - bpp: 1.2522 - mse: 1.4715e-04\n",
      "Epoch 347: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.6630 - bpp: 1.2522 - mse: 1.4715e-04\n",
      "Epoch 348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6810 - bpp: 1.2355 - mse: 1.4926e-04\n",
      "Epoch 348: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.6810 - bpp: 1.2355 - mse: 1.4926e-04\n",
      "Epoch 349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.9207 - bpp: 1.2931 - mse: 2.8245e-04\n",
      "Epoch 349: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 5.9207 - bpp: 1.2931 - mse: 2.8245e-04\n",
      "Epoch 350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1288 - bpp: 1.2543 - mse: 1.7545e-04\n",
      "Epoch 350: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.1288 - bpp: 1.2543 - mse: 1.7545e-04\n",
      "Epoch 351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1819 - bpp: 1.2736 - mse: 1.7751e-04\n",
      "Epoch 351: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.1819 - bpp: 1.2736 - mse: 1.7751e-04\n",
      "Epoch 352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9739 - bpp: 1.2352 - mse: 1.6716e-04\n",
      "Epoch 352: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9739 - bpp: 1.2352 - mse: 1.6716e-04\n",
      "Epoch 353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3282 - bpp: 1.2443 - mse: 1.8823e-04\n",
      "Epoch 353: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.3282 - bpp: 1.2443 - mse: 1.8823e-04\n",
      "Epoch 354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6763 - bpp: 1.2377 - mse: 1.4884e-04\n",
      "Epoch 354: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6763 - bpp: 1.2377 - mse: 1.4884e-04\n",
      "Epoch 355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0972 - bpp: 1.2593 - mse: 1.7321e-04\n",
      "Epoch 355: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.0972 - bpp: 1.2593 - mse: 1.7321e-04\n",
      "Epoch 356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0091 - bpp: 1.2313 - mse: 1.6954e-04\n",
      "Epoch 356: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.0091 - bpp: 1.2313 - mse: 1.6954e-04\n",
      "Epoch 357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5494 - bpp: 1.3004 - mse: 1.9830e-04\n",
      "Epoch 357: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.5494 - bpp: 1.3004 - mse: 1.9830e-04\n",
      "Epoch 358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8444 - bpp: 1.2412 - mse: 1.5889e-04\n",
      "Epoch 358: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8444 - bpp: 1.2412 - mse: 1.5889e-04\n",
      "Epoch 359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0478 - bpp: 1.2581 - mse: 1.7027e-04\n",
      "Epoch 359: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.0478 - bpp: 1.2581 - mse: 1.7027e-04\n",
      "Epoch 360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4804 - bpp: 1.2629 - mse: 1.9638e-04\n",
      "Epoch 360: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.4804 - bpp: 1.2629 - mse: 1.9638e-04\n",
      "Epoch 361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8747 - bpp: 1.2430 - mse: 1.6063e-04\n",
      "Epoch 361: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.8747 - bpp: 1.2430 - mse: 1.6063e-04\n",
      "Epoch 362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9383 - bpp: 1.3015 - mse: 2.2197e-04\n",
      "Epoch 362: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.9383 - bpp: 1.3015 - mse: 2.2197e-04\n",
      "Epoch 363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6485 - bpp: 1.2803 - mse: 2.0558e-04\n",
      "Epoch 363: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 4.6485 - bpp: 1.2803 - mse: 2.0558e-04\n",
      "Epoch 364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7721 - bpp: 1.2417 - mse: 1.5445e-04\n",
      "Epoch 364: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.7721 - bpp: 1.2417 - mse: 1.5445e-04\n",
      "Epoch 365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3273 - bpp: 1.2695 - mse: 1.8663e-04\n",
      "Epoch 365: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.3273 - bpp: 1.2695 - mse: 1.8663e-04\n",
      "Epoch 366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6678 - bpp: 1.2775 - mse: 2.0693e-04\n",
      "Epoch 366: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.6678 - bpp: 1.2775 - mse: 2.0693e-04\n",
      "Epoch 367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9992 - bpp: 1.2636 - mse: 1.6696e-04\n",
      "Epoch 367: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 224ms/step - loss: 3.9992 - bpp: 1.2636 - mse: 1.6696e-04\n",
      "Epoch 368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6779 - bpp: 1.2882 - mse: 2.0689e-04\n",
      "Epoch 368: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.6779 - bpp: 1.2882 - mse: 2.0689e-04\n",
      "Epoch 369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1758 - bpp: 1.2674 - mse: 1.7751e-04\n",
      "Epoch 369: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.1758 - bpp: 1.2674 - mse: 1.7751e-04\n",
      "Epoch 370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0733 - bpp: 1.2621 - mse: 1.7158e-04\n",
      "Epoch 370: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0733 - bpp: 1.2621 - mse: 1.7158e-04\n",
      "Epoch 371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0413 - bpp: 1.2513 - mse: 1.7029e-04\n",
      "Epoch 371: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 4.0413 - bpp: 1.2513 - mse: 1.7029e-04\n",
      "Epoch 372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9750 - bpp: 1.2637 - mse: 1.6548e-04\n",
      "Epoch 372: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.9750 - bpp: 1.2637 - mse: 1.6548e-04\n",
      "Epoch 373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.2081 - bpp: 1.2939 - mse: 2.3891e-04\n",
      "Epoch 373: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 5.2081 - bpp: 1.2939 - mse: 2.3891e-04\n",
      "Epoch 374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8951 - bpp: 1.2868 - mse: 2.2023e-04\n",
      "Epoch 374: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.8951 - bpp: 1.2868 - mse: 2.2023e-04\n",
      "Epoch 375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4465 - bpp: 1.2757 - mse: 1.9353e-04\n",
      "Epoch 375: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.4465 - bpp: 1.2757 - mse: 1.9353e-04\n",
      "Epoch 376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8527 - bpp: 1.2546 - mse: 1.5858e-04\n",
      "Epoch 376: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.8527 - bpp: 1.2546 - mse: 1.5858e-04\n",
      "Epoch 377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1388 - bpp: 1.2764 - mse: 1.7471e-04\n",
      "Epoch 377: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 4.1388 - bpp: 1.2764 - mse: 1.7471e-04\n",
      "Epoch 378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8026 - bpp: 1.2438 - mse: 1.5617e-04\n",
      "Epoch 378: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.8026 - bpp: 1.2438 - mse: 1.5617e-04\n",
      "Epoch 379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9873 - bpp: 1.2519 - mse: 1.6695e-04\n",
      "Epoch 379: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.9873 - bpp: 1.2519 - mse: 1.6695e-04\n",
      "Epoch 380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5798 - bpp: 1.2771 - mse: 2.0158e-04\n",
      "Epoch 380: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.5798 - bpp: 1.2771 - mse: 2.0158e-04\n",
      "Epoch 381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7104 - bpp: 1.2306 - mse: 1.5135e-04\n",
      "Epoch 381: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 3.7104 - bpp: 1.2306 - mse: 1.5135e-04\n",
      "Epoch 382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6534 - bpp: 1.2359 - mse: 1.4755e-04\n",
      "Epoch 382: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6534 - bpp: 1.2359 - mse: 1.4755e-04\n",
      "Epoch 383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0900 - bpp: 1.2622 - mse: 1.7260e-04\n",
      "Epoch 383: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0900 - bpp: 1.2622 - mse: 1.7260e-04\n",
      "Epoch 384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2472 - bpp: 1.2816 - mse: 1.8101e-04\n",
      "Epoch 384: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 4.2472 - bpp: 1.2816 - mse: 1.8101e-04\n",
      "Epoch 385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5868 - bpp: 1.2626 - mse: 2.0289e-04\n",
      "Epoch 385: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 4.5868 - bpp: 1.2626 - mse: 2.0289e-04\n",
      "Epoch 386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3596 - bpp: 1.2850 - mse: 1.8766e-04\n",
      "Epoch 386: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 4.3596 - bpp: 1.2850 - mse: 1.8766e-04\n",
      "Epoch 387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3675 - bpp: 1.2380 - mse: 1.9101e-04\n",
      "Epoch 387: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 4.3675 - bpp: 1.2380 - mse: 1.9101e-04\n",
      "Epoch 388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7202 - bpp: 1.2385 - mse: 1.5147e-04\n",
      "Epoch 388: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.7202 - bpp: 1.2385 - mse: 1.5147e-04\n",
      "Epoch 389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7250 - bpp: 1.2372 - mse: 1.5184e-04\n",
      "Epoch 389: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.7250 - bpp: 1.2372 - mse: 1.5184e-04\n",
      "Epoch 390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2329 - bpp: 1.2673 - mse: 1.8100e-04\n",
      "Epoch 390: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.2329 - bpp: 1.2673 - mse: 1.8100e-04\n",
      "Epoch 391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1477 - bpp: 1.2620 - mse: 1.7613e-04\n",
      "Epoch 391: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 4.1477 - bpp: 1.2620 - mse: 1.7613e-04\n",
      "Epoch 392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8442 - bpp: 1.2575 - mse: 1.5788e-04\n",
      "Epoch 392: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8442 - bpp: 1.2575 - mse: 1.5788e-04\n",
      "Epoch 393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1041 - bpp: 1.2739 - mse: 1.7274e-04\n",
      "Epoch 393: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 4.1041 - bpp: 1.2739 - mse: 1.7274e-04\n",
      "Epoch 394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6648 - bpp: 1.2432 - mse: 1.4780e-04\n",
      "Epoch 394: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6648 - bpp: 1.2432 - mse: 1.4780e-04\n",
      "Epoch 395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9709 - bpp: 1.2556 - mse: 1.6573e-04\n",
      "Epoch 395: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.9709 - bpp: 1.2556 - mse: 1.6573e-04\n",
      "Epoch 396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8065 - bpp: 1.2545 - mse: 1.5576e-04\n",
      "Epoch 396: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.8065 - bpp: 1.2545 - mse: 1.5576e-04\n",
      "Epoch 397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4626 - bpp: 1.2571 - mse: 1.9565e-04\n",
      "Epoch 397: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.4626 - bpp: 1.2571 - mse: 1.9565e-04\n",
      "Epoch 398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7970 - bpp: 1.2508 - mse: 2.1645e-04\n",
      "Epoch 398: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 4.7970 - bpp: 1.2508 - mse: 2.1645e-04\n",
      "Epoch 399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7741 - bpp: 1.2705 - mse: 2.1384e-04\n",
      "Epoch 399: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.7741 - bpp: 1.2705 - mse: 2.1384e-04\n",
      "Epoch 400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5886 - bpp: 1.2806 - mse: 2.0191e-04\n",
      "Epoch 400: loss did not improve from 3.52158\n",
      "200/200 [==============================] - 44s 217ms/step - loss: 4.5886 - bpp: 1.2806 - mse: 2.0191e-04\n",
      "Epoch 401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4629 - bpp: 1.2183 - mse: 1.3700e-04\n",
      "Epoch 401: loss improved from 3.52158 to 3.46289, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.4629 - bpp: 1.2183 - mse: 1.3700e-04\n",
      "Epoch 402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3099 - bpp: 1.2852 - mse: 1.8461e-04\n",
      "Epoch 402: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.3099 - bpp: 1.2852 - mse: 1.8461e-04\n",
      "Epoch 403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6659 - bpp: 1.2454 - mse: 1.4774e-04\n",
      "Epoch 403: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 224ms/step - loss: 3.6659 - bpp: 1.2454 - mse: 1.4774e-04\n",
      "Epoch 404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1661 - bpp: 1.2621 - mse: 1.7725e-04\n",
      "Epoch 404: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.1661 - bpp: 1.2621 - mse: 1.7725e-04\n",
      "Epoch 405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6445 - bpp: 1.2581 - mse: 1.4565e-04\n",
      "Epoch 405: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6445 - bpp: 1.2581 - mse: 1.4565e-04\n",
      "Epoch 406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.6375 - bpp: 1.2634 - mse: 2.0594e-04\n",
      "Epoch 406: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.6375 - bpp: 1.2634 - mse: 2.0594e-04\n",
      "Epoch 407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1646 - bpp: 1.2670 - mse: 1.7686e-04\n",
      "Epoch 407: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 4.1646 - bpp: 1.2670 - mse: 1.7686e-04\n",
      "Epoch 408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2200 - bpp: 1.2559 - mse: 1.8092e-04\n",
      "Epoch 408: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.2200 - bpp: 1.2559 - mse: 1.8092e-04\n",
      "Epoch 409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6132 - bpp: 1.2240 - mse: 1.4582e-04\n",
      "Epoch 409: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6132 - bpp: 1.2240 - mse: 1.4582e-04\n",
      "Epoch 410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5430 - bpp: 1.2450 - mse: 1.4026e-04\n",
      "Epoch 410: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5430 - bpp: 1.2450 - mse: 1.4026e-04\n",
      "Epoch 411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8415 - bpp: 1.2630 - mse: 1.5738e-04\n",
      "Epoch 411: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.8415 - bpp: 1.2630 - mse: 1.5738e-04\n",
      "Epoch 412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7443 - bpp: 1.2383 - mse: 1.5295e-04\n",
      "Epoch 412: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7443 - bpp: 1.2383 - mse: 1.5295e-04\n",
      "Epoch 413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1317 - bpp: 1.3018 - mse: 1.7273e-04\n",
      "Epoch 413: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 4.1317 - bpp: 1.3018 - mse: 1.7273e-04\n",
      "Epoch 414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9987 - bpp: 1.2640 - mse: 1.6691e-04\n",
      "Epoch 414: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.9987 - bpp: 1.2640 - mse: 1.6691e-04\n",
      "Epoch 415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3192 - bpp: 1.2698 - mse: 1.8612e-04\n",
      "Epoch 415: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.3192 - bpp: 1.2698 - mse: 1.8612e-04\n",
      "Epoch 416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4629 - bpp: 1.2245 - mse: 1.3662e-04\n",
      "Epoch 416: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4629 - bpp: 1.2245 - mse: 1.3662e-04\n",
      "Epoch 417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9252 - bpp: 1.2456 - mse: 1.6355e-04\n",
      "Epoch 417: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9252 - bpp: 1.2456 - mse: 1.6355e-04\n",
      "Epoch 418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3846 - bpp: 1.2263 - mse: 1.9276e-04\n",
      "Epoch 418: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.3846 - bpp: 1.2263 - mse: 1.9276e-04\n",
      "Epoch 419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9239 - bpp: 1.2494 - mse: 1.6324e-04\n",
      "Epoch 419: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.9239 - bpp: 1.2494 - mse: 1.6324e-04\n",
      "Epoch 420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9575 - bpp: 1.2545 - mse: 1.6498e-04\n",
      "Epoch 420: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.9575 - bpp: 1.2545 - mse: 1.6498e-04\n",
      "Epoch 421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2566 - bpp: 1.2604 - mse: 1.8288e-04\n",
      "Epoch 421: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.2566 - bpp: 1.2604 - mse: 1.8288e-04\n",
      "Epoch 422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2953 - bpp: 1.2539 - mse: 1.8563e-04\n",
      "Epoch 422: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.2953 - bpp: 1.2539 - mse: 1.8563e-04\n",
      "Epoch 423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6072 - bpp: 1.2205 - mse: 1.4567e-04\n",
      "Epoch 423: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6072 - bpp: 1.2205 - mse: 1.4567e-04\n",
      "Epoch 424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6233 - bpp: 1.2438 - mse: 1.4524e-04\n",
      "Epoch 424: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6233 - bpp: 1.2438 - mse: 1.4524e-04\n",
      "Epoch 425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5347 - bpp: 1.2568 - mse: 2.0007e-04\n",
      "Epoch 425: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.5347 - bpp: 1.2568 - mse: 2.0007e-04\n",
      "Epoch 426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9212 - bpp: 1.2330 - mse: 1.6408e-04\n",
      "Epoch 426: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.9212 - bpp: 1.2330 - mse: 1.6408e-04\n",
      "Epoch 427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8445 - bpp: 1.2424 - mse: 1.5882e-04\n",
      "Epoch 427: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.8445 - bpp: 1.2424 - mse: 1.5882e-04\n",
      "Epoch 428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6749 - bpp: 1.2303 - mse: 1.4920e-04\n",
      "Epoch 428: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6749 - bpp: 1.2303 - mse: 1.4920e-04\n",
      "Epoch 429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9995 - bpp: 1.2573 - mse: 1.6737e-04\n",
      "Epoch 429: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9995 - bpp: 1.2573 - mse: 1.6737e-04\n",
      "Epoch 430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0117 - bpp: 1.2634 - mse: 1.6774e-04\n",
      "Epoch 430: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.0117 - bpp: 1.2634 - mse: 1.6774e-04\n",
      "Epoch 431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5636 - bpp: 1.2150 - mse: 1.4335e-04\n",
      "Epoch 431: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5636 - bpp: 1.2150 - mse: 1.4335e-04\n",
      "Epoch 432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9978 - bpp: 1.2420 - mse: 1.6820e-04\n",
      "Epoch 432: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.9978 - bpp: 1.2420 - mse: 1.6820e-04\n",
      "Epoch 433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9257 - bpp: 1.2150 - mse: 1.6544e-04\n",
      "Epoch 433: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.9257 - bpp: 1.2150 - mse: 1.6544e-04\n",
      "Epoch 434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0126 - bpp: 1.2198 - mse: 1.7046e-04\n",
      "Epoch 434: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 4.0126 - bpp: 1.2198 - mse: 1.7046e-04\n",
      "Epoch 435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.5561 - bpp: 1.2670 - mse: 2.0075e-04\n",
      "Epoch 435: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 4.5561 - bpp: 1.2670 - mse: 2.0075e-04\n",
      "Epoch 436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7052 - bpp: 1.2343 - mse: 1.5081e-04\n",
      "Epoch 436: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.7052 - bpp: 1.2343 - mse: 1.5081e-04\n",
      "Epoch 437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9511 - bpp: 1.2715 - mse: 1.6355e-04\n",
      "Epoch 437: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.9511 - bpp: 1.2715 - mse: 1.6355e-04\n",
      "Epoch 438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8666 - bpp: 1.2264 - mse: 1.6114e-04\n",
      "Epoch 438: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8666 - bpp: 1.2264 - mse: 1.6114e-04\n",
      "Epoch 439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9315 - bpp: 1.2381 - mse: 1.6440e-04\n",
      "Epoch 439: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.9315 - bpp: 1.2381 - mse: 1.6440e-04\n",
      "Epoch 440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5276 - bpp: 1.2110 - mse: 1.4139e-04\n",
      "Epoch 440: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.5276 - bpp: 1.2110 - mse: 1.4139e-04\n",
      "Epoch 441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6939 - bpp: 1.2086 - mse: 1.5169e-04\n",
      "Epoch 441: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.6939 - bpp: 1.2086 - mse: 1.5169e-04\n",
      "Epoch 442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7074 - bpp: 1.2454 - mse: 1.5027e-04\n",
      "Epoch 442: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.7074 - bpp: 1.2454 - mse: 1.5027e-04\n",
      "Epoch 443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9760 - bpp: 1.2271 - mse: 1.6778e-04\n",
      "Epoch 443: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.9760 - bpp: 1.2271 - mse: 1.6778e-04\n",
      "Epoch 444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7636 - bpp: 1.2294 - mse: 1.5467e-04\n",
      "Epoch 444: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.7636 - bpp: 1.2294 - mse: 1.5467e-04\n",
      "Epoch 445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7872 - bpp: 1.2247 - mse: 1.5640e-04\n",
      "Epoch 445: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7872 - bpp: 1.2247 - mse: 1.5640e-04\n",
      "Epoch 446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8584 - bpp: 1.2318 - mse: 1.6032e-04\n",
      "Epoch 446: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.8584 - bpp: 1.2318 - mse: 1.6032e-04\n",
      "Epoch 447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6694 - bpp: 1.2514 - mse: 1.4758e-04\n",
      "Epoch 447: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6694 - bpp: 1.2514 - mse: 1.4758e-04\n",
      "Epoch 448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1509 - bpp: 1.2553 - mse: 1.7673e-04\n",
      "Epoch 448: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.1509 - bpp: 1.2553 - mse: 1.7673e-04\n",
      "Epoch 449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6846 - bpp: 1.2397 - mse: 1.4923e-04\n",
      "Epoch 449: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.6846 - bpp: 1.2397 - mse: 1.4923e-04\n",
      "Epoch 450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0078 - bpp: 1.2498 - mse: 1.6834e-04\n",
      "Epoch 450: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0078 - bpp: 1.2498 - mse: 1.6834e-04\n",
      "Epoch 451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8853 - bpp: 1.2492 - mse: 1.6089e-04\n",
      "Epoch 451: loss did not improve from 3.46289\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.8853 - bpp: 1.2492 - mse: 1.6089e-04\n",
      "Epoch 452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1989 - bpp: 1.2071 - mse: 1.2157e-04\n",
      "Epoch 452: loss improved from 3.46289 to 3.19885, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.1989 - bpp: 1.2071 - mse: 1.2157e-04\n",
      "Epoch 453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9404 - bpp: 1.2564 - mse: 1.6382e-04\n",
      "Epoch 453: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.9404 - bpp: 1.2564 - mse: 1.6382e-04\n",
      "Epoch 454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6425 - bpp: 1.2247 - mse: 1.4757e-04\n",
      "Epoch 454: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.6425 - bpp: 1.2247 - mse: 1.4757e-04\n",
      "Epoch 455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7624 - bpp: 1.2096 - mse: 1.5581e-04\n",
      "Epoch 455: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.7624 - bpp: 1.2096 - mse: 1.5581e-04\n",
      "Epoch 456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0969 - bpp: 1.2228 - mse: 1.7542e-04\n",
      "Epoch 456: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 4.0969 - bpp: 1.2228 - mse: 1.7542e-04\n",
      "Epoch 457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2800 - bpp: 1.2251 - mse: 1.8646e-04\n",
      "Epoch 457: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 4.2800 - bpp: 1.2251 - mse: 1.8646e-04\n",
      "Epoch 458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5481 - bpp: 1.2278 - mse: 1.4162e-04\n",
      "Epoch 458: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.5481 - bpp: 1.2278 - mse: 1.4162e-04\n",
      "Epoch 459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5108 - bpp: 1.2272 - mse: 1.3938e-04\n",
      "Epoch 459: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.5108 - bpp: 1.2272 - mse: 1.3938e-04\n",
      "Epoch 460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7842 - bpp: 1.2553 - mse: 1.5435e-04\n",
      "Epoch 460: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.7842 - bpp: 1.2553 - mse: 1.5435e-04\n",
      "Epoch 461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1923 - bpp: 1.2717 - mse: 1.7826e-04\n",
      "Epoch 461: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 4.1923 - bpp: 1.2717 - mse: 1.7826e-04\n",
      "Epoch 462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5968 - bpp: 1.2333 - mse: 1.4426e-04\n",
      "Epoch 462: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5968 - bpp: 1.2333 - mse: 1.4426e-04\n",
      "Epoch 463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0071 - bpp: 1.2345 - mse: 1.6923e-04\n",
      "Epoch 463: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 4.0071 - bpp: 1.2345 - mse: 1.6923e-04\n",
      "Epoch 464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9655 - bpp: 1.2375 - mse: 1.6651e-04\n",
      "Epoch 464: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9655 - bpp: 1.2375 - mse: 1.6651e-04\n",
      "Epoch 465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1979 - bpp: 1.2429 - mse: 1.8036e-04\n",
      "Epoch 465: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 4.1979 - bpp: 1.2429 - mse: 1.8036e-04\n",
      "Epoch 466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4025 - bpp: 1.2129 - mse: 1.3364e-04\n",
      "Epoch 466: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.4025 - bpp: 1.2129 - mse: 1.3364e-04\n",
      "Epoch 467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7096 - bpp: 1.2225 - mse: 1.5180e-04\n",
      "Epoch 467: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7096 - bpp: 1.2225 - mse: 1.5180e-04\n",
      "Epoch 468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5357 - bpp: 1.2181 - mse: 1.4145e-04\n",
      "Epoch 468: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5357 - bpp: 1.2181 - mse: 1.4145e-04\n",
      "Epoch 469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7136 - bpp: 1.2271 - mse: 1.5177e-04\n",
      "Epoch 469: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7136 - bpp: 1.2271 - mse: 1.5177e-04\n",
      "Epoch 470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6530 - bpp: 1.2058 - mse: 1.4937e-04\n",
      "Epoch 470: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6530 - bpp: 1.2058 - mse: 1.4937e-04\n",
      "Epoch 471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7444 - bpp: 1.2161 - mse: 1.5432e-04\n",
      "Epoch 471: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.7444 - bpp: 1.2161 - mse: 1.5432e-04\n",
      "Epoch 472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8537 - bpp: 1.2541 - mse: 2.1970e-04\n",
      "Epoch 472: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.8537 - bpp: 1.2541 - mse: 2.1970e-04\n",
      "Epoch 473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7746 - bpp: 1.2326 - mse: 1.5515e-04\n",
      "Epoch 473: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.7746 - bpp: 1.2326 - mse: 1.5515e-04\n",
      "Epoch 474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7019 - bpp: 1.2179 - mse: 1.5161e-04\n",
      "Epoch 474: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.7019 - bpp: 1.2179 - mse: 1.5161e-04\n",
      "Epoch 475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3812 - bpp: 1.1997 - mse: 1.3315e-04\n",
      "Epoch 475: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.3812 - bpp: 1.1997 - mse: 1.3315e-04\n",
      "Epoch 476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4456 - bpp: 1.2009 - mse: 1.3700e-04\n",
      "Epoch 476: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4456 - bpp: 1.2009 - mse: 1.3700e-04\n",
      "Epoch 477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4119 - bpp: 1.1994 - mse: 1.3504e-04\n",
      "Epoch 477: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.4119 - bpp: 1.1994 - mse: 1.3504e-04\n",
      "Epoch 478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4412 - bpp: 1.2207 - mse: 1.3552e-04\n",
      "Epoch 478: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4412 - bpp: 1.2207 - mse: 1.3552e-04\n",
      "Epoch 479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.8900 - bpp: 1.2390 - mse: 2.2284e-04\n",
      "Epoch 479: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 4.8900 - bpp: 1.2390 - mse: 2.2284e-04\n",
      "Epoch 480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6689 - bpp: 1.2339 - mse: 1.4862e-04\n",
      "Epoch 480: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.6689 - bpp: 1.2339 - mse: 1.4862e-04\n",
      "Epoch 481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4680 - bpp: 1.2199 - mse: 1.3722e-04\n",
      "Epoch 481: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4680 - bpp: 1.2199 - mse: 1.3722e-04\n",
      "Epoch 482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4850 - bpp: 1.2017 - mse: 1.3937e-04\n",
      "Epoch 482: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.4850 - bpp: 1.2017 - mse: 1.3937e-04\n",
      "Epoch 483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7957 - bpp: 1.2365 - mse: 1.5620e-04\n",
      "Epoch 483: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7957 - bpp: 1.2365 - mse: 1.5620e-04\n",
      "Epoch 484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8392 - bpp: 1.2353 - mse: 1.5893e-04\n",
      "Epoch 484: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.8392 - bpp: 1.2353 - mse: 1.5893e-04\n",
      "Epoch 485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3876 - bpp: 1.1905 - mse: 1.3411e-04\n",
      "Epoch 485: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.3876 - bpp: 1.1905 - mse: 1.3411e-04\n",
      "Epoch 486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8407 - bpp: 1.2192 - mse: 1.6001e-04\n",
      "Epoch 486: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.8407 - bpp: 1.2192 - mse: 1.6001e-04\n",
      "Epoch 487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6593 - bpp: 1.2174 - mse: 1.4904e-04\n",
      "Epoch 487: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.6593 - bpp: 1.2174 - mse: 1.4904e-04\n",
      "Epoch 488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7031 - bpp: 1.2129 - mse: 1.5199e-04\n",
      "Epoch 488: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7031 - bpp: 1.2129 - mse: 1.5199e-04\n",
      "Epoch 489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6442 - bpp: 1.2258 - mse: 1.4760e-04\n",
      "Epoch 489: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.6442 - bpp: 1.2258 - mse: 1.4760e-04\n",
      "Epoch 490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6427 - bpp: 1.2228 - mse: 1.4770e-04\n",
      "Epoch 490: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.6427 - bpp: 1.2228 - mse: 1.4770e-04\n",
      "Epoch 491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4497 - bpp: 1.2029 - mse: 1.3713e-04\n",
      "Epoch 491: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4497 - bpp: 1.2029 - mse: 1.3713e-04\n",
      "Epoch 492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8457 - bpp: 1.2382 - mse: 1.5915e-04\n",
      "Epoch 492: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.8457 - bpp: 1.2382 - mse: 1.5915e-04\n",
      "Epoch 493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0335 - bpp: 1.2356 - mse: 1.7077e-04\n",
      "Epoch 493: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 4.0335 - bpp: 1.2356 - mse: 1.7077e-04\n",
      "Epoch 494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.2708 - bpp: 1.2640 - mse: 1.8352e-04\n",
      "Epoch 494: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 4.2708 - bpp: 1.2640 - mse: 1.8352e-04\n",
      "Epoch 495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8695 - bpp: 1.2294 - mse: 1.6114e-04\n",
      "Epoch 495: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.8695 - bpp: 1.2294 - mse: 1.6114e-04\n",
      "Epoch 496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9419 - bpp: 1.2198 - mse: 1.6615e-04\n",
      "Epoch 496: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.9419 - bpp: 1.2198 - mse: 1.6615e-04\n",
      "Epoch 497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2764 - bpp: 1.1915 - mse: 1.2725e-04\n",
      "Epoch 497: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2764 - bpp: 1.1915 - mse: 1.2725e-04\n",
      "Epoch 498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3026 - bpp: 1.1825 - mse: 1.2940e-04\n",
      "Epoch 498: loss did not improve from 3.19885\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3026 - bpp: 1.1825 - mse: 1.2940e-04\n",
      "Epoch 499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1532 - bpp: 1.1865 - mse: 1.2004e-04\n",
      "Epoch 499: loss improved from 3.19885 to 3.15324, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.1532 - bpp: 1.1865 - mse: 1.2004e-04\n",
      "Epoch 500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7635 - bpp: 1.2262 - mse: 1.5486e-04\n",
      "Epoch 500: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7635 - bpp: 1.2262 - mse: 1.5486e-04\n",
      "Epoch 501/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.9530 - bpp: 1.2389 - mse: 2.2669e-04\n",
      "Epoch 501: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 4.9530 - bpp: 1.2389 - mse: 2.2669e-04\n",
      "Epoch 502/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9979 - bpp: 1.2381 - mse: 1.6844e-04\n",
      "Epoch 502: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.9979 - bpp: 1.2381 - mse: 1.6844e-04\n",
      "Epoch 503/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8595 - bpp: 1.2452 - mse: 1.5956e-04\n",
      "Epoch 503: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.8595 - bpp: 1.2452 - mse: 1.5956e-04\n",
      "Epoch 504/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5148 - bpp: 1.2021 - mse: 1.4115e-04\n",
      "Epoch 504: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5148 - bpp: 1.2021 - mse: 1.4115e-04\n",
      "Epoch 505/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4259 - bpp: 1.1892 - mse: 1.3652e-04\n",
      "Epoch 505: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4259 - bpp: 1.1892 - mse: 1.3652e-04\n",
      "Epoch 506/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4511 - bpp: 1.1943 - mse: 1.3774e-04\n",
      "Epoch 506: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4511 - bpp: 1.1943 - mse: 1.3774e-04\n",
      "Epoch 507/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3001 - bpp: 1.1916 - mse: 1.2869e-04\n",
      "Epoch 507: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3001 - bpp: 1.1916 - mse: 1.2869e-04\n",
      "Epoch 508/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5504 - bpp: 1.2135 - mse: 1.4263e-04\n",
      "Epoch 508: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.5504 - bpp: 1.2135 - mse: 1.4263e-04\n",
      "Epoch 509/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5778 - bpp: 1.1949 - mse: 1.4544e-04\n",
      "Epoch 509: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.5778 - bpp: 1.1949 - mse: 1.4544e-04\n",
      "Epoch 510/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8558 - bpp: 1.2487 - mse: 1.5912e-04\n",
      "Epoch 510: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.8558 - bpp: 1.2487 - mse: 1.5912e-04\n",
      "Epoch 511/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6731 - bpp: 1.1866 - mse: 1.5176e-04\n",
      "Epoch 511: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.6731 - bpp: 1.1866 - mse: 1.5176e-04\n",
      "Epoch 512/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3443 - bpp: 1.1937 - mse: 1.3126e-04\n",
      "Epoch 512: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3443 - bpp: 1.1937 - mse: 1.3126e-04\n",
      "Epoch 513/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6680 - bpp: 1.1954 - mse: 1.5092e-04\n",
      "Epoch 513: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.6680 - bpp: 1.1954 - mse: 1.5092e-04\n",
      "Epoch 514/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1692 - bpp: 1.1762 - mse: 1.2165e-04\n",
      "Epoch 514: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.1692 - bpp: 1.1762 - mse: 1.2165e-04\n",
      "Epoch 515/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0451 - bpp: 1.2183 - mse: 1.7254e-04\n",
      "Epoch 515: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 4.0451 - bpp: 1.2183 - mse: 1.7254e-04\n",
      "Epoch 516/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6335 - bpp: 1.2326 - mse: 1.4654e-04\n",
      "Epoch 516: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.6335 - bpp: 1.2326 - mse: 1.4654e-04\n",
      "Epoch 517/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5704 - bpp: 1.2150 - mse: 1.4376e-04\n",
      "Epoch 517: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5704 - bpp: 1.2150 - mse: 1.4376e-04\n",
      "Epoch 518/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5643 - bpp: 1.1867 - mse: 1.4512e-04\n",
      "Epoch 518: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5643 - bpp: 1.1867 - mse: 1.4512e-04\n",
      "Epoch 519/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7121 - bpp: 1.2159 - mse: 1.5236e-04\n",
      "Epoch 519: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7121 - bpp: 1.2159 - mse: 1.5236e-04\n",
      "Epoch 520/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4970 - bpp: 1.2033 - mse: 1.4000e-04\n",
      "Epoch 520: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.4970 - bpp: 1.2033 - mse: 1.4000e-04\n",
      "Epoch 521/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6592 - bpp: 1.1848 - mse: 1.5102e-04\n",
      "Epoch 521: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.6592 - bpp: 1.1848 - mse: 1.5102e-04\n",
      "Epoch 522/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 5.1684 - bpp: 1.2289 - mse: 2.4045e-04\n",
      "Epoch 522: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 5.1684 - bpp: 1.2289 - mse: 2.4045e-04\n",
      "Epoch 523/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1745 - bpp: 1.1851 - mse: 1.2142e-04\n",
      "Epoch 523: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.1745 - bpp: 1.1851 - mse: 1.2142e-04\n",
      "Epoch 524/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5585 - bpp: 1.2046 - mse: 1.4367e-04\n",
      "Epoch 524: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5585 - bpp: 1.2046 - mse: 1.4367e-04\n",
      "Epoch 525/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5660 - bpp: 1.2084 - mse: 1.4390e-04\n",
      "Epoch 525: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5660 - bpp: 1.2084 - mse: 1.4390e-04\n",
      "Epoch 526/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4727 - bpp: 1.2014 - mse: 1.3863e-04\n",
      "Epoch 526: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4727 - bpp: 1.2014 - mse: 1.3863e-04\n",
      "Epoch 527/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5086 - bpp: 1.2155 - mse: 1.3996e-04\n",
      "Epoch 527: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5086 - bpp: 1.2155 - mse: 1.3996e-04\n",
      "Epoch 528/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4303 - bpp: 1.2345 - mse: 1.9505e-04\n",
      "Epoch 528: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 4.4303 - bpp: 1.2345 - mse: 1.9505e-04\n",
      "Epoch 529/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5985 - bpp: 1.2066 - mse: 1.4599e-04\n",
      "Epoch 529: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5985 - bpp: 1.2066 - mse: 1.4599e-04\n",
      "Epoch 530/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7819 - bpp: 1.2021 - mse: 1.5746e-04\n",
      "Epoch 530: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.7819 - bpp: 1.2021 - mse: 1.5746e-04\n",
      "Epoch 531/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4584 - bpp: 1.1931 - mse: 1.3826e-04\n",
      "Epoch 531: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4584 - bpp: 1.1931 - mse: 1.3826e-04\n",
      "Epoch 532/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1628 - bpp: 1.1518 - mse: 1.2275e-04\n",
      "Epoch 532: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1628 - bpp: 1.1518 - mse: 1.2275e-04\n",
      "Epoch 533/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2742 - bpp: 1.1764 - mse: 1.2804e-04\n",
      "Epoch 533: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.2742 - bpp: 1.1764 - mse: 1.2804e-04\n",
      "Epoch 534/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4845 - bpp: 1.2076 - mse: 2.0001e-04\n",
      "Epoch 534: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 4.4845 - bpp: 1.2076 - mse: 2.0001e-04\n",
      "Epoch 535/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1660 - bpp: 1.1727 - mse: 1.2166e-04\n",
      "Epoch 535: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.1660 - bpp: 1.1727 - mse: 1.2166e-04\n",
      "Epoch 536/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6783 - bpp: 1.2032 - mse: 1.5107e-04\n",
      "Epoch 536: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.6783 - bpp: 1.2032 - mse: 1.5107e-04\n",
      "Epoch 537/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7672 - bpp: 1.2079 - mse: 1.5621e-04\n",
      "Epoch 537: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.7672 - bpp: 1.2079 - mse: 1.5621e-04\n",
      "Epoch 538/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4558 - bpp: 1.2016 - mse: 1.3758e-04\n",
      "Epoch 538: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.4558 - bpp: 1.2016 - mse: 1.3758e-04\n",
      "Epoch 539/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6754 - bpp: 1.2340 - mse: 1.4901e-04\n",
      "Epoch 539: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 228ms/step - loss: 3.6754 - bpp: 1.2340 - mse: 1.4901e-04\n",
      "Epoch 540/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6673 - bpp: 1.2005 - mse: 1.5056e-04\n",
      "Epoch 540: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6673 - bpp: 1.2005 - mse: 1.5056e-04\n",
      "Epoch 541/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2985 - bpp: 1.1920 - mse: 1.2857e-04\n",
      "Epoch 541: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.2985 - bpp: 1.1920 - mse: 1.2857e-04\n",
      "Epoch 542/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7001 - bpp: 1.2008 - mse: 1.5255e-04\n",
      "Epoch 542: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7001 - bpp: 1.2008 - mse: 1.5255e-04\n",
      "Epoch 543/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6576 - bpp: 1.2045 - mse: 1.4972e-04\n",
      "Epoch 543: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 3.6576 - bpp: 1.2045 - mse: 1.4972e-04\n",
      "Epoch 544/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3994 - bpp: 1.1768 - mse: 1.3566e-04\n",
      "Epoch 544: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.3994 - bpp: 1.1768 - mse: 1.3566e-04\n",
      "Epoch 545/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3621 - bpp: 1.1960 - mse: 1.3221e-04\n",
      "Epoch 545: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.3621 - bpp: 1.1960 - mse: 1.3221e-04\n",
      "Epoch 546/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9297 - bpp: 1.2447 - mse: 1.6388e-04\n",
      "Epoch 546: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.9297 - bpp: 1.2447 - mse: 1.6388e-04\n",
      "Epoch 547/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1883 - bpp: 1.1653 - mse: 1.2347e-04\n",
      "Epoch 547: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 216ms/step - loss: 3.1883 - bpp: 1.1653 - mse: 1.2347e-04\n",
      "Epoch 548/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7427 - bpp: 1.2161 - mse: 1.5421e-04\n",
      "Epoch 548: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7427 - bpp: 1.2161 - mse: 1.5421e-04\n",
      "Epoch 549/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8069 - bpp: 1.2214 - mse: 1.5781e-04\n",
      "Epoch 549: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8069 - bpp: 1.2214 - mse: 1.5781e-04\n",
      "Epoch 550/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4749 - bpp: 1.1866 - mse: 1.3966e-04\n",
      "Epoch 550: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 3.4749 - bpp: 1.1866 - mse: 1.3966e-04\n",
      "Epoch 551/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7247 - bpp: 1.2049 - mse: 1.5379e-04\n",
      "Epoch 551: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 3.7247 - bpp: 1.2049 - mse: 1.5379e-04\n",
      "Epoch 552/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4451 - bpp: 1.1898 - mse: 1.3765e-04\n",
      "Epoch 552: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4451 - bpp: 1.1898 - mse: 1.3765e-04\n",
      "Epoch 553/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6880 - bpp: 1.1841 - mse: 1.5283e-04\n",
      "Epoch 553: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 3.6880 - bpp: 1.1841 - mse: 1.5283e-04\n",
      "Epoch 554/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6836 - bpp: 1.2023 - mse: 1.5145e-04\n",
      "Epoch 554: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 3.6836 - bpp: 1.2023 - mse: 1.5145e-04\n",
      "Epoch 555/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8683 - bpp: 1.2182 - mse: 1.6175e-04\n",
      "Epoch 555: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.8683 - bpp: 1.2182 - mse: 1.6175e-04\n",
      "Epoch 556/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9683 - bpp: 1.2071 - mse: 1.6853e-04\n",
      "Epoch 556: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 221ms/step - loss: 3.9683 - bpp: 1.2071 - mse: 1.6853e-04\n",
      "Epoch 557/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3910 - bpp: 1.1709 - mse: 1.3550e-04\n",
      "Epoch 557: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3910 - bpp: 1.1709 - mse: 1.3550e-04\n",
      "Epoch 558/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2801 - bpp: 1.1824 - mse: 1.2803e-04\n",
      "Epoch 558: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.2801 - bpp: 1.1824 - mse: 1.2803e-04\n",
      "Epoch 559/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4884 - bpp: 1.1812 - mse: 1.4082e-04\n",
      "Epoch 559: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.4884 - bpp: 1.1812 - mse: 1.4082e-04\n",
      "Epoch 560/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7537 - bpp: 1.1985 - mse: 1.5596e-04\n",
      "Epoch 560: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.7537 - bpp: 1.1985 - mse: 1.5596e-04\n",
      "Epoch 561/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7012 - bpp: 1.1879 - mse: 1.5340e-04\n",
      "Epoch 561: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 3.7012 - bpp: 1.1879 - mse: 1.5340e-04\n",
      "Epoch 562/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6113 - bpp: 1.2018 - mse: 1.4707e-04\n",
      "Epoch 562: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.6113 - bpp: 1.2018 - mse: 1.4707e-04\n",
      "Epoch 563/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6008 - bpp: 1.2066 - mse: 1.4613e-04\n",
      "Epoch 563: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.6008 - bpp: 1.2066 - mse: 1.4613e-04\n",
      "Epoch 564/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7269 - bpp: 1.2066 - mse: 1.5382e-04\n",
      "Epoch 564: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.7269 - bpp: 1.2066 - mse: 1.5382e-04\n",
      "Epoch 565/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5306 - bpp: 1.1810 - mse: 1.4341e-04\n",
      "Epoch 565: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 3.5306 - bpp: 1.1810 - mse: 1.4341e-04\n",
      "Epoch 566/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3713 - bpp: 1.2102 - mse: 1.9294e-04\n",
      "Epoch 566: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 4.3713 - bpp: 1.2102 - mse: 1.9294e-04\n",
      "Epoch 567/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6963 - bpp: 1.2145 - mse: 1.5147e-04\n",
      "Epoch 567: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.6963 - bpp: 1.2145 - mse: 1.5147e-04\n",
      "Epoch 568/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2981 - bpp: 1.1771 - mse: 1.2946e-04\n",
      "Epoch 568: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.2981 - bpp: 1.1771 - mse: 1.2946e-04\n",
      "Epoch 569/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6134 - bpp: 1.2017 - mse: 1.4720e-04\n",
      "Epoch 569: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6134 - bpp: 1.2017 - mse: 1.4720e-04\n",
      "Epoch 570/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9052 - bpp: 1.2197 - mse: 1.6391e-04\n",
      "Epoch 570: loss did not improve from 3.15324\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.9052 - bpp: 1.2197 - mse: 1.6391e-04\n",
      "Epoch 571/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1485 - bpp: 1.1704 - mse: 1.2073e-04\n",
      "Epoch 571: loss improved from 3.15324 to 3.14846, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.1485 - bpp: 1.1704 - mse: 1.2073e-04\n",
      "Epoch 572/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3908 - bpp: 1.1838 - mse: 1.3471e-04\n",
      "Epoch 572: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3908 - bpp: 1.1838 - mse: 1.3471e-04\n",
      "Epoch 573/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8286 - bpp: 1.1940 - mse: 1.6080e-04\n",
      "Epoch 573: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.8286 - bpp: 1.1940 - mse: 1.6080e-04\n",
      "Epoch 574/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8898 - bpp: 1.2331 - mse: 1.6215e-04\n",
      "Epoch 574: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.8898 - bpp: 1.2331 - mse: 1.6215e-04\n",
      "Epoch 575/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3498 - bpp: 1.1999 - mse: 1.9226e-04\n",
      "Epoch 575: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 4.3498 - bpp: 1.1999 - mse: 1.9226e-04\n",
      "Epoch 576/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1490 - bpp: 1.1677 - mse: 1.2093e-04\n",
      "Epoch 576: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.1490 - bpp: 1.1677 - mse: 1.2093e-04\n",
      "Epoch 577/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2850 - bpp: 1.1614 - mse: 1.2962e-04\n",
      "Epoch 577: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2850 - bpp: 1.1614 - mse: 1.2962e-04\n",
      "Epoch 578/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5949 - bpp: 1.2170 - mse: 1.4514e-04\n",
      "Epoch 578: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5949 - bpp: 1.2170 - mse: 1.4514e-04\n",
      "Epoch 579/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5586 - bpp: 1.1876 - mse: 1.4471e-04\n",
      "Epoch 579: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.5586 - bpp: 1.1876 - mse: 1.4471e-04\n",
      "Epoch 580/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6840 - bpp: 1.2265 - mse: 1.4999e-04\n",
      "Epoch 580: loss did not improve from 3.14846\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.6840 - bpp: 1.2265 - mse: 1.4999e-04\n",
      "Epoch 581/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9407 - bpp: 1.1639 - mse: 1.0845e-04\n",
      "Epoch 581: loss improved from 3.14846 to 2.94070, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9407 - bpp: 1.1639 - mse: 1.0845e-04\n",
      "Epoch 582/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0006 - bpp: 1.1503 - mse: 1.1294e-04\n",
      "Epoch 582: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 235ms/step - loss: 3.0006 - bpp: 1.1503 - mse: 1.1294e-04\n",
      "Epoch 583/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1211 - bpp: 1.1661 - mse: 1.1932e-04\n",
      "Epoch 583: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1211 - bpp: 1.1661 - mse: 1.1932e-04\n",
      "Epoch 584/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4167 - bpp: 1.2095 - mse: 1.3472e-04\n",
      "Epoch 584: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.4167 - bpp: 1.2095 - mse: 1.3472e-04\n",
      "Epoch 585/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2801 - bpp: 1.1744 - mse: 1.2852e-04\n",
      "Epoch 585: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.2801 - bpp: 1.1744 - mse: 1.2852e-04\n",
      "Epoch 586/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3443 - bpp: 1.1775 - mse: 1.3225e-04\n",
      "Epoch 586: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3443 - bpp: 1.1775 - mse: 1.3225e-04\n",
      "Epoch 587/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9986 - bpp: 1.2187 - mse: 1.6967e-04\n",
      "Epoch 587: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.9986 - bpp: 1.2187 - mse: 1.6967e-04\n",
      "Epoch 588/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7386 - bpp: 1.2006 - mse: 1.5491e-04\n",
      "Epoch 588: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.7386 - bpp: 1.2006 - mse: 1.5491e-04\n",
      "Epoch 589/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7106 - bpp: 1.1858 - mse: 1.5410e-04\n",
      "Epoch 589: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 234ms/step - loss: 3.7106 - bpp: 1.1858 - mse: 1.5410e-04\n",
      "Epoch 590/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3819 - bpp: 1.2091 - mse: 1.3262e-04\n",
      "Epoch 590: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.3819 - bpp: 1.2091 - mse: 1.3262e-04\n",
      "Epoch 591/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8905 - bpp: 1.2287 - mse: 1.6247e-04\n",
      "Epoch 591: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.8905 - bpp: 1.2287 - mse: 1.6247e-04\n",
      "Epoch 592/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9720 - bpp: 1.1951 - mse: 1.6949e-04\n",
      "Epoch 592: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.9720 - bpp: 1.1951 - mse: 1.6949e-04\n",
      "Epoch 593/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.1775 - bpp: 1.1944 - mse: 1.8207e-04\n",
      "Epoch 593: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 4.1775 - bpp: 1.1944 - mse: 1.8207e-04\n",
      "Epoch 594/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4386 - bpp: 1.1992 - mse: 1.3668e-04\n",
      "Epoch 594: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.4386 - bpp: 1.1992 - mse: 1.3668e-04\n",
      "Epoch 595/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8266 - bpp: 1.1983 - mse: 1.6042e-04\n",
      "Epoch 595: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.8266 - bpp: 1.1983 - mse: 1.6042e-04\n",
      "Epoch 596/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6637 - bpp: 1.1875 - mse: 1.5113e-04\n",
      "Epoch 596: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.6637 - bpp: 1.1875 - mse: 1.5113e-04\n",
      "Epoch 597/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7383 - bpp: 1.1804 - mse: 1.5612e-04\n",
      "Epoch 597: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.7383 - bpp: 1.1804 - mse: 1.5612e-04\n",
      "Epoch 598/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3425 - bpp: 1.1647 - mse: 1.3292e-04\n",
      "Epoch 598: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.3425 - bpp: 1.1647 - mse: 1.3292e-04\n",
      "Epoch 599/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7245 - bpp: 1.2047 - mse: 1.5379e-04\n",
      "Epoch 599: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.7245 - bpp: 1.2047 - mse: 1.5379e-04\n",
      "Epoch 600/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3627 - bpp: 1.1767 - mse: 1.3342e-04\n",
      "Epoch 600: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.3627 - bpp: 1.1767 - mse: 1.3342e-04\n",
      "Epoch 601/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2335 - bpp: 1.1633 - mse: 1.2636e-04\n",
      "Epoch 601: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.2335 - bpp: 1.1633 - mse: 1.2636e-04\n",
      "Epoch 602/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8914 - bpp: 1.2056 - mse: 1.6393e-04\n",
      "Epoch 602: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.8914 - bpp: 1.2056 - mse: 1.6393e-04\n",
      "Epoch 603/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5778 - bpp: 1.1980 - mse: 1.4525e-04\n",
      "Epoch 603: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.5778 - bpp: 1.1980 - mse: 1.4525e-04\n",
      "Epoch 604/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0348 - bpp: 1.1996 - mse: 1.7305e-04\n",
      "Epoch 604: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 4.0348 - bpp: 1.1996 - mse: 1.7305e-04\n",
      "Epoch 605/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3615 - bpp: 1.1682 - mse: 1.3387e-04\n",
      "Epoch 605: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3615 - bpp: 1.1682 - mse: 1.3387e-04\n",
      "Epoch 606/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2424 - bpp: 1.1613 - mse: 1.2702e-04\n",
      "Epoch 606: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.2424 - bpp: 1.1613 - mse: 1.2702e-04\n",
      "Epoch 607/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6449 - bpp: 1.2018 - mse: 1.4912e-04\n",
      "Epoch 607: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.6449 - bpp: 1.2018 - mse: 1.4912e-04\n",
      "Epoch 608/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8773 - bpp: 1.2146 - mse: 1.6251e-04\n",
      "Epoch 608: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.8773 - bpp: 1.2146 - mse: 1.6251e-04\n",
      "Epoch 609/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5834 - bpp: 1.1981 - mse: 1.4559e-04\n",
      "Epoch 609: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.5834 - bpp: 1.1981 - mse: 1.4559e-04\n",
      "Epoch 610/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4810 - bpp: 1.1949 - mse: 1.3953e-04\n",
      "Epoch 610: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.4810 - bpp: 1.1949 - mse: 1.3953e-04\n",
      "Epoch 611/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4241 - bpp: 1.2008 - mse: 1.3570e-04\n",
      "Epoch 611: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.4241 - bpp: 1.2008 - mse: 1.3570e-04\n",
      "Epoch 612/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5022 - bpp: 1.1843 - mse: 1.4148e-04\n",
      "Epoch 612: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.5022 - bpp: 1.1843 - mse: 1.4148e-04\n",
      "Epoch 613/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9421 - bpp: 1.1770 - mse: 1.6877e-04\n",
      "Epoch 613: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.9421 - bpp: 1.1770 - mse: 1.6877e-04\n",
      "Epoch 614/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3529 - bpp: 1.1822 - mse: 1.3249e-04\n",
      "Epoch 614: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.3529 - bpp: 1.1822 - mse: 1.3249e-04\n",
      "Epoch 615/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6441 - bpp: 1.1853 - mse: 1.5007e-04\n",
      "Epoch 615: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.6441 - bpp: 1.1853 - mse: 1.5007e-04\n",
      "Epoch 616/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1485 - bpp: 1.1406 - mse: 1.2255e-04\n",
      "Epoch 616: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1485 - bpp: 1.1406 - mse: 1.2255e-04\n",
      "Epoch 617/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4354 - bpp: 1.1798 - mse: 1.3767e-04\n",
      "Epoch 617: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.4354 - bpp: 1.1798 - mse: 1.3767e-04\n",
      "Epoch 618/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3130 - bpp: 1.1728 - mse: 1.3063e-04\n",
      "Epoch 618: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3.3130 - bpp: 1.1728 - mse: 1.3063e-04\n",
      "Epoch 619/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6503 - bpp: 1.1869 - mse: 1.5036e-04\n",
      "Epoch 619: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6503 - bpp: 1.1869 - mse: 1.5036e-04\n",
      "Epoch 620/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5203 - bpp: 1.2003 - mse: 1.4160e-04\n",
      "Epoch 620: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.5203 - bpp: 1.2003 - mse: 1.4160e-04\n",
      "Epoch 621/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8519 - bpp: 1.2137 - mse: 1.6102e-04\n",
      "Epoch 621: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.8519 - bpp: 1.2137 - mse: 1.6102e-04\n",
      "Epoch 622/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4872 - bpp: 1.1740 - mse: 1.4119e-04\n",
      "Epoch 622: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.4872 - bpp: 1.1740 - mse: 1.4119e-04\n",
      "Epoch 623/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1091 - bpp: 1.1541 - mse: 1.1932e-04\n",
      "Epoch 623: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.1091 - bpp: 1.1541 - mse: 1.1932e-04\n",
      "Epoch 624/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2489 - bpp: 1.1709 - mse: 1.2683e-04\n",
      "Epoch 624: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2489 - bpp: 1.1709 - mse: 1.2683e-04\n",
      "Epoch 625/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9458 - bpp: 1.2019 - mse: 1.6748e-04\n",
      "Epoch 625: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.9458 - bpp: 1.2019 - mse: 1.6748e-04\n",
      "Epoch 626/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0789 - bpp: 1.1401 - mse: 1.1834e-04\n",
      "Epoch 626: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0789 - bpp: 1.1401 - mse: 1.1834e-04\n",
      "Epoch 627/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8376 - bpp: 1.2051 - mse: 1.6068e-04\n",
      "Epoch 627: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.8376 - bpp: 1.2051 - mse: 1.6068e-04\n",
      "Epoch 628/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7753 - bpp: 1.2103 - mse: 1.5655e-04\n",
      "Epoch 628: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.7753 - bpp: 1.2103 - mse: 1.5655e-04\n",
      "Epoch 629/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1436 - bpp: 1.1491 - mse: 1.2174e-04\n",
      "Epoch 629: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.1436 - bpp: 1.1491 - mse: 1.2174e-04\n",
      "Epoch 630/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7667 - bpp: 1.1818 - mse: 1.5777e-04\n",
      "Epoch 630: loss did not improve from 2.94070\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.7667 - bpp: 1.1818 - mse: 1.5777e-04\n",
      "Epoch 631/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9040 - bpp: 1.1384 - mse: 1.0776e-04\n",
      "Epoch 631: loss improved from 2.94070 to 2.90399, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9040 - bpp: 1.1384 - mse: 1.0776e-04\n",
      "Epoch 632/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0621 - bpp: 1.1460 - mse: 1.1695e-04\n",
      "Epoch 632: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.0621 - bpp: 1.1460 - mse: 1.1695e-04\n",
      "Epoch 633/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3461 - bpp: 1.1746 - mse: 1.3253e-04\n",
      "Epoch 633: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.3461 - bpp: 1.1746 - mse: 1.3253e-04\n",
      "Epoch 634/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7881 - bpp: 1.1987 - mse: 1.5804e-04\n",
      "Epoch 634: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.7881 - bpp: 1.1987 - mse: 1.5804e-04\n",
      "Epoch 635/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4186 - bpp: 1.1913 - mse: 1.3594e-04\n",
      "Epoch 635: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.4186 - bpp: 1.1913 - mse: 1.3594e-04\n",
      "Epoch 636/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3452 - bpp: 1.1758 - mse: 1.3241e-04\n",
      "Epoch 636: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.3452 - bpp: 1.1758 - mse: 1.3241e-04\n",
      "Epoch 637/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2390 - bpp: 1.1506 - mse: 1.2747e-04\n",
      "Epoch 637: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.2390 - bpp: 1.1506 - mse: 1.2747e-04\n",
      "Epoch 638/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3393 - bpp: 1.1783 - mse: 1.3190e-04\n",
      "Epoch 638: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 3.3393 - bpp: 1.1783 - mse: 1.3190e-04\n",
      "Epoch 639/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4675 - bpp: 1.1658 - mse: 1.4049e-04\n",
      "Epoch 639: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4675 - bpp: 1.1658 - mse: 1.4049e-04\n",
      "Epoch 640/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6208 - bpp: 1.2021 - mse: 1.4763e-04\n",
      "Epoch 640: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.6208 - bpp: 1.2021 - mse: 1.4763e-04\n",
      "Epoch 641/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.3804 - bpp: 1.1822 - mse: 1.9520e-04\n",
      "Epoch 641: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.3804 - bpp: 1.1822 - mse: 1.9520e-04\n",
      "Epoch 642/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4874 - bpp: 1.1739 - mse: 1.4120e-04\n",
      "Epoch 642: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.4874 - bpp: 1.1739 - mse: 1.4120e-04\n",
      "Epoch 643/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0801 - bpp: 1.1522 - mse: 1.1767e-04\n",
      "Epoch 643: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 3.0801 - bpp: 1.1522 - mse: 1.1767e-04\n",
      "Epoch 644/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1770 - bpp: 1.1585 - mse: 1.2320e-04\n",
      "Epoch 644: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.1770 - bpp: 1.1585 - mse: 1.2320e-04\n",
      "Epoch 645/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6446 - bpp: 1.1676 - mse: 1.5119e-04\n",
      "Epoch 645: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 226ms/step - loss: 3.6446 - bpp: 1.1676 - mse: 1.5119e-04\n",
      "Epoch 646/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4827 - bpp: 1.1995 - mse: 1.3936e-04\n",
      "Epoch 646: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.4827 - bpp: 1.1995 - mse: 1.3936e-04\n",
      "Epoch 647/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4625 - bpp: 1.1727 - mse: 1.3976e-04\n",
      "Epoch 647: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4625 - bpp: 1.1727 - mse: 1.3976e-04\n",
      "Epoch 648/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3355 - bpp: 1.1744 - mse: 1.3190e-04\n",
      "Epoch 648: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3355 - bpp: 1.1744 - mse: 1.3190e-04\n",
      "Epoch 649/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1858 - bpp: 1.1564 - mse: 1.2387e-04\n",
      "Epoch 649: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.1858 - bpp: 1.1564 - mse: 1.2387e-04\n",
      "Epoch 650/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.4132 - bpp: 1.2115 - mse: 1.9542e-04\n",
      "Epoch 650: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 4.4132 - bpp: 1.2115 - mse: 1.9542e-04\n",
      "Epoch 651/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.9818 - bpp: 1.2083 - mse: 1.6928e-04\n",
      "Epoch 651: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 45s 222ms/step - loss: 3.9818 - bpp: 1.2083 - mse: 1.6928e-04\n",
      "Epoch 652/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6966 - bpp: 1.1983 - mse: 1.5248e-04\n",
      "Epoch 652: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.6966 - bpp: 1.1983 - mse: 1.5248e-04\n",
      "Epoch 653/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6421 - bpp: 1.1928 - mse: 1.4950e-04\n",
      "Epoch 653: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.6421 - bpp: 1.1928 - mse: 1.4950e-04\n",
      "Epoch 654/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5632 - bpp: 1.2075 - mse: 1.4378e-04\n",
      "Epoch 654: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.5632 - bpp: 1.2075 - mse: 1.4378e-04\n",
      "Epoch 655/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2218 - bpp: 1.1595 - mse: 1.2587e-04\n",
      "Epoch 655: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2218 - bpp: 1.1595 - mse: 1.2587e-04\n",
      "Epoch 656/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3107 - bpp: 1.1840 - mse: 1.2980e-04\n",
      "Epoch 656: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3107 - bpp: 1.1840 - mse: 1.2980e-04\n",
      "Epoch 657/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2422 - bpp: 1.1575 - mse: 1.2724e-04\n",
      "Epoch 657: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.2422 - bpp: 1.1575 - mse: 1.2724e-04\n",
      "Epoch 658/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0392 - bpp: 1.1494 - mse: 1.1535e-04\n",
      "Epoch 658: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.0392 - bpp: 1.1494 - mse: 1.1535e-04\n",
      "Epoch 659/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1552 - bpp: 1.1496 - mse: 1.2241e-04\n",
      "Epoch 659: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.1552 - bpp: 1.1496 - mse: 1.2241e-04\n",
      "Epoch 660/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2692 - bpp: 1.1698 - mse: 1.2814e-04\n",
      "Epoch 660: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2692 - bpp: 1.1698 - mse: 1.2814e-04\n",
      "Epoch 661/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4150 - bpp: 1.1878 - mse: 1.3593e-04\n",
      "Epoch 661: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 3.4150 - bpp: 1.1878 - mse: 1.3593e-04\n",
      "Epoch 662/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3176 - bpp: 1.1900 - mse: 1.2986e-04\n",
      "Epoch 662: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3176 - bpp: 1.1900 - mse: 1.2986e-04\n",
      "Epoch 663/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3438 - bpp: 1.1778 - mse: 1.3220e-04\n",
      "Epoch 663: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.3438 - bpp: 1.1778 - mse: 1.3220e-04\n",
      "Epoch 664/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2699 - bpp: 1.1693 - mse: 1.2821e-04\n",
      "Epoch 664: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.2699 - bpp: 1.1693 - mse: 1.2821e-04\n",
      "Epoch 665/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7279 - bpp: 1.2049 - mse: 1.5399e-04\n",
      "Epoch 665: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.7279 - bpp: 1.2049 - mse: 1.5399e-04\n",
      "Epoch 666/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4107 - bpp: 1.1838 - mse: 1.3592e-04\n",
      "Epoch 666: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4107 - bpp: 1.1838 - mse: 1.3592e-04\n",
      "Epoch 667/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5820 - bpp: 1.1739 - mse: 1.4698e-04\n",
      "Epoch 667: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 3.5820 - bpp: 1.1739 - mse: 1.4698e-04\n",
      "Epoch 668/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6609 - bpp: 1.2024 - mse: 1.5006e-04\n",
      "Epoch 668: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 226ms/step - loss: 3.6609 - bpp: 1.2024 - mse: 1.5006e-04\n",
      "Epoch 669/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3265 - bpp: 1.1590 - mse: 1.3229e-04\n",
      "Epoch 669: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 3.3265 - bpp: 1.1590 - mse: 1.3229e-04\n",
      "Epoch 670/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3828 - bpp: 1.1792 - mse: 1.3449e-04\n",
      "Epoch 670: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3828 - bpp: 1.1792 - mse: 1.3449e-04\n",
      "Epoch 671/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2269 - bpp: 1.1558 - mse: 1.2641e-04\n",
      "Epoch 671: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.2269 - bpp: 1.1558 - mse: 1.2641e-04\n",
      "Epoch 672/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3177 - bpp: 1.1557 - mse: 1.3196e-04\n",
      "Epoch 672: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3177 - bpp: 1.1557 - mse: 1.3196e-04\n",
      "Epoch 673/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2980 - bpp: 1.1549 - mse: 1.3081e-04\n",
      "Epoch 673: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.2980 - bpp: 1.1549 - mse: 1.3081e-04\n",
      "Epoch 674/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3075 - bpp: 1.1873 - mse: 1.2941e-04\n",
      "Epoch 674: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.3075 - bpp: 1.1873 - mse: 1.2941e-04\n",
      "Epoch 675/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5112 - bpp: 1.1877 - mse: 1.4182e-04\n",
      "Epoch 675: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.5112 - bpp: 1.1877 - mse: 1.4182e-04\n",
      "Epoch 676/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0118 - bpp: 1.1701 - mse: 1.1241e-04\n",
      "Epoch 676: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0118 - bpp: 1.1701 - mse: 1.1241e-04\n",
      "Epoch 677/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3127 - bpp: 1.1543 - mse: 1.3174e-04\n",
      "Epoch 677: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3127 - bpp: 1.1543 - mse: 1.3174e-04\n",
      "Epoch 678/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3345 - bpp: 1.1865 - mse: 1.3110e-04\n",
      "Epoch 678: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.3345 - bpp: 1.1865 - mse: 1.3110e-04\n",
      "Epoch 679/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3931 - bpp: 1.1688 - mse: 1.3576e-04\n",
      "Epoch 679: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.3931 - bpp: 1.1688 - mse: 1.3576e-04\n",
      "Epoch 680/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4547 - bpp: 1.1781 - mse: 1.3895e-04\n",
      "Epoch 680: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.4547 - bpp: 1.1781 - mse: 1.3895e-04\n",
      "Epoch 681/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4301 - bpp: 1.1570 - mse: 1.3874e-04\n",
      "Epoch 681: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.4301 - bpp: 1.1570 - mse: 1.3874e-04\n",
      "Epoch 682/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.0069 - bpp: 1.2107 - mse: 1.7067e-04\n",
      "Epoch 682: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 4.0069 - bpp: 1.2107 - mse: 1.7067e-04\n",
      "Epoch 683/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0726 - bpp: 1.1425 - mse: 1.1780e-04\n",
      "Epoch 683: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0726 - bpp: 1.1425 - mse: 1.1780e-04\n",
      "Epoch 684/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4655 - bpp: 1.1766 - mse: 1.3971e-04\n",
      "Epoch 684: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.4655 - bpp: 1.1766 - mse: 1.3971e-04\n",
      "Epoch 685/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3519 - bpp: 1.1776 - mse: 1.3271e-04\n",
      "Epoch 685: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.3519 - bpp: 1.1776 - mse: 1.3271e-04\n",
      "Epoch 686/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1417 - bpp: 1.1624 - mse: 1.2081e-04\n",
      "Epoch 686: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.1417 - bpp: 1.1624 - mse: 1.2081e-04\n",
      "Epoch 687/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0055 - bpp: 1.1383 - mse: 1.1396e-04\n",
      "Epoch 687: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0055 - bpp: 1.1383 - mse: 1.1396e-04\n",
      "Epoch 688/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1467 - bpp: 1.1329 - mse: 1.2291e-04\n",
      "Epoch 688: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1467 - bpp: 1.1329 - mse: 1.2291e-04\n",
      "Epoch 689/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3641 - bpp: 1.1776 - mse: 1.3345e-04\n",
      "Epoch 689: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.3641 - bpp: 1.1776 - mse: 1.3345e-04\n",
      "Epoch 690/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5125 - bpp: 1.1637 - mse: 1.4336e-04\n",
      "Epoch 690: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.5125 - bpp: 1.1637 - mse: 1.4336e-04\n",
      "Epoch 691/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2832 - bpp: 1.1655 - mse: 1.2925e-04\n",
      "Epoch 691: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.2832 - bpp: 1.1655 - mse: 1.2925e-04\n",
      "Epoch 692/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3771 - bpp: 1.1549 - mse: 1.3564e-04\n",
      "Epoch 692: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.3771 - bpp: 1.1549 - mse: 1.3564e-04\n",
      "Epoch 693/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2361 - bpp: 1.1417 - mse: 1.2783e-04\n",
      "Epoch 693: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2361 - bpp: 1.1417 - mse: 1.2783e-04\n",
      "Epoch 694/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5756 - bpp: 1.1829 - mse: 1.4604e-04\n",
      "Epoch 694: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.5756 - bpp: 1.1829 - mse: 1.4604e-04\n",
      "Epoch 695/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5709 - bpp: 1.1744 - mse: 1.4627e-04\n",
      "Epoch 695: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5709 - bpp: 1.1744 - mse: 1.4627e-04\n",
      "Epoch 696/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5135 - bpp: 1.1885 - mse: 1.4191e-04\n",
      "Epoch 696: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.5135 - bpp: 1.1885 - mse: 1.4191e-04\n",
      "Epoch 697/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1428 - bpp: 1.1553 - mse: 1.2131e-04\n",
      "Epoch 697: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.1428 - bpp: 1.1553 - mse: 1.2131e-04\n",
      "Epoch 698/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3410 - bpp: 1.1735 - mse: 1.3229e-04\n",
      "Epoch 698: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3410 - bpp: 1.1735 - mse: 1.3229e-04\n",
      "Epoch 699/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4040 - bpp: 1.1526 - mse: 1.3742e-04\n",
      "Epoch 699: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.4040 - bpp: 1.1526 - mse: 1.3742e-04\n",
      "Epoch 700/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3479 - bpp: 1.1761 - mse: 1.3255e-04\n",
      "Epoch 700: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3479 - bpp: 1.1761 - mse: 1.3255e-04\n",
      "Epoch 701/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2763 - bpp: 1.1516 - mse: 1.2969e-04\n",
      "Epoch 701: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.2763 - bpp: 1.1516 - mse: 1.2969e-04\n",
      "Epoch 702/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3890 - bpp: 1.1675 - mse: 1.3559e-04\n",
      "Epoch 702: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3890 - bpp: 1.1675 - mse: 1.3559e-04\n",
      "Epoch 703/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2786 - bpp: 1.1695 - mse: 1.2872e-04\n",
      "Epoch 703: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.2786 - bpp: 1.1695 - mse: 1.2872e-04\n",
      "Epoch 704/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2001 - bpp: 1.1645 - mse: 1.2425e-04\n",
      "Epoch 704: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 243ms/step - loss: 3.2001 - bpp: 1.1645 - mse: 1.2425e-04\n",
      "Epoch 705/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2548 - bpp: 1.1715 - mse: 1.2715e-04\n",
      "Epoch 705: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.2548 - bpp: 1.1715 - mse: 1.2715e-04\n",
      "Epoch 706/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3522 - bpp: 1.1765 - mse: 1.3279e-04\n",
      "Epoch 706: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.3522 - bpp: 1.1765 - mse: 1.3279e-04\n",
      "Epoch 707/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3218 - bpp: 1.1678 - mse: 1.3147e-04\n",
      "Epoch 707: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.3218 - bpp: 1.1678 - mse: 1.3147e-04\n",
      "Epoch 708/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4951 - bpp: 1.1581 - mse: 1.4264e-04\n",
      "Epoch 708: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.4951 - bpp: 1.1581 - mse: 1.4264e-04\n",
      "Epoch 709/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3957 - bpp: 1.1703 - mse: 1.3582e-04\n",
      "Epoch 709: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.3957 - bpp: 1.1703 - mse: 1.3582e-04\n",
      "Epoch 710/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3088 - bpp: 1.1714 - mse: 1.3046e-04\n",
      "Epoch 710: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3088 - bpp: 1.1714 - mse: 1.3046e-04\n",
      "Epoch 711/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.8041 - bpp: 1.1521 - mse: 1.6186e-04\n",
      "Epoch 711: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.8041 - bpp: 1.1521 - mse: 1.6186e-04\n",
      "Epoch 712/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1698 - bpp: 1.1577 - mse: 1.2281e-04\n",
      "Epoch 712: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1698 - bpp: 1.1577 - mse: 1.2281e-04\n",
      "Epoch 713/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0428 - bpp: 1.1232 - mse: 1.1717e-04\n",
      "Epoch 713: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0428 - bpp: 1.1232 - mse: 1.1717e-04\n",
      "Epoch 714/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3472 - bpp: 1.1924 - mse: 1.3152e-04\n",
      "Epoch 714: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3472 - bpp: 1.1924 - mse: 1.3152e-04\n",
      "Epoch 715/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1614 - bpp: 1.1285 - mse: 1.2408e-04\n",
      "Epoch 715: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.1614 - bpp: 1.1285 - mse: 1.2408e-04\n",
      "Epoch 716/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1755 - bpp: 1.1488 - mse: 1.2370e-04\n",
      "Epoch 716: loss did not improve from 2.90399\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.1755 - bpp: 1.1488 - mse: 1.2370e-04\n",
      "Epoch 717/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8025 - bpp: 1.1336 - mse: 1.0186e-04\n",
      "Epoch 717: loss improved from 2.90399 to 2.80251, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.8025 - bpp: 1.1336 - mse: 1.0186e-04\n",
      "Epoch 718/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3264 - bpp: 1.1709 - mse: 1.3156e-04\n",
      "Epoch 718: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3264 - bpp: 1.1709 - mse: 1.3156e-04\n",
      "Epoch 719/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3709 - bpp: 1.1714 - mse: 1.3425e-04\n",
      "Epoch 719: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3709 - bpp: 1.1714 - mse: 1.3425e-04\n",
      "Epoch 720/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5359 - bpp: 1.1993 - mse: 1.4261e-04\n",
      "Epoch 720: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5359 - bpp: 1.1993 - mse: 1.4261e-04\n",
      "Epoch 721/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2543 - bpp: 1.1545 - mse: 1.2817e-04\n",
      "Epoch 721: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2543 - bpp: 1.1545 - mse: 1.2817e-04\n",
      "Epoch 722/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9124 - bpp: 1.1294 - mse: 1.0882e-04\n",
      "Epoch 722: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9124 - bpp: 1.1294 - mse: 1.0882e-04\n",
      "Epoch 723/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4108 - bpp: 1.1707 - mse: 1.3672e-04\n",
      "Epoch 723: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.4108 - bpp: 1.1707 - mse: 1.3672e-04\n",
      "Epoch 724/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1332 - bpp: 1.1369 - mse: 1.2184e-04\n",
      "Epoch 724: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1332 - bpp: 1.1369 - mse: 1.2184e-04\n",
      "Epoch 725/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2840 - bpp: 1.1512 - mse: 1.3018e-04\n",
      "Epoch 725: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 3.2840 - bpp: 1.1512 - mse: 1.3018e-04\n",
      "Epoch 726/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0665 - bpp: 1.1348 - mse: 1.1790e-04\n",
      "Epoch 726: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.0665 - bpp: 1.1348 - mse: 1.1790e-04\n",
      "Epoch 727/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4323 - bpp: 1.1678 - mse: 1.3821e-04\n",
      "Epoch 727: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4323 - bpp: 1.1678 - mse: 1.3821e-04\n",
      "Epoch 728/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1255 - bpp: 1.1395 - mse: 1.2122e-04\n",
      "Epoch 728: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1255 - bpp: 1.1395 - mse: 1.2122e-04\n",
      "Epoch 729/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5386 - bpp: 1.1537 - mse: 1.4556e-04\n",
      "Epoch 729: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.5386 - bpp: 1.1537 - mse: 1.4556e-04\n",
      "Epoch 730/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2062 - bpp: 1.1601 - mse: 1.2488e-04\n",
      "Epoch 730: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2062 - bpp: 1.1601 - mse: 1.2488e-04\n",
      "Epoch 731/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2391 - bpp: 1.1463 - mse: 1.2774e-04\n",
      "Epoch 731: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2391 - bpp: 1.1463 - mse: 1.2774e-04\n",
      "Epoch 732/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8994 - bpp: 1.1306 - mse: 1.0796e-04\n",
      "Epoch 732: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8994 - bpp: 1.1306 - mse: 1.0796e-04\n",
      "Epoch 733/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4550 - bpp: 1.1845 - mse: 1.3858e-04\n",
      "Epoch 733: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 3.4550 - bpp: 1.1845 - mse: 1.3858e-04\n",
      "Epoch 734/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2954 - bpp: 1.1673 - mse: 1.2989e-04\n",
      "Epoch 734: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2954 - bpp: 1.1673 - mse: 1.2989e-04\n",
      "Epoch 735/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1940 - bpp: 1.1454 - mse: 1.2504e-04\n",
      "Epoch 735: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1940 - bpp: 1.1454 - mse: 1.2504e-04\n",
      "Epoch 736/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3683 - bpp: 1.1647 - mse: 1.3450e-04\n",
      "Epoch 736: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3683 - bpp: 1.1647 - mse: 1.3450e-04\n",
      "Epoch 737/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4314 - bpp: 1.1550 - mse: 1.3894e-04\n",
      "Epoch 737: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 3.4314 - bpp: 1.1550 - mse: 1.3894e-04\n",
      "Epoch 738/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6426 - bpp: 1.1935 - mse: 1.4948e-04\n",
      "Epoch 738: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.6426 - bpp: 1.1935 - mse: 1.4948e-04\n",
      "Epoch 739/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0736 - bpp: 1.1430 - mse: 1.1783e-04\n",
      "Epoch 739: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 3.0736 - bpp: 1.1430 - mse: 1.1783e-04\n",
      "Epoch 740/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0538 - bpp: 1.1363 - mse: 1.1704e-04\n",
      "Epoch 740: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 3.0538 - bpp: 1.1363 - mse: 1.1704e-04\n",
      "Epoch 741/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9608 - bpp: 1.1497 - mse: 1.1054e-04\n",
      "Epoch 741: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 2.9608 - bpp: 1.1497 - mse: 1.1054e-04\n",
      "Epoch 742/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4636 - bpp: 1.1464 - mse: 1.4144e-04\n",
      "Epoch 742: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4636 - bpp: 1.1464 - mse: 1.4144e-04\n",
      "Epoch 743/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5061 - bpp: 1.1478 - mse: 1.4394e-04\n",
      "Epoch 743: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.5061 - bpp: 1.1478 - mse: 1.4394e-04\n",
      "Epoch 744/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3482 - bpp: 1.1535 - mse: 1.3395e-04\n",
      "Epoch 744: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.3482 - bpp: 1.1535 - mse: 1.3395e-04\n",
      "Epoch 745/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5808 - bpp: 1.1626 - mse: 1.4760e-04\n",
      "Epoch 745: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.5808 - bpp: 1.1626 - mse: 1.4760e-04\n",
      "Epoch 746/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3962 - bpp: 1.1495 - mse: 1.3713e-04\n",
      "Epoch 746: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3962 - bpp: 1.1495 - mse: 1.3713e-04\n",
      "Epoch 747/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0740 - bpp: 1.1527 - mse: 1.1727e-04\n",
      "Epoch 747: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0740 - bpp: 1.1527 - mse: 1.1727e-04\n",
      "Epoch 748/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1558 - bpp: 1.1511 - mse: 1.2236e-04\n",
      "Epoch 748: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1558 - bpp: 1.1511 - mse: 1.2236e-04\n",
      "Epoch 749/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2976 - bpp: 1.1643 - mse: 1.3021e-04\n",
      "Epoch 749: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.2976 - bpp: 1.1643 - mse: 1.3021e-04\n",
      "Epoch 750/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2699 - bpp: 1.1588 - mse: 1.2886e-04\n",
      "Epoch 750: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.2699 - bpp: 1.1588 - mse: 1.2886e-04\n",
      "Epoch 751/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3329 - bpp: 1.1472 - mse: 1.3340e-04\n",
      "Epoch 751: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3329 - bpp: 1.1472 - mse: 1.3340e-04\n",
      "Epoch 752/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1337 - bpp: 1.1567 - mse: 1.2067e-04\n",
      "Epoch 752: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1337 - bpp: 1.1567 - mse: 1.2067e-04\n",
      "Epoch 753/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1398 - bpp: 1.1270 - mse: 1.2285e-04\n",
      "Epoch 753: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1398 - bpp: 1.1270 - mse: 1.2285e-04\n",
      "Epoch 754/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1450 - bpp: 1.1354 - mse: 1.2266e-04\n",
      "Epoch 754: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1450 - bpp: 1.1354 - mse: 1.2266e-04\n",
      "Epoch 755/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3236 - bpp: 1.1763 - mse: 1.3106e-04\n",
      "Epoch 755: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3236 - bpp: 1.1763 - mse: 1.3106e-04\n",
      "Epoch 756/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1770 - bpp: 1.1754 - mse: 1.2217e-04\n",
      "Epoch 756: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1770 - bpp: 1.1754 - mse: 1.2217e-04\n",
      "Epoch 757/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4219 - bpp: 1.1894 - mse: 1.3626e-04\n",
      "Epoch 757: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.4219 - bpp: 1.1894 - mse: 1.3626e-04\n",
      "Epoch 758/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0675 - bpp: 1.1485 - mse: 1.1713e-04\n",
      "Epoch 758: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0675 - bpp: 1.1485 - mse: 1.1713e-04\n",
      "Epoch 759/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5298 - bpp: 1.1780 - mse: 1.4355e-04\n",
      "Epoch 759: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.5298 - bpp: 1.1780 - mse: 1.4355e-04\n",
      "Epoch 760/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5151 - bpp: 1.1449 - mse: 1.4467e-04\n",
      "Epoch 760: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.5151 - bpp: 1.1449 - mse: 1.4467e-04\n",
      "Epoch 761/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3590 - bpp: 1.1586 - mse: 1.3430e-04\n",
      "Epoch 761: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.3590 - bpp: 1.1586 - mse: 1.3430e-04\n",
      "Epoch 762/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1580 - bpp: 1.1285 - mse: 1.2387e-04\n",
      "Epoch 762: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1580 - bpp: 1.1285 - mse: 1.2387e-04\n",
      "Epoch 763/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1312 - bpp: 1.1422 - mse: 1.2140e-04\n",
      "Epoch 763: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1312 - bpp: 1.1422 - mse: 1.2140e-04\n",
      "Epoch 764/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4697 - bpp: 1.1703 - mse: 1.4034e-04\n",
      "Epoch 764: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.4697 - bpp: 1.1703 - mse: 1.4034e-04\n",
      "Epoch 765/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2565 - bpp: 1.1427 - mse: 1.2902e-04\n",
      "Epoch 765: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.2565 - bpp: 1.1427 - mse: 1.2902e-04\n",
      "Epoch 766/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7993 - bpp: 1.1941 - mse: 1.5901e-04\n",
      "Epoch 766: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.7993 - bpp: 1.1941 - mse: 1.5901e-04\n",
      "Epoch 767/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4892 - bpp: 1.1663 - mse: 1.4178e-04\n",
      "Epoch 767: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.4892 - bpp: 1.1663 - mse: 1.4178e-04\n",
      "Epoch 768/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2506 - bpp: 1.1345 - mse: 1.2916e-04\n",
      "Epoch 768: loss did not improve from 2.80251\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2506 - bpp: 1.1345 - mse: 1.2916e-04\n",
      "Epoch 769/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7067 - bpp: 1.1034 - mse: 9.7854e-05\n",
      "Epoch 769: loss improved from 2.80251 to 2.70666, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7067 - bpp: 1.1034 - mse: 9.7854e-05\n",
      "Epoch 770/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0144 - bpp: 1.1275 - mse: 1.1517e-04\n",
      "Epoch 770: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0144 - bpp: 1.1275 - mse: 1.1517e-04\n",
      "Epoch 771/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0526 - bpp: 1.1303 - mse: 1.1733e-04\n",
      "Epoch 771: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0526 - bpp: 1.1303 - mse: 1.1733e-04\n",
      "Epoch 772/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2361 - bpp: 1.1487 - mse: 1.2741e-04\n",
      "Epoch 772: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2361 - bpp: 1.1487 - mse: 1.2741e-04\n",
      "Epoch 773/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3337 - bpp: 1.1610 - mse: 1.3261e-04\n",
      "Epoch 773: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3337 - bpp: 1.1610 - mse: 1.3261e-04\n",
      "Epoch 774/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1062 - bpp: 1.1500 - mse: 1.1939e-04\n",
      "Epoch 774: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.1062 - bpp: 1.1500 - mse: 1.1939e-04\n",
      "Epoch 775/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4511 - bpp: 1.1603 - mse: 1.3982e-04\n",
      "Epoch 775: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.4511 - bpp: 1.1603 - mse: 1.3982e-04\n",
      "Epoch 776/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1847 - bpp: 1.1506 - mse: 1.2415e-04\n",
      "Epoch 776: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.1847 - bpp: 1.1506 - mse: 1.2415e-04\n",
      "Epoch 777/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3104 - bpp: 1.1626 - mse: 1.3109e-04\n",
      "Epoch 777: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3104 - bpp: 1.1626 - mse: 1.3109e-04\n",
      "Epoch 778/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2210 - bpp: 1.1481 - mse: 1.2652e-04\n",
      "Epoch 778: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 3.2210 - bpp: 1.1481 - mse: 1.2652e-04\n",
      "Epoch 779/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3922 - bpp: 1.1655 - mse: 1.3590e-04\n",
      "Epoch 779: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3922 - bpp: 1.1655 - mse: 1.3590e-04\n",
      "Epoch 780/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9076 - bpp: 1.1424 - mse: 1.0774e-04\n",
      "Epoch 780: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 2.9076 - bpp: 1.1424 - mse: 1.0774e-04\n",
      "Epoch 781/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0927 - bpp: 1.1325 - mse: 1.1964e-04\n",
      "Epoch 781: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0927 - bpp: 1.1325 - mse: 1.1964e-04\n",
      "Epoch 782/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4505 - bpp: 1.1805 - mse: 1.3855e-04\n",
      "Epoch 782: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.4505 - bpp: 1.1805 - mse: 1.3855e-04\n",
      "Epoch 783/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2085 - bpp: 1.1226 - mse: 1.2731e-04\n",
      "Epoch 783: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2085 - bpp: 1.1226 - mse: 1.2731e-04\n",
      "Epoch 784/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3181 - bpp: 1.1699 - mse: 1.3112e-04\n",
      "Epoch 784: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.3181 - bpp: 1.1699 - mse: 1.3112e-04\n",
      "Epoch 785/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0878 - bpp: 1.1358 - mse: 1.1914e-04\n",
      "Epoch 785: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0878 - bpp: 1.1358 - mse: 1.1914e-04\n",
      "Epoch 786/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3705 - bpp: 1.1635 - mse: 1.3470e-04\n",
      "Epoch 786: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3705 - bpp: 1.1635 - mse: 1.3470e-04\n",
      "Epoch 787/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6872 - bpp: 1.1719 - mse: 1.5352e-04\n",
      "Epoch 787: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6872 - bpp: 1.1719 - mse: 1.5352e-04\n",
      "Epoch 788/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1348 - bpp: 1.1461 - mse: 1.2138e-04\n",
      "Epoch 788: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1348 - bpp: 1.1461 - mse: 1.2138e-04\n",
      "Epoch 789/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7005 - bpp: 1.1556 - mse: 1.5533e-04\n",
      "Epoch 789: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 239ms/step - loss: 3.7005 - bpp: 1.1556 - mse: 1.5533e-04\n",
      "Epoch 790/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2267 - bpp: 1.1589 - mse: 1.2621e-04\n",
      "Epoch 790: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2267 - bpp: 1.1589 - mse: 1.2621e-04\n",
      "Epoch 791/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0579 - bpp: 1.1262 - mse: 1.1790e-04\n",
      "Epoch 791: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0579 - bpp: 1.1262 - mse: 1.1790e-04\n",
      "Epoch 792/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5271 - bpp: 1.1713 - mse: 1.4379e-04\n",
      "Epoch 792: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.5271 - bpp: 1.1713 - mse: 1.4379e-04\n",
      "Epoch 793/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0185 - bpp: 1.1392 - mse: 1.1471e-04\n",
      "Epoch 793: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0185 - bpp: 1.1392 - mse: 1.1471e-04\n",
      "Epoch 794/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2123 - bpp: 1.1581 - mse: 1.2538e-04\n",
      "Epoch 794: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.2123 - bpp: 1.1581 - mse: 1.2538e-04\n",
      "Epoch 795/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1486 - bpp: 1.1488 - mse: 1.2206e-04\n",
      "Epoch 795: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1486 - bpp: 1.1488 - mse: 1.2206e-04\n",
      "Epoch 796/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3458 - bpp: 1.1614 - mse: 1.3333e-04\n",
      "Epoch 796: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3458 - bpp: 1.1614 - mse: 1.3333e-04\n",
      "Epoch 797/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2835 - bpp: 1.1464 - mse: 1.3044e-04\n",
      "Epoch 797: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2835 - bpp: 1.1464 - mse: 1.3044e-04\n",
      "Epoch 798/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4589 - bpp: 1.1575 - mse: 1.4047e-04\n",
      "Epoch 798: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.4589 - bpp: 1.1575 - mse: 1.4047e-04\n",
      "Epoch 799/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2851 - bpp: 1.1412 - mse: 1.3086e-04\n",
      "Epoch 799: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2851 - bpp: 1.1412 - mse: 1.3086e-04\n",
      "Epoch 800/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9337 - bpp: 1.1152 - mse: 1.1099e-04\n",
      "Epoch 800: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9337 - bpp: 1.1152 - mse: 1.1099e-04\n",
      "Epoch 801/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3558 - bpp: 1.1519 - mse: 1.3452e-04\n",
      "Epoch 801: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3558 - bpp: 1.1519 - mse: 1.3452e-04\n",
      "Epoch 802/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6610 - bpp: 1.1753 - mse: 1.5171e-04\n",
      "Epoch 802: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.6610 - bpp: 1.1753 - mse: 1.5171e-04\n",
      "Epoch 803/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1307 - bpp: 1.1625 - mse: 1.2013e-04\n",
      "Epoch 803: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1307 - bpp: 1.1625 - mse: 1.2013e-04\n",
      "Epoch 804/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2456 - bpp: 1.1543 - mse: 1.2764e-04\n",
      "Epoch 804: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.2456 - bpp: 1.1543 - mse: 1.2764e-04\n",
      "Epoch 805/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3200 - bpp: 1.1740 - mse: 1.3098e-04\n",
      "Epoch 805: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3200 - bpp: 1.1740 - mse: 1.3098e-04\n",
      "Epoch 806/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2260 - bpp: 1.1468 - mse: 1.2690e-04\n",
      "Epoch 806: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.2260 - bpp: 1.1468 - mse: 1.2690e-04\n",
      "Epoch 807/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2111 - bpp: 1.1432 - mse: 1.2621e-04\n",
      "Epoch 807: loss did not improve from 2.70666\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 3.2111 - bpp: 1.1432 - mse: 1.2621e-04\n",
      "Epoch 808/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5826 - bpp: 1.0918 - mse: 9.0990e-05\n",
      "Epoch 808: loss improved from 2.70666 to 2.58260, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.5826 - bpp: 1.0918 - mse: 9.0990e-05\n",
      "Epoch 809/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8151 - bpp: 1.1230 - mse: 1.0328e-04\n",
      "Epoch 809: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.8151 - bpp: 1.1230 - mse: 1.0328e-04\n",
      "Epoch 810/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1256 - bpp: 1.1634 - mse: 1.1976e-04\n",
      "Epoch 810: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1256 - bpp: 1.1634 - mse: 1.1976e-04\n",
      "Epoch 811/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7811 - bpp: 1.1821 - mse: 1.5863e-04\n",
      "Epoch 811: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.7811 - bpp: 1.1821 - mse: 1.5863e-04\n",
      "Epoch 812/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3730 - bpp: 1.1612 - mse: 1.3500e-04\n",
      "Epoch 812: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.3730 - bpp: 1.1612 - mse: 1.3500e-04\n",
      "Epoch 813/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2907 - bpp: 1.1504 - mse: 1.3063e-04\n",
      "Epoch 813: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.2907 - bpp: 1.1504 - mse: 1.3063e-04\n",
      "Epoch 814/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1492 - bpp: 1.1548 - mse: 1.2173e-04\n",
      "Epoch 814: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1492 - bpp: 1.1548 - mse: 1.2173e-04\n",
      "Epoch 815/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2809 - bpp: 1.1450 - mse: 1.3037e-04\n",
      "Epoch 815: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.2809 - bpp: 1.1450 - mse: 1.3037e-04\n",
      "Epoch 816/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9947 - bpp: 1.1324 - mse: 1.1367e-04\n",
      "Epoch 816: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.9947 - bpp: 1.1324 - mse: 1.1367e-04\n",
      "Epoch 817/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1713 - bpp: 1.1443 - mse: 1.2372e-04\n",
      "Epoch 817: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1713 - bpp: 1.1443 - mse: 1.2372e-04\n",
      "Epoch 818/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1409 - bpp: 1.1515 - mse: 1.2142e-04\n",
      "Epoch 818: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1409 - bpp: 1.1515 - mse: 1.2142e-04\n",
      "Epoch 819/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2183 - bpp: 1.1551 - mse: 1.2593e-04\n",
      "Epoch 819: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 3.2183 - bpp: 1.1551 - mse: 1.2593e-04\n",
      "Epoch 820/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3586 - bpp: 1.1612 - mse: 1.3412e-04\n",
      "Epoch 820: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.3586 - bpp: 1.1612 - mse: 1.3412e-04\n",
      "Epoch 821/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2388 - bpp: 1.1584 - mse: 1.2698e-04\n",
      "Epoch 821: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.2388 - bpp: 1.1584 - mse: 1.2698e-04\n",
      "Epoch 822/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2142 - bpp: 1.1435 - mse: 1.2639e-04\n",
      "Epoch 822: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2142 - bpp: 1.1435 - mse: 1.2639e-04\n",
      "Epoch 823/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6279 - bpp: 1.1978 - mse: 1.4832e-04\n",
      "Epoch 823: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.6279 - bpp: 1.1978 - mse: 1.4832e-04\n",
      "Epoch 824/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3496 - bpp: 1.1466 - mse: 1.3446e-04\n",
      "Epoch 824: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.3496 - bpp: 1.1466 - mse: 1.3446e-04\n",
      "Epoch 825/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2250 - bpp: 1.1428 - mse: 1.2709e-04\n",
      "Epoch 825: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2250 - bpp: 1.1428 - mse: 1.2709e-04\n",
      "Epoch 826/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2447 - bpp: 1.1453 - mse: 1.2814e-04\n",
      "Epoch 826: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 245ms/step - loss: 3.2447 - bpp: 1.1453 - mse: 1.2814e-04\n",
      "Epoch 827/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0297 - bpp: 1.1459 - mse: 1.1498e-04\n",
      "Epoch 827: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0297 - bpp: 1.1459 - mse: 1.1498e-04\n",
      "Epoch 828/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1515 - bpp: 1.1557 - mse: 1.2182e-04\n",
      "Epoch 828: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.1515 - bpp: 1.1557 - mse: 1.2182e-04\n",
      "Epoch 829/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3002 - bpp: 1.1364 - mse: 1.3207e-04\n",
      "Epoch 829: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3002 - bpp: 1.1364 - mse: 1.3207e-04\n",
      "Epoch 830/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4073 - bpp: 1.1580 - mse: 1.3729e-04\n",
      "Epoch 830: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.4073 - bpp: 1.1580 - mse: 1.3729e-04\n",
      "Epoch 831/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3513 - bpp: 1.1650 - mse: 1.3344e-04\n",
      "Epoch 831: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 241ms/step - loss: 3.3513 - bpp: 1.1650 - mse: 1.3344e-04\n",
      "Epoch 832/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0425 - bpp: 1.1378 - mse: 1.1625e-04\n",
      "Epoch 832: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.0425 - bpp: 1.1378 - mse: 1.1625e-04\n",
      "Epoch 833/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3272 - bpp: 1.1541 - mse: 1.3264e-04\n",
      "Epoch 833: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.3272 - bpp: 1.1541 - mse: 1.3264e-04\n",
      "Epoch 834/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1998 - bpp: 1.1516 - mse: 1.2501e-04\n",
      "Epoch 834: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1998 - bpp: 1.1516 - mse: 1.2501e-04\n",
      "Epoch 835/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4939 - bpp: 1.1857 - mse: 1.4088e-04\n",
      "Epoch 835: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 3.4939 - bpp: 1.1857 - mse: 1.4088e-04\n",
      "Epoch 836/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3605 - bpp: 1.1792 - mse: 1.3314e-04\n",
      "Epoch 836: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3605 - bpp: 1.1792 - mse: 1.3314e-04\n",
      "Epoch 837/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7169 - bpp: 1.1032 - mse: 9.8493e-05\n",
      "Epoch 837: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 2.7169 - bpp: 1.1032 - mse: 9.8493e-05\n",
      "Epoch 838/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9103 - bpp: 1.1209 - mse: 1.0921e-04\n",
      "Epoch 838: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 2.9103 - bpp: 1.1209 - mse: 1.0921e-04\n",
      "Epoch 839/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8584 - bpp: 1.1135 - mse: 1.0650e-04\n",
      "Epoch 839: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.8584 - bpp: 1.1135 - mse: 1.0650e-04\n",
      "Epoch 840/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1324 - bpp: 1.1324 - mse: 1.2207e-04\n",
      "Epoch 840: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1324 - bpp: 1.1324 - mse: 1.2207e-04\n",
      "Epoch 841/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6085 - bpp: 1.1530 - mse: 1.4987e-04\n",
      "Epoch 841: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.6085 - bpp: 1.1530 - mse: 1.4987e-04\n",
      "Epoch 842/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1513 - bpp: 1.1368 - mse: 1.2295e-04\n",
      "Epoch 842: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1513 - bpp: 1.1368 - mse: 1.2295e-04\n",
      "Epoch 843/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.7827 - bpp: 1.1827 - mse: 1.5869e-04\n",
      "Epoch 843: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.7827 - bpp: 1.1827 - mse: 1.5869e-04\n",
      "Epoch 844/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7670 - bpp: 1.0864 - mse: 1.0258e-04\n",
      "Epoch 844: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.7670 - bpp: 1.0864 - mse: 1.0258e-04\n",
      "Epoch 845/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9951 - bpp: 1.1434 - mse: 1.1301e-04\n",
      "Epoch 845: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9951 - bpp: 1.1434 - mse: 1.1301e-04\n",
      "Epoch 846/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2674 - bpp: 1.1352 - mse: 1.3014e-04\n",
      "Epoch 846: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.2674 - bpp: 1.1352 - mse: 1.3014e-04\n",
      "Epoch 847/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9228 - bpp: 1.1348 - mse: 1.0913e-04\n",
      "Epoch 847: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.9228 - bpp: 1.1348 - mse: 1.0913e-04\n",
      "Epoch 848/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2629 - bpp: 1.1568 - mse: 1.2855e-04\n",
      "Epoch 848: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2629 - bpp: 1.1568 - mse: 1.2855e-04\n",
      "Epoch 849/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0799 - bpp: 1.1243 - mse: 1.1936e-04\n",
      "Epoch 849: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0799 - bpp: 1.1243 - mse: 1.1936e-04\n",
      "Epoch 850/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1447 - bpp: 1.1490 - mse: 1.2181e-04\n",
      "Epoch 850: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1447 - bpp: 1.1490 - mse: 1.2181e-04\n",
      "Epoch 851/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8150 - bpp: 1.1260 - mse: 1.0309e-04\n",
      "Epoch 851: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 2.8150 - bpp: 1.1260 - mse: 1.0309e-04\n",
      "Epoch 852/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1429 - bpp: 1.1380 - mse: 1.2237e-04\n",
      "Epoch 852: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 236ms/step - loss: 3.1429 - bpp: 1.1380 - mse: 1.2237e-04\n",
      "Epoch 853/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7897 - bpp: 1.1077 - mse: 1.0266e-04\n",
      "Epoch 853: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 2.7897 - bpp: 1.1077 - mse: 1.0266e-04\n",
      "Epoch 854/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4096 - bpp: 1.1474 - mse: 1.3807e-04\n",
      "Epoch 854: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.4096 - bpp: 1.1474 - mse: 1.3807e-04\n",
      "Epoch 855/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8719 - bpp: 1.1268 - mse: 1.0651e-04\n",
      "Epoch 855: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 2.8719 - bpp: 1.1268 - mse: 1.0651e-04\n",
      "Epoch 856/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0076 - bpp: 1.1404 - mse: 1.1397e-04\n",
      "Epoch 856: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3.0076 - bpp: 1.1404 - mse: 1.1397e-04\n",
      "Epoch 857/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1409 - bpp: 1.1511 - mse: 1.2145e-04\n",
      "Epoch 857: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.1409 - bpp: 1.1511 - mse: 1.2145e-04\n",
      "Epoch 858/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1726 - bpp: 1.1571 - mse: 1.2302e-04\n",
      "Epoch 858: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 231ms/step - loss: 3.1726 - bpp: 1.1571 - mse: 1.2302e-04\n",
      "Epoch 859/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3941 - bpp: 1.1557 - mse: 1.3663e-04\n",
      "Epoch 859: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.3941 - bpp: 1.1557 - mse: 1.3663e-04\n",
      "Epoch 860/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1126 - bpp: 1.1220 - mse: 1.2149e-04\n",
      "Epoch 860: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 3.1126 - bpp: 1.1220 - mse: 1.2149e-04\n",
      "Epoch 861/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1239 - bpp: 1.1472 - mse: 1.2065e-04\n",
      "Epoch 861: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1239 - bpp: 1.1472 - mse: 1.2065e-04\n",
      "Epoch 862/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8363 - bpp: 1.1093 - mse: 1.0540e-04\n",
      "Epoch 862: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8363 - bpp: 1.1093 - mse: 1.0540e-04\n",
      "Epoch 863/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9431 - bpp: 1.1340 - mse: 1.1041e-04\n",
      "Epoch 863: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9431 - bpp: 1.1340 - mse: 1.1041e-04\n",
      "Epoch 864/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0590 - bpp: 1.1506 - mse: 1.1648e-04\n",
      "Epoch 864: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0590 - bpp: 1.1506 - mse: 1.1648e-04\n",
      "Epoch 865/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7422 - bpp: 1.1137 - mse: 9.9395e-05\n",
      "Epoch 865: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 2.7422 - bpp: 1.1137 - mse: 9.9395e-05\n",
      "Epoch 866/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1755 - bpp: 1.1435 - mse: 1.2402e-04\n",
      "Epoch 866: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1755 - bpp: 1.1435 - mse: 1.2402e-04\n",
      "Epoch 867/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1321 - bpp: 1.1324 - mse: 1.2205e-04\n",
      "Epoch 867: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1321 - bpp: 1.1324 - mse: 1.2205e-04\n",
      "Epoch 868/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3075 - bpp: 1.1623 - mse: 1.3093e-04\n",
      "Epoch 868: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3075 - bpp: 1.1623 - mse: 1.3093e-04\n",
      "Epoch 869/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0991 - bpp: 1.1017 - mse: 1.2191e-04\n",
      "Epoch 869: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.0991 - bpp: 1.1017 - mse: 1.2191e-04\n",
      "Epoch 870/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3511 - bpp: 1.1640 - mse: 1.3349e-04\n",
      "Epoch 870: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 3.3511 - bpp: 1.1640 - mse: 1.3349e-04\n",
      "Epoch 871/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3506 - bpp: 1.1356 - mse: 1.3519e-04\n",
      "Epoch 871: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.3506 - bpp: 1.1356 - mse: 1.3519e-04\n",
      "Epoch 872/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6118 - bpp: 1.1539 - mse: 1.5002e-04\n",
      "Epoch 872: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.6118 - bpp: 1.1539 - mse: 1.5002e-04\n",
      "Epoch 873/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1511 - bpp: 1.1288 - mse: 1.2344e-04\n",
      "Epoch 873: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1511 - bpp: 1.1288 - mse: 1.2344e-04\n",
      "Epoch 874/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6175 - bpp: 1.1822 - mse: 1.4864e-04\n",
      "Epoch 874: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 3.6175 - bpp: 1.1822 - mse: 1.4864e-04\n",
      "Epoch 875/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3390 - bpp: 1.1840 - mse: 1.3153e-04\n",
      "Epoch 875: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3390 - bpp: 1.1840 - mse: 1.3153e-04\n",
      "Epoch 876/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8857 - bpp: 1.1181 - mse: 1.0789e-04\n",
      "Epoch 876: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.8857 - bpp: 1.1181 - mse: 1.0789e-04\n",
      "Epoch 877/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3759 - bpp: 1.1612 - mse: 1.3517e-04\n",
      "Epoch 877: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.3759 - bpp: 1.1612 - mse: 1.3517e-04\n",
      "Epoch 878/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6134 - bpp: 1.1906 - mse: 1.4788e-04\n",
      "Epoch 878: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.6134 - bpp: 1.1906 - mse: 1.4788e-04\n",
      "Epoch 879/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0345 - bpp: 1.1385 - mse: 1.1572e-04\n",
      "Epoch 879: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0345 - bpp: 1.1385 - mse: 1.1572e-04\n",
      "Epoch 880/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2075 - bpp: 1.1303 - mse: 1.2678e-04\n",
      "Epoch 880: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2075 - bpp: 1.1303 - mse: 1.2678e-04\n",
      "Epoch 881/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2599 - bpp: 1.1470 - mse: 1.2896e-04\n",
      "Epoch 881: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2599 - bpp: 1.1470 - mse: 1.2896e-04\n",
      "Epoch 882/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9571 - bpp: 1.1303 - mse: 1.1150e-04\n",
      "Epoch 882: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9571 - bpp: 1.1303 - mse: 1.1150e-04\n",
      "Epoch 883/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3299 - bpp: 1.1628 - mse: 1.3227e-04\n",
      "Epoch 883: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.3299 - bpp: 1.1628 - mse: 1.3227e-04\n",
      "Epoch 884/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9575 - bpp: 1.1366 - mse: 1.1114e-04\n",
      "Epoch 884: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9575 - bpp: 1.1366 - mse: 1.1114e-04\n",
      "Epoch 885/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0319 - bpp: 1.1445 - mse: 1.1520e-04\n",
      "Epoch 885: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0319 - bpp: 1.1445 - mse: 1.1520e-04\n",
      "Epoch 886/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1338 - bpp: 1.1612 - mse: 1.2040e-04\n",
      "Epoch 886: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.1338 - bpp: 1.1612 - mse: 1.2040e-04\n",
      "Epoch 887/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2429 - bpp: 1.1534 - mse: 1.2754e-04\n",
      "Epoch 887: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.2429 - bpp: 1.1534 - mse: 1.2754e-04\n",
      "Epoch 888/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1485 - bpp: 1.1321 - mse: 1.2307e-04\n",
      "Epoch 888: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1485 - bpp: 1.1321 - mse: 1.2307e-04\n",
      "Epoch 889/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0493 - bpp: 1.1368 - mse: 1.1673e-04\n",
      "Epoch 889: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0493 - bpp: 1.1368 - mse: 1.1673e-04\n",
      "Epoch 890/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1468 - bpp: 1.1490 - mse: 1.2194e-04\n",
      "Epoch 890: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.1468 - bpp: 1.1490 - mse: 1.2194e-04\n",
      "Epoch 891/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1379 - bpp: 1.1491 - mse: 1.2138e-04\n",
      "Epoch 891: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1379 - bpp: 1.1491 - mse: 1.2138e-04\n",
      "Epoch 892/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0967 - bpp: 1.1420 - mse: 1.1930e-04\n",
      "Epoch 892: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 3.0967 - bpp: 1.1420 - mse: 1.1930e-04\n",
      "Epoch 893/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8800 - bpp: 1.1148 - mse: 1.0774e-04\n",
      "Epoch 893: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.8800 - bpp: 1.1148 - mse: 1.0774e-04\n",
      "Epoch 894/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2338 - bpp: 1.1372 - mse: 1.2797e-04\n",
      "Epoch 894: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.2338 - bpp: 1.1372 - mse: 1.2797e-04\n",
      "Epoch 895/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9854 - bpp: 1.1174 - mse: 1.1402e-04\n",
      "Epoch 895: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 2.9854 - bpp: 1.1174 - mse: 1.1402e-04\n",
      "Epoch 896/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0810 - bpp: 1.1527 - mse: 1.1770e-04\n",
      "Epoch 896: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.0810 - bpp: 1.1527 - mse: 1.1770e-04\n",
      "Epoch 897/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1480 - bpp: 1.1052 - mse: 1.2469e-04\n",
      "Epoch 897: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.1480 - bpp: 1.1052 - mse: 1.2469e-04\n",
      "Epoch 898/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0872 - bpp: 1.1277 - mse: 1.1960e-04\n",
      "Epoch 898: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.0872 - bpp: 1.1277 - mse: 1.1960e-04\n",
      "Epoch 899/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2962 - bpp: 1.1319 - mse: 1.3209e-04\n",
      "Epoch 899: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 3.2962 - bpp: 1.1319 - mse: 1.3209e-04\n",
      "Epoch 900/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9436 - bpp: 1.1246 - mse: 1.1102e-04\n",
      "Epoch 900: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 2.9436 - bpp: 1.1246 - mse: 1.1102e-04\n",
      "Epoch 901/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2530 - bpp: 1.1421 - mse: 1.2884e-04\n",
      "Epoch 901: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.2530 - bpp: 1.1421 - mse: 1.2884e-04\n",
      "Epoch 902/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3578 - bpp: 1.1680 - mse: 1.3366e-04\n",
      "Epoch 902: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 3.3578 - bpp: 1.1680 - mse: 1.3366e-04\n",
      "Epoch 903/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0013 - bpp: 1.1170 - mse: 1.1501e-04\n",
      "Epoch 903: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0013 - bpp: 1.1170 - mse: 1.1501e-04\n",
      "Epoch 904/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9118 - bpp: 1.1326 - mse: 1.0859e-04\n",
      "Epoch 904: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.9118 - bpp: 1.1326 - mse: 1.0859e-04\n",
      "Epoch 905/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0352 - bpp: 1.1253 - mse: 1.1657e-04\n",
      "Epoch 905: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 3.0352 - bpp: 1.1253 - mse: 1.1657e-04\n",
      "Epoch 906/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0205 - bpp: 1.1090 - mse: 1.1667e-04\n",
      "Epoch 906: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0205 - bpp: 1.1090 - mse: 1.1667e-04\n",
      "Epoch 907/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3889 - bpp: 1.1755 - mse: 1.3510e-04\n",
      "Epoch 907: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 47s 232ms/step - loss: 3.3889 - bpp: 1.1755 - mse: 1.3510e-04\n",
      "Epoch 908/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1935 - bpp: 1.1317 - mse: 1.2584e-04\n",
      "Epoch 908: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1935 - bpp: 1.1317 - mse: 1.2584e-04\n",
      "Epoch 909/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0151 - bpp: 1.1457 - mse: 1.1410e-04\n",
      "Epoch 909: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 3.0151 - bpp: 1.1457 - mse: 1.1410e-04\n",
      "Epoch 910/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9652 - bpp: 1.1175 - mse: 1.1277e-04\n",
      "Epoch 910: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9652 - bpp: 1.1175 - mse: 1.1277e-04\n",
      "Epoch 911/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8941 - bpp: 1.1255 - mse: 1.0795e-04\n",
      "Epoch 911: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 2.8941 - bpp: 1.1255 - mse: 1.0795e-04\n",
      "Epoch 912/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0495 - bpp: 1.1300 - mse: 1.1716e-04\n",
      "Epoch 912: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0495 - bpp: 1.1300 - mse: 1.1716e-04\n",
      "Epoch 913/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9374 - bpp: 1.1306 - mse: 1.1028e-04\n",
      "Epoch 913: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9374 - bpp: 1.1306 - mse: 1.1028e-04\n",
      "Epoch 914/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8906 - bpp: 1.1004 - mse: 1.0926e-04\n",
      "Epoch 914: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8906 - bpp: 1.1004 - mse: 1.0926e-04\n",
      "Epoch 915/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2662 - bpp: 1.1345 - mse: 1.3011e-04\n",
      "Epoch 915: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.2662 - bpp: 1.1345 - mse: 1.3011e-04\n",
      "Epoch 916/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3044 - bpp: 1.1552 - mse: 1.3118e-04\n",
      "Epoch 916: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3044 - bpp: 1.1552 - mse: 1.3118e-04\n",
      "Epoch 917/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8380 - bpp: 1.1179 - mse: 1.0499e-04\n",
      "Epoch 917: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8380 - bpp: 1.1179 - mse: 1.0499e-04\n",
      "Epoch 918/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3055 - bpp: 1.1488 - mse: 1.3164e-04\n",
      "Epoch 918: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3055 - bpp: 1.1488 - mse: 1.3164e-04\n",
      "Epoch 919/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0591 - bpp: 1.1402 - mse: 1.1712e-04\n",
      "Epoch 919: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0591 - bpp: 1.1402 - mse: 1.1712e-04\n",
      "Epoch 920/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3491 - bpp: 1.1704 - mse: 1.3298e-04\n",
      "Epoch 920: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.3491 - bpp: 1.1704 - mse: 1.3298e-04\n",
      "Epoch 921/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0947 - bpp: 1.1450 - mse: 1.1900e-04\n",
      "Epoch 921: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0947 - bpp: 1.1450 - mse: 1.1900e-04\n",
      "Epoch 922/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0999 - bpp: 1.1372 - mse: 1.1979e-04\n",
      "Epoch 922: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0999 - bpp: 1.1372 - mse: 1.1979e-04\n",
      "Epoch 923/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8626 - bpp: 1.0956 - mse: 1.0785e-04\n",
      "Epoch 923: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8626 - bpp: 1.0956 - mse: 1.0785e-04\n",
      "Epoch 924/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1029 - bpp: 1.1465 - mse: 1.1941e-04\n",
      "Epoch 924: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1029 - bpp: 1.1465 - mse: 1.1941e-04\n",
      "Epoch 925/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0278 - bpp: 1.1345 - mse: 1.1556e-04\n",
      "Epoch 925: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0278 - bpp: 1.1345 - mse: 1.1556e-04\n",
      "Epoch 926/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9909 - bpp: 1.1454 - mse: 1.1264e-04\n",
      "Epoch 926: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9909 - bpp: 1.1454 - mse: 1.1264e-04\n",
      "Epoch 927/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9828 - bpp: 1.1249 - mse: 1.1340e-04\n",
      "Epoch 927: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 2.9828 - bpp: 1.1249 - mse: 1.1340e-04\n",
      "Epoch 928/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1985 - bpp: 1.1623 - mse: 1.2428e-04\n",
      "Epoch 928: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1985 - bpp: 1.1623 - mse: 1.2428e-04\n",
      "Epoch 929/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9753 - bpp: 1.1298 - mse: 1.1264e-04\n",
      "Epoch 929: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9753 - bpp: 1.1298 - mse: 1.1264e-04\n",
      "Epoch 930/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3782 - bpp: 1.1770 - mse: 1.3435e-04\n",
      "Epoch 930: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.3782 - bpp: 1.1770 - mse: 1.3435e-04\n",
      "Epoch 931/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8938 - bpp: 1.1191 - mse: 1.0832e-04\n",
      "Epoch 931: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8938 - bpp: 1.1191 - mse: 1.0832e-04\n",
      "Epoch 932/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9948 - bpp: 1.1162 - mse: 1.1466e-04\n",
      "Epoch 932: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9948 - bpp: 1.1162 - mse: 1.1466e-04\n",
      "Epoch 933/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9210 - bpp: 1.1075 - mse: 1.1069e-04\n",
      "Epoch 933: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 48s 241ms/step - loss: 2.9210 - bpp: 1.1075 - mse: 1.1069e-04\n",
      "Epoch 934/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8783 - bpp: 1.1295 - mse: 1.0674e-04\n",
      "Epoch 934: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.8783 - bpp: 1.1295 - mse: 1.0674e-04\n",
      "Epoch 935/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0872 - bpp: 1.1310 - mse: 1.1940e-04\n",
      "Epoch 935: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0872 - bpp: 1.1310 - mse: 1.1940e-04\n",
      "Epoch 936/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0518 - bpp: 1.1456 - mse: 1.1634e-04\n",
      "Epoch 936: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0518 - bpp: 1.1456 - mse: 1.1634e-04\n",
      "Epoch 937/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0526 - bpp: 1.1237 - mse: 1.1773e-04\n",
      "Epoch 937: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0526 - bpp: 1.1237 - mse: 1.1773e-04\n",
      "Epoch 938/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0497 - bpp: 1.1269 - mse: 1.1736e-04\n",
      "Epoch 938: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0497 - bpp: 1.1269 - mse: 1.1736e-04\n",
      "Epoch 939/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1896 - bpp: 1.1441 - mse: 1.2485e-04\n",
      "Epoch 939: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.1896 - bpp: 1.1441 - mse: 1.2485e-04\n",
      "Epoch 940/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8269 - bpp: 1.1119 - mse: 1.0468e-04\n",
      "Epoch 940: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8269 - bpp: 1.1119 - mse: 1.0468e-04\n",
      "Epoch 941/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2221 - bpp: 1.1234 - mse: 1.2810e-04\n",
      "Epoch 941: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.2221 - bpp: 1.1234 - mse: 1.2810e-04\n",
      "Epoch 942/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2403 - bpp: 1.1550 - mse: 1.2728e-04\n",
      "Epoch 942: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.2403 - bpp: 1.1550 - mse: 1.2728e-04\n",
      "Epoch 943/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8975 - bpp: 1.1200 - mse: 1.0849e-04\n",
      "Epoch 943: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8975 - bpp: 1.1200 - mse: 1.0849e-04\n",
      "Epoch 944/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7712 - bpp: 1.0950 - mse: 1.0231e-04\n",
      "Epoch 944: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7712 - bpp: 1.0950 - mse: 1.0231e-04\n",
      "Epoch 945/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1351 - bpp: 1.1384 - mse: 1.2187e-04\n",
      "Epoch 945: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1351 - bpp: 1.1384 - mse: 1.2187e-04\n",
      "Epoch 946/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0054 - bpp: 1.1269 - mse: 1.1466e-04\n",
      "Epoch 946: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0054 - bpp: 1.1269 - mse: 1.1466e-04\n",
      "Epoch 947/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1915 - bpp: 1.1275 - mse: 1.2597e-04\n",
      "Epoch 947: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 3.1915 - bpp: 1.1275 - mse: 1.2597e-04\n",
      "Epoch 948/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1280 - bpp: 1.1312 - mse: 1.2187e-04\n",
      "Epoch 948: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1280 - bpp: 1.1312 - mse: 1.2187e-04\n",
      "Epoch 949/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1726 - bpp: 1.1504 - mse: 1.2343e-04\n",
      "Epoch 949: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 260ms/step - loss: 3.1726 - bpp: 1.1504 - mse: 1.2343e-04\n",
      "Epoch 950/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8567 - bpp: 1.1197 - mse: 1.0602e-04\n",
      "Epoch 950: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.8567 - bpp: 1.1197 - mse: 1.0602e-04\n",
      "Epoch 951/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9836 - bpp: 1.1319 - mse: 1.1302e-04\n",
      "Epoch 951: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9836 - bpp: 1.1319 - mse: 1.1302e-04\n",
      "Epoch 952/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1798 - bpp: 1.1433 - mse: 1.2430e-04\n",
      "Epoch 952: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1798 - bpp: 1.1433 - mse: 1.2430e-04\n",
      "Epoch 953/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4571 - bpp: 1.1771 - mse: 1.3916e-04\n",
      "Epoch 953: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.4571 - bpp: 1.1771 - mse: 1.3916e-04\n",
      "Epoch 954/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1130 - bpp: 1.1182 - mse: 1.2175e-04\n",
      "Epoch 954: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1130 - bpp: 1.1182 - mse: 1.2175e-04\n",
      "Epoch 955/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3635 - bpp: 1.1459 - mse: 1.3536e-04\n",
      "Epoch 955: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.3635 - bpp: 1.1459 - mse: 1.3536e-04\n",
      "Epoch 956/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1627 - bpp: 1.1363 - mse: 1.2368e-04\n",
      "Epoch 956: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1627 - bpp: 1.1363 - mse: 1.2368e-04\n",
      "Epoch 957/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8166 - bpp: 1.1247 - mse: 1.0326e-04\n",
      "Epoch 957: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8166 - bpp: 1.1247 - mse: 1.0326e-04\n",
      "Epoch 958/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9824 - bpp: 1.1263 - mse: 1.1329e-04\n",
      "Epoch 958: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9824 - bpp: 1.1263 - mse: 1.1329e-04\n",
      "Epoch 959/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9960 - bpp: 1.1168 - mse: 1.1470e-04\n",
      "Epoch 959: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.9960 - bpp: 1.1168 - mse: 1.1470e-04\n",
      "Epoch 960/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9309 - bpp: 1.1220 - mse: 1.1041e-04\n",
      "Epoch 960: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9309 - bpp: 1.1220 - mse: 1.1041e-04\n",
      "Epoch 961/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1617 - bpp: 1.1306 - mse: 1.2397e-04\n",
      "Epoch 961: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1617 - bpp: 1.1306 - mse: 1.2397e-04\n",
      "Epoch 962/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0643 - bpp: 1.1281 - mse: 1.1818e-04\n",
      "Epoch 962: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0643 - bpp: 1.1281 - mse: 1.1818e-04\n",
      "Epoch 963/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0631 - bpp: 1.1311 - mse: 1.1792e-04\n",
      "Epoch 963: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0631 - bpp: 1.1311 - mse: 1.1792e-04\n",
      "Epoch 964/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2986 - bpp: 1.1520 - mse: 1.3101e-04\n",
      "Epoch 964: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2986 - bpp: 1.1520 - mse: 1.3101e-04\n",
      "Epoch 965/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2854 - bpp: 1.1462 - mse: 1.3056e-04\n",
      "Epoch 965: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2854 - bpp: 1.1462 - mse: 1.3056e-04\n",
      "Epoch 966/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0112 - bpp: 1.1354 - mse: 1.1449e-04\n",
      "Epoch 966: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0112 - bpp: 1.1354 - mse: 1.1449e-04\n",
      "Epoch 967/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9854 - bpp: 1.1309 - mse: 1.1319e-04\n",
      "Epoch 967: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9854 - bpp: 1.1309 - mse: 1.1319e-04\n",
      "Epoch 968/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0096 - bpp: 1.1163 - mse: 1.1556e-04\n",
      "Epoch 968: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0096 - bpp: 1.1163 - mse: 1.1556e-04\n",
      "Epoch 969/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3137 - bpp: 1.1549 - mse: 1.3177e-04\n",
      "Epoch 969: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 3.3137 - bpp: 1.1549 - mse: 1.3177e-04\n",
      "Epoch 970/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9301 - bpp: 1.1274 - mse: 1.1003e-04\n",
      "Epoch 970: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9301 - bpp: 1.1274 - mse: 1.1003e-04\n",
      "Epoch 971/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2784 - bpp: 1.1645 - mse: 1.2902e-04\n",
      "Epoch 971: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2784 - bpp: 1.1645 - mse: 1.2902e-04\n",
      "Epoch 972/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9432 - bpp: 1.0992 - mse: 1.1255e-04\n",
      "Epoch 972: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.9432 - bpp: 1.0992 - mse: 1.1255e-04\n",
      "Epoch 973/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9017 - bpp: 1.1269 - mse: 1.0832e-04\n",
      "Epoch 973: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9017 - bpp: 1.1269 - mse: 1.0832e-04\n",
      "Epoch 974/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4054 - bpp: 1.1601 - mse: 1.3704e-04\n",
      "Epoch 974: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.4054 - bpp: 1.1601 - mse: 1.3704e-04\n",
      "Epoch 975/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2268 - bpp: 1.1352 - mse: 1.2766e-04\n",
      "Epoch 975: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2268 - bpp: 1.1352 - mse: 1.2766e-04\n",
      "Epoch 976/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1149 - bpp: 1.1422 - mse: 1.2040e-04\n",
      "Epoch 976: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.1149 - bpp: 1.1422 - mse: 1.2040e-04\n",
      "Epoch 977/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7985 - bpp: 1.1320 - mse: 1.0171e-04\n",
      "Epoch 977: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.7985 - bpp: 1.1320 - mse: 1.0171e-04\n",
      "Epoch 978/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9696 - bpp: 1.1223 - mse: 1.1275e-04\n",
      "Epoch 978: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9696 - bpp: 1.1223 - mse: 1.1275e-04\n",
      "Epoch 979/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9878 - bpp: 1.1486 - mse: 1.1226e-04\n",
      "Epoch 979: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9878 - bpp: 1.1486 - mse: 1.1226e-04\n",
      "Epoch 980/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3316 - bpp: 1.1465 - mse: 1.3337e-04\n",
      "Epoch 980: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3316 - bpp: 1.1465 - mse: 1.3337e-04\n",
      "Epoch 981/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9416 - bpp: 1.1335 - mse: 1.1035e-04\n",
      "Epoch 981: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9416 - bpp: 1.1335 - mse: 1.1035e-04\n",
      "Epoch 982/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4449 - bpp: 1.1689 - mse: 1.3892e-04\n",
      "Epoch 982: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.4449 - bpp: 1.1689 - mse: 1.3892e-04\n",
      "Epoch 983/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9915 - bpp: 1.1335 - mse: 1.1340e-04\n",
      "Epoch 983: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 254ms/step - loss: 2.9915 - bpp: 1.1335 - mse: 1.1340e-04\n",
      "Epoch 984/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1806 - bpp: 1.1323 - mse: 1.2502e-04\n",
      "Epoch 984: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 3.1806 - bpp: 1.1323 - mse: 1.2502e-04\n",
      "Epoch 985/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0085 - bpp: 1.1147 - mse: 1.1559e-04\n",
      "Epoch 985: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.0085 - bpp: 1.1147 - mse: 1.1559e-04\n",
      "Epoch 986/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0874 - bpp: 1.1315 - mse: 1.1938e-04\n",
      "Epoch 986: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0874 - bpp: 1.1315 - mse: 1.1938e-04\n",
      "Epoch 987/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2416 - bpp: 1.1314 - mse: 1.2879e-04\n",
      "Epoch 987: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.2416 - bpp: 1.1314 - mse: 1.2879e-04\n",
      "Epoch 988/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2231 - bpp: 1.1654 - mse: 1.2559e-04\n",
      "Epoch 988: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.2231 - bpp: 1.1654 - mse: 1.2559e-04\n",
      "Epoch 989/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1266 - bpp: 1.1166 - mse: 1.2268e-04\n",
      "Epoch 989: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.1266 - bpp: 1.1166 - mse: 1.2268e-04\n",
      "Epoch 990/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0225 - bpp: 1.1105 - mse: 1.1670e-04\n",
      "Epoch 990: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0225 - bpp: 1.1105 - mse: 1.1670e-04\n",
      "Epoch 991/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9575 - bpp: 1.0984 - mse: 1.1347e-04\n",
      "Epoch 991: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9575 - bpp: 1.0984 - mse: 1.1347e-04\n",
      "Epoch 992/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0339 - bpp: 1.1564 - mse: 1.1460e-04\n",
      "Epoch 992: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.0339 - bpp: 1.1564 - mse: 1.1460e-04\n",
      "Epoch 993/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3526 - bpp: 1.1470 - mse: 1.3462e-04\n",
      "Epoch 993: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.3526 - bpp: 1.1470 - mse: 1.3462e-04\n",
      "Epoch 994/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1383 - bpp: 1.1285 - mse: 1.2267e-04\n",
      "Epoch 994: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1383 - bpp: 1.1285 - mse: 1.2267e-04\n",
      "Epoch 995/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0994 - bpp: 1.1482 - mse: 1.1909e-04\n",
      "Epoch 995: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0994 - bpp: 1.1482 - mse: 1.1909e-04\n",
      "Epoch 996/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0706 - bpp: 1.1385 - mse: 1.1793e-04\n",
      "Epoch 996: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 3.0706 - bpp: 1.1385 - mse: 1.1793e-04\n",
      "Epoch 997/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0981 - bpp: 1.1279 - mse: 1.2025e-04\n",
      "Epoch 997: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0981 - bpp: 1.1279 - mse: 1.2025e-04\n",
      "Epoch 998/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1382 - bpp: 1.1403 - mse: 1.2194e-04\n",
      "Epoch 998: loss did not improve from 2.58260\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1382 - bpp: 1.1403 - mse: 1.2194e-04\n",
      "Epoch 999/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5735 - bpp: 1.0786 - mse: 9.1236e-05\n",
      "Epoch 999: loss improved from 2.58260 to 2.57346, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.5735 - bpp: 1.0786 - mse: 9.1236e-05\n",
      "Epoch 1000/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4496 - bpp: 1.1573 - mse: 1.3992e-04\n",
      "Epoch 1000: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.4496 - bpp: 1.1573 - mse: 1.3992e-04\n",
      "Epoch 1001/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2975 - bpp: 1.1517 - mse: 1.3096e-04\n",
      "Epoch 1001: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 3.2975 - bpp: 1.1517 - mse: 1.3096e-04\n",
      "Epoch 1002/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4403 - bpp: 1.1591 - mse: 1.3923e-04\n",
      "Epoch 1002: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 3.4403 - bpp: 1.1591 - mse: 1.3923e-04\n",
      "Epoch 1003/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2958 - bpp: 1.1378 - mse: 1.3171e-04\n",
      "Epoch 1003: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2958 - bpp: 1.1378 - mse: 1.3171e-04\n",
      "Epoch 1004/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9480 - bpp: 1.1147 - mse: 1.1190e-04\n",
      "Epoch 1004: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9480 - bpp: 1.1147 - mse: 1.1190e-04\n",
      "Epoch 1005/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8094 - bpp: 1.1067 - mse: 1.0393e-04\n",
      "Epoch 1005: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8094 - bpp: 1.1067 - mse: 1.0393e-04\n",
      "Epoch 1006/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8773 - bpp: 1.1214 - mse: 1.0717e-04\n",
      "Epoch 1006: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8773 - bpp: 1.1214 - mse: 1.0717e-04\n",
      "Epoch 1007/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8673 - bpp: 1.1347 - mse: 1.0575e-04\n",
      "Epoch 1007: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8673 - bpp: 1.1347 - mse: 1.0575e-04\n",
      "Epoch 1008/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7291 - bpp: 1.0984 - mse: 9.9530e-05\n",
      "Epoch 1008: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.7291 - bpp: 1.0984 - mse: 9.9530e-05\n",
      "Epoch 1009/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1827 - bpp: 1.1352 - mse: 1.2497e-04\n",
      "Epoch 1009: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1827 - bpp: 1.1352 - mse: 1.2497e-04\n",
      "Epoch 1010/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8658 - bpp: 1.1281 - mse: 1.0606e-04\n",
      "Epoch 1010: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.8658 - bpp: 1.1281 - mse: 1.0606e-04\n",
      "Epoch 1011/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0463 - bpp: 1.1228 - mse: 1.1740e-04\n",
      "Epoch 1011: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0463 - bpp: 1.1228 - mse: 1.1740e-04\n",
      "Epoch 1012/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0914 - bpp: 1.1188 - mse: 1.2040e-04\n",
      "Epoch 1012: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 3.0914 - bpp: 1.1188 - mse: 1.2040e-04\n",
      "Epoch 1013/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2739 - bpp: 1.1375 - mse: 1.3039e-04\n",
      "Epoch 1013: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2739 - bpp: 1.1375 - mse: 1.3039e-04\n",
      "Epoch 1014/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0721 - bpp: 1.1412 - mse: 1.1785e-04\n",
      "Epoch 1014: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0721 - bpp: 1.1412 - mse: 1.1785e-04\n",
      "Epoch 1015/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1621 - bpp: 1.1521 - mse: 1.2268e-04\n",
      "Epoch 1015: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1621 - bpp: 1.1521 - mse: 1.2268e-04\n",
      "Epoch 1016/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3861 - bpp: 1.1531 - mse: 1.3629e-04\n",
      "Epoch 1016: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3861 - bpp: 1.1531 - mse: 1.3629e-04\n",
      "Epoch 1017/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8597 - bpp: 1.1381 - mse: 1.0508e-04\n",
      "Epoch 1017: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8597 - bpp: 1.1381 - mse: 1.0508e-04\n",
      "Epoch 1018/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7729 - bpp: 1.0990 - mse: 1.0217e-04\n",
      "Epoch 1018: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.7729 - bpp: 1.0990 - mse: 1.0217e-04\n",
      "Epoch 1019/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3645 - bpp: 1.1598 - mse: 1.3456e-04\n",
      "Epoch 1019: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.3645 - bpp: 1.1598 - mse: 1.3456e-04\n",
      "Epoch 1020/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3872 - bpp: 1.1418 - mse: 1.3705e-04\n",
      "Epoch 1020: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.3872 - bpp: 1.1418 - mse: 1.3705e-04\n",
      "Epoch 1021/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1444 - bpp: 1.1382 - mse: 1.2245e-04\n",
      "Epoch 1021: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.1444 - bpp: 1.1382 - mse: 1.2245e-04\n",
      "Epoch 1022/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9641 - bpp: 1.1283 - mse: 1.1205e-04\n",
      "Epoch 1022: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9641 - bpp: 1.1283 - mse: 1.1205e-04\n",
      "Epoch 1023/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0309 - bpp: 1.1324 - mse: 1.1588e-04\n",
      "Epoch 1023: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0309 - bpp: 1.1324 - mse: 1.1588e-04\n",
      "Epoch 1024/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4856 - bpp: 1.1530 - mse: 1.4237e-04\n",
      "Epoch 1024: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.4856 - bpp: 1.1530 - mse: 1.4237e-04\n",
      "Epoch 1025/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1343 - bpp: 1.1243 - mse: 1.2268e-04\n",
      "Epoch 1025: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1343 - bpp: 1.1243 - mse: 1.2268e-04\n",
      "Epoch 1026/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9956 - bpp: 1.1426 - mse: 1.1310e-04\n",
      "Epoch 1026: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9956 - bpp: 1.1426 - mse: 1.1310e-04\n",
      "Epoch 1027/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3525 - bpp: 1.1505 - mse: 1.3440e-04\n",
      "Epoch 1027: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3525 - bpp: 1.1505 - mse: 1.3440e-04\n",
      "Epoch 1028/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1146 - bpp: 1.1508 - mse: 1.1986e-04\n",
      "Epoch 1028: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.1146 - bpp: 1.1508 - mse: 1.1986e-04\n",
      "Epoch 1029/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7093 - bpp: 1.0963 - mse: 9.8451e-05\n",
      "Epoch 1029: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.7093 - bpp: 1.0963 - mse: 9.8451e-05\n",
      "Epoch 1030/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8096 - bpp: 1.1112 - mse: 1.0366e-04\n",
      "Epoch 1030: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8096 - bpp: 1.1112 - mse: 1.0366e-04\n",
      "Epoch 1031/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4004 - bpp: 1.1600 - mse: 1.3675e-04\n",
      "Epoch 1031: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.4004 - bpp: 1.1600 - mse: 1.3675e-04\n",
      "Epoch 1032/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0078 - bpp: 1.1332 - mse: 1.1441e-04\n",
      "Epoch 1032: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0078 - bpp: 1.1332 - mse: 1.1441e-04\n",
      "Epoch 1033/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1567 - bpp: 1.1348 - mse: 1.2341e-04\n",
      "Epoch 1033: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1567 - bpp: 1.1348 - mse: 1.2341e-04\n",
      "Epoch 1034/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0061 - bpp: 1.1199 - mse: 1.1513e-04\n",
      "Epoch 1034: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0061 - bpp: 1.1199 - mse: 1.1513e-04\n",
      "Epoch 1035/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1556 - bpp: 1.1367 - mse: 1.2323e-04\n",
      "Epoch 1035: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1556 - bpp: 1.1367 - mse: 1.2323e-04\n",
      "Epoch 1036/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1806 - bpp: 1.1498 - mse: 1.2395e-04\n",
      "Epoch 1036: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1806 - bpp: 1.1498 - mse: 1.2395e-04\n",
      "Epoch 1037/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4810 - bpp: 1.1735 - mse: 1.4084e-04\n",
      "Epoch 1037: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.4810 - bpp: 1.1735 - mse: 1.4084e-04\n",
      "Epoch 1038/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1228 - bpp: 1.1302 - mse: 1.2161e-04\n",
      "Epoch 1038: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1228 - bpp: 1.1302 - mse: 1.2161e-04\n",
      "Epoch 1039/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2705 - bpp: 1.1503 - mse: 1.2941e-04\n",
      "Epoch 1039: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.2705 - bpp: 1.1503 - mse: 1.2941e-04\n",
      "Epoch 1040/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8585 - bpp: 1.1057 - mse: 1.0698e-04\n",
      "Epoch 1040: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8585 - bpp: 1.1057 - mse: 1.0698e-04\n",
      "Epoch 1041/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1970 - bpp: 1.1464 - mse: 1.2516e-04\n",
      "Epoch 1041: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1970 - bpp: 1.1464 - mse: 1.2516e-04\n",
      "Epoch 1042/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8574 - bpp: 1.1149 - mse: 1.0636e-04\n",
      "Epoch 1042: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.8574 - bpp: 1.1149 - mse: 1.0636e-04\n",
      "Epoch 1043/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6952 - bpp: 1.1100 - mse: 9.6750e-05\n",
      "Epoch 1043: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 2.6952 - bpp: 1.1100 - mse: 9.6750e-05\n",
      "Epoch 1044/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9939 - bpp: 1.1356 - mse: 1.1342e-04\n",
      "Epoch 1044: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9939 - bpp: 1.1356 - mse: 1.1342e-04\n",
      "Epoch 1045/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2296 - bpp: 1.1447 - mse: 1.2725e-04\n",
      "Epoch 1045: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 250ms/step - loss: 3.2296 - bpp: 1.1447 - mse: 1.2725e-04\n",
      "Epoch 1046/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0667 - bpp: 1.1283 - mse: 1.1831e-04\n",
      "Epoch 1046: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0667 - bpp: 1.1283 - mse: 1.1831e-04\n",
      "Epoch 1047/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7261 - bpp: 1.1025 - mse: 9.9094e-05\n",
      "Epoch 1047: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7261 - bpp: 1.1025 - mse: 9.9094e-05\n",
      "Epoch 1048/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8441 - bpp: 1.1037 - mse: 1.0623e-04\n",
      "Epoch 1048: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8441 - bpp: 1.1037 - mse: 1.0623e-04\n",
      "Epoch 1049/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0137 - bpp: 1.1342 - mse: 1.1471e-04\n",
      "Epoch 1049: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0137 - bpp: 1.1342 - mse: 1.1471e-04\n",
      "Epoch 1050/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1385 - bpp: 1.1415 - mse: 1.2189e-04\n",
      "Epoch 1050: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1385 - bpp: 1.1415 - mse: 1.2189e-04\n",
      "Epoch 1051/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9095 - bpp: 1.1140 - mse: 1.0959e-04\n",
      "Epoch 1051: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9095 - bpp: 1.1140 - mse: 1.0959e-04\n",
      "Epoch 1052/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3867 - bpp: 1.1739 - mse: 1.3506e-04\n",
      "Epoch 1052: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.3867 - bpp: 1.1739 - mse: 1.3506e-04\n",
      "Epoch 1053/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0835 - bpp: 1.1389 - mse: 1.1869e-04\n",
      "Epoch 1053: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0835 - bpp: 1.1389 - mse: 1.1869e-04\n",
      "Epoch 1054/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8310 - bpp: 1.1281 - mse: 1.0394e-04\n",
      "Epoch 1054: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 2.8310 - bpp: 1.1281 - mse: 1.0394e-04\n",
      "Epoch 1055/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0424 - bpp: 1.1127 - mse: 1.1778e-04\n",
      "Epoch 1055: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0424 - bpp: 1.1127 - mse: 1.1778e-04\n",
      "Epoch 1056/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2029 - bpp: 1.1463 - mse: 1.2553e-04\n",
      "Epoch 1056: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2029 - bpp: 1.1463 - mse: 1.2553e-04\n",
      "Epoch 1057/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8779 - bpp: 1.1372 - mse: 1.0624e-04\n",
      "Epoch 1057: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8779 - bpp: 1.1372 - mse: 1.0624e-04\n",
      "Epoch 1058/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0612 - bpp: 1.1144 - mse: 1.1882e-04\n",
      "Epoch 1058: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0612 - bpp: 1.1144 - mse: 1.1882e-04\n",
      "Epoch 1059/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9650 - bpp: 1.1147 - mse: 1.1294e-04\n",
      "Epoch 1059: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9650 - bpp: 1.1147 - mse: 1.1294e-04\n",
      "Epoch 1060/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0264 - bpp: 1.1381 - mse: 1.1525e-04\n",
      "Epoch 1060: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0264 - bpp: 1.1381 - mse: 1.1525e-04\n",
      "Epoch 1061/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8525 - bpp: 1.1190 - mse: 1.0580e-04\n",
      "Epoch 1061: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8525 - bpp: 1.1190 - mse: 1.0580e-04\n",
      "Epoch 1062/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9804 - bpp: 1.1183 - mse: 1.1365e-04\n",
      "Epoch 1062: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9804 - bpp: 1.1183 - mse: 1.1365e-04\n",
      "Epoch 1063/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0161 - bpp: 1.1157 - mse: 1.1599e-04\n",
      "Epoch 1063: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0161 - bpp: 1.1157 - mse: 1.1599e-04\n",
      "Epoch 1064/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2708 - bpp: 1.1293 - mse: 1.3071e-04\n",
      "Epoch 1064: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.2708 - bpp: 1.1293 - mse: 1.3071e-04\n",
      "Epoch 1065/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2303 - bpp: 1.1598 - mse: 1.2638e-04\n",
      "Epoch 1065: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2303 - bpp: 1.1598 - mse: 1.2638e-04\n",
      "Epoch 1066/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8536 - bpp: 1.1154 - mse: 1.0609e-04\n",
      "Epoch 1066: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8536 - bpp: 1.1154 - mse: 1.0609e-04\n",
      "Epoch 1067/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0677 - bpp: 1.1211 - mse: 1.1881e-04\n",
      "Epoch 1067: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0677 - bpp: 1.1211 - mse: 1.1881e-04\n",
      "Epoch 1068/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9206 - bpp: 1.1040 - mse: 1.1087e-04\n",
      "Epoch 1068: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9206 - bpp: 1.1040 - mse: 1.1087e-04\n",
      "Epoch 1069/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9785 - bpp: 1.1249 - mse: 1.1313e-04\n",
      "Epoch 1069: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9785 - bpp: 1.1249 - mse: 1.1313e-04\n",
      "Epoch 1070/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1420 - bpp: 1.1530 - mse: 1.2140e-04\n",
      "Epoch 1070: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1420 - bpp: 1.1530 - mse: 1.2140e-04\n",
      "Epoch 1071/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2470 - bpp: 1.1499 - mse: 1.2800e-04\n",
      "Epoch 1071: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 258ms/step - loss: 3.2470 - bpp: 1.1499 - mse: 1.2800e-04\n",
      "Epoch 1072/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0051 - bpp: 1.1208 - mse: 1.1501e-04\n",
      "Epoch 1072: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0051 - bpp: 1.1208 - mse: 1.1501e-04\n",
      "Epoch 1073/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1364 - bpp: 1.1234 - mse: 1.2287e-04\n",
      "Epoch 1073: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1364 - bpp: 1.1234 - mse: 1.2287e-04\n",
      "Epoch 1074/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7526 - bpp: 1.0998 - mse: 1.0087e-04\n",
      "Epoch 1074: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.7526 - bpp: 1.0998 - mse: 1.0087e-04\n",
      "Epoch 1075/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1430 - bpp: 1.1437 - mse: 1.2203e-04\n",
      "Epoch 1075: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1430 - bpp: 1.1437 - mse: 1.2203e-04\n",
      "Epoch 1076/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8139 - bpp: 1.1041 - mse: 1.0436e-04\n",
      "Epoch 1076: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8139 - bpp: 1.1041 - mse: 1.0436e-04\n",
      "Epoch 1077/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1847 - bpp: 1.1482 - mse: 1.2430e-04\n",
      "Epoch 1077: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1847 - bpp: 1.1482 - mse: 1.2430e-04\n",
      "Epoch 1078/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0918 - bpp: 1.1438 - mse: 1.1890e-04\n",
      "Epoch 1078: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0918 - bpp: 1.1438 - mse: 1.1890e-04\n",
      "Epoch 1079/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0982 - bpp: 1.1341 - mse: 1.1988e-04\n",
      "Epoch 1079: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.0982 - bpp: 1.1341 - mse: 1.1988e-04\n",
      "Epoch 1080/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8560 - bpp: 1.1024 - mse: 1.0703e-04\n",
      "Epoch 1080: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8560 - bpp: 1.1024 - mse: 1.0703e-04\n",
      "Epoch 1081/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0680 - bpp: 1.1227 - mse: 1.1873e-04\n",
      "Epoch 1081: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0680 - bpp: 1.1227 - mse: 1.1873e-04\n",
      "Epoch 1082/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2332 - bpp: 1.1425 - mse: 1.2761e-04\n",
      "Epoch 1082: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.2332 - bpp: 1.1425 - mse: 1.2761e-04\n",
      "Epoch 1083/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2355 - bpp: 1.1131 - mse: 1.2954e-04\n",
      "Epoch 1083: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 259ms/step - loss: 3.2355 - bpp: 1.1131 - mse: 1.2954e-04\n",
      "Epoch 1084/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8476 - bpp: 1.1292 - mse: 1.0488e-04\n",
      "Epoch 1084: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8476 - bpp: 1.1292 - mse: 1.0488e-04\n",
      "Epoch 1085/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9388 - bpp: 1.1133 - mse: 1.1142e-04\n",
      "Epoch 1085: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9388 - bpp: 1.1133 - mse: 1.1142e-04\n",
      "Epoch 1086/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7898 - bpp: 1.0877 - mse: 1.0388e-04\n",
      "Epoch 1086: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.7898 - bpp: 1.0877 - mse: 1.0388e-04\n",
      "Epoch 1087/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1680 - bpp: 1.1424 - mse: 1.2363e-04\n",
      "Epoch 1087: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1680 - bpp: 1.1424 - mse: 1.2363e-04\n",
      "Epoch 1088/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8733 - bpp: 1.1219 - mse: 1.0690e-04\n",
      "Epoch 1088: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.8733 - bpp: 1.1219 - mse: 1.0690e-04\n",
      "Epoch 1089/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1707 - bpp: 1.1485 - mse: 1.2342e-04\n",
      "Epoch 1089: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1707 - bpp: 1.1485 - mse: 1.2342e-04\n",
      "Epoch 1090/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2327 - bpp: 1.1415 - mse: 1.2763e-04\n",
      "Epoch 1090: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2327 - bpp: 1.1415 - mse: 1.2763e-04\n",
      "Epoch 1091/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0806 - bpp: 1.1291 - mse: 1.1911e-04\n",
      "Epoch 1091: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0806 - bpp: 1.1291 - mse: 1.1911e-04\n",
      "Epoch 1092/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0161 - bpp: 1.1248 - mse: 1.1544e-04\n",
      "Epoch 1092: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.0161 - bpp: 1.1248 - mse: 1.1544e-04\n",
      "Epoch 1093/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8429 - bpp: 1.1157 - mse: 1.0542e-04\n",
      "Epoch 1093: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8429 - bpp: 1.1157 - mse: 1.0542e-04\n",
      "Epoch 1094/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7568 - bpp: 1.0981 - mse: 1.0124e-04\n",
      "Epoch 1094: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7568 - bpp: 1.0981 - mse: 1.0124e-04\n",
      "Epoch 1095/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7802 - bpp: 1.1102 - mse: 1.0193e-04\n",
      "Epoch 1095: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7802 - bpp: 1.1102 - mse: 1.0193e-04\n",
      "Epoch 1096/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1179 - bpp: 1.1390 - mse: 1.2078e-04\n",
      "Epoch 1096: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1179 - bpp: 1.1390 - mse: 1.2078e-04\n",
      "Epoch 1097/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8980 - bpp: 1.1096 - mse: 1.0916e-04\n",
      "Epoch 1097: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8980 - bpp: 1.1096 - mse: 1.0916e-04\n",
      "Epoch 1098/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1298 - bpp: 1.1343 - mse: 1.2180e-04\n",
      "Epoch 1098: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1298 - bpp: 1.1343 - mse: 1.2180e-04\n",
      "Epoch 1099/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9975 - bpp: 1.1024 - mse: 1.1566e-04\n",
      "Epoch 1099: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.9975 - bpp: 1.1024 - mse: 1.1566e-04\n",
      "Epoch 1100/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9159 - bpp: 1.1067 - mse: 1.1043e-04\n",
      "Epoch 1100: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9159 - bpp: 1.1067 - mse: 1.1043e-04\n",
      "Epoch 1101/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8330 - bpp: 1.1126 - mse: 1.0500e-04\n",
      "Epoch 1101: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.8330 - bpp: 1.1126 - mse: 1.0500e-04\n",
      "Epoch 1102/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2860 - bpp: 1.1567 - mse: 1.2996e-04\n",
      "Epoch 1102: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.2860 - bpp: 1.1567 - mse: 1.2996e-04\n",
      "Epoch 1103/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0162 - bpp: 1.1479 - mse: 1.1404e-04\n",
      "Epoch 1103: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0162 - bpp: 1.1479 - mse: 1.1404e-04\n",
      "Epoch 1104/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3944 - bpp: 1.1494 - mse: 1.3702e-04\n",
      "Epoch 1104: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.3944 - bpp: 1.1494 - mse: 1.3702e-04\n",
      "Epoch 1105/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1495 - bpp: 1.1461 - mse: 1.2227e-04\n",
      "Epoch 1105: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1495 - bpp: 1.1461 - mse: 1.2227e-04\n",
      "Epoch 1106/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0851 - bpp: 1.1316 - mse: 1.1923e-04\n",
      "Epoch 1106: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0851 - bpp: 1.1316 - mse: 1.1923e-04\n",
      "Epoch 1107/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0015 - bpp: 1.1252 - mse: 1.1453e-04\n",
      "Epoch 1107: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.0015 - bpp: 1.1252 - mse: 1.1453e-04\n",
      "Epoch 1108/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1003 - bpp: 1.1358 - mse: 1.1990e-04\n",
      "Epoch 1108: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1003 - bpp: 1.1358 - mse: 1.1990e-04\n",
      "Epoch 1109/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9060 - bpp: 1.1242 - mse: 1.0875e-04\n",
      "Epoch 1109: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9060 - bpp: 1.1242 - mse: 1.0875e-04\n",
      "Epoch 1110/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1213 - bpp: 1.1269 - mse: 1.2173e-04\n",
      "Epoch 1110: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.1213 - bpp: 1.1269 - mse: 1.2173e-04\n",
      "Epoch 1111/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9810 - bpp: 1.1373 - mse: 1.1253e-04\n",
      "Epoch 1111: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9810 - bpp: 1.1373 - mse: 1.1253e-04\n",
      "Epoch 1112/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0942 - bpp: 1.1475 - mse: 1.1882e-04\n",
      "Epoch 1112: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0942 - bpp: 1.1475 - mse: 1.1882e-04\n",
      "Epoch 1113/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0496 - bpp: 1.1397 - mse: 1.1657e-04\n",
      "Epoch 1113: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0496 - bpp: 1.1397 - mse: 1.1657e-04\n",
      "Epoch 1114/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1275 - bpp: 1.1304 - mse: 1.2189e-04\n",
      "Epoch 1114: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1275 - bpp: 1.1304 - mse: 1.2189e-04\n",
      "Epoch 1115/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1708 - bpp: 1.1509 - mse: 1.2328e-04\n",
      "Epoch 1115: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1708 - bpp: 1.1509 - mse: 1.2328e-04\n",
      "Epoch 1116/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0561 - bpp: 1.1118 - mse: 1.1867e-04\n",
      "Epoch 1116: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0561 - bpp: 1.1118 - mse: 1.1867e-04\n",
      "Epoch 1117/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8646 - bpp: 1.1009 - mse: 1.0764e-04\n",
      "Epoch 1117: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8646 - bpp: 1.1009 - mse: 1.0764e-04\n",
      "Epoch 1118/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1142 - bpp: 1.1451 - mse: 1.2019e-04\n",
      "Epoch 1118: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.1142 - bpp: 1.1451 - mse: 1.2019e-04\n",
      "Epoch 1119/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0950 - bpp: 1.1466 - mse: 1.1892e-04\n",
      "Epoch 1119: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0950 - bpp: 1.1466 - mse: 1.1892e-04\n",
      "Epoch 1120/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9487 - bpp: 1.1404 - mse: 1.1037e-04\n",
      "Epoch 1120: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.9487 - bpp: 1.1404 - mse: 1.1037e-04\n",
      "Epoch 1121/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8015 - bpp: 1.0967 - mse: 1.0405e-04\n",
      "Epoch 1121: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.8015 - bpp: 1.0967 - mse: 1.0405e-04\n",
      "Epoch 1122/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5599 - bpp: 1.1591 - mse: 1.4653e-04\n",
      "Epoch 1122: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 3.5599 - bpp: 1.1591 - mse: 1.4653e-04\n",
      "Epoch 1123/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0722 - bpp: 1.1429 - mse: 1.1775e-04\n",
      "Epoch 1123: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0722 - bpp: 1.1429 - mse: 1.1775e-04\n",
      "Epoch 1124/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1161 - bpp: 1.1376 - mse: 1.2076e-04\n",
      "Epoch 1124: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.1161 - bpp: 1.1376 - mse: 1.2076e-04\n",
      "Epoch 1125/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7487 - bpp: 1.1010 - mse: 1.0057e-04\n",
      "Epoch 1125: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7487 - bpp: 1.1010 - mse: 1.0057e-04\n",
      "Epoch 1126/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7876 - bpp: 1.0923 - mse: 1.0347e-04\n",
      "Epoch 1126: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7876 - bpp: 1.0923 - mse: 1.0347e-04\n",
      "Epoch 1127/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8596 - bpp: 1.0905 - mse: 1.0798e-04\n",
      "Epoch 1127: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8596 - bpp: 1.0905 - mse: 1.0798e-04\n",
      "Epoch 1128/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3522 - bpp: 1.1673 - mse: 1.3336e-04\n",
      "Epoch 1128: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3522 - bpp: 1.1673 - mse: 1.3336e-04\n",
      "Epoch 1129/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0746 - bpp: 1.1189 - mse: 1.1937e-04\n",
      "Epoch 1129: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0746 - bpp: 1.1189 - mse: 1.1937e-04\n",
      "Epoch 1130/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8610 - bpp: 1.1376 - mse: 1.0519e-04\n",
      "Epoch 1130: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.8610 - bpp: 1.1376 - mse: 1.0519e-04\n",
      "Epoch 1131/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9029 - bpp: 1.1275 - mse: 1.0837e-04\n",
      "Epoch 1131: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9029 - bpp: 1.1275 - mse: 1.0837e-04\n",
      "Epoch 1132/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2309 - bpp: 1.1314 - mse: 1.2815e-04\n",
      "Epoch 1132: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.2309 - bpp: 1.1314 - mse: 1.2815e-04\n",
      "Epoch 1133/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8931 - bpp: 1.1133 - mse: 1.0863e-04\n",
      "Epoch 1133: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8931 - bpp: 1.1133 - mse: 1.0863e-04\n",
      "Epoch 1134/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2249 - bpp: 1.1373 - mse: 1.2742e-04\n",
      "Epoch 1134: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 3.2249 - bpp: 1.1373 - mse: 1.2742e-04\n",
      "Epoch 1135/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9393 - bpp: 1.1286 - mse: 1.1051e-04\n",
      "Epoch 1135: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 2.9393 - bpp: 1.1286 - mse: 1.1051e-04\n",
      "Epoch 1136/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8248 - bpp: 1.1222 - mse: 1.0391e-04\n",
      "Epoch 1136: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8248 - bpp: 1.1222 - mse: 1.0391e-04\n",
      "Epoch 1137/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2728 - bpp: 1.1500 - mse: 1.2956e-04\n",
      "Epoch 1137: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.2728 - bpp: 1.1500 - mse: 1.2956e-04\n",
      "Epoch 1138/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8567 - bpp: 1.0915 - mse: 1.0774e-04\n",
      "Epoch 1138: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 2.8567 - bpp: 1.0915 - mse: 1.0774e-04\n",
      "Epoch 1139/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7934 - bpp: 1.1140 - mse: 1.0250e-04\n",
      "Epoch 1139: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7934 - bpp: 1.1140 - mse: 1.0250e-04\n",
      "Epoch 1140/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2925 - bpp: 1.1569 - mse: 1.3035e-04\n",
      "Epoch 1140: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2925 - bpp: 1.1569 - mse: 1.3035e-04\n",
      "Epoch 1141/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1550 - bpp: 1.1411 - mse: 1.2292e-04\n",
      "Epoch 1141: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1550 - bpp: 1.1411 - mse: 1.2292e-04\n",
      "Epoch 1142/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9743 - bpp: 1.1365 - mse: 1.1217e-04\n",
      "Epoch 1142: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.9743 - bpp: 1.1365 - mse: 1.1217e-04\n",
      "Epoch 1143/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2740 - bpp: 1.1671 - mse: 1.2859e-04\n",
      "Epoch 1143: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.2740 - bpp: 1.1671 - mse: 1.2859e-04\n",
      "Epoch 1144/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1772 - bpp: 1.1432 - mse: 1.2415e-04\n",
      "Epoch 1144: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1772 - bpp: 1.1432 - mse: 1.2415e-04\n",
      "Epoch 1145/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0389 - bpp: 1.1298 - mse: 1.1652e-04\n",
      "Epoch 1145: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0389 - bpp: 1.1298 - mse: 1.1652e-04\n",
      "Epoch 1146/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0013 - bpp: 1.1196 - mse: 1.1485e-04\n",
      "Epoch 1146: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0013 - bpp: 1.1196 - mse: 1.1485e-04\n",
      "Epoch 1147/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9831 - bpp: 1.1321 - mse: 1.1298e-04\n",
      "Epoch 1147: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 2.9831 - bpp: 1.1321 - mse: 1.1298e-04\n",
      "Epoch 1148/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9908 - bpp: 1.1300 - mse: 1.1358e-04\n",
      "Epoch 1148: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9908 - bpp: 1.1300 - mse: 1.1358e-04\n",
      "Epoch 1149/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0244 - bpp: 1.1267 - mse: 1.1583e-04\n",
      "Epoch 1149: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 3.0244 - bpp: 1.1267 - mse: 1.1583e-04\n",
      "Epoch 1150/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9330 - bpp: 1.0979 - mse: 1.1201e-04\n",
      "Epoch 1150: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.9330 - bpp: 1.0979 - mse: 1.1201e-04\n",
      "Epoch 1151/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2332 - bpp: 1.1509 - mse: 1.2709e-04\n",
      "Epoch 1151: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2332 - bpp: 1.1509 - mse: 1.2709e-04\n",
      "Epoch 1152/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8640 - bpp: 1.1191 - mse: 1.0650e-04\n",
      "Epoch 1152: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8640 - bpp: 1.1191 - mse: 1.0650e-04\n",
      "Epoch 1153/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8637 - bpp: 1.1149 - mse: 1.0674e-04\n",
      "Epoch 1153: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8637 - bpp: 1.1149 - mse: 1.0674e-04\n",
      "Epoch 1154/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0582 - bpp: 1.1238 - mse: 1.1806e-04\n",
      "Epoch 1154: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0582 - bpp: 1.1238 - mse: 1.1806e-04\n",
      "Epoch 1155/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0848 - bpp: 1.1376 - mse: 1.1885e-04\n",
      "Epoch 1155: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0848 - bpp: 1.1376 - mse: 1.1885e-04\n",
      "Epoch 1156/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0838 - bpp: 1.1326 - mse: 1.1909e-04\n",
      "Epoch 1156: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0838 - bpp: 1.1326 - mse: 1.1909e-04\n",
      "Epoch 1157/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0741 - bpp: 1.1324 - mse: 1.1851e-04\n",
      "Epoch 1157: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0741 - bpp: 1.1324 - mse: 1.1851e-04\n",
      "Epoch 1158/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0822 - bpp: 1.1342 - mse: 1.1889e-04\n",
      "Epoch 1158: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0822 - bpp: 1.1342 - mse: 1.1889e-04\n",
      "Epoch 1159/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0797 - bpp: 1.1484 - mse: 1.1787e-04\n",
      "Epoch 1159: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0797 - bpp: 1.1484 - mse: 1.1787e-04\n",
      "Epoch 1160/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0166 - bpp: 1.1047 - mse: 1.1669e-04\n",
      "Epoch 1160: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0166 - bpp: 1.1047 - mse: 1.1669e-04\n",
      "Epoch 1161/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7800 - bpp: 1.1061 - mse: 1.0217e-04\n",
      "Epoch 1161: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.7800 - bpp: 1.1061 - mse: 1.0217e-04\n",
      "Epoch 1162/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1291 - bpp: 1.1176 - mse: 1.2277e-04\n",
      "Epoch 1162: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1291 - bpp: 1.1176 - mse: 1.2277e-04\n",
      "Epoch 1163/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0072 - bpp: 1.1261 - mse: 1.1481e-04\n",
      "Epoch 1163: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.0072 - bpp: 1.1261 - mse: 1.1481e-04\n",
      "Epoch 1164/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8906 - bpp: 1.1130 - mse: 1.0850e-04\n",
      "Epoch 1164: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8906 - bpp: 1.1130 - mse: 1.0850e-04\n",
      "Epoch 1165/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3541 - bpp: 1.1443 - mse: 1.3488e-04\n",
      "Epoch 1165: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 3.3541 - bpp: 1.1443 - mse: 1.3488e-04\n",
      "Epoch 1166/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0794 - bpp: 1.1308 - mse: 1.1894e-04\n",
      "Epoch 1166: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0794 - bpp: 1.1308 - mse: 1.1894e-04\n",
      "Epoch 1167/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8734 - bpp: 1.1165 - mse: 1.0723e-04\n",
      "Epoch 1167: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 238ms/step - loss: 2.8734 - bpp: 1.1165 - mse: 1.0723e-04\n",
      "Epoch 1168/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1612 - bpp: 1.1263 - mse: 1.2420e-04\n",
      "Epoch 1168: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.1612 - bpp: 1.1263 - mse: 1.2420e-04\n",
      "Epoch 1169/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0476 - bpp: 1.1274 - mse: 1.1720e-04\n",
      "Epoch 1169: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0476 - bpp: 1.1274 - mse: 1.1720e-04\n",
      "Epoch 1170/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1484 - bpp: 1.1311 - mse: 1.2313e-04\n",
      "Epoch 1170: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1484 - bpp: 1.1311 - mse: 1.2313e-04\n",
      "Epoch 1171/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8455 - bpp: 1.1098 - mse: 1.0594e-04\n",
      "Epoch 1171: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8455 - bpp: 1.1098 - mse: 1.0594e-04\n",
      "Epoch 1172/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7565 - bpp: 1.0954 - mse: 1.0139e-04\n",
      "Epoch 1172: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.7565 - bpp: 1.0954 - mse: 1.0139e-04\n",
      "Epoch 1173/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0541 - bpp: 1.1396 - mse: 1.1685e-04\n",
      "Epoch 1173: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0541 - bpp: 1.1396 - mse: 1.1685e-04\n",
      "Epoch 1174/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1428 - bpp: 1.1477 - mse: 1.2177e-04\n",
      "Epoch 1174: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1428 - bpp: 1.1477 - mse: 1.2177e-04\n",
      "Epoch 1175/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7903 - bpp: 1.1076 - mse: 1.0270e-04\n",
      "Epoch 1175: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7903 - bpp: 1.1076 - mse: 1.0270e-04\n",
      "Epoch 1176/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3625 - bpp: 1.1579 - mse: 1.3456e-04\n",
      "Epoch 1176: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.3625 - bpp: 1.1579 - mse: 1.3456e-04\n",
      "Epoch 1177/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8973 - bpp: 1.1084 - mse: 1.0919e-04\n",
      "Epoch 1177: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8973 - bpp: 1.1084 - mse: 1.0919e-04\n",
      "Epoch 1178/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2368 - bpp: 1.1392 - mse: 1.2803e-04\n",
      "Epoch 1178: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2368 - bpp: 1.1392 - mse: 1.2803e-04\n",
      "Epoch 1179/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0757 - bpp: 1.1242 - mse: 1.1911e-04\n",
      "Epoch 1179: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.0757 - bpp: 1.1242 - mse: 1.1911e-04\n",
      "Epoch 1180/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1432 - bpp: 1.1420 - mse: 1.2214e-04\n",
      "Epoch 1180: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.1432 - bpp: 1.1420 - mse: 1.2214e-04\n",
      "Epoch 1181/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1552 - bpp: 1.1224 - mse: 1.2407e-04\n",
      "Epoch 1181: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1552 - bpp: 1.1224 - mse: 1.2407e-04\n",
      "Epoch 1182/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3345 - bpp: 1.1285 - mse: 1.3465e-04\n",
      "Epoch 1182: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.3345 - bpp: 1.1285 - mse: 1.3465e-04\n",
      "Epoch 1183/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8844 - bpp: 1.1410 - mse: 1.0641e-04\n",
      "Epoch 1183: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8844 - bpp: 1.1410 - mse: 1.0641e-04\n",
      "Epoch 1184/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2919 - bpp: 1.1589 - mse: 1.3019e-04\n",
      "Epoch 1184: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.2919 - bpp: 1.1589 - mse: 1.3019e-04\n",
      "Epoch 1185/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0676 - bpp: 1.1206 - mse: 1.1883e-04\n",
      "Epoch 1185: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.0676 - bpp: 1.1206 - mse: 1.1883e-04\n",
      "Epoch 1186/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8870 - bpp: 1.0985 - mse: 1.0916e-04\n",
      "Epoch 1186: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.8870 - bpp: 1.0985 - mse: 1.0916e-04\n",
      "Epoch 1187/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0427 - bpp: 1.1196 - mse: 1.1738e-04\n",
      "Epoch 1187: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 3.0427 - bpp: 1.1196 - mse: 1.1738e-04\n",
      "Epoch 1188/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6070 - bpp: 1.0879 - mse: 9.2719e-05\n",
      "Epoch 1188: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.6070 - bpp: 1.0879 - mse: 9.2719e-05\n",
      "Epoch 1189/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1778 - bpp: 1.1333 - mse: 1.2479e-04\n",
      "Epoch 1189: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1778 - bpp: 1.1333 - mse: 1.2479e-04\n",
      "Epoch 1190/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0309 - bpp: 1.1217 - mse: 1.1653e-04\n",
      "Epoch 1190: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.0309 - bpp: 1.1217 - mse: 1.1653e-04\n",
      "Epoch 1191/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1771 - bpp: 1.1576 - mse: 1.2326e-04\n",
      "Epoch 1191: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 264ms/step - loss: 3.1771 - bpp: 1.1576 - mse: 1.2326e-04\n",
      "Epoch 1192/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1350 - bpp: 1.1519 - mse: 1.2104e-04\n",
      "Epoch 1192: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1350 - bpp: 1.1519 - mse: 1.2104e-04\n",
      "Epoch 1193/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.6469 - bpp: 1.1506 - mse: 1.5236e-04\n",
      "Epoch 1193: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.6469 - bpp: 1.1506 - mse: 1.5236e-04\n",
      "Epoch 1194/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0180 - bpp: 1.1217 - mse: 1.1574e-04\n",
      "Epoch 1194: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0180 - bpp: 1.1217 - mse: 1.1574e-04\n",
      "Epoch 1195/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0827 - bpp: 1.1112 - mse: 1.2033e-04\n",
      "Epoch 1195: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0827 - bpp: 1.1112 - mse: 1.2033e-04\n",
      "Epoch 1196/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7602 - bpp: 1.0978 - mse: 1.0147e-04\n",
      "Epoch 1196: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7602 - bpp: 1.0978 - mse: 1.0147e-04\n",
      "Epoch 1197/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4349 - bpp: 1.1630 - mse: 1.3867e-04\n",
      "Epoch 1197: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.4349 - bpp: 1.1630 - mse: 1.3867e-04\n",
      "Epoch 1198/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9645 - bpp: 1.1361 - mse: 1.1160e-04\n",
      "Epoch 1198: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9645 - bpp: 1.1361 - mse: 1.1160e-04\n",
      "Epoch 1199/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9988 - bpp: 1.1151 - mse: 1.1497e-04\n",
      "Epoch 1199: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9988 - bpp: 1.1151 - mse: 1.1497e-04\n",
      "Epoch 1200/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9360 - bpp: 1.1029 - mse: 1.1188e-04\n",
      "Epoch 1200: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9360 - bpp: 1.1029 - mse: 1.1188e-04\n",
      "Epoch 1201/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8998 - bpp: 1.1359 - mse: 1.0766e-04\n",
      "Epoch 1201: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.8998 - bpp: 1.1359 - mse: 1.0766e-04\n",
      "Epoch 1202/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9169 - bpp: 1.1105 - mse: 1.1025e-04\n",
      "Epoch 1202: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9169 - bpp: 1.1105 - mse: 1.1025e-04\n",
      "Epoch 1203/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2487 - bpp: 1.1415 - mse: 1.2861e-04\n",
      "Epoch 1203: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.2487 - bpp: 1.1415 - mse: 1.2861e-04\n",
      "Epoch 1204/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5046 - bpp: 1.1486 - mse: 1.4380e-04\n",
      "Epoch 1204: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.5046 - bpp: 1.1486 - mse: 1.4380e-04\n",
      "Epoch 1205/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1434 - bpp: 1.1382 - mse: 1.2239e-04\n",
      "Epoch 1205: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 3.1434 - bpp: 1.1382 - mse: 1.2239e-04\n",
      "Epoch 1206/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1291 - bpp: 1.1306 - mse: 1.2198e-04\n",
      "Epoch 1206: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1291 - bpp: 1.1306 - mse: 1.2198e-04\n",
      "Epoch 1207/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1766 - bpp: 1.1506 - mse: 1.2366e-04\n",
      "Epoch 1207: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1766 - bpp: 1.1506 - mse: 1.2366e-04\n",
      "Epoch 1208/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9704 - bpp: 1.1328 - mse: 1.1215e-04\n",
      "Epoch 1208: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9704 - bpp: 1.1328 - mse: 1.1215e-04\n",
      "Epoch 1209/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6808 - bpp: 1.0967 - mse: 9.6684e-05\n",
      "Epoch 1209: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.6808 - bpp: 1.0967 - mse: 9.6684e-05\n",
      "Epoch 1210/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9097 - bpp: 1.1099 - mse: 1.0985e-04\n",
      "Epoch 1210: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9097 - bpp: 1.1099 - mse: 1.0985e-04\n",
      "Epoch 1211/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1162 - bpp: 1.1380 - mse: 1.2074e-04\n",
      "Epoch 1211: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.1162 - bpp: 1.1380 - mse: 1.2074e-04\n",
      "Epoch 1212/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7317 - bpp: 1.1076 - mse: 9.9125e-05\n",
      "Epoch 1212: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.7317 - bpp: 1.1076 - mse: 9.9125e-05\n",
      "Epoch 1213/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8120 - bpp: 1.1145 - mse: 1.0360e-04\n",
      "Epoch 1213: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8120 - bpp: 1.1145 - mse: 1.0360e-04\n",
      "Epoch 1214/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9370 - bpp: 1.1101 - mse: 1.1150e-04\n",
      "Epoch 1214: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9370 - bpp: 1.1101 - mse: 1.1150e-04\n",
      "Epoch 1215/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9170 - bpp: 1.1092 - mse: 1.1034e-04\n",
      "Epoch 1215: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.9170 - bpp: 1.1092 - mse: 1.1034e-04\n",
      "Epoch 1216/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8860 - bpp: 1.1125 - mse: 1.0825e-04\n",
      "Epoch 1216: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8860 - bpp: 1.1125 - mse: 1.0825e-04\n",
      "Epoch 1217/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0907 - bpp: 1.1439 - mse: 1.1882e-04\n",
      "Epoch 1217: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0907 - bpp: 1.1439 - mse: 1.1882e-04\n",
      "Epoch 1218/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9825 - bpp: 1.1114 - mse: 1.1421e-04\n",
      "Epoch 1218: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.9825 - bpp: 1.1114 - mse: 1.1421e-04\n",
      "Epoch 1219/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7416 - bpp: 1.1036 - mse: 9.9972e-05\n",
      "Epoch 1219: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7416 - bpp: 1.1036 - mse: 9.9972e-05\n",
      "Epoch 1220/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1607 - bpp: 1.1359 - mse: 1.2359e-04\n",
      "Epoch 1220: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.1607 - bpp: 1.1359 - mse: 1.2359e-04\n",
      "Epoch 1221/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0831 - bpp: 1.1375 - mse: 1.1875e-04\n",
      "Epoch 1221: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0831 - bpp: 1.1375 - mse: 1.1875e-04\n",
      "Epoch 1222/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0194 - bpp: 1.1302 - mse: 1.1531e-04\n",
      "Epoch 1222: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0194 - bpp: 1.1302 - mse: 1.1531e-04\n",
      "Epoch 1223/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0090 - bpp: 1.1304 - mse: 1.1466e-04\n",
      "Epoch 1223: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0090 - bpp: 1.1304 - mse: 1.1466e-04\n",
      "Epoch 1224/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6989 - bpp: 1.1031 - mse: 9.7402e-05\n",
      "Epoch 1224: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.6989 - bpp: 1.1031 - mse: 9.7402e-05\n",
      "Epoch 1225/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9583 - bpp: 1.1259 - mse: 1.1184e-04\n",
      "Epoch 1225: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9583 - bpp: 1.1259 - mse: 1.1184e-04\n",
      "Epoch 1226/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1152 - bpp: 1.1495 - mse: 1.1998e-04\n",
      "Epoch 1226: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1152 - bpp: 1.1495 - mse: 1.1998e-04\n",
      "Epoch 1227/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2638 - bpp: 1.1392 - mse: 1.2968e-04\n",
      "Epoch 1227: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.2638 - bpp: 1.1392 - mse: 1.2968e-04\n",
      "Epoch 1228/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2084 - bpp: 1.1463 - mse: 1.2586e-04\n",
      "Epoch 1228: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2084 - bpp: 1.1463 - mse: 1.2586e-04\n",
      "Epoch 1229/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2740 - bpp: 1.1506 - mse: 1.2960e-04\n",
      "Epoch 1229: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 3.2740 - bpp: 1.1506 - mse: 1.2960e-04\n",
      "Epoch 1230/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9988 - bpp: 1.1385 - mse: 1.1355e-04\n",
      "Epoch 1230: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9988 - bpp: 1.1385 - mse: 1.1355e-04\n",
      "Epoch 1231/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6078 - bpp: 1.1086 - mse: 9.1501e-05\n",
      "Epoch 1231: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.6078 - bpp: 1.1086 - mse: 9.1501e-05\n",
      "Epoch 1232/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9604 - bpp: 1.1244 - mse: 1.1205e-04\n",
      "Epoch 1232: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9604 - bpp: 1.1244 - mse: 1.1205e-04\n",
      "Epoch 1233/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9887 - bpp: 1.1189 - mse: 1.1412e-04\n",
      "Epoch 1233: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9887 - bpp: 1.1189 - mse: 1.1412e-04\n",
      "Epoch 1234/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8646 - bpp: 1.1121 - mse: 1.0697e-04\n",
      "Epoch 1234: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8646 - bpp: 1.1121 - mse: 1.0697e-04\n",
      "Epoch 1235/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3399 - bpp: 1.1645 - mse: 1.3278e-04\n",
      "Epoch 1235: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 251ms/step - loss: 3.3399 - bpp: 1.1645 - mse: 1.3278e-04\n",
      "Epoch 1236/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9071 - bpp: 1.0869 - mse: 1.1110e-04\n",
      "Epoch 1236: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9071 - bpp: 1.0869 - mse: 1.1110e-04\n",
      "Epoch 1237/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8786 - bpp: 1.0964 - mse: 1.0878e-04\n",
      "Epoch 1237: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 2.8786 - bpp: 1.0964 - mse: 1.0878e-04\n",
      "Epoch 1238/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8820 - bpp: 1.1064 - mse: 1.0838e-04\n",
      "Epoch 1238: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8820 - bpp: 1.1064 - mse: 1.0838e-04\n",
      "Epoch 1239/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8380 - bpp: 1.1158 - mse: 1.0512e-04\n",
      "Epoch 1239: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8380 - bpp: 1.1158 - mse: 1.0512e-04\n",
      "Epoch 1240/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8718 - bpp: 1.1052 - mse: 1.0782e-04\n",
      "Epoch 1240: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 2.8718 - bpp: 1.1052 - mse: 1.0782e-04\n",
      "Epoch 1241/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0237 - bpp: 1.1426 - mse: 1.1482e-04\n",
      "Epoch 1241: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 3.0237 - bpp: 1.1426 - mse: 1.1482e-04\n",
      "Epoch 1242/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8545 - bpp: 1.1022 - mse: 1.0695e-04\n",
      "Epoch 1242: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8545 - bpp: 1.1022 - mse: 1.0695e-04\n",
      "Epoch 1243/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9469 - bpp: 1.1197 - mse: 1.1152e-04\n",
      "Epoch 1243: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.9469 - bpp: 1.1197 - mse: 1.1152e-04\n",
      "Epoch 1244/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0234 - bpp: 1.1378 - mse: 1.1509e-04\n",
      "Epoch 1244: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0234 - bpp: 1.1378 - mse: 1.1509e-04\n",
      "Epoch 1245/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7674 - bpp: 1.1152 - mse: 1.0085e-04\n",
      "Epoch 1245: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.7674 - bpp: 1.1152 - mse: 1.0085e-04\n",
      "Epoch 1246/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0118 - bpp: 1.1413 - mse: 1.1417e-04\n",
      "Epoch 1246: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0118 - bpp: 1.1413 - mse: 1.1417e-04\n",
      "Epoch 1247/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6853 - bpp: 1.0989 - mse: 9.6826e-05\n",
      "Epoch 1247: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.6853 - bpp: 1.0989 - mse: 9.6826e-05\n",
      "Epoch 1248/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7409 - bpp: 1.1035 - mse: 9.9939e-05\n",
      "Epoch 1248: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7409 - bpp: 1.1035 - mse: 9.9939e-05\n",
      "Epoch 1249/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1013 - bpp: 1.1406 - mse: 1.1967e-04\n",
      "Epoch 1249: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1013 - bpp: 1.1406 - mse: 1.1967e-04\n",
      "Epoch 1250/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7659 - bpp: 1.1013 - mse: 1.0160e-04\n",
      "Epoch 1250: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7659 - bpp: 1.1013 - mse: 1.0160e-04\n",
      "Epoch 1251/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9345 - bpp: 1.1323 - mse: 1.1000e-04\n",
      "Epoch 1251: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.9345 - bpp: 1.1323 - mse: 1.1000e-04\n",
      "Epoch 1252/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7893 - bpp: 1.0992 - mse: 1.0316e-04\n",
      "Epoch 1252: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7893 - bpp: 1.0992 - mse: 1.0316e-04\n",
      "Epoch 1253/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7816 - bpp: 1.1050 - mse: 1.0233e-04\n",
      "Epoch 1253: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.7816 - bpp: 1.1050 - mse: 1.0233e-04\n",
      "Epoch 1254/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2487 - bpp: 1.1409 - mse: 1.2865e-04\n",
      "Epoch 1254: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.2487 - bpp: 1.1409 - mse: 1.2865e-04\n",
      "Epoch 1255/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0923 - bpp: 1.1187 - mse: 1.2046e-04\n",
      "Epoch 1255: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0923 - bpp: 1.1187 - mse: 1.2046e-04\n",
      "Epoch 1256/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9632 - bpp: 1.1224 - mse: 1.1235e-04\n",
      "Epoch 1256: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.9632 - bpp: 1.1224 - mse: 1.1235e-04\n",
      "Epoch 1257/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6001 - bpp: 1.0955 - mse: 9.1838e-05\n",
      "Epoch 1257: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.6001 - bpp: 1.0955 - mse: 9.1838e-05\n",
      "Epoch 1258/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0979 - bpp: 1.1339 - mse: 1.1987e-04\n",
      "Epoch 1258: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 3.0979 - bpp: 1.1339 - mse: 1.1987e-04\n",
      "Epoch 1259/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6608 - bpp: 1.1053 - mse: 9.4940e-05\n",
      "Epoch 1259: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 2.6608 - bpp: 1.1053 - mse: 9.4940e-05\n",
      "Epoch 1260/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8426 - bpp: 1.1076 - mse: 1.0589e-04\n",
      "Epoch 1260: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8426 - bpp: 1.1076 - mse: 1.0589e-04\n",
      "Epoch 1261/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0125 - bpp: 1.1328 - mse: 1.1473e-04\n",
      "Epoch 1261: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.0125 - bpp: 1.1328 - mse: 1.1473e-04\n",
      "Epoch 1262/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6948 - bpp: 1.0994 - mse: 9.7378e-05\n",
      "Epoch 1262: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.6948 - bpp: 1.0994 - mse: 9.7378e-05\n",
      "Epoch 1263/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8525 - bpp: 1.1237 - mse: 1.0551e-04\n",
      "Epoch 1263: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.8525 - bpp: 1.1237 - mse: 1.0551e-04\n",
      "Epoch 1264/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9274 - bpp: 1.1201 - mse: 1.1031e-04\n",
      "Epoch 1264: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.9274 - bpp: 1.1201 - mse: 1.1031e-04\n",
      "Epoch 1265/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7090 - bpp: 1.1044 - mse: 9.7932e-05\n",
      "Epoch 1265: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7090 - bpp: 1.1044 - mse: 9.7932e-05\n",
      "Epoch 1266/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0610 - bpp: 1.1245 - mse: 1.1820e-04\n",
      "Epoch 1266: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.0610 - bpp: 1.1245 - mse: 1.1820e-04\n",
      "Epoch 1267/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0508 - bpp: 1.1458 - mse: 1.1627e-04\n",
      "Epoch 1267: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.0508 - bpp: 1.1458 - mse: 1.1627e-04\n",
      "Epoch 1268/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0633 - bpp: 1.1412 - mse: 1.1732e-04\n",
      "Epoch 1268: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3.0633 - bpp: 1.1412 - mse: 1.1732e-04\n",
      "Epoch 1269/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8508 - bpp: 1.1070 - mse: 1.0643e-04\n",
      "Epoch 1269: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8508 - bpp: 1.1070 - mse: 1.0643e-04\n",
      "Epoch 1270/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8831 - bpp: 1.1215 - mse: 1.0752e-04\n",
      "Epoch 1270: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.8831 - bpp: 1.1215 - mse: 1.0752e-04\n",
      "Epoch 1271/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6673 - bpp: 1.0723 - mse: 9.7349e-05\n",
      "Epoch 1271: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6673 - bpp: 1.0723 - mse: 9.7349e-05\n",
      "Epoch 1272/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7833 - bpp: 1.1163 - mse: 1.0174e-04\n",
      "Epoch 1272: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7833 - bpp: 1.1163 - mse: 1.0174e-04\n",
      "Epoch 1273/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8773 - bpp: 1.1377 - mse: 1.0617e-04\n",
      "Epoch 1273: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8773 - bpp: 1.1377 - mse: 1.0617e-04\n",
      "Epoch 1274/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4125 - bpp: 1.1687 - mse: 1.3695e-04\n",
      "Epoch 1274: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 3.4125 - bpp: 1.1687 - mse: 1.3695e-04\n",
      "Epoch 1275/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8619 - bpp: 1.1033 - mse: 1.0734e-04\n",
      "Epoch 1275: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8619 - bpp: 1.1033 - mse: 1.0734e-04\n",
      "Epoch 1276/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5791 - bpp: 1.0808 - mse: 9.1448e-05\n",
      "Epoch 1276: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.5791 - bpp: 1.0808 - mse: 9.1448e-05\n",
      "Epoch 1277/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8911 - bpp: 1.1130 - mse: 1.0853e-04\n",
      "Epoch 1277: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8911 - bpp: 1.1130 - mse: 1.0853e-04\n",
      "Epoch 1278/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8094 - bpp: 1.0834 - mse: 1.0534e-04\n",
      "Epoch 1278: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.8094 - bpp: 1.0834 - mse: 1.0534e-04\n",
      "Epoch 1279/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0140 - bpp: 1.1252 - mse: 1.1528e-04\n",
      "Epoch 1279: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.0140 - bpp: 1.1252 - mse: 1.1528e-04\n",
      "Epoch 1280/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0505 - bpp: 1.1266 - mse: 1.1743e-04\n",
      "Epoch 1280: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.0505 - bpp: 1.1266 - mse: 1.1743e-04\n",
      "Epoch 1281/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2778 - bpp: 1.1395 - mse: 1.3051e-04\n",
      "Epoch 1281: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 3.2778 - bpp: 1.1395 - mse: 1.3051e-04\n",
      "Epoch 1282/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8977 - bpp: 1.1019 - mse: 1.0961e-04\n",
      "Epoch 1282: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 2.8977 - bpp: 1.1019 - mse: 1.0961e-04\n",
      "Epoch 1283/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0275 - bpp: 1.1362 - mse: 1.1544e-04\n",
      "Epoch 1283: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0275 - bpp: 1.1362 - mse: 1.1544e-04\n",
      "Epoch 1284/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1290 - bpp: 1.1115 - mse: 1.2314e-04\n",
      "Epoch 1284: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.1290 - bpp: 1.1115 - mse: 1.2314e-04\n",
      "Epoch 1285/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0660 - bpp: 1.1314 - mse: 1.1808e-04\n",
      "Epoch 1285: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 3.0660 - bpp: 1.1314 - mse: 1.1808e-04\n",
      "Epoch 1286/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3066 - bpp: 1.1497 - mse: 1.3164e-04\n",
      "Epoch 1286: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.3066 - bpp: 1.1497 - mse: 1.3164e-04\n",
      "Epoch 1287/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9719 - bpp: 1.1231 - mse: 1.1284e-04\n",
      "Epoch 1287: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.9719 - bpp: 1.1231 - mse: 1.1284e-04\n",
      "Epoch 1288/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9354 - bpp: 1.1164 - mse: 1.1102e-04\n",
      "Epoch 1288: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9354 - bpp: 1.1164 - mse: 1.1102e-04\n",
      "Epoch 1289/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7184 - bpp: 1.1224 - mse: 9.7416e-05\n",
      "Epoch 1289: loss did not improve from 2.57346\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7184 - bpp: 1.1224 - mse: 9.7416e-05\n",
      "Epoch 1290/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.4701 - bpp: 1.0671 - mse: 8.5631e-05\n",
      "Epoch 1290: loss improved from 2.57346 to 2.47009, saving model to checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.4701 - bpp: 1.0671 - mse: 8.5631e-05\n",
      "Epoch 1291/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1126 - bpp: 1.1426 - mse: 1.2024e-04\n",
      "Epoch 1291: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.1126 - bpp: 1.1426 - mse: 1.2024e-04\n",
      "Epoch 1292/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0666 - bpp: 1.1190 - mse: 1.1887e-04\n",
      "Epoch 1292: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 3.0666 - bpp: 1.1190 - mse: 1.1887e-04\n",
      "Epoch 1293/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3210 - bpp: 1.1391 - mse: 1.3318e-04\n",
      "Epoch 1293: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.3210 - bpp: 1.1391 - mse: 1.3318e-04\n",
      "Epoch 1294/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7266 - bpp: 1.0986 - mse: 9.9370e-05\n",
      "Epoch 1294: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7266 - bpp: 1.0986 - mse: 9.9370e-05\n",
      "Epoch 1295/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8234 - bpp: 1.1040 - mse: 1.0495e-04\n",
      "Epoch 1295: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.8234 - bpp: 1.1040 - mse: 1.0495e-04\n",
      "Epoch 1296/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3078 - bpp: 1.1362 - mse: 1.3254e-04\n",
      "Epoch 1296: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 3.3078 - bpp: 1.1362 - mse: 1.3254e-04\n",
      "Epoch 1297/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1690 - bpp: 1.1463 - mse: 1.2346e-04\n",
      "Epoch 1297: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.1690 - bpp: 1.1463 - mse: 1.2346e-04\n",
      "Epoch 1298/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9102 - bpp: 1.1238 - mse: 1.0903e-04\n",
      "Epoch 1298: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9102 - bpp: 1.1238 - mse: 1.0903e-04\n",
      "Epoch 1299/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7783 - bpp: 1.0984 - mse: 1.0253e-04\n",
      "Epoch 1299: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7783 - bpp: 1.0984 - mse: 1.0253e-04\n",
      "Epoch 1300/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8823 - bpp: 1.1196 - mse: 1.0759e-04\n",
      "Epoch 1300: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 2.8823 - bpp: 1.1196 - mse: 1.0759e-04\n",
      "Epoch 1301/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1712 - bpp: 1.1234 - mse: 1.2499e-04\n",
      "Epoch 1301: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.1712 - bpp: 1.1234 - mse: 1.2499e-04\n",
      "Epoch 1302/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0324 - bpp: 1.1416 - mse: 1.1540e-04\n",
      "Epoch 1302: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0324 - bpp: 1.1416 - mse: 1.1540e-04\n",
      "Epoch 1303/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9644 - bpp: 1.1368 - mse: 1.1155e-04\n",
      "Epoch 1303: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.9644 - bpp: 1.1368 - mse: 1.1155e-04\n",
      "Epoch 1304/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9941 - bpp: 1.1344 - mse: 1.1350e-04\n",
      "Epoch 1304: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.9941 - bpp: 1.1344 - mse: 1.1350e-04\n",
      "Epoch 1305/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3352 - bpp: 1.1470 - mse: 1.3356e-04\n",
      "Epoch 1305: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.3352 - bpp: 1.1470 - mse: 1.3356e-04\n",
      "Epoch 1306/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1077 - bpp: 1.1453 - mse: 1.1978e-04\n",
      "Epoch 1306: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.1077 - bpp: 1.1453 - mse: 1.1978e-04\n",
      "Epoch 1307/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2126 - bpp: 1.1389 - mse: 1.2657e-04\n",
      "Epoch 1307: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2126 - bpp: 1.1389 - mse: 1.2657e-04\n",
      "Epoch 1308/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0220 - bpp: 1.1549 - mse: 1.1396e-04\n",
      "Epoch 1308: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.0220 - bpp: 1.1549 - mse: 1.1396e-04\n",
      "Epoch 1309/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7711 - bpp: 1.1106 - mse: 1.0135e-04\n",
      "Epoch 1309: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7711 - bpp: 1.1106 - mse: 1.0135e-04\n",
      "Epoch 1310/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1515 - bpp: 1.1156 - mse: 1.2426e-04\n",
      "Epoch 1310: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.1515 - bpp: 1.1156 - mse: 1.2426e-04\n",
      "Epoch 1311/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2523 - bpp: 1.1543 - mse: 1.2805e-04\n",
      "Epoch 1311: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2523 - bpp: 1.1543 - mse: 1.2805e-04\n",
      "Epoch 1312/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8256 - bpp: 1.1066 - mse: 1.0492e-04\n",
      "Epoch 1312: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8256 - bpp: 1.1066 - mse: 1.0492e-04\n",
      "Epoch 1313/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7837 - bpp: 1.1205 - mse: 1.0152e-04\n",
      "Epoch 1313: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.7837 - bpp: 1.1205 - mse: 1.0152e-04\n",
      "Epoch 1314/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2853 - bpp: 1.1603 - mse: 1.2970e-04\n",
      "Epoch 1314: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 271ms/step - loss: 3.2853 - bpp: 1.1603 - mse: 1.2970e-04\n",
      "Epoch 1315/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0711 - bpp: 1.1425 - mse: 1.1771e-04\n",
      "Epoch 1315: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0711 - bpp: 1.1425 - mse: 1.1771e-04\n",
      "Epoch 1316/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8718 - bpp: 1.1153 - mse: 1.0720e-04\n",
      "Epoch 1316: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.8718 - bpp: 1.1153 - mse: 1.0720e-04\n",
      "Epoch 1317/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8871 - bpp: 1.1279 - mse: 1.0738e-04\n",
      "Epoch 1317: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.8871 - bpp: 1.1279 - mse: 1.0738e-04\n",
      "Epoch 1318/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6592 - bpp: 1.0842 - mse: 9.6127e-05\n",
      "Epoch 1318: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.6592 - bpp: 1.0842 - mse: 9.6127e-05\n",
      "Epoch 1319/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8018 - bpp: 1.0903 - mse: 1.0446e-04\n",
      "Epoch 1319: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8018 - bpp: 1.0903 - mse: 1.0446e-04\n",
      "Epoch 1320/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6826 - bpp: 1.0900 - mse: 9.7210e-05\n",
      "Epoch 1320: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6826 - bpp: 1.0900 - mse: 9.7210e-05\n",
      "Epoch 1321/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8500 - bpp: 1.1141 - mse: 1.0595e-04\n",
      "Epoch 1321: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 2.8500 - bpp: 1.1141 - mse: 1.0595e-04\n",
      "Epoch 1322/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2008 - bpp: 1.1202 - mse: 1.2699e-04\n",
      "Epoch 1322: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2008 - bpp: 1.1202 - mse: 1.2699e-04\n",
      "Epoch 1323/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0314 - bpp: 1.1431 - mse: 1.1525e-04\n",
      "Epoch 1323: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.0314 - bpp: 1.1431 - mse: 1.1525e-04\n",
      "Epoch 1324/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0148 - bpp: 1.1486 - mse: 1.1390e-04\n",
      "Epoch 1324: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.0148 - bpp: 1.1486 - mse: 1.1390e-04\n",
      "Epoch 1325/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0217 - bpp: 1.1373 - mse: 1.1501e-04\n",
      "Epoch 1325: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 3.0217 - bpp: 1.1373 - mse: 1.1501e-04\n",
      "Epoch 1326/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8905 - bpp: 1.1147 - mse: 1.0839e-04\n",
      "Epoch 1326: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.8905 - bpp: 1.1147 - mse: 1.0839e-04\n",
      "Epoch 1327/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2302 - bpp: 1.1424 - mse: 1.2743e-04\n",
      "Epoch 1327: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 243ms/step - loss: 3.2302 - bpp: 1.1424 - mse: 1.2743e-04\n",
      "Epoch 1328/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1692 - bpp: 1.1514 - mse: 1.2316e-04\n",
      "Epoch 1328: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.1692 - bpp: 1.1514 - mse: 1.2316e-04\n",
      "Epoch 1329/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8619 - bpp: 1.1125 - mse: 1.0677e-04\n",
      "Epoch 1329: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 2.8619 - bpp: 1.1125 - mse: 1.0677e-04\n",
      "Epoch 1330/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9466 - bpp: 1.1138 - mse: 1.1187e-04\n",
      "Epoch 1330: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9466 - bpp: 1.1138 - mse: 1.1187e-04\n",
      "Epoch 1331/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9910 - bpp: 1.1330 - mse: 1.1341e-04\n",
      "Epoch 1331: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 2.9910 - bpp: 1.1330 - mse: 1.1341e-04\n",
      "Epoch 1332/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7299 - bpp: 1.0943 - mse: 9.9832e-05\n",
      "Epoch 1332: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.7299 - bpp: 1.0943 - mse: 9.9832e-05\n",
      "Epoch 1333/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8976 - bpp: 1.1094 - mse: 1.0914e-04\n",
      "Epoch 1333: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.8976 - bpp: 1.1094 - mse: 1.0914e-04\n",
      "Epoch 1334/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2417 - bpp: 1.1561 - mse: 1.2729e-04\n",
      "Epoch 1334: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.2417 - bpp: 1.1561 - mse: 1.2729e-04\n",
      "Epoch 1335/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0524 - bpp: 1.1210 - mse: 1.1788e-04\n",
      "Epoch 1335: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 3.0524 - bpp: 1.1210 - mse: 1.1788e-04\n",
      "Epoch 1336/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8581 - bpp: 1.1071 - mse: 1.0687e-04\n",
      "Epoch 1336: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 2.8581 - bpp: 1.1071 - mse: 1.0687e-04\n",
      "Epoch 1337/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9720 - bpp: 1.1323 - mse: 1.1228e-04\n",
      "Epoch 1337: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.9720 - bpp: 1.1323 - mse: 1.1228e-04\n",
      "Epoch 1338/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9293 - bpp: 1.1244 - mse: 1.1017e-04\n",
      "Epoch 1338: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.9293 - bpp: 1.1244 - mse: 1.1017e-04\n",
      "Epoch 1339/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.5373 - bpp: 1.1611 - mse: 1.4504e-04\n",
      "Epoch 1339: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.5373 - bpp: 1.1611 - mse: 1.4504e-04\n",
      "Epoch 1340/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0696 - bpp: 1.1505 - mse: 1.1713e-04\n",
      "Epoch 1340: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 3.0696 - bpp: 1.1505 - mse: 1.1713e-04\n",
      "Epoch 1341/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0883 - bpp: 1.1258 - mse: 1.1978e-04\n",
      "Epoch 1341: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0883 - bpp: 1.1258 - mse: 1.1978e-04\n",
      "Epoch 1342/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8606 - bpp: 1.1094 - mse: 1.0688e-04\n",
      "Epoch 1342: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 2.8606 - bpp: 1.1094 - mse: 1.0688e-04\n",
      "Epoch 1343/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0660 - bpp: 1.1166 - mse: 1.1898e-04\n",
      "Epoch 1343: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 3.0660 - bpp: 1.1166 - mse: 1.1898e-04\n",
      "Epoch 1344/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7995 - bpp: 1.1078 - mse: 1.0325e-04\n",
      "Epoch 1344: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.7995 - bpp: 1.1078 - mse: 1.0325e-04\n",
      "Epoch 1345/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9466 - bpp: 1.1245 - mse: 1.1121e-04\n",
      "Epoch 1345: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9466 - bpp: 1.1245 - mse: 1.1121e-04\n",
      "Epoch 1346/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6043 - bpp: 1.0840 - mse: 9.2791e-05\n",
      "Epoch 1346: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.6043 - bpp: 1.0840 - mse: 9.2791e-05\n",
      "Epoch 1347/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9461 - bpp: 1.1229 - mse: 1.1128e-04\n",
      "Epoch 1347: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.9461 - bpp: 1.1229 - mse: 1.1128e-04\n",
      "Epoch 1348/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9747 - bpp: 1.1172 - mse: 1.1337e-04\n",
      "Epoch 1348: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 2.9747 - bpp: 1.1172 - mse: 1.1337e-04\n",
      "Epoch 1349/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1157 - bpp: 1.1562 - mse: 1.1960e-04\n",
      "Epoch 1349: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.1157 - bpp: 1.1562 - mse: 1.1960e-04\n",
      "Epoch 1350/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1443 - bpp: 1.1261 - mse: 1.2318e-04\n",
      "Epoch 1350: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.1443 - bpp: 1.1261 - mse: 1.2318e-04\n",
      "Epoch 1351/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0705 - bpp: 1.1252 - mse: 1.1874e-04\n",
      "Epoch 1351: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 3.0705 - bpp: 1.1252 - mse: 1.1874e-04\n",
      "Epoch 1352/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8203 - bpp: 1.0842 - mse: 1.0597e-04\n",
      "Epoch 1352: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.8203 - bpp: 1.0842 - mse: 1.0597e-04\n",
      "Epoch 1353/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2808 - bpp: 1.1384 - mse: 1.3076e-04\n",
      "Epoch 1353: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.2808 - bpp: 1.1384 - mse: 1.3076e-04\n",
      "Epoch 1354/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8136 - bpp: 1.1157 - mse: 1.0363e-04\n",
      "Epoch 1354: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.8136 - bpp: 1.1157 - mse: 1.0363e-04\n",
      "Epoch 1355/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7708 - bpp: 1.0925 - mse: 1.0243e-04\n",
      "Epoch 1355: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.7708 - bpp: 1.0925 - mse: 1.0243e-04\n",
      "Epoch 1356/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7263 - bpp: 1.0969 - mse: 9.9447e-05\n",
      "Epoch 1356: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7263 - bpp: 1.0969 - mse: 9.9447e-05\n",
      "Epoch 1357/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3058 - bpp: 1.1306 - mse: 1.3276e-04\n",
      "Epoch 1357: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3.3058 - bpp: 1.1306 - mse: 1.3276e-04\n",
      "Epoch 1358/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9872 - bpp: 1.1271 - mse: 1.1353e-04\n",
      "Epoch 1358: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.9872 - bpp: 1.1271 - mse: 1.1353e-04\n",
      "Epoch 1359/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0072 - bpp: 1.1198 - mse: 1.1520e-04\n",
      "Epoch 1359: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.0072 - bpp: 1.1198 - mse: 1.1520e-04\n",
      "Epoch 1360/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9864 - bpp: 1.1290 - mse: 1.1336e-04\n",
      "Epoch 1360: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9864 - bpp: 1.1290 - mse: 1.1336e-04\n",
      "Epoch 1361/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9623 - bpp: 1.1302 - mse: 1.1182e-04\n",
      "Epoch 1361: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9623 - bpp: 1.1302 - mse: 1.1182e-04\n",
      "Epoch 1362/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8358 - bpp: 1.1212 - mse: 1.0465e-04\n",
      "Epoch 1362: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8358 - bpp: 1.1212 - mse: 1.0465e-04\n",
      "Epoch 1363/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9922 - bpp: 1.1497 - mse: 1.1246e-04\n",
      "Epoch 1363: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.9922 - bpp: 1.1497 - mse: 1.1246e-04\n",
      "Epoch 1364/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2968 - bpp: 1.1688 - mse: 1.2988e-04\n",
      "Epoch 1364: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 3.2968 - bpp: 1.1688 - mse: 1.2988e-04\n",
      "Epoch 1365/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2336 - bpp: 1.1517 - mse: 1.2707e-04\n",
      "Epoch 1365: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2336 - bpp: 1.1517 - mse: 1.2707e-04\n",
      "Epoch 1366/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9037 - bpp: 1.1164 - mse: 1.0909e-04\n",
      "Epoch 1366: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.9037 - bpp: 1.1164 - mse: 1.0909e-04\n",
      "Epoch 1367/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8815 - bpp: 1.1112 - mse: 1.0805e-04\n",
      "Epoch 1367: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 2.8815 - bpp: 1.1112 - mse: 1.0805e-04\n",
      "Epoch 1368/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9183 - bpp: 1.1181 - mse: 1.0988e-04\n",
      "Epoch 1368: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.9183 - bpp: 1.1181 - mse: 1.0988e-04\n",
      "Epoch 1369/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3464 - bpp: 1.1354 - mse: 1.3495e-04\n",
      "Epoch 1369: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 249ms/step - loss: 3.3464 - bpp: 1.1354 - mse: 1.3495e-04\n",
      "Epoch 1370/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0206 - bpp: 1.1293 - mse: 1.1543e-04\n",
      "Epoch 1370: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0206 - bpp: 1.1293 - mse: 1.1543e-04\n",
      "Epoch 1371/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0765 - bpp: 1.1192 - mse: 1.1946e-04\n",
      "Epoch 1371: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.0765 - bpp: 1.1192 - mse: 1.1946e-04\n",
      "Epoch 1372/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1916 - bpp: 1.1378 - mse: 1.2536e-04\n",
      "Epoch 1372: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1916 - bpp: 1.1378 - mse: 1.2536e-04\n",
      "Epoch 1373/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6048 - bpp: 1.0719 - mse: 9.3561e-05\n",
      "Epoch 1373: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.6048 - bpp: 1.0719 - mse: 9.3561e-05\n",
      "Epoch 1374/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7347 - bpp: 1.0852 - mse: 1.0068e-04\n",
      "Epoch 1374: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 2.7347 - bpp: 1.0852 - mse: 1.0068e-04\n",
      "Epoch 1375/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0789 - bpp: 1.1310 - mse: 1.1889e-04\n",
      "Epoch 1375: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.0789 - bpp: 1.1310 - mse: 1.1889e-04\n",
      "Epoch 1376/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9855 - bpp: 1.1270 - mse: 1.1343e-04\n",
      "Epoch 1376: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9855 - bpp: 1.1270 - mse: 1.1343e-04\n",
      "Epoch 1377/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3055 - bpp: 1.1531 - mse: 1.3137e-04\n",
      "Epoch 1377: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3055 - bpp: 1.1531 - mse: 1.3137e-04\n",
      "Epoch 1378/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.4424 - bpp: 1.1819 - mse: 1.3797e-04\n",
      "Epoch 1378: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.4424 - bpp: 1.1819 - mse: 1.3797e-04\n",
      "Epoch 1379/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8687 - bpp: 1.0971 - mse: 1.0813e-04\n",
      "Epoch 1379: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.8687 - bpp: 1.0971 - mse: 1.0813e-04\n",
      "Epoch 1380/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9724 - bpp: 1.1148 - mse: 1.1338e-04\n",
      "Epoch 1380: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 247ms/step - loss: 2.9724 - bpp: 1.1148 - mse: 1.1338e-04\n",
      "Epoch 1381/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2522 - bpp: 1.1492 - mse: 1.2836e-04\n",
      "Epoch 1381: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 3.2522 - bpp: 1.1492 - mse: 1.2836e-04\n",
      "Epoch 1382/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7255 - bpp: 1.1080 - mse: 9.8725e-05\n",
      "Epoch 1382: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.7255 - bpp: 1.1080 - mse: 9.8725e-05\n",
      "Epoch 1383/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2169 - bpp: 1.1359 - mse: 1.2701e-04\n",
      "Epoch 1383: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 3.2169 - bpp: 1.1359 - mse: 1.2701e-04\n",
      "Epoch 1384/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8069 - bpp: 1.1080 - mse: 1.0369e-04\n",
      "Epoch 1384: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.8069 - bpp: 1.1080 - mse: 1.0369e-04\n",
      "Epoch 1385/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2280 - bpp: 1.1545 - mse: 1.2655e-04\n",
      "Epoch 1385: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.2280 - bpp: 1.1545 - mse: 1.2655e-04\n",
      "Epoch 1386/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7220 - bpp: 1.1012 - mse: 9.8927e-05\n",
      "Epoch 1386: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.7220 - bpp: 1.1012 - mse: 9.8927e-05\n",
      "Epoch 1387/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9982 - bpp: 1.1155 - mse: 1.1491e-04\n",
      "Epoch 1387: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.9982 - bpp: 1.1155 - mse: 1.1491e-04\n",
      "Epoch 1388/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7517 - bpp: 1.1203 - mse: 9.9572e-05\n",
      "Epoch 1388: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.7517 - bpp: 1.1203 - mse: 9.9572e-05\n",
      "Epoch 1389/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1286 - bpp: 1.1481 - mse: 1.2088e-04\n",
      "Epoch 1389: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 3.1286 - bpp: 1.1481 - mse: 1.2088e-04\n",
      "Epoch 1390/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8075 - bpp: 1.0976 - mse: 1.0436e-04\n",
      "Epoch 1390: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.8075 - bpp: 1.0976 - mse: 1.0436e-04\n",
      "Epoch 1391/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0325 - bpp: 1.1457 - mse: 1.1517e-04\n",
      "Epoch 1391: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 3.0325 - bpp: 1.1457 - mse: 1.1517e-04\n",
      "Epoch 1392/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9894 - bpp: 1.1278 - mse: 1.1362e-04\n",
      "Epoch 1392: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.9894 - bpp: 1.1278 - mse: 1.1362e-04\n",
      "Epoch 1393/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6079 - bpp: 1.0787 - mse: 9.3336e-05\n",
      "Epoch 1393: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6079 - bpp: 1.0787 - mse: 9.3336e-05\n",
      "Epoch 1394/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7211 - bpp: 1.0802 - mse: 1.0015e-04\n",
      "Epoch 1394: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7211 - bpp: 1.0802 - mse: 1.0015e-04\n",
      "Epoch 1395/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9464 - bpp: 1.1395 - mse: 1.1028e-04\n",
      "Epoch 1395: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 2.9464 - bpp: 1.1395 - mse: 1.1028e-04\n",
      "Epoch 1396/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8966 - bpp: 1.1339 - mse: 1.0759e-04\n",
      "Epoch 1396: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8966 - bpp: 1.1339 - mse: 1.0759e-04\n",
      "Epoch 1397/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7779 - bpp: 1.1095 - mse: 1.0183e-04\n",
      "Epoch 1397: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.7779 - bpp: 1.1095 - mse: 1.0183e-04\n",
      "Epoch 1398/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7232 - bpp: 1.0987 - mse: 9.9148e-05\n",
      "Epoch 1398: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 2.7232 - bpp: 1.0987 - mse: 9.9148e-05\n",
      "Epoch 1399/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8361 - bpp: 1.1029 - mse: 1.0578e-04\n",
      "Epoch 1399: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.8361 - bpp: 1.1029 - mse: 1.0578e-04\n",
      "Epoch 1400/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6895 - bpp: 1.0762 - mse: 9.8469e-05\n",
      "Epoch 1400: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 2.6895 - bpp: 1.0762 - mse: 9.8469e-05\n",
      "Epoch 1401/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7160 - bpp: 1.0965 - mse: 9.8848e-05\n",
      "Epoch 1401: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7160 - bpp: 1.0965 - mse: 9.8848e-05\n",
      "Epoch 1402/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3479 - bpp: 1.1618 - mse: 1.3343e-04\n",
      "Epoch 1402: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 3.3479 - bpp: 1.1618 - mse: 1.3343e-04\n",
      "Epoch 1403/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8474 - bpp: 1.1205 - mse: 1.0540e-04\n",
      "Epoch 1403: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 57s 282ms/step - loss: 2.8474 - bpp: 1.1205 - mse: 1.0540e-04\n",
      "Epoch 1404/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9587 - bpp: 1.1334 - mse: 1.1140e-04\n",
      "Epoch 1404: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9587 - bpp: 1.1334 - mse: 1.1140e-04\n",
      "Epoch 1405/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6404 - bpp: 1.1048 - mse: 9.3726e-05\n",
      "Epoch 1405: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.6404 - bpp: 1.1048 - mse: 9.3726e-05\n",
      "Epoch 1406/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9829 - bpp: 1.1047 - mse: 1.1464e-04\n",
      "Epoch 1406: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 2.9829 - bpp: 1.1047 - mse: 1.1464e-04\n",
      "Epoch 1407/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9464 - bpp: 1.1221 - mse: 1.1135e-04\n",
      "Epoch 1407: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.9464 - bpp: 1.1221 - mse: 1.1135e-04\n",
      "Epoch 1408/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9324 - bpp: 1.1304 - mse: 1.0998e-04\n",
      "Epoch 1408: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 276ms/step - loss: 2.9324 - bpp: 1.1304 - mse: 1.0998e-04\n",
      "Epoch 1409/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2126 - bpp: 1.1256 - mse: 1.2738e-04\n",
      "Epoch 1409: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 257ms/step - loss: 3.2126 - bpp: 1.1256 - mse: 1.2738e-04\n",
      "Epoch 1410/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0342 - bpp: 1.1105 - mse: 1.1741e-04\n",
      "Epoch 1410: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0342 - bpp: 1.1105 - mse: 1.1741e-04\n",
      "Epoch 1411/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7979 - bpp: 1.1271 - mse: 1.0198e-04\n",
      "Epoch 1411: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 252ms/step - loss: 2.7979 - bpp: 1.1271 - mse: 1.0198e-04\n",
      "Epoch 1412/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8453 - bpp: 1.1285 - mse: 1.0478e-04\n",
      "Epoch 1412: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8453 - bpp: 1.1285 - mse: 1.0478e-04\n",
      "Epoch 1413/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8992 - bpp: 1.1204 - mse: 1.0857e-04\n",
      "Epoch 1413: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 2.8992 - bpp: 1.1204 - mse: 1.0857e-04\n",
      "Epoch 1414/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8992 - bpp: 1.1168 - mse: 1.0879e-04\n",
      "Epoch 1414: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.8992 - bpp: 1.1168 - mse: 1.0879e-04\n",
      "Epoch 1415/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8736 - bpp: 1.1215 - mse: 1.0694e-04\n",
      "Epoch 1415: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 256ms/step - loss: 2.8736 - bpp: 1.1215 - mse: 1.0694e-04\n",
      "Epoch 1416/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8199 - bpp: 1.0986 - mse: 1.0506e-04\n",
      "Epoch 1416: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 255ms/step - loss: 2.8199 - bpp: 1.0986 - mse: 1.0506e-04\n",
      "Epoch 1417/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0922 - bpp: 1.1325 - mse: 1.1961e-04\n",
      "Epoch 1417: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.0922 - bpp: 1.1325 - mse: 1.1961e-04\n",
      "Epoch 1418/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6724 - bpp: 1.1043 - mse: 9.5710e-05\n",
      "Epoch 1418: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.6724 - bpp: 1.1043 - mse: 9.5710e-05\n",
      "Epoch 1419/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7736 - bpp: 1.0971 - mse: 1.0232e-04\n",
      "Epoch 1419: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 2.7736 - bpp: 1.0971 - mse: 1.0232e-04\n",
      "Epoch 1420/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0003 - bpp: 1.1333 - mse: 1.1395e-04\n",
      "Epoch 1420: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0003 - bpp: 1.1333 - mse: 1.1395e-04\n",
      "Epoch 1421/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1637 - bpp: 1.1178 - mse: 1.2487e-04\n",
      "Epoch 1421: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 3.1637 - bpp: 1.1178 - mse: 1.2487e-04\n",
      "Epoch 1422/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7938 - bpp: 1.1012 - mse: 1.0330e-04\n",
      "Epoch 1422: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 274ms/step - loss: 2.7938 - bpp: 1.1012 - mse: 1.0330e-04\n",
      "Epoch 1423/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7340 - bpp: 1.1109 - mse: 9.9065e-05\n",
      "Epoch 1423: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 2.7340 - bpp: 1.1109 - mse: 9.9065e-05\n",
      "Epoch 1424/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7868 - bpp: 1.1126 - mse: 1.0218e-04\n",
      "Epoch 1424: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7868 - bpp: 1.1126 - mse: 1.0218e-04\n",
      "Epoch 1425/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9189 - bpp: 1.1366 - mse: 1.0878e-04\n",
      "Epoch 1425: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 2.9189 - bpp: 1.1366 - mse: 1.0878e-04\n",
      "Epoch 1426/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8862 - bpp: 1.1251 - mse: 1.0749e-04\n",
      "Epoch 1426: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 2.8862 - bpp: 1.1251 - mse: 1.0749e-04\n",
      "Epoch 1427/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2339 - bpp: 1.1469 - mse: 1.2738e-04\n",
      "Epoch 1427: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.2339 - bpp: 1.1469 - mse: 1.2738e-04\n",
      "Epoch 1428/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2223 - bpp: 1.1395 - mse: 1.2713e-04\n",
      "Epoch 1428: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 3.2223 - bpp: 1.1395 - mse: 1.2713e-04\n",
      "Epoch 1429/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9844 - bpp: 1.1368 - mse: 1.1277e-04\n",
      "Epoch 1429: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 2.9844 - bpp: 1.1368 - mse: 1.1277e-04\n",
      "Epoch 1430/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8448 - bpp: 1.1020 - mse: 1.0638e-04\n",
      "Epoch 1430: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 2.8448 - bpp: 1.1020 - mse: 1.0638e-04\n",
      "Epoch 1431/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8748 - bpp: 1.1079 - mse: 1.0784e-04\n",
      "Epoch 1431: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.8748 - bpp: 1.1079 - mse: 1.0784e-04\n",
      "Epoch 1432/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0633 - bpp: 1.1555 - mse: 1.1644e-04\n",
      "Epoch 1432: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.0633 - bpp: 1.1555 - mse: 1.1644e-04\n",
      "Epoch 1433/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7621 - bpp: 1.0928 - mse: 1.0188e-04\n",
      "Epoch 1433: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 2.7621 - bpp: 1.0928 - mse: 1.0188e-04\n",
      "Epoch 1434/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7061 - bpp: 1.1156 - mse: 9.7077e-05\n",
      "Epoch 1434: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 2.7061 - bpp: 1.1156 - mse: 9.7077e-05\n",
      "Epoch 1435/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8983 - bpp: 1.1138 - mse: 1.0892e-04\n",
      "Epoch 1435: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.8983 - bpp: 1.1138 - mse: 1.0892e-04\n",
      "Epoch 1436/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8052 - bpp: 1.0971 - mse: 1.0426e-04\n",
      "Epoch 1436: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 2.8052 - bpp: 1.0971 - mse: 1.0426e-04\n",
      "Epoch 1437/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1274 - bpp: 1.1423 - mse: 1.2116e-04\n",
      "Epoch 1437: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1274 - bpp: 1.1423 - mse: 1.2116e-04\n",
      "Epoch 1438/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8423 - bpp: 1.0972 - mse: 1.0651e-04\n",
      "Epoch 1438: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 2.8423 - bpp: 1.0972 - mse: 1.0651e-04\n",
      "Epoch 1439/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6754 - bpp: 1.1027 - mse: 9.5988e-05\n",
      "Epoch 1439: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 2.6754 - bpp: 1.1027 - mse: 9.5988e-05\n",
      "Epoch 1440/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9454 - bpp: 1.1084 - mse: 1.1212e-04\n",
      "Epoch 1440: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.9454 - bpp: 1.1084 - mse: 1.1212e-04\n",
      "Epoch 1441/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1561 - bpp: 1.1521 - mse: 1.2231e-04\n",
      "Epoch 1441: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 3.1561 - bpp: 1.1521 - mse: 1.2231e-04\n",
      "Epoch 1442/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8487 - bpp: 1.1180 - mse: 1.0564e-04\n",
      "Epoch 1442: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 2.8487 - bpp: 1.1180 - mse: 1.0564e-04\n",
      "Epoch 1443/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9046 - bpp: 1.1303 - mse: 1.0829e-04\n",
      "Epoch 1443: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9046 - bpp: 1.1303 - mse: 1.0829e-04\n",
      "Epoch 1444/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1796 - bpp: 1.1519 - mse: 1.2376e-04\n",
      "Epoch 1444: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 3.1796 - bpp: 1.1519 - mse: 1.2376e-04\n",
      "Epoch 1445/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7794 - bpp: 1.1044 - mse: 1.0223e-04\n",
      "Epoch 1445: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 266ms/step - loss: 2.7794 - bpp: 1.1044 - mse: 1.0223e-04\n",
      "Epoch 1446/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8468 - bpp: 1.0948 - mse: 1.0693e-04\n",
      "Epoch 1446: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8468 - bpp: 1.0948 - mse: 1.0693e-04\n",
      "Epoch 1447/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7310 - bpp: 1.0966 - mse: 9.9759e-05\n",
      "Epoch 1447: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.7310 - bpp: 1.0966 - mse: 9.9759e-05\n",
      "Epoch 1448/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1406 - bpp: 1.1527 - mse: 1.2133e-04\n",
      "Epoch 1448: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 275ms/step - loss: 3.1406 - bpp: 1.1527 - mse: 1.2133e-04\n",
      "Epoch 1449/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9889 - bpp: 1.1178 - mse: 1.1421e-04\n",
      "Epoch 1449: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9889 - bpp: 1.1178 - mse: 1.1421e-04\n",
      "Epoch 1450/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9792 - bpp: 1.1264 - mse: 1.1309e-04\n",
      "Epoch 1450: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 2.9792 - bpp: 1.1264 - mse: 1.1309e-04\n",
      "Epoch 1451/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7024 - bpp: 1.1069 - mse: 9.7380e-05\n",
      "Epoch 1451: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.7024 - bpp: 1.1069 - mse: 9.7380e-05\n",
      "Epoch 1452/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2508 - bpp: 1.1382 - mse: 1.2894e-04\n",
      "Epoch 1452: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.2508 - bpp: 1.1382 - mse: 1.2894e-04\n",
      "Epoch 1453/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3426 - bpp: 1.1503 - mse: 1.3380e-04\n",
      "Epoch 1453: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 3.3426 - bpp: 1.1503 - mse: 1.3380e-04\n",
      "Epoch 1454/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1479 - bpp: 1.1497 - mse: 1.2196e-04\n",
      "Epoch 1454: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.1479 - bpp: 1.1497 - mse: 1.2196e-04\n",
      "Epoch 1455/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7161 - bpp: 1.1044 - mse: 9.8372e-05\n",
      "Epoch 1455: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.7161 - bpp: 1.1044 - mse: 9.8372e-05\n",
      "Epoch 1456/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7988 - bpp: 1.1142 - mse: 1.0282e-04\n",
      "Epoch 1456: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.7988 - bpp: 1.1142 - mse: 1.0282e-04\n",
      "Epoch 1457/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0920 - bpp: 1.1326 - mse: 1.1959e-04\n",
      "Epoch 1457: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0920 - bpp: 1.1326 - mse: 1.1959e-04\n",
      "Epoch 1458/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0481 - bpp: 1.1032 - mse: 1.1871e-04\n",
      "Epoch 1458: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0481 - bpp: 1.1032 - mse: 1.1871e-04\n",
      "Epoch 1459/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9935 - bpp: 1.1281 - mse: 1.1386e-04\n",
      "Epoch 1459: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9935 - bpp: 1.1281 - mse: 1.1386e-04\n",
      "Epoch 1460/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8085 - bpp: 1.0975 - mse: 1.0443e-04\n",
      "Epoch 1460: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 270ms/step - loss: 2.8085 - bpp: 1.0975 - mse: 1.0443e-04\n",
      "Epoch 1461/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1063 - bpp: 1.1306 - mse: 1.2059e-04\n",
      "Epoch 1461: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 3.1063 - bpp: 1.1306 - mse: 1.2059e-04\n",
      "Epoch 1462/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8859 - bpp: 1.1184 - mse: 1.0788e-04\n",
      "Epoch 1462: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 2.8859 - bpp: 1.1184 - mse: 1.0788e-04\n",
      "Epoch 1463/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8811 - bpp: 1.1121 - mse: 1.0797e-04\n",
      "Epoch 1463: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 2.8811 - bpp: 1.1121 - mse: 1.0797e-04\n",
      "Epoch 1464/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1132 - bpp: 1.1354 - mse: 1.2072e-04\n",
      "Epoch 1464: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1132 - bpp: 1.1354 - mse: 1.2072e-04\n",
      "Epoch 1465/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9277 - bpp: 1.1310 - mse: 1.0967e-04\n",
      "Epoch 1465: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 57s 281ms/step - loss: 2.9277 - bpp: 1.1310 - mse: 1.0967e-04\n",
      "Epoch 1466/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8580 - bpp: 1.1119 - mse: 1.0657e-04\n",
      "Epoch 1466: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.8580 - bpp: 1.1119 - mse: 1.0657e-04\n",
      "Epoch 1467/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8174 - bpp: 1.1182 - mse: 1.0371e-04\n",
      "Epoch 1467: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 2.8174 - bpp: 1.1182 - mse: 1.0371e-04\n",
      "Epoch 1468/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0955 - bpp: 1.1396 - mse: 1.1938e-04\n",
      "Epoch 1468: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0955 - bpp: 1.1396 - mse: 1.1938e-04\n",
      "Epoch 1469/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0007 - bpp: 1.1427 - mse: 1.1340e-04\n",
      "Epoch 1469: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 3.0007 - bpp: 1.1427 - mse: 1.1340e-04\n",
      "Epoch 1470/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9585 - bpp: 1.1204 - mse: 1.1219e-04\n",
      "Epoch 1470: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9585 - bpp: 1.1204 - mse: 1.1219e-04\n",
      "Epoch 1471/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8266 - bpp: 1.1082 - mse: 1.0488e-04\n",
      "Epoch 1471: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 2.8266 - bpp: 1.1082 - mse: 1.0488e-04\n",
      "Epoch 1472/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.5971 - bpp: 1.0886 - mse: 9.2071e-05\n",
      "Epoch 1472: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 2.5971 - bpp: 1.0886 - mse: 9.2071e-05\n",
      "Epoch 1473/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6635 - bpp: 1.0709 - mse: 9.7202e-05\n",
      "Epoch 1473: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 56s 277ms/step - loss: 2.6635 - bpp: 1.0709 - mse: 9.7202e-05\n",
      "Epoch 1474/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2991 - bpp: 1.1615 - mse: 1.3047e-04\n",
      "Epoch 1474: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 3.2991 - bpp: 1.1615 - mse: 1.3047e-04\n",
      "Epoch 1475/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0515 - bpp: 1.1413 - mse: 1.1659e-04\n",
      "Epoch 1475: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.0515 - bpp: 1.1413 - mse: 1.1659e-04\n",
      "Epoch 1476/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8714 - bpp: 1.1278 - mse: 1.0642e-04\n",
      "Epoch 1476: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 2.8714 - bpp: 1.1278 - mse: 1.0642e-04\n",
      "Epoch 1477/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8407 - bpp: 1.1180 - mse: 1.0515e-04\n",
      "Epoch 1477: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.8407 - bpp: 1.1180 - mse: 1.0515e-04\n",
      "Epoch 1478/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0417 - bpp: 1.1476 - mse: 1.1561e-04\n",
      "Epoch 1478: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 3.0417 - bpp: 1.1476 - mse: 1.1561e-04\n",
      "Epoch 1479/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0903 - bpp: 1.1331 - mse: 1.1946e-04\n",
      "Epoch 1479: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0903 - bpp: 1.1331 - mse: 1.1946e-04\n",
      "Epoch 1480/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7568 - bpp: 1.1002 - mse: 1.0111e-04\n",
      "Epoch 1480: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 272ms/step - loss: 2.7568 - bpp: 1.1002 - mse: 1.0111e-04\n",
      "Epoch 1481/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8538 - bpp: 1.1219 - mse: 1.0571e-04\n",
      "Epoch 1481: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.8538 - bpp: 1.1219 - mse: 1.0571e-04\n",
      "Epoch 1482/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9744 - bpp: 1.1156 - mse: 1.1345e-04\n",
      "Epoch 1482: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 2.9744 - bpp: 1.1156 - mse: 1.1345e-04\n",
      "Epoch 1483/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1277 - bpp: 1.1336 - mse: 1.2171e-04\n",
      "Epoch 1483: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 3.1277 - bpp: 1.1336 - mse: 1.2171e-04\n",
      "Epoch 1484/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1431 - bpp: 1.1625 - mse: 1.2089e-04\n",
      "Epoch 1484: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.1431 - bpp: 1.1625 - mse: 1.2089e-04\n",
      "Epoch 1485/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9626 - bpp: 1.1280 - mse: 1.1198e-04\n",
      "Epoch 1485: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.9626 - bpp: 1.1280 - mse: 1.1198e-04\n",
      "Epoch 1486/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0306 - bpp: 1.1337 - mse: 1.1578e-04\n",
      "Epoch 1486: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 3.0306 - bpp: 1.1337 - mse: 1.1578e-04\n",
      "Epoch 1487/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9303 - bpp: 1.1196 - mse: 1.1052e-04\n",
      "Epoch 1487: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 267ms/step - loss: 2.9303 - bpp: 1.1196 - mse: 1.1052e-04\n",
      "Epoch 1488/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1060 - bpp: 1.1239 - mse: 1.2097e-04\n",
      "Epoch 1488: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 3.1060 - bpp: 1.1239 - mse: 1.2097e-04\n",
      "Epoch 1489/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1118 - bpp: 1.1397 - mse: 1.2037e-04\n",
      "Epoch 1489: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 265ms/step - loss: 3.1118 - bpp: 1.1397 - mse: 1.2037e-04\n",
      "Epoch 1490/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.2630 - bpp: 1.1430 - mse: 1.2939e-04\n",
      "Epoch 1490: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 3.2630 - bpp: 1.1430 - mse: 1.2939e-04\n",
      "Epoch 1491/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9118 - bpp: 1.1013 - mse: 1.1051e-04\n",
      "Epoch 1491: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 2.9118 - bpp: 1.1013 - mse: 1.1051e-04\n",
      "Epoch 1492/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0821 - bpp: 1.1376 - mse: 1.1868e-04\n",
      "Epoch 1492: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 3.0821 - bpp: 1.1376 - mse: 1.1868e-04\n",
      "Epoch 1493/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9534 - bpp: 1.1198 - mse: 1.1191e-04\n",
      "Epoch 1493: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 2.9534 - bpp: 1.1198 - mse: 1.1191e-04\n",
      "Epoch 1494/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.9985 - bpp: 1.1267 - mse: 1.1425e-04\n",
      "Epoch 1494: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 261ms/step - loss: 2.9985 - bpp: 1.1267 - mse: 1.1425e-04\n",
      "Epoch 1495/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0172 - bpp: 1.1553 - mse: 1.1364e-04\n",
      "Epoch 1495: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 3.0172 - bpp: 1.1553 - mse: 1.1364e-04\n",
      "Epoch 1496/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.0645 - bpp: 1.1249 - mse: 1.1838e-04\n",
      "Epoch 1496: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 262ms/step - loss: 3.0645 - bpp: 1.1249 - mse: 1.1838e-04\n",
      "Epoch 1497/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.6868 - bpp: 1.1058 - mse: 9.6496e-05\n",
      "Epoch 1497: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 2.6868 - bpp: 1.1058 - mse: 9.6496e-05\n",
      "Epoch 1498/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1134 - bpp: 1.1333 - mse: 1.2086e-04\n",
      "Epoch 1498: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 3.1134 - bpp: 1.1333 - mse: 1.2086e-04\n",
      "Epoch 1499/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.7774 - bpp: 1.1018 - mse: 1.0227e-04\n",
      "Epoch 1499: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 2.7774 - bpp: 1.1018 - mse: 1.0227e-04\n",
      "Epoch 1500/1500\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.1022 - bpp: 1.1228 - mse: 1.2081e-04\n",
      "Epoch 1500: loss did not improve from 2.47009\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 3.1022 - bpp: 1.1228 - mse: 1.2081e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the compress\n",
      "in decompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as optical_flow_loss_3_layer_call_fn, optical_flow_loss_3_layer_call_and_return_conditional_losses, dwt_3_layer_call_fn, dwt_3_layer_call_and_return_conditional_losses, mc1_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_checkpoints_wavelets_haar_Lmbd_16384_epcs_1500_I_QP_27_240x240_CosineDecay_20220505-154218/assets\n"
     ]
    }
   ],
   "source": [
    "trainer_14 = TrainOpenDVCW(BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, Height, Width, Channel, NUM_FILTERS, lmbda*2*2*2, lr_init, lr_alpha, early_stop, I_QP, wavelet_name, checkponts_prev_path, np_folder)\n",
    "trainer_14.compile()\n",
    "trainer_14.fit()\n",
    "trainer_14.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load\n",
    "import OpenDVCW\n",
    "\n",
    "# img_path = load.load_path_n(\"folder_cloud_test.npy\", 0)\n",
    "img_path = \"/mnt/WindowsDev/DataSets/Beauty_1920x1080_120fps_420_8bit_YUV_RAW/\"\n",
    "i_frame = img_path + 'im0' + '.png'\n",
    "p_frame = img_path + 'im1' + '.png'\n",
    "out_bin = \"Test_com/test{}.bin\".format(0)\n",
    "out_decom = \"Test_com/testdcom{}.png\".format(0)\n",
    "\n",
    "p_on_test = \"Test_com/test_p_frame{}.png\".format(0)\n",
    "i_on_test = \"Test_com/test_i_frame{}.png\".format(0)\n",
    "\n",
    "OpenDVCW.write_png(p_on_test, OpenDVCW.read_png_crop(p_frame, Width, Height))\n",
    "OpenDVCW.write_png(i_on_test, OpenDVCW.read_png_crop(i_frame, Width, Height))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compress\n",
      "decompress\n",
      "bin size:  2282 psnr:  37.022711351569335 bpp:  75.72304995617878\n",
      "compress\n",
      "decompress\n",
      "bin size:  1514 psnr:  38.266512930758694 bpp:  114.13474240422721\n",
      "compress\n",
      "decompress\n",
      "bin size:  2859 psnr:  39.35762683804636 bpp:  60.44071353620147\n",
      "compress\n",
      "decompress\n",
      "bin size:  7484 psnr:  39.09203802192782 bpp:  23.089257081774452\n"
     ]
    }
   ],
   "source": [
    "trainer_11.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_11.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_12.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_12.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_13.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_13.check_psnr(p_on_test, out_decom, out_bin)\n",
    "trainer_14.test(i_frame, p_frame, out_bin, out_decom)\n",
    "trainer_14.check_psnr(p_on_test, out_decom, out_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
